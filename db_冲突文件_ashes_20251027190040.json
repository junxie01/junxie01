{"meta":{"version":1,"warehouse":"5.0.1"},"models":{"Asset":[{"_id":"source/CNAME","path":"CNAME","modified":1,"renderable":0},{"_id":"source/ads.txt","path":"ads.txt","modified":1,"renderable":0},{"_id":"source/robots.txt","path":"robots.txt","modified":1,"renderable":0},{"_id":"themes/next/source/css/main.styl","path":"css/main.styl","modified":1,"renderable":1},{"_id":"themes/next/source/css/noscript.styl","path":"css/noscript.styl","modified":1,"renderable":1},{"_id":"themes/next/source/images/algolia_logo.svg","path":"images/algolia_logo.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/alipay.jpg","path":"images/alipay.jpg","modified":1,"renderable":1},{"_id":"themes/next/source/images/alipay.png","path":"images/alipay.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/apple-touch-icon-next.png","path":"images/apple-touch-icon-next.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/avatar.gif","path":"images/avatar.gif","modified":1,"renderable":1},{"_id":"themes/next/source/images/bg.jpg","path":"images/bg.jpg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cartoon.jpg","path":"images/cartoon.jpg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","path":"images/cc-by-nc-nd.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","path":"images/cc-by-nc-sa.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc.svg","path":"images/cc-by-nc.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nd.svg","path":"images/cc-by-nd.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-sa.svg","path":"images/cc-by-sa.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by.svg","path":"images/cc-by.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-zero.svg","path":"images/cc-zero.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/favicon-16x16-next.png","path":"images/favicon-16x16-next.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/favicon-32x32-next.png","path":"images/favicon-32x32-next.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/icon.png","path":"images/icon.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/j-icon-16x16.png","path":"images/j-icon-16x16.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/j-icon-32x32.png","path":"images/j-icon-32x32.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/logo-algolia-nebula-blue-full.svg","path":"images/logo-algolia-nebula-blue-full.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/logo.svg","path":"images/logo.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/onion.jpg","path":"images/onion.jpg","modified":1,"renderable":1},{"_id":"themes/next/source/images/seisamuse.png","path":"images/seisamuse.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/wechat_channel.jpg","path":"images/wechat_channel.jpg","modified":1,"renderable":1},{"_id":"themes/next/source/images/wechatpay.jpg","path":"images/wechatpay.jpg","modified":1,"renderable":1},{"_id":"themes/next/source/images/wechatpay.png","path":"images/wechatpay.png","modified":1,"renderable":1},{"_id":"themes/next/source/js/bookmark.js","path":"js/bookmark.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/comments-buttons.js","path":"js/comments-buttons.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/comments.js","path":"js/comments.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/config.js","path":"js/config.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/motion.js","path":"js/motion.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/next-boot.js","path":"js/next-boot.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/pjax.js","path":"js/pjax.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/schedule.js","path":"js/schedule.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/sidebar.js","path":"js/sidebar.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/utils.js","path":"js/utils.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/third-party/addtoany.js","path":"js/third-party/addtoany.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/third-party/fancybox.js","path":"js/third-party/fancybox.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/third-party/pace.js","path":"js/third-party/pace.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/third-party/quicklink.js","path":"js/third-party/quicklink.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/third-party/analytics/baidu-analytics.js","path":"js/third-party/analytics/baidu-analytics.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/third-party/analytics/google-analytics.js","path":"js/third-party/analytics/google-analytics.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/third-party/analytics/growingio.js","path":"js/third-party/analytics/growingio.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/third-party/analytics/matomo.js","path":"js/third-party/analytics/matomo.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/third-party/chat/chatra.js","path":"js/third-party/chat/chatra.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/third-party/chat/tidio.js","path":"js/third-party/chat/tidio.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/third-party/comments/changyan.js","path":"js/third-party/comments/changyan.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/third-party/comments/disqus.js","path":"js/third-party/comments/disqus.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/third-party/comments/disqusjs.js","path":"js/third-party/comments/disqusjs.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/third-party/comments/gitalk.js","path":"js/third-party/comments/gitalk.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/third-party/comments/isso.js","path":"js/third-party/comments/isso.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/third-party/comments/livere.js","path":"js/third-party/comments/livere.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/third-party/comments/utterances.js","path":"js/third-party/comments/utterances.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/third-party/math/katex.js","path":"js/third-party/math/katex.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/third-party/math/mathjax.js","path":"js/third-party/math/mathjax.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/third-party/search/algolia-search.js","path":"js/third-party/search/algolia-search.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/third-party/search/local-search.js","path":"js/third-party/search/local-search.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/third-party/statistics/firestore.js","path":"js/third-party/statistics/firestore.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/third-party/statistics/lean-analytics.js","path":"js/third-party/statistics/lean-analytics.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/third-party/tags/mermaid.js","path":"js/third-party/tags/mermaid.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/third-party/tags/pdf.js","path":"js/third-party/tags/pdf.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/third-party/tags/wavedrom.js","path":"js/third-party/tags/wavedrom.js","modified":1,"renderable":1}],"Cache":[{"_id":"source/CNAME","hash":"1b08c75f029668b73f799332a7d19f07da16828e","modified":1716791202011},{"_id":"source/ads.txt","hash":"6553ac389f542a9341fc3d2cc65d12883145404b","modified":1716791195372},{"_id":"source/manifest.json","hash":"60bb1d62edf7d1cf362cdc96a1a8d8b266f48f07","modified":1716791797725},{"_id":"source/robots.txt","hash":"77aa9867d42bc5f009b06bad546ba80dfee58bbf","modified":1716791208505},{"_id":"source/_data/sidebar.njk","hash":"fb19daa19f4d0e91b7f1cd9f60dad64a8a170041","modified":1718554155203},{"_id":"source/about/index.md","hash":"df23e1308658d4ce4b344051e9f61b18f9b7c29d","modified":1726114138549},{"_id":"source/categories/index.md","hash":"0d10d91651cc71c8b12b5a2099b252a5a992c0e1","modified":1716791177507},{"_id":"source/_posts/2006-06-11-寂寞.md","hash":"4a298cd8295b37296aa95e8bf8bcf6a6e76b1267","modified":1716733056844},{"_id":"source/_posts/2006-11-24-阿甘.md","hash":"7f302a18d02a87216b0ce26153e4ed092064f995","modified":1716733056844},{"_id":"source/_posts/2007-04-14-好快刀.md","hash":"93a4b8daefc630909fb5bb854d66d49459c20fbe","modified":1716733056844},{"_id":"source/_posts/2007-12-13-南京大屠杀.md","hash":"dd09ef68272257ab1ac6fe1c0a55d972e8de0154","modified":1716733056844},{"_id":"source/_posts/2008-07-27-去他的.md","hash":"c3b5a4920d88b5140500d4468c497c0bd8775402","modified":1716733056844},{"_id":"source/_posts/2009-02-17-外婆外公的故事.md","hash":"99715ecbec611b8854a7a1b47dad6f18734b0560","modified":1716733056844},{"_id":"source/_posts/2009-04-10-星期五.md","hash":"562d72ee7646d3fe208d94d1389476eed6cb953e","modified":1716733056844},{"_id":"source/_posts/2009-08-12-the-city-of-life-and-death.md","hash":"82d35455b0d18a1bcb5238bf8b83c3a167daff2a","modified":1716733056844},{"_id":"source/_posts/2009-08-12-无题.md","hash":"9364c6672309ec35f1a5ce81b59e450199103368","modified":1716733056844},{"_id":"source/_posts/2009-08-18-mist.md","hash":"39faf798532c59e0e2ca3c27a9f48ebe8b9b639d","modified":1716733056844},{"_id":"source/_posts/2009-10-30-发霉了.md","hash":"eaa75411daf172b35232f372b24033c748fcabe4","modified":1716733056844},{"_id":"source/_posts/2009-11-20-流水一.md","hash":"939b127f9ce5945dcbff483db977586e22d91136","modified":1716733056844},{"_id":"source/_posts/2009-12-14-123.md","hash":"e466dbfd7a422159864a8f1f5c094fdda4209ca6","modified":1716733056845},{"_id":"source/_posts/2009-12-19-花木兰.md","hash":"442c608520145fb560dded1a2c02cb1fd1099e99","modified":1716733056845},{"_id":"source/_posts/2009-12-23-Dloc.md","hash":"c5d252080b2d3af70d78952e40526481713c983b","modified":1716733056845},{"_id":"source/_posts/2010-01-01-旧年.md","hash":"af7f2f88ee52fba0e7244507623d883d7e83662e","modified":1716733056845},{"_id":"source/_posts/2010-01-04-红色.md","hash":"2eb66b4af3b31b67d658103ecfe738e4aa6d91a2","modified":1716733056845},{"_id":"source/_posts/2010-01-12-头晕.md","hash":"5b102a0e0686d04bb9fff79d84e45820caa4dc5e","modified":1716733056845},{"_id":"source/_posts/2010-02-06-饭后感2.md","hash":"7269a7e19da153987480fda82b965017e0e48055","modified":1716733056845},{"_id":"source/_posts/2010-04-30-流水三.md","hash":"9befe5be77d5428bb1ef6f01d7def9979c888946","modified":1716733056845},{"_id":"source/_posts/2010-08-10-扑克.md","hash":"698def24f3a6ebb606dbc9c6f9a8033747d05227","modified":1716733056845},{"_id":"source/_posts/2010-10-11-消失的几天.md","hash":"a0dc83c6c42901ecfb7b219b10ba1422d3fd9e1c","modified":1716733056845},{"_id":"source/_posts/2010-10-21-宁波.md","hash":"148ee6df38cda85507844d0db37032755af8dc4c","modified":1716733056845},{"_id":"source/_posts/2010-11-12-怪癖.md","hash":"f0cf19205463ef636706d630212d734d29656124","modified":1716733056845},{"_id":"source/_posts/2011-01-13-愿逝者安息.md","hash":"4c90765469a57211fddf31c518e9c9e149f23d2e","modified":1716733056845},{"_id":"source/_posts/2011-02-18-成都印象.md","hash":"d9e7a136ca05a57cb31b2774076023a3a20a1eb0","modified":1716733056845},{"_id":"source/_posts/2011-02-22-读后感.md","hash":"e741f920203ccb4db230fdb6490caa7a5150b7fc","modified":1716733056845},{"_id":"source/_posts/2011-02-26-猫.md","hash":"48946025bfccf7cdb3afef3f444062d705caf0f0","modified":1716733056845},{"_id":"source/_posts/2012-02-09-活着or霸王别姬.md","hash":"606f7e9f0c5dab973371401680cbab41d4238a87","modified":1716733056845},{"_id":"source/_posts/2012-04-01-花卷.md","hash":"dbe89c06e650c96ae1ef9debc820542936a2b19a","modified":1716733056845},{"_id":"source/_posts/2013-12-09-雾霾齐步走.md","hash":"d6ac7de336ef76df65bf4085ec3b3cab1e3b3317","modified":1716733056845},{"_id":"source/_posts/2013-12-24-Win7下格掉Linux盘如何启动windows.md","hash":"6814e09cd9cf9e622a418c4e175c9500efb7f1cd","modified":1716733056845},{"_id":"source/_posts/2015-07-08-乱2.md","hash":"cce80649811afc8abc46bc409781d4e8af5a453f","modified":1716733056845},{"_id":"source/_posts/2015-11-01-启程去玛雅.md","hash":"90a5ffbb964770eaf419e6e17db55495d6e32831","modified":1716733056845},{"_id":"source/_posts/2015-11-01-血色乎浪漫.md","hash":"35622e79f3cf1f092bdd51c057cd8301d3b0fd8d","modified":1716733056845},{"_id":"source/_posts/2015-11-01-跟伴.md","hash":"3ea60a8eb89c443ae68029b224cae1f69dead21b","modified":1716733056845},{"_id":"source/_posts/2020-05-26-how-I-build-this-web.md","hash":"5943d53fd390366d21cd0b377a19f89626e68562","modified":1716733056845},{"_id":"source/_posts/2020-05-30-how-to-reply-to-reviewer.md","hash":"ddc6316dd0bd6937d19114b45a267c41e21a8e84","modified":1716733056845},{"_id":"source/_posts/2020-05-31-how-to-backup-hexo.md","hash":"e5eec3cfef9b8413ca2c5346c84e8ee92c3c6f01","modified":1716733056845},{"_id":"source/_posts/2020-05-31-passwd-free-for-deployment.md","hash":"67089a62ceddee2d074c62312464e7abde3e2acd","modified":1716733056845},{"_id":"source/_posts/2020-05-31-reward-configuration.md","hash":"044d8dc6965e368eddd3086b9e28b0fcb2ab5f3f","modified":1716733056845},{"_id":"source/_posts/2020-05-31-show-picture-in-hexo.md","hash":"3f65fe005d04c10dacacbe8ac82791ca117869a2","modified":1716733056845},{"_id":"source/_posts/2020-05-31-word-count.md","hash":"c2f29bf6033c47f3da2301321847cb3da49c69c5","modified":1716733056845},{"_id":"source/_posts/2020-06-03-about-diary.md","hash":"6dfaf19d05476280c18e0e78eaaa3ab4bbea43a2","modified":1716733056846},{"_id":"source/_posts/2020-06-03-wangyi-blog-transfer.md","hash":"feb78ef9074733931901ef85b24d70f3b0ba9b0c","modified":1716733056846},{"_id":"source/_posts/2020-06-04-funny-thing-about-Eric.md","hash":"521ed4dcffc1f2415f6783d1395caa4a177b9fc4","modified":1716733056846},{"_id":"source/_posts/2020-06-05-history-and-inversion.md","hash":"31ace6ab0d2b935746c040ab85661533b1b5c5d3","modified":1746862268051},{"_id":"source/_posts/2020-06-05-no-more-blog-transfer.md","hash":"ea3dc353069253ff54db66a5d16a89d74100d161","modified":1716733056846},{"_id":"source/_posts/2020-06-10-what-did-I-do-to-this-blog.md","hash":"64c16cb1a67361a352d5ad9b76240bce359f843c","modified":1716733056846},{"_id":"source/_posts/2020-06-12-learn-sed.md","hash":"950b79e74aa0d7f08e3835972d8c59c0a04623b3","modified":1716733056846},{"_id":"source/_posts/2020-06-18-stop-os-update.md","hash":"3baa520f36cce647d69db49cb976eca9f8b7e05d","modified":1716733056846},{"_id":"source/_posts/2020-06-20-how-to-add-frame-in-hexo-next.md","hash":"e287823f7296c9fe99854f406589c58021663030","modified":1716733056846},{"_id":"source/_posts/2020-06-22-install-and-backup-mediawiki.md","hash":"049e235ae6f8fe16172c728c06ca7406e79a3af9","modified":1716733056846},{"_id":"source/_posts/2020-06-23-avatar-to-homepage.md","hash":"bebffadee6c4b3fa4ced3e4b7ab51629b41f5230","modified":1716733056846},{"_id":"source/_posts/2020-07-04-gmt-time-axes.md","hash":"5c24aa8bc45104439dcefba12662ed73f1a6a204","modified":1716733056846},{"_id":"source/_posts/2020-07-05-how-to-use-fftw.md","hash":"02d6cd97ae2b452987fe1f2498668454d5425ea9","modified":1716733056846},{"_id":"source/_posts/2020-07-08-how-to-access-google.md","hash":"2442b1e3a2cdc7b2475355c5f3f6d8a540de9670","modified":1716733056846},{"_id":"source/_posts/2020-07-10-IQ-decrease.md","hash":"bec939685aabea65643f41f1a67c391d7817732a","modified":1716733056846},{"_id":"source/_posts/2020-07-21-mantle-transition-zone.md","hash":"83cffec2838ed46ce175e8be90f4b5389387e626","modified":1716733056846},{"_id":"source/_posts/2020-07-29-US-upper-mantle-vs-model.md","hash":"9637eb2948c623d4eb260a854a5b8f6fa6e06b43","modified":1716733056846},{"_id":"source/_posts/2020-07-31-how-to-configure-chinese-for-gmt.md","hash":"5ea32b093e751cf2033d53f62c92247a46210f9d","modified":1716733056847},{"_id":"source/_posts/2020-09-14-how-to-calculate-synthetic-NCF.md","hash":"ee018a7b498ff72b9e13d5c19b4b392cd1ccf54b","modified":1716733056847},{"_id":"source/_posts/2020-09-25-how-to-download-video-from-internet.md","hash":"b5532b075cecba6970080838ba71efe04e14cf41","modified":1716733056847},{"_id":"source/_posts/2020-11-07-about-anti-paper.md","hash":"4b4a5ca139cd0218bb271fc66f93f190c2b6bf2f","modified":1716733056847},{"_id":"source/_posts/2020-11-19-addiction.md","hash":"b25991a41ebad245b43827a1c06216d216c87e0f","modified":1716733056847},{"_id":"source/_posts/2020-11-20-how-to-install-filezilla.md","hash":"d909177c965508877b7a14ef4ba3e6e037da47fb","modified":1716733056847},{"_id":"source/_posts/2021-02-12-happy-new-year.md","hash":"baf966cd5a1a6161f0ae97c20c1eefa631fecd7a","modified":1716733056847},{"_id":"source/_posts/2021-03-02-after-fedora32.md","hash":"61ceb801ed49a566d1fc487010fef4dda8bc47b4","modified":1716733056847},{"_id":"source/_posts/2021-03-08-sky-and-universe.md","hash":"b9068a57633b18142639e26a87c6d0716b2a74d9","modified":1716733056847},{"_id":"source/_posts/2021-03-09-read-file-bash.md","hash":"672df6be273a79f42bc185d2f835bbd609b3390b","modified":1716733056847},{"_id":"source/_posts/2021-03-29-pdf.md","hash":"49ae3e53ed95a4cb4907a21af33c0900aa070941","modified":1716733056847},{"_id":"source/_posts/2021-07-23-install-elementary-os-again.md","hash":"b4c7552b6c6137c1bc9bcdf2a6bedf3086e96b43","modified":1716733056847},{"_id":"source/_posts/2024-05-26-reference-mod.md","hash":"e7e22d1bc8b7acdc69b0c61ab995531b050b36a5","modified":1716791258006},{"_id":"source/_posts/2024-05-27-add_counter.md","hash":"1f038694e3789d5a0a31bce824eb106022c1c418","modified":1716896511234},{"_id":"source/_posts/2024-05-27-git-error.md","hash":"f76ae2666db33220924c108ffed040cdbf13be34","modified":1716897401463},{"_id":"source/_posts/2024-05-27-optimize-daily-task.md","hash":"6b9b27ec153434af74c665ae52d3e329f077d22e","modified":1716896441309},{"_id":"source/_posts/2024-05-28-encrypt_test.md","hash":"65f218b8789b23a298d16e7e9b00e1f96fde2a9f","modified":1750217006181},{"_id":"source/_posts/2024-05-27-rule-no1.md","hash":"1eeaf27011f06c439b63a49c939e03b51571bd9d","modified":1716896419495},{"_id":"source/_posts/2024-05-28-how-to-add-frame.md","hash":"7cc2e1b17132faeace037aa1db34a1d5bfaded85","modified":1716896218834},{"_id":"source/_posts/2024-05-28-how-to-encrypt.md","hash":"b295df0e8dc7f6537967e75216adae4ae9493743","modified":1716896189756},{"_id":"source/_posts/2024-05-28-how-to-pretend-you-know.md","hash":"5ffe7ddf81f86f236818d846dcf0ea093014189a","modified":1716896146552},{"_id":"source/_posts/2024-05-28-how-to-use-utterances.md","hash":"871e98b077eb3d7ccb559a4cceccc445e135e6fd","modified":1716896102796},{"_id":"source/_posts/2024-05-29-to-desk.md","hash":"a95fd06a05922640388c6600f08a97f7d955c7f6","modified":1718374993230},{"_id":"source/_posts/2024-05-31-how-to-set-X11-in-fedora.md","hash":"9647dcac1b78b7c91debfc87ffb725be4b015f5d","modified":1718374948443},{"_id":"source/_posts/2024-06-03-ai-tools.md","hash":"d6b5bf28ba143e9483ecdaa561162d7de3961006","modified":1717409742880},{"_id":"source/_posts/2024-06-06-no-audio-control.md","hash":"f89a2859536b799a43c1c2f94c972d58532622c3","modified":1717638193742},{"_id":"source/_posts/2024-06-06-no-audio-in-playing-browser-video.md","hash":"b6e548c8441a0f3232200b8a49941f2612d4a0de","modified":1717649294737},{"_id":"source/_posts/2024-06-06-no-file-found-in-LaTeX.md","hash":"e42e6a4c700c2695a533407f4484d6bfd69c25bf","modified":1717641077929},{"_id":"source/_posts/2024-06-11-memorise-blue.md","hash":"89f6ed505c62604c5fcdf2d1fc91f13580af08b6","modified":1718374903715},{"_id":"source/_posts/2024-06-14-how-to-make-the-brain-sharp.md","hash":"8c95243a9fb67a116832ba7633613088cce8f0b5","modified":1718448459949},{"_id":"source/_posts/2024-06-13-object-detection.md","hash":"efa5a2c79af66097f0394d1eb85ba0f17903696c","modified":1718290851493},{"_id":"source/_posts/2024-06-15-how-to-write-blog.md","hash":"b1a731f16a9cbf364d801c86e76bde947ca3f9f5","modified":1718411049458},{"_id":"source/_posts/2024-06-03-gls1.md","hash":"48fbecf72f7fc78c08fa8dcac5a9a6e7a9e5a8d4","modified":1717553980666},{"_id":"source/_posts/2024-06-15-paper-reading-2.md","hash":"dcfd19a8b7274a2ab009468671408f38e608b0d7","modified":1718609498406},{"_id":"source/_posts/2024-06-14-paper-reading-1.md","hash":"6dcfa9337eedd09872df12d38b7b736358328b22","modified":1718377207802},{"_id":"source/_posts/2024-06-15-paper-reading-3.md","hash":"b670b22f7832e59e26c9fed0e2a6d4ee28411334","modified":1718448413209},{"_id":"source/_posts/2024-06-15-paper-reading.md","hash":"e2d94ff245aed5103ba0fe7cf2e46b49b25d82d6","modified":1718687894409},{"_id":"source/_posts/2024-06-16-paper-reading-4.md","hash":"4975c20d929d2a7cb953a30aa7db1abf2daba9f6","modified":1718552756985},{"_id":"source/_posts/2024-06-16-paper-reading-5.md","hash":"f0c240a0efb8945f8bab24eaf8da5dd8cdf9a1b0","modified":1718553548007},{"_id":"source/_posts/2024-06-17-how-to-review.md","hash":"32e876fb2b2aea03f6492ffdbd4071379010c692","modified":1718677184538},{"_id":"source/_posts/2024-06-17-paper-reading-6.md","hash":"eb686854207c2dc22ba55c26a35c407208e15b3c","modified":1718592509364},{"_id":"source/_posts/2024-06-17-paper-reading-7.md","hash":"0f76d147d1e69bc341f77f8ad49b3b88fb600fde","modified":1718687613591},{"_id":"source/_posts/2024-06-18-add-video.md","hash":"8274c1275db236a20279e1fed3ff0c20d20ef334","modified":1718714529317},{"_id":"source/_posts/2024-06-18-paper-reading-10.md","hash":"51136927869c8b6f3720d1fe0f9c772bcdd1711a","modified":1718716399143},{"_id":"source/_posts/2024-06-18-paper-reading-8.md","hash":"7a9144c1460335bdff7182da7d5487cf3ab76dcf","modified":1718687749799},{"_id":"source/_posts/2024-06-18-paper-reading-9.md","hash":"9b7003d7016cb14f0f51a322b8ec36751158ecaa","modified":1718692399514},{"_id":"source/_posts/2024-06-19-paper-reading-11.md","hash":"9fd474aea08851aac03bddd1bdb427ea76b7a064","modified":1718842487694},{"_id":"source/_posts/2024-06-20-code-and-project1.md","hash":"2b4fe2da26c2b3756d3fe15845d48fdd51218059","modified":1744878527248},{"_id":"source/_posts/2024-06-20-how-to-read-paper.md","hash":"fb2945baf9c16d0d28d313b5cb0d168ed3acda05","modified":1718870358685},{"_id":"source/_posts/2024-06-20-paper-reading-12.md","hash":"ac3bd25b3917ace91598687630de693197c622c5","modified":1718852043477},{"_id":"source/_posts/2024-06-20-paper-reading-13.md","hash":"c8613fffcec1e0a17062c77b3eca70dd768a7002","modified":1718866646048},{"_id":"source/_posts/2024-06-20-science-blogs.md","hash":"f6698a04ffaf98efd7490fdd557173c69a7e19ec","modified":1722906022636},{"_id":"source/_posts/2024-06-22-paper-reading-14.md","hash":"810a6470e7ed3c4a2c25717b7b48e4d454252977","modified":1719024999302},{"_id":"source/_posts/2024-06-26-paper-reading-15.md","hash":"d6fa5f3deb81b389f3acc72dc21f8a2cc75c9369","modified":1719411711301},{"_id":"source/_posts/2024-06-27-paper-reading-16.md","hash":"361f642ded9e411463a1be2553de4d6b7ebdf3ba","modified":1719449531587},{"_id":"source/_posts/2024-06-27-paper-reading-17.md","hash":"dd6d4b28a77888f3a7aff2f420adb46e197d04ee","modified":1719450218428},{"_id":"source/_posts/2024-06-29-paper-reading-18.md","hash":"d8f8a9f24e15f9d62191eb120f9b3ff0d0878267","modified":1719630653503},{"_id":"source/_posts/2024-07-09-how-to-download-Snet-data.md","hash":"4bbe994068b3ff031a554107deba0b35f821f8cb","modified":1720516276289},{"_id":"source/_posts/2024-07-19-music.md","hash":"d91c13ea5eb3e207d141ce7362ea89a5b94d48ad","modified":1750215323140},{"_id":"source/_posts/2024-07-25-obspy-paz.md","hash":"4e0e610b4ba6eba11b716bb3c1bfe594133d4857","modified":1740364888024},{"_id":"source/_posts/2024-09-01-how-to-download-fnet-station-list.md","hash":"c6e33dbad456a5c50d07b6d9feef75dd1c179760","modified":1725159760385},{"_id":"source/_posts/2024-09-03-paper-reading-19.md","hash":"5492308bd87adecfb0fe41dbd662e7b5eb763866","modified":1725372748701},{"_id":"source/_posts/2024-09-09-paper-reading-20.md","hash":"16e5343e4b94ea3ad75171a2532a60c7c78b00bd","modified":1728105574234},{"_id":"source/_posts/2024-10-05-paper-reading-21.md","hash":"6c7abc99a708c015ac9959a7b717bed6a9dd0cf0","modified":1728105588638},{"_id":"source/_posts/2024-10-12-efficient-shell-script.md","hash":"9a37d280fefa4d4be6a1a44a103792b7260b7994","modified":1728711725998},{"_id":"source/_posts/2024-10-30-paper-reading-22.md","hash":"a5b6efc5061cb0d881a6d7b6d1798688a9f542d7","modified":1730529226621},{"_id":"source/_posts/2024-11-02-paper-reading-23.md","hash":"95ebd7f8f89096e17e27296b0870a7ce0ee8dedf","modified":1730533762068},{"_id":"source/_posts/2024-11-07-paper-reading-24.md","hash":"7dcf4ec9bc1fba00b4cec00d13ec7ca143ec5d51","modified":1739184068832},{"_id":"source/_posts/2024-12-19-find-linux-back.md","hash":"d6e5e0ecd78faa20f6219ca558a84d66853d8369","modified":1734608345492},{"_id":"source/_posts/2025-02-05-how-to-install-deepseek.md","hash":"bace8477db69f6ca660fa198f28b7f634c99868f","modified":1738744208930},{"_id":"source/_posts/2025-02-10-paper-reading-25.md","hash":"e8613202c463f99b2d903af500adfd249eb28928","modified":1739184068035},{"_id":"source/_posts/2025-02-14-paper-reading-26.md","hash":"40f517f8c5e16b5aaaf19b1b5f270a524ea4fcbd","modified":1739516348702},{"_id":"source/_posts/2025-04-17-code-and-project2.md","hash":"9cc9c3e75bdf90fcc93fa82df71dc7b1cdf783f5","modified":1745029801980},{"_id":"source/_posts/2025-04-21-down-ambient-noise-py.md","hash":"a850e2cd87569e73aca2f8fb9754b05070e8e9ab","modified":1745241780240},{"_id":"source/_posts/2025-04-22-download-fnet-data-py.md","hash":"c2d3c3ebac82f3c350a072ff6ab4e0af06804141","modified":1745283240522},{"_id":"source/_posts/2025-04-23-paper-reading-27.md","hash":"ca8e3a42eb3d2f5e614cce86b5a53f124086217f","modified":1745394449840},{"_id":"source/_posts/2025-04-23-remove-response-miniseed.md","hash":"9579722f9e87edf3ada742150589f3b055a71e55","modified":1745392734078},{"_id":"source/_posts/2025-04-24-download-earthquake-py.md","hash":"d76682ec0ee64971824f09b6adf8c5c7cb3749e5","modified":1747377719516},{"_id":"source/_posts/2025-05-10-gmt-arrow.md","hash":"386ecc61261cb55f35f40c7c3b115b88dd7bac11","modified":1746930201948},{"_id":"source/_posts/2025-05-10-mouse-click-monitoring.md","hash":"c02bf610183103cf17e4a2d9ade486bd9367292b","modified":1746930166618},{"_id":"source/_posts/2025-05-16-download-eq-data.md","hash":"37c77aac92ff00625fee48161851ebe4cd591b1c","modified":1747377979646},{"_id":"source/_posts/2025-05-31-bad-and-evil.md","hash":"d86447132cd99aa077d635965d53d99fcbaeea2e","modified":1748776731192},{"_id":"source/_posts/2025-06-01-attention-mechanism.md","hash":"2f7ddef7e326b3596d44dfc0743b876f6fd2184e","modified":1748782883897},{"_id":"source/_posts/2025-06-07-statistic-data-download.md","hash":"62c795632f5e8a7eb1d49ed38dac4ca5429a56f0","modified":1749297491040},{"_id":"source/_posts/2025-06-07-download-continuous-seis.md","hash":"46a40917b0e3adfe44ccfeeaed73e97f341b2221","modified":1749297068953},{"_id":"source/_posts/2025-06-08-download-continous-data-update.md","hash":"5196dc2b9ce1ccb6d8facd93e63d25e64e578f60","modified":1749391323497},{"_id":"source/_posts/2025-06-08-problem-of-urllib3.md","hash":"0bdca8b16657ecdeea6ee91f3a9b0b8352d0f3e4","modified":1749364185887},{"_id":"source/_posts/2025-06-17-how-to-install-wemeet.md","hash":"23eee05ce7cbaefa560e84dedf814392415c1415","modified":1750138563503},{"_id":"source/_posts/2025-06-17-plot-work-flow.md","hash":"4e3e1ca5f2ee59ad8b735943391eaf4603b6e2d0","modified":1750209167774},{"_id":"source/_posts/2025-06-17-run-sequencer.md","hash":"f0527c419302057ae87accbe080b917e75da566c","modified":1750216787359},{"_id":"source/_posts/2025-06-21-jupyter-notebook-extensions.md","hash":"978e44877e1be0ba1476646d5261627fda17d8f3","modified":1750509004873},{"_id":"source/_posts/2025-06-21-latex-math-express.md","hash":"7b32b04a34de2d9e5e7e36ec0398f90b21066d96","modified":1750497953424},{"_id":"source/_posts/2025-06-21-news-website.md","hash":"d0f0b428ca00b1d124a63a5921d5a2aff5eacf51","modified":1750504983220},{"_id":"source/_posts/2025-06-21-python-script1.md","hash":"c5b3998ba5d2bb241f81f5baaf7430a2c1034ad1","modified":1751290269319},{"_id":"source/_posts/2025-06-27-mfp.md","hash":"799d2bf8392e5a570f9fceaaa4186a8107b5b690","modified":1750986434517},{"_id":"source/_posts/2025-06-30-python-script2.md","hash":"4db03a04945e0c63f5f3c892f38ce7d05df2d3cc","modified":1751291010793},{"_id":"source/_posts/2025-07-01-distribute-package.md","hash":"826ebe620554b958f5fde969b41fcbdea0ee1d39","modified":1751342197835},{"_id":"source/_posts/2025-08-24-fk.md","hash":"9d1a6146956b6c35d017f1d9836cddac98df2162","modified":1756130621362},{"_id":"source/_posts/2025-08-25-png-to-mp4.md","hash":"cb147387d0647a13585a9949f7a0b847f0b98bd0","modified":1756130448919},{"_id":"source/_posts/2025-10-06-fedora-install-freshress.md","hash":"1ebbae7c6f60afb3d45c3f1df2c2ff3a2a942216","modified":1759796547125},{"_id":"source/_posts/2025-10-10-paper-reading-28.md","hash":"ccbb51198e9f0b32b4abff386c61ce09fd004c1b","modified":1760074069511},{"_id":"source/_posts/2025-10-19-paper-reading-29.md","hash":"9a619742a8ccd1ecc94e54257e6ff15762f63fcc","modified":1760880910939},{"_id":"source/tags/index.md","hash":"8c50777be14255c82b3ed89a982b17a34646ee7a","modified":1716791167286},{"_id":"source/_posts/2025-10-24-noise-source-back-azimuth.md","hash":"04ce2ce24c11b3e793f2474036eae784c4771957","modified":1761274282342},{"_id":"source/_posts/2020-06-20-how-to-add-frame-in-hexo-next/frame.png","hash":"3e7779737fca44d93f3659c9595898ee5651158a","modified":1716733056846},{"_id":"source/_posts/2020-07-31-how-to-configure-chinese-for-gmt/pstext.png","hash":"1ec300ebc2457ccd9d0ec9cf07e80a24d1bd1dfe","modified":1716733056846},{"_id":"source/_posts/2021-02-12-happy-new-year/acce.png","hash":"90bdd202a7bbbd2bbd5322a6f6e92b510f567f30","modified":1716733056847},{"_id":"source/_posts/2020-05-31-reward-configuration/donate.png","hash":"2b4ffd57019bfa452247194fdf83879c7da04b7a","modified":1716733056845},{"_id":"source/_posts/2020-07-10-IQ-decrease/iq.jpg","hash":"76643626c56b2e5107b38df376ac035b2f661b81","modified":1716733056846},{"_id":"source/_posts/2020-07-21-mantle-transition-zone/Picture2.png","hash":"c5acabd7384c45c65ef286bf5c47f1b1e9caebc3","modified":1716733056846},{"_id":"source/_posts/2020-06-18-stop-os-update/app.png","hash":"56687bfb4ca03a699c1f3674285a1317a86f2494","modified":1716733056846},{"_id":"source/_posts/2020-07-04-gmt-time-axes/1.png","hash":"9942242d7e71451dc6f45e21af4f3c14b0fb8be9","modified":1716733056846},{"_id":"source/_posts/2020-07-04-gmt-time-axes/2.png","hash":"8c5f225e6e265eb49d8470d536642003ef748673","modified":1716733056846},{"_id":"source/_posts/2020-09-14-how-to-calculate-synthetic-NCF/source_dis.png","hash":"1923233a6d9a4b302b1b0cc8c20a5658c2dab6f6","modified":1716733056847},{"_id":"source/_posts/2020-07-04-gmt-time-axes/spec.png","hash":"7fbfe86da3d9bdd9b87c093cb80b0a1351aad8df","modified":1716733056846},{"_id":"source/_posts/2020-07-29-US-upper-mantle-vs-model/figure5.png","hash":"4c7a6263723d30021eda57676063f1c6f9c51cee","modified":1716733056846},{"_id":"themes/next/README.md","hash":"20d3aab17b7d9b7ab537800a5ee932af8438664a","modified":1716732167059},{"_id":"themes/next/_vendors.yml","hash":"82dc85404bb716360c136059f8b4ead67f46549c","modified":1716732167061},{"_id":"themes/next/_config.yml","hash":"77f69a2f3ce464add52f1f0a64b7fe3bf2e3d2fe","modified":1761207621289},{"_id":"themes/next/LICENSE.md","hash":"68fc9a03d50fd4b5ea97092b05967d1819dea2c4","modified":1716732167058},{"_id":"themes/next/package.json","hash":"4299d2c9c9564503b0c3c3919a51b1d78ff15b64","modified":1716884899656},{"_id":"themes/next/docs/AUTHORS.md","hash":"a648823121563c34a177ae91f5a774b5e29f01a0","modified":1716732167058},{"_id":"themes/next/docs/AGPL3.md","hash":"0d2b8c5fa8a614723be0767cc3bca39c49578036","modified":1716732167058},{"_id":"themes/next/docs/LICENSE.txt","hash":"f5b14f791b7cfa1d16da981d929152e088a5d1b8","modified":1716732167058},{"_id":"themes/next/languages/README.md","hash":"b2567e32805dda79601157351a07e5ca9fe01315","modified":1716732167058},{"_id":"themes/next/languages/ar.yml","hash":"7d0f39e8684284a04bb9808521c87fecda8bd131","modified":1716732167058},{"_id":"themes/next/languages/bn.yml","hash":"564bed75da6e05b11dce6164508f97a15e2fb6c2","modified":1716732167058},{"_id":"themes/next/languages/de.yml","hash":"79b37df731c29665dee6cd7c90d278e1edfb6e24","modified":1716732167058},{"_id":"themes/next/languages/en.yml","hash":"ba0fd79a2b1d8db01a034180556061745965ff05","modified":1716732167058},{"_id":"themes/next/languages/eo.yml","hash":"e34bb33ae827bf2f0727088599a73bc64bdad1b0","modified":1716732167058},{"_id":"themes/next/languages/es.yml","hash":"dffc63ef42e1266b88e0acf08994fd17a9908d53","modified":1716732167058},{"_id":"themes/next/languages/fa.yml","hash":"f3ffc444599f4ac92d62e9ed00a1490ebc277d70","modified":1716732167058},{"_id":"themes/next/languages/fr.yml","hash":"8ac44e58f71a38b7697a2f7f98a6971ed818cb5b","modified":1716732167058},{"_id":"themes/next/languages/id.yml","hash":"929df147f4f17d638b07de5fe52ca13e2549ab1c","modified":1716732167058},{"_id":"themes/next/languages/it.yml","hash":"16d716ecfd748def2f6486ef5a82d0ab7ceb4890","modified":1716732167058},{"_id":"themes/next/languages/ja.yml","hash":"543222bfc516aab6c33e8534f807972ecb8943a9","modified":1716732167058},{"_id":"themes/next/languages/nl.yml","hash":"3cb3687696635ec71b4ca40c5fc43b56acc8843e","modified":1716732167059},{"_id":"themes/next/languages/pt-BR.yml","hash":"76b8576ce228d540a16b1f0af5af2cce20923194","modified":1716732167059},{"_id":"themes/next/languages/pt.yml","hash":"70de366e10ea584ba039d40d6b35ac97f93454ad","modified":1716732167059},{"_id":"themes/next/languages/ko.yml","hash":"d345a303310c8a5f4836c3683f3580f861ebd1b4","modified":1716732167058},{"_id":"themes/next/languages/ru.yml","hash":"c6d8de0ff7d8148d09993257cfd3b7aca755696c","modified":1716732167059},{"_id":"themes/next/languages/si.yml","hash":"2d712eedf3f60d04d36c3108cf5a12e2a52e875c","modified":1716732167059},{"_id":"themes/next/languages/th.yml","hash":"6829e998b39f8f143e20b276bb1f62d95a29de58","modified":1716732167059},{"_id":"themes/next/languages/tr.yml","hash":"a57e4ed089b893a95f5e1ecff17ce625165f4d46","modified":1716732167059},{"_id":"themes/next/languages/uk.yml","hash":"ff537047b4b4c3ca9a7b64fa7f428a9942751eeb","modified":1716732167059},{"_id":"themes/next/languages/vi.yml","hash":"7ebcba5e1128784195e4681dffc9d34c4e873fec","modified":1716732167059},{"_id":"themes/next/languages/zh-CN.yml","hash":"741d7efe0262c9cdc2c648014b55599665d90f6b","modified":1716732167059},{"_id":"themes/next/languages/zh-HK.yml","hash":"88ea50eeb9097ab4a87a44981a102d8594feb064","modified":1716732167059},{"_id":"themes/next/languages/zh-TW.yml","hash":"4695c87d6b81b3a23d16ad6513d9eaa925f8d8ad","modified":1716732167059},{"_id":"themes/next/languages/tk.yml","hash":"511726054873f6f8d7ce0d2e803f6731de0ddbe7","modified":1716732167059},{"_id":"themes/next/layout/_layout.njk","hash":"fc0a45112f2dcfc2642404e8934ea32a793c3bd7","modified":1716732167059},{"_id":"themes/next/layout/archive.njk","hash":"d759f4d2cf5ddc6875ea250113a00662c1caf6d1","modified":1716732167061},{"_id":"themes/next/layout/category.njk","hash":"c68b7343d0f8145010f93351908cc36ef6212ec1","modified":1716732167061},{"_id":"themes/next/layout/page.njk","hash":"af6d7570621be760536c216a56d74e40a1cceae2","modified":1716732167061},{"_id":"themes/next/layout/post.njk","hash":"0bfce9f133f501a9a4837257e3b862b3bbca15be","modified":1716732167061},{"_id":"themes/next/layout/tag.njk","hash":"9e16ba20c28a7f2c6bc75aa427f48122301a30aa","modified":1716732167061},{"_id":"themes/next/docs/ru/README.md","hash":"0be2d7a75ffc3d9a963cf89a13bd1b50579f8304","modified":1716732167058},{"_id":"themes/next/layout/index.njk","hash":"dd63e488ae8cc144335a5958acedf6a16edd7a92","modified":1716732167061},{"_id":"themes/next/docs/zh-CN/CODE_OF_CONDUCT.md","hash":"12a6631617695504d5cf2a94b57d87bd331bef6f","modified":1716732167058},{"_id":"themes/next/docs/zh-CN/CONTRIBUTING.md","hash":"a089f7a8368ab0b7d7b9b7ec0ac3767a453435df","modified":1716732167058},{"_id":"themes/next/docs/zh-CN/README.md","hash":"287f57dbdfd23341800a0ff310f3474272b9dcc8","modified":1716732167058},{"_id":"themes/next/layout/_macro/post.njk","hash":"952449064fcb6a5cefc281b585f9149809f857f1","modified":1716732167061},{"_id":"themes/next/layout/_macro/sidebar.njk","hash":"547c62ab14d9e05d2d9116db9048a677fbe1fb6d","modified":1717552549093},{"_id":"themes/next/layout/_macro/sidebar.njk.bk","hash":"b7133685cdd212f98026d98cba75f57bb7578438","modified":1717552540250},{"_id":"themes/next/layout/_partials/comments.njk","hash":"d0c470b0f6690aa217e9ada848c5e2e73fb27c6f","modified":1716732167060},{"_id":"themes/next/layout/_macro/post-collapse.njk","hash":"313637fe3569f98fd926e8cd0fcc75d098eb6e6e","modified":1716732167061},{"_id":"themes/next/layout/_partials/footer.njk","hash":"f412995bdc31d11f779ce1a8be07a72cbb711c29","modified":1716800706993},{"_id":"themes/next/layout/_partials/languages.njk","hash":"e43f22198cccb5f6e306b1ce0d28d12a4fb891f8","modified":1716732167060},{"_id":"themes/next/layout/_partials/pagination.njk","hash":"bc719473ed5948ab6859449d60b8d36cfc1542b4","modified":1716732167060},{"_id":"themes/next/layout/_scripts/index.njk","hash":"7ed1fa981bf4765af092d7b178acbdeeb95d5b20","modified":1716732167061},{"_id":"themes/next/layout/_scripts/vendors.njk","hash":"be80b9fe415a9a09d74c28e230995fd292dfc123","modified":1716732167061},{"_id":"themes/next/layout/_third-party/addtoany.njk","hash":"ef64c6bfb8540cd874701236b9be47db2496e98e","modified":1716732167059},{"_id":"themes/next/layout/_third-party/fancybox.njk","hash":"844559f46e2ff1c8be234d5763703106e2072a7b","modified":1716732167060},{"_id":"themes/next/layout/_partials/widgets.njk","hash":"d83fb59f02c5e6630a7770401a05c02f6f07358b","modified":1716732167061},{"_id":"themes/next/layout/_third-party/index.njk","hash":"dfd7cdd6ba89f8c3deabc27726c7a350cadafd11","modified":1716732167060},{"_id":"themes/next/layout/_third-party/pace.njk","hash":"d7ad5714079f7f65446f880baf14722435ca9061","modified":1716732167060},{"_id":"themes/next/layout/_third-party/quicklink.njk","hash":"0efed71ed530447718c4ea5bbd5fc8695b0b0d5f","modified":1716732167060},{"_id":"themes/next/scripts/filters/default-injects.js","hash":"872f01cb10e422a648ea505436532e776e92926b","modified":1716732167057},{"_id":"themes/next/scripts/filters/locals.js","hash":"9eb5310664759931287dd28ea39165dfb67f12ed","modified":1716732167057},{"_id":"themes/next/scripts/filters/minify.js","hash":"2063aaa1db448ebcf7b0fdbbc54d3991a368bbd3","modified":1716732167057},{"_id":"themes/next/scripts/filters/post.js","hash":"fdc8a0af90035e89c3fcb754a0eb189b8951a2bc","modified":1716732167057},{"_id":"themes/next/scripts/events/index.js","hash":"bd9ea82376cd87df611ea3ae077875c7c595a3df","modified":1716732167058},{"_id":"themes/next/scripts/helpers/engine.js","hash":"049b1a0b66563e39f68710bb576a8c7342ae749c","modified":1716732167058},{"_id":"themes/next/scripts/helpers/font.js","hash":"3394185a7f0393c16ce52c8028f90da3e9239c55","modified":1716732167058},{"_id":"themes/next/scripts/helpers/navigation.js","hash":"78107021101553c3d23e89290f7530b60cf4aa86","modified":1716732167058},{"_id":"themes/next/scripts/helpers/next-paginator.js","hash":"e86c764b546e4fbb87970cabc4135a56f9ef9fe1","modified":1716732167058},{"_id":"themes/next/scripts/helpers/next-config.js","hash":"ce6bd4054653a4066b19869819a17b568eeee915","modified":1716732167058},{"_id":"themes/next/scripts/helpers/next-url.js","hash":"6281d47c1de98eb38f3aa0f6df29bbb19d412173","modified":1716732167058},{"_id":"themes/next/scripts/helpers/next-vendors.js","hash":"af3946a595f997eb43d9af87428e4898c9acbc82","modified":1716732167058},{"_id":"themes/next/scripts/tags/button.js","hash":"c6ad2ed544fbb25ecb5d820c36e76302504271b7","modified":1716732167057},{"_id":"themes/next/scripts/tags/caniuse.js","hash":"935a311142a409c1896b3ae3f01fe7a9e2db1134","modified":1716732167057},{"_id":"themes/next/scripts/tags/center-quote.js","hash":"92c19d796bdb3320df9caea59bf52df7a95d9da9","modified":1716732167057},{"_id":"themes/next/scripts/tags/group-pictures.js","hash":"8d205b7ffdaa9a89bb8f75410507ee1bab230f55","modified":1716732167057},{"_id":"themes/next/scripts/tags/index.js","hash":"1f6aba7820f1fb58b61969485148db21846e1aa9","modified":1716732167057},{"_id":"themes/next/scripts/tags/label.js","hash":"8a73348186113bae0a51ea2f891c1bb882fab05a","modified":1716732167057},{"_id":"themes/next/scripts/tags/link-grid.js","hash":"18a483c2d5afd701f6080ffdddf2d1321370336c","modified":1716732167057},{"_id":"themes/next/scripts/tags/mermaid.js","hash":"4fb01ca650fa8b256b8d48f50dc1b18350bd3d6d","modified":1716732167057},{"_id":"themes/next/scripts/tags/note.js","hash":"7b94ddb46b7d4b0fe815f2fbe4bd375f07f55363","modified":1716732167057},{"_id":"themes/next/scripts/tags/pdf.js","hash":"344636b6fd7e27e8831c1e194039afc0d61931cd","modified":1716732167057},{"_id":"themes/next/scripts/tags/tabs.js","hash":"0eabe51da40b4b13e16419c8fe02452d9a4fef73","modified":1716732167057},{"_id":"themes/next/scripts/tags/video.js","hash":"2ee926448583be8f95af1f2884ae2c9c4830151d","modified":1716732167057},{"_id":"themes/next/scripts/tags/wavedrom.js","hash":"b44dfeeb58b41945d469141787f3dbce4b117d08","modified":1716732167057},{"_id":"themes/next/source/css/_colors.styl","hash":"3c6798c10cc220d83481cb3f3782e78558cee789","modified":1716732167054},{"_id":"themes/next/source/css/_mixins.styl","hash":"bbeae369eaba9a2565fc359a5b79184d21bdd167","modified":1716732167055},{"_id":"themes/next/source/css/main.styl","hash":"921a58577f411cf4eb5cfd66db0a241f8f88578c","modified":1716732167057},{"_id":"themes/next/source/css/noscript.styl","hash":"dadc81256afb127b77eac6763d5ee0ec9c77f0a3","modified":1716732167057},{"_id":"themes/next/source/images/algolia_logo.svg","hash":"ec119560b382b2624e00144ae01c137186e91621","modified":1716735885676},{"_id":"themes/next/source/images/apple-touch-icon-next.png","hash":"2959dbc97f31c80283e67104fe0854e2369e40aa","modified":1716735885676},{"_id":"themes/next/source/images/avatar.gif","hash":"18c53e15eb0c84b139995f9334ed8522b40aeaf6","modified":1716735885676},{"_id":"themes/next/source/images/alipay.png","hash":"15569378dd21b0c710373d897a44603a3bed387b","modified":1716735885676},{"_id":"themes/next/source/images/cartoon.jpg","hash":"042af7387a7795d23ac492dd9080b6e0867d0d3e","modified":1716735885676},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","hash":"c6524ece3f8039a5f612feaf865d21ec8a794564","modified":1716735885676},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","hash":"3031be41e8753c70508aa88e84ed8f4f653f157e","modified":1716735885676},{"_id":"themes/next/source/images/cc-by-nc.svg","hash":"8d39b39d88f8501c0d27f8df9aae47136ebc59b7","modified":1716735885676},{"_id":"themes/next/source/images/cc-by-nd.svg","hash":"c563508ce9ced1e66948024ba1153400ac0e0621","modified":1716735885676},{"_id":"themes/next/source/images/cc-by-sa.svg","hash":"aa4742d733c8af8d38d4c183b8adbdcab045872e","modified":1716735885676},{"_id":"themes/next/source/images/cc-by.svg","hash":"28a0a4fe355a974a5e42f68031652b76798d4f7e","modified":1716735885676},{"_id":"themes/next/source/images/cc-zero.svg","hash":"87669bf8ac268a91d027a0a4802c92a1473e9030","modified":1716735885676},{"_id":"themes/next/source/images/favicon-16x16-next.png","hash":"943a0d67a9cdf8c198109b28f9dbd42f761d11c3","modified":1716735885676},{"_id":"themes/next/source/images/favicon-32x32-next.png","hash":"0749d7b24b0d2fae1c8eb7f671ad4646ee1894b1","modified":1716735885676},{"_id":"themes/next/source/images/icon.png","hash":"f7d14d0eba4a2d69b26b7cdf229156e0048ebff6","modified":1716735885676},{"_id":"themes/next/source/images/j-icon-16x16.png","hash":"d5f47b175f172971fc3fe3e891b8db767dc8d055","modified":1716735885676},{"_id":"themes/next/source/images/j-icon-32x32.png","hash":"ee0dc2efce610affbaa13c416251dc6e2e036ddd","modified":1716735885676},{"_id":"themes/next/source/images/logo-algolia-nebula-blue-full.svg","hash":"b85e274207b1392782476a0430feac98db1e7da0","modified":1716732167053},{"_id":"themes/next/source/images/logo.svg","hash":"d29cacbae1bdc4bbccb542107ee0524fe55ad6de","modified":1716735885676},{"_id":"themes/next/source/images/onion.jpg","hash":"4ea5453f2d71a672a7e1d8bda79931139ccb6858","modified":1716735885676},{"_id":"themes/next/source/js/bookmark.js","hash":"0f563ffbf05fad30e854e413ab17ff7164ab5a53","modified":1716732167054},{"_id":"themes/next/source/images/wechatpay.png","hash":"efdf5466bea015de5b12336fc580d70eba8417b5","modified":1716735885676},{"_id":"themes/next/source/js/comments-buttons.js","hash":"1a7344440321713426a0b2ab17e276b5bdf85ade","modified":1716732167054},{"_id":"themes/next/source/js/comments.js","hash":"66ae2e26ea36a41b72c638ea8b220296638ae952","modified":1716732167054},{"_id":"themes/next/source/js/config.js","hash":"4c4ebbe3b3f3841a26f9d5af6d0ba8bc6da01c54","modified":1716732167054},{"_id":"themes/next/source/js/motion.js","hash":"8e587c086e3cf8687108fbb3241fe1534c3df463","modified":1716732167054},{"_id":"themes/next/source/js/next-boot.js","hash":"8e2d589585f5270ee90285d3e65b69923c7629d8","modified":1716732167054},{"_id":"themes/next/source/js/pjax.js","hash":"adc751f9b63b7a6b4d381506d35a1b3ff4de891f","modified":1716732167054},{"_id":"themes/next/source/js/schedule.js","hash":"a1333258726caf84f368a8f8454639c7dc1626bb","modified":1716732167054},{"_id":"themes/next/source/js/sidebar.js","hash":"b3289010a0cb52c525b1395db72bd463424f2f48","modified":1716732167054},{"_id":"themes/next/source/js/utils.js","hash":"f92420649b150703469bba41cbd5c72768beed88","modified":1716732167054},{"_id":"themes/next/layout/_partials/head/head.njk","hash":"5388b157bba4a40b9312f4a45c6678974ccf0837","modified":1717500628353},{"_id":"themes/next/layout/_partials/header/brand.njk","hash":"dd9c4c03e99dfde0dfb8edefcb2c933f2f560efc","modified":1716732167060},{"_id":"themes/next/layout/_partials/head/head-unique.njk","hash":"8da52a144060db1a0a088ccb2e6cc8376d1fce70","modified":1716732167060},{"_id":"themes/next/layout/_partials/header/index.njk","hash":"650de421a8ce4cf685428ffbe0087ff84cbd1356","modified":1716732167060},{"_id":"themes/next/layout/_partials/header/menu-item.njk","hash":"41a8b0cc16f60fa085cb719d07216d86b6bc4bf8","modified":1716732167060},{"_id":"themes/next/layout/_partials/header/sub-menu.njk","hash":"06480d8ec5f0b87eafd47f082f07968d7282dd5c","modified":1716732167060},{"_id":"themes/next/layout/_partials/page/breadcrumb.njk","hash":"89825e75cc45e9709fa6ba89883669eedaff6f46","modified":1716732167060},{"_id":"themes/next/layout/_partials/page/categories.njk","hash":"17156d99941f28a225951ffdcfa9a115e20dc2d2","modified":1716732167060},{"_id":"themes/next/layout/_partials/page/page-header.njk","hash":"7ed4f102a1825195cff8d7995bf9219f323a9034","modified":1716732167060},{"_id":"themes/next/layout/_partials/page/schedule.njk","hash":"0f4bc8e257da60f77c0c1738607b2bde55810684","modified":1716732167060},{"_id":"themes/next/layout/_partials/page/tags.njk","hash":"a18d1598e36cc72f2b0b24c3cc3c5990dfaa3254","modified":1716732167060},{"_id":"themes/next/layout/_partials/header/menu.njk","hash":"ee6fc2f111572d3eeab0a2fecbb2d6b3e37ab26b","modified":1716732167060},{"_id":"themes/next/layout/_partials/post/post-copyright.njk","hash":"bfff923526d6800218f08dba6ce0bbf5c17755fd","modified":1716732167060},{"_id":"themes/next/layout/_partials/post/post-followme.njk","hash":"c1e33b4889f75acc490af3c8bde0ec56c518ff41","modified":1716732167060},{"_id":"themes/next/layout/_partials/post/post-meta.njk","hash":"9fa47e4fb342811da590ee4adc91cf81118c0a39","modified":1716732167060},{"_id":"themes/next/layout/_partials/post/post-reward.njk","hash":"e8b8a7c41e9ec612d0c0c73419529d55d1c16256","modified":1716732167061},{"_id":"themes/next/layout/_partials/post/post-share.njk","hash":"16696990e4ce65fc8db18c4635082a5d5d06ff07","modified":1716732167061},{"_id":"themes/next/layout/_partials/search/algolia-search.njk","hash":"efb2b6f19df02ba5ae623a1f274fff52aed21e6f","modified":1716732167060},{"_id":"themes/next/layout/_partials/post/post-related.njk","hash":"e0986db00a0201dd3c60570f964829c84ba5bc68","modified":1716732167060},{"_id":"themes/next/layout/_partials/search/index.njk","hash":"8f6f256ab3b351ffc80f1f3f1d9834e9a7cfac31","modified":1716732167060},{"_id":"themes/next/layout/_partials/search/localsearch.njk","hash":"661f7acae43f0be694266323320f977d84119abe","modified":1716732167060},{"_id":"themes/next/layout/_partials/sidebar/site-overview.njk","hash":"a1e37607761e9339de567f1130b9bf0ece6e1a2d","modified":1716794767784},{"_id":"themes/next/layout/_third-party/analytics/cloudflare.njk","hash":"a5b8297c2c383124dd6a56e256ecc0c0dcf489be","modified":1716732167059},{"_id":"themes/next/layout/_third-party/analytics/google-analytics.njk","hash":"d89066ff53879693f023e540d59c86137172c529","modified":1716732167059},{"_id":"themes/next/layout/_third-party/analytics/growingio.njk","hash":"8afaa772c390bd9d53a5cff9645ac3168334eb98","modified":1716732167059},{"_id":"themes/next/layout/_third-party/analytics/index.njk","hash":"f900306497b133e8b098bd9f4b96b93d1d96c185","modified":1716732167059},{"_id":"themes/next/layout/_third-party/analytics/baidu-analytics.njk","hash":"6215309aee028dcb734452beec448c5afb6c63fc","modified":1716732167059},{"_id":"themes/next/layout/_third-party/analytics/matomo.njk","hash":"4e89648a8ec8194c5823064cbca39c938a799006","modified":1716732167059},{"_id":"themes/next/layout/_third-party/analytics/microsoft-clarity.njk","hash":"9dc00fcb0a05899f048eace9f9160b78956655d5","modified":1716732167059},{"_id":"themes/next/layout/_third-party/analytics/plausible.njk","hash":"ef9f2bb7110507f1c4336800af9157d5fa9765bd","modified":1716732167059},{"_id":"themes/next/layout/_third-party/chat/chatra.njk","hash":"d7263fca16d0278ccf1f6aa1c6df6902a6344a09","modified":1716732167060},{"_id":"themes/next/layout/_third-party/analytics/umami.njk","hash":"3343750682fbd8535e50f8129be3003ad26015b4","modified":1716732167059},{"_id":"themes/next/layout/_third-party/chat/tidio.njk","hash":"02aab857c27fc103216029be991688b12a73a525","modified":1716732167060},{"_id":"themes/next/layout/_third-party/comments/changyan.njk","hash":"d1c950f8fbdf85e7a3eae5463767a89e858e8220","modified":1716732167059},{"_id":"themes/next/layout/_third-party/comments/disqus.njk","hash":"9375b19a89b7fa9474e558d085af5448d4c5c50c","modified":1716732167059},{"_id":"themes/next/layout/_third-party/comments/disqusjs.njk","hash":"0749cb6902baecdfd01f779a2a2513f6d2f6a823","modified":1716732167059},{"_id":"themes/next/layout/_third-party/comments/gitalk.njk","hash":"b63b7e2ede0d3e66e732fa1a06bda9b19e1e85d4","modified":1716732167059},{"_id":"themes/next/layout/_third-party/comments/isso.njk","hash":"64cc3bdaf644fd32c0d0a247f29f5b6904da9af3","modified":1716732167060},{"_id":"themes/next/layout/_third-party/comments/livere.njk","hash":"3b13b09fba84ec6000886890a6710736a2b8fafe","modified":1716732167060},{"_id":"themes/next/layout/_third-party/comments/utterances.njk","hash":"5a94032bc3512a10ad4328fc19ec07b819a1d687","modified":1716732167060},{"_id":"themes/next/layout/_third-party/math/index.njk","hash":"abf37fc55aa86702118e8fdf5bf2d389dd589aa0","modified":1716732167060},{"_id":"themes/next/layout/_third-party/math/katex.njk","hash":"1ebf658690468ea197bdd0416eb7cfa4bd0b083a","modified":1716732167060},{"_id":"themes/next/layout/_third-party/math/mathjax.njk","hash":"3677017fd4572b158311f5f5d870590ab25184e0","modified":1716732167060},{"_id":"themes/next/layout/_third-party/search/algolia-search.njk","hash":"24ed76e0c72a25ac152820c750a05826a706b6f4","modified":1716732167059},{"_id":"themes/next/layout/_third-party/search/localsearch.njk","hash":"e45ea3542cdc9ed7ec8447b5e6f35df4c5e82758","modified":1716732167059},{"_id":"themes/next/layout/_third-party/statistics/busuanzi-counter.njk","hash":"a4bc501da0f22f7e420f0ca47e83988ce90b1368","modified":1716732167059},{"_id":"themes/next/layout/_third-party/statistics/firestore.njk","hash":"d32ebe94560fa95824478ebbff531bffc47b194d","modified":1716732167059},{"_id":"themes/next/layout/_third-party/statistics/index.njk","hash":"568ddf7955d11d93fb5e842b403a7ac8b1b7fdb1","modified":1716732167059},{"_id":"themes/next/layout/_third-party/statistics/lean-analytics.njk","hash":"2446e748cdc102c78492216319ac02148db7daf6","modified":1716732167059},{"_id":"themes/next/scripts/events/lib/config.js","hash":"9ec51eb61f7fee612ffc5252f489003a0fa301fc","modified":1716732167058},{"_id":"themes/next/scripts/events/lib/highlight.js","hash":"8300553bf2a1c4bfaec76f2da56465016e9d8058","modified":1716732167058},{"_id":"themes/next/scripts/events/lib/injects.js","hash":"d987709267a1bc6e5014411e9983d7c49c102c16","modified":1716732167058},{"_id":"themes/next/scripts/events/lib/navigation.js","hash":"dd3562686d95a50375e6fd32e717ccb0d99c1e3d","modified":1716732167058},{"_id":"themes/next/scripts/events/lib/utils.js","hash":"5942feb3f31ed3480bf50b0f5a4a305b5bdca3d6","modified":1716732167058},{"_id":"themes/next/scripts/events/lib/vendors.js","hash":"e2b4a9d6b08155735ec336eedc506763d5671821","modified":1716732167058},{"_id":"themes/next/scripts/filters/comment/changyan.js","hash":"5798cfc8f63665031dd3e01debed051628cec319","modified":1716732167057},{"_id":"themes/next/scripts/filters/comment/common.js","hash":"19a402a225c31edffc50f202a14e0d582d3db23e","modified":1716732167057},{"_id":"themes/next/scripts/filters/comment/default-config.js","hash":"93ee5f9109dad885dc38c49bcee630c10f9dce6e","modified":1716732167057},{"_id":"themes/next/scripts/filters/comment/disqus.js","hash":"7f71d6b271ba65ff333d5682e7575711d368c0d2","modified":1716732167057},{"_id":"themes/next/scripts/filters/comment/disqusjs.js","hash":"a600a98e7436edeb31e291abca359885567df3c9","modified":1716732167057},{"_id":"themes/next/scripts/filters/comment/gitalk.js","hash":"7bb7dafdd7f6bca8464b54e17e552ce7f1714195","modified":1716732167057},{"_id":"themes/next/scripts/filters/comment/isso.js","hash":"ff8b5b5145220a17d0ecd9508ba9bd2d3b2da47d","modified":1716732167057},{"_id":"themes/next/scripts/filters/comment/livere.js","hash":"5a07d8bb52bc1d51a624ca8db54be144566c306b","modified":1716732167057},{"_id":"themes/next/scripts/filters/comment/utterances.js","hash":"d3bded697bc32dace689d2a6dfb6eb7514169d15","modified":1716732167057},{"_id":"themes/next/layout/_third-party/tags/mermaid.njk","hash":"099e031f52fb8e47b3af5b2684737efc9e643ee7","modified":1716732167060},{"_id":"themes/next/layout/_third-party/tags/pdf.njk","hash":"2c81984cc4f5123103460442f6e046f5b6c97127","modified":1716732167060},{"_id":"themes/next/layout/_third-party/tags/wavedrom.njk","hash":"02202bf563fb5eedde2ccad4d6c5b9109d30a703","modified":1716732167060},{"_id":"themes/next/source/css/_variables/Gemini.styl","hash":"96e0a7c2a65ce68215e17e369085b2ea2f1334f2","modified":1716732167057},{"_id":"themes/next/source/css/_variables/Mist.styl","hash":"2c800eaab6c613e5d091be2111aaa786641aa0c2","modified":1716732167057},{"_id":"themes/next/source/css/_variables/Muse.styl","hash":"879b49f693af0c04c285b2dd0c9cccaf77347b7c","modified":1716732167057},{"_id":"themes/next/source/css/_variables/Pisces.styl","hash":"087456421529001237d0142f044e89b608d18ffa","modified":1717548195983},{"_id":"themes/next/source/css/_variables/base.styl","hash":"8b4100f316e9924f2410802615107130588d721e","modified":1716732167057},{"_id":"themes/next/source/js/third-party/addtoany.js","hash":"5276c8f78ee562a8965216dc67d762e59cb4a9f2","modified":1716732167053},{"_id":"themes/next/source/js/third-party/fancybox.js","hash":"819f382c561fe5ec23c67cc5fabd63dd1cc22dc1","modified":1716732167053},{"_id":"themes/next/source/js/third-party/pace.js","hash":"0ef04218b93561ba4d0ff420d556c3d90a756d32","modified":1716732167054},{"_id":"themes/next/source/js/third-party/quicklink.js","hash":"eed02e6fced8e5a653077205d4d4d7834ca71472","modified":1716732167054},{"_id":"themes/next/source/css/_common/components/back-to-top.styl","hash":"7664491542046df9a3887cf40a06e00c0b4086a9","modified":1716732167055},{"_id":"themes/next/source/css/_common/components/index.styl","hash":"2298e521253b3bf376a2412271bc2a7d305051f3","modified":1716732167055},{"_id":"themes/next/source/css/_common/components/reading-progress.styl","hash":"90a86045a33c1bae49fc2f6fa1e1b53170c7f77b","modified":1716732167055},{"_id":"themes/next/source/css/_common/outline/index.styl","hash":"8e34df131830d4fa3725e4590a672ba1cf1903e5","modified":1716732167056},{"_id":"themes/next/source/css/_common/outline/mobile.styl","hash":"1dbf2c339adcd27026c3a2ded32ee91ce08cea26","modified":1716732167057},{"_id":"themes/next/source/css/_common/scaffolding/base.styl","hash":"d0a7c99095f490b0d2ed6b1be43d435960798cec","modified":1716732167055},{"_id":"themes/next/source/css/_common/scaffolding/comments.styl","hash":"e4fecc889ba3317a64e9abba5842c79dff9b7827","modified":1716732167056},{"_id":"themes/next/source/css/_common/scaffolding/buttons.styl","hash":"a042571d85ff7265f799004239a45f36b716b8a6","modified":1716732167056},{"_id":"themes/next/source/css/_common/scaffolding/index.styl","hash":"523fb7b653b87ae37fc91fc8813e4ffad87b0d7e","modified":1716732167056},{"_id":"themes/next/source/css/_common/scaffolding/normalize.styl","hash":"b56367ea676ea8e8783ea89cd4ab150c7da7a060","modified":1716732167056},{"_id":"themes/next/source/css/_common/scaffolding/pagination.styl","hash":"f4228c759db4a650c8d38745c2edd1dc83c45687","modified":1716732167056},{"_id":"themes/next/source/css/_common/scaffolding/tables.styl","hash":"e840b23d33023e6d45e018f6e84b683dd56efd8d","modified":1716732167056},{"_id":"themes/next/source/css/_common/scaffolding/toggles.styl","hash":"37be10c413438060fc76ed31ae74d4300c38c5eb","modified":1716732167056},{"_id":"themes/next/source/css/_schemes/Gemini/index.styl","hash":"9dfe853c901bdc52fc950bacdf15484dbb9bf140","modified":1716732167055},{"_id":"themes/next/source/css/_schemes/Mist/_header.styl","hash":"dafc6d23c80d6fe3e55a7711e94210d2479b629a","modified":1716732167054},{"_id":"themes/next/source/css/_schemes/Mist/_layout.styl","hash":"fa4fd8f76464e214fb7318f325b13c2b62f4b478","modified":1716732167054},{"_id":"themes/next/source/css/_schemes/Mist/_menu.styl","hash":"f23c53e32d140091b819be2603d1afbbb5d66933","modified":1716732167054},{"_id":"themes/next/source/css/_schemes/Mist/_posts-expand.styl","hash":"485d23ccb42c0d0c8ead7ea8930dd3e06d79a285","modified":1716732167054},{"_id":"themes/next/source/css/_schemes/Mist/index.styl","hash":"ab16a3dcdc0393b9b582ef59dcc13db9320e917c","modified":1716732167054},{"_id":"themes/next/source/css/_schemes/Muse/_header.styl","hash":"3fbfab591f280e2e7f3b0265901c93bc4bd137ed","modified":1716732167054},{"_id":"themes/next/source/css/_schemes/Muse/_layout.styl","hash":"6569a6640f79d247a8235b3914772c0e2f99ead2","modified":1716732167054},{"_id":"themes/next/source/css/_schemes/Muse/_menu.styl","hash":"e31f6adbb22a451f07e4661cff9a2f12e4e99a36","modified":1716732167054},{"_id":"themes/next/source/css/_schemes/Muse/_sidebar.styl","hash":"c29a827e82d2820ed8977c92994da73721200fac","modified":1716732167054},{"_id":"themes/next/source/css/_schemes/Muse/_sub-menu.styl","hash":"c48ccd8d6651fe1a01faff8f01179456d39ba9b1","modified":1716732167054},{"_id":"themes/next/source/css/_schemes/Muse/index.styl","hash":"6ad168288b213cec357e9b5a97674ff2ef3a910c","modified":1716732167054},{"_id":"themes/next/source/css/_schemes/Pisces/_header.styl","hash":"dc03835e42d82eaf2633cf3b627990ad3e1f5967","modified":1716732167054},{"_id":"themes/next/source/css/_schemes/Pisces/_layout.styl","hash":"c6186e099d27e411a9249adae05f7bb0d2c2de2a","modified":1717552119874},{"_id":"themes/next/source/css/_schemes/Pisces/_sub-menu.styl","hash":"778ed2ad5643b93970c95626b325defeb586733f","modified":1716732167054},{"_id":"themes/next/source/css/_schemes/Pisces/_sidebar.styl","hash":"4ba99551eac29ca25db2163fe04f69220daa24a2","modified":1717552246361},{"_id":"themes/next/source/css/_schemes/Pisces/_menu.styl","hash":"8398adc86b6ddc9061770cfed8a32de1a0e57417","modified":1717550870027},{"_id":"themes/next/source/css/_schemes/Pisces/index.styl","hash":"d99b954d6a15e1727ffa529077103ecd54aa8a3e","modified":1717552019446},{"_id":"themes/next/source/js/third-party/analytics/baidu-analytics.js","hash":"f629acc46ff40c071ffd31b77d5c7616f0fdd778","modified":1716732167053},{"_id":"themes/next/source/js/third-party/analytics/google-analytics.js","hash":"def07bcc7c17d8a0caad177fb1dd2f3a5e5b3536","modified":1716732167053},{"_id":"themes/next/source/js/third-party/analytics/growingio.js","hash":"78dd3cf04082b7dbe6246e404b2aa8e726922402","modified":1716732167053},{"_id":"themes/next/source/js/third-party/analytics/matomo.js","hash":"c6a25b26a1443caa70b47fd3dfa282271574deb5","modified":1716732167053},{"_id":"themes/next/source/js/third-party/chat/chatra.js","hash":"c32180522788c10e51df1803aa6842ef0432ddc9","modified":1716732167053},{"_id":"themes/next/source/js/third-party/chat/tidio.js","hash":"b0079f6a4601e06ca6fe46e83a2f5af553e9bc3c","modified":1716732167053},{"_id":"themes/next/source/js/third-party/comments/changyan.js","hash":"260d1a77d6a3bb33a579d3e4cca1997003e799b5","modified":1716732167053},{"_id":"themes/next/source/js/third-party/comments/disqus.js","hash":"da361917d65e5dca8362f8cdeb6c8cc0e8316cec","modified":1716732167053},{"_id":"themes/next/source/js/third-party/comments/disqusjs.js","hash":"1e826dea3f684c0515f362dc1352447a1f0eae71","modified":1716732167053},{"_id":"themes/next/source/js/third-party/comments/gitalk.js","hash":"0ec038cf83e8ec067534f16a54041e47a3c1e59a","modified":1716732167053},{"_id":"themes/next/source/js/third-party/comments/isso.js","hash":"753a873b6f566aff5ba77ca23f91b78eb880ca64","modified":1716732167053},{"_id":"themes/next/source/js/third-party/comments/livere.js","hash":"2247d88c934c765c43013337860774aaa99f0b31","modified":1716732167053},{"_id":"themes/next/source/js/third-party/comments/utterances.js","hash":"f67f90eb03e284c82da2b8cf2f1e31801813c16d","modified":1716732167053},{"_id":"themes/next/source/js/third-party/math/katex.js","hash":"83c54ee536e487a1031783443fe0cb63b1b4767e","modified":1716732167054},{"_id":"themes/next/source/js/third-party/math/mathjax.js","hash":"5c749b9c1c3bb738122d0516211ecff6496d4907","modified":1716732167054},{"_id":"themes/next/source/js/third-party/search/algolia-search.js","hash":"fdb7b7cef1a147d897e7f7cd8903b58368ec2062","modified":1716732167053},{"_id":"themes/next/source/js/third-party/search/local-search.js","hash":"4536cb6d0a9bbaaa86fab3fa0101f6a3a3ec5a76","modified":1716732167053},{"_id":"themes/next/source/js/third-party/statistics/firestore.js","hash":"6e0682bb42170d61b13b786295f45f9c785f8b73","modified":1716732167053},{"_id":"themes/next/source/js/third-party/statistics/lean-analytics.js","hash":"835cbf54c49ef1327f47df70ff2636ad36b6f57d","modified":1716732167053},{"_id":"themes/next/source/js/third-party/tags/mermaid.js","hash":"6bf821310342c5b87a631873e7650a475a0765f1","modified":1716732167054},{"_id":"themes/next/source/js/third-party/tags/pdf.js","hash":"af78c22f0e61c8c8aa8794e585e0d632c6d4fcb8","modified":1716732167054},{"_id":"themes/next/source/js/third-party/tags/wavedrom.js","hash":"40dcd10df6edf124088c329346e0cc0bdac74ef1","modified":1716732167054},{"_id":"themes/next/source/css/_common/components/pages/breadcrumb.styl","hash":"8afdc311c6b8db121758371f95cf1c5e77354f42","modified":1716732167055},{"_id":"themes/next/source/css/_common/components/pages/categories.styl","hash":"51a97a33879289904cb523ddc2d88b5b0c60fa72","modified":1716732167055},{"_id":"themes/next/source/css/_common/components/pages/index.styl","hash":"7504dbc5c70262b048143b2c37d2b5aa2809afa2","modified":1716732167055},{"_id":"themes/next/source/css/_common/components/pages/schedule.styl","hash":"6b816c2511242ee503fb5f34cd3e4dcdafc06b85","modified":1716732167055},{"_id":"themes/next/source/css/_common/components/pages/tag-cloud.styl","hash":"4a39ceead4cb8645c75a172aba16d6f25b8122fd","modified":1716798020325},{"_id":"themes/next/source/css/_common/components/post/index.styl","hash":"9d75c45b391a3bfb45fc4e85db1ed0eba87926a4","modified":1716880759656},{"_id":"themes/next/source/css/_common/components/post/index.styl.bk","hash":"098d4bd034e986fcf7e443eac4fc2193935461b7","modified":1716879327943},{"_id":"themes/next/source/css/_common/components/post/post-body.styl","hash":"56d5b7ff73f466c9ae54f7204ae899281295d749","modified":1716732167055},{"_id":"themes/next/source/css/_common/components/post/post-collapse.styl","hash":"809bab3414b1eb1ae44444eb821126868f764414","modified":1716732167055},{"_id":"themes/next/source/css/_common/components/post/post-followme.styl","hash":"1ecfd64507954810b07a9d21fb5305b5378feda0","modified":1716732167055},{"_id":"themes/next/source/css/_common/components/post/post-footer.styl","hash":"11497388f124bfbb4001495a67d3629a9f618405","modified":1716732167055},{"_id":"themes/next/source/css/_common/components/post/post-gallery.styl","hash":"aa366d37389760c8595529b850f461569577a1c5","modified":1716732167055},{"_id":"themes/next/source/css/_common/components/post/post-header.styl","hash":"1191f1bfa5c43e54be8e5b3cc0d802984e161747","modified":1716732167055},{"_id":"themes/next/source/css/_common/components/post/post-nav.styl","hash":"9ac6f477177264c26a46e8333b8456720a0444dc","modified":1716732167055},{"_id":"themes/next/source/css/_common/components/post/post-reward.styl","hash":"04cf4a69537fc14d3b8904f965d283356853847f","modified":1716732167055},{"_id":"themes/next/source/css/_common/components/post/post-widgets.styl","hash":"ebfba158a0a4af3d1dabcacbc58986664de52140","modified":1716732167055},{"_id":"themes/next/source/css/_common/components/third-party/disqusjs.styl","hash":"877a537d5b95beb048142e4fdee6f17e6ef9c7bb","modified":1716732167055},{"_id":"themes/next/source/css/_common/components/third-party/gitalk.styl","hash":"8f094c4ac17e2ab45569b12d157747f9c7333c12","modified":1716732167055},{"_id":"themes/next/source/css/_common/components/third-party/index.styl","hash":"54d12e2c5d9982f7b9e5b23be5133954a8514e9d","modified":1716732167055},{"_id":"themes/next/source/css/_common/components/third-party/math.styl","hash":"9d995eb4871a6c273d9d51558676a1fdabf69e72","modified":1716732167055},{"_id":"themes/next/source/css/_common/components/third-party/search.styl","hash":"e72799ce3f9b79753e365b2f8c8ef6c310668d4a","modified":1716732167055},{"_id":"themes/next/source/css/_common/components/third-party/utterances.styl","hash":"56d90ae0559caa55b75f3c300ff2711f9ed65fc4","modified":1716732167055},{"_id":"themes/next/source/css/_common/outline/footer/index.styl","hash":"4e967702cf4c637132346bc74ec8854426f1a68c","modified":1716732167056},{"_id":"themes/next/source/css/_common/outline/header/bookmark.styl","hash":"e74f4bb47a101b014ee2a1783c87f3b87323f9a0","modified":1716732167056},{"_id":"themes/next/source/css/_common/outline/header/github-banner.styl","hash":"38c64c2d04e46848382bfa246a0e9c508294767b","modified":1716732167056},{"_id":"themes/next/source/css/_common/outline/header/index.styl","hash":"6e0d0796ef7fbbb62ffdfb448753a850de82c74f","modified":1716732167056},{"_id":"themes/next/source/css/_common/outline/header/menu.styl","hash":"a3dd3edea9c01b66b28a8367185269b9dcc3bdee","modified":1716732167056},{"_id":"themes/next/source/css/_common/outline/header/site-meta.styl","hash":"a851e9d5aefcd027c95eeb323860b6da70f202d1","modified":1716732167056},{"_id":"themes/next/source/css/_common/outline/header/site-nav.styl","hash":"bf3ad8b4268f763a1e26377681644887694bc009","modified":1716732167056},{"_id":"themes/next/source/css/_common/outline/sidebar/index.styl","hash":"7c203ec68c0f54429caf35803dbac85b18540278","modified":1716732167056},{"_id":"themes/next/source/css/_common/outline/sidebar/related-posts.styl","hash":"b05908f04ef95f2d91e6eba89b12411c378d050f","modified":1716732167056},{"_id":"themes/next/source/css/_common/outline/sidebar/sidebar-author-links.styl","hash":"0847400d8579b0a2dd1bf662c78954c10adf2680","modified":1716732167056},{"_id":"themes/next/source/css/_common/outline/sidebar/sidebar-author.styl","hash":"5b38ac4a0f1ade0e681aff0e3366c481d9cf3dcd","modified":1716732167056},{"_id":"themes/next/source/css/_common/outline/sidebar/sidebar-blogroll.styl","hash":"c6a27beb3f741211a14576026f3b4cfc44cc6407","modified":1716732167056},{"_id":"themes/next/source/css/_common/outline/sidebar/sidebar-button.styl","hash":"46eece42510c2c89bb9209afb0262ad76a4b0b36","modified":1716732167056},{"_id":"themes/next/source/css/_common/outline/sidebar/sidebar-nav.styl","hash":"24752d145c6fb8f5344dca9c7b9640839c02e009","modified":1716732167056},{"_id":"themes/next/source/css/_common/outline/sidebar/sidebar-toc.styl","hash":"c2e354a565c8c1b32bd0ceacc972b17982758b67","modified":1716732167056},{"_id":"themes/next/source/css/_common/outline/sidebar/sidebar-toggle.styl","hash":"741566d6ac5f852b5c8dee6a8996b65e48e7c97f","modified":1716732167056},{"_id":"themes/next/source/css/_common/outline/sidebar/site-state.styl","hash":"26dd0adfcb1db6df29c6090c8d7e9b5a43583fb0","modified":1716732167056},{"_id":"themes/next/source/css/_common/scaffolding/highlight/copy-code.styl","hash":"f634f94828620e88c3f5a8db56f7944f6ba232b0","modified":1716732167056},{"_id":"themes/next/source/css/_common/scaffolding/highlight/fold.styl","hash":"42a0b65491ad85438596b3fe0b7f23973e4cef34","modified":1716732167056},{"_id":"themes/next/source/css/_common/scaffolding/highlight/index.styl","hash":"138f78147bc6bd6005f329ada34dc79b7625542d","modified":1716732167056},{"_id":"themes/next/source/css/_common/scaffolding/tags/blockquote-center.styl","hash":"d6418fd2bbfba7b73ddf11ec62db9637fdf5d8af","modified":1716732167055},{"_id":"themes/next/source/css/_common/scaffolding/tags/group-pictures.styl","hash":"393ff96234e4196b569d4b11496774eb78e147de","modified":1716732167055},{"_id":"themes/next/source/css/_common/scaffolding/tags/index.styl","hash":"22cd37bd5df9972d5074710896aba4424ad5161c","modified":1716732167055},{"_id":"themes/next/source/css/_common/scaffolding/tags/label.styl","hash":"debee14539272fbe3835a7d3853af2230baa3501","modified":1716732167055},{"_id":"themes/next/source/css/_common/scaffolding/tags/link-grid.styl","hash":"7f8a7345e6537a62cd9e9a94c8f7065b541d9b04","modified":1716732167056},{"_id":"themes/next/source/css/_common/scaffolding/tags/mermaid.styl","hash":"48d35dba575a7c9e8845b16652e76b7d4a4646de","modified":1716732167056},{"_id":"themes/next/source/css/_common/scaffolding/tags/note.styl","hash":"98d4c20aff0f0fcfe1824017fb06ab21ef0d218e","modified":1716732167056},{"_id":"themes/next/source/css/_common/scaffolding/tags/pdf.styl","hash":"b6654a1d7cf82577d8263faffee8af3ad4a5c0e8","modified":1716732167056},{"_id":"themes/next/source/css/_common/scaffolding/tags/tabs.styl","hash":"33dd6ad015dde65fd46f34961655442e8e82b52e","modified":1716732167056},{"_id":"themes/next/source/css/_common/scaffolding/tags/wavedrom.styl","hash":"af113411ad9cca7674177be36af8dd399680834d","modified":1716732167056},{"_id":"themes/next/source/images/alipay.jpg","hash":"2564c6ccf3940671c65f198e8479edaa26315377","modified":1716735885676},{"_id":"themes/next/source/images/wechat_channel.jpg","hash":"2354f69ffa50bc22f389dd80423827d62d6fcc9a","modified":1716735885676},{"_id":"themes/next/source/images/seisamuse.png","hash":"1e2bcd2ebb115699288facd92abcd47bf3a4cedc","modified":1716735885676},{"_id":"themes/next/package-lock.json","hash":"918385a3db21e508b393710b318d4ce49a1b91ec","modified":1716884899701},{"_id":"themes/next/source/images/wechatpay.jpg","hash":"19ab15aec58a8cf5c802467a44b45f5385013f27","modified":1716735885676},{"_id":"source/_posts/2020-07-21-mantle-transition-zone/Picture1.png","hash":"3d1cdee808ffa1c3986e7ddebfb2c0b2c9b9c4d3","modified":1716733056846},{"_id":"themes/next/source/images/bg.jpg","hash":"93007f70b09f554b1c8fca77bc8d0fdec2a65cb4","modified":1716735885676},{"_id":"public/manifest.json","hash":"65610f3f173cf38562b6250b7b44e206a0d2b675","modified":1761274286822},{"_id":"public/baidusitemap.xml","hash":"46ca0ed27fca6ea7bb9b93a5d09f60329f7335e0","modified":1761274286822},{"_id":"public/atom.xml","hash":"44949ef2f71d67fd7c29f7929ba53ea9b3331f13","modified":1761274286822},{"_id":"public/search.xml","hash":"a86df657f484c5ae002117c597b83a8b58f5a083","modified":1761274286822},{"_id":"public/post-sitemap.xml","hash":"99e046c49a3bf3ee6b440fe8237ceca5fe6d686a","modified":1761274286822},{"_id":"public/page-sitemap.xml","hash":"34ff20b96bc2b6f8a963b5297e1fd81c8e29c513","modified":1761274286822},{"_id":"public/sitemap.xsl","hash":"4321fa69dc1b8811d32b7a1478e5603e038cea1a","modified":1761274286822},{"_id":"public/sitemap.xml","hash":"eed9700dafb244beb32229594626ffa66b5a13be","modified":1761274286822},{"_id":"public/about/index.html","hash":"70b8dd9414d6501fe4bc54b5b1babe084cfb8fa5","modified":1761274286822},{"_id":"public/categories/index.html","hash":"ebbab1046bc433d9f29ff5b080a848e2235b240a","modified":1761274286822},{"_id":"public/tags/index.html","hash":"01c083ee90942901adecb372105ff49dacc974d8","modified":1761274286822},{"_id":"public/noise-source-back-azimuth.html","hash":"82edcf308f88b55e24956432f14eb043913ffcd1","modified":1761274286822},{"_id":"public/paper-reading-29.html","hash":"5babceabae5ebf3f96d25f6a32b0fa66432d925e","modified":1761274286822},{"_id":"public/paper-reading-28.html","hash":"37ad0771df1438ee200d8e258822188b3be18d61","modified":1761274286822},{"_id":"public/fedora-install-freshress.html","hash":"23aaf5358d38a930b96d7c4b5a6935b341313c88","modified":1761274286822},{"_id":"public/png-to-mp4.html","hash":"8a5681daffed641bc02b38a6400660a89b909290","modified":1761274286822},{"_id":"public/fk.html","hash":"979dfb7a868c9af0d79d3d2e5af86553e02a7196","modified":1761274286822},{"_id":"public/distribute-package.html","hash":"a3bcfe1beea08d5c3048d21e63cd2a645cce57d1","modified":1761274286822},{"_id":"public/python-script2.html","hash":"85961ac1ef2175a9de4e3899b0670ebab0e11872","modified":1761274286822},{"_id":"public/mfp.html","hash":"555c7b483cf8dcfaef5664fabd06a353440c6ed6","modified":1761274286822},{"_id":"public/jupyter-notebook-extensions.html","hash":"92e72cbecbb92d66221087620b48c6acb4244870","modified":1761274286822},{"_id":"public/news-website.html","hash":"71e3cfeb0de53ceeeee85aa1c7bb42f8340c7d7e","modified":1761274286822},{"_id":"public/latex-math-express.html","hash":"3defeced6d6b9aa46a48c3f6686e32d28601bb55","modified":1761274286822},{"_id":"public/python-script1.html","hash":"4222cf3285647b6b661485ce62c024582913bc60","modified":1761274286822},{"_id":"public/plot-work-flow.html","hash":"6937fa93870d23012989828a077848ef90bd36cd","modified":1761274286822},{"_id":"public/problem-of-urllib3.html","hash":"c9b53ae994490ca56b5c2eca7ac62362db0146a2","modified":1761274286822},{"_id":"public/run-sequencer.html","hash":"504aba03200cec9bbffe723082961fac3deccf16","modified":1761274286822},{"_id":"public/how-to-install-wemeet.html","hash":"739ce65f1280fe52d5ef6efac735f70fd32e666e","modified":1761274286822},{"_id":"public/download-continous-data-update.html","hash":"f457427026eba3660aba2ba83fce6f7de9f42fa8","modified":1761274286822},{"_id":"public/statistic-data-download.html","hash":"ae74543dcaef8090fd108a61840642e62663d026","modified":1761274286822},{"_id":"public/download-continuous-seis.html","hash":"6e6e9fb70370d3929f2fe43310c02e300319733d","modified":1761274286822},{"_id":"public/attention-mechanism.html","hash":"38f96df8a618a1c82a0297bf6b09ac35994cab61","modified":1761274286822},{"_id":"public/bad-and-evil.html","hash":"e83f12baa450aeb407cd6dc2a90ecab238d59786","modified":1761274286822},{"_id":"public/download-eq-data.html","hash":"0822db5a3a001e3be9581fbaec59d815ce1aaa89","modified":1761274286822},{"_id":"public/mouse-click-monitoring.html","hash":"d75140fa18a52fbc6f3d73c9aa96c79f4fee877d","modified":1761274286822},{"_id":"public/gmt-arrow.html","hash":"0fd167349f6e858e31ad5f5d8a8b8014c7571c7a","modified":1761274286822},{"_id":"public/download-earthquake-py.html","hash":"75a039ae798be514c8d8a3067dc05bdb53ff614a","modified":1761274286822},{"_id":"public/paper-reading-27.html","hash":"63263b97d111b28c0fdc3a92106a197952f50666","modified":1761274286822},{"_id":"public/remove-response-miniseed.html","hash":"18427214ebeecc2a23b47e4455ba20d296f667c4","modified":1761274286822},{"_id":"public/download-fnet-data-py.html","hash":"0ab1bdef8a0b303a37cb6071a62b7b0decb3d6ff","modified":1761274286822},{"_id":"public/down-ambient-noise-py.html","hash":"cbfb3fe5545473c6b601c8a79dee8f21e292d6c3","modified":1761274286822},{"_id":"public/code-and-project2.html","hash":"f2282117cb6c29f4c1f47f61ca00079e721b96dc","modified":1761274286822},{"_id":"public/paper-reading-26.html","hash":"267b8360c794476b2fc1fcf213d902b05171e514","modified":1761274286822},{"_id":"public/paper-reading-25.html","hash":"c03628fccc01dd6b2b317ac9e55b799bafcfa99b","modified":1761274286822},{"_id":"public/how-to-install-deepseek.html","hash":"0059c236e08fe6dc2c0eb120eb25b56b9a818f29","modified":1761274286822},{"_id":"public/find-linux-back.html","hash":"ce47a0abb261a92c23d692044ae4af41fda5c399","modified":1761274286822},{"_id":"public/paper-reading-24.html","hash":"637a1362287eb9860b2f4621530a1b60bfca3cf9","modified":1761274286822},{"_id":"public/paper-reading-23.html","hash":"f8cb78510ad090b0e108b13ed589b62a85c537c9","modified":1761274286822},{"_id":"public/paper-reading-22.html","hash":"915144369589b94f500e5ca0032e98acffbad251","modified":1761274286822},{"_id":"public/efficient-shell-script.html","hash":"ca422fb1e983ede5f80218eeaa3cd42dfaec5edd","modified":1761274286822},{"_id":"public/paper-reading-21.html","hash":"0f6aff9d3a73caff7f8b578692372d8e658d48d6","modified":1761274286822},{"_id":"public/paper-reading-20.html","hash":"e67333cb8d51d3a1cbefcd1da3e51d4cef55db7f","modified":1761274286822},{"_id":"public/paper-reading-19.html","hash":"2a807f55bbaf4043d5fb84839d07ac6786a8a475","modified":1761274286822},{"_id":"public/how-to-download-fnet-station-list.html","hash":"8e9c84a5f1c026ae0e41c1d78cb7e779e410b043","modified":1761274286822},{"_id":"public/obspy-paz.html","hash":"eb5ddb12b25c1606bb3180a9090549fb6fc09af1","modified":1761274286822},{"_id":"public/music.html","hash":"4f315eaccd868bc32bdc3bf91b5aaf3d41c2d58a","modified":1761274286822},{"_id":"public/how-to-download-Snet-data.html","hash":"1ca453a06b22cc4f6186bf685dd0ae4d657930f2","modified":1761274286822},{"_id":"public/paper-reading-18.html","hash":"7512da3ac1d5420560976a9a8d5a4becbfec96f2","modified":1761274286822},{"_id":"public/paper-reading-17.html","hash":"06761bb54440b7bb5370922b781bf3911f5a60d2","modified":1761274286822},{"_id":"public/paper-reading-16.html","hash":"91f77f364e4cff372db2b7658530d38c1ab6143b","modified":1761274286822},{"_id":"public/paper-reading-15.html","hash":"f94e2cd9230757939bff4ff24ad58607740e58a1","modified":1761274286822},{"_id":"public/paper-reading-14.html","hash":"80d24ea47ac4f3c99bb41dabf6bbb486b32aef0d","modified":1761274286822},{"_id":"public/science-blogs.html","hash":"db71a7dcb1df0fecf62efd4f1c2bac57fb38bf03","modified":1761274286822},{"_id":"public/paper-reading-13.html","hash":"89c18fbf1e9288b88c9c6fc1fc9c17cdac389785","modified":1761274286822},{"_id":"public/how-to-read-paper.html","hash":"ba044e385a93d2866685638d6950a428873b3886","modified":1761274286822},{"_id":"public/code-and-project1.html","hash":"fb360567ef59fe1e64a9d69d8ab82532894c8acd","modified":1761274286822},{"_id":"public/paper-reading-12.html","hash":"737829c51bc8d4b77be3a91ba84ce693b62cd5ba","modified":1761274286822},{"_id":"public/paper-reading-11.html","hash":"167b203ccbef1748357668304ad1587b382e9188","modified":1761274286822},{"_id":"public/paper-reading-10.html","hash":"7d07e6a4e31e2f00380e29c70bde4ec1b72628eb","modified":1761274286822},{"_id":"public/add-video.html","hash":"d037faff602f87b2b5470f317528232fa8062314","modified":1761274286822},{"_id":"public/paper-reading-9.html","hash":"272ec518f0c89eec75e6141455d93dca99173f37","modified":1761274286822},{"_id":"public/paper-reading-8.html","hash":"6dadea255b22a64fb26479c9fb5dc5c7607cc6c2","modified":1761274286822},{"_id":"public/paper-reading-7.html","hash":"8baec33d5705d84d5a8b92735d852252a4e0f601","modified":1761274286822},{"_id":"public/how-to-review.html","hash":"5e27b5c18ad9c96229abfd4b6a82bc34ab290e36","modified":1761274286822},{"_id":"public/paper-reading-6.html","hash":"e1a9a544768bd12791b572cd27ddd08425c20ce7","modified":1761274286822},{"_id":"public/paper-reading-5.html","hash":"94959794b1516dd44a90be2a88066da46dbfd735","modified":1761274286822},{"_id":"public/paper-reading-4.html","hash":"fd97392b3dad5edc4c6840178400095a43038d77","modified":1761274286822},{"_id":"public/paper-reading-3.html","hash":"f0cb8ac18b3e104fb0ee941939c46584ec6ee437","modified":1761274286822},{"_id":"public/paper-reading.html","hash":"7abe8db642ebdde9e5c6ea7653ae610e2281a066","modified":1761274286822},{"_id":"public/paper-reading-2.html","hash":"1693f9e885086ad81c1a2397fa8a2af4aa66438f","modified":1761274286822},{"_id":"public/how-to-write-blog.html","hash":"ff6121f8ae3e0eb5167c423394f8d01436f8813b","modified":1761274286822},{"_id":"public/paper-reading-1.html","hash":"cf01b2f1d628d48f1220bae052acf22b531502bc","modified":1761274286822},{"_id":"public/how-to-make-the-brain-sharp.html","hash":"df5483954c38ba27689ea9f225c9c86b5b6df73e","modified":1761274286822},{"_id":"public/object-detection.html","hash":"abdc0d6515ad12a18b5afc9a80e3d9ef72130bd0","modified":1761274286822},{"_id":"public/memorise-blue.html","hash":"96460253cb2292256b63b5194ddf5b41a9b8a5a2","modified":1761274286822},{"_id":"public/no-audio-in-playing-browser-video.html","hash":"9548aa4ef3cc08ae428b5dc7347d9870383368fd","modified":1761274286822},{"_id":"public/no-file-found-in-LaTeX.html","hash":"d0298815f900bceb2b5fe9c8b2fce150cdac0f1e","modified":1761274286822},{"_id":"public/no-audio-control.html","hash":"a02499ed408505c4b7f2a1052e0936e428ff09d4","modified":1761274286822},{"_id":"public/ai-tools.html","hash":"60a8535506656ab3d27661fad9248455ef2b5122","modified":1761274286822},{"_id":"public/gls1.html","hash":"d7dd5764e0e4e9fca2236f569ff53c5c88ca5b9f","modified":1761274286822},{"_id":"public/how-to-set-X11-in-fedora.html","hash":"0999b672428bea438788bcf5ae221abaf4a98594","modified":1761274286822},{"_id":"public/to-desk.html","hash":"805874a99854c02ae7a3955eb74bb3a8df278500","modified":1761274286822},{"_id":"public/how-to-use-utterances.html","hash":"8785ca67f4632286a207bbc7f9bdc01b6a31de75","modified":1761274286822},{"_id":"public/how-to-add-frame.html","hash":"a203c0daedc7ade2bb9764387b72cb75a2d4bcf5","modified":1761274286822},{"_id":"public/how-to-encrypt.html","hash":"91aa17441c17b34cac9e2d6b4c6aeb61b8ef30a8","modified":1761274286822},{"_id":"public/encrypt_test.html","hash":"ecf9d11966edb6f7327cecd4729be55004d5ba8c","modified":1761274286822},{"_id":"public/how-to-pretend-you-know.html","hash":"b48a9e4ccdf94fbe408cc894d4bce3254c3269b2","modified":1761274286822},{"_id":"public/rule-no1.html","hash":"79129010932b61fe2deeac2dad9e177b2022ab30","modified":1761274286822},{"_id":"public/optimize-daily-task.html","hash":"e3a04d6b8bcb4826980dedb7ab7b50915b70066b","modified":1761274286822},{"_id":"public/git-error.html","hash":"de05caecdf33282f585ec39e6031da841ea628cb","modified":1761274286822},{"_id":"public/add_counter.html","hash":"7bbab84fbe5cdffc9b678e7f9d2c0bf68d5835d1","modified":1761274286822},{"_id":"public/reference-mod.html","hash":"8daa0ebf78ea0708ec2e2f39b76ca952f18deea1","modified":1761274286822},{"_id":"public/install-elementary-os-again.html","hash":"7a72125b9c3944f149835b202f4107fa822f1295","modified":1761274286822},{"_id":"public/pdf.html","hash":"9024a94b40ec3017675f1b4ef8a557480bcadf4b","modified":1761274286822},{"_id":"public/read-file-bash.html","hash":"5d73453c564ad9d8a9af1ae2e67ca26253393a64","modified":1761274286822},{"_id":"public/sky-and-universe.html","hash":"7b8015992fe656f4a4660eedd5a4fa83db31283a","modified":1761274286822},{"_id":"public/after-fedora32.html","hash":"c755774ceedac073f1495b633d97e81ceaa85bd5","modified":1761274286822},{"_id":"public/happy-new-year.html","hash":"7c606b3d916faed96cdfe5226485ef564ceb8f34","modified":1761274286822},{"_id":"public/how-to-install-filezilla.html","hash":"8931a705977d43e25d2cc13de34ca2c591f07c7b","modified":1761274286822},{"_id":"public/addiction.html","hash":"e7f670156263a4c6b10f5ac19adc9f94ea4c43b4","modified":1761274286822},{"_id":"public/about-anti-paper.html","hash":"40f82cb68c9ded86e8b8e77e0b5133ab63561a7b","modified":1761274286822},{"_id":"public/how-to-download-video-from-internet.html","hash":"a7abe21ea6513de6138dbe6e4e470b32e0fde4bc","modified":1761274286822},{"_id":"public/how-to-calculate-synthetic-NCF.html","hash":"4ff6c6567d8cbd114c627d7af6ff4e7462f1daf0","modified":1761274286822},{"_id":"public/how-to-configure-chinese-for-gmt.html","hash":"bdd789eefccac09f39c36f404013c67d6c4f7ca4","modified":1761274286822},{"_id":"public/US-upper-mantle-vs-model.html","hash":"b074b22458a01cbaa6dcd7dd02601b41cec7606b","modified":1761274286822},{"_id":"public/mantle-transition-zone.html","hash":"ba7993c49b0594587f0bb792a02bba3d91990df7","modified":1761274286822},{"_id":"public/IQ-decrease.html","hash":"3b27b5cf5358de3c9800194a78c5b57f4d244389","modified":1761274286822},{"_id":"public/how-to-access-google.html","hash":"4866d446231ce8047e9f0aa322c140938516f1b4","modified":1761274286822},{"_id":"public/how-to-use-fftw.html","hash":"a8e79a6e6b28cba6f7b33b1435bfc65ad84f18f8","modified":1761274286822},{"_id":"public/gmt-time-axes.html","hash":"731aa3188df140c5241f71ad151c44b7226faf92","modified":1761274286822},{"_id":"public/avatar-to-homepage.html","hash":"7b7c4342678bd8d018d131eadff96df88eb48be4","modified":1761274286822},{"_id":"public/install-and-backup-mediawiki.html","hash":"9585b35b39c8c607f09eb9a59b54fdd4691a0f31","modified":1761274286822},{"_id":"public/how-to-add-frame-in-hexo-next.html","hash":"53c7094188cdf5fe9d8db12e20a36beac00d0017","modified":1761274286822},{"_id":"public/stop-os-update.html","hash":"807ab7cc3bfee59ad9b0aff6e695a4d506264b1f","modified":1761274286822},{"_id":"public/learn-sed.html","hash":"dd0a8d1dd461fc33304c0c2c1f89d573bb4d649f","modified":1761274286822},{"_id":"public/what-did-I-do-to-this-blog.html","hash":"1331bf1a745c7c44f688f0f6c380650566429236","modified":1761274286822},{"_id":"public/no-more-blog-transfer.html","hash":"95fab26de4b3e4e11da94607cca72eb925270685","modified":1761274286822},{"_id":"public/history-and-inversion.html","hash":"c7ed510dd6e7459565f39b562e015ef8e48d1be7","modified":1761274286822},{"_id":"public/funny-thing-about-Eric.html","hash":"68fb961f20fe9983c8e91143cd85af69393a3065","modified":1761274286822},{"_id":"public/wangyi-blog-transfer.html","hash":"cdc79a42859a2465e5a67697f79d0c1cae99d7a0","modified":1761274286822},{"_id":"public/about-diary.html","hash":"29fb8c36a7b1bb194fedc81b461e752cf47569bc","modified":1761274286822},{"_id":"public/how-to-backup-hexo.html","hash":"7ea8fa0df48c5031c2636d0911d44958662e06c5","modified":1761274286822},{"_id":"public/passwd-free-for-deployment.html","hash":"98116e75baf6d132536bacb16fdb2c7e80522b7d","modified":1761274286822},{"_id":"public/show-picture-in-hexo.html","hash":"a5c80e63facb6405ca1e5cb0d1bde25997eebdbf","modified":1761274286822},{"_id":"public/reward-configuration.html","hash":"37d557f8348c6ee284876fb908d15e474919c2e7","modified":1761274286822},{"_id":"public/word-count.html","hash":"f3980f9d2cf47f6181b2ecfe5927c331c12f7d17","modified":1761274286822},{"_id":"public/how-to-reply-to-reviewer.html","hash":"36db77058a2a4e3a637d075537905e8ccddc7459","modified":1761274286822},{"_id":"public/how-I-build-this-web.html","hash":"dcfa905fdfac3a473da537dd4cfcf7de4cc087cb","modified":1761274286822},{"_id":"public/跟伴.html","hash":"16e093c0d6c9d31718bd7e066260c3b8124fd9db","modified":1761274286822},{"_id":"public/启程去玛雅.html","hash":"8cedca00ac6cb6602645fba144b8696b904b4ab4","modified":1761274286822},{"_id":"public/血色乎浪漫.html","hash":"3ad8b7aad9341c32b19949b129eaf9bbb0478e1c","modified":1761274286822},{"_id":"public/乱2.html","hash":"45bbc0768e484800e5ef98591e1b5ceec301e7bb","modified":1761274286822},{"_id":"public/Win7下格掉Linux盘如何启动windows.html","hash":"811a1df7a924e7a9aec761cafa44ef3dd670c448","modified":1761274286822},{"_id":"public/雾霾齐步走.html","hash":"906e598cc9699f96be834e8f1ff90b53471dfd81","modified":1761274286822},{"_id":"public/花卷.html","hash":"822a6cee07637925f6d1a396f97ed93df07882f5","modified":1761274286822},{"_id":"public/活着or霸王别姬.html","hash":"468256d204a00d78e31a99a2a52f6d3b57fa7c9c","modified":1761274286822},{"_id":"public/猫.html","hash":"e03fb2507c95f73999c71cc000f78019d7535285","modified":1761274286822},{"_id":"public/读后感.html","hash":"f97730ef814f1a294a051bd0025b1eb31be4ea0c","modified":1761274286822},{"_id":"public/成都印象.html","hash":"9c29337986160b177040cbade4eaf017cc6818bf","modified":1761274286822},{"_id":"public/愿逝者安息.html","hash":"4265e4dc9de4d599e8a3317d5151d60fa63c66f7","modified":1761274286822},{"_id":"public/怪癖.html","hash":"d57ec87a47dda335a7bddca0c3165ad8d1ebbafd","modified":1761274286822},{"_id":"public/宁波.html","hash":"7caea58681c531d0e0f6e5dedea57ef01a9bef8e","modified":1761274286822},{"_id":"public/消失的几天.html","hash":"f3a62351076d43246bd7fb7893a3f76841ae0764","modified":1761274286822},{"_id":"public/扑克.html","hash":"0a922dc55a0f2cb87ef470a805c6aa4891dd6f96","modified":1761274286822},{"_id":"public/流水三.html","hash":"f9a59a8cd148cbaf544530e8d3f58b9583834445","modified":1761274286822},{"_id":"public/饭后感2.html","hash":"f345a0f7e30487b6b65e92d4e613a3364cad6f71","modified":1761274286822},{"_id":"public/头晕.html","hash":"00889d5a81bfe8277e05630840dd32b545f75db9","modified":1761274286822},{"_id":"public/红色.html","hash":"77a08dec3cc1c932fcae1b3c142ff7a563248c3b","modified":1761274286822},{"_id":"public/旧年.html","hash":"feadd247ecf9dd8f261f409a860584d0bf9ee1d0","modified":1761274286822},{"_id":"public/Dloc.html","hash":"794bae03ae5057b62743ffec39cfd7a3a5bf07b5","modified":1761274286822},{"_id":"public/花木兰.html","hash":"a143f4b421de510d9ca29b570d04460791ef9f6c","modified":1761274286822},{"_id":"public/123.html","hash":"75e8a086a667c06e9e98c122f8e88a9ae20b756c","modified":1761274286822},{"_id":"public/流水一.html","hash":"98a31dda069f179b7335873a8311e7927defcd71","modified":1761274286822},{"_id":"public/发霉了.html","hash":"9e2a2b0eb2046971deed262af95f9db1bc3a3355","modified":1761274286822},{"_id":"public/mist.html","hash":"b3243afc2b5216766691a409cec9a2c9e6cdbbe1","modified":1761274286822},{"_id":"public/the-city-of-life-and-death.html","hash":"96860863101b9dd7502563cb30daa4db5d13e616","modified":1761274286822},{"_id":"public/无题.html","hash":"6fb444a9b119035980a3638e94b3b08e103f13fa","modified":1761274286822},{"_id":"public/星期五.html","hash":"ef2fa27cb2a1cccbc566508e659aa37d3491fc35","modified":1761274286822},{"_id":"public/外婆外公的故事.html","hash":"c91d789e8fe9eff510181c80e5037d0cabb9b4f1","modified":1761274286822},{"_id":"public/去他的.html","hash":"3a59fe264ba31a3cf48b904e7acd32c5f16a64bd","modified":1761274286822},{"_id":"public/南京大屠杀.html","hash":"2171b6faf5e699e4724c252ae97892e2d2f7fa3a","modified":1761274286822},{"_id":"public/好快刀.html","hash":"32afd12fa8a7110dc73e3b0d1b5562dc6f680de3","modified":1761274286822},{"_id":"public/阿甘.html","hash":"95df8cdbea27ac3d4fbcaa86fffcda74d19061c0","modified":1761274286822},{"_id":"public/寂寞.html","hash":"544bf11ffa5b205b924bb8e8b3b74bbd66e0a3a3","modified":1761274286822},{"_id":"public/archives/index.html","hash":"d5c5e2a104bca40db220b073091bd39af4d0a0ce","modified":1761274286822},{"_id":"public/archives/page/4/index.html","hash":"1ffed1e1f6173a98a1db921da88f95b6a6eabffc","modified":1761274286822},{"_id":"public/archives/page/3/index.html","hash":"38b4e29b790706fbac9e2cace9561c72fc50f6ef","modified":1761274286822},{"_id":"public/archives/page/6/index.html","hash":"213fe35e29c217484cc071bfae1a74fa51d5255c","modified":1761274286822},{"_id":"public/archives/page/7/index.html","hash":"8cadb657f145d43d211aa795ae78f6c2a2a194e7","modified":1761274286822},{"_id":"public/archives/page/8/index.html","hash":"15d0682130bc3aa02cfcd765a6a487a913e436f8","modified":1761274286822},{"_id":"public/archives/page/9/index.html","hash":"442e7f4b5ebcb90eb4558674750b492caded7336","modified":1761274286822},{"_id":"public/archives/page/2/index.html","hash":"d8ce9a3ed4a4dd385bb3cac90dc9703fe4d9cfca","modified":1761274286822},{"_id":"public/archives/page/10/index.html","hash":"333c7dde6cff87fbfa064674e011ff68434c8ee2","modified":1761274286822},{"_id":"public/archives/page/11/index.html","hash":"a2a8414f42b482ccdd33f55e4dce9ab642bfbd4f","modified":1761274286822},{"_id":"public/archives/page/13/index.html","hash":"9e346ada560fd49cd811c5c1c7c5d2889a465878","modified":1761274286822},{"_id":"public/archives/page/14/index.html","hash":"194761b6dca5040fe426ed2b9c7e5a81b02883d0","modified":1761274286822},{"_id":"public/archives/page/15/index.html","hash":"4310779baa1eb850b4b64c1c8e6bfec586b4034e","modified":1761274286822},{"_id":"public/archives/page/5/index.html","hash":"4e41c7c4124aa79b317d79b39ef82dfc48bab8eb","modified":1761274286822},{"_id":"public/archives/page/12/index.html","hash":"c15227ea6bf7ff1a90daea7b7e0422948ad4ca45","modified":1761274286822},{"_id":"public/archives/2006/index.html","hash":"10f49657ef924e7081c461a087f70a562e5ea63a","modified":1761274286822},{"_id":"public/archives/page/16/index.html","hash":"aeb23d44902c3c97e17b7635c9b1bac05afab0d8","modified":1761274286822},{"_id":"public/archives/2006/11/index.html","hash":"1ac9c9c271315e7f3dfee7bf710d6d95a9bb18d3","modified":1761274286822},{"_id":"public/archives/page/17/index.html","hash":"a7f5f83845a04f6b5a8d16648249a2e73171732a","modified":1761274286822},{"_id":"public/archives/2007/04/index.html","hash":"32c8be633012ab3228695b848888792d565a5e34","modified":1761274286822},{"_id":"public/archives/2007/12/index.html","hash":"9d11d9aec10ce988171a600a873f24d9f3fc5738","modified":1761274286822},{"_id":"public/archives/2008/index.html","hash":"01f71dc2112b7309a3c1ef56113f1c66117ae926","modified":1761274286822},{"_id":"public/archives/2007/index.html","hash":"82414c80eda136f3f28f9091e0a2a23dba214515","modified":1761274286822},{"_id":"public/archives/2006/06/index.html","hash":"e24ebb6bfa206b9f2c560b811f9017b26300bb02","modified":1761274286822},{"_id":"public/archives/2009/02/index.html","hash":"13163b84a431f7dfd36845078bc44ce41c4742bf","modified":1761274286822},{"_id":"public/archives/2008/07/index.html","hash":"ce8eed211faad14cf3c3edd21e1c66a0026f7f8f","modified":1761274286822},{"_id":"public/archives/2009/08/index.html","hash":"b434d719bb81fefaead746d2d7183c3c1c589eb5","modified":1761274286822},{"_id":"public/archives/2009/index.html","hash":"97a48ba858350a55d338046f1e50e270f5bd4ee3","modified":1761274286822},{"_id":"public/archives/2009/04/index.html","hash":"fef2deac9eacd2c56b78d4140b4c8aee243a4f5b","modified":1761274286822},{"_id":"public/archives/2009/11/index.html","hash":"42c5fb794eff2146edea3834c6217c24d3cf6e5e","modified":1761274286822},{"_id":"public/archives/2010/index.html","hash":"f518add976dcd1595fae4c2baa5e27f6c3d574e0","modified":1761274286822},{"_id":"public/archives/2009/12/index.html","hash":"e16773c5377140c519c5c1906bef36de38b738bd","modified":1761274286822},{"_id":"public/archives/2010/04/index.html","hash":"aeef2b65ae78f6f119c575cf3dfc2d8a1852b37e","modified":1761274286822},{"_id":"public/archives/2009/10/index.html","hash":"c2dd9f5735f5e89d2bcc41c76f7fad10d953a138","modified":1761274286822},{"_id":"public/archives/2010/01/index.html","hash":"4469a03d654e86fced0b06479606e6b7f577f62f","modified":1761274286822},{"_id":"public/archives/2010/10/index.html","hash":"c73e9597954d9a52c5a86f8228473b6ae73ce240","modified":1761274286822},{"_id":"public/archives/2010/02/index.html","hash":"6289a93bcc8f4f02d4e99dca268946b591e52317","modified":1761274286822},{"_id":"public/archives/2010/08/index.html","hash":"81852d37938363b3004ea1808b8b4aaf80072dc2","modified":1761274286822},{"_id":"public/archives/2011/01/index.html","hash":"43342ca974c7b72526ade3a9c0498ed61621108f","modified":1761274286822},{"_id":"public/archives/2011/02/index.html","hash":"1d8b6ab89b4c2d712be5d3bc83729987c9c834bd","modified":1761274286822},{"_id":"public/archives/2011/index.html","hash":"a3f447cc73a5c771a331671b156177e37cfbda82","modified":1761274286822},{"_id":"public/archives/2010/11/index.html","hash":"35d07721c47026930c7af2fd52c1c113bce26cc9","modified":1761274286822},{"_id":"public/archives/2012/index.html","hash":"af2c0f0bfa5b670904cf439b3498860dad7a26fc","modified":1761274286822},{"_id":"public/archives/2012/04/index.html","hash":"4d1e23a7e87519104a62f098a1481196fafcbd70","modified":1761274286822},{"_id":"public/archives/2013/12/index.html","hash":"cdffa6274dd34dfa2973778719ebc21133035019","modified":1761274286822},{"_id":"public/archives/2015/index.html","hash":"4876685922250c29ac0b072cb7ff4857affebaae","modified":1761274286822},{"_id":"public/archives/2012/02/index.html","hash":"f863c78945b74c2299124f74079b81515a8e3756","modified":1761274286822},{"_id":"public/archives/2015/11/index.html","hash":"71a33aa2ba27f0728e1f41c96e14f72cf676c173","modified":1761274286822},{"_id":"public/archives/2013/index.html","hash":"1bc947cb146cdf35ff265d5a19dddc8800cf12a7","modified":1761274286822},{"_id":"public/archives/2015/07/index.html","hash":"f50d1174d7cb41c7dd15c982e434f9a7a78d48fe","modified":1761274286822},{"_id":"public/archives/2020/page/3/index.html","hash":"b03f61e93b14e63174205958faea5efd9e654083","modified":1761274286822},{"_id":"public/archives/2020/05/index.html","hash":"db86ed1ae59c6800aba1c82403e8ceea205aa65f","modified":1761274286822},{"_id":"public/archives/2020/page/2/index.html","hash":"3ac6db9ab1166bd3ddc7820fac13072811ba723a","modified":1761274286822},{"_id":"public/archives/2020/06/index.html","hash":"8301d4775baec90954d7f85281b99340789925da","modified":1761274286822},{"_id":"public/archives/2020/06/page/2/index.html","hash":"76d9a018078a2664d884df5a884e5cf2c7a89676","modified":1761274286822},{"_id":"public/archives/2020/index.html","hash":"7691d998f94977f3502b071fba9277f6c4e2bb4d","modified":1761274286822},{"_id":"public/archives/2020/11/index.html","hash":"d2626113500c4270d8bfca59385df2e9a43ab4df","modified":1761274286822},{"_id":"public/archives/2020/09/index.html","hash":"56d81ea37a962c3122bedd62fd0bffa78bf42454","modified":1761274286822},{"_id":"public/archives/2021/02/index.html","hash":"bb7b8da8b3b1ed6243ee4f1c99c168da823054bc","modified":1761274286822},{"_id":"public/archives/2021/03/index.html","hash":"f11ec51c9f93baff5f03632aa7ff469efb445d7b","modified":1761274286822},{"_id":"public/archives/2024/index.html","hash":"8640379843b79570a0aa216224f2e8b96bca11d8","modified":1761274286822},{"_id":"public/archives/2021/index.html","hash":"c816dccbb9f92f15645faa360f104eeb5611f545","modified":1761274286822},{"_id":"public/archives/2024/page/2/index.html","hash":"7a05979b047c2b29ff2a80304f9625b11bf384ac","modified":1761274286822},{"_id":"public/archives/2024/page/3/index.html","hash":"c39410018b3f4d5302393d09d430ef55a82c242c","modified":1761274286822},{"_id":"public/archives/2024/page/4/index.html","hash":"358d395477a1a27e22ab5f7453c24ac41828b635","modified":1761274286822},{"_id":"public/archives/2021/07/index.html","hash":"1aebe6b7a3fce57771c78521a988ebc57da44f4a","modified":1761274286822},{"_id":"public/archives/2024/page/5/index.html","hash":"90d929ea7f1f3ea3d102fd7e543a185b49a152c2","modified":1761274286822},{"_id":"public/archives/2024/page/6/index.html","hash":"28362945ca317ff816a93793f84321619c73fcd8","modified":1761274286822},{"_id":"public/archives/2024/05/page/2/index.html","hash":"4785e198fa3e8e00876c20533543203e9fcb0ab6","modified":1761274286822},{"_id":"public/archives/2024/06/index.html","hash":"cb95573beaef7d0e0ef087dde4e08934a266674a","modified":1761274286822},{"_id":"public/archives/2024/06/page/2/index.html","hash":"aec87aea04b9e3a7916c15bafc9a3a400c068529","modified":1761274286822},{"_id":"public/archives/2024/05/index.html","hash":"37c3ec3f923f3a1a980f8fda4bf18d37c58e16ab","modified":1761274286822},{"_id":"public/archives/2024/06/page/4/index.html","hash":"fbb53fa2d445e55cac8641b8556232233b86d6d2","modified":1761274286822},{"_id":"public/archives/2024/06/page/3/index.html","hash":"167cef0d5f9e50c432d88e208924195541933b90","modified":1761274286822},{"_id":"public/archives/2024/09/index.html","hash":"e5238089ac2427d98bde9b52cb927e457e2e4ba7","modified":1761274286822},{"_id":"public/archives/2024/10/index.html","hash":"5db4b290ab84a8683cddbf93d7a6888c6a4056c6","modified":1761274286822},{"_id":"public/archives/2024/11/index.html","hash":"60ff6887957a5a54cc8ebb56b45fcc02d1580bda","modified":1761274286822},{"_id":"public/archives/2024/07/index.html","hash":"e4f88e0261c790f80393d512670ea8c2152b776e","modified":1761274286822},{"_id":"public/archives/2025/index.html","hash":"7a883f653adcc9cc0bad1605e3c34d74f020a081","modified":1761274286822},{"_id":"public/archives/2025/page/2/index.html","hash":"f0cd2f4f9c9066cdefdcb814ae9650666f6672ce","modified":1761274286822},{"_id":"public/archives/2020/07/index.html","hash":"502651511e7b13910fd4333033fd63b5d50e127f","modified":1761274286822},{"_id":"public/archives/2024/12/index.html","hash":"429cf3dd3a09ab799bf90a0800cd847579ab53aa","modified":1761274286822},{"_id":"public/archives/2025/02/index.html","hash":"4174e75b05f4947e50d6399e42fe854e6cbbb5a7","modified":1761274286822},{"_id":"public/archives/2025/page/3/index.html","hash":"8341e74018ccbb6a3b9f8ef4f4dcd69c260239f1","modified":1761274286822},{"_id":"public/archives/2025/04/index.html","hash":"3f634ed64cc04c7e019dd616b14ca43c22478a7b","modified":1761274286822},{"_id":"public/archives/2025/06/index.html","hash":"7c049ffe65f310070cf9b1649ebf0c486de55406","modified":1761274286822},{"_id":"public/archives/2025/page/4/index.html","hash":"4dcf9878729aba499fb68f58401c4bd5a62dba21","modified":1761274286822},{"_id":"public/archives/2025/07/index.html","hash":"df93e9e7bcaa7df98d96066cd1ded497cc93166f","modified":1761274286822},{"_id":"public/archives/2025/08/index.html","hash":"da84fc139e57d0819711da74f2afaef10afaf527","modified":1761274286822},{"_id":"public/archives/2025/10/index.html","hash":"dec2dc833e1e2e51320eb4ea7640c95d175f8e59","modified":1761274286822},{"_id":"public/index.html","hash":"ce74756cb31b5210bdf925f7d92775b907a7e339","modified":1761274286822},{"_id":"public/archives/2025/06/page/2/index.html","hash":"400416eedbf504f31002647e8e4ed87cb106ec7e","modified":1761274286822},{"_id":"public/page/2/index.html","hash":"5b06c18e3b7c1ba5230f324fd537a0de8c767460","modified":1761274286822},{"_id":"public/archives/2025/05/index.html","hash":"96b6140ff9c5a1432cce02817fc92310acd08bd7","modified":1761274286822},{"_id":"public/page/4/index.html","hash":"a80b47146ed49f0d2fe227964b90c2354b638ab1","modified":1761274286822},{"_id":"public/page/6/index.html","hash":"3f902919168847e5d12440f303b64aeb3dc0a072","modified":1761274286822},{"_id":"public/page/7/index.html","hash":"01a2fb08ed01988c75325746bbde10351f2b2f0d","modified":1761274286822},{"_id":"public/page/5/index.html","hash":"8a7c320c8bcd8fd694cde204eee8a409b53e6330","modified":1761274286822},{"_id":"public/page/9/index.html","hash":"4b0fa81553e24041d9de6402f6efd7637dce00e4","modified":1761274286822},{"_id":"public/page/8/index.html","hash":"1d76b4d1a6e403f1027f3da92aab6c63a37e9295","modified":1761274286822},{"_id":"public/page/11/index.html","hash":"63bb155e5f60400825441bca590f6412b5b1edd8","modified":1761274286822},{"_id":"public/page/10/index.html","hash":"7ff85df5156ed66a4db5f23d2ddc7cf2774c3f3b","modified":1761274286822},{"_id":"public/page/13/index.html","hash":"9bdef851ce1bb917bb83de762cb590f7b1a1fb8c","modified":1761274286822},{"_id":"public/page/3/index.html","hash":"9e9759ee5932be65494b03302974040ff7174ffb","modified":1761274286822},{"_id":"public/page/15/index.html","hash":"12dae0b09bb2ff32e353b338d7feaf84c072523e","modified":1761274286822},{"_id":"public/page/12/index.html","hash":"bc8d67af207938b1687ab85ee71c96ee3c36c0d6","modified":1761274286822},{"_id":"public/page/14/index.html","hash":"3067e0727b985d77938ec2730dfaabacfbfec35b","modified":1761274286822},{"_id":"public/tags/这是啥/index.html","hash":"2ed8f1c8c52710b9b9e3c49c91d4ba13bc39361a","modified":1761274286822},{"_id":"public/page/17/index.html","hash":"2ab0008133a05fc072bb0904301a492fe7c57a1a","modified":1761274286822},{"_id":"public/tags/阿甘/index.html","hash":"d2e1e96e2b78c1f5a4c4563ad70ba49a1237b0c3","modified":1761274286822},{"_id":"public/page/16/index.html","hash":"e596453eb6e309d16fbb54c77ca4e7f6b9a6f0cb","modified":1761274286822},{"_id":"public/tags/杂/index.html","hash":"ca2876d976920952826d5fe9801a3b59dc87313e","modified":1761274286822},{"_id":"public/tags/外公/index.html","hash":"06ec8c30c536bd42535c31835d092503a4d2af19","modified":1761274286822},{"_id":"public/tags/外婆/index.html","hash":"ef4b09a1cbd2c778b6cb8cf60d353e0da7c848f7","modified":1761274286822},{"_id":"public/tags/无题/index.html","hash":"06e27174fbd33520d6e3b2d9e50103d4f1db8c84","modified":1761274286822},{"_id":"public/tags/饭后感/index.html","hash":"ba100ad67ccc35f11a914827a1363bb3b17f65f6","modified":1761274286822},{"_id":"public/tags/宁波/index.html","hash":"dc6a9d088b9c875df190460647b5160c9da90f0a","modified":1761274286822},{"_id":"public/tags/迷雾/index.html","hash":"73bc5e1ea42c9f7ea38b022cb52dc0349194d12a","modified":1761274286822},{"_id":"public/tags/躯壳/index.html","hash":"93b041cbeeff4864ca5d285297df070a72dd0ae2","modified":1761274286822},{"_id":"public/tags/憎恨/index.html","hash":"30a7e7b263b1008cf95ea23ecd06d37a95d8ac66","modified":1761274286822},{"_id":"public/tags/逝者/index.html","hash":"ecdd9a8d7af0c7490bf4595f34d7b42f6838bf04","modified":1761274286822},{"_id":"public/tags/好友/index.html","hash":"2e6dd8ac263191086c72ce7f33deff48a4a60c26","modified":1761274286822},{"_id":"public/tags/安息/index.html","hash":"a9ec38710eaf9594620e2ce91e247d0c01daf7e9","modified":1761274286822},{"_id":"public/tags/打牌/index.html","hash":"0322f11dd6a1662e88e981506ddf1eb32b998c5f","modified":1761274286822},{"_id":"public/tags/成都/index.html","hash":"5bde2be12fe20ccdd07add86f70522d52193a56e","modified":1761274286822},{"_id":"public/tags/盆地/index.html","hash":"5495d796539e26b6801378ebb5e2ed7b87ad4a9e","modified":1761274286822},{"_id":"public/tags/读后感/index.html","hash":"f4cd8b99ad3d2abb52f49d63d2eb6a755928eb90","modified":1761274286822},{"_id":"public/tags/茶铺/index.html","hash":"428950cd00cf7edfe3eacd941a977c2ffd0d8a61","modified":1761274286822},{"_id":"public/tags/诡异/index.html","hash":"675493518b2baf178ada707cb58e06332a020081","modified":1761274286822},{"_id":"public/tags/电影/index.html","hash":"87df253c17820b1b752f47256b8f8da51199fabf","modified":1761274286822},{"_id":"public/tags/霸王别姬/index.html","hash":"5094617db1877e3fb5981ff92f1bb018e17e1a35","modified":1761274286822},{"_id":"public/tags/猫/index.html","hash":"03d43473e233f8215b7e1733ed86efbd5e9f7a28","modified":1761274286822},{"_id":"public/tags/雾霾/index.html","hash":"bc3207752a9d9d994c59bbcc0b921ad7d3eea098","modified":1761274286822},{"_id":"public/tags/grub/index.html","hash":"7e194a99fd913a27218e0bca0f88b0f2021ba3ff","modified":1761274286822},{"_id":"public/tags/命题作文/index.html","hash":"57565ffb1bab1270c3e1a85d7fa0c0545c45679c","modified":1761274286822},{"_id":"public/tags/电视剧/index.html","hash":"7420e5b0bd40ea1f18a8f384163849c42fbdb8e6","modified":1761274286822},{"_id":"public/tags/活着/index.html","hash":"5a945a78c90277ff2f95c1aebcd7f597c61b9ff4","modified":1761274286822},{"_id":"public/tags/妖怪/index.html","hash":"48e0449629b57687def3876bbf1e679bd93c96e5","modified":1761274286822},{"_id":"public/tags/next/index.html","hash":"1c1d4863e6c41a89be5bd896f9a0582fcc421407","modified":1761274286822},{"_id":"public/tags/paper/index.html","hash":"ac813d02159eb67adfa7a5e7d0faee44500e4f5f","modified":1761274286822},{"_id":"public/tags/web/index.html","hash":"1b970c6e7d2530e0d0825a1adc30e0d73961e5a2","modified":1761274286822},{"_id":"public/tags/paper/page/3/index.html","hash":"d4eb3f275f760ad64ae039b772898bd6facc3c47","modified":1761274286822},{"_id":"public/tags/paper/page/4/index.html","hash":"ada223c668dd2df6925e58fd1f2e422eea6aed59","modified":1761274286822},{"_id":"public/tags/paper/page/2/index.html","hash":"a04033b5335983b68892604a08d409d0108a282a","modified":1761274286822},{"_id":"public/tags/hexo/index.html","hash":"81d907c6978c20cac19d5d6c153b4ada0722221a","modified":1761274286822},{"_id":"public/tags/日记/index.html","hash":"309f69408a87e37365eb852ebdd6791b33342b1b","modified":1761274286822},{"_id":"public/tags/博客/index.html","hash":"bb16486d2432b58bfc359b3fe07da6d6c4d071d3","modified":1761274286822},{"_id":"public/tags/网易/index.html","hash":"0bc95a3cd078cf3c7949ebf80abf94bbd54a68be","modified":1761274286822},{"_id":"public/tags/儿子/index.html","hash":"88c92a23ffcef74d849d736002c8a07e8a82c789","modified":1761274286822},{"_id":"public/tags/web/page/2/index.html","hash":"6f8cb9ba9db92716d83afb5dd967a101068919aa","modified":1761274286822},{"_id":"public/tags/历史/index.html","hash":"f7ce42e3010df5c606a700c49171aee1cf295e68","modified":1761274286822},{"_id":"public/tags/Linux/index.html","hash":"4c3e938bebfbcb3f3c9059645f04b9d7a63064cf","modified":1761274286822},{"_id":"public/tags/反演/index.html","hash":"69fbaf942a1318759dae3dc1607b213b6b884748","modified":1761274286822},{"_id":"public/tags/sed/index.html","hash":"15210d7e1cee8b0e1af026eb4e275ab309ff86b0","modified":1761274286822},{"_id":"public/tags/wiki/index.html","hash":"7b522489d87c12b58763e346e4ca98f7d9c90468","modified":1761274286822},{"_id":"public/tags/axes/index.html","hash":"5a76bfdef94e63a2700b7b8d3823f5e3204f0320","modified":1761274286822},{"_id":"public/tags/乱/index.html","hash":"6ea18350908046a15b9d130300c3f4ba22e39064","modified":1761274286822},{"_id":"public/tags/blog/index.html","hash":"f3bbde637b9b0c4196b5f2dcc6ecb149983e6d6e","modified":1761274286822},{"_id":"public/tags/linux/index.html","hash":"edd65b5e62d1854f71d99c94452efa133ee32a0e","modified":1761274286822},{"_id":"public/tags/中文/index.html","hash":"9c2d63fb01764259f380981fec01d6cfeb261051","modified":1761274286822},{"_id":"public/tags/model/index.html","hash":"bfeb72eac2d98b6656f14fb015795eac233b8959","modified":1761274286822},{"_id":"public/tags/sem/index.html","hash":"7e15bd7944b7c8b72ee1ee3dff4b06c40511423c","modified":1761274286822},{"_id":"public/tags/过渡带/index.html","hash":"a9766b36a4774189b079425051e7e129f0e62cf0","modified":1761274286822},{"_id":"public/tags/video/index.html","hash":"ab2d2de74703d4cb06decc5312e57ce78bfc7ea1","modified":1761274286822},{"_id":"public/tags/filezilla/index.html","hash":"999a6948e48b07ec899481800a3005da6296922e","modified":1761274286822},{"_id":"public/tags/瘾/index.html","hash":"f060e314f800cb0cb4592fd25d41dc58e2bbd28a","modified":1761274286822},{"_id":"public/tags/git/index.html","hash":"d1080d7f89262f43190ec48c931035c68118e12b","modified":1761274286822},{"_id":"public/tags/学习/index.html","hash":"ed3c7f31b9dfeccdaac5a3d12da3e3a010100844","modified":1761274286822},{"_id":"public/tags/NCF/index.html","hash":"3a1a76552d2a54c3cb58a6157607bb282c5b591e","modified":1761274286822},{"_id":"public/tags/ai/index.html","hash":"d118f1d0a1c490c56b1a88d681f27f1248cf5f7c","modified":1761274286822},{"_id":"public/tags/laTeX/index.html","hash":"20d941d2aaddff8e6c3b566fccd3a2d0a845626e","modified":1761274286822},{"_id":"public/tags/大脑/index.html","hash":"79f8efebe62a2ea058a2d09535f2b971ff2742a4","modified":1761274286822},{"_id":"public/tags/某日记/index.html","hash":"8870288b10001bbf6acce98c8b591e6044719158","modified":1761274286822},{"_id":"public/tags/review/index.html","hash":"5acce7f6ef47ccb20e60b05092884a7321db8358","modified":1761274286822},{"_id":"public/tags/glacial-seismology/index.html","hash":"dfc43e1792d57ebbd68e1c33c36de819acd46865","modified":1761274286822},{"_id":"public/tags/project/index.html","hash":"44de92fd9559dfd03ecc4979e1650f142dbcbaff","modified":1761274286822},{"_id":"public/tags/code/index.html","hash":"de6a7eb6ce0f9168f12ee4aa9aef2456205c3c42","modified":1761274286822},{"_id":"public/tags/work/index.html","hash":"27cbd6ee102e21f02523939d7158bb69e6c39b09","modified":1761274286822},{"_id":"public/tags/seismic/index.html","hash":"163e97e8aecb242ccd5f8535f878ef2e94740215","modified":1761274286822},{"_id":"public/tags/science/index.html","hash":"34baf75ef317edf4ad618c998a24c0f41516a6ab","modified":1761274286822},{"_id":"public/tags/Seismology/index.html","hash":"a4d6ff36000cb9f3d36f48438d16931d20779ace","modified":1761274286822},{"_id":"public/tags/python/page/2/index.html","hash":"6c8e3a56ab5147a26ebc4798ec9511be82cfb69d","modified":1761274286822},{"_id":"public/tags/seismology/index.html","hash":"2b316a7a4671673abaa054002e4da0a209ceed29","modified":1761274286822},{"_id":"public/tags/python/index.html","hash":"12c82f5b3d8e30e166732aeb8104e6f97ca676f9","modified":1761274286822},{"_id":"public/tags/obspy/index.html","hash":"5caae3c90e9918bd951b6b1864318098370d9d9c","modified":1761274286822},{"_id":"public/tags/script/index.html","hash":"e28c569f991e413ff773618f67e38055a2852bc6","modified":1761274286822},{"_id":"public/tags/blogs/index.html","hash":"81024c7c853c4786582a7754541c26999dc9a01e","modified":1761274286822},{"_id":"public/tags/LaTeX/index.html","hash":"6b65ac699530b1979bcc28afd062ed8fc3d509d0","modified":1761274286822},{"_id":"public/tags/Fun/index.html","hash":"4afce7d453afb81e6a4ce6de022fe7a5b5b81bfc","modified":1761274286822},{"_id":"public/categories/某日记/index.html","hash":"e53acee01fb41e0a7f58c6b5289173841b938c10","modified":1761274286822},{"_id":"public/tags/gmt/index.html","hash":"29bf12ab844baf41b8abe5b7e445cc7f623e0151","modified":1761274286822},{"_id":"public/categories/乱笔/index.html","hash":"89b7178df721d27eec0da97cea85070ef483252e","modified":1761274286822},{"_id":"public/tags/乱笔/index.html","hash":"dae697140578a993bcb09451b9ce2ed928c44323","modified":1761274286822},{"_id":"public/categories/日记/index.html","hash":"fd0f40a54a093c8a7a771a7ee191504d2bdde839","modified":1761274286822},{"_id":"public/categories/日记/page/2/index.html","hash":"a9a64574bd8c3210b236889a3d2f5ca7f2738436","modified":1761274286822},{"_id":"public/categories/某日记/page/2/index.html","hash":"c9f0b2e626acec4c3422f4b6f33689001916dfb9","modified":1761274286822},{"_id":"public/categories/Linux/page/2/index.html","hash":"9bcb99934e5090c5d870abb1b39f90c89654946d","modified":1761274286822},{"_id":"public/categories/web/index.html","hash":"efb9d5f2d3c6bc13b41cb1166a87cd44f7be1c86","modified":1761274286822},{"_id":"public/categories/web/page/2/index.html","hash":"2ef1f953619d48c4d2e4ee1b448d20d4a9e03197","modified":1761274286822},{"_id":"public/categories/work/index.html","hash":"3633c57f21bd0a32d43fd1abc3886fbf46981cc8","modified":1761274286822},{"_id":"public/categories/work/page/2/index.html","hash":"db0b6bfed2055069e69d00e2c80138ebec202ecd","modified":1761274286822},{"_id":"public/categories/work/page/3/index.html","hash":"375e9612ad4bab6ac44caa2377d20a02411bcf0b","modified":1761274286822},{"_id":"public/categories/Linux/index.html","hash":"fcce19e74c6136b6db1456c101781fadf4a438d1","modified":1761274286822},{"_id":"public/categories/work/page/4/index.html","hash":"4f93b6962bec19c73b758433f7c75ab10e30178d","modified":1761274286822},{"_id":"public/categories/work/page/5/index.html","hash":"32eca6368da81705185312b7cc54c74c9ee71e3a","modified":1761274286822},{"_id":"public/categories/gmt/index.html","hash":"9bed46ab1839e8e15c6152aee7114a8210de8324","modified":1761274286822},{"_id":"public/categories/学习/index.html","hash":"9d7d5bfdb5980d87f2a0c5f12f269cef9164ce32","modified":1761274286822},{"_id":"public/categories/work/page/6/index.html","hash":"dfbc1fe241c93d85b61a478704c5abc7584e0b09","modified":1761274286822},{"_id":"public/categories/Tools/index.html","hash":"c3de9002f16d0d1c6c3ddc9b76f4991b763a9b37","modified":1761274286822},{"_id":"public/categories/seismology/index.html","hash":"a6ca3b954a99a71ff39e54639c6f5c2cd8e4e19d","modified":1761274286822},{"_id":"public/categories/python/index.html","hash":"b87bb77506557e5ced563c24db82666be6ab1077","modified":1761274286822},{"_id":"public/categories/杂/index.html","hash":"149582522448cc4a13a21cc071f592b4b28b07fc","modified":1761274286822},{"_id":"public/categories/ai/index.html","hash":"e8f1615e68fd609cf2c8c4d798e6e09ddfd1bbe9","modified":1761274286822},{"_id":"public/robots.txt","hash":"77aa9867d42bc5f009b06bad546ba80dfee58bbf","modified":1761274286822},{"_id":"public/images/algolia_logo.svg","hash":"ec119560b382b2624e00144ae01c137186e91621","modified":1761274286822},{"_id":"public/CNAME","hash":"1b08c75f029668b73f799332a7d19f07da16828e","modified":1761274286822},{"_id":"public/ads.txt","hash":"6553ac389f542a9341fc3d2cc65d12883145404b","modified":1761274286822},{"_id":"public/images/alipay.png","hash":"15569378dd21b0c710373d897a44603a3bed387b","modified":1761274286822},{"_id":"public/images/avatar.gif","hash":"18c53e15eb0c84b139995f9334ed8522b40aeaf6","modified":1761274286822},{"_id":"public/images/cc-by-nc.svg","hash":"8d39b39d88f8501c0d27f8df9aae47136ebc59b7","modified":1761274286822},{"_id":"public/images/apple-touch-icon-next.png","hash":"2959dbc97f31c80283e67104fe0854e2369e40aa","modified":1761274286822},{"_id":"public/images/cc-by-nc-sa.svg","hash":"3031be41e8753c70508aa88e84ed8f4f653f157e","modified":1761274286822},{"_id":"public/images/cc-by-nc-nd.svg","hash":"c6524ece3f8039a5f612feaf865d21ec8a794564","modified":1761274286822},{"_id":"public/images/cc-by-nd.svg","hash":"c563508ce9ced1e66948024ba1153400ac0e0621","modified":1761274286822},{"_id":"public/images/cc-zero.svg","hash":"87669bf8ac268a91d027a0a4802c92a1473e9030","modified":1761274286822},{"_id":"public/images/cartoon.jpg","hash":"042af7387a7795d23ac492dd9080b6e0867d0d3e","modified":1761274286822},{"_id":"public/images/cc-by-sa.svg","hash":"aa4742d733c8af8d38d4c183b8adbdcab045872e","modified":1761274286822},{"_id":"public/images/favicon-16x16-next.png","hash":"943a0d67a9cdf8c198109b28f9dbd42f761d11c3","modified":1761274286822},{"_id":"public/images/cc-by.svg","hash":"28a0a4fe355a974a5e42f68031652b76798d4f7e","modified":1761274286822},{"_id":"public/images/icon.png","hash":"f7d14d0eba4a2d69b26b7cdf229156e0048ebff6","modified":1761274286822},{"_id":"public/images/j-icon-16x16.png","hash":"d5f47b175f172971fc3fe3e891b8db767dc8d055","modified":1761274286822},{"_id":"public/images/j-icon-32x32.png","hash":"ee0dc2efce610affbaa13c416251dc6e2e036ddd","modified":1761274286822},{"_id":"public/images/favicon-32x32-next.png","hash":"0749d7b24b0d2fae1c8eb7f671ad4646ee1894b1","modified":1761274286822},{"_id":"public/images/onion.jpg","hash":"4ea5453f2d71a672a7e1d8bda79931139ccb6858","modified":1761274286822},{"_id":"public/images/logo.svg","hash":"d29cacbae1bdc4bbccb542107ee0524fe55ad6de","modified":1761274286822},{"_id":"public/images/logo-algolia-nebula-blue-full.svg","hash":"b85e274207b1392782476a0430feac98db1e7da0","modified":1761274286822},{"_id":"public/images/wechatpay.png","hash":"efdf5466bea015de5b12336fc580d70eba8417b5","modified":1761274286822},{"_id":"public/how-to-add-frame-in-hexo-next/frame.png","hash":"3e7779737fca44d93f3659c9595898ee5651158a","modified":1761274286822},{"_id":"public/how-to-configure-chinese-for-gmt/pstext.png","hash":"1ec300ebc2457ccd9d0ec9cf07e80a24d1bd1dfe","modified":1761274286822},{"_id":"public/happy-new-year/acce.png","hash":"90bdd202a7bbbd2bbd5322a6f6e92b510f567f30","modified":1761274286822},{"_id":"public/assets/js/APlayer.min.js","hash":"22caa28ff6b41a16ff40f15d38f1739e22359478","modified":1761274286822},{"_id":"public/css/hbe.style.css","hash":"cba825c72f583ce13e280b24df5a6c1cc2fcbf6a","modified":1761274286822},{"_id":"public/lib/hbe.js","hash":"f2f75e90c4b155a418ace16556a8c3dbf8135eeb","modified":1761274286822},{"_id":"public/assets/css/APlayer.min.css","hash":"07372a2ba507388d0fed166d761b1c2c2a659dce","modified":1761274286822},{"_id":"public/assets/js/Meting.min.js","hash":"a0585220b918d78649a7893279e1ec4fb5abe835","modified":1761274286822},{"_id":"public/images/alipay.jpg","hash":"2564c6ccf3940671c65f198e8479edaa26315377","modified":1761274286822},{"_id":"public/images/seisamuse.png","hash":"1e2bcd2ebb115699288facd92abcd47bf3a4cedc","modified":1761274286822},{"_id":"public/images/wechat_channel.jpg","hash":"2354f69ffa50bc22f389dd80423827d62d6fcc9a","modified":1761274286822},{"_id":"public/reward-configuration/donate.png","hash":"2b4ffd57019bfa452247194fdf83879c7da04b7a","modified":1761274286822},{"_id":"public/IQ-decrease/iq.jpg","hash":"76643626c56b2e5107b38df376ac035b2f661b81","modified":1761274286822},{"_id":"public/mantle-transition-zone/Picture2.png","hash":"c5acabd7384c45c65ef286bf5c47f1b1e9caebc3","modified":1761274286822},{"_id":"public/css/main.css","hash":"493c238077419a6b6d965aeaa1bb27c8042f4246","modified":1761274286822},{"_id":"public/css/noscript.css","hash":"4cd5301e478e0e0d4b176740ec314087ec5cb707","modified":1761274286822},{"_id":"public/js/bookmark.js","hash":"0f563ffbf05fad30e854e413ab17ff7164ab5a53","modified":1761274286822},{"_id":"public/js/comments-buttons.js","hash":"1a7344440321713426a0b2ab17e276b5bdf85ade","modified":1761274286822},{"_id":"public/js/comments.js","hash":"66ae2e26ea36a41b72c638ea8b220296638ae952","modified":1761274286822},{"_id":"public/js/motion.js","hash":"8e587c086e3cf8687108fbb3241fe1534c3df463","modified":1761274286822},{"_id":"public/js/next-boot.js","hash":"8e2d589585f5270ee90285d3e65b69923c7629d8","modified":1761274286822},{"_id":"public/js/pjax.js","hash":"adc751f9b63b7a6b4d381506d35a1b3ff4de891f","modified":1761274286822},{"_id":"public/js/schedule.js","hash":"a1333258726caf84f368a8f8454639c7dc1626bb","modified":1761274286822},{"_id":"public/js/utils.js","hash":"f92420649b150703469bba41cbd5c72768beed88","modified":1761274286822},{"_id":"public/js/third-party/addtoany.js","hash":"5276c8f78ee562a8965216dc67d762e59cb4a9f2","modified":1761274286822},{"_id":"public/js/config.js","hash":"4c4ebbe3b3f3841a26f9d5af6d0ba8bc6da01c54","modified":1761274286822},{"_id":"public/js/third-party/pace.js","hash":"0ef04218b93561ba4d0ff420d556c3d90a756d32","modified":1761274286822},{"_id":"public/js/sidebar.js","hash":"b3289010a0cb52c525b1395db72bd463424f2f48","modified":1761274286822},{"_id":"public/js/third-party/analytics/baidu-analytics.js","hash":"f629acc46ff40c071ffd31b77d5c7616f0fdd778","modified":1761274286822},{"_id":"public/js/third-party/quicklink.js","hash":"eed02e6fced8e5a653077205d4d4d7834ca71472","modified":1761274286822},{"_id":"public/js/third-party/analytics/growingio.js","hash":"78dd3cf04082b7dbe6246e404b2aa8e726922402","modified":1761274286822},{"_id":"public/js/third-party/analytics/google-analytics.js","hash":"def07bcc7c17d8a0caad177fb1dd2f3a5e5b3536","modified":1761274286822},{"_id":"public/js/third-party/chat/chatra.js","hash":"c32180522788c10e51df1803aa6842ef0432ddc9","modified":1761274286822},{"_id":"public/js/third-party/analytics/matomo.js","hash":"c6a25b26a1443caa70b47fd3dfa282271574deb5","modified":1761274286822},{"_id":"public/js/third-party/chat/tidio.js","hash":"b0079f6a4601e06ca6fe46e83a2f5af553e9bc3c","modified":1761274286822},{"_id":"public/js/third-party/comments/disqus.js","hash":"da361917d65e5dca8362f8cdeb6c8cc0e8316cec","modified":1761274286822},{"_id":"public/js/third-party/comments/changyan.js","hash":"260d1a77d6a3bb33a579d3e4cca1997003e799b5","modified":1761274286822},{"_id":"public/js/third-party/comments/gitalk.js","hash":"0ec038cf83e8ec067534f16a54041e47a3c1e59a","modified":1761274286822},{"_id":"public/js/third-party/comments/isso.js","hash":"753a873b6f566aff5ba77ca23f91b78eb880ca64","modified":1761274286822},{"_id":"public/js/third-party/fancybox.js","hash":"819f382c561fe5ec23c67cc5fabd63dd1cc22dc1","modified":1761274286822},{"_id":"public/js/third-party/comments/livere.js","hash":"2247d88c934c765c43013337860774aaa99f0b31","modified":1761274286822},{"_id":"public/js/third-party/comments/disqusjs.js","hash":"1e826dea3f684c0515f362dc1352447a1f0eae71","modified":1761274286822},{"_id":"public/js/third-party/math/mathjax.js","hash":"5c749b9c1c3bb738122d0516211ecff6496d4907","modified":1761274286822},{"_id":"public/js/third-party/search/algolia-search.js","hash":"fdb7b7cef1a147d897e7f7cd8903b58368ec2062","modified":1761274286822},{"_id":"public/js/third-party/search/local-search.js","hash":"4536cb6d0a9bbaaa86fab3fa0101f6a3a3ec5a76","modified":1761274286822},{"_id":"public/js/third-party/math/katex.js","hash":"83c54ee536e487a1031783443fe0cb63b1b4767e","modified":1761274286822},{"_id":"public/js/third-party/comments/utterances.js","hash":"f67f90eb03e284c82da2b8cf2f1e31801813c16d","modified":1761274286822},{"_id":"public/js/third-party/tags/mermaid.js","hash":"6bf821310342c5b87a631873e7650a475a0765f1","modified":1761274286822},{"_id":"public/js/third-party/statistics/firestore.js","hash":"6e0682bb42170d61b13b786295f45f9c785f8b73","modified":1761274286822},{"_id":"public/js/third-party/tags/wavedrom.js","hash":"40dcd10df6edf124088c329346e0cc0bdac74ef1","modified":1761274286822},{"_id":"public/js/third-party/tags/pdf.js","hash":"af78c22f0e61c8c8aa8794e585e0d632c6d4fcb8","modified":1761274286822},{"_id":"public/js/third-party/statistics/lean-analytics.js","hash":"835cbf54c49ef1327f47df70ff2636ad36b6f57d","modified":1761274286822},{"_id":"public/images/wechatpay.jpg","hash":"19ab15aec58a8cf5c802467a44b45f5385013f27","modified":1761274286822},{"_id":"public/stop-os-update/app.png","hash":"56687bfb4ca03a699c1f3674285a1317a86f2494","modified":1761274286822},{"_id":"public/gmt-time-axes/1.png","hash":"9942242d7e71451dc6f45e21af4f3c14b0fb8be9","modified":1761274286822},{"_id":"public/gmt-time-axes/2.png","hash":"8c5f225e6e265eb49d8470d536642003ef748673","modified":1761274286822},{"_id":"public/how-to-calculate-synthetic-NCF/source_dis.png","hash":"1923233a6d9a4b302b1b0cc8c20a5658c2dab6f6","modified":1761274286822},{"_id":"public/gmt-time-axes/spec.png","hash":"7fbfe86da3d9bdd9b87c093cb80b0a1351aad8df","modified":1761274286822},{"_id":"public/US-upper-mantle-vs-model/figure5.png","hash":"4c7a6263723d30021eda57676063f1c6f9c51cee","modified":1761274286822},{"_id":"public/mantle-transition-zone/Picture1.png","hash":"3d1cdee808ffa1c3986e7ddebfb2c0b2c9b9c4d3","modified":1761274286822},{"_id":"public/images/bg.jpg","hash":"93007f70b09f554b1c8fca77bc8d0fdec2a65cb4","modified":1761274286822}],"Category":[{"name":"某日记","_id":"cmh498iob0004wvou3t2m1wbh"},{"name":"乱笔","_id":"cmh498ioh000hwvou9jescuhj"},{"name":"日记","_id":"cmh498iol000vwvou65jqgsu2"},{"name":"杂","_id":"cmh498iov002iwvoubenbh8q3"},{"name":"Linux","_id":"cmh498iox002swvoub6h1bc8l"},{"name":"web","_id":"cmh498ip00038wvou3btofi23"},{"name":"work","_id":"cmh498ip1003fwvou1ab8djs3"},{"name":"gmt","_id":"cmh498ip8004rwvou85za9xd6"},{"name":"学习","_id":"cmh498ipi006jwvouczyyhiqz"},{"name":"Tools","_id":"cmh498ipm0078wvougjmpbftb"},{"name":"seismology","_id":"cmh498iqd00c5wvou4mzzfude"},{"name":"ai","_id":"cmh498iqg00cqwvou8510dynk"},{"name":"python","_id":"cmh498iqk00diwvou47358807"}],"Data":[{"_id":"sidebar","data":"\n"}],"Page":[{"_content":"{\n    \"name\": \"SEISAMUSE\",\n    \"short_name\": \"SEISAMUSE\",\n    \"icons\": [\n        {\n            \"src\": \"./icons/android-chrome-512x512.png\",\n            \"sizes\": \"512x512\",\n            \"type\": \"image/png\"\n        }\n    ],\n    \"theme_color\": \"#fff\",\n    \"background_color\": \"#fff\",\n    \"display\": \"standalone\",\n    \"orientation\": \"portrait-primary\",\n    \"start_url\": \"./?utm_source=homescreen\"\n}\n","source":"manifest.json","raw":"{\n    \"name\": \"SEISAMUSE\",\n    \"short_name\": \"SEISAMUSE\",\n    \"icons\": [\n        {\n            \"src\": \"./icons/android-chrome-512x512.png\",\n            \"sizes\": \"512x512\",\n            \"type\": \"image/png\"\n        }\n    ],\n    \"theme_color\": \"#fff\",\n    \"background_color\": \"#fff\",\n    \"display\": \"standalone\",\n    \"orientation\": \"portrait-primary\",\n    \"start_url\": \"./?utm_source=homescreen\"\n}\n","date":"2024-06-03T08:59:11.947Z","updated":"2024-05-27T06:36:37.725Z","path":"manifest.json","layout":"false","title":"","comments":1,"_id":"cmh498io40000wvou5he0hd83","content":"{\"name\":\"SEISAMUSE\",\"short_name\":\"SEISAMUSE\",\"icons\":[{\"src\":\"./icons/android-chrome-512x512.png\",\"sizes\":\"512x512\",\"type\":\"image/png\"}],\"theme_color\":\"#fff\",\"background_color\":\"#fff\",\"display\":\"standalone\",\"orientation\":\"portrait-primary\",\"start_url\":\"./?utm_source=homescreen\"}"},{"title":"关于我","date":"2020-05-28T06:03:54.000Z","type":"about","comments":0,"_content":"## 我干啥的\n搞地球物理学的战五宅。\n\n## 研究方向\n地震学，速度结构，背景噪声，地震定位等。\n\n## 这是哪里\n这里是我用来记笔记的地方。\n\n## 我的能力\n会点地球物理，会点分析数据，会写点小文章，会点Linux。\n\n## 其他链接\n[Google scholar](https://scholar.google.com/citations?user=HlONCtkAAAAJ&hl=en)，[ResearchGate](https://www.researchgate.net/profile/Jun_Xie6)\n\n## 文章列表\n38, 危自根, 储日升, 谢军等, (2024), 当阳复向斜页岩气探测区地壳结构及其构造暗示, 地球物理学报, 67(8).\n37, Jun Xie, Xiangfang Zeng, Chao Liang, et al., (2024), Ice plate deformation and cracking revealed by an in situ-distributed acoustic sensing array, The Cryosphere, 18(2): 837-847. \n36, AG Osotuyi, Sidao Ni, Jiajun Chong, et al., (2023), Seismometer orientation correction via teleseismic receiver function measurements in West Africa and adjacent Islands, Seismological Society of America, 94(3): 1509-1525.\n35, Jin Ruizhi, Xiaohui He, Hongjian Fang, et al., (2023), Topography effect on ambient noise tomography: a case study for the Longmen Shan area, eastern Tibetan Plateau, Geophysical Journal International, 233(1): 1-12.\n34, 胡锦涛, 谢军, 危自根等, (2023), 三峡库区秭归段浅层速度结构和孕震环境, 地震学报, 45(2): 223-233.\n33, 张丽娜, 谢军, 迟本鑫等 (2023), 分布式光纤地震传感技术在成像研究中的应用进展, 地球与行星物理论评, 54(2): 140-149.\n32, 林融冰, 包丰, 谢军等 (2022), 光缆布设方式对犇犃犛主, 被动源记录的影响, 地球物理学报，65(10).\n31, Wei Zigen, Risheng Chu, Jun Xie, et al. (2022), Crustal structure in the Weiyuan shale gas field, China, and its tectonic implications, Tectonophysics, 837: 229449.\n30, 王烁帆, 倪四道, 王伟涛等 (2022), 基于背景噪声经验格林函数的地震准确定位精度分析, 地球物理学报, 65(8).\n29, 操玉文, 曾祥方, 李正斌等(2022), 云南漾濞Ms6.4地震信号的旋转和平动分量面波记录分析研究, 地球物理学报, 65(2).\n28, Chen Yongyan, Jun Xie, Sidao Ni, (2022), Generation mechanism of the 26 s and 28 s tremors in the Gulf of Guinea from statistical analysis of magnitudes and event intervals, Earth and Planetary Science Letters 578, 117334.\n27, Lv Hao, Xiangfang Zeng, Feng Bao et al., (2022), ADE-Net: A deep neural network for DAS earthquake detection trained with a limited number of positive samples, IEEE Transactions on Geoscience and Remote Sensing 60, 1-11.\n26, Song Zhenhong, Xiangfang Zeng, Jun Xie, et al., (2021), Sensing shallow structure and traffic noise with fiber-optic internet cables in an urban area, Surveys in Geophysics 42: 1401-1423.\n25, Xia Xin, Zhiwei Li, Feng Bao, et al., (2021), Sedimentary structure of the Sichuan Basin derived from seismic ambient noise tomography, Geophysical Journal International, 225(1): 54-67.\n24, Xie Jun, Risheng Chu, Sidao Ni, (2021), Evaluating global tomography models with antipodal ambient noise cross correlation functions, Journal of Geophysical Research: Solid Earth, 126(3): e2020JB020444.\n23, Chen Haopeng, Zhiwei Li, Zhicai Luo, et al., (2021), Crust and upper mantle structure of the South China Sea and adjacent areas from the joint inversion of ambient noise and earthquake surface wave dispersions, Geochemistry, Geophysics, Geosystems, e2020GC009356.\n22, Lin Xin, Jinlai Hao, Dun Wang, et al., (2021), Coseismic Slip Distribution of the 24 January 2020 Mw 6.7 Doganyol Earthquake and in Relation to the Foreshock and Aftershock Activities, Seismological Society of America, 92(1): 127-139.\n21, Baolong Zhang, Xiangfang Zeng, Jun Xie, et al., (2020), Validity of Resolving the 785 km Discontinuity in the Lower Mantle with P′P′ PrecursorsSeismological Research Letters.\n20, Ping Ping, Risheng Chu, Yu Zhang, et al., (2020), Enhancing Signal-to-Noise Ratios of High-Frequency Rayleigh Waves Extracted from Ambient Seismic Noises in Topographic Region, Bulletin of the Seismological Society of America.\n19, Xie Jun, Sidao Ni, Chu Risheng, (2020), Relocation of the June 17th, 2017 Nuugaatsiaq (Greenland) landside based on Green’s functions from ambient seismic noise,Journal of Geophysical Research: Solid Earth, 125(5).\n18, Aizhi Guo, Sidao Ni, Jun Xie, et al. (2019), Millimerter-level ultra-long period multiple earth-circling surface waves retrieved from dense high-rate GPS network, Earth and Planetary Science Letters.\n17, Adebayo Ojo, Sidao Ni, Jun Xie, et al., (2019), Further constraints on the shear wave velocity structure of Cameroon from joint inversion of receiver function, Rayleigh wave dispersion and ellipticity measurements, Geophysical Journal International 217(1):589-619\n16, Xie Jun, Sidao Ni, (2019), Imaging 3D upper-mantle structure with autocorrelation of seismic noise recorded on a transportable single station, Seismological Research Letters.\n15, Xie Jun, Risheng Chu, Yingjie Yang, (2018), 3D upper-mantle shear velocity model beneath the contiguous United States based on broadband surface wave from ambient seismic noise, Pure and Applied Geophysics.\n14, Xie Jun, Sidao Ni, Risheng Chu, et al., (2017), Assessing the short-term clock drift of early broadband stations with burst events of the 26 s persistent and localized microseism, Geophysical Journal International.\n13, Li Guoliang, Fenglin Niu, Yingjie Yang, et al., (2017), An investigation of time-frequency domain phase-weighted stacking and its application to phase-velocity extraction from ambient noise’s empirical Green’s functions, Geophys J Int, 212,1143-1156. doi: 10.1093/gji/ggx448.\n12, Zhao Kaifeng, Yinhe Luo, Jun Xie (2017), Broad-band Rayleigh wave phase velocity maps (10-150 s) across the United States from ambient noise data. Geophys J Int 208, 1265-275. doi:10.1093/gji/ggw460.\n11, Xie Jun, Yinjie Yang, Sidao Ni, (2016), On the accuracy of long-period Rayleigh waves extracted from ambient noise. Geophys J Int 206, 48-5.\n10, Li Guoliang, Haichao Chen, Fenglin Niu, et al., (2016), Measurement of Rayleigh wave ellipticity and its application to the joint inversion of high-resolution S-wave velocity structure beneath northeast China, J. Geophys. Res. Solid EarthVolume 121, Number 2, doi:10.1002/2015JB012459.\n9, Zeng, Xiangfang, Jun Xie, Sidao Ni, (2015), Ground Truth Location of Earthquakes by Use of Ambient Seismic Noise From a Sparse Seismic Network: A Case Study in Western Australia, Pure Appl. Geophys., 172: 1397. doi:10.1007/s00024-014-0993-6\n8, Xia, Yingjie, Sidao Ni, Xiangfang Zeng, et al., (2015), Synchronizing Intercontinental Seismic Networks Using the 26 s Persistent Localized Microseismic Source, Bull. Seismol. Soc. Am., vol. 105 no. 4 2101-2108.\n7, Bao Feng, Sidao Ni, Jun Xie, et al., (2014), Validating Accuracy of Rayleigh Wave Dispersion Extracted from Ambient Seismic Noise Via Comparison with Data from a Ground-Truth Earthquake, Bull. Seismol. Soc. Am., vol. 104 no. 4 2133-2141.\n6, Bao Feng, Sidao Ni, J. Zheng, et al., (2013), Accurate earthquake location with instrumental clock error: A case study for the 19 January 2011 Anqing earthquake sequence, Acta Seismologica Sinica (in Chinese) , 35 (2) :160-172\n5, Lü Yan, Sidao Ni, Jun Xie, et al., (2013), Crustal S-wave velocity structureof the Yellowstone region using a seismic ambient noise method, Earthq Sci, 26: 283. doi:10.1007/s11589-013-0016-1\n4, Xie Jun, Sidao Ni, Xiangfang Zeng, (2012), 1D shear wave velocity structure of the shallow upper crust in central Sichuan Basin, Earthq. Res. Sichuan (in Chinese), (2) :20-24.\n3, Chen Weiwen, Sidao Ni, S. Wei, et al., (2011), Effects of sedimentary layer on earthquake source modelling from geodetic inversion, Earthq Sci, Volume 24, Issue 2, pp.221-227.\n2, Xie Jun, Xiangfang Zeng, Weiwen Chen et al., (2011), Comparison of ground truth location of earthquake from InSAR and from ambient seismic noise: A case study of the 1998 Zhangbei earthquake, Earthq Sci, Volume 24, Issue 2, pp.239-247.\n1, Luo Yan, Sidao Ni, Xangfang Zeng. et al., (2011), The M5.0 Suining-Tongnan (China) earthquake of 31 January 2010: A destructive earthquake occurring in sedimentary cover, Chin. Sci. Bull., 56: 521. doi:10.1007/s11434-010-4276-2.\n","source":"about/index.md","raw":"---\ntitle: 关于我\ndate: 2020-05-28 14:03:54\ntype: \"about\"\ncomments: false\n---\n## 我干啥的\n搞地球物理学的战五宅。\n\n## 研究方向\n地震学，速度结构，背景噪声，地震定位等。\n\n## 这是哪里\n这里是我用来记笔记的地方。\n\n## 我的能力\n会点地球物理，会点分析数据，会写点小文章，会点Linux。\n\n## 其他链接\n[Google scholar](https://scholar.google.com/citations?user=HlONCtkAAAAJ&hl=en)，[ResearchGate](https://www.researchgate.net/profile/Jun_Xie6)\n\n## 文章列表\n38, 危自根, 储日升, 谢军等, (2024), 当阳复向斜页岩气探测区地壳结构及其构造暗示, 地球物理学报, 67(8).\n37, Jun Xie, Xiangfang Zeng, Chao Liang, et al., (2024), Ice plate deformation and cracking revealed by an in situ-distributed acoustic sensing array, The Cryosphere, 18(2): 837-847. \n36, AG Osotuyi, Sidao Ni, Jiajun Chong, et al., (2023), Seismometer orientation correction via teleseismic receiver function measurements in West Africa and adjacent Islands, Seismological Society of America, 94(3): 1509-1525.\n35, Jin Ruizhi, Xiaohui He, Hongjian Fang, et al., (2023), Topography effect on ambient noise tomography: a case study for the Longmen Shan area, eastern Tibetan Plateau, Geophysical Journal International, 233(1): 1-12.\n34, 胡锦涛, 谢军, 危自根等, (2023), 三峡库区秭归段浅层速度结构和孕震环境, 地震学报, 45(2): 223-233.\n33, 张丽娜, 谢军, 迟本鑫等 (2023), 分布式光纤地震传感技术在成像研究中的应用进展, 地球与行星物理论评, 54(2): 140-149.\n32, 林融冰, 包丰, 谢军等 (2022), 光缆布设方式对犇犃犛主, 被动源记录的影响, 地球物理学报，65(10).\n31, Wei Zigen, Risheng Chu, Jun Xie, et al. (2022), Crustal structure in the Weiyuan shale gas field, China, and its tectonic implications, Tectonophysics, 837: 229449.\n30, 王烁帆, 倪四道, 王伟涛等 (2022), 基于背景噪声经验格林函数的地震准确定位精度分析, 地球物理学报, 65(8).\n29, 操玉文, 曾祥方, 李正斌等(2022), 云南漾濞Ms6.4地震信号的旋转和平动分量面波记录分析研究, 地球物理学报, 65(2).\n28, Chen Yongyan, Jun Xie, Sidao Ni, (2022), Generation mechanism of the 26 s and 28 s tremors in the Gulf of Guinea from statistical analysis of magnitudes and event intervals, Earth and Planetary Science Letters 578, 117334.\n27, Lv Hao, Xiangfang Zeng, Feng Bao et al., (2022), ADE-Net: A deep neural network for DAS earthquake detection trained with a limited number of positive samples, IEEE Transactions on Geoscience and Remote Sensing 60, 1-11.\n26, Song Zhenhong, Xiangfang Zeng, Jun Xie, et al., (2021), Sensing shallow structure and traffic noise with fiber-optic internet cables in an urban area, Surveys in Geophysics 42: 1401-1423.\n25, Xia Xin, Zhiwei Li, Feng Bao, et al., (2021), Sedimentary structure of the Sichuan Basin derived from seismic ambient noise tomography, Geophysical Journal International, 225(1): 54-67.\n24, Xie Jun, Risheng Chu, Sidao Ni, (2021), Evaluating global tomography models with antipodal ambient noise cross correlation functions, Journal of Geophysical Research: Solid Earth, 126(3): e2020JB020444.\n23, Chen Haopeng, Zhiwei Li, Zhicai Luo, et al., (2021), Crust and upper mantle structure of the South China Sea and adjacent areas from the joint inversion of ambient noise and earthquake surface wave dispersions, Geochemistry, Geophysics, Geosystems, e2020GC009356.\n22, Lin Xin, Jinlai Hao, Dun Wang, et al., (2021), Coseismic Slip Distribution of the 24 January 2020 Mw 6.7 Doganyol Earthquake and in Relation to the Foreshock and Aftershock Activities, Seismological Society of America, 92(1): 127-139.\n21, Baolong Zhang, Xiangfang Zeng, Jun Xie, et al., (2020), Validity of Resolving the 785 km Discontinuity in the Lower Mantle with P′P′ PrecursorsSeismological Research Letters.\n20, Ping Ping, Risheng Chu, Yu Zhang, et al., (2020), Enhancing Signal-to-Noise Ratios of High-Frequency Rayleigh Waves Extracted from Ambient Seismic Noises in Topographic Region, Bulletin of the Seismological Society of America.\n19, Xie Jun, Sidao Ni, Chu Risheng, (2020), Relocation of the June 17th, 2017 Nuugaatsiaq (Greenland) landside based on Green’s functions from ambient seismic noise,Journal of Geophysical Research: Solid Earth, 125(5).\n18, Aizhi Guo, Sidao Ni, Jun Xie, et al. (2019), Millimerter-level ultra-long period multiple earth-circling surface waves retrieved from dense high-rate GPS network, Earth and Planetary Science Letters.\n17, Adebayo Ojo, Sidao Ni, Jun Xie, et al., (2019), Further constraints on the shear wave velocity structure of Cameroon from joint inversion of receiver function, Rayleigh wave dispersion and ellipticity measurements, Geophysical Journal International 217(1):589-619\n16, Xie Jun, Sidao Ni, (2019), Imaging 3D upper-mantle structure with autocorrelation of seismic noise recorded on a transportable single station, Seismological Research Letters.\n15, Xie Jun, Risheng Chu, Yingjie Yang, (2018), 3D upper-mantle shear velocity model beneath the contiguous United States based on broadband surface wave from ambient seismic noise, Pure and Applied Geophysics.\n14, Xie Jun, Sidao Ni, Risheng Chu, et al., (2017), Assessing the short-term clock drift of early broadband stations with burst events of the 26 s persistent and localized microseism, Geophysical Journal International.\n13, Li Guoliang, Fenglin Niu, Yingjie Yang, et al., (2017), An investigation of time-frequency domain phase-weighted stacking and its application to phase-velocity extraction from ambient noise’s empirical Green’s functions, Geophys J Int, 212,1143-1156. doi: 10.1093/gji/ggx448.\n12, Zhao Kaifeng, Yinhe Luo, Jun Xie (2017), Broad-band Rayleigh wave phase velocity maps (10-150 s) across the United States from ambient noise data. Geophys J Int 208, 1265-275. doi:10.1093/gji/ggw460.\n11, Xie Jun, Yinjie Yang, Sidao Ni, (2016), On the accuracy of long-period Rayleigh waves extracted from ambient noise. Geophys J Int 206, 48-5.\n10, Li Guoliang, Haichao Chen, Fenglin Niu, et al., (2016), Measurement of Rayleigh wave ellipticity and its application to the joint inversion of high-resolution S-wave velocity structure beneath northeast China, J. Geophys. Res. Solid EarthVolume 121, Number 2, doi:10.1002/2015JB012459.\n9, Zeng, Xiangfang, Jun Xie, Sidao Ni, (2015), Ground Truth Location of Earthquakes by Use of Ambient Seismic Noise From a Sparse Seismic Network: A Case Study in Western Australia, Pure Appl. Geophys., 172: 1397. doi:10.1007/s00024-014-0993-6\n8, Xia, Yingjie, Sidao Ni, Xiangfang Zeng, et al., (2015), Synchronizing Intercontinental Seismic Networks Using the 26 s Persistent Localized Microseismic Source, Bull. Seismol. Soc. Am., vol. 105 no. 4 2101-2108.\n7, Bao Feng, Sidao Ni, Jun Xie, et al., (2014), Validating Accuracy of Rayleigh Wave Dispersion Extracted from Ambient Seismic Noise Via Comparison with Data from a Ground-Truth Earthquake, Bull. Seismol. Soc. Am., vol. 104 no. 4 2133-2141.\n6, Bao Feng, Sidao Ni, J. Zheng, et al., (2013), Accurate earthquake location with instrumental clock error: A case study for the 19 January 2011 Anqing earthquake sequence, Acta Seismologica Sinica (in Chinese) , 35 (2) :160-172\n5, Lü Yan, Sidao Ni, Jun Xie, et al., (2013), Crustal S-wave velocity structureof the Yellowstone region using a seismic ambient noise method, Earthq Sci, 26: 283. doi:10.1007/s11589-013-0016-1\n4, Xie Jun, Sidao Ni, Xiangfang Zeng, (2012), 1D shear wave velocity structure of the shallow upper crust in central Sichuan Basin, Earthq. Res. Sichuan (in Chinese), (2) :20-24.\n3, Chen Weiwen, Sidao Ni, S. Wei, et al., (2011), Effects of sedimentary layer on earthquake source modelling from geodetic inversion, Earthq Sci, Volume 24, Issue 2, pp.221-227.\n2, Xie Jun, Xiangfang Zeng, Weiwen Chen et al., (2011), Comparison of ground truth location of earthquake from InSAR and from ambient seismic noise: A case study of the 1998 Zhangbei earthquake, Earthq Sci, Volume 24, Issue 2, pp.239-247.\n1, Luo Yan, Sidao Ni, Xangfang Zeng. et al., (2011), The M5.0 Suining-Tongnan (China) earthquake of 31 January 2010: A destructive earthquake occurring in sedimentary cover, Chin. Sci. Bull., 56: 521. doi:10.1007/s11434-010-4276-2.\n","updated":"2024-09-12T04:08:58.549Z","path":"about/index.html","layout":"page","_id":"cmh498io90002wvoufo74cjd6","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><h2 id=\"我干啥的\"><a href=\"#我干啥的\" class=\"headerlink\" title=\"我干啥的\"></a>我干啥的</h2><p>搞地球物理学的战五宅。</p>\n<h2 id=\"研究方向\"><a href=\"#研究方向\" class=\"headerlink\" title=\"研究方向\"></a>研究方向</h2><p>地震学，速度结构，背景噪声，地震定位等。</p>\n<h2 id=\"这是哪里\"><a href=\"#这是哪里\" class=\"headerlink\" title=\"这是哪里\"></a>这是哪里</h2><p>这里是我用来记笔记的地方。</p>\n<h2 id=\"我的能力\"><a href=\"#我的能力\" class=\"headerlink\" title=\"我的能力\"></a>我的能力</h2><p>会点地球物理，会点分析数据，会写点小文章，会点Linux。</p>\n<h2 id=\"其他链接\"><a href=\"#其他链接\" class=\"headerlink\" title=\"其他链接\"></a>其他链接</h2><p><a href=\"https://scholar.google.com/citations?user=HlONCtkAAAAJ&hl=en\">Google scholar</a>，<a href=\"https://www.researchgate.net/profile/Jun_Xie6\">ResearchGate</a></p>\n<h2 id=\"文章列表\"><a href=\"#文章列表\" class=\"headerlink\" title=\"文章列表\"></a>文章列表</h2><p>38, 危自根, 储日升, 谢军等, (2024), 当阳复向斜页岩气探测区地壳结构及其构造暗示, 地球物理学报, 67(8).<br>37, Jun Xie, Xiangfang Zeng, Chao Liang, et al., (2024), Ice plate deformation and cracking revealed by an in situ-distributed acoustic sensing array, The Cryosphere, 18(2): 837-847.<br>36, AG Osotuyi, Sidao Ni, Jiajun Chong, et al., (2023), Seismometer orientation correction via teleseismic receiver function measurements in West Africa and adjacent Islands, Seismological Society of America, 94(3): 1509-1525.<br>35, Jin Ruizhi, Xiaohui He, Hongjian Fang, et al., (2023), Topography effect on ambient noise tomography: a case study for the Longmen Shan area, eastern Tibetan Plateau, Geophysical Journal International, 233(1): 1-12.<br>34, 胡锦涛, 谢军, 危自根等, (2023), 三峡库区秭归段浅层速度结构和孕震环境, 地震学报, 45(2): 223-233.<br>33, 张丽娜, 谢军, 迟本鑫等 (2023), 分布式光纤地震传感技术在成像研究中的应用进展, 地球与行星物理论评, 54(2): 140-149.<br>32, 林融冰, 包丰, 谢军等 (2022), 光缆布设方式对犇犃犛主, 被动源记录的影响, 地球物理学报，65(10).<br>31, Wei Zigen, Risheng Chu, Jun Xie, et al. (2022), Crustal structure in the Weiyuan shale gas field, China, and its tectonic implications, Tectonophysics, 837: 229449.<br>30, 王烁帆, 倪四道, 王伟涛等 (2022), 基于背景噪声经验格林函数的地震准确定位精度分析, 地球物理学报, 65(8).<br>29, 操玉文, 曾祥方, 李正斌等(2022), 云南漾濞Ms6.4地震信号的旋转和平动分量面波记录分析研究, 地球物理学报, 65(2).<br>28, Chen Yongyan, Jun Xie, Sidao Ni, (2022), Generation mechanism of the 26 s and 28 s tremors in the Gulf of Guinea from statistical analysis of magnitudes and event intervals, Earth and Planetary Science Letters 578, 117334.<br>27, Lv Hao, Xiangfang Zeng, Feng Bao et al., (2022), ADE-Net: A deep neural network for DAS earthquake detection trained with a limited number of positive samples, IEEE Transactions on Geoscience and Remote Sensing 60, 1-11.<br>26, Song Zhenhong, Xiangfang Zeng, Jun Xie, et al., (2021), Sensing shallow structure and traffic noise with fiber-optic internet cables in an urban area, Surveys in Geophysics 42: 1401-1423.<br>25, Xia Xin, Zhiwei Li, Feng Bao, et al., (2021), Sedimentary structure of the Sichuan Basin derived from seismic ambient noise tomography, Geophysical Journal International, 225(1): 54-67.<br>24, Xie Jun, Risheng Chu, Sidao Ni, (2021), Evaluating global tomography models with antipodal ambient noise cross correlation functions, Journal of Geophysical Research: Solid Earth, 126(3): e2020JB020444.<br>23, Chen Haopeng, Zhiwei Li, Zhicai Luo, et al., (2021), Crust and upper mantle structure of the South China Sea and adjacent areas from the joint inversion of ambient noise and earthquake surface wave dispersions, Geochemistry, Geophysics, Geosystems, e2020GC009356.<br>22, Lin Xin, Jinlai Hao, Dun Wang, et al., (2021), Coseismic Slip Distribution of the 24 January 2020 Mw 6.7 Doganyol Earthquake and in Relation to the Foreshock and Aftershock Activities, Seismological Society of America, 92(1): 127-139.<br>21, Baolong Zhang, Xiangfang Zeng, Jun Xie, et al., (2020), Validity of Resolving the 785 km Discontinuity in the Lower Mantle with P′P′ PrecursorsSeismological Research Letters.<br>20, Ping Ping, Risheng Chu, Yu Zhang, et al., (2020), Enhancing Signal-to-Noise Ratios of High-Frequency Rayleigh Waves Extracted from Ambient Seismic Noises in Topographic Region, Bulletin of the Seismological Society of America.<br>19, Xie Jun, Sidao Ni, Chu Risheng, (2020), Relocation of the June 17th, 2017 Nuugaatsiaq (Greenland) landside based on Green’s functions from ambient seismic noise,Journal of Geophysical Research: Solid Earth, 125(5).<br>18, Aizhi Guo, Sidao Ni, Jun Xie, et al. (2019), Millimerter-level ultra-long period multiple earth-circling surface waves retrieved from dense high-rate GPS network, Earth and Planetary Science Letters.<br>17, Adebayo Ojo, Sidao Ni, Jun Xie, et al., (2019), Further constraints on the shear wave velocity structure of Cameroon from joint inversion of receiver function, Rayleigh wave dispersion and ellipticity measurements, Geophysical Journal International 217(1):589-619<br>16, Xie Jun, Sidao Ni, (2019), Imaging 3D upper-mantle structure with autocorrelation of seismic noise recorded on a transportable single station, Seismological Research Letters.<br>15, Xie Jun, Risheng Chu, Yingjie Yang, (2018), 3D upper-mantle shear velocity model beneath the contiguous United States based on broadband surface wave from ambient seismic noise, Pure and Applied Geophysics.<br>14, Xie Jun, Sidao Ni, Risheng Chu, et al., (2017), Assessing the short-term clock drift of early broadband stations with burst events of the 26 s persistent and localized microseism, Geophysical Journal International.<br>13, Li Guoliang, Fenglin Niu, Yingjie Yang, et al., (2017), An investigation of time-frequency domain phase-weighted stacking and its application to phase-velocity extraction from ambient noise’s empirical Green’s functions, Geophys J Int, 212,1143-1156. doi: 10.1093&#x2F;gji&#x2F;ggx448.<br>12, Zhao Kaifeng, Yinhe Luo, Jun Xie (2017), Broad-band Rayleigh wave phase velocity maps (10-150 s) across the United States from ambient noise data. Geophys J Int 208, 1265-275. doi:10.1093&#x2F;gji&#x2F;ggw460.<br>11, Xie Jun, Yinjie Yang, Sidao Ni, (2016), On the accuracy of long-period Rayleigh waves extracted from ambient noise. Geophys J Int 206, 48-5.<br>10, Li Guoliang, Haichao Chen, Fenglin Niu, et al., (2016), Measurement of Rayleigh wave ellipticity and its application to the joint inversion of high-resolution S-wave velocity structure beneath northeast China, J. Geophys. Res. Solid EarthVolume 121, Number 2, doi:10.1002&#x2F;2015JB012459.<br>9, Zeng, Xiangfang, Jun Xie, Sidao Ni, (2015), Ground Truth Location of Earthquakes by Use of Ambient Seismic Noise From a Sparse Seismic Network: A Case Study in Western Australia, Pure Appl. Geophys., 172: 1397. doi:10.1007&#x2F;s00024-014-0993-6<br>8, Xia, Yingjie, Sidao Ni, Xiangfang Zeng, et al., (2015), Synchronizing Intercontinental Seismic Networks Using the 26 s Persistent Localized Microseismic Source, Bull. Seismol. Soc. Am., vol. 105 no. 4 2101-2108.<br>7, Bao Feng, Sidao Ni, Jun Xie, et al., (2014), Validating Accuracy of Rayleigh Wave Dispersion Extracted from Ambient Seismic Noise Via Comparison with Data from a Ground-Truth Earthquake, Bull. Seismol. Soc. Am., vol. 104 no. 4 2133-2141.<br>6, Bao Feng, Sidao Ni, J. Zheng, et al., (2013), Accurate earthquake location with instrumental clock error: A case study for the 19 January 2011 Anqing earthquake sequence, Acta Seismologica Sinica (in Chinese) , 35 (2) :160-172<br>5, Lü Yan, Sidao Ni, Jun Xie, et al., (2013), Crustal S-wave velocity structureof the Yellowstone region using a seismic ambient noise method, Earthq Sci, 26: 283. doi:10.1007&#x2F;s11589-013-0016-1<br>4, Xie Jun, Sidao Ni, Xiangfang Zeng, (2012), 1D shear wave velocity structure of the shallow upper crust in central Sichuan Basin, Earthq. Res. Sichuan (in Chinese), (2) :20-24.<br>3, Chen Weiwen, Sidao Ni, S. Wei, et al., (2011), Effects of sedimentary layer on earthquake source modelling from geodetic inversion, Earthq Sci, Volume 24, Issue 2, pp.221-227.<br>2, Xie Jun, Xiangfang Zeng, Weiwen Chen et al., (2011), Comparison of ground truth location of earthquake from InSAR and from ambient seismic noise: A case study of the 1998 Zhangbei earthquake, Earthq Sci, Volume 24, Issue 2, pp.239-247.<br>1, Luo Yan, Sidao Ni, Xangfang Zeng. et al., (2011), The M5.0 Suining-Tongnan (China) earthquake of 31 January 2010: A destructive earthquake occurring in sedimentary cover, Chin. Sci. Bull., 56: 521. doi:10.1007&#x2F;s11434-010-4276-2.</p>\n","related_posts":[],"length":6441,"excerpt":"","more":"<h2 id=\"我干啥的\"><a href=\"#我干啥的\" class=\"headerlink\" title=\"我干啥的\"></a>我干啥的</h2><p>搞地球物理学的战五宅。</p>\n<h2 id=\"研究方向\"><a href=\"#研究方向\" class=\"headerlink\" title=\"研究方向\"></a>研究方向</h2><p>地震学，速度结构，背景噪声，地震定位等。</p>\n<h2 id=\"这是哪里\"><a href=\"#这是哪里\" class=\"headerlink\" title=\"这是哪里\"></a>这是哪里</h2><p>这里是我用来记笔记的地方。</p>\n<h2 id=\"我的能力\"><a href=\"#我的能力\" class=\"headerlink\" title=\"我的能力\"></a>我的能力</h2><p>会点地球物理，会点分析数据，会写点小文章，会点Linux。</p>\n<h2 id=\"其他链接\"><a href=\"#其他链接\" class=\"headerlink\" title=\"其他链接\"></a>其他链接</h2><p><a href=\"https://scholar.google.com/citations?user=HlONCtkAAAAJ&hl=en\">Google scholar</a>，<a href=\"https://www.researchgate.net/profile/Jun_Xie6\">ResearchGate</a></p>\n<h2 id=\"文章列表\"><a href=\"#文章列表\" class=\"headerlink\" title=\"文章列表\"></a>文章列表</h2><p>38, 危自根, 储日升, 谢军等, (2024), 当阳复向斜页岩气探测区地壳结构及其构造暗示, 地球物理学报, 67(8).<br>37, Jun Xie, Xiangfang Zeng, Chao Liang, et al., (2024), Ice plate deformation and cracking revealed by an in situ-distributed acoustic sensing array, The Cryosphere, 18(2): 837-847.<br>36, AG Osotuyi, Sidao Ni, Jiajun Chong, et al., (2023), Seismometer orientation correction via teleseismic receiver function measurements in West Africa and adjacent Islands, Seismological Society of America, 94(3): 1509-1525.<br>35, Jin Ruizhi, Xiaohui He, Hongjian Fang, et al., (2023), Topography effect on ambient noise tomography: a case study for the Longmen Shan area, eastern Tibetan Plateau, Geophysical Journal International, 233(1): 1-12.<br>34, 胡锦涛, 谢军, 危自根等, (2023), 三峡库区秭归段浅层速度结构和孕震环境, 地震学报, 45(2): 223-233.<br>33, 张丽娜, 谢军, 迟本鑫等 (2023), 分布式光纤地震传感技术在成像研究中的应用进展, 地球与行星物理论评, 54(2): 140-149.<br>32, 林融冰, 包丰, 谢军等 (2022), 光缆布设方式对犇犃犛主, 被动源记录的影响, 地球物理学报，65(10).<br>31, Wei Zigen, Risheng Chu, Jun Xie, et al. (2022), Crustal structure in the Weiyuan shale gas field, China, and its tectonic implications, Tectonophysics, 837: 229449.<br>30, 王烁帆, 倪四道, 王伟涛等 (2022), 基于背景噪声经验格林函数的地震准确定位精度分析, 地球物理学报, 65(8).<br>29, 操玉文, 曾祥方, 李正斌等(2022), 云南漾濞Ms6.4地震信号的旋转和平动分量面波记录分析研究, 地球物理学报, 65(2).<br>28, Chen Yongyan, Jun Xie, Sidao Ni, (2022), Generation mechanism of the 26 s and 28 s tremors in the Gulf of Guinea from statistical analysis of magnitudes and event intervals, Earth and Planetary Science Letters 578, 117334.<br>27, Lv Hao, Xiangfang Zeng, Feng Bao et al., (2022), ADE-Net: A deep neural network for DAS earthquake detection trained with a limited number of positive samples, IEEE Transactions on Geoscience and Remote Sensing 60, 1-11.<br>26, Song Zhenhong, Xiangfang Zeng, Jun Xie, et al., (2021), Sensing shallow structure and traffic noise with fiber-optic internet cables in an urban area, Surveys in Geophysics 42: 1401-1423.<br>25, Xia Xin, Zhiwei Li, Feng Bao, et al., (2021), Sedimentary structure of the Sichuan Basin derived from seismic ambient noise tomography, Geophysical Journal International, 225(1): 54-67.<br>24, Xie Jun, Risheng Chu, Sidao Ni, (2021), Evaluating global tomography models with antipodal ambient noise cross correlation functions, Journal of Geophysical Research: Solid Earth, 126(3): e2020JB020444.<br>23, Chen Haopeng, Zhiwei Li, Zhicai Luo, et al., (2021), Crust and upper mantle structure of the South China Sea and adjacent areas from the joint inversion of ambient noise and earthquake surface wave dispersions, Geochemistry, Geophysics, Geosystems, e2020GC009356.<br>22, Lin Xin, Jinlai Hao, Dun Wang, et al., (2021), Coseismic Slip Distribution of the 24 January 2020 Mw 6.7 Doganyol Earthquake and in Relation to the Foreshock and Aftershock Activities, Seismological Society of America, 92(1): 127-139.<br>21, Baolong Zhang, Xiangfang Zeng, Jun Xie, et al., (2020), Validity of Resolving the 785 km Discontinuity in the Lower Mantle with P′P′ PrecursorsSeismological Research Letters.<br>20, Ping Ping, Risheng Chu, Yu Zhang, et al., (2020), Enhancing Signal-to-Noise Ratios of High-Frequency Rayleigh Waves Extracted from Ambient Seismic Noises in Topographic Region, Bulletin of the Seismological Society of America.<br>19, Xie Jun, Sidao Ni, Chu Risheng, (2020), Relocation of the June 17th, 2017 Nuugaatsiaq (Greenland) landside based on Green’s functions from ambient seismic noise,Journal of Geophysical Research: Solid Earth, 125(5).<br>18, Aizhi Guo, Sidao Ni, Jun Xie, et al. (2019), Millimerter-level ultra-long period multiple earth-circling surface waves retrieved from dense high-rate GPS network, Earth and Planetary Science Letters.<br>17, Adebayo Ojo, Sidao Ni, Jun Xie, et al., (2019), Further constraints on the shear wave velocity structure of Cameroon from joint inversion of receiver function, Rayleigh wave dispersion and ellipticity measurements, Geophysical Journal International 217(1):589-619<br>16, Xie Jun, Sidao Ni, (2019), Imaging 3D upper-mantle structure with autocorrelation of seismic noise recorded on a transportable single station, Seismological Research Letters.<br>15, Xie Jun, Risheng Chu, Yingjie Yang, (2018), 3D upper-mantle shear velocity model beneath the contiguous United States based on broadband surface wave from ambient seismic noise, Pure and Applied Geophysics.<br>14, Xie Jun, Sidao Ni, Risheng Chu, et al., (2017), Assessing the short-term clock drift of early broadband stations with burst events of the 26 s persistent and localized microseism, Geophysical Journal International.<br>13, Li Guoliang, Fenglin Niu, Yingjie Yang, et al., (2017), An investigation of time-frequency domain phase-weighted stacking and its application to phase-velocity extraction from ambient noise’s empirical Green’s functions, Geophys J Int, 212,1143-1156. doi: 10.1093&#x2F;gji&#x2F;ggx448.<br>12, Zhao Kaifeng, Yinhe Luo, Jun Xie (2017), Broad-band Rayleigh wave phase velocity maps (10-150 s) across the United States from ambient noise data. Geophys J Int 208, 1265-275. doi:10.1093&#x2F;gji&#x2F;ggw460.<br>11, Xie Jun, Yinjie Yang, Sidao Ni, (2016), On the accuracy of long-period Rayleigh waves extracted from ambient noise. Geophys J Int 206, 48-5.<br>10, Li Guoliang, Haichao Chen, Fenglin Niu, et al., (2016), Measurement of Rayleigh wave ellipticity and its application to the joint inversion of high-resolution S-wave velocity structure beneath northeast China, J. Geophys. Res. Solid EarthVolume 121, Number 2, doi:10.1002&#x2F;2015JB012459.<br>9, Zeng, Xiangfang, Jun Xie, Sidao Ni, (2015), Ground Truth Location of Earthquakes by Use of Ambient Seismic Noise From a Sparse Seismic Network: A Case Study in Western Australia, Pure Appl. Geophys., 172: 1397. doi:10.1007&#x2F;s00024-014-0993-6<br>8, Xia, Yingjie, Sidao Ni, Xiangfang Zeng, et al., (2015), Synchronizing Intercontinental Seismic Networks Using the 26 s Persistent Localized Microseismic Source, Bull. Seismol. Soc. Am., vol. 105 no. 4 2101-2108.<br>7, Bao Feng, Sidao Ni, Jun Xie, et al., (2014), Validating Accuracy of Rayleigh Wave Dispersion Extracted from Ambient Seismic Noise Via Comparison with Data from a Ground-Truth Earthquake, Bull. Seismol. Soc. Am., vol. 104 no. 4 2133-2141.<br>6, Bao Feng, Sidao Ni, J. Zheng, et al., (2013), Accurate earthquake location with instrumental clock error: A case study for the 19 January 2011 Anqing earthquake sequence, Acta Seismologica Sinica (in Chinese) , 35 (2) :160-172<br>5, Lü Yan, Sidao Ni, Jun Xie, et al., (2013), Crustal S-wave velocity structureof the Yellowstone region using a seismic ambient noise method, Earthq Sci, 26: 283. doi:10.1007&#x2F;s11589-013-0016-1<br>4, Xie Jun, Sidao Ni, Xiangfang Zeng, (2012), 1D shear wave velocity structure of the shallow upper crust in central Sichuan Basin, Earthq. Res. Sichuan (in Chinese), (2) :20-24.<br>3, Chen Weiwen, Sidao Ni, S. Wei, et al., (2011), Effects of sedimentary layer on earthquake source modelling from geodetic inversion, Earthq Sci, Volume 24, Issue 2, pp.221-227.<br>2, Xie Jun, Xiangfang Zeng, Weiwen Chen et al., (2011), Comparison of ground truth location of earthquake from InSAR and from ambient seismic noise: A case study of the 1998 Zhangbei earthquake, Earthq Sci, Volume 24, Issue 2, pp.239-247.<br>1, Luo Yan, Sidao Ni, Xangfang Zeng. et al., (2011), The M5.0 Suining-Tongnan (China) earthquake of 31 January 2010: A destructive earthquake occurring in sedimentary cover, Chin. Sci. Bull., 56: 521. doi:10.1007&#x2F;s11434-010-4276-2.</p>\n"},{"title":"categories","date":"2020-05-27T17:22:16.000Z","type":"categories","comments":0,"_content":"","source":"categories/index.md","raw":"---\ntitle: categories\ndate: 2020-05-28 01:22:16\ntype: \"categories\"\ncomments: false\n---\n","updated":"2024-05-27T06:26:17.507Z","path":"categories/index.html","layout":"page","_id":"cmh498ioc0006wvoudk44747e","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script>","related_posts":[],"length":0,"excerpt":"","more":""},{"title":"tags","date":"2020-05-27T17:19:43.000Z","type":"tags","comments":0,"_content":"","source":"tags/index.md","raw":"---\ntitle: tags\ndate: 2020-05-28 01:19:43\ntype: \"tags\"\ncomments: false\n---\n","updated":"2024-05-27T06:26:07.286Z","path":"tags/index.html","layout":"page","_id":"cmh498iod0008wvoucc8x6w8x","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script>","related_posts":[],"length":0,"excerpt":"","more":""}],"Post":[{"title":"寂寞","abbrlink":64007,"date":"2006-06-11T07:47:32.000Z","_content":"\n&emsp;&emsp;一只小鼠死了,我很伤心.当听知他的死时,我差点落泪,但是泪水只在眼里转了一转,并没有流下来.我不懂我是怎么了?难到我的良心已在这浊世当中损失殆尽？还是我堕落了？\n\n","source":"_posts/2006-06-11-寂寞.md","raw":"---\ntitle: 寂寞\ncategories:\n  - 某日记\ntags:\n  - 这是啥\nabbrlink: 64007\ndate: 2006-06-11 15:47:32\n---\n\n&emsp;&emsp;一只小鼠死了,我很伤心.当听知他的死时,我差点落泪,但是泪水只在眼里转了一转,并没有流下来.我不懂我是怎么了?难到我的良心已在这浊世当中损失殆尽？还是我堕落了？\n\n","slug":"寂寞","published":1,"updated":"2024-05-26T14:17:36.844Z","comments":1,"layout":"post","photos":[],"_id":"cmh498io60001wvou0n657en9","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>&emsp;&emsp;一只小鼠死了,我很伤心.当听知他的死时,我差点落泪,但是泪水只在眼里转了一转,并没有流下来.我不懂我是怎么了?难到我的良心已在这浊世当中损失殆尽？还是我堕落了？</p>\n","related_posts":[],"length":92,"excerpt":"","more":"<p>&emsp;&emsp;一只小鼠死了,我很伤心.当听知他的死时,我差点落泪,但是泪水只在眼里转了一转,并没有流下来.我不懂我是怎么了?难到我的良心已在这浊世当中损失殆尽？还是我堕落了？</p>\n"},{"title":"阿甘","abbrlink":44237,"date":"2006-11-24T12:09:07.000Z","_content":"\n&emsp;&emsp;记得第一次看阿甘正传时，我流泪了！\n\n&emsp;&emsp;阿甘的妈妈临死前，对阿甘说的话我开始觉得奇怪，同学告诉我说：她是用她自己的语言来让她的儿子明白……\n\n&emsp;&emsp;阿甘的妻子死的时候，她问阿甘跑步都看到了什么？阿甘说看到了美丽的山谷，看到了平静的湖水，看到了天地相接……她说要是她也在就好了！阿甘说：You were!（你一直和我在一起）\n\n&emsp;&emsp;虽说我也和阿甘一样笨，但却没有他那样的运气！\n\n&emsp;&emsp;运气？\n\n&emsp;&emsp;哈！\n\n&emsp;&emsp;世上哪儿来的运气？\n\n&emsp;&emsp;究其原因，阿甘并不是靠运气，而是靠一颗执著的心！我不能把他的心移植到我的胸腔内。但是我拥有我自己的心！\n\n&emsp;&emsp;相信执著的我也会像阿甘一样在人生的路上走得更远！\n\n&emsp;&emsp;加油啊！\n\n","source":"_posts/2006-11-24-阿甘.md","raw":"---\ntitle: 阿甘\ncategories:\n  - 某日记\ntags:\n  - 阿甘\nabbrlink: 44237\ndate: 2006-11-24 20:09:07\n---\n\n&emsp;&emsp;记得第一次看阿甘正传时，我流泪了！\n\n&emsp;&emsp;阿甘的妈妈临死前，对阿甘说的话我开始觉得奇怪，同学告诉我说：她是用她自己的语言来让她的儿子明白……\n\n&emsp;&emsp;阿甘的妻子死的时候，她问阿甘跑步都看到了什么？阿甘说看到了美丽的山谷，看到了平静的湖水，看到了天地相接……她说要是她也在就好了！阿甘说：You were!（你一直和我在一起）\n\n&emsp;&emsp;虽说我也和阿甘一样笨，但却没有他那样的运气！\n\n&emsp;&emsp;运气？\n\n&emsp;&emsp;哈！\n\n&emsp;&emsp;世上哪儿来的运气？\n\n&emsp;&emsp;究其原因，阿甘并不是靠运气，而是靠一颗执著的心！我不能把他的心移植到我的胸腔内。但是我拥有我自己的心！\n\n&emsp;&emsp;相信执著的我也会像阿甘一样在人生的路上走得更远！\n\n&emsp;&emsp;加油啊！\n\n","slug":"阿甘","published":1,"updated":"2024-05-26T14:17:36.844Z","comments":1,"layout":"post","photos":[],"_id":"cmh498io90003wvou3k2u7eug","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>&emsp;&emsp;记得第一次看阿甘正传时，我流泪了！</p>\n<p>&emsp;&emsp;阿甘的妈妈临死前，对阿甘说的话我开始觉得奇怪，同学告诉我说：她是用她自己的语言来让她的儿子明白……</p>\n<p>&emsp;&emsp;阿甘的妻子死的时候，她问阿甘跑步都看到了什么？阿甘说看到了美丽的山谷，看到了平静的湖水，看到了天地相接……她说要是她也在就好了！阿甘说：You were!（你一直和我在一起）</p>\n<p>&emsp;&emsp;虽说我也和阿甘一样笨，但却没有他那样的运气！</p>\n<p>&emsp;&emsp;运气？</p>\n<p>&emsp;&emsp;哈！</p>\n<p>&emsp;&emsp;世上哪儿来的运气？</p>\n<p>&emsp;&emsp;究其原因，阿甘并不是靠运气，而是靠一颗执著的心！我不能把他的心移植到我的胸腔内。但是我拥有我自己的心！</p>\n<p>&emsp;&emsp;相信执著的我也会像阿甘一样在人生的路上走得更远！</p>\n<p>&emsp;&emsp;加油啊！</p>\n","related_posts":[],"length":387,"excerpt":"","more":"<p>&emsp;&emsp;记得第一次看阿甘正传时，我流泪了！</p>\n<p>&emsp;&emsp;阿甘的妈妈临死前，对阿甘说的话我开始觉得奇怪，同学告诉我说：她是用她自己的语言来让她的儿子明白……</p>\n<p>&emsp;&emsp;阿甘的妻子死的时候，她问阿甘跑步都看到了什么？阿甘说看到了美丽的山谷，看到了平静的湖水，看到了天地相接……她说要是她也在就好了！阿甘说：You were!（你一直和我在一起）</p>\n<p>&emsp;&emsp;虽说我也和阿甘一样笨，但却没有他那样的运气！</p>\n<p>&emsp;&emsp;运气？</p>\n<p>&emsp;&emsp;哈！</p>\n<p>&emsp;&emsp;世上哪儿来的运气？</p>\n<p>&emsp;&emsp;究其原因，阿甘并不是靠运气，而是靠一颗执著的心！我不能把他的心移植到我的胸腔内。但是我拥有我自己的心！</p>\n<p>&emsp;&emsp;相信执著的我也会像阿甘一样在人生的路上走得更远！</p>\n<p>&emsp;&emsp;加油啊！</p>\n"},{"title":"好快刀","abbrlink":17668,"date":"2007-04-14T03:22:53.000Z","_content":"\n&emsp;&emsp;在我还没有来得及目送最后一屡夕晖之前，夜已悄悄的笼罩下来。从地底下蒸出的水汽弥散开来，烟雾弥漫的街道像是通往地府的黄泉路。路上行人不多，偶尔路过一个，像是久死的干尸，摇摇晃晃地往地府赶去。只有几只青蛙的叫声证明这还是人间。 \n\n&emsp;&emsp;我坐在铺子中间，张开双腿，裤管挽得老高。胸口敞开，露出清晰可数的肋骨。一手抚着脖子上的粗汗，一手拼命的舞着扇子，来不及诅咒这可恶的天气。 \n\n&emsp;&emsp;妻子在后屋准备晚饭。我的任务就是守着案板前挂着的几片剩肉，希望那个好心人尽快把它买走，然后好好泡个澡。几只苍蝇来回飞舞，目标就是那几片快干掉的肉，但它们却迟迟不肯动手。我也没有心思去赶它们，况且它们也该心烦了，我想。案板上横卧着一把大菜刀，上面蒙了一层油。整个肉店就数它最显眼，最安静，似乎有什么大任务正等着它做。 \n\n&emsp;&emsp;“相公，救命啊……放……开我……”突然，妻子的尖叫声夹杂着一个男人的声音从后院传来把一切喧哗都暂停了，我的心也停止了跳动。一股寒意从头窜遍全身，扇子无声的落下。几秒钟的失魂之后，我跳出了椅子，冲到案前抓起菜刀，奔后院而来。我的脚步很沉，脑子里什么都没有，又什么可怕的情形都有，手中的刀握得格外的紧，像沉重的放不下的担子。 \n\n&emsp;&emsp;一个秃头胖大男人正压在拼命挣扎的妻子身上。一股自骨髓的愤怒喷涌而出：“住手…………”屋子和院子颤抖着，那是一只凶猛的野兽发出的吼声。时间暂停了，一股冷汗浸透了我的背。 \n\n&emsp;&emsp;胖大男人似乎吃了一惊，停止了手中的工作，抬头来看看到底是谁在冲自己咆哮。衣衫不整的妻子趁这个机会挣脱开来，哭丧着躲在我的身后。我定眼一看，不是别人，正是徐三霸那无恶不作的恶棍。人人都受他欺压，又怕他，没有人敢跟他斗，因为与他作对的人都没有好下场。我早想惩治他，只恐于力量不足。 \n\n&emsp;&emsp;他缓慢的站起来，整了整衣角。两只虎眼死盯着坏他好事的我。我心一惊：平时见他只觉他很壮硕，今天近些看，只怕再多几个我也敌他不过。 \n\n&emsp;&emsp;他慢慢向我走过来。“你要干什么？”我举起手中的刀，颤抖着。我的衣服湿透了，豆大的汗珠往外直冒。“想和你老婆玩儿玩儿。”他的嘴角露出奸淫的笑。说完，便立在了我面前，犹如一只猎食的巨兽。突然，他一手擒住我拿刀的手，只一扔，我和刀一起飞到了花坛边，重重的砸在了地上。我没有听到有没有骨碎的的声音，只听到受惊的妻子发出的尖叫声。我的头有些眩晕。我看到那只野兽又扑向了妻子。我四周摸了摸，摸到了菜刀，抓了起来，冲向那只野兽。谁知他早有防备，背着我只一脚，正中我的肚子，菜刀和我又飞了出去。肚子上一阵剧痛。手脚都没有了力气，丝毫不能动弹。我几乎晕过去了。隐隐约约，我看到了妻子的令人心生怜爱的面容，听到了妻子欢乐的笑声。几年来妻子总是无怨无悔的跟着我这个毫无成就的屠夫，不管我做什么妻子总是积极支持。在我失落时，她会与我分担烦恼给我万分的安慰，在我穷困时，她总是想尽办法来帮助我。妻子对我太好了，给我的太多了，而我却不懂得珍惜，从来没有给过妻子什么，也没有好好的代过她。而如今…… \n\n&emsp;&emsp;妻子的尖叫声再次把我惊醒。不知哪里来的力量，我挣扎地爬起来，找回了那把祖传的菜刀。我又想起了父亲。是他苦口婆心的教导我，教我如何做人，还教了我祖传的刀法。不管我选择哪条路都由我自己走，他说。而我总是与他作对，而此时我决定作屠夫，这是父亲的宿愿。我踩着祖传的步法，快速靠近他，刀光一闪。空气静谧了，妻子也安静了。只见徐三霸的头从脖子上滑落到地上，滚动着，边滚嘴里边说：“好快刀，好……快刀……”随后，他的身子也慢慢的倒下，血飞溅了一地。手中得刀落在了地上，我全身瘫软地倒下了，全身冒着冷汗，脑子里一片空白。妻子抽泣着爬到我的身边。我们俩拥在了一块儿。“没事了，一切都好了，他死了……”我安慰着妻子。“死了……”我突然才意识到。“我杀人了，我杀人了……” \n\n&emsp;&emsp;“你醒醒，你醒醒……”床头妻子把我摇醒。 \n\n","source":"_posts/2007-04-14-好快刀.md","raw":"---\ntitle: 好快刀\ncategories:\n  - 乱笔\ntags:\n  - 杂\nabbrlink: 17668\ndate: 2007-04-14 11:22:53\n---\n\n&emsp;&emsp;在我还没有来得及目送最后一屡夕晖之前，夜已悄悄的笼罩下来。从地底下蒸出的水汽弥散开来，烟雾弥漫的街道像是通往地府的黄泉路。路上行人不多，偶尔路过一个，像是久死的干尸，摇摇晃晃地往地府赶去。只有几只青蛙的叫声证明这还是人间。 \n\n&emsp;&emsp;我坐在铺子中间，张开双腿，裤管挽得老高。胸口敞开，露出清晰可数的肋骨。一手抚着脖子上的粗汗，一手拼命的舞着扇子，来不及诅咒这可恶的天气。 \n\n&emsp;&emsp;妻子在后屋准备晚饭。我的任务就是守着案板前挂着的几片剩肉，希望那个好心人尽快把它买走，然后好好泡个澡。几只苍蝇来回飞舞，目标就是那几片快干掉的肉，但它们却迟迟不肯动手。我也没有心思去赶它们，况且它们也该心烦了，我想。案板上横卧着一把大菜刀，上面蒙了一层油。整个肉店就数它最显眼，最安静，似乎有什么大任务正等着它做。 \n\n&emsp;&emsp;“相公，救命啊……放……开我……”突然，妻子的尖叫声夹杂着一个男人的声音从后院传来把一切喧哗都暂停了，我的心也停止了跳动。一股寒意从头窜遍全身，扇子无声的落下。几秒钟的失魂之后，我跳出了椅子，冲到案前抓起菜刀，奔后院而来。我的脚步很沉，脑子里什么都没有，又什么可怕的情形都有，手中的刀握得格外的紧，像沉重的放不下的担子。 \n\n&emsp;&emsp;一个秃头胖大男人正压在拼命挣扎的妻子身上。一股自骨髓的愤怒喷涌而出：“住手…………”屋子和院子颤抖着，那是一只凶猛的野兽发出的吼声。时间暂停了，一股冷汗浸透了我的背。 \n\n&emsp;&emsp;胖大男人似乎吃了一惊，停止了手中的工作，抬头来看看到底是谁在冲自己咆哮。衣衫不整的妻子趁这个机会挣脱开来，哭丧着躲在我的身后。我定眼一看，不是别人，正是徐三霸那无恶不作的恶棍。人人都受他欺压，又怕他，没有人敢跟他斗，因为与他作对的人都没有好下场。我早想惩治他，只恐于力量不足。 \n\n&emsp;&emsp;他缓慢的站起来，整了整衣角。两只虎眼死盯着坏他好事的我。我心一惊：平时见他只觉他很壮硕，今天近些看，只怕再多几个我也敌他不过。 \n\n&emsp;&emsp;他慢慢向我走过来。“你要干什么？”我举起手中的刀，颤抖着。我的衣服湿透了，豆大的汗珠往外直冒。“想和你老婆玩儿玩儿。”他的嘴角露出奸淫的笑。说完，便立在了我面前，犹如一只猎食的巨兽。突然，他一手擒住我拿刀的手，只一扔，我和刀一起飞到了花坛边，重重的砸在了地上。我没有听到有没有骨碎的的声音，只听到受惊的妻子发出的尖叫声。我的头有些眩晕。我看到那只野兽又扑向了妻子。我四周摸了摸，摸到了菜刀，抓了起来，冲向那只野兽。谁知他早有防备，背着我只一脚，正中我的肚子，菜刀和我又飞了出去。肚子上一阵剧痛。手脚都没有了力气，丝毫不能动弹。我几乎晕过去了。隐隐约约，我看到了妻子的令人心生怜爱的面容，听到了妻子欢乐的笑声。几年来妻子总是无怨无悔的跟着我这个毫无成就的屠夫，不管我做什么妻子总是积极支持。在我失落时，她会与我分担烦恼给我万分的安慰，在我穷困时，她总是想尽办法来帮助我。妻子对我太好了，给我的太多了，而我却不懂得珍惜，从来没有给过妻子什么，也没有好好的代过她。而如今…… \n\n&emsp;&emsp;妻子的尖叫声再次把我惊醒。不知哪里来的力量，我挣扎地爬起来，找回了那把祖传的菜刀。我又想起了父亲。是他苦口婆心的教导我，教我如何做人，还教了我祖传的刀法。不管我选择哪条路都由我自己走，他说。而我总是与他作对，而此时我决定作屠夫，这是父亲的宿愿。我踩着祖传的步法，快速靠近他，刀光一闪。空气静谧了，妻子也安静了。只见徐三霸的头从脖子上滑落到地上，滚动着，边滚嘴里边说：“好快刀，好……快刀……”随后，他的身子也慢慢的倒下，血飞溅了一地。手中得刀落在了地上，我全身瘫软地倒下了，全身冒着冷汗，脑子里一片空白。妻子抽泣着爬到我的身边。我们俩拥在了一块儿。“没事了，一切都好了，他死了……”我安慰着妻子。“死了……”我突然才意识到。“我杀人了，我杀人了……” \n\n&emsp;&emsp;“你醒醒，你醒醒……”床头妻子把我摇醒。 \n\n","slug":"好快刀","published":1,"updated":"2024-05-26T14:17:36.844Z","comments":1,"layout":"post","photos":[],"_id":"cmh498ioc0007wvouhzx3ccb4","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>&emsp;&emsp;在我还没有来得及目送最后一屡夕晖之前，夜已悄悄的笼罩下来。从地底下蒸出的水汽弥散开来，烟雾弥漫的街道像是通往地府的黄泉路。路上行人不多，偶尔路过一个，像是久死的干尸，摇摇晃晃地往地府赶去。只有几只青蛙的叫声证明这还是人间。 </p>\n<p>&emsp;&emsp;我坐在铺子中间，张开双腿，裤管挽得老高。胸口敞开，露出清晰可数的肋骨。一手抚着脖子上的粗汗，一手拼命的舞着扇子，来不及诅咒这可恶的天气。 </p>\n<p>&emsp;&emsp;妻子在后屋准备晚饭。我的任务就是守着案板前挂着的几片剩肉，希望那个好心人尽快把它买走，然后好好泡个澡。几只苍蝇来回飞舞，目标就是那几片快干掉的肉，但它们却迟迟不肯动手。我也没有心思去赶它们，况且它们也该心烦了，我想。案板上横卧着一把大菜刀，上面蒙了一层油。整个肉店就数它最显眼，最安静，似乎有什么大任务正等着它做。 </p>\n<p>&emsp;&emsp;“相公，救命啊……放……开我……”突然，妻子的尖叫声夹杂着一个男人的声音从后院传来把一切喧哗都暂停了，我的心也停止了跳动。一股寒意从头窜遍全身，扇子无声的落下。几秒钟的失魂之后，我跳出了椅子，冲到案前抓起菜刀，奔后院而来。我的脚步很沉，脑子里什么都没有，又什么可怕的情形都有，手中的刀握得格外的紧，像沉重的放不下的担子。 </p>\n<p>&emsp;&emsp;一个秃头胖大男人正压在拼命挣扎的妻子身上。一股自骨髓的愤怒喷涌而出：“住手…………”屋子和院子颤抖着，那是一只凶猛的野兽发出的吼声。时间暂停了，一股冷汗浸透了我的背。 </p>\n<p>&emsp;&emsp;胖大男人似乎吃了一惊，停止了手中的工作，抬头来看看到底是谁在冲自己咆哮。衣衫不整的妻子趁这个机会挣脱开来，哭丧着躲在我的身后。我定眼一看，不是别人，正是徐三霸那无恶不作的恶棍。人人都受他欺压，又怕他，没有人敢跟他斗，因为与他作对的人都没有好下场。我早想惩治他，只恐于力量不足。 </p>\n<p>&emsp;&emsp;他缓慢的站起来，整了整衣角。两只虎眼死盯着坏他好事的我。我心一惊：平时见他只觉他很壮硕，今天近些看，只怕再多几个我也敌他不过。 </p>\n<p>&emsp;&emsp;他慢慢向我走过来。“你要干什么？”我举起手中的刀，颤抖着。我的衣服湿透了，豆大的汗珠往外直冒。“想和你老婆玩儿玩儿。”他的嘴角露出奸淫的笑。说完，便立在了我面前，犹如一只猎食的巨兽。突然，他一手擒住我拿刀的手，只一扔，我和刀一起飞到了花坛边，重重的砸在了地上。我没有听到有没有骨碎的的声音，只听到受惊的妻子发出的尖叫声。我的头有些眩晕。我看到那只野兽又扑向了妻子。我四周摸了摸，摸到了菜刀，抓了起来，冲向那只野兽。谁知他早有防备，背着我只一脚，正中我的肚子，菜刀和我又飞了出去。肚子上一阵剧痛。手脚都没有了力气，丝毫不能动弹。我几乎晕过去了。隐隐约约，我看到了妻子的令人心生怜爱的面容，听到了妻子欢乐的笑声。几年来妻子总是无怨无悔的跟着我这个毫无成就的屠夫，不管我做什么妻子总是积极支持。在我失落时，她会与我分担烦恼给我万分的安慰，在我穷困时，她总是想尽办法来帮助我。妻子对我太好了，给我的太多了，而我却不懂得珍惜，从来没有给过妻子什么，也没有好好的代过她。而如今…… </p>\n<p>&emsp;&emsp;妻子的尖叫声再次把我惊醒。不知哪里来的力量，我挣扎地爬起来，找回了那把祖传的菜刀。我又想起了父亲。是他苦口婆心的教导我，教我如何做人，还教了我祖传的刀法。不管我选择哪条路都由我自己走，他说。而我总是与他作对，而此时我决定作屠夫，这是父亲的宿愿。我踩着祖传的步法，快速靠近他，刀光一闪。空气静谧了，妻子也安静了。只见徐三霸的头从脖子上滑落到地上，滚动着，边滚嘴里边说：“好快刀，好……快刀……”随后，他的身子也慢慢的倒下，血飞溅了一地。手中得刀落在了地上，我全身瘫软地倒下了，全身冒着冷汗，脑子里一片空白。妻子抽泣着爬到我的身边。我们俩拥在了一块儿。“没事了，一切都好了，他死了……”我安慰着妻子。“死了……”我突然才意识到。“我杀人了，我杀人了……” </p>\n<p>&emsp;&emsp;“你醒醒，你醒醒……”床头妻子把我摇醒。 </p>\n","related_posts":[],"length":1679,"excerpt":"","more":"<p>&emsp;&emsp;在我还没有来得及目送最后一屡夕晖之前，夜已悄悄的笼罩下来。从地底下蒸出的水汽弥散开来，烟雾弥漫的街道像是通往地府的黄泉路。路上行人不多，偶尔路过一个，像是久死的干尸，摇摇晃晃地往地府赶去。只有几只青蛙的叫声证明这还是人间。 </p>\n<p>&emsp;&emsp;我坐在铺子中间，张开双腿，裤管挽得老高。胸口敞开，露出清晰可数的肋骨。一手抚着脖子上的粗汗，一手拼命的舞着扇子，来不及诅咒这可恶的天气。 </p>\n<p>&emsp;&emsp;妻子在后屋准备晚饭。我的任务就是守着案板前挂着的几片剩肉，希望那个好心人尽快把它买走，然后好好泡个澡。几只苍蝇来回飞舞，目标就是那几片快干掉的肉，但它们却迟迟不肯动手。我也没有心思去赶它们，况且它们也该心烦了，我想。案板上横卧着一把大菜刀，上面蒙了一层油。整个肉店就数它最显眼，最安静，似乎有什么大任务正等着它做。 </p>\n<p>&emsp;&emsp;“相公，救命啊……放……开我……”突然，妻子的尖叫声夹杂着一个男人的声音从后院传来把一切喧哗都暂停了，我的心也停止了跳动。一股寒意从头窜遍全身，扇子无声的落下。几秒钟的失魂之后，我跳出了椅子，冲到案前抓起菜刀，奔后院而来。我的脚步很沉，脑子里什么都没有，又什么可怕的情形都有，手中的刀握得格外的紧，像沉重的放不下的担子。 </p>\n<p>&emsp;&emsp;一个秃头胖大男人正压在拼命挣扎的妻子身上。一股自骨髓的愤怒喷涌而出：“住手…………”屋子和院子颤抖着，那是一只凶猛的野兽发出的吼声。时间暂停了，一股冷汗浸透了我的背。 </p>\n<p>&emsp;&emsp;胖大男人似乎吃了一惊，停止了手中的工作，抬头来看看到底是谁在冲自己咆哮。衣衫不整的妻子趁这个机会挣脱开来，哭丧着躲在我的身后。我定眼一看，不是别人，正是徐三霸那无恶不作的恶棍。人人都受他欺压，又怕他，没有人敢跟他斗，因为与他作对的人都没有好下场。我早想惩治他，只恐于力量不足。 </p>\n<p>&emsp;&emsp;他缓慢的站起来，整了整衣角。两只虎眼死盯着坏他好事的我。我心一惊：平时见他只觉他很壮硕，今天近些看，只怕再多几个我也敌他不过。 </p>\n<p>&emsp;&emsp;他慢慢向我走过来。“你要干什么？”我举起手中的刀，颤抖着。我的衣服湿透了，豆大的汗珠往外直冒。“想和你老婆玩儿玩儿。”他的嘴角露出奸淫的笑。说完，便立在了我面前，犹如一只猎食的巨兽。突然，他一手擒住我拿刀的手，只一扔，我和刀一起飞到了花坛边，重重的砸在了地上。我没有听到有没有骨碎的的声音，只听到受惊的妻子发出的尖叫声。我的头有些眩晕。我看到那只野兽又扑向了妻子。我四周摸了摸，摸到了菜刀，抓了起来，冲向那只野兽。谁知他早有防备，背着我只一脚，正中我的肚子，菜刀和我又飞了出去。肚子上一阵剧痛。手脚都没有了力气，丝毫不能动弹。我几乎晕过去了。隐隐约约，我看到了妻子的令人心生怜爱的面容，听到了妻子欢乐的笑声。几年来妻子总是无怨无悔的跟着我这个毫无成就的屠夫，不管我做什么妻子总是积极支持。在我失落时，她会与我分担烦恼给我万分的安慰，在我穷困时，她总是想尽办法来帮助我。妻子对我太好了，给我的太多了，而我却不懂得珍惜，从来没有给过妻子什么，也没有好好的代过她。而如今…… </p>\n<p>&emsp;&emsp;妻子的尖叫声再次把我惊醒。不知哪里来的力量，我挣扎地爬起来，找回了那把祖传的菜刀。我又想起了父亲。是他苦口婆心的教导我，教我如何做人，还教了我祖传的刀法。不管我选择哪条路都由我自己走，他说。而我总是与他作对，而此时我决定作屠夫，这是父亲的宿愿。我踩着祖传的步法，快速靠近他，刀光一闪。空气静谧了，妻子也安静了。只见徐三霸的头从脖子上滑落到地上，滚动着，边滚嘴里边说：“好快刀，好……快刀……”随后，他的身子也慢慢的倒下，血飞溅了一地。手中得刀落在了地上，我全身瘫软地倒下了，全身冒着冷汗，脑子里一片空白。妻子抽泣着爬到我的身边。我们俩拥在了一块儿。“没事了，一切都好了，他死了……”我安慰着妻子。“死了……”我突然才意识到。“我杀人了，我杀人了……” </p>\n<p>&emsp;&emsp;“你醒醒，你醒醒……”床头妻子把我摇醒。 </p>\n"},{"title":"南京大屠杀","abbrlink":31563,"date":"2007-12-13T13:41:53.000Z","_content":"\n&emsp;&emsp;今天是南京大屠杀七十周年纪念日。\n\n&emsp;&emsp;大礼堂播放了南京大屠杀的纪录片。我回到了那个恐怖时代，目睹了令人发指的自以为高级的人类的兽行。不管某些个日本人承不承认，那都是一段令所有中国人应该铭记的淌血的历史。\n\n&emsp;&emsp;如果有时间机器，我真想回到那个时代，首先把裕仁给爆头了。要是能够杀掉一个人来改变这段历史的话，应该就是杀他了。但是杀了他，日本的纳粹思想就能够改变吗？而且如果杀了他，我不就成了没有人性的人了？况且时间机器是暂时没有可能造好的了。\n\n&emsp;&emsp;不管怎么样，这都是一段改变不了的真实的历史。也不要只记住的是仇恨。\n\n&emsp;&emsp;铭记历史，振奋自我，超越自我；同时应该记住我们还是人。\n\n","source":"_posts/2007-12-13-南京大屠杀.md","raw":"---\ntitle: 南京大屠杀\ncategories:\n  - 某日记\ntags:\n  - 杂\nabbrlink: 31563\ndate: 2007-12-13 21:41:53\n---\n\n&emsp;&emsp;今天是南京大屠杀七十周年纪念日。\n\n&emsp;&emsp;大礼堂播放了南京大屠杀的纪录片。我回到了那个恐怖时代，目睹了令人发指的自以为高级的人类的兽行。不管某些个日本人承不承认，那都是一段令所有中国人应该铭记的淌血的历史。\n\n&emsp;&emsp;如果有时间机器，我真想回到那个时代，首先把裕仁给爆头了。要是能够杀掉一个人来改变这段历史的话，应该就是杀他了。但是杀了他，日本的纳粹思想就能够改变吗？而且如果杀了他，我不就成了没有人性的人了？况且时间机器是暂时没有可能造好的了。\n\n&emsp;&emsp;不管怎么样，这都是一段改变不了的真实的历史。也不要只记住的是仇恨。\n\n&emsp;&emsp;铭记历史，振奋自我，超越自我；同时应该记住我们还是人。\n\n","slug":"南京大屠杀","published":1,"updated":"2024-05-26T14:17:36.844Z","comments":1,"layout":"post","photos":[],"_id":"cmh498iod0009wvouhqnc1583","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>&emsp;&emsp;今天是南京大屠杀七十周年纪念日。</p>\n<p>&emsp;&emsp;大礼堂播放了南京大屠杀的纪录片。我回到了那个恐怖时代，目睹了令人发指的自以为高级的人类的兽行。不管某些个日本人承不承认，那都是一段令所有中国人应该铭记的淌血的历史。</p>\n<p>&emsp;&emsp;如果有时间机器，我真想回到那个时代，首先把裕仁给爆头了。要是能够杀掉一个人来改变这段历史的话，应该就是杀他了。但是杀了他，日本的纳粹思想就能够改变吗？而且如果杀了他，我不就成了没有人性的人了？况且时间机器是暂时没有可能造好的了。</p>\n<p>&emsp;&emsp;不管怎么样，这都是一段改变不了的真实的历史。也不要只记住的是仇恨。</p>\n<p>&emsp;&emsp;铭记历史，振奋自我，超越自我；同时应该记住我们还是人。</p>\n","related_posts":[],"length":332,"excerpt":"","more":"<p>&emsp;&emsp;今天是南京大屠杀七十周年纪念日。</p>\n<p>&emsp;&emsp;大礼堂播放了南京大屠杀的纪录片。我回到了那个恐怖时代，目睹了令人发指的自以为高级的人类的兽行。不管某些个日本人承不承认，那都是一段令所有中国人应该铭记的淌血的历史。</p>\n<p>&emsp;&emsp;如果有时间机器，我真想回到那个时代，首先把裕仁给爆头了。要是能够杀掉一个人来改变这段历史的话，应该就是杀他了。但是杀了他，日本的纳粹思想就能够改变吗？而且如果杀了他，我不就成了没有人性的人了？况且时间机器是暂时没有可能造好的了。</p>\n<p>&emsp;&emsp;不管怎么样，这都是一段改变不了的真实的历史。也不要只记住的是仇恨。</p>\n<p>&emsp;&emsp;铭记历史，振奋自我，超越自我；同时应该记住我们还是人。</p>\n"},{"title":"去他的","abbrlink":61552,"date":"2008-07-27T13:29:36.000Z","_content":"\n&emsp;&emsp;不要再一而再再而三地指导我做什么，尤其是在显而易见的情况下。搞不清楚是你唠叨还是因为你的唠叨让我觉得自己很笨。管它的呢，你唠叨并不代表我不知道，你唠叨并不一定我要听，你唠叨并不代表我很笨，嗨！去他的。就算我很笨，那又怎么样，只要活得开心！至于我真的不知道的东西，你放心我一定会听的。所以你唠叨我会装着听的，决不反驳，乖吧^\\_^\n\n&emsp;&emsp;不要再为无聊的，无伤和气的东东发脾气。发脾气有什么用呢？答案：1，那些东东不会因发脾气而消失，所以发脾气没有用。2，发脾气代表自己不顺心，不顺心没准心血管都会堵塞，伤身体啊！所以为什么要生气呢！如果真的要生气，那就先从一数到100000吧！去他的，活得开心就好！\n\n&emsp;&emsp;不要再胆怯。真好笑，看到他（她）为什么会结巴得说不出话，他又不会把你给吃了，就算他是食人族的那又怎么样，你又没有被绑起来！去他的，只要他说什么做什么没有伤害到你。活得开心就好。\n\n&emsp;&emsp;不要在我面前摆出一幅郁闷的表情，就是像我借了你的钱很久没有还的样子一样。虽然我是心理委员，不过现在才发现不及格。如果我心情好的话还是会帮你一点小忙，去？那伤心事。不要告诉我你的郁闷的表情不是因为伤心事，否则我无能为力。如果我的心情一般，见到了你恐怕我会比你还郁闷。不过请放心我不会比你还郁闷。人生郁闷是一天，开心也是一天，我干嘛要郁闷？\n\n&emsp;&emsp;如果你不是我的好朋友但和我关系又不一般，如果有一件开心的事要告诉我，如果这件开心的事和我无关，如果这件事只是你的开心事，请先考虑一下再告诉我，因为我没法控制我的脸使其与我的心情相违背，那叫喜怒不形于色，我是怕你看见我不知怎么开心的焦灼的脸而情绪低落。\n\n&emsp;&emsp;不要全部相信我上面写的东西，因为我的手与我的心有时是不一致的，去他的，看了我的日志千万不要伤心^\\_^\n\n","source":"_posts/2008-07-27-去他的.md","raw":"---\ntitle: 去他的\ncategories:\n  - 某日记\ntags:\n  - 杂\nabbrlink: 61552\ndate: 2008-07-27 21:29:36\n---\n\n&emsp;&emsp;不要再一而再再而三地指导我做什么，尤其是在显而易见的情况下。搞不清楚是你唠叨还是因为你的唠叨让我觉得自己很笨。管它的呢，你唠叨并不代表我不知道，你唠叨并不一定我要听，你唠叨并不代表我很笨，嗨！去他的。就算我很笨，那又怎么样，只要活得开心！至于我真的不知道的东西，你放心我一定会听的。所以你唠叨我会装着听的，决不反驳，乖吧^\\_^\n\n&emsp;&emsp;不要再为无聊的，无伤和气的东东发脾气。发脾气有什么用呢？答案：1，那些东东不会因发脾气而消失，所以发脾气没有用。2，发脾气代表自己不顺心，不顺心没准心血管都会堵塞，伤身体啊！所以为什么要生气呢！如果真的要生气，那就先从一数到100000吧！去他的，活得开心就好！\n\n&emsp;&emsp;不要再胆怯。真好笑，看到他（她）为什么会结巴得说不出话，他又不会把你给吃了，就算他是食人族的那又怎么样，你又没有被绑起来！去他的，只要他说什么做什么没有伤害到你。活得开心就好。\n\n&emsp;&emsp;不要在我面前摆出一幅郁闷的表情，就是像我借了你的钱很久没有还的样子一样。虽然我是心理委员，不过现在才发现不及格。如果我心情好的话还是会帮你一点小忙，去？那伤心事。不要告诉我你的郁闷的表情不是因为伤心事，否则我无能为力。如果我的心情一般，见到了你恐怕我会比你还郁闷。不过请放心我不会比你还郁闷。人生郁闷是一天，开心也是一天，我干嘛要郁闷？\n\n&emsp;&emsp;如果你不是我的好朋友但和我关系又不一般，如果有一件开心的事要告诉我，如果这件开心的事和我无关，如果这件事只是你的开心事，请先考虑一下再告诉我，因为我没法控制我的脸使其与我的心情相违背，那叫喜怒不形于色，我是怕你看见我不知怎么开心的焦灼的脸而情绪低落。\n\n&emsp;&emsp;不要全部相信我上面写的东西，因为我的手与我的心有时是不一致的，去他的，看了我的日志千万不要伤心^\\_^\n\n","slug":"去他的","published":1,"updated":"2024-05-26T14:17:36.844Z","comments":1,"layout":"post","photos":[],"_id":"cmh498ioe000awvoualyhgorn","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>&emsp;&emsp;不要再一而再再而三地指导我做什么，尤其是在显而易见的情况下。搞不清楚是你唠叨还是因为你的唠叨让我觉得自己很笨。管它的呢，你唠叨并不代表我不知道，你唠叨并不一定我要听，你唠叨并不代表我很笨，嗨！去他的。就算我很笨，那又怎么样，只要活得开心！至于我真的不知道的东西，你放心我一定会听的。所以你唠叨我会装着听的，决不反驳，乖吧^_^</p>\n<p>&emsp;&emsp;不要再为无聊的，无伤和气的东东发脾气。发脾气有什么用呢？答案：1，那些东东不会因发脾气而消失，所以发脾气没有用。2，发脾气代表自己不顺心，不顺心没准心血管都会堵塞，伤身体啊！所以为什么要生气呢！如果真的要生气，那就先从一数到100000吧！去他的，活得开心就好！</p>\n<p>&emsp;&emsp;不要再胆怯。真好笑，看到他（她）为什么会结巴得说不出话，他又不会把你给吃了，就算他是食人族的那又怎么样，你又没有被绑起来！去他的，只要他说什么做什么没有伤害到你。活得开心就好。</p>\n<p>&emsp;&emsp;不要在我面前摆出一幅郁闷的表情，就是像我借了你的钱很久没有还的样子一样。虽然我是心理委员，不过现在才发现不及格。如果我心情好的话还是会帮你一点小忙，去？那伤心事。不要告诉我你的郁闷的表情不是因为伤心事，否则我无能为力。如果我的心情一般，见到了你恐怕我会比你还郁闷。不过请放心我不会比你还郁闷。人生郁闷是一天，开心也是一天，我干嘛要郁闷？</p>\n<p>&emsp;&emsp;如果你不是我的好朋友但和我关系又不一般，如果有一件开心的事要告诉我，如果这件开心的事和我无关，如果这件事只是你的开心事，请先考虑一下再告诉我，因为我没法控制我的脸使其与我的心情相违背，那叫喜怒不形于色，我是怕你看见我不知怎么开心的焦灼的脸而情绪低落。</p>\n<p>&emsp;&emsp;不要全部相信我上面写的东西，因为我的手与我的心有时是不一致的，去他的，看了我的日志千万不要伤心^_^</p>\n","related_posts":[],"length":797,"excerpt":"","more":"<p>&emsp;&emsp;不要再一而再再而三地指导我做什么，尤其是在显而易见的情况下。搞不清楚是你唠叨还是因为你的唠叨让我觉得自己很笨。管它的呢，你唠叨并不代表我不知道，你唠叨并不一定我要听，你唠叨并不代表我很笨，嗨！去他的。就算我很笨，那又怎么样，只要活得开心！至于我真的不知道的东西，你放心我一定会听的。所以你唠叨我会装着听的，决不反驳，乖吧^_^</p>\n<p>&emsp;&emsp;不要再为无聊的，无伤和气的东东发脾气。发脾气有什么用呢？答案：1，那些东东不会因发脾气而消失，所以发脾气没有用。2，发脾气代表自己不顺心，不顺心没准心血管都会堵塞，伤身体啊！所以为什么要生气呢！如果真的要生气，那就先从一数到100000吧！去他的，活得开心就好！</p>\n<p>&emsp;&emsp;不要再胆怯。真好笑，看到他（她）为什么会结巴得说不出话，他又不会把你给吃了，就算他是食人族的那又怎么样，你又没有被绑起来！去他的，只要他说什么做什么没有伤害到你。活得开心就好。</p>\n<p>&emsp;&emsp;不要在我面前摆出一幅郁闷的表情，就是像我借了你的钱很久没有还的样子一样。虽然我是心理委员，不过现在才发现不及格。如果我心情好的话还是会帮你一点小忙，去？那伤心事。不要告诉我你的郁闷的表情不是因为伤心事，否则我无能为力。如果我的心情一般，见到了你恐怕我会比你还郁闷。不过请放心我不会比你还郁闷。人生郁闷是一天，开心也是一天，我干嘛要郁闷？</p>\n<p>&emsp;&emsp;如果你不是我的好朋友但和我关系又不一般，如果有一件开心的事要告诉我，如果这件开心的事和我无关，如果这件事只是你的开心事，请先考虑一下再告诉我，因为我没法控制我的脸使其与我的心情相违背，那叫喜怒不形于色，我是怕你看见我不知怎么开心的焦灼的脸而情绪低落。</p>\n<p>&emsp;&emsp;不要全部相信我上面写的东西，因为我的手与我的心有时是不一致的，去他的，看了我的日志千万不要伤心^_^</p>\n"},{"title":"外婆外公的故事","abbrlink":60318,"date":"2009-02-17T05:33:03.000Z","_content":"\n## 大面的由来\n\n&emsp;&emsp;我们所在的那个镇叫做大面铺。外公外婆几十年来几乎没有离开那个镇上百里。\n\n&emsp;&emsp;外公，大面铺为什么叫大面铺。外公说，大面铺以前并不叫大面铺，而叫倒面铺。于是故事就来了：\n\n&emsp;&emsp;很久很久以前，外公也不知道那是什么时候，鲁班和长腿大仙一同修建长东寺。一天，他们两都觉得无聊，于是想出一个消磨时间的比赛。比试看是鲁班先做好一张椅子，还是长腿大仙先从面粉厂挑回一担面粉。比赛开始。鲁班用纯熟的手艺开始砍木头,长腿大仙就更快了。只见他挑上担子只一步就跨到了界牌铺，第二步就跨到了洪门铺，第三步就到了面粉厂了。长腿大仙迅速装好面粉准备往回走。当他刚往回迈出第一步时，鲁班的椅子一半都还没有做好。聪明的鲁班料想这回输定了，于是将他的墨线悄悄地伸出去只一弹，长腿大仙一个跟斗就摔倒在了洪门铺与面粉厂中间的一块儿地上，面粉撒了一地。长腿大仙不得不爬起来重新回到面粉厂装面粉。等到他往回跨第一步时又被鲁班的墨线给弹摔倒了。如此，几番折腾，最后当长腿大仙回到长东寺时，鲁班也刚好做好椅子。于是两人打了个平手。长腿大仙摔倒的地方撒了一地的面粉，于是那块地方就被叫做倒面铺。后来又不知不觉地变成了大面铺。外公低下头继续弄他的东西……\n\n## 鲁班的墨\n\n&emsp;&emsp;外公，鲁班的墨线怎么这么厉害。当然厉害了。鲁班破木头从来都不用锯子或斧头，他就用墨线那么一弹，木头就齐齐地成了两半。他的墨是特制的，非得要用那山上的泉水兑，才能弹得动木头。有一天鲁班的墨用完了，于是叫他的徒弟上山打泉水调制墨。徒弟懒，不愿上山，于是撒了一泡尿来兑墨。鲁班用调好的墨弹木头，可是不管怎么弹木头都没有动静。鲁班于是就发现了问题，问他的徒弟，你这水是从山上打的吗？外公脸上露出了婴儿般的笑容……\n\n## 竹皇\n\n&emsp;&emsp;外婆说，有一天她到外面倒垃圾。只听见对面一条竹子发出唧唧咋咋的怪叫，还在不停的摆动。我说，那应该是竹子上面有一只鸟或者什么的吧？不是，我确定不是，我走近了看，没有看到有鸟，我用绳子作了记号，然后就跑回家叫你外公来看是怎么回事。你外公说我好傻。他说那是竹皇，是竹子中的黄帝，有灵性的，发现他以后就应该立刻砍下来，入药，大补。你现在才来叫我有什么用，他已经跑了。后来去看，我做记号的那根竹子果真不叫了。外婆一副无辜的样子……\n\n## 金鹅\n\n&emsp;&emsp;说到有灵性的东西就是以前我给你讲过的金鹅了，外婆说。我听他们讲，有一天一个人到荷塘里面打水，每次他用水桶去舀水，都有一只鹅子跳到他的桶里面，最后他不耐烦了，于是就把那只鹅抓了起来，这才发现是一只金鹅子，于是那个人就发财了。那是该那个人发财啊，别人的水桶它怎么不去窜呢？偏偏跑到他的桶里面。你见过金鹅吗？没有，我都是听他们讲的。你外公倒是见到过。那一年我们都到邻居家看电视去了，你外公一个人坐在院子里。你知道的以前我们家养过鹅的，就在里屋的巷子里。这时你外公就看到门口蹲了一只鹅，你也知道，你外公的眼神不好，他看到一团白色，想肯定是鹅子跑出来了。于是就对着鹅子叫：你还不回去！过了一会儿鹅子就不见了。回到小巷子里，发现鹅子都在，那有跑出来？要是你外公眼神好走过去就把它抱起来，要是你外公不说那句话而是直接去抱它，要是……我们家早就发财了……外婆露出了开朗的笑声……\n\n","source":"_posts/2009-02-17-外婆外公的故事.md","raw":"---\ntitle: 外婆外公的故事\ncategories:\n  - 乱笔\ntags:\n  - 外公\n  - 外婆\nabbrlink: 60318\ndate: 2009-02-17 13:33:03\n---\n\n## 大面的由来\n\n&emsp;&emsp;我们所在的那个镇叫做大面铺。外公外婆几十年来几乎没有离开那个镇上百里。\n\n&emsp;&emsp;外公，大面铺为什么叫大面铺。外公说，大面铺以前并不叫大面铺，而叫倒面铺。于是故事就来了：\n\n&emsp;&emsp;很久很久以前，外公也不知道那是什么时候，鲁班和长腿大仙一同修建长东寺。一天，他们两都觉得无聊，于是想出一个消磨时间的比赛。比试看是鲁班先做好一张椅子，还是长腿大仙先从面粉厂挑回一担面粉。比赛开始。鲁班用纯熟的手艺开始砍木头,长腿大仙就更快了。只见他挑上担子只一步就跨到了界牌铺，第二步就跨到了洪门铺，第三步就到了面粉厂了。长腿大仙迅速装好面粉准备往回走。当他刚往回迈出第一步时，鲁班的椅子一半都还没有做好。聪明的鲁班料想这回输定了，于是将他的墨线悄悄地伸出去只一弹，长腿大仙一个跟斗就摔倒在了洪门铺与面粉厂中间的一块儿地上，面粉撒了一地。长腿大仙不得不爬起来重新回到面粉厂装面粉。等到他往回跨第一步时又被鲁班的墨线给弹摔倒了。如此，几番折腾，最后当长腿大仙回到长东寺时，鲁班也刚好做好椅子。于是两人打了个平手。长腿大仙摔倒的地方撒了一地的面粉，于是那块地方就被叫做倒面铺。后来又不知不觉地变成了大面铺。外公低下头继续弄他的东西……\n\n## 鲁班的墨\n\n&emsp;&emsp;外公，鲁班的墨线怎么这么厉害。当然厉害了。鲁班破木头从来都不用锯子或斧头，他就用墨线那么一弹，木头就齐齐地成了两半。他的墨是特制的，非得要用那山上的泉水兑，才能弹得动木头。有一天鲁班的墨用完了，于是叫他的徒弟上山打泉水调制墨。徒弟懒，不愿上山，于是撒了一泡尿来兑墨。鲁班用调好的墨弹木头，可是不管怎么弹木头都没有动静。鲁班于是就发现了问题，问他的徒弟，你这水是从山上打的吗？外公脸上露出了婴儿般的笑容……\n\n## 竹皇\n\n&emsp;&emsp;外婆说，有一天她到外面倒垃圾。只听见对面一条竹子发出唧唧咋咋的怪叫，还在不停的摆动。我说，那应该是竹子上面有一只鸟或者什么的吧？不是，我确定不是，我走近了看，没有看到有鸟，我用绳子作了记号，然后就跑回家叫你外公来看是怎么回事。你外公说我好傻。他说那是竹皇，是竹子中的黄帝，有灵性的，发现他以后就应该立刻砍下来，入药，大补。你现在才来叫我有什么用，他已经跑了。后来去看，我做记号的那根竹子果真不叫了。外婆一副无辜的样子……\n\n## 金鹅\n\n&emsp;&emsp;说到有灵性的东西就是以前我给你讲过的金鹅了，外婆说。我听他们讲，有一天一个人到荷塘里面打水，每次他用水桶去舀水，都有一只鹅子跳到他的桶里面，最后他不耐烦了，于是就把那只鹅抓了起来，这才发现是一只金鹅子，于是那个人就发财了。那是该那个人发财啊，别人的水桶它怎么不去窜呢？偏偏跑到他的桶里面。你见过金鹅吗？没有，我都是听他们讲的。你外公倒是见到过。那一年我们都到邻居家看电视去了，你外公一个人坐在院子里。你知道的以前我们家养过鹅的，就在里屋的巷子里。这时你外公就看到门口蹲了一只鹅，你也知道，你外公的眼神不好，他看到一团白色，想肯定是鹅子跑出来了。于是就对着鹅子叫：你还不回去！过了一会儿鹅子就不见了。回到小巷子里，发现鹅子都在，那有跑出来？要是你外公眼神好走过去就把它抱起来，要是你外公不说那句话而是直接去抱它，要是……我们家早就发财了……外婆露出了开朗的笑声……\n\n","slug":"外婆外公的故事","published":1,"updated":"2024-05-26T14:17:36.844Z","comments":1,"layout":"post","photos":[],"_id":"cmh498iog000ewvoubleu9i6i","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><h2 id=\"大面的由来\"><a href=\"#大面的由来\" class=\"headerlink\" title=\"大面的由来\"></a>大面的由来</h2><p>&emsp;&emsp;我们所在的那个镇叫做大面铺。外公外婆几十年来几乎没有离开那个镇上百里。</p>\n<p>&emsp;&emsp;外公，大面铺为什么叫大面铺。外公说，大面铺以前并不叫大面铺，而叫倒面铺。于是故事就来了：</p>\n<p>&emsp;&emsp;很久很久以前，外公也不知道那是什么时候，鲁班和长腿大仙一同修建长东寺。一天，他们两都觉得无聊，于是想出一个消磨时间的比赛。比试看是鲁班先做好一张椅子，还是长腿大仙先从面粉厂挑回一担面粉。比赛开始。鲁班用纯熟的手艺开始砍木头,长腿大仙就更快了。只见他挑上担子只一步就跨到了界牌铺，第二步就跨到了洪门铺，第三步就到了面粉厂了。长腿大仙迅速装好面粉准备往回走。当他刚往回迈出第一步时，鲁班的椅子一半都还没有做好。聪明的鲁班料想这回输定了，于是将他的墨线悄悄地伸出去只一弹，长腿大仙一个跟斗就摔倒在了洪门铺与面粉厂中间的一块儿地上，面粉撒了一地。长腿大仙不得不爬起来重新回到面粉厂装面粉。等到他往回跨第一步时又被鲁班的墨线给弹摔倒了。如此，几番折腾，最后当长腿大仙回到长东寺时，鲁班也刚好做好椅子。于是两人打了个平手。长腿大仙摔倒的地方撒了一地的面粉，于是那块地方就被叫做倒面铺。后来又不知不觉地变成了大面铺。外公低下头继续弄他的东西……</p>\n<h2 id=\"鲁班的墨\"><a href=\"#鲁班的墨\" class=\"headerlink\" title=\"鲁班的墨\"></a>鲁班的墨</h2><p>&emsp;&emsp;外公，鲁班的墨线怎么这么厉害。当然厉害了。鲁班破木头从来都不用锯子或斧头，他就用墨线那么一弹，木头就齐齐地成了两半。他的墨是特制的，非得要用那山上的泉水兑，才能弹得动木头。有一天鲁班的墨用完了，于是叫他的徒弟上山打泉水调制墨。徒弟懒，不愿上山，于是撒了一泡尿来兑墨。鲁班用调好的墨弹木头，可是不管怎么弹木头都没有动静。鲁班于是就发现了问题，问他的徒弟，你这水是从山上打的吗？外公脸上露出了婴儿般的笑容……</p>\n<h2 id=\"竹皇\"><a href=\"#竹皇\" class=\"headerlink\" title=\"竹皇\"></a>竹皇</h2><p>&emsp;&emsp;外婆说，有一天她到外面倒垃圾。只听见对面一条竹子发出唧唧咋咋的怪叫，还在不停的摆动。我说，那应该是竹子上面有一只鸟或者什么的吧？不是，我确定不是，我走近了看，没有看到有鸟，我用绳子作了记号，然后就跑回家叫你外公来看是怎么回事。你外公说我好傻。他说那是竹皇，是竹子中的黄帝，有灵性的，发现他以后就应该立刻砍下来，入药，大补。你现在才来叫我有什么用，他已经跑了。后来去看，我做记号的那根竹子果真不叫了。外婆一副无辜的样子……</p>\n<h2 id=\"金鹅\"><a href=\"#金鹅\" class=\"headerlink\" title=\"金鹅\"></a>金鹅</h2><p>&emsp;&emsp;说到有灵性的东西就是以前我给你讲过的金鹅了，外婆说。我听他们讲，有一天一个人到荷塘里面打水，每次他用水桶去舀水，都有一只鹅子跳到他的桶里面，最后他不耐烦了，于是就把那只鹅抓了起来，这才发现是一只金鹅子，于是那个人就发财了。那是该那个人发财啊，别人的水桶它怎么不去窜呢？偏偏跑到他的桶里面。你见过金鹅吗？没有，我都是听他们讲的。你外公倒是见到过。那一年我们都到邻居家看电视去了，你外公一个人坐在院子里。你知道的以前我们家养过鹅的，就在里屋的巷子里。这时你外公就看到门口蹲了一只鹅，你也知道，你外公的眼神不好，他看到一团白色，想肯定是鹅子跑出来了。于是就对着鹅子叫：你还不回去！过了一会儿鹅子就不见了。回到小巷子里，发现鹅子都在，那有跑出来？要是你外公眼神好走过去就把它抱起来，要是你外公不说那句话而是直接去抱它，要是……我们家早就发财了……外婆露出了开朗的笑声……</p>\n","related_posts":[],"length":1372,"excerpt":"","more":"<h2 id=\"大面的由来\"><a href=\"#大面的由来\" class=\"headerlink\" title=\"大面的由来\"></a>大面的由来</h2><p>&emsp;&emsp;我们所在的那个镇叫做大面铺。外公外婆几十年来几乎没有离开那个镇上百里。</p>\n<p>&emsp;&emsp;外公，大面铺为什么叫大面铺。外公说，大面铺以前并不叫大面铺，而叫倒面铺。于是故事就来了：</p>\n<p>&emsp;&emsp;很久很久以前，外公也不知道那是什么时候，鲁班和长腿大仙一同修建长东寺。一天，他们两都觉得无聊，于是想出一个消磨时间的比赛。比试看是鲁班先做好一张椅子，还是长腿大仙先从面粉厂挑回一担面粉。比赛开始。鲁班用纯熟的手艺开始砍木头,长腿大仙就更快了。只见他挑上担子只一步就跨到了界牌铺，第二步就跨到了洪门铺，第三步就到了面粉厂了。长腿大仙迅速装好面粉准备往回走。当他刚往回迈出第一步时，鲁班的椅子一半都还没有做好。聪明的鲁班料想这回输定了，于是将他的墨线悄悄地伸出去只一弹，长腿大仙一个跟斗就摔倒在了洪门铺与面粉厂中间的一块儿地上，面粉撒了一地。长腿大仙不得不爬起来重新回到面粉厂装面粉。等到他往回跨第一步时又被鲁班的墨线给弹摔倒了。如此，几番折腾，最后当长腿大仙回到长东寺时，鲁班也刚好做好椅子。于是两人打了个平手。长腿大仙摔倒的地方撒了一地的面粉，于是那块地方就被叫做倒面铺。后来又不知不觉地变成了大面铺。外公低下头继续弄他的东西……</p>\n<h2 id=\"鲁班的墨\"><a href=\"#鲁班的墨\" class=\"headerlink\" title=\"鲁班的墨\"></a>鲁班的墨</h2><p>&emsp;&emsp;外公，鲁班的墨线怎么这么厉害。当然厉害了。鲁班破木头从来都不用锯子或斧头，他就用墨线那么一弹，木头就齐齐地成了两半。他的墨是特制的，非得要用那山上的泉水兑，才能弹得动木头。有一天鲁班的墨用完了，于是叫他的徒弟上山打泉水调制墨。徒弟懒，不愿上山，于是撒了一泡尿来兑墨。鲁班用调好的墨弹木头，可是不管怎么弹木头都没有动静。鲁班于是就发现了问题，问他的徒弟，你这水是从山上打的吗？外公脸上露出了婴儿般的笑容……</p>\n<h2 id=\"竹皇\"><a href=\"#竹皇\" class=\"headerlink\" title=\"竹皇\"></a>竹皇</h2><p>&emsp;&emsp;外婆说，有一天她到外面倒垃圾。只听见对面一条竹子发出唧唧咋咋的怪叫，还在不停的摆动。我说，那应该是竹子上面有一只鸟或者什么的吧？不是，我确定不是，我走近了看，没有看到有鸟，我用绳子作了记号，然后就跑回家叫你外公来看是怎么回事。你外公说我好傻。他说那是竹皇，是竹子中的黄帝，有灵性的，发现他以后就应该立刻砍下来，入药，大补。你现在才来叫我有什么用，他已经跑了。后来去看，我做记号的那根竹子果真不叫了。外婆一副无辜的样子……</p>\n<h2 id=\"金鹅\"><a href=\"#金鹅\" class=\"headerlink\" title=\"金鹅\"></a>金鹅</h2><p>&emsp;&emsp;说到有灵性的东西就是以前我给你讲过的金鹅了，外婆说。我听他们讲，有一天一个人到荷塘里面打水，每次他用水桶去舀水，都有一只鹅子跳到他的桶里面，最后他不耐烦了，于是就把那只鹅抓了起来，这才发现是一只金鹅子，于是那个人就发财了。那是该那个人发财啊，别人的水桶它怎么不去窜呢？偏偏跑到他的桶里面。你见过金鹅吗？没有，我都是听他们讲的。你外公倒是见到过。那一年我们都到邻居家看电视去了，你外公一个人坐在院子里。你知道的以前我们家养过鹅的，就在里屋的巷子里。这时你外公就看到门口蹲了一只鹅，你也知道，你外公的眼神不好，他看到一团白色，想肯定是鹅子跑出来了。于是就对着鹅子叫：你还不回去！过了一会儿鹅子就不见了。回到小巷子里，发现鹅子都在，那有跑出来？要是你外公眼神好走过去就把它抱起来，要是你外公不说那句话而是直接去抱它，要是……我们家早就发财了……外婆露出了开朗的笑声……</p>\n"},{"title":"星期五","abbrlink":20831,"date":"2009-04-10T13:22:15.000Z","_content":"\n&emsp;&emsp;好久没有坐过电梯了，今天，腿实在疼的不行了，所以还是坐电梯了。\n\n&emsp;&emsp;地毯上写着星期五。\n\n&emsp;&emsp;看到星期五就想到了：鲁宾逊漂流记，黑色星期五，今晚有电影，今晚12点才熄灯，今晚算是周末的开始了，今晚会玩游戏，会玩到很晚，今天是十五，月亮很圆，今天是小姑的生日。\n\n&emsp;&emsp;不过最重要的是：快要毕业了。\n\n&emsp;&emsp;可是似乎我还有好多大学应该做的事没有做：谈恋爱，在网吧包夜打游戏，找份兼职做，打打架……\n\n&emsp;&emsp;前天健身了，很累，晚上感冒了，现在全身都没有力，感觉好没有动力和意义。忽然又想起刚才和老妈打电话。我提到了跳楼的家伙，老妈火了，说道，傻帽，人生这么美好，跳楼？是不是那根筋搭错了？\n\n&emsp;&emsp;对啊，接着玩，玩到有力气为止\n\n","source":"_posts/2009-04-10-星期五.md","raw":"---\ntitle: 星期五\ncategories:\n  - 某日记\ntags:\n  - 杂\nabbrlink: 20831\ndate: 2009-04-10 21:22:15\n---\n\n&emsp;&emsp;好久没有坐过电梯了，今天，腿实在疼的不行了，所以还是坐电梯了。\n\n&emsp;&emsp;地毯上写着星期五。\n\n&emsp;&emsp;看到星期五就想到了：鲁宾逊漂流记，黑色星期五，今晚有电影，今晚12点才熄灯，今晚算是周末的开始了，今晚会玩游戏，会玩到很晚，今天是十五，月亮很圆，今天是小姑的生日。\n\n&emsp;&emsp;不过最重要的是：快要毕业了。\n\n&emsp;&emsp;可是似乎我还有好多大学应该做的事没有做：谈恋爱，在网吧包夜打游戏，找份兼职做，打打架……\n\n&emsp;&emsp;前天健身了，很累，晚上感冒了，现在全身都没有力，感觉好没有动力和意义。忽然又想起刚才和老妈打电话。我提到了跳楼的家伙，老妈火了，说道，傻帽，人生这么美好，跳楼？是不是那根筋搭错了？\n\n&emsp;&emsp;对啊，接着玩，玩到有力气为止\n\n","slug":"星期五","published":1,"updated":"2024-05-26T14:17:36.844Z","comments":1,"layout":"post","photos":[],"_id":"cmh498ioh000fwvou4ll8gwt4","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>&emsp;&emsp;好久没有坐过电梯了，今天，腿实在疼的不行了，所以还是坐电梯了。</p>\n<p>&emsp;&emsp;地毯上写着星期五。</p>\n<p>&emsp;&emsp;看到星期五就想到了：鲁宾逊漂流记，黑色星期五，今晚有电影，今晚12点才熄灯，今晚算是周末的开始了，今晚会玩游戏，会玩到很晚，今天是十五，月亮很圆，今天是小姑的生日。</p>\n<p>&emsp;&emsp;不过最重要的是：快要毕业了。</p>\n<p>&emsp;&emsp;可是似乎我还有好多大学应该做的事没有做：谈恋爱，在网吧包夜打游戏，找份兼职做，打打架……</p>\n<p>&emsp;&emsp;前天健身了，很累，晚上感冒了，现在全身都没有力，感觉好没有动力和意义。忽然又想起刚才和老妈打电话。我提到了跳楼的家伙，老妈火了，说道，傻帽，人生这么美好，跳楼？是不是那根筋搭错了？</p>\n<p>&emsp;&emsp;对啊，接着玩，玩到有力气为止</p>\n","related_posts":[],"length":368,"excerpt":"","more":"<p>&emsp;&emsp;好久没有坐过电梯了，今天，腿实在疼的不行了，所以还是坐电梯了。</p>\n<p>&emsp;&emsp;地毯上写着星期五。</p>\n<p>&emsp;&emsp;看到星期五就想到了：鲁宾逊漂流记，黑色星期五，今晚有电影，今晚12点才熄灯，今晚算是周末的开始了，今晚会玩游戏，会玩到很晚，今天是十五，月亮很圆，今天是小姑的生日。</p>\n<p>&emsp;&emsp;不过最重要的是：快要毕业了。</p>\n<p>&emsp;&emsp;可是似乎我还有好多大学应该做的事没有做：谈恋爱，在网吧包夜打游戏，找份兼职做，打打架……</p>\n<p>&emsp;&emsp;前天健身了，很累，晚上感冒了，现在全身都没有力，感觉好没有动力和意义。忽然又想起刚才和老妈打电话。我提到了跳楼的家伙，老妈火了，说道，傻帽，人生这么美好，跳楼？是不是那根筋搭错了？</p>\n<p>&emsp;&emsp;对啊，接着玩，玩到有力气为止</p>\n"},{"title":"The City of Life and Death","abbrlink":1318,"date":"2009-08-12T13:16:00.000Z","_content":"\n&emsp;&emsp;13日看的《南京！南京》，不知道为什么把南京的名字叫两遍，可能是因为历史的厚重，提到南京就令人想起令人悲痛的往事，1937年12月13日，南京沦陷。\n\n&emsp;&emsp;先说影片吧！\n\n&emsp;&emsp;颜色，黑白。看不见绚丽的颜色，天空没有颜色，花草没有颜色，房屋没有颜色，人也没有颜色，展现一种绝望与黑暗的感觉。也许是为了体现历史的沉重感。\n\n&emsp;&emsp;第一场枪战。没有血肉模糊，片中连一滴血都看不到，当然这不是一部体现战争残酷的战争片，也不是体现男子气概的动作片。没有突出的战斗策略，不像《拯救大兵瑞恩》那么有条有理，有细节，有的只是一片混战，展现的是南京最后一股反抗的力量，当然这给了我们一丝希望。这最后一股反抗力量居然打赢了敌人的先头小部队。《拯救》最后赶来增援的是的正义方（那边是正义？）而这部影片里最后来的确是敌人的增援。先给人以一线希望，然后令这个希望坠落万丈深渊，我们知道，从现在起，悲剧就已经开始。\n\n&emsp;&emsp;枪杀。日本兵准备枪杀所有的俘虏。用不流利的中文命令俘虏“起立”，“向后转”，”向前走“……走向刑场。被俘的民众唯命是从，任人宰割，当然他们有的只是对于生命的一点点渴望。被俘的军人开始从不听从日本兵的命令，有的是军人的尊严，与身为中国人的骨气。后来又纷纷起身走向刑场，体现军人的不怕死的牺牲精神。（不过两个衔接上是不是有点问题？）\n\n&emsp;&emsp;打麻将。难民区外面是枪声战火，里面却安安心心地挫起了麻将，是麻木了吗？还是根本就是事不关己，心安理得小市民思想？\n\n&emsp;&emsp;理发。为了不让自己被强暴，女子被迫理成短发假扮男子。其中一个妓女居然口口声声说为以后的生计而拒绝理发。麻木的小市民啊……\n\n&emsp;&emsp;强暴。整部片子大部分的描写用在了强暴上。（我不知道这是为何，是为了契合其中一个日本慰安妇，还是如今女权问题成了时事？）\n\n&emsp;&emsp;场景。我说的是背景，地点。有成为废墟的南京城，教堂里，街上，屋子里（不知那里的屋子里，我的意思是没有流动，蒙太奇手法也许可以弥补。），南京难民区，刑场，一条无尽的两边开满花的路。\n\n&emsp;&emsp;人物。刘烨演的军人，是最后一股反抗力量，是军人的代表。被俘，要被枪杀时，他第一个起身，走向刑场。高圆圆演的姜老师，还有作为人的爱心，怜悯心，尊严。范伟演的唐先生，有小市民的自保思想，也有作为中国人的骨气，与人性。中泉英雄演的角川，自始至终只杀过两个人，一个是姜老师，一个是自己。杀姜老师是为了保住姜老师的尊严，成全姜老师。自杀是不堪忍受生活在人间却如同置身炼狱。角川是日本兵中唯一一个还保留有人性的人，是看清了真实的人，其他日本兵的人性都是麻木的，兽性袒露无遗。角川这个角色我感觉是一个突破，不能说影片对角川这样的人有多么的赞扬，但确实是以前此类电影所没有的。但是，影片里面似乎又无形的将（也许他本来没有，只是我们臆想。）角川与其他日本兵对比，将角川与中国的小市民对比。百合子，同许多被日本兵拉去逼迫做慰安妇的女人一样，也是被折磨致死。也是一种对比，我们可以看到，日本兵的麻木与兽性所达到的程度，总之是没有留丝毫的人性，就算是自己的国人又如何。顺子，也是和刘烨一起的军人，但是他在刑场上活了下来。这个人我不懂，从军人沦落到小市民，丧失了血性，后来成了只为求生，甚至向姜老师求救，间接害了姜老师，最后角川放了小孩和顺子，顺子脸上居然笑开了花，我不懂，我很不懂。群众演员，也许是因为面对一个沉重的历史，每个人都很投入，都很传神，完全不同于以往的其他内地片子。\n\n&emsp;&emsp; 两年前看过南京大屠杀的纪录片，义愤填膺，如今又看了拍的影片居然没有过多的想法。难道是我麻木了？\n\n","source":"_posts/2009-08-12-the-city-of-life-and-death.md","raw":"---\ntitle: The City of Life and Death\ncategories:\n  - 日记\ntags:\n  - 电影\nabbrlink: 1318\ndate: 2009-08-12 21:16:00\n---\n\n&emsp;&emsp;13日看的《南京！南京》，不知道为什么把南京的名字叫两遍，可能是因为历史的厚重，提到南京就令人想起令人悲痛的往事，1937年12月13日，南京沦陷。\n\n&emsp;&emsp;先说影片吧！\n\n&emsp;&emsp;颜色，黑白。看不见绚丽的颜色，天空没有颜色，花草没有颜色，房屋没有颜色，人也没有颜色，展现一种绝望与黑暗的感觉。也许是为了体现历史的沉重感。\n\n&emsp;&emsp;第一场枪战。没有血肉模糊，片中连一滴血都看不到，当然这不是一部体现战争残酷的战争片，也不是体现男子气概的动作片。没有突出的战斗策略，不像《拯救大兵瑞恩》那么有条有理，有细节，有的只是一片混战，展现的是南京最后一股反抗的力量，当然这给了我们一丝希望。这最后一股反抗力量居然打赢了敌人的先头小部队。《拯救》最后赶来增援的是的正义方（那边是正义？）而这部影片里最后来的确是敌人的增援。先给人以一线希望，然后令这个希望坠落万丈深渊，我们知道，从现在起，悲剧就已经开始。\n\n&emsp;&emsp;枪杀。日本兵准备枪杀所有的俘虏。用不流利的中文命令俘虏“起立”，“向后转”，”向前走“……走向刑场。被俘的民众唯命是从，任人宰割，当然他们有的只是对于生命的一点点渴望。被俘的军人开始从不听从日本兵的命令，有的是军人的尊严，与身为中国人的骨气。后来又纷纷起身走向刑场，体现军人的不怕死的牺牲精神。（不过两个衔接上是不是有点问题？）\n\n&emsp;&emsp;打麻将。难民区外面是枪声战火，里面却安安心心地挫起了麻将，是麻木了吗？还是根本就是事不关己，心安理得小市民思想？\n\n&emsp;&emsp;理发。为了不让自己被强暴，女子被迫理成短发假扮男子。其中一个妓女居然口口声声说为以后的生计而拒绝理发。麻木的小市民啊……\n\n&emsp;&emsp;强暴。整部片子大部分的描写用在了强暴上。（我不知道这是为何，是为了契合其中一个日本慰安妇，还是如今女权问题成了时事？）\n\n&emsp;&emsp;场景。我说的是背景，地点。有成为废墟的南京城，教堂里，街上，屋子里（不知那里的屋子里，我的意思是没有流动，蒙太奇手法也许可以弥补。），南京难民区，刑场，一条无尽的两边开满花的路。\n\n&emsp;&emsp;人物。刘烨演的军人，是最后一股反抗力量，是军人的代表。被俘，要被枪杀时，他第一个起身，走向刑场。高圆圆演的姜老师，还有作为人的爱心，怜悯心，尊严。范伟演的唐先生，有小市民的自保思想，也有作为中国人的骨气，与人性。中泉英雄演的角川，自始至终只杀过两个人，一个是姜老师，一个是自己。杀姜老师是为了保住姜老师的尊严，成全姜老师。自杀是不堪忍受生活在人间却如同置身炼狱。角川是日本兵中唯一一个还保留有人性的人，是看清了真实的人，其他日本兵的人性都是麻木的，兽性袒露无遗。角川这个角色我感觉是一个突破，不能说影片对角川这样的人有多么的赞扬，但确实是以前此类电影所没有的。但是，影片里面似乎又无形的将（也许他本来没有，只是我们臆想。）角川与其他日本兵对比，将角川与中国的小市民对比。百合子，同许多被日本兵拉去逼迫做慰安妇的女人一样，也是被折磨致死。也是一种对比，我们可以看到，日本兵的麻木与兽性所达到的程度，总之是没有留丝毫的人性，就算是自己的国人又如何。顺子，也是和刘烨一起的军人，但是他在刑场上活了下来。这个人我不懂，从军人沦落到小市民，丧失了血性，后来成了只为求生，甚至向姜老师求救，间接害了姜老师，最后角川放了小孩和顺子，顺子脸上居然笑开了花，我不懂，我很不懂。群众演员，也许是因为面对一个沉重的历史，每个人都很投入，都很传神，完全不同于以往的其他内地片子。\n\n&emsp;&emsp; 两年前看过南京大屠杀的纪录片，义愤填膺，如今又看了拍的影片居然没有过多的想法。难道是我麻木了？\n\n","slug":"the-city-of-life-and-death","published":1,"updated":"2024-05-26T14:17:36.844Z","comments":1,"layout":"post","photos":[],"_id":"cmh498ioi000jwvou9hu6gacb","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>&emsp;&emsp;13日看的《南京！南京》，不知道为什么把南京的名字叫两遍，可能是因为历史的厚重，提到南京就令人想起令人悲痛的往事，1937年12月13日，南京沦陷。</p>\n<p>&emsp;&emsp;先说影片吧！</p>\n<p>&emsp;&emsp;颜色，黑白。看不见绚丽的颜色，天空没有颜色，花草没有颜色，房屋没有颜色，人也没有颜色，展现一种绝望与黑暗的感觉。也许是为了体现历史的沉重感。</p>\n<p>&emsp;&emsp;第一场枪战。没有血肉模糊，片中连一滴血都看不到，当然这不是一部体现战争残酷的战争片，也不是体现男子气概的动作片。没有突出的战斗策略，不像《拯救大兵瑞恩》那么有条有理，有细节，有的只是一片混战，展现的是南京最后一股反抗的力量，当然这给了我们一丝希望。这最后一股反抗力量居然打赢了敌人的先头小部队。《拯救》最后赶来增援的是的正义方（那边是正义？）而这部影片里最后来的确是敌人的增援。先给人以一线希望，然后令这个希望坠落万丈深渊，我们知道，从现在起，悲剧就已经开始。</p>\n<p>&emsp;&emsp;枪杀。日本兵准备枪杀所有的俘虏。用不流利的中文命令俘虏“起立”，“向后转”，”向前走“……走向刑场。被俘的民众唯命是从，任人宰割，当然他们有的只是对于生命的一点点渴望。被俘的军人开始从不听从日本兵的命令，有的是军人的尊严，与身为中国人的骨气。后来又纷纷起身走向刑场，体现军人的不怕死的牺牲精神。（不过两个衔接上是不是有点问题？）</p>\n<p>&emsp;&emsp;打麻将。难民区外面是枪声战火，里面却安安心心地挫起了麻将，是麻木了吗？还是根本就是事不关己，心安理得小市民思想？</p>\n<p>&emsp;&emsp;理发。为了不让自己被强暴，女子被迫理成短发假扮男子。其中一个妓女居然口口声声说为以后的生计而拒绝理发。麻木的小市民啊……</p>\n<p>&emsp;&emsp;强暴。整部片子大部分的描写用在了强暴上。（我不知道这是为何，是为了契合其中一个日本慰安妇，还是如今女权问题成了时事？）</p>\n<p>&emsp;&emsp;场景。我说的是背景，地点。有成为废墟的南京城，教堂里，街上，屋子里（不知那里的屋子里，我的意思是没有流动，蒙太奇手法也许可以弥补。），南京难民区，刑场，一条无尽的两边开满花的路。</p>\n<p>&emsp;&emsp;人物。刘烨演的军人，是最后一股反抗力量，是军人的代表。被俘，要被枪杀时，他第一个起身，走向刑场。高圆圆演的姜老师，还有作为人的爱心，怜悯心，尊严。范伟演的唐先生，有小市民的自保思想，也有作为中国人的骨气，与人性。中泉英雄演的角川，自始至终只杀过两个人，一个是姜老师，一个是自己。杀姜老师是为了保住姜老师的尊严，成全姜老师。自杀是不堪忍受生活在人间却如同置身炼狱。角川是日本兵中唯一一个还保留有人性的人，是看清了真实的人，其他日本兵的人性都是麻木的，兽性袒露无遗。角川这个角色我感觉是一个突破，不能说影片对角川这样的人有多么的赞扬，但确实是以前此类电影所没有的。但是，影片里面似乎又无形的将（也许他本来没有，只是我们臆想。）角川与其他日本兵对比，将角川与中国的小市民对比。百合子，同许多被日本兵拉去逼迫做慰安妇的女人一样，也是被折磨致死。也是一种对比，我们可以看到，日本兵的麻木与兽性所达到的程度，总之是没有留丝毫的人性，就算是自己的国人又如何。顺子，也是和刘烨一起的军人，但是他在刑场上活了下来。这个人我不懂，从军人沦落到小市民，丧失了血性，后来成了只为求生，甚至向姜老师求救，间接害了姜老师，最后角川放了小孩和顺子，顺子脸上居然笑开了花，我不懂，我很不懂。群众演员，也许是因为面对一个沉重的历史，每个人都很投入，都很传神，完全不同于以往的其他内地片子。</p>\n<p>&emsp;&emsp; 两年前看过南京大屠杀的纪录片，义愤填膺，如今又看了拍的影片居然没有过多的想法。难道是我麻木了？</p>\n","related_posts":[],"length":1564,"excerpt":"","more":"<p>&emsp;&emsp;13日看的《南京！南京》，不知道为什么把南京的名字叫两遍，可能是因为历史的厚重，提到南京就令人想起令人悲痛的往事，1937年12月13日，南京沦陷。</p>\n<p>&emsp;&emsp;先说影片吧！</p>\n<p>&emsp;&emsp;颜色，黑白。看不见绚丽的颜色，天空没有颜色，花草没有颜色，房屋没有颜色，人也没有颜色，展现一种绝望与黑暗的感觉。也许是为了体现历史的沉重感。</p>\n<p>&emsp;&emsp;第一场枪战。没有血肉模糊，片中连一滴血都看不到，当然这不是一部体现战争残酷的战争片，也不是体现男子气概的动作片。没有突出的战斗策略，不像《拯救大兵瑞恩》那么有条有理，有细节，有的只是一片混战，展现的是南京最后一股反抗的力量，当然这给了我们一丝希望。这最后一股反抗力量居然打赢了敌人的先头小部队。《拯救》最后赶来增援的是的正义方（那边是正义？）而这部影片里最后来的确是敌人的增援。先给人以一线希望，然后令这个希望坠落万丈深渊，我们知道，从现在起，悲剧就已经开始。</p>\n<p>&emsp;&emsp;枪杀。日本兵准备枪杀所有的俘虏。用不流利的中文命令俘虏“起立”，“向后转”，”向前走“……走向刑场。被俘的民众唯命是从，任人宰割，当然他们有的只是对于生命的一点点渴望。被俘的军人开始从不听从日本兵的命令，有的是军人的尊严，与身为中国人的骨气。后来又纷纷起身走向刑场，体现军人的不怕死的牺牲精神。（不过两个衔接上是不是有点问题？）</p>\n<p>&emsp;&emsp;打麻将。难民区外面是枪声战火，里面却安安心心地挫起了麻将，是麻木了吗？还是根本就是事不关己，心安理得小市民思想？</p>\n<p>&emsp;&emsp;理发。为了不让自己被强暴，女子被迫理成短发假扮男子。其中一个妓女居然口口声声说为以后的生计而拒绝理发。麻木的小市民啊……</p>\n<p>&emsp;&emsp;强暴。整部片子大部分的描写用在了强暴上。（我不知道这是为何，是为了契合其中一个日本慰安妇，还是如今女权问题成了时事？）</p>\n<p>&emsp;&emsp;场景。我说的是背景，地点。有成为废墟的南京城，教堂里，街上，屋子里（不知那里的屋子里，我的意思是没有流动，蒙太奇手法也许可以弥补。），南京难民区，刑场，一条无尽的两边开满花的路。</p>\n<p>&emsp;&emsp;人物。刘烨演的军人，是最后一股反抗力量，是军人的代表。被俘，要被枪杀时，他第一个起身，走向刑场。高圆圆演的姜老师，还有作为人的爱心，怜悯心，尊严。范伟演的唐先生，有小市民的自保思想，也有作为中国人的骨气，与人性。中泉英雄演的角川，自始至终只杀过两个人，一个是姜老师，一个是自己。杀姜老师是为了保住姜老师的尊严，成全姜老师。自杀是不堪忍受生活在人间却如同置身炼狱。角川是日本兵中唯一一个还保留有人性的人，是看清了真实的人，其他日本兵的人性都是麻木的，兽性袒露无遗。角川这个角色我感觉是一个突破，不能说影片对角川这样的人有多么的赞扬，但确实是以前此类电影所没有的。但是，影片里面似乎又无形的将（也许他本来没有，只是我们臆想。）角川与其他日本兵对比，将角川与中国的小市民对比。百合子，同许多被日本兵拉去逼迫做慰安妇的女人一样，也是被折磨致死。也是一种对比，我们可以看到，日本兵的麻木与兽性所达到的程度，总之是没有留丝毫的人性，就算是自己的国人又如何。顺子，也是和刘烨一起的军人，但是他在刑场上活了下来。这个人我不懂，从军人沦落到小市民，丧失了血性，后来成了只为求生，甚至向姜老师求救，间接害了姜老师，最后角川放了小孩和顺子，顺子脸上居然笑开了花，我不懂，我很不懂。群众演员，也许是因为面对一个沉重的历史，每个人都很投入，都很传神，完全不同于以往的其他内地片子。</p>\n<p>&emsp;&emsp; 两年前看过南京大屠杀的纪录片，义愤填膺，如今又看了拍的影片居然没有过多的想法。难道是我麻木了？</p>\n"},{"title":"无题","abbrlink":58856,"date":"2009-08-12T13:14:38.000Z","_content":"\n&emsp;&emsp;很难描述这几日的天气怎样，事实上无论外面的天气如何与我无干。\n\n&emsp;&emsp;出门的时候我也没有翻皇历，因为我没有皇历可翻。\n\n&emsp;&emsp;不管是天气还是皇历，所有事情只有了人的意识的参与才会有意义。\n\n&emsp;&emsp;当然我不是说我的意识在飘散。而是我的心情很乱。\n\n&emsp;&emsp;我睡在实验室，不太想回那熟悉而又陌生的宿舍。但我又不能在实验室睡得太懒，我不想把我“可爱”的睡姿展现给大家。所以我还是决定回到宿舍小憩。\n\n&emsp;&emsp;我熟练地掏出钥匙串，在其中捡出开挂锁的那一把。虽然开过无数次们，但是我还是弄错了，我挑出的那把与挂锁钥匙很像，却不是。那把是四年前初到学校时留在我的书桌上的钥匙。\n\n&emsp;&emsp;我幻想过这把钥匙的各种幻想，也许它是开启某个密室门的钥匙，也许它可以打开一个惊天动地的秘密。于是我把它套在了我的钥匙串上，随身携带了四年，幻想了四年。\n\n&emsp;&emsp;今天这个幻想破了，梦也该醒了。除了增加钥匙串重量，让我弄混开锁钥匙，它几乎没有任何作用。\n\n&emsp;&emsp;突然想起，似乎我却没有过什么梦。不知自己这二十几年来在做什么，像个孩子。\n\n&emsp;&emsp;也许只是因为身边的许多相处日长的好朋友的离开导致我的突然地不清醒，可笑。\n\n&emsp;&emsp;也许再过些时日，这股孩子气就会随着我们逐渐退化的记忆慢慢消散，寥无痕迹。\n\n&emsp;&emsp;猪妖，该干什么，干什么去！\n\n&emsp;&emsp;美孚，希尔顿……\n\n&emsp;&emsp;忽而又发现，我整天都在梦里面。\n\n","source":"_posts/2009-08-12-无题.md","raw":"---\ntitle: 无题\ncategories:\n  - 某日记\ntags:\n  - 无题\n  - 杂\nabbrlink: 58856\ndate: 2009-08-12 21:14:38\n---\n\n&emsp;&emsp;很难描述这几日的天气怎样，事实上无论外面的天气如何与我无干。\n\n&emsp;&emsp;出门的时候我也没有翻皇历，因为我没有皇历可翻。\n\n&emsp;&emsp;不管是天气还是皇历，所有事情只有了人的意识的参与才会有意义。\n\n&emsp;&emsp;当然我不是说我的意识在飘散。而是我的心情很乱。\n\n&emsp;&emsp;我睡在实验室，不太想回那熟悉而又陌生的宿舍。但我又不能在实验室睡得太懒，我不想把我“可爱”的睡姿展现给大家。所以我还是决定回到宿舍小憩。\n\n&emsp;&emsp;我熟练地掏出钥匙串，在其中捡出开挂锁的那一把。虽然开过无数次们，但是我还是弄错了，我挑出的那把与挂锁钥匙很像，却不是。那把是四年前初到学校时留在我的书桌上的钥匙。\n\n&emsp;&emsp;我幻想过这把钥匙的各种幻想，也许它是开启某个密室门的钥匙，也许它可以打开一个惊天动地的秘密。于是我把它套在了我的钥匙串上，随身携带了四年，幻想了四年。\n\n&emsp;&emsp;今天这个幻想破了，梦也该醒了。除了增加钥匙串重量，让我弄混开锁钥匙，它几乎没有任何作用。\n\n&emsp;&emsp;突然想起，似乎我却没有过什么梦。不知自己这二十几年来在做什么，像个孩子。\n\n&emsp;&emsp;也许只是因为身边的许多相处日长的好朋友的离开导致我的突然地不清醒，可笑。\n\n&emsp;&emsp;也许再过些时日，这股孩子气就会随着我们逐渐退化的记忆慢慢消散，寥无痕迹。\n\n&emsp;&emsp;猪妖，该干什么，干什么去！\n\n&emsp;&emsp;美孚，希尔顿……\n\n&emsp;&emsp;忽而又发现，我整天都在梦里面。\n\n","slug":"无题","published":1,"updated":"2024-05-26T14:17:36.844Z","comments":1,"layout":"post","photos":[],"_id":"cmh498ioi000mwvou4d412v2b","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>&emsp;&emsp;很难描述这几日的天气怎样，事实上无论外面的天气如何与我无干。</p>\n<p>&emsp;&emsp;出门的时候我也没有翻皇历，因为我没有皇历可翻。</p>\n<p>&emsp;&emsp;不管是天气还是皇历，所有事情只有了人的意识的参与才会有意义。</p>\n<p>&emsp;&emsp;当然我不是说我的意识在飘散。而是我的心情很乱。</p>\n<p>&emsp;&emsp;我睡在实验室，不太想回那熟悉而又陌生的宿舍。但我又不能在实验室睡得太懒，我不想把我“可爱”的睡姿展现给大家。所以我还是决定回到宿舍小憩。</p>\n<p>&emsp;&emsp;我熟练地掏出钥匙串，在其中捡出开挂锁的那一把。虽然开过无数次们，但是我还是弄错了，我挑出的那把与挂锁钥匙很像，却不是。那把是四年前初到学校时留在我的书桌上的钥匙。</p>\n<p>&emsp;&emsp;我幻想过这把钥匙的各种幻想，也许它是开启某个密室门的钥匙，也许它可以打开一个惊天动地的秘密。于是我把它套在了我的钥匙串上，随身携带了四年，幻想了四年。</p>\n<p>&emsp;&emsp;今天这个幻想破了，梦也该醒了。除了增加钥匙串重量，让我弄混开锁钥匙，它几乎没有任何作用。</p>\n<p>&emsp;&emsp;突然想起，似乎我却没有过什么梦。不知自己这二十几年来在做什么，像个孩子。</p>\n<p>&emsp;&emsp;也许只是因为身边的许多相处日长的好朋友的离开导致我的突然地不清醒，可笑。</p>\n<p>&emsp;&emsp;也许再过些时日，这股孩子气就会随着我们逐渐退化的记忆慢慢消散，寥无痕迹。</p>\n<p>&emsp;&emsp;猪妖，该干什么，干什么去！</p>\n<p>&emsp;&emsp;美孚，希尔顿……</p>\n<p>&emsp;&emsp;忽而又发现，我整天都在梦里面。</p>\n","related_posts":[],"length":686,"excerpt":"","more":"<p>&emsp;&emsp;很难描述这几日的天气怎样，事实上无论外面的天气如何与我无干。</p>\n<p>&emsp;&emsp;出门的时候我也没有翻皇历，因为我没有皇历可翻。</p>\n<p>&emsp;&emsp;不管是天气还是皇历，所有事情只有了人的意识的参与才会有意义。</p>\n<p>&emsp;&emsp;当然我不是说我的意识在飘散。而是我的心情很乱。</p>\n<p>&emsp;&emsp;我睡在实验室，不太想回那熟悉而又陌生的宿舍。但我又不能在实验室睡得太懒，我不想把我“可爱”的睡姿展现给大家。所以我还是决定回到宿舍小憩。</p>\n<p>&emsp;&emsp;我熟练地掏出钥匙串，在其中捡出开挂锁的那一把。虽然开过无数次们，但是我还是弄错了，我挑出的那把与挂锁钥匙很像，却不是。那把是四年前初到学校时留在我的书桌上的钥匙。</p>\n<p>&emsp;&emsp;我幻想过这把钥匙的各种幻想，也许它是开启某个密室门的钥匙，也许它可以打开一个惊天动地的秘密。于是我把它套在了我的钥匙串上，随身携带了四年，幻想了四年。</p>\n<p>&emsp;&emsp;今天这个幻想破了，梦也该醒了。除了增加钥匙串重量，让我弄混开锁钥匙，它几乎没有任何作用。</p>\n<p>&emsp;&emsp;突然想起，似乎我却没有过什么梦。不知自己这二十几年来在做什么，像个孩子。</p>\n<p>&emsp;&emsp;也许只是因为身边的许多相处日长的好朋友的离开导致我的突然地不清醒，可笑。</p>\n<p>&emsp;&emsp;也许再过些时日，这股孩子气就会随着我们逐渐退化的记忆慢慢消散，寥无痕迹。</p>\n<p>&emsp;&emsp;猪妖，该干什么，干什么去！</p>\n<p>&emsp;&emsp;美孚，希尔顿……</p>\n<p>&emsp;&emsp;忽而又发现，我整天都在梦里面。</p>\n"},{"title":"mist","abbrlink":42985,"date":"2009-08-18T05:40:47.000Z","_content":"\n&emsp;&emsp;看了许多的电影，不知怎么的老喜欢看电影。同学说，你看了那么多电影就没有想法吗？我说有。那么你为什么不把这些想法写下来呢？我说，说的对。于是我便回忆看过的电影，对有些有看法的电影说一说。\n\n&emsp;&emsp;这部电影是一年前同学下的，据说有科幻色彩，我对科幻比较敏感，于是就同他一起坐下来看了这部电影。\n\n&emsp;&emsp;倒是想不起来是自己的幻想，还是电影里面本来有的线索。说一座山上面的军事基地在进行机密实验，发生了可怕的事故。大概是打开了和另一个世界的联系的通道。另一个世界的迷雾从通道弥散开来。男主人公带着自己的儿子，到超市买东西。结果，不多久雾气就淹没了整个小镇。尖叫声从雾气中传来。大家都躲到了超市 里面。整个故事的大部分时间都在超市里发展。第一个怪物是在超市后门出现的，只是一只软软的有无数牙齿的触手。看不到它的全貌，但已经感觉到了恐怖，让人 起鸡皮疙瘩的恐怖。也许看不到才增添了几分恐怖的气氛。触手被男主人公用斧头砍掉了一只，另一个员工就惨了，他被触手拖到了迷雾里。    \n\n&emsp;&emsp;迷雾，看不到的恐怖才是最恐怖的。真正的恐怖却又来自人的内心。\n\n&emsp;&emsp;到了晚上又有可怕的大蚊子袭击超市，接着是吃蚊子的可怕飞龙。几个人死掉了。其中一个是被蚊子咬到中毒死的，她肿起来了，超恐怖。有部分人开始抗争，用各 种武器。后来超市逐渐分成了两部分人。一部分持积极态度主人公为代表，另一部分人是一个疯女人为代表。这部人持消极态度，认为是上帝的惩罚，有些是被疯女 人的言语蛊惑跟随她的，有些是见到了恐怖的镜像吓倒的。大概也就是反应社会上的各种人的生活态度吧！\n\n&emsp;&emsp;为救受伤的人，主人公带几个人冒着危和恐怖到旁边的药店取药。药店里面被恐怖的能够吐出强腐蚀性蛛丝的蜘蛛占领。几个人挂掉了。但是成功地拿到了药。\n\n&emsp;&emsp;为了出去寻求帮助，继续抗争，还是妥协任怪物宰割吞食的问题上两派人起了争执，疯女人被杀掉。\n\n&emsp;&emsp;主人公同自己的孩子，一个女士，一对老夫妻五人坐上了主人公的汽车奔驰在寻求帮助的路上，或者希望能逃离迷雾。途经主人公的家，已狼藉一片。主人公回想起 因为忘记修补窗户导致妻子枉死，痛苦不已。车周围还有体形巨大的怪兽行走，山摇地动。不久迷雾还没散，但是汽车已经没有油了。主人公手中有一把枪，但是只 有四颗子弹。为了不被怪物带走，忍受痛苦，大家都愿意自杀。但是子弹也不够。四声枪响过后。车上只剩主人公一人，万分痛苦。（主人答应不让怪物带走他的孩 子，他做到了）他叫喊着，你们这些怪物来吧，吃了我。他下车了，但是根本就没有了站起来的力气，他太悲痛了，因为他亲手杀死了自己的妻子和孩子。\n\n&emsp;&emsp;但此时，迷雾渐渐散去，只见军队开来，还有剩下的那些在超市里面的人。怪物都不见了。极为讽刺的是留下来的人都得救了，而出去寻求帮助的人却不是被怪物吃掉，而是自杀。人们在面对恐惧时以为勇敢就是出路，就是幸免。但在极端恐怖时，人们只能用自杀来了结。完。\n\n&emsp;&emsp;对于主人公杀死自己的孩子这一点我和同学的分歧比较大。要换作是我，我是觉不可能亲手杀掉自己的孩子的。但同学认为，与其看到孩子受罪，不如痛快的让他了结了痛苦，让罪都自己一个人受。\n\n&emsp;&emsp;整个剧几乎就不能看到比较大的怪物同人之间的战斗场面。怪物袭击人的场面也不多。唯一能看到比较大的是那触手。而被迷雾笼罩的城镇也给人一种窒息的感觉。 场景一直在超市里，用超市反应整个城镇。人们的心理，以及生存的态度表现的比较多，比较深刻。疯女人的消极以及煽动性的话语让你有种跳进电影把她杀掉的冲 动。多听她的话，也许活着的斗志都会被消磨。\n\n&emsp;&emsp;看完整部电影就感觉吃不下饭了。那只触手给人的恐怖感觉久久不能挥去，很沉闷，而世事的无常又带给我们对于自己的命运未知的恐惧。\n\n","source":"_posts/2009-08-18-mist.md","raw":"---\ntitle: mist\ncategories:\n  - 某日记\ntags:\n  - 电影\n  - 迷雾\nabbrlink: 42985\ndate: 2009-08-18 13:40:47\n---\n\n&emsp;&emsp;看了许多的电影，不知怎么的老喜欢看电影。同学说，你看了那么多电影就没有想法吗？我说有。那么你为什么不把这些想法写下来呢？我说，说的对。于是我便回忆看过的电影，对有些有看法的电影说一说。\n\n&emsp;&emsp;这部电影是一年前同学下的，据说有科幻色彩，我对科幻比较敏感，于是就同他一起坐下来看了这部电影。\n\n&emsp;&emsp;倒是想不起来是自己的幻想，还是电影里面本来有的线索。说一座山上面的军事基地在进行机密实验，发生了可怕的事故。大概是打开了和另一个世界的联系的通道。另一个世界的迷雾从通道弥散开来。男主人公带着自己的儿子，到超市买东西。结果，不多久雾气就淹没了整个小镇。尖叫声从雾气中传来。大家都躲到了超市 里面。整个故事的大部分时间都在超市里发展。第一个怪物是在超市后门出现的，只是一只软软的有无数牙齿的触手。看不到它的全貌，但已经感觉到了恐怖，让人 起鸡皮疙瘩的恐怖。也许看不到才增添了几分恐怖的气氛。触手被男主人公用斧头砍掉了一只，另一个员工就惨了，他被触手拖到了迷雾里。    \n\n&emsp;&emsp;迷雾，看不到的恐怖才是最恐怖的。真正的恐怖却又来自人的内心。\n\n&emsp;&emsp;到了晚上又有可怕的大蚊子袭击超市，接着是吃蚊子的可怕飞龙。几个人死掉了。其中一个是被蚊子咬到中毒死的，她肿起来了，超恐怖。有部分人开始抗争，用各 种武器。后来超市逐渐分成了两部分人。一部分持积极态度主人公为代表，另一部分人是一个疯女人为代表。这部人持消极态度，认为是上帝的惩罚，有些是被疯女 人的言语蛊惑跟随她的，有些是见到了恐怖的镜像吓倒的。大概也就是反应社会上的各种人的生活态度吧！\n\n&emsp;&emsp;为救受伤的人，主人公带几个人冒着危和恐怖到旁边的药店取药。药店里面被恐怖的能够吐出强腐蚀性蛛丝的蜘蛛占领。几个人挂掉了。但是成功地拿到了药。\n\n&emsp;&emsp;为了出去寻求帮助，继续抗争，还是妥协任怪物宰割吞食的问题上两派人起了争执，疯女人被杀掉。\n\n&emsp;&emsp;主人公同自己的孩子，一个女士，一对老夫妻五人坐上了主人公的汽车奔驰在寻求帮助的路上，或者希望能逃离迷雾。途经主人公的家，已狼藉一片。主人公回想起 因为忘记修补窗户导致妻子枉死，痛苦不已。车周围还有体形巨大的怪兽行走，山摇地动。不久迷雾还没散，但是汽车已经没有油了。主人公手中有一把枪，但是只 有四颗子弹。为了不被怪物带走，忍受痛苦，大家都愿意自杀。但是子弹也不够。四声枪响过后。车上只剩主人公一人，万分痛苦。（主人答应不让怪物带走他的孩 子，他做到了）他叫喊着，你们这些怪物来吧，吃了我。他下车了，但是根本就没有了站起来的力气，他太悲痛了，因为他亲手杀死了自己的妻子和孩子。\n\n&emsp;&emsp;但此时，迷雾渐渐散去，只见军队开来，还有剩下的那些在超市里面的人。怪物都不见了。极为讽刺的是留下来的人都得救了，而出去寻求帮助的人却不是被怪物吃掉，而是自杀。人们在面对恐惧时以为勇敢就是出路，就是幸免。但在极端恐怖时，人们只能用自杀来了结。完。\n\n&emsp;&emsp;对于主人公杀死自己的孩子这一点我和同学的分歧比较大。要换作是我，我是觉不可能亲手杀掉自己的孩子的。但同学认为，与其看到孩子受罪，不如痛快的让他了结了痛苦，让罪都自己一个人受。\n\n&emsp;&emsp;整个剧几乎就不能看到比较大的怪物同人之间的战斗场面。怪物袭击人的场面也不多。唯一能看到比较大的是那触手。而被迷雾笼罩的城镇也给人一种窒息的感觉。 场景一直在超市里，用超市反应整个城镇。人们的心理，以及生存的态度表现的比较多，比较深刻。疯女人的消极以及煽动性的话语让你有种跳进电影把她杀掉的冲 动。多听她的话，也许活着的斗志都会被消磨。\n\n&emsp;&emsp;看完整部电影就感觉吃不下饭了。那只触手给人的恐怖感觉久久不能挥去，很沉闷，而世事的无常又带给我们对于自己的命运未知的恐惧。\n\n","slug":"mist","published":1,"updated":"2024-05-26T14:17:36.844Z","comments":1,"layout":"post","photos":[],"_id":"cmh498ioj000qwvou8tn18cpn","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>&emsp;&emsp;看了许多的电影，不知怎么的老喜欢看电影。同学说，你看了那么多电影就没有想法吗？我说有。那么你为什么不把这些想法写下来呢？我说，说的对。于是我便回忆看过的电影，对有些有看法的电影说一说。</p>\n<p>&emsp;&emsp;这部电影是一年前同学下的，据说有科幻色彩，我对科幻比较敏感，于是就同他一起坐下来看了这部电影。</p>\n<p>&emsp;&emsp;倒是想不起来是自己的幻想，还是电影里面本来有的线索。说一座山上面的军事基地在进行机密实验，发生了可怕的事故。大概是打开了和另一个世界的联系的通道。另一个世界的迷雾从通道弥散开来。男主人公带着自己的儿子，到超市买东西。结果，不多久雾气就淹没了整个小镇。尖叫声从雾气中传来。大家都躲到了超市 里面。整个故事的大部分时间都在超市里发展。第一个怪物是在超市后门出现的，只是一只软软的有无数牙齿的触手。看不到它的全貌，但已经感觉到了恐怖，让人 起鸡皮疙瘩的恐怖。也许看不到才增添了几分恐怖的气氛。触手被男主人公用斧头砍掉了一只，另一个员工就惨了，他被触手拖到了迷雾里。    </p>\n<p>&emsp;&emsp;迷雾，看不到的恐怖才是最恐怖的。真正的恐怖却又来自人的内心。</p>\n<p>&emsp;&emsp;到了晚上又有可怕的大蚊子袭击超市，接着是吃蚊子的可怕飞龙。几个人死掉了。其中一个是被蚊子咬到中毒死的，她肿起来了，超恐怖。有部分人开始抗争，用各 种武器。后来超市逐渐分成了两部分人。一部分持积极态度主人公为代表，另一部分人是一个疯女人为代表。这部人持消极态度，认为是上帝的惩罚，有些是被疯女 人的言语蛊惑跟随她的，有些是见到了恐怖的镜像吓倒的。大概也就是反应社会上的各种人的生活态度吧！</p>\n<p>&emsp;&emsp;为救受伤的人，主人公带几个人冒着危和恐怖到旁边的药店取药。药店里面被恐怖的能够吐出强腐蚀性蛛丝的蜘蛛占领。几个人挂掉了。但是成功地拿到了药。</p>\n<p>&emsp;&emsp;为了出去寻求帮助，继续抗争，还是妥协任怪物宰割吞食的问题上两派人起了争执，疯女人被杀掉。</p>\n<p>&emsp;&emsp;主人公同自己的孩子，一个女士，一对老夫妻五人坐上了主人公的汽车奔驰在寻求帮助的路上，或者希望能逃离迷雾。途经主人公的家，已狼藉一片。主人公回想起 因为忘记修补窗户导致妻子枉死，痛苦不已。车周围还有体形巨大的怪兽行走，山摇地动。不久迷雾还没散，但是汽车已经没有油了。主人公手中有一把枪，但是只 有四颗子弹。为了不被怪物带走，忍受痛苦，大家都愿意自杀。但是子弹也不够。四声枪响过后。车上只剩主人公一人，万分痛苦。（主人答应不让怪物带走他的孩 子，他做到了）他叫喊着，你们这些怪物来吧，吃了我。他下车了，但是根本就没有了站起来的力气，他太悲痛了，因为他亲手杀死了自己的妻子和孩子。</p>\n<p>&emsp;&emsp;但此时，迷雾渐渐散去，只见军队开来，还有剩下的那些在超市里面的人。怪物都不见了。极为讽刺的是留下来的人都得救了，而出去寻求帮助的人却不是被怪物吃掉，而是自杀。人们在面对恐惧时以为勇敢就是出路，就是幸免。但在极端恐怖时，人们只能用自杀来了结。完。</p>\n<p>&emsp;&emsp;对于主人公杀死自己的孩子这一点我和同学的分歧比较大。要换作是我，我是觉不可能亲手杀掉自己的孩子的。但同学认为，与其看到孩子受罪，不如痛快的让他了结了痛苦，让罪都自己一个人受。</p>\n<p>&emsp;&emsp;整个剧几乎就不能看到比较大的怪物同人之间的战斗场面。怪物袭击人的场面也不多。唯一能看到比较大的是那触手。而被迷雾笼罩的城镇也给人一种窒息的感觉。 场景一直在超市里，用超市反应整个城镇。人们的心理，以及生存的态度表现的比较多，比较深刻。疯女人的消极以及煽动性的话语让你有种跳进电影把她杀掉的冲 动。多听她的话，也许活着的斗志都会被消磨。</p>\n<p>&emsp;&emsp;看完整部电影就感觉吃不下饭了。那只触手给人的恐怖感觉久久不能挥去，很沉闷，而世事的无常又带给我们对于自己的命运未知的恐惧。</p>\n","related_posts":[],"length":1614,"excerpt":"","more":"<p>&emsp;&emsp;看了许多的电影，不知怎么的老喜欢看电影。同学说，你看了那么多电影就没有想法吗？我说有。那么你为什么不把这些想法写下来呢？我说，说的对。于是我便回忆看过的电影，对有些有看法的电影说一说。</p>\n<p>&emsp;&emsp;这部电影是一年前同学下的，据说有科幻色彩，我对科幻比较敏感，于是就同他一起坐下来看了这部电影。</p>\n<p>&emsp;&emsp;倒是想不起来是自己的幻想，还是电影里面本来有的线索。说一座山上面的军事基地在进行机密实验，发生了可怕的事故。大概是打开了和另一个世界的联系的通道。另一个世界的迷雾从通道弥散开来。男主人公带着自己的儿子，到超市买东西。结果，不多久雾气就淹没了整个小镇。尖叫声从雾气中传来。大家都躲到了超市 里面。整个故事的大部分时间都在超市里发展。第一个怪物是在超市后门出现的，只是一只软软的有无数牙齿的触手。看不到它的全貌，但已经感觉到了恐怖，让人 起鸡皮疙瘩的恐怖。也许看不到才增添了几分恐怖的气氛。触手被男主人公用斧头砍掉了一只，另一个员工就惨了，他被触手拖到了迷雾里。    </p>\n<p>&emsp;&emsp;迷雾，看不到的恐怖才是最恐怖的。真正的恐怖却又来自人的内心。</p>\n<p>&emsp;&emsp;到了晚上又有可怕的大蚊子袭击超市，接着是吃蚊子的可怕飞龙。几个人死掉了。其中一个是被蚊子咬到中毒死的，她肿起来了，超恐怖。有部分人开始抗争，用各 种武器。后来超市逐渐分成了两部分人。一部分持积极态度主人公为代表，另一部分人是一个疯女人为代表。这部人持消极态度，认为是上帝的惩罚，有些是被疯女 人的言语蛊惑跟随她的，有些是见到了恐怖的镜像吓倒的。大概也就是反应社会上的各种人的生活态度吧！</p>\n<p>&emsp;&emsp;为救受伤的人，主人公带几个人冒着危和恐怖到旁边的药店取药。药店里面被恐怖的能够吐出强腐蚀性蛛丝的蜘蛛占领。几个人挂掉了。但是成功地拿到了药。</p>\n<p>&emsp;&emsp;为了出去寻求帮助，继续抗争，还是妥协任怪物宰割吞食的问题上两派人起了争执，疯女人被杀掉。</p>\n<p>&emsp;&emsp;主人公同自己的孩子，一个女士，一对老夫妻五人坐上了主人公的汽车奔驰在寻求帮助的路上，或者希望能逃离迷雾。途经主人公的家，已狼藉一片。主人公回想起 因为忘记修补窗户导致妻子枉死，痛苦不已。车周围还有体形巨大的怪兽行走，山摇地动。不久迷雾还没散，但是汽车已经没有油了。主人公手中有一把枪，但是只 有四颗子弹。为了不被怪物带走，忍受痛苦，大家都愿意自杀。但是子弹也不够。四声枪响过后。车上只剩主人公一人，万分痛苦。（主人答应不让怪物带走他的孩 子，他做到了）他叫喊着，你们这些怪物来吧，吃了我。他下车了，但是根本就没有了站起来的力气，他太悲痛了，因为他亲手杀死了自己的妻子和孩子。</p>\n<p>&emsp;&emsp;但此时，迷雾渐渐散去，只见军队开来，还有剩下的那些在超市里面的人。怪物都不见了。极为讽刺的是留下来的人都得救了，而出去寻求帮助的人却不是被怪物吃掉，而是自杀。人们在面对恐惧时以为勇敢就是出路，就是幸免。但在极端恐怖时，人们只能用自杀来了结。完。</p>\n<p>&emsp;&emsp;对于主人公杀死自己的孩子这一点我和同学的分歧比较大。要换作是我，我是觉不可能亲手杀掉自己的孩子的。但同学认为，与其看到孩子受罪，不如痛快的让他了结了痛苦，让罪都自己一个人受。</p>\n<p>&emsp;&emsp;整个剧几乎就不能看到比较大的怪物同人之间的战斗场面。怪物袭击人的场面也不多。唯一能看到比较大的是那触手。而被迷雾笼罩的城镇也给人一种窒息的感觉。 场景一直在超市里，用超市反应整个城镇。人们的心理，以及生存的态度表现的比较多，比较深刻。疯女人的消极以及煽动性的话语让你有种跳进电影把她杀掉的冲 动。多听她的话，也许活着的斗志都会被消磨。</p>\n<p>&emsp;&emsp;看完整部电影就感觉吃不下饭了。那只触手给人的恐怖感觉久久不能挥去，很沉闷，而世事的无常又带给我们对于自己的命运未知的恐惧。</p>\n"},{"title":"发霉了","abbrlink":12640,"date":"2009-10-30T11:49:24.000Z","_content":"\n&emsp;&emsp;你知道吗？我快发霉了。\n\n&emsp;&emsp;不是身上长出灰绿色毛茸茸真菌的那钟发霉，而是从里面来的。就像脑子里可以长出蘑菇一样，不能长出灯泡了。\n\n&emsp;&emsp;我骑了自行车去吃晚饭，我已经太久没有动。我骑的很慢，比晚饭过后散步的老奶奶还要慢。吃饭的人很多，正是吃饭的时候。在饭堂门口挺车的时候差一点就撞到背后驶来的一个小伙，真是的，连身体的灵敏度都降低了。但是为什么又不让我撞到？最好撞到一个漂亮女孩儿（在做梦啦……）！吃晚饭只花了我十分钟。不要误会，我不是吃不下，只是平时吃饭都是这个速度。似乎吃得有些快啊，不过吃饭就专心吃饭咯，本没有其他事做，本不应该做其他事情。\n\n&emsp;&emsp;我骑上自行车，沿着平时去往实验室的路骑，骑的比饭后散步的老公公还要慢。\n\n&emsp;&emsp;我骑到了校园的最北边的北门。外面就是吵闹的街，车辆过往飞驰。天哪，我连学校都不敢出去，我是怎么了？我在原地来回骑了许多个圈，我也记不得有多少个圈。外面的吵闹声声声入耳，心里的喧哗却是蠢蠢欲动喷薄欲出。但是我脑子里什么都没有。我沿着另一条与之前平行的路返回。如果每个人都是一条直线，哇噻，世上那么多的线，我们居然能够有交点，那真是奇迹。剩下的线当然不能说都是平行的，更多的是处于不同平面的。我觉得平行的和有交点的同样难得啊！\n\n&emsp;&emsp;有时我喜欢用眼睛盯住朝我走来的每一个人，直到他们都胆怯的转移视线，有时我却害怕见到任何一双眼睛，我只低着头看我路。但很多时候我找不到自己的路。而今天我选择低头看我自己的路。\n\n&emsp;&emsp;我骑到了校园的最南面。\n\n&emsp;&emsp;突然不知道我出来是干啥的了。\n\n","source":"_posts/2009-10-30-发霉了.md","raw":"---\ntitle: 发霉了\ncategories:\n  - 日记\ntags:\nabbrlink: 12640\ndate: 2009-10-30 19:49:24\n---\n\n&emsp;&emsp;你知道吗？我快发霉了。\n\n&emsp;&emsp;不是身上长出灰绿色毛茸茸真菌的那钟发霉，而是从里面来的。就像脑子里可以长出蘑菇一样，不能长出灯泡了。\n\n&emsp;&emsp;我骑了自行车去吃晚饭，我已经太久没有动。我骑的很慢，比晚饭过后散步的老奶奶还要慢。吃饭的人很多，正是吃饭的时候。在饭堂门口挺车的时候差一点就撞到背后驶来的一个小伙，真是的，连身体的灵敏度都降低了。但是为什么又不让我撞到？最好撞到一个漂亮女孩儿（在做梦啦……）！吃晚饭只花了我十分钟。不要误会，我不是吃不下，只是平时吃饭都是这个速度。似乎吃得有些快啊，不过吃饭就专心吃饭咯，本没有其他事做，本不应该做其他事情。\n\n&emsp;&emsp;我骑上自行车，沿着平时去往实验室的路骑，骑的比饭后散步的老公公还要慢。\n\n&emsp;&emsp;我骑到了校园的最北边的北门。外面就是吵闹的街，车辆过往飞驰。天哪，我连学校都不敢出去，我是怎么了？我在原地来回骑了许多个圈，我也记不得有多少个圈。外面的吵闹声声声入耳，心里的喧哗却是蠢蠢欲动喷薄欲出。但是我脑子里什么都没有。我沿着另一条与之前平行的路返回。如果每个人都是一条直线，哇噻，世上那么多的线，我们居然能够有交点，那真是奇迹。剩下的线当然不能说都是平行的，更多的是处于不同平面的。我觉得平行的和有交点的同样难得啊！\n\n&emsp;&emsp;有时我喜欢用眼睛盯住朝我走来的每一个人，直到他们都胆怯的转移视线，有时我却害怕见到任何一双眼睛，我只低着头看我路。但很多时候我找不到自己的路。而今天我选择低头看我自己的路。\n\n&emsp;&emsp;我骑到了校园的最南面。\n\n&emsp;&emsp;突然不知道我出来是干啥的了。\n\n","slug":"发霉了","published":1,"updated":"2024-05-26T14:17:36.844Z","comments":1,"layout":"post","photos":[],"_id":"cmh498iok000twvouctii41yt","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>&emsp;&emsp;你知道吗？我快发霉了。</p>\n<p>&emsp;&emsp;不是身上长出灰绿色毛茸茸真菌的那钟发霉，而是从里面来的。就像脑子里可以长出蘑菇一样，不能长出灯泡了。</p>\n<p>&emsp;&emsp;我骑了自行车去吃晚饭，我已经太久没有动。我骑的很慢，比晚饭过后散步的老奶奶还要慢。吃饭的人很多，正是吃饭的时候。在饭堂门口挺车的时候差一点就撞到背后驶来的一个小伙，真是的，连身体的灵敏度都降低了。但是为什么又不让我撞到？最好撞到一个漂亮女孩儿（在做梦啦……）！吃晚饭只花了我十分钟。不要误会，我不是吃不下，只是平时吃饭都是这个速度。似乎吃得有些快啊，不过吃饭就专心吃饭咯，本没有其他事做，本不应该做其他事情。</p>\n<p>&emsp;&emsp;我骑上自行车，沿着平时去往实验室的路骑，骑的比饭后散步的老公公还要慢。</p>\n<p>&emsp;&emsp;我骑到了校园的最北边的北门。外面就是吵闹的街，车辆过往飞驰。天哪，我连学校都不敢出去，我是怎么了？我在原地来回骑了许多个圈，我也记不得有多少个圈。外面的吵闹声声声入耳，心里的喧哗却是蠢蠢欲动喷薄欲出。但是我脑子里什么都没有。我沿着另一条与之前平行的路返回。如果每个人都是一条直线，哇噻，世上那么多的线，我们居然能够有交点，那真是奇迹。剩下的线当然不能说都是平行的，更多的是处于不同平面的。我觉得平行的和有交点的同样难得啊！</p>\n<p>&emsp;&emsp;有时我喜欢用眼睛盯住朝我走来的每一个人，直到他们都胆怯的转移视线，有时我却害怕见到任何一双眼睛，我只低着头看我路。但很多时候我找不到自己的路。而今天我选择低头看我自己的路。</p>\n<p>&emsp;&emsp;我骑到了校园的最南面。</p>\n<p>&emsp;&emsp;突然不知道我出来是干啥的了。</p>\n","related_posts":[],"length":718,"excerpt":"","more":"<p>&emsp;&emsp;你知道吗？我快发霉了。</p>\n<p>&emsp;&emsp;不是身上长出灰绿色毛茸茸真菌的那钟发霉，而是从里面来的。就像脑子里可以长出蘑菇一样，不能长出灯泡了。</p>\n<p>&emsp;&emsp;我骑了自行车去吃晚饭，我已经太久没有动。我骑的很慢，比晚饭过后散步的老奶奶还要慢。吃饭的人很多，正是吃饭的时候。在饭堂门口挺车的时候差一点就撞到背后驶来的一个小伙，真是的，连身体的灵敏度都降低了。但是为什么又不让我撞到？最好撞到一个漂亮女孩儿（在做梦啦……）！吃晚饭只花了我十分钟。不要误会，我不是吃不下，只是平时吃饭都是这个速度。似乎吃得有些快啊，不过吃饭就专心吃饭咯，本没有其他事做，本不应该做其他事情。</p>\n<p>&emsp;&emsp;我骑上自行车，沿着平时去往实验室的路骑，骑的比饭后散步的老公公还要慢。</p>\n<p>&emsp;&emsp;我骑到了校园的最北边的北门。外面就是吵闹的街，车辆过往飞驰。天哪，我连学校都不敢出去，我是怎么了？我在原地来回骑了许多个圈，我也记不得有多少个圈。外面的吵闹声声声入耳，心里的喧哗却是蠢蠢欲动喷薄欲出。但是我脑子里什么都没有。我沿着另一条与之前平行的路返回。如果每个人都是一条直线，哇噻，世上那么多的线，我们居然能够有交点，那真是奇迹。剩下的线当然不能说都是平行的，更多的是处于不同平面的。我觉得平行的和有交点的同样难得啊！</p>\n<p>&emsp;&emsp;有时我喜欢用眼睛盯住朝我走来的每一个人，直到他们都胆怯的转移视线，有时我却害怕见到任何一双眼睛，我只低着头看我路。但很多时候我找不到自己的路。而今天我选择低头看我自己的路。</p>\n<p>&emsp;&emsp;我骑到了校园的最南面。</p>\n<p>&emsp;&emsp;突然不知道我出来是干啥的了。</p>\n"},{"title":"流水一","abbrlink":40187,"date":"2009-11-20T13:53:20.000Z","_content":"\n&emsp;&emsp;10点半起的床，哇，疯了。我应该没有那么懒吧！\n\n&emsp;&emsp;睁开眼，看表，掀开被子，穿衣服，穿裤子，下床，开电脑，嗯，我肯定是疯了，下床的第一件事居然是开电脑。大伙儿都起床了，估计是我起床的声音把他们弄醒了，或者他们找到了起床的借口，反正大伙儿相继都起来了，在10分钟之内。呵呵，我都不知道开电脑干啥。还是去洗漱吧！说来就怪了，大胡子的头发睡了觉起来怎么就一点也不乱，还是那么飘逸，而我的，居然被说Q，被说成是了超级赛亚人。\n\n&emsp;&emsp;吃饭去了。大胡骑自行车。据说是要理财去，不过听说3个月利润6块钱，于是决定，还是吃饭实在。桃李哦，最近，就近原则，我喜欢。资源最省。二楼，吃烤鸭，嗯，每次吃烤鸭都会觉得满足，吃饭时什么都不想。对了，还有两只懒猪在宿舍呢。我负责帮他们带饭。“党员该做的事呀！”嘿嘿。\n\n&emsp;&emsp;吃过饭，啊，看到了不该看到的东西。双腿岔开坐在大胡的自行车后座，哇，我完了，长不大了。\n\n&emsp;&emsp;我又窝到宿舍了，作啥？嗯，看heroes.s04.e10，昨天看过的，只是没有字幕，看懂了80％的样子。samule的能力，sylor哪里去了，莫非是在peter身上，peter怎么变得那么差劲，还有hiro，哇，这个剧乱得就跟我的生活一样。不对，我的生活应该是简单到令人难以想象才对。编程啊，哦……我的笔记在实验室，好借口哦……\n\n&emsp;&emsp;看犬夜叉啦，和小白一起看。背后的大胡看什么“黑椒”，我们看犬夜叉的时候一直在说，阿细啊，不要看犬夜叉了，这么“清纯”的，来，和我一起看口味重的黑椒。呵呵，无聊。口味重了受不起。\n\n&emsp;&emsp;这个时候要是有瓜子磕该多好，小白说。好啊，我们去买怎么样？我看到他穿的是一双拖鞋，还是我去买吧！听到你说这话真是太好了，待会儿回来我们玩游戏。\n\n&emsp;&emsp;我去买东西啦。不过我向来不怎么吃零食的，买啥？瓜子，麻花，山楂，橘子，香蕉，嗯！\n\n&emsp;&emsp;dota，死红红，居然要上网打AI，好吧，奉陪了。\n\n&emsp;&emsp;两盘，哦，我的麻花，都被小白洗啦！\n\n&emsp;&emsp;吃饭……小白消失了？超哥，后后，红红，糟了，there suppose to be another one，不会吧！这也能忘，他吃的是黄豆，嗯，这个绝对没有记错。我的记性啊……\n\n&emsp;&emsp;又见桃李，又吃烤鸭，明明刷了卡，大妈却诬我，理亏了吧，全是骨头，呃，一点感觉都没有了，完全找不到满足感。\n\n&emsp;&emsp;开会，班委会。活动，选举。\n\n&emsp;&emsp;日志中，切莫打扰，哎……我在做什么？编程，作业，不懂的东西……\n\n&emsp;&emsp;加油^\\_^\n\n","source":"_posts/2009-11-20-流水一.md","raw":"---\ntitle: 流水一\ncategories:\n  - 日记\ntags:\nabbrlink: 40187\ndate: 2009-11-20 21:53:20\n---\n\n&emsp;&emsp;10点半起的床，哇，疯了。我应该没有那么懒吧！\n\n&emsp;&emsp;睁开眼，看表，掀开被子，穿衣服，穿裤子，下床，开电脑，嗯，我肯定是疯了，下床的第一件事居然是开电脑。大伙儿都起床了，估计是我起床的声音把他们弄醒了，或者他们找到了起床的借口，反正大伙儿相继都起来了，在10分钟之内。呵呵，我都不知道开电脑干啥。还是去洗漱吧！说来就怪了，大胡子的头发睡了觉起来怎么就一点也不乱，还是那么飘逸，而我的，居然被说Q，被说成是了超级赛亚人。\n\n&emsp;&emsp;吃饭去了。大胡骑自行车。据说是要理财去，不过听说3个月利润6块钱，于是决定，还是吃饭实在。桃李哦，最近，就近原则，我喜欢。资源最省。二楼，吃烤鸭，嗯，每次吃烤鸭都会觉得满足，吃饭时什么都不想。对了，还有两只懒猪在宿舍呢。我负责帮他们带饭。“党员该做的事呀！”嘿嘿。\n\n&emsp;&emsp;吃过饭，啊，看到了不该看到的东西。双腿岔开坐在大胡的自行车后座，哇，我完了，长不大了。\n\n&emsp;&emsp;我又窝到宿舍了，作啥？嗯，看heroes.s04.e10，昨天看过的，只是没有字幕，看懂了80％的样子。samule的能力，sylor哪里去了，莫非是在peter身上，peter怎么变得那么差劲，还有hiro，哇，这个剧乱得就跟我的生活一样。不对，我的生活应该是简单到令人难以想象才对。编程啊，哦……我的笔记在实验室，好借口哦……\n\n&emsp;&emsp;看犬夜叉啦，和小白一起看。背后的大胡看什么“黑椒”，我们看犬夜叉的时候一直在说，阿细啊，不要看犬夜叉了，这么“清纯”的，来，和我一起看口味重的黑椒。呵呵，无聊。口味重了受不起。\n\n&emsp;&emsp;这个时候要是有瓜子磕该多好，小白说。好啊，我们去买怎么样？我看到他穿的是一双拖鞋，还是我去买吧！听到你说这话真是太好了，待会儿回来我们玩游戏。\n\n&emsp;&emsp;我去买东西啦。不过我向来不怎么吃零食的，买啥？瓜子，麻花，山楂，橘子，香蕉，嗯！\n\n&emsp;&emsp;dota，死红红，居然要上网打AI，好吧，奉陪了。\n\n&emsp;&emsp;两盘，哦，我的麻花，都被小白洗啦！\n\n&emsp;&emsp;吃饭……小白消失了？超哥，后后，红红，糟了，there suppose to be another one，不会吧！这也能忘，他吃的是黄豆，嗯，这个绝对没有记错。我的记性啊……\n\n&emsp;&emsp;又见桃李，又吃烤鸭，明明刷了卡，大妈却诬我，理亏了吧，全是骨头，呃，一点感觉都没有了，完全找不到满足感。\n\n&emsp;&emsp;开会，班委会。活动，选举。\n\n&emsp;&emsp;日志中，切莫打扰，哎……我在做什么？编程，作业，不懂的东西……\n\n&emsp;&emsp;加油^\\_^\n\n","slug":"流水一","published":1,"updated":"2024-05-26T14:17:36.844Z","comments":1,"layout":"post","photos":[],"_id":"cmh498iol000xwvou8kwr49dq","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>&emsp;&emsp;10点半起的床，哇，疯了。我应该没有那么懒吧！</p>\n<p>&emsp;&emsp;睁开眼，看表，掀开被子，穿衣服，穿裤子，下床，开电脑，嗯，我肯定是疯了，下床的第一件事居然是开电脑。大伙儿都起床了，估计是我起床的声音把他们弄醒了，或者他们找到了起床的借口，反正大伙儿相继都起来了，在10分钟之内。呵呵，我都不知道开电脑干啥。还是去洗漱吧！说来就怪了，大胡子的头发睡了觉起来怎么就一点也不乱，还是那么飘逸，而我的，居然被说Q，被说成是了超级赛亚人。</p>\n<p>&emsp;&emsp;吃饭去了。大胡骑自行车。据说是要理财去，不过听说3个月利润6块钱，于是决定，还是吃饭实在。桃李哦，最近，就近原则，我喜欢。资源最省。二楼，吃烤鸭，嗯，每次吃烤鸭都会觉得满足，吃饭时什么都不想。对了，还有两只懒猪在宿舍呢。我负责帮他们带饭。“党员该做的事呀！”嘿嘿。</p>\n<p>&emsp;&emsp;吃过饭，啊，看到了不该看到的东西。双腿岔开坐在大胡的自行车后座，哇，我完了，长不大了。</p>\n<p>&emsp;&emsp;我又窝到宿舍了，作啥？嗯，看heroes.s04.e10，昨天看过的，只是没有字幕，看懂了80％的样子。samule的能力，sylor哪里去了，莫非是在peter身上，peter怎么变得那么差劲，还有hiro，哇，这个剧乱得就跟我的生活一样。不对，我的生活应该是简单到令人难以想象才对。编程啊，哦……我的笔记在实验室，好借口哦……</p>\n<p>&emsp;&emsp;看犬夜叉啦，和小白一起看。背后的大胡看什么“黑椒”，我们看犬夜叉的时候一直在说，阿细啊，不要看犬夜叉了，这么“清纯”的，来，和我一起看口味重的黑椒。呵呵，无聊。口味重了受不起。</p>\n<p>&emsp;&emsp;这个时候要是有瓜子磕该多好，小白说。好啊，我们去买怎么样？我看到他穿的是一双拖鞋，还是我去买吧！听到你说这话真是太好了，待会儿回来我们玩游戏。</p>\n<p>&emsp;&emsp;我去买东西啦。不过我向来不怎么吃零食的，买啥？瓜子，麻花，山楂，橘子，香蕉，嗯！</p>\n<p>&emsp;&emsp;dota，死红红，居然要上网打AI，好吧，奉陪了。</p>\n<p>&emsp;&emsp;两盘，哦，我的麻花，都被小白洗啦！</p>\n<p>&emsp;&emsp;吃饭……小白消失了？超哥，后后，红红，糟了，there suppose to be another one，不会吧！这也能忘，他吃的是黄豆，嗯，这个绝对没有记错。我的记性啊……</p>\n<p>&emsp;&emsp;又见桃李，又吃烤鸭，明明刷了卡，大妈却诬我，理亏了吧，全是骨头，呃，一点感觉都没有了，完全找不到满足感。</p>\n<p>&emsp;&emsp;开会，班委会。活动，选举。</p>\n<p>&emsp;&emsp;日志中，切莫打扰，哎……我在做什么？编程，作业，不懂的东西……</p>\n<p>&emsp;&emsp;加油^_^</p>\n","related_posts":[],"length":1150,"excerpt":"","more":"<p>&emsp;&emsp;10点半起的床，哇，疯了。我应该没有那么懒吧！</p>\n<p>&emsp;&emsp;睁开眼，看表，掀开被子，穿衣服，穿裤子，下床，开电脑，嗯，我肯定是疯了，下床的第一件事居然是开电脑。大伙儿都起床了，估计是我起床的声音把他们弄醒了，或者他们找到了起床的借口，反正大伙儿相继都起来了，在10分钟之内。呵呵，我都不知道开电脑干啥。还是去洗漱吧！说来就怪了，大胡子的头发睡了觉起来怎么就一点也不乱，还是那么飘逸，而我的，居然被说Q，被说成是了超级赛亚人。</p>\n<p>&emsp;&emsp;吃饭去了。大胡骑自行车。据说是要理财去，不过听说3个月利润6块钱，于是决定，还是吃饭实在。桃李哦，最近，就近原则，我喜欢。资源最省。二楼，吃烤鸭，嗯，每次吃烤鸭都会觉得满足，吃饭时什么都不想。对了，还有两只懒猪在宿舍呢。我负责帮他们带饭。“党员该做的事呀！”嘿嘿。</p>\n<p>&emsp;&emsp;吃过饭，啊，看到了不该看到的东西。双腿岔开坐在大胡的自行车后座，哇，我完了，长不大了。</p>\n<p>&emsp;&emsp;我又窝到宿舍了，作啥？嗯，看heroes.s04.e10，昨天看过的，只是没有字幕，看懂了80％的样子。samule的能力，sylor哪里去了，莫非是在peter身上，peter怎么变得那么差劲，还有hiro，哇，这个剧乱得就跟我的生活一样。不对，我的生活应该是简单到令人难以想象才对。编程啊，哦……我的笔记在实验室，好借口哦……</p>\n<p>&emsp;&emsp;看犬夜叉啦，和小白一起看。背后的大胡看什么“黑椒”，我们看犬夜叉的时候一直在说，阿细啊，不要看犬夜叉了，这么“清纯”的，来，和我一起看口味重的黑椒。呵呵，无聊。口味重了受不起。</p>\n<p>&emsp;&emsp;这个时候要是有瓜子磕该多好，小白说。好啊，我们去买怎么样？我看到他穿的是一双拖鞋，还是我去买吧！听到你说这话真是太好了，待会儿回来我们玩游戏。</p>\n<p>&emsp;&emsp;我去买东西啦。不过我向来不怎么吃零食的，买啥？瓜子，麻花，山楂，橘子，香蕉，嗯！</p>\n<p>&emsp;&emsp;dota，死红红，居然要上网打AI，好吧，奉陪了。</p>\n<p>&emsp;&emsp;两盘，哦，我的麻花，都被小白洗啦！</p>\n<p>&emsp;&emsp;吃饭……小白消失了？超哥，后后，红红，糟了，there suppose to be another one，不会吧！这也能忘，他吃的是黄豆，嗯，这个绝对没有记错。我的记性啊……</p>\n<p>&emsp;&emsp;又见桃李，又吃烤鸭，明明刷了卡，大妈却诬我，理亏了吧，全是骨头，呃，一点感觉都没有了，完全找不到满足感。</p>\n<p>&emsp;&emsp;开会，班委会。活动，选举。</p>\n<p>&emsp;&emsp;日志中，切莫打扰，哎……我在做什么？编程，作业，不懂的东西……</p>\n<p>&emsp;&emsp;加油^_^</p>\n"},{"title":"123","abbrlink":47620,"date":"2009-12-14T10:37:21.000Z","_content":"\n&emsp;&emsp;天下着小雨，早上出门的时候还没有下的。天气预报还是挺准的。\n\n&emsp;&emsp;我的实验室在10楼。本来打定主意每天都爬楼梯的。后来因为爬楼梯把膝盖给伤了，找了个借口说，每次爬楼梯都是刚吃了饭，刚吃了饭爬楼梯对胃肯定不好。于是还是成了一个耗费国家电力的家伙。\n\n&emsp;&emsp;在货梯旁边，洗漱池背后从一楼到十楼，至少是十楼打，打通了一个洞。从那里往下看，可以看到这个洞一直通到一楼。和站在窗口往外看不一样，从这里只能看到目眩，看不到美景，或者至少是活物。这个洞是大概一个月之前打通的。没有人知道是用来做什么的。我甚至觉得就着这个洞可以发生一系列离奇的盗窃、杀人案件。可是，什么都没有发生。直到今天。\n\n&emsp;&emsp;不好意思，不要误会，并不是今天真的发生了离奇的事件。而是一声声整齐的呐喊。1,2……3……\n\n&emsp;&emsp;几条黑色粗大的电缆线还是数据线的从天花板上面滑下来，躺在黢黑的走廊里面。经过时还以为是蠢蠢欲动的蟒蛇。还好天冷，衣服传的比较多，不至于吓出一身冷汗。走廊的东边，也就是洗漱池和货梯旁边围了一群人，大概有七八个人。衣服比较脏乱，或者至少上面有一层让人看不清的灰尘。他们手里握着那根不只是光缆还是电缆的黑粗绳子。他们的眼睛全注视着缆绳，完全没有看到我。我径直进了实验室。外面有节奏的响起“1，2，3……”以及一人用建议的口吻调整队形，增加士气的声音。\n\n&emsp;&emsp;不一会儿上课了。老师在黑板上狂书。我们在底下笔走游龙。教室就在实验室隔壁。外面的响声更盛。丝毫没有停歇的意思。身边同学似乎被这声音吵得无心听讲，无心做笔记了。因为他时不时地就会看时间。“怎么才过了两分种……”他叫道。我想起了《美丽心灵》里面纳什讲课，外面施工的情景。估计我们的老师的功力还没有纳什那么高。不知道我们之中有没有那么高功力的人。\n\n&emsp;&emsp;哦……我的思绪也飞走了。\n\n&emsp;&emsp;下课了。我不经意地仔细看了看缆绳。有好几股铜线组成，大概一个手掌勉强能握住。从一楼到十楼每层三米少说也三十米，三十米的缆绳哇，肯定重的要命。\n\n&emsp;&emsp;天气预报说今晚有小雪，明天有中雪。其实我都不知道我喜不喜欢下雪了。\n\n","source":"_posts/2009-12-14-123.md","raw":"---\ntitle: 123\ncategories:\n  - 日记\ntags:\nabbrlink: 47620\ndate: 2009-12-14 18:37:21\n---\n\n&emsp;&emsp;天下着小雨，早上出门的时候还没有下的。天气预报还是挺准的。\n\n&emsp;&emsp;我的实验室在10楼。本来打定主意每天都爬楼梯的。后来因为爬楼梯把膝盖给伤了，找了个借口说，每次爬楼梯都是刚吃了饭，刚吃了饭爬楼梯对胃肯定不好。于是还是成了一个耗费国家电力的家伙。\n\n&emsp;&emsp;在货梯旁边，洗漱池背后从一楼到十楼，至少是十楼打，打通了一个洞。从那里往下看，可以看到这个洞一直通到一楼。和站在窗口往外看不一样，从这里只能看到目眩，看不到美景，或者至少是活物。这个洞是大概一个月之前打通的。没有人知道是用来做什么的。我甚至觉得就着这个洞可以发生一系列离奇的盗窃、杀人案件。可是，什么都没有发生。直到今天。\n\n&emsp;&emsp;不好意思，不要误会，并不是今天真的发生了离奇的事件。而是一声声整齐的呐喊。1,2……3……\n\n&emsp;&emsp;几条黑色粗大的电缆线还是数据线的从天花板上面滑下来，躺在黢黑的走廊里面。经过时还以为是蠢蠢欲动的蟒蛇。还好天冷，衣服传的比较多，不至于吓出一身冷汗。走廊的东边，也就是洗漱池和货梯旁边围了一群人，大概有七八个人。衣服比较脏乱，或者至少上面有一层让人看不清的灰尘。他们手里握着那根不只是光缆还是电缆的黑粗绳子。他们的眼睛全注视着缆绳，完全没有看到我。我径直进了实验室。外面有节奏的响起“1，2，3……”以及一人用建议的口吻调整队形，增加士气的声音。\n\n&emsp;&emsp;不一会儿上课了。老师在黑板上狂书。我们在底下笔走游龙。教室就在实验室隔壁。外面的响声更盛。丝毫没有停歇的意思。身边同学似乎被这声音吵得无心听讲，无心做笔记了。因为他时不时地就会看时间。“怎么才过了两分种……”他叫道。我想起了《美丽心灵》里面纳什讲课，外面施工的情景。估计我们的老师的功力还没有纳什那么高。不知道我们之中有没有那么高功力的人。\n\n&emsp;&emsp;哦……我的思绪也飞走了。\n\n&emsp;&emsp;下课了。我不经意地仔细看了看缆绳。有好几股铜线组成，大概一个手掌勉强能握住。从一楼到十楼每层三米少说也三十米，三十米的缆绳哇，肯定重的要命。\n\n&emsp;&emsp;天气预报说今晚有小雪，明天有中雪。其实我都不知道我喜不喜欢下雪了。\n\n","slug":"123","published":1,"updated":"2024-05-26T14:17:36.845Z","comments":1,"layout":"post","photos":[],"_id":"cmh498iom0010wvoud4hp2qil","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>&emsp;&emsp;天下着小雨，早上出门的时候还没有下的。天气预报还是挺准的。</p>\n<p>&emsp;&emsp;我的实验室在10楼。本来打定主意每天都爬楼梯的。后来因为爬楼梯把膝盖给伤了，找了个借口说，每次爬楼梯都是刚吃了饭，刚吃了饭爬楼梯对胃肯定不好。于是还是成了一个耗费国家电力的家伙。</p>\n<p>&emsp;&emsp;在货梯旁边，洗漱池背后从一楼到十楼，至少是十楼打，打通了一个洞。从那里往下看，可以看到这个洞一直通到一楼。和站在窗口往外看不一样，从这里只能看到目眩，看不到美景，或者至少是活物。这个洞是大概一个月之前打通的。没有人知道是用来做什么的。我甚至觉得就着这个洞可以发生一系列离奇的盗窃、杀人案件。可是，什么都没有发生。直到今天。</p>\n<p>&emsp;&emsp;不好意思，不要误会，并不是今天真的发生了离奇的事件。而是一声声整齐的呐喊。1,2……3……</p>\n<p>&emsp;&emsp;几条黑色粗大的电缆线还是数据线的从天花板上面滑下来，躺在黢黑的走廊里面。经过时还以为是蠢蠢欲动的蟒蛇。还好天冷，衣服传的比较多，不至于吓出一身冷汗。走廊的东边，也就是洗漱池和货梯旁边围了一群人，大概有七八个人。衣服比较脏乱，或者至少上面有一层让人看不清的灰尘。他们手里握着那根不只是光缆还是电缆的黑粗绳子。他们的眼睛全注视着缆绳，完全没有看到我。我径直进了实验室。外面有节奏的响起“1，2，3……”以及一人用建议的口吻调整队形，增加士气的声音。</p>\n<p>&emsp;&emsp;不一会儿上课了。老师在黑板上狂书。我们在底下笔走游龙。教室就在实验室隔壁。外面的响声更盛。丝毫没有停歇的意思。身边同学似乎被这声音吵得无心听讲，无心做笔记了。因为他时不时地就会看时间。“怎么才过了两分种……”他叫道。我想起了《美丽心灵》里面纳什讲课，外面施工的情景。估计我们的老师的功力还没有纳什那么高。不知道我们之中有没有那么高功力的人。</p>\n<p>&emsp;&emsp;哦……我的思绪也飞走了。</p>\n<p>&emsp;&emsp;下课了。我不经意地仔细看了看缆绳。有好几股铜线组成，大概一个手掌勉强能握住。从一楼到十楼每层三米少说也三十米，三十米的缆绳哇，肯定重的要命。</p>\n<p>&emsp;&emsp;天气预报说今晚有小雪，明天有中雪。其实我都不知道我喜不喜欢下雪了。</p>\n","related_posts":[],"length":939,"excerpt":"","more":"<p>&emsp;&emsp;天下着小雨，早上出门的时候还没有下的。天气预报还是挺准的。</p>\n<p>&emsp;&emsp;我的实验室在10楼。本来打定主意每天都爬楼梯的。后来因为爬楼梯把膝盖给伤了，找了个借口说，每次爬楼梯都是刚吃了饭，刚吃了饭爬楼梯对胃肯定不好。于是还是成了一个耗费国家电力的家伙。</p>\n<p>&emsp;&emsp;在货梯旁边，洗漱池背后从一楼到十楼，至少是十楼打，打通了一个洞。从那里往下看，可以看到这个洞一直通到一楼。和站在窗口往外看不一样，从这里只能看到目眩，看不到美景，或者至少是活物。这个洞是大概一个月之前打通的。没有人知道是用来做什么的。我甚至觉得就着这个洞可以发生一系列离奇的盗窃、杀人案件。可是，什么都没有发生。直到今天。</p>\n<p>&emsp;&emsp;不好意思，不要误会，并不是今天真的发生了离奇的事件。而是一声声整齐的呐喊。1,2……3……</p>\n<p>&emsp;&emsp;几条黑色粗大的电缆线还是数据线的从天花板上面滑下来，躺在黢黑的走廊里面。经过时还以为是蠢蠢欲动的蟒蛇。还好天冷，衣服传的比较多，不至于吓出一身冷汗。走廊的东边，也就是洗漱池和货梯旁边围了一群人，大概有七八个人。衣服比较脏乱，或者至少上面有一层让人看不清的灰尘。他们手里握着那根不只是光缆还是电缆的黑粗绳子。他们的眼睛全注视着缆绳，完全没有看到我。我径直进了实验室。外面有节奏的响起“1，2，3……”以及一人用建议的口吻调整队形，增加士气的声音。</p>\n<p>&emsp;&emsp;不一会儿上课了。老师在黑板上狂书。我们在底下笔走游龙。教室就在实验室隔壁。外面的响声更盛。丝毫没有停歇的意思。身边同学似乎被这声音吵得无心听讲，无心做笔记了。因为他时不时地就会看时间。“怎么才过了两分种……”他叫道。我想起了《美丽心灵》里面纳什讲课，外面施工的情景。估计我们的老师的功力还没有纳什那么高。不知道我们之中有没有那么高功力的人。</p>\n<p>&emsp;&emsp;哦……我的思绪也飞走了。</p>\n<p>&emsp;&emsp;下课了。我不经意地仔细看了看缆绳。有好几股铜线组成，大概一个手掌勉强能握住。从一楼到十楼每层三米少说也三十米，三十米的缆绳哇，肯定重的要命。</p>\n<p>&emsp;&emsp;天气预报说今晚有小雪，明天有中雪。其实我都不知道我喜不喜欢下雪了。</p>\n"},{"title":"花木兰","abbrlink":47379,"date":"2009-12-19T05:55:32.000Z","_content":"\n&emsp;&emsp;《花木兰》是晚上7点放映，5点售票。师兄请客，我主动请缨去买票。\n\n&emsp;&emsp;基于上次《2012》售票形式的火爆，于是我决定早一点到大礼堂排队。3点40我已经到大礼堂了，结果一个人都没有，连门都锁着紧紧的。透明玻璃大门里面摆着一张大大的海报。手工书写的“花木兰”几个打字十分惹眼。\n\n&emsp;&emsp;一对情侣走过来，朝里望了望，然后开了另一扇门走了进去。呵呵，我居然没有看到那边的门是开着的。我跟着他们走了进去。坐在了东边角落的椅子上。中间有个茶几，对面就是那对情侣。他们窃窃私语着。我就一个没电，短线的电灯泡。我装作漠不关心的样子，慢慢从书包里掏出京极夏彦的《姑获鸟之夏》。书包里的书不少，能在这个时候用来打发时间的就只有这本了。是vincentc从图书馆借来刚看完的。据他描述，看完了以后，毛骨悚然却合情合理令人感伤。于是他就塞给了我，强烈推荐我看。\n\n&emsp;&emsp;我开始翻看关于读者京极夏彦的介绍。一般看书我都不会看这些，尤其是莫名其妙的一个名人对于这本书的长篇大论的序。这些序好像除了赞赏夸奖以外就没有其他内容。不过今天我答应来买票就是要考验一下自己的耐性，看看有没有退步。因为以前要是等上四五个小时我都还能耐得住，不过前一段时间似乎有些浮躁。我想看看我的浮躁到底到达了什么样的境界。\n\n&emsp;&emsp;于是我开始看京极夏彦的简介。这家伙简直不是“盖”的，简介里面把他说的跟个小说神似的。\n\n&emsp;&emsp;倒要看看他写的东西到底是什么，难道比《红楼梦》还厉害？\n\n&emsp;&emsp;开头感觉就很罗嗦。不过这种罗嗦对于长篇小说是必要的吧，这样才能把环境描述清楚。也许我的文学素养根本就和蚕翼一样薄，完全理解不了书中的深层次的语义。我看书的速度慢的跟蜗牛上树一样，都快四点半了，我就看了十多页。这时排队买票的人已经来了不少，大概有十几个了。而且已经排成了队，跃跃欲试。我赶紧装好了书准备也加入队伍。但是发现，手脚都快冻僵了。都怪今天的中午的太阳，我以为大地会给这阳光给考热，还特地脱了一件衣服，我想我一定是哪一根筋今天搭错了。\n\n&emsp;&emsp;我站在一个头挂耳机的家伙的后面，他在熟练的用老成的口吻打着电话。我又把书拿出来继续翻着。不一会儿我身后就串接了上百个形形色色的家伙。我可没有功夫来理会这些家伙的情况。因为我的手脚的冻僵了，我只好左脚换右脚的左右摇晃，来换取一些热量。可是这微弱的热量根本不足以让我的身体增加一点儿可测量的温度。\n\n&emsp;&emsp;前面挂耳机的家伙满口的川音，听起来很耳熟，但有不能确定认识。\n\n&emsp;&emsp;“如果温家宝有朱熔基那样的手腕就好了……”“他提出了环境保护，可是一点用都没有……”“未来中国的核电将占世界的60%”“如果上海人花200万买一套房子，还不如移民到加拿大。移民加拿大只要四五十万……”\n\n&emsp;&emsp;这家伙都在说些什么啊？似乎就是一个对中国社会了解得十分透彻的专家。\n\n&emsp;&emsp;功夫不负有心人啊！买票窗口终于在我冻僵之前打开了。我向买票的阿姨索要了22张票，差点塞了120块钱给她（每张5块。）。大家的视线都注视着我，看着我手上的两大版票，看得我怪不好意思的。\n\n&emsp;&emsp;《花木兰》开演了。整体还不错，除了一些比较雷的对白。花木兰，民族英雄，还有什么好说的。\n\n&emsp;&emsp;回到宿舍，我和小白又看起了《犬夜叉》。这几集故事太精彩，我们被故事情节深深地吸住了。\n\n&emsp;&emsp;白心上人是得道活佛，有那么高强的纯净法力。确仍然败给了死亡这道坎，从而憎恨世人憎恨世界。他哪里还有资格作佛。世上也没有一个完全的人，每个人心中总有善和恶。明白了这一点，白心上人成佛了，我们的心里也坦然了许多。\n\n","source":"_posts/2009-12-19-花木兰.md","raw":"---\ntitle: 花木兰\ncategories:\n  - 日记\ntags:\nabbrlink: 47379\ndate: 2009-12-19 13:55:32\n---\n\n&emsp;&emsp;《花木兰》是晚上7点放映，5点售票。师兄请客，我主动请缨去买票。\n\n&emsp;&emsp;基于上次《2012》售票形式的火爆，于是我决定早一点到大礼堂排队。3点40我已经到大礼堂了，结果一个人都没有，连门都锁着紧紧的。透明玻璃大门里面摆着一张大大的海报。手工书写的“花木兰”几个打字十分惹眼。\n\n&emsp;&emsp;一对情侣走过来，朝里望了望，然后开了另一扇门走了进去。呵呵，我居然没有看到那边的门是开着的。我跟着他们走了进去。坐在了东边角落的椅子上。中间有个茶几，对面就是那对情侣。他们窃窃私语着。我就一个没电，短线的电灯泡。我装作漠不关心的样子，慢慢从书包里掏出京极夏彦的《姑获鸟之夏》。书包里的书不少，能在这个时候用来打发时间的就只有这本了。是vincentc从图书馆借来刚看完的。据他描述，看完了以后，毛骨悚然却合情合理令人感伤。于是他就塞给了我，强烈推荐我看。\n\n&emsp;&emsp;我开始翻看关于读者京极夏彦的介绍。一般看书我都不会看这些，尤其是莫名其妙的一个名人对于这本书的长篇大论的序。这些序好像除了赞赏夸奖以外就没有其他内容。不过今天我答应来买票就是要考验一下自己的耐性，看看有没有退步。因为以前要是等上四五个小时我都还能耐得住，不过前一段时间似乎有些浮躁。我想看看我的浮躁到底到达了什么样的境界。\n\n&emsp;&emsp;于是我开始看京极夏彦的简介。这家伙简直不是“盖”的，简介里面把他说的跟个小说神似的。\n\n&emsp;&emsp;倒要看看他写的东西到底是什么，难道比《红楼梦》还厉害？\n\n&emsp;&emsp;开头感觉就很罗嗦。不过这种罗嗦对于长篇小说是必要的吧，这样才能把环境描述清楚。也许我的文学素养根本就和蚕翼一样薄，完全理解不了书中的深层次的语义。我看书的速度慢的跟蜗牛上树一样，都快四点半了，我就看了十多页。这时排队买票的人已经来了不少，大概有十几个了。而且已经排成了队，跃跃欲试。我赶紧装好了书准备也加入队伍。但是发现，手脚都快冻僵了。都怪今天的中午的太阳，我以为大地会给这阳光给考热，还特地脱了一件衣服，我想我一定是哪一根筋今天搭错了。\n\n&emsp;&emsp;我站在一个头挂耳机的家伙的后面，他在熟练的用老成的口吻打着电话。我又把书拿出来继续翻着。不一会儿我身后就串接了上百个形形色色的家伙。我可没有功夫来理会这些家伙的情况。因为我的手脚的冻僵了，我只好左脚换右脚的左右摇晃，来换取一些热量。可是这微弱的热量根本不足以让我的身体增加一点儿可测量的温度。\n\n&emsp;&emsp;前面挂耳机的家伙满口的川音，听起来很耳熟，但有不能确定认识。\n\n&emsp;&emsp;“如果温家宝有朱熔基那样的手腕就好了……”“他提出了环境保护，可是一点用都没有……”“未来中国的核电将占世界的60%”“如果上海人花200万买一套房子，还不如移民到加拿大。移民加拿大只要四五十万……”\n\n&emsp;&emsp;这家伙都在说些什么啊？似乎就是一个对中国社会了解得十分透彻的专家。\n\n&emsp;&emsp;功夫不负有心人啊！买票窗口终于在我冻僵之前打开了。我向买票的阿姨索要了22张票，差点塞了120块钱给她（每张5块。）。大家的视线都注视着我，看着我手上的两大版票，看得我怪不好意思的。\n\n&emsp;&emsp;《花木兰》开演了。整体还不错，除了一些比较雷的对白。花木兰，民族英雄，还有什么好说的。\n\n&emsp;&emsp;回到宿舍，我和小白又看起了《犬夜叉》。这几集故事太精彩，我们被故事情节深深地吸住了。\n\n&emsp;&emsp;白心上人是得道活佛，有那么高强的纯净法力。确仍然败给了死亡这道坎，从而憎恨世人憎恨世界。他哪里还有资格作佛。世上也没有一个完全的人，每个人心中总有善和恶。明白了这一点，白心上人成佛了，我们的心里也坦然了许多。\n\n","slug":"花木兰","published":1,"updated":"2024-05-26T14:17:36.845Z","comments":1,"layout":"post","photos":[],"_id":"cmh498ion0014wvou4gju31fu","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>&emsp;&emsp;《花木兰》是晚上7点放映，5点售票。师兄请客，我主动请缨去买票。</p>\n<p>&emsp;&emsp;基于上次《2012》售票形式的火爆，于是我决定早一点到大礼堂排队。3点40我已经到大礼堂了，结果一个人都没有，连门都锁着紧紧的。透明玻璃大门里面摆着一张大大的海报。手工书写的“花木兰”几个打字十分惹眼。</p>\n<p>&emsp;&emsp;一对情侣走过来，朝里望了望，然后开了另一扇门走了进去。呵呵，我居然没有看到那边的门是开着的。我跟着他们走了进去。坐在了东边角落的椅子上。中间有个茶几，对面就是那对情侣。他们窃窃私语着。我就一个没电，短线的电灯泡。我装作漠不关心的样子，慢慢从书包里掏出京极夏彦的《姑获鸟之夏》。书包里的书不少，能在这个时候用来打发时间的就只有这本了。是vincentc从图书馆借来刚看完的。据他描述，看完了以后，毛骨悚然却合情合理令人感伤。于是他就塞给了我，强烈推荐我看。</p>\n<p>&emsp;&emsp;我开始翻看关于读者京极夏彦的介绍。一般看书我都不会看这些，尤其是莫名其妙的一个名人对于这本书的长篇大论的序。这些序好像除了赞赏夸奖以外就没有其他内容。不过今天我答应来买票就是要考验一下自己的耐性，看看有没有退步。因为以前要是等上四五个小时我都还能耐得住，不过前一段时间似乎有些浮躁。我想看看我的浮躁到底到达了什么样的境界。</p>\n<p>&emsp;&emsp;于是我开始看京极夏彦的简介。这家伙简直不是“盖”的，简介里面把他说的跟个小说神似的。</p>\n<p>&emsp;&emsp;倒要看看他写的东西到底是什么，难道比《红楼梦》还厉害？</p>\n<p>&emsp;&emsp;开头感觉就很罗嗦。不过这种罗嗦对于长篇小说是必要的吧，这样才能把环境描述清楚。也许我的文学素养根本就和蚕翼一样薄，完全理解不了书中的深层次的语义。我看书的速度慢的跟蜗牛上树一样，都快四点半了，我就看了十多页。这时排队买票的人已经来了不少，大概有十几个了。而且已经排成了队，跃跃欲试。我赶紧装好了书准备也加入队伍。但是发现，手脚都快冻僵了。都怪今天的中午的太阳，我以为大地会给这阳光给考热，还特地脱了一件衣服，我想我一定是哪一根筋今天搭错了。</p>\n<p>&emsp;&emsp;我站在一个头挂耳机的家伙的后面，他在熟练的用老成的口吻打着电话。我又把书拿出来继续翻着。不一会儿我身后就串接了上百个形形色色的家伙。我可没有功夫来理会这些家伙的情况。因为我的手脚的冻僵了，我只好左脚换右脚的左右摇晃，来换取一些热量。可是这微弱的热量根本不足以让我的身体增加一点儿可测量的温度。</p>\n<p>&emsp;&emsp;前面挂耳机的家伙满口的川音，听起来很耳熟，但有不能确定认识。</p>\n<p>&emsp;&emsp;“如果温家宝有朱熔基那样的手腕就好了……”“他提出了环境保护，可是一点用都没有……”“未来中国的核电将占世界的60%”“如果上海人花200万买一套房子，还不如移民到加拿大。移民加拿大只要四五十万……”</p>\n<p>&emsp;&emsp;这家伙都在说些什么啊？似乎就是一个对中国社会了解得十分透彻的专家。</p>\n<p>&emsp;&emsp;功夫不负有心人啊！买票窗口终于在我冻僵之前打开了。我向买票的阿姨索要了22张票，差点塞了120块钱给她（每张5块。）。大家的视线都注视着我，看着我手上的两大版票，看得我怪不好意思的。</p>\n<p>&emsp;&emsp;《花木兰》开演了。整体还不错，除了一些比较雷的对白。花木兰，民族英雄，还有什么好说的。</p>\n<p>&emsp;&emsp;回到宿舍，我和小白又看起了《犬夜叉》。这几集故事太精彩，我们被故事情节深深地吸住了。</p>\n<p>&emsp;&emsp;白心上人是得道活佛，有那么高强的纯净法力。确仍然败给了死亡这道坎，从而憎恨世人憎恨世界。他哪里还有资格作佛。世上也没有一个完全的人，每个人心中总有善和恶。明白了这一点，白心上人成佛了，我们的心里也坦然了许多。</p>\n","related_posts":[],"length":1579,"excerpt":"","more":"<p>&emsp;&emsp;《花木兰》是晚上7点放映，5点售票。师兄请客，我主动请缨去买票。</p>\n<p>&emsp;&emsp;基于上次《2012》售票形式的火爆，于是我决定早一点到大礼堂排队。3点40我已经到大礼堂了，结果一个人都没有，连门都锁着紧紧的。透明玻璃大门里面摆着一张大大的海报。手工书写的“花木兰”几个打字十分惹眼。</p>\n<p>&emsp;&emsp;一对情侣走过来，朝里望了望，然后开了另一扇门走了进去。呵呵，我居然没有看到那边的门是开着的。我跟着他们走了进去。坐在了东边角落的椅子上。中间有个茶几，对面就是那对情侣。他们窃窃私语着。我就一个没电，短线的电灯泡。我装作漠不关心的样子，慢慢从书包里掏出京极夏彦的《姑获鸟之夏》。书包里的书不少，能在这个时候用来打发时间的就只有这本了。是vincentc从图书馆借来刚看完的。据他描述，看完了以后，毛骨悚然却合情合理令人感伤。于是他就塞给了我，强烈推荐我看。</p>\n<p>&emsp;&emsp;我开始翻看关于读者京极夏彦的介绍。一般看书我都不会看这些，尤其是莫名其妙的一个名人对于这本书的长篇大论的序。这些序好像除了赞赏夸奖以外就没有其他内容。不过今天我答应来买票就是要考验一下自己的耐性，看看有没有退步。因为以前要是等上四五个小时我都还能耐得住，不过前一段时间似乎有些浮躁。我想看看我的浮躁到底到达了什么样的境界。</p>\n<p>&emsp;&emsp;于是我开始看京极夏彦的简介。这家伙简直不是“盖”的，简介里面把他说的跟个小说神似的。</p>\n<p>&emsp;&emsp;倒要看看他写的东西到底是什么，难道比《红楼梦》还厉害？</p>\n<p>&emsp;&emsp;开头感觉就很罗嗦。不过这种罗嗦对于长篇小说是必要的吧，这样才能把环境描述清楚。也许我的文学素养根本就和蚕翼一样薄，完全理解不了书中的深层次的语义。我看书的速度慢的跟蜗牛上树一样，都快四点半了，我就看了十多页。这时排队买票的人已经来了不少，大概有十几个了。而且已经排成了队，跃跃欲试。我赶紧装好了书准备也加入队伍。但是发现，手脚都快冻僵了。都怪今天的中午的太阳，我以为大地会给这阳光给考热，还特地脱了一件衣服，我想我一定是哪一根筋今天搭错了。</p>\n<p>&emsp;&emsp;我站在一个头挂耳机的家伙的后面，他在熟练的用老成的口吻打着电话。我又把书拿出来继续翻着。不一会儿我身后就串接了上百个形形色色的家伙。我可没有功夫来理会这些家伙的情况。因为我的手脚的冻僵了，我只好左脚换右脚的左右摇晃，来换取一些热量。可是这微弱的热量根本不足以让我的身体增加一点儿可测量的温度。</p>\n<p>&emsp;&emsp;前面挂耳机的家伙满口的川音，听起来很耳熟，但有不能确定认识。</p>\n<p>&emsp;&emsp;“如果温家宝有朱熔基那样的手腕就好了……”“他提出了环境保护，可是一点用都没有……”“未来中国的核电将占世界的60%”“如果上海人花200万买一套房子，还不如移民到加拿大。移民加拿大只要四五十万……”</p>\n<p>&emsp;&emsp;这家伙都在说些什么啊？似乎就是一个对中国社会了解得十分透彻的专家。</p>\n<p>&emsp;&emsp;功夫不负有心人啊！买票窗口终于在我冻僵之前打开了。我向买票的阿姨索要了22张票，差点塞了120块钱给她（每张5块。）。大家的视线都注视着我，看着我手上的两大版票，看得我怪不好意思的。</p>\n<p>&emsp;&emsp;《花木兰》开演了。整体还不错，除了一些比较雷的对白。花木兰，民族英雄，还有什么好说的。</p>\n<p>&emsp;&emsp;回到宿舍，我和小白又看起了《犬夜叉》。这几集故事太精彩，我们被故事情节深深地吸住了。</p>\n<p>&emsp;&emsp;白心上人是得道活佛，有那么高强的纯净法力。确仍然败给了死亡这道坎，从而憎恨世人憎恨世界。他哪里还有资格作佛。世上也没有一个完全的人，每个人心中总有善和恶。明白了这一点，白心上人成佛了，我们的心里也坦然了许多。</p>\n"},{"title":"Dloc","abbrlink":13497,"date":"2009-12-23T11:01:36.000Z","_content":"\n&emsp;&emsp;我似乎又dloc了。我不是故意的。大概是因为上周末晚饭过后出去转了一转，还有昨晚也吹了吹冷风的缘故。\n\n&emsp;&emsp;Dloc对于我是司空见惯的了。我几乎没有什么大的病痛，除了初三摔断手壁，高三给自己狗咬到。dloc这种事情不到一个月就会有。或许是因为抵抗力差了些吧！老妈说我小时候三天两头就住院了，能挺过来还挺不容易。\n\n&emsp;&emsp;从小到大我记得的dloc症状大概就只有两种发展类型。一种就是狂流鼻涕，另一种是先喉咙痛，然后狂流鼻涕。\n\n&emsp;&emsp;几乎每次快到考试的时候就会dloc。我有时会怀疑是考试综合症。老妈说头发长了就会“变狗”。变狗的意思就是dloc，生病。我甚至想过用科学的方法来合理头发长了与dloc的关系。比如头发长了，免疫系统更新较慢等等。因为正如老妈讲的，每次我的头发长的时候都会dloc，但是我却找不到他们之间的关系。 \n\n&emsp;&emsp;记得最清楚的一次感冒考试是高一考数学。因为经受了初中老师的关于考试时间的观念，不管有没有把试卷做完都应该坐到考试结束。那天dloc正进入严重时期，爆发期。考试到一半的时候，我准备的纸巾已经被我的鼻涕吸完了。好吧，这的确比较恶心，随后当然就没有办法咯。我用一只手写着卷子，另一手拧着鼻子。那次的考试似乎有点简单，大家纷纷都提前离场了。大概提早了半个多小时，考场里面几乎就只有我和另外一个同学了。我仍然坚持着。坚持着把时间坐够。最后，监考老师说，你们还交不交的啊，不交我走了。要知道那个时候离考试结束还有十多分钟呢！我们只好把试卷交了。结束我拧鼻子的痛苦。\n\n&emsp;&emsp;食堂的苦瓜从来都没有炒熟过，苦的难以下咽。自从尝了第一次以后我便没有吃过第二次。如果食堂师傅做的苦瓜能有老妈做的那么好就太棒了。有一次dloc居然影响到了我的味觉，吃东西都没有味道。于是我就打了平时不敢吃的苦瓜。\n\n&emsp;&emsp;其实dloc对于现在的我一点影响都没有，除了可以成为我不去实验室的借口。\n\n&emsp;&emsp;也许dloc还能一点一点得侵蚀人的大脑，让人变得更傻。\n\n","source":"_posts/2009-12-23-Dloc.md","raw":"---\ntitle: Dloc\ncategories:\n  - 日记\ntags:\nabbrlink: 13497\ndate: 2009-12-23 19:01:36\n---\n\n&emsp;&emsp;我似乎又dloc了。我不是故意的。大概是因为上周末晚饭过后出去转了一转，还有昨晚也吹了吹冷风的缘故。\n\n&emsp;&emsp;Dloc对于我是司空见惯的了。我几乎没有什么大的病痛，除了初三摔断手壁，高三给自己狗咬到。dloc这种事情不到一个月就会有。或许是因为抵抗力差了些吧！老妈说我小时候三天两头就住院了，能挺过来还挺不容易。\n\n&emsp;&emsp;从小到大我记得的dloc症状大概就只有两种发展类型。一种就是狂流鼻涕，另一种是先喉咙痛，然后狂流鼻涕。\n\n&emsp;&emsp;几乎每次快到考试的时候就会dloc。我有时会怀疑是考试综合症。老妈说头发长了就会“变狗”。变狗的意思就是dloc，生病。我甚至想过用科学的方法来合理头发长了与dloc的关系。比如头发长了，免疫系统更新较慢等等。因为正如老妈讲的，每次我的头发长的时候都会dloc，但是我却找不到他们之间的关系。 \n\n&emsp;&emsp;记得最清楚的一次感冒考试是高一考数学。因为经受了初中老师的关于考试时间的观念，不管有没有把试卷做完都应该坐到考试结束。那天dloc正进入严重时期，爆发期。考试到一半的时候，我准备的纸巾已经被我的鼻涕吸完了。好吧，这的确比较恶心，随后当然就没有办法咯。我用一只手写着卷子，另一手拧着鼻子。那次的考试似乎有点简单，大家纷纷都提前离场了。大概提早了半个多小时，考场里面几乎就只有我和另外一个同学了。我仍然坚持着。坚持着把时间坐够。最后，监考老师说，你们还交不交的啊，不交我走了。要知道那个时候离考试结束还有十多分钟呢！我们只好把试卷交了。结束我拧鼻子的痛苦。\n\n&emsp;&emsp;食堂的苦瓜从来都没有炒熟过，苦的难以下咽。自从尝了第一次以后我便没有吃过第二次。如果食堂师傅做的苦瓜能有老妈做的那么好就太棒了。有一次dloc居然影响到了我的味觉，吃东西都没有味道。于是我就打了平时不敢吃的苦瓜。\n\n&emsp;&emsp;其实dloc对于现在的我一点影响都没有，除了可以成为我不去实验室的借口。\n\n&emsp;&emsp;也许dloc还能一点一点得侵蚀人的大脑，让人变得更傻。\n\n","slug":"Dloc","published":1,"updated":"2024-05-26T14:17:36.845Z","comments":1,"layout":"post","photos":[],"_id":"cmh498ion0017wvouhq2480i9","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>&emsp;&emsp;我似乎又dloc了。我不是故意的。大概是因为上周末晚饭过后出去转了一转，还有昨晚也吹了吹冷风的缘故。</p>\n<p>&emsp;&emsp;Dloc对于我是司空见惯的了。我几乎没有什么大的病痛，除了初三摔断手壁，高三给自己狗咬到。dloc这种事情不到一个月就会有。或许是因为抵抗力差了些吧！老妈说我小时候三天两头就住院了，能挺过来还挺不容易。</p>\n<p>&emsp;&emsp;从小到大我记得的dloc症状大概就只有两种发展类型。一种就是狂流鼻涕，另一种是先喉咙痛，然后狂流鼻涕。</p>\n<p>&emsp;&emsp;几乎每次快到考试的时候就会dloc。我有时会怀疑是考试综合症。老妈说头发长了就会“变狗”。变狗的意思就是dloc，生病。我甚至想过用科学的方法来合理头发长了与dloc的关系。比如头发长了，免疫系统更新较慢等等。因为正如老妈讲的，每次我的头发长的时候都会dloc，但是我却找不到他们之间的关系。 </p>\n<p>&emsp;&emsp;记得最清楚的一次感冒考试是高一考数学。因为经受了初中老师的关于考试时间的观念，不管有没有把试卷做完都应该坐到考试结束。那天dloc正进入严重时期，爆发期。考试到一半的时候，我准备的纸巾已经被我的鼻涕吸完了。好吧，这的确比较恶心，随后当然就没有办法咯。我用一只手写着卷子，另一手拧着鼻子。那次的考试似乎有点简单，大家纷纷都提前离场了。大概提早了半个多小时，考场里面几乎就只有我和另外一个同学了。我仍然坚持着。坚持着把时间坐够。最后，监考老师说，你们还交不交的啊，不交我走了。要知道那个时候离考试结束还有十多分钟呢！我们只好把试卷交了。结束我拧鼻子的痛苦。</p>\n<p>&emsp;&emsp;食堂的苦瓜从来都没有炒熟过，苦的难以下咽。自从尝了第一次以后我便没有吃过第二次。如果食堂师傅做的苦瓜能有老妈做的那么好就太棒了。有一次dloc居然影响到了我的味觉，吃东西都没有味道。于是我就打了平时不敢吃的苦瓜。</p>\n<p>&emsp;&emsp;其实dloc对于现在的我一点影响都没有，除了可以成为我不去实验室的借口。</p>\n<p>&emsp;&emsp;也许dloc还能一点一点得侵蚀人的大脑，让人变得更傻。</p>\n","related_posts":[],"length":889,"excerpt":"","more":"<p>&emsp;&emsp;我似乎又dloc了。我不是故意的。大概是因为上周末晚饭过后出去转了一转，还有昨晚也吹了吹冷风的缘故。</p>\n<p>&emsp;&emsp;Dloc对于我是司空见惯的了。我几乎没有什么大的病痛，除了初三摔断手壁，高三给自己狗咬到。dloc这种事情不到一个月就会有。或许是因为抵抗力差了些吧！老妈说我小时候三天两头就住院了，能挺过来还挺不容易。</p>\n<p>&emsp;&emsp;从小到大我记得的dloc症状大概就只有两种发展类型。一种就是狂流鼻涕，另一种是先喉咙痛，然后狂流鼻涕。</p>\n<p>&emsp;&emsp;几乎每次快到考试的时候就会dloc。我有时会怀疑是考试综合症。老妈说头发长了就会“变狗”。变狗的意思就是dloc，生病。我甚至想过用科学的方法来合理头发长了与dloc的关系。比如头发长了，免疫系统更新较慢等等。因为正如老妈讲的，每次我的头发长的时候都会dloc，但是我却找不到他们之间的关系。 </p>\n<p>&emsp;&emsp;记得最清楚的一次感冒考试是高一考数学。因为经受了初中老师的关于考试时间的观念，不管有没有把试卷做完都应该坐到考试结束。那天dloc正进入严重时期，爆发期。考试到一半的时候，我准备的纸巾已经被我的鼻涕吸完了。好吧，这的确比较恶心，随后当然就没有办法咯。我用一只手写着卷子，另一手拧着鼻子。那次的考试似乎有点简单，大家纷纷都提前离场了。大概提早了半个多小时，考场里面几乎就只有我和另外一个同学了。我仍然坚持着。坚持着把时间坐够。最后，监考老师说，你们还交不交的啊，不交我走了。要知道那个时候离考试结束还有十多分钟呢！我们只好把试卷交了。结束我拧鼻子的痛苦。</p>\n<p>&emsp;&emsp;食堂的苦瓜从来都没有炒熟过，苦的难以下咽。自从尝了第一次以后我便没有吃过第二次。如果食堂师傅做的苦瓜能有老妈做的那么好就太棒了。有一次dloc居然影响到了我的味觉，吃东西都没有味道。于是我就打了平时不敢吃的苦瓜。</p>\n<p>&emsp;&emsp;其实dloc对于现在的我一点影响都没有，除了可以成为我不去实验室的借口。</p>\n<p>&emsp;&emsp;也许dloc还能一点一点得侵蚀人的大脑，让人变得更傻。</p>\n"},{"title":"旧年","abbrlink":48930,"date":"2010-01-01T02:15:07.000Z","_content":"\n&emsp;&emsp;我本应该在09年年末做一个年终总结的，但是因为各种原因，以及自己的犹豫不绝和薄弱的意志才拖到现在。\n\n&emsp;&emsp;我想我的09年就可以用我没有写总结的原因来说明：各种外部的因素限制以及自己内心的脆弱。\n\n&emsp;&emsp;在这里回故一下09年的事迹，怕到某年某月想回想这段往事却找脑中找不到，记不得。\n\n&emsp;&emsp;09年二月，家那边下过了场雪，那只有不到一天的短暂寿命的雪，我说，瑞雪兆丰年。\n\n&emsp;&emsp;09年不知在那个地方看到了我的运程，说我会遇到一个能够给我带来好运的人，还说下半年我会有桃花运。\n\n&emsp;&emsp;09年4，5月，我们在抓紧着时间准备着本科时期的最后一个作业，毕业论文。事实上大部分时间还是在玩。\n\n&emsp;&emsp;09年6月，我毕业了。和相处几年的同窗说再见。我没有喝多，但是我却让我自己以为自己喝多了。我流泪了，但是没有哭。穿上了学士服，和同学留下了最后的本科记忆。我以为未来是美好的。\n\n&emsp;&emsp;09年7，8月，在家度过的最漫长的暑假，我不知道接下来迎接我的是什么。\n\n&emsp;&emsp;09年9月，我成了一个研究僧。对于学习一样是那么懒惰，对于工作仍然没有动力。\n\n&emsp;&emsp;09年10月，拿到了还能算是工资的第一笔钱。但是却没能用来买有意思的东西。因为我的电脑在同一时间瘫痪。\n\n&emsp;&emsp;09年11月，我递交了第一封情书。虽然我早知道结果，但是心里却依然很痛。\n\n&emsp;&emsp;09年12月，我和小白打赌，如果每玩一次游戏就给他十块钱。结果是他挑唆我玩，我给了十块，完了一天。\n\n&emsp;&emsp;09年最令人难忘的是，我们毕业了。各自都有自己美好的出路，前程。我们开心的喝酒、谈笑、照毕业照。噢，对了，分发毕业照的时候我似乎发错了，谁多领了的赶紧还我，因为我还没有。\n\n&emsp;&emsp;09年值得开心的事是，那个对我09年运程的估计是对的。因为在下班年真的认识了好多女生，不过我一个都没有抓住。当然那不是重点，重点是，我认识了好多朋友。几个舍友哥们幽默、知识渊博、平易近人。一大帮容易相处的师兄总能在关键时候有莫大的帮助。还有就是和我一起打发时间的七上八下。能带给我好运的人，应该就是我的导师，七上八下，师兄，室友。\n\n&emsp;&emsp;09年最伤心的事是，我好像一点成就都没有。这是08年的失误，09年的失败啊！\n\n&emsp;&emsp;10年不能再像09年那样没有计划了。09年没有计划的我就像是无头苍蝇在到处乱撞，也像是漂泊在太平洋的小舟遇上了阴雨天气，没有指南针，没有方向，没有动力，没有出路。\n\n&emsp;&emsp;再见，2009！\n\n","source":"_posts/2010-01-01-旧年.md","raw":"---\ntitle: 旧年\ncategories:\n  - 日记\ntags:\nabbrlink: 48930\ndate: 2010-01-01 10:15:07\n---\n\n&emsp;&emsp;我本应该在09年年末做一个年终总结的，但是因为各种原因，以及自己的犹豫不绝和薄弱的意志才拖到现在。\n\n&emsp;&emsp;我想我的09年就可以用我没有写总结的原因来说明：各种外部的因素限制以及自己内心的脆弱。\n\n&emsp;&emsp;在这里回故一下09年的事迹，怕到某年某月想回想这段往事却找脑中找不到，记不得。\n\n&emsp;&emsp;09年二月，家那边下过了场雪，那只有不到一天的短暂寿命的雪，我说，瑞雪兆丰年。\n\n&emsp;&emsp;09年不知在那个地方看到了我的运程，说我会遇到一个能够给我带来好运的人，还说下半年我会有桃花运。\n\n&emsp;&emsp;09年4，5月，我们在抓紧着时间准备着本科时期的最后一个作业，毕业论文。事实上大部分时间还是在玩。\n\n&emsp;&emsp;09年6月，我毕业了。和相处几年的同窗说再见。我没有喝多，但是我却让我自己以为自己喝多了。我流泪了，但是没有哭。穿上了学士服，和同学留下了最后的本科记忆。我以为未来是美好的。\n\n&emsp;&emsp;09年7，8月，在家度过的最漫长的暑假，我不知道接下来迎接我的是什么。\n\n&emsp;&emsp;09年9月，我成了一个研究僧。对于学习一样是那么懒惰，对于工作仍然没有动力。\n\n&emsp;&emsp;09年10月，拿到了还能算是工资的第一笔钱。但是却没能用来买有意思的东西。因为我的电脑在同一时间瘫痪。\n\n&emsp;&emsp;09年11月，我递交了第一封情书。虽然我早知道结果，但是心里却依然很痛。\n\n&emsp;&emsp;09年12月，我和小白打赌，如果每玩一次游戏就给他十块钱。结果是他挑唆我玩，我给了十块，完了一天。\n\n&emsp;&emsp;09年最令人难忘的是，我们毕业了。各自都有自己美好的出路，前程。我们开心的喝酒、谈笑、照毕业照。噢，对了，分发毕业照的时候我似乎发错了，谁多领了的赶紧还我，因为我还没有。\n\n&emsp;&emsp;09年值得开心的事是，那个对我09年运程的估计是对的。因为在下班年真的认识了好多女生，不过我一个都没有抓住。当然那不是重点，重点是，我认识了好多朋友。几个舍友哥们幽默、知识渊博、平易近人。一大帮容易相处的师兄总能在关键时候有莫大的帮助。还有就是和我一起打发时间的七上八下。能带给我好运的人，应该就是我的导师，七上八下，师兄，室友。\n\n&emsp;&emsp;09年最伤心的事是，我好像一点成就都没有。这是08年的失误，09年的失败啊！\n\n&emsp;&emsp;10年不能再像09年那样没有计划了。09年没有计划的我就像是无头苍蝇在到处乱撞，也像是漂泊在太平洋的小舟遇上了阴雨天气，没有指南针，没有方向，没有动力，没有出路。\n\n&emsp;&emsp;再见，2009！\n\n","slug":"旧年","published":1,"updated":"2024-05-26T14:17:36.845Z","comments":1,"layout":"post","photos":[],"_id":"cmh498ioo001awvou4tzt5d35","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>&emsp;&emsp;我本应该在09年年末做一个年终总结的，但是因为各种原因，以及自己的犹豫不绝和薄弱的意志才拖到现在。</p>\n<p>&emsp;&emsp;我想我的09年就可以用我没有写总结的原因来说明：各种外部的因素限制以及自己内心的脆弱。</p>\n<p>&emsp;&emsp;在这里回故一下09年的事迹，怕到某年某月想回想这段往事却找脑中找不到，记不得。</p>\n<p>&emsp;&emsp;09年二月，家那边下过了场雪，那只有不到一天的短暂寿命的雪，我说，瑞雪兆丰年。</p>\n<p>&emsp;&emsp;09年不知在那个地方看到了我的运程，说我会遇到一个能够给我带来好运的人，还说下半年我会有桃花运。</p>\n<p>&emsp;&emsp;09年4，5月，我们在抓紧着时间准备着本科时期的最后一个作业，毕业论文。事实上大部分时间还是在玩。</p>\n<p>&emsp;&emsp;09年6月，我毕业了。和相处几年的同窗说再见。我没有喝多，但是我却让我自己以为自己喝多了。我流泪了，但是没有哭。穿上了学士服，和同学留下了最后的本科记忆。我以为未来是美好的。</p>\n<p>&emsp;&emsp;09年7，8月，在家度过的最漫长的暑假，我不知道接下来迎接我的是什么。</p>\n<p>&emsp;&emsp;09年9月，我成了一个研究僧。对于学习一样是那么懒惰，对于工作仍然没有动力。</p>\n<p>&emsp;&emsp;09年10月，拿到了还能算是工资的第一笔钱。但是却没能用来买有意思的东西。因为我的电脑在同一时间瘫痪。</p>\n<p>&emsp;&emsp;09年11月，我递交了第一封情书。虽然我早知道结果，但是心里却依然很痛。</p>\n<p>&emsp;&emsp;09年12月，我和小白打赌，如果每玩一次游戏就给他十块钱。结果是他挑唆我玩，我给了十块，完了一天。</p>\n<p>&emsp;&emsp;09年最令人难忘的是，我们毕业了。各自都有自己美好的出路，前程。我们开心的喝酒、谈笑、照毕业照。噢，对了，分发毕业照的时候我似乎发错了，谁多领了的赶紧还我，因为我还没有。</p>\n<p>&emsp;&emsp;09年值得开心的事是，那个对我09年运程的估计是对的。因为在下班年真的认识了好多女生，不过我一个都没有抓住。当然那不是重点，重点是，我认识了好多朋友。几个舍友哥们幽默、知识渊博、平易近人。一大帮容易相处的师兄总能在关键时候有莫大的帮助。还有就是和我一起打发时间的七上八下。能带给我好运的人，应该就是我的导师，七上八下，师兄，室友。</p>\n<p>&emsp;&emsp;09年最伤心的事是，我好像一点成就都没有。这是08年的失误，09年的失败啊！</p>\n<p>&emsp;&emsp;10年不能再像09年那样没有计划了。09年没有计划的我就像是无头苍蝇在到处乱撞，也像是漂泊在太平洋的小舟遇上了阴雨天气，没有指南针，没有方向，没有动力，没有出路。</p>\n<p>&emsp;&emsp;再见，2009！</p>\n","related_posts":[],"length":1144,"excerpt":"","more":"<p>&emsp;&emsp;我本应该在09年年末做一个年终总结的，但是因为各种原因，以及自己的犹豫不绝和薄弱的意志才拖到现在。</p>\n<p>&emsp;&emsp;我想我的09年就可以用我没有写总结的原因来说明：各种外部的因素限制以及自己内心的脆弱。</p>\n<p>&emsp;&emsp;在这里回故一下09年的事迹，怕到某年某月想回想这段往事却找脑中找不到，记不得。</p>\n<p>&emsp;&emsp;09年二月，家那边下过了场雪，那只有不到一天的短暂寿命的雪，我说，瑞雪兆丰年。</p>\n<p>&emsp;&emsp;09年不知在那个地方看到了我的运程，说我会遇到一个能够给我带来好运的人，还说下半年我会有桃花运。</p>\n<p>&emsp;&emsp;09年4，5月，我们在抓紧着时间准备着本科时期的最后一个作业，毕业论文。事实上大部分时间还是在玩。</p>\n<p>&emsp;&emsp;09年6月，我毕业了。和相处几年的同窗说再见。我没有喝多，但是我却让我自己以为自己喝多了。我流泪了，但是没有哭。穿上了学士服，和同学留下了最后的本科记忆。我以为未来是美好的。</p>\n<p>&emsp;&emsp;09年7，8月，在家度过的最漫长的暑假，我不知道接下来迎接我的是什么。</p>\n<p>&emsp;&emsp;09年9月，我成了一个研究僧。对于学习一样是那么懒惰，对于工作仍然没有动力。</p>\n<p>&emsp;&emsp;09年10月，拿到了还能算是工资的第一笔钱。但是却没能用来买有意思的东西。因为我的电脑在同一时间瘫痪。</p>\n<p>&emsp;&emsp;09年11月，我递交了第一封情书。虽然我早知道结果，但是心里却依然很痛。</p>\n<p>&emsp;&emsp;09年12月，我和小白打赌，如果每玩一次游戏就给他十块钱。结果是他挑唆我玩，我给了十块，完了一天。</p>\n<p>&emsp;&emsp;09年最令人难忘的是，我们毕业了。各自都有自己美好的出路，前程。我们开心的喝酒、谈笑、照毕业照。噢，对了，分发毕业照的时候我似乎发错了，谁多领了的赶紧还我，因为我还没有。</p>\n<p>&emsp;&emsp;09年值得开心的事是，那个对我09年运程的估计是对的。因为在下班年真的认识了好多女生，不过我一个都没有抓住。当然那不是重点，重点是，我认识了好多朋友。几个舍友哥们幽默、知识渊博、平易近人。一大帮容易相处的师兄总能在关键时候有莫大的帮助。还有就是和我一起打发时间的七上八下。能带给我好运的人，应该就是我的导师，七上八下，师兄，室友。</p>\n<p>&emsp;&emsp;09年最伤心的事是，我好像一点成就都没有。这是08年的失误，09年的失败啊！</p>\n<p>&emsp;&emsp;10年不能再像09年那样没有计划了。09年没有计划的我就像是无头苍蝇在到处乱撞，也像是漂泊在太平洋的小舟遇上了阴雨天气，没有指南针，没有方向，没有动力，没有出路。</p>\n<p>&emsp;&emsp;再见，2009！</p>\n"},{"title":"红色","abbrlink":25994,"date":"2010-01-04T12:24:07.000Z","_content":"\n&emsp;&emsp;红色是我比较喜欢的一种颜色，或者说我个人比较喜欢红色的东西，但是红色内裤除外。\n\n&emsp;&emsp;新年的前一天，vincent调侃的问道：“明年是谁的本命年啊？”我居然傻到附和，举起了手。接下来便是不想听到的：“记得一定要穿红色内裤，可以辟邪的……”\n\n&emsp;&emsp;“可是我没有红色内裤，明天我就去买……”我还假装开心的应道。不过后来真的没有买。\n\n&emsp;&emsp;今天早上起床后兴高采烈的跑下楼去实验室。结果在下到一楼的时候一脚就踏空了，全身的重量集中在歪向一遍的右脚。顿时痛得我差点叫出声来。那种痛没有办法形容，总之你会巴望着受伤的脚长在别人腿上，就算自己能飞起来也不能减轻一丁点儿痛楚，当然那个时候你不可能想到飞。唯一能想的就是，一定没事，一定没事，千万不要伤到骨头。我撑着拐角的扶手悬空了一回会儿，然后有80%的把握没有伤到骨头。回宿舍呢，还是去实验室？回宿舍还有五楼要爬，我可爬不动；去实验室骑车，只需要下一层楼，然后骑车，还好，还能坚持，况且还有课要上；但是，要不要去医院？以前也偶尔崴到脚，不过不会有多严重，崴了一会儿就能好。但是这次能够感觉到不是一时半会儿就痊愈的。\n\n&emsp;&emsp;下午上完课，脚还在痛，要是烙下病根儿可不好。要不要去看医生呢？七上八下说要的，他预支了一次惩罚我的机会让我去看。既然处于一番好意，那我就只好遵命，犯了一次规去找vincent帮忙送我去医院看脚。\n\n&emsp;&emsp;悲剧的事情发生了。vincent骑自行车不会载人，况且我的自行车没有后座。让vincent去借车，结果问到最后，就借到老大的那辆女士小轮永久，后轮没有气。有打气的地方，可是坐上去连腿都伸不直。于是打电话找有正常的车会载人的小平，可是电话那头只有一个说着标准普通话，通知我会短信通知机主的女士的声音，估计小平又去陪女朋友了。打电话找大胡，大胡的电话通了，嘟了半天，就是没有人接，估计又是去打球去了。打电话给小白，对了，小白的自行车也没有后座。对还有二毛。电话通了，二毛还在西区上课。不过人挺好的，接通电话说20分钟后就回来。\n\n&emsp;&emsp;我踱着脚，时而跳两步和vincent在大楼大厅里面等二毛。忽然就想起今年是本命年，然后话题就转到了红内裤。\n\n&emsp;&emsp;然后我明白了一个道理，命这种事情，信则灵，不信就没什么了。真不巧啊，我有点信了。\n\n&emsp;&emsp;医院5点30关门。二毛明明说20分钟到的，结果等了半个多小时。然后来了个电话说，你们再等7、8分钟，刚才我的车链子掉了，刚刚修好，马上就过来。等他回来的时候已经五点过十多分了。不过还算赶的紧，去医院放射科拍片的时候，医生刚刚关机器。还好那医生人挺好的，愿意帮我重开。大概挂科处，放射科，外科，收费处，还有买药窗口今天接待的最后一个人就是我了。不幸中的万幸就是，没有伤到骨头，嘿嘿。\n\n&emsp;&emsp;准备从此窝在宿舍，再窝上一个星期。应该用冷水泡脚还是热水？小白说，热水，还热情地帮我打了水。泡起来的确舒服。泡完脚手机来了几条短信。短信1：阿细，要先用冷水敷，然后再用热水泡。短信2：今晚9点组会，请准时参加。天呐！\n\n&emsp;&emsp;我在想我的人品是不是和手机的那个什么积分一样，过年就清零了。哎～\n\n&emsp;&emsp;多攒点人品，嗯！加油……\n\n","source":"_posts/2010-01-04-红色.md","raw":"---\ntitle: 红色\ncategories:\n  - 日记\ntags:\nabbrlink: 25994\ndate: 2010-01-04 20:24:07\n---\n\n&emsp;&emsp;红色是我比较喜欢的一种颜色，或者说我个人比较喜欢红色的东西，但是红色内裤除外。\n\n&emsp;&emsp;新年的前一天，vincent调侃的问道：“明年是谁的本命年啊？”我居然傻到附和，举起了手。接下来便是不想听到的：“记得一定要穿红色内裤，可以辟邪的……”\n\n&emsp;&emsp;“可是我没有红色内裤，明天我就去买……”我还假装开心的应道。不过后来真的没有买。\n\n&emsp;&emsp;今天早上起床后兴高采烈的跑下楼去实验室。结果在下到一楼的时候一脚就踏空了，全身的重量集中在歪向一遍的右脚。顿时痛得我差点叫出声来。那种痛没有办法形容，总之你会巴望着受伤的脚长在别人腿上，就算自己能飞起来也不能减轻一丁点儿痛楚，当然那个时候你不可能想到飞。唯一能想的就是，一定没事，一定没事，千万不要伤到骨头。我撑着拐角的扶手悬空了一回会儿，然后有80%的把握没有伤到骨头。回宿舍呢，还是去实验室？回宿舍还有五楼要爬，我可爬不动；去实验室骑车，只需要下一层楼，然后骑车，还好，还能坚持，况且还有课要上；但是，要不要去医院？以前也偶尔崴到脚，不过不会有多严重，崴了一会儿就能好。但是这次能够感觉到不是一时半会儿就痊愈的。\n\n&emsp;&emsp;下午上完课，脚还在痛，要是烙下病根儿可不好。要不要去看医生呢？七上八下说要的，他预支了一次惩罚我的机会让我去看。既然处于一番好意，那我就只好遵命，犯了一次规去找vincent帮忙送我去医院看脚。\n\n&emsp;&emsp;悲剧的事情发生了。vincent骑自行车不会载人，况且我的自行车没有后座。让vincent去借车，结果问到最后，就借到老大的那辆女士小轮永久，后轮没有气。有打气的地方，可是坐上去连腿都伸不直。于是打电话找有正常的车会载人的小平，可是电话那头只有一个说着标准普通话，通知我会短信通知机主的女士的声音，估计小平又去陪女朋友了。打电话找大胡，大胡的电话通了，嘟了半天，就是没有人接，估计又是去打球去了。打电话给小白，对了，小白的自行车也没有后座。对还有二毛。电话通了，二毛还在西区上课。不过人挺好的，接通电话说20分钟后就回来。\n\n&emsp;&emsp;我踱着脚，时而跳两步和vincent在大楼大厅里面等二毛。忽然就想起今年是本命年，然后话题就转到了红内裤。\n\n&emsp;&emsp;然后我明白了一个道理，命这种事情，信则灵，不信就没什么了。真不巧啊，我有点信了。\n\n&emsp;&emsp;医院5点30关门。二毛明明说20分钟到的，结果等了半个多小时。然后来了个电话说，你们再等7、8分钟，刚才我的车链子掉了，刚刚修好，马上就过来。等他回来的时候已经五点过十多分了。不过还算赶的紧，去医院放射科拍片的时候，医生刚刚关机器。还好那医生人挺好的，愿意帮我重开。大概挂科处，放射科，外科，收费处，还有买药窗口今天接待的最后一个人就是我了。不幸中的万幸就是，没有伤到骨头，嘿嘿。\n\n&emsp;&emsp;准备从此窝在宿舍，再窝上一个星期。应该用冷水泡脚还是热水？小白说，热水，还热情地帮我打了水。泡起来的确舒服。泡完脚手机来了几条短信。短信1：阿细，要先用冷水敷，然后再用热水泡。短信2：今晚9点组会，请准时参加。天呐！\n\n&emsp;&emsp;我在想我的人品是不是和手机的那个什么积分一样，过年就清零了。哎～\n\n&emsp;&emsp;多攒点人品，嗯！加油……\n\n","slug":"红色","published":1,"updated":"2024-05-26T14:17:36.845Z","comments":1,"layout":"post","photos":[],"_id":"cmh498ioo001cwvouea9pfzu8","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>&emsp;&emsp;红色是我比较喜欢的一种颜色，或者说我个人比较喜欢红色的东西，但是红色内裤除外。</p>\n<p>&emsp;&emsp;新年的前一天，vincent调侃的问道：“明年是谁的本命年啊？”我居然傻到附和，举起了手。接下来便是不想听到的：“记得一定要穿红色内裤，可以辟邪的……”</p>\n<p>&emsp;&emsp;“可是我没有红色内裤，明天我就去买……”我还假装开心的应道。不过后来真的没有买。</p>\n<p>&emsp;&emsp;今天早上起床后兴高采烈的跑下楼去实验室。结果在下到一楼的时候一脚就踏空了，全身的重量集中在歪向一遍的右脚。顿时痛得我差点叫出声来。那种痛没有办法形容，总之你会巴望着受伤的脚长在别人腿上，就算自己能飞起来也不能减轻一丁点儿痛楚，当然那个时候你不可能想到飞。唯一能想的就是，一定没事，一定没事，千万不要伤到骨头。我撑着拐角的扶手悬空了一回会儿，然后有80%的把握没有伤到骨头。回宿舍呢，还是去实验室？回宿舍还有五楼要爬，我可爬不动；去实验室骑车，只需要下一层楼，然后骑车，还好，还能坚持，况且还有课要上；但是，要不要去医院？以前也偶尔崴到脚，不过不会有多严重，崴了一会儿就能好。但是这次能够感觉到不是一时半会儿就痊愈的。</p>\n<p>&emsp;&emsp;下午上完课，脚还在痛，要是烙下病根儿可不好。要不要去看医生呢？七上八下说要的，他预支了一次惩罚我的机会让我去看。既然处于一番好意，那我就只好遵命，犯了一次规去找vincent帮忙送我去医院看脚。</p>\n<p>&emsp;&emsp;悲剧的事情发生了。vincent骑自行车不会载人，况且我的自行车没有后座。让vincent去借车，结果问到最后，就借到老大的那辆女士小轮永久，后轮没有气。有打气的地方，可是坐上去连腿都伸不直。于是打电话找有正常的车会载人的小平，可是电话那头只有一个说着标准普通话，通知我会短信通知机主的女士的声音，估计小平又去陪女朋友了。打电话找大胡，大胡的电话通了，嘟了半天，就是没有人接，估计又是去打球去了。打电话给小白，对了，小白的自行车也没有后座。对还有二毛。电话通了，二毛还在西区上课。不过人挺好的，接通电话说20分钟后就回来。</p>\n<p>&emsp;&emsp;我踱着脚，时而跳两步和vincent在大楼大厅里面等二毛。忽然就想起今年是本命年，然后话题就转到了红内裤。</p>\n<p>&emsp;&emsp;然后我明白了一个道理，命这种事情，信则灵，不信就没什么了。真不巧啊，我有点信了。</p>\n<p>&emsp;&emsp;医院5点30关门。二毛明明说20分钟到的，结果等了半个多小时。然后来了个电话说，你们再等7、8分钟，刚才我的车链子掉了，刚刚修好，马上就过来。等他回来的时候已经五点过十多分了。不过还算赶的紧，去医院放射科拍片的时候，医生刚刚关机器。还好那医生人挺好的，愿意帮我重开。大概挂科处，放射科，外科，收费处，还有买药窗口今天接待的最后一个人就是我了。不幸中的万幸就是，没有伤到骨头，嘿嘿。</p>\n<p>&emsp;&emsp;准备从此窝在宿舍，再窝上一个星期。应该用冷水泡脚还是热水？小白说，热水，还热情地帮我打了水。泡起来的确舒服。泡完脚手机来了几条短信。短信1：阿细，要先用冷水敷，然后再用热水泡。短信2：今晚9点组会，请准时参加。天呐！</p>\n<p>&emsp;&emsp;我在想我的人品是不是和手机的那个什么积分一样，过年就清零了。哎～</p>\n<p>&emsp;&emsp;多攒点人品，嗯！加油……</p>\n","related_posts":[],"length":1400,"excerpt":"","more":"<p>&emsp;&emsp;红色是我比较喜欢的一种颜色，或者说我个人比较喜欢红色的东西，但是红色内裤除外。</p>\n<p>&emsp;&emsp;新年的前一天，vincent调侃的问道：“明年是谁的本命年啊？”我居然傻到附和，举起了手。接下来便是不想听到的：“记得一定要穿红色内裤，可以辟邪的……”</p>\n<p>&emsp;&emsp;“可是我没有红色内裤，明天我就去买……”我还假装开心的应道。不过后来真的没有买。</p>\n<p>&emsp;&emsp;今天早上起床后兴高采烈的跑下楼去实验室。结果在下到一楼的时候一脚就踏空了，全身的重量集中在歪向一遍的右脚。顿时痛得我差点叫出声来。那种痛没有办法形容，总之你会巴望着受伤的脚长在别人腿上，就算自己能飞起来也不能减轻一丁点儿痛楚，当然那个时候你不可能想到飞。唯一能想的就是，一定没事，一定没事，千万不要伤到骨头。我撑着拐角的扶手悬空了一回会儿，然后有80%的把握没有伤到骨头。回宿舍呢，还是去实验室？回宿舍还有五楼要爬，我可爬不动；去实验室骑车，只需要下一层楼，然后骑车，还好，还能坚持，况且还有课要上；但是，要不要去医院？以前也偶尔崴到脚，不过不会有多严重，崴了一会儿就能好。但是这次能够感觉到不是一时半会儿就痊愈的。</p>\n<p>&emsp;&emsp;下午上完课，脚还在痛，要是烙下病根儿可不好。要不要去看医生呢？七上八下说要的，他预支了一次惩罚我的机会让我去看。既然处于一番好意，那我就只好遵命，犯了一次规去找vincent帮忙送我去医院看脚。</p>\n<p>&emsp;&emsp;悲剧的事情发生了。vincent骑自行车不会载人，况且我的自行车没有后座。让vincent去借车，结果问到最后，就借到老大的那辆女士小轮永久，后轮没有气。有打气的地方，可是坐上去连腿都伸不直。于是打电话找有正常的车会载人的小平，可是电话那头只有一个说着标准普通话，通知我会短信通知机主的女士的声音，估计小平又去陪女朋友了。打电话找大胡，大胡的电话通了，嘟了半天，就是没有人接，估计又是去打球去了。打电话给小白，对了，小白的自行车也没有后座。对还有二毛。电话通了，二毛还在西区上课。不过人挺好的，接通电话说20分钟后就回来。</p>\n<p>&emsp;&emsp;我踱着脚，时而跳两步和vincent在大楼大厅里面等二毛。忽然就想起今年是本命年，然后话题就转到了红内裤。</p>\n<p>&emsp;&emsp;然后我明白了一个道理，命这种事情，信则灵，不信就没什么了。真不巧啊，我有点信了。</p>\n<p>&emsp;&emsp;医院5点30关门。二毛明明说20分钟到的，结果等了半个多小时。然后来了个电话说，你们再等7、8分钟，刚才我的车链子掉了，刚刚修好，马上就过来。等他回来的时候已经五点过十多分了。不过还算赶的紧，去医院放射科拍片的时候，医生刚刚关机器。还好那医生人挺好的，愿意帮我重开。大概挂科处，放射科，外科，收费处，还有买药窗口今天接待的最后一个人就是我了。不幸中的万幸就是，没有伤到骨头，嘿嘿。</p>\n<p>&emsp;&emsp;准备从此窝在宿舍，再窝上一个星期。应该用冷水泡脚还是热水？小白说，热水，还热情地帮我打了水。泡起来的确舒服。泡完脚手机来了几条短信。短信1：阿细，要先用冷水敷，然后再用热水泡。短信2：今晚9点组会，请准时参加。天呐！</p>\n<p>&emsp;&emsp;我在想我的人品是不是和手机的那个什么积分一样，过年就清零了。哎～</p>\n<p>&emsp;&emsp;多攒点人品，嗯！加油……</p>\n"},{"title":"头晕","abbrlink":54283,"date":"2010-01-12T15:23:39.000Z","_content":"\n&emsp;&emsp;《avatar》很火。不是火辣的火，呃，也不一定，也许在那威人的眼里面他们身材十分火辣也说不一定。反正最近每天打开网页都能见到avatar的宣传，上映，观后感铺天盖地的映入眼帘。\n\n&emsp;&emsp;下午去电影院看了3D的avatar，确切的来讲是“被看”。因为大伙儿都看，都在谈论。自己不看，不谈论就会落伍。顺着朋友的观点，我就得到了以上的结论和推论。而我是冲着3D去看的，但不能不说没有受到舆论和宣传的影响。\n\n&emsp;&emsp;同学问为什么看完电影回来没有激烈的讨论，基于我说这部片子很感人很震撼？我只能说，当时看的时候真的很感人很震撼，至于为什么看完以后就没了热情，只能说太完美啦！当然，完美不是指故事情节，这一点是针对于那些说故事情节老套，各种漫画动画用老了的而言。\n\n&emsp;&emsp;还有，我想说的就是，头好晕。因为今天和小白去准备买15好以后的票，结果一问说只能买三天之内的。可是三天之后又考试，三天内还是不要看，好好复习为好。但是一问，三天之内的各个好时段的票都空了。嗯，难得跑那么远来一次，看看今天有没有，有的话就看掉好了。有呃，不过中午1：30，而且只剩下第一排。好吧，还是将就将就勉强勉强。于是把其他5个家伙一起给招过来。\n\n&emsp;&emsp;开看啦。我的天，屏幕那么高，170分钟，看完下来脖子肯定断掉了。坚持一下，牺牲一回啦，为了这个传奇。挺清晰，活灵活现，有时觉得那些飞虫就在眼前，还想用手把它们赶走，还有那个催泪弹投过来时，感觉是快砸到我的头，身体不禁想躲。剧情发展速度也很合适，主要是蒙太奇用得比较好。不像有些电视，想用一两个镜头来表达十年发生的事情或者感情的发展变化，往往让人觉得太快，太迅速，难以接受。细节也是十分出色的。\n\n&emsp;&emsp;问题：1，几个科学家做实验，把人的意识转移到克隆的avatar身上，这个，难以说通吧！2，潘多拉星球的所有生命组成的超级网络把人类的意识和灵魂转移到avatar体内，不可思议啊！本来想用电脑的联网来解释的，这倒不错，但是转移意识就弄得魔幻了。3，那个大的网络可以召唤所有潘多拉生命起来反抗外族，不可思议啊，怎么交流的？有点魔幻。4，第一排啊，头晕，脖子痛，全身都麻了。对哦，这些都不能算是问题的，特别是在如此震撼的视觉下。\n\n&emsp;&emsp;哎呀，眼睛饱餐了一顿，时间杀死了一些，心震撼了一回，心情疏通了一些，中午吃的事物中的油脂沉积了些，钱砸了一些，头晕了一回，脚酸了一回……\n\n&emsp;&emsp;“明天该好好复习了吧？”\n\n&emsp;&emsp;“复习哪要那么久？”\n\n&emsp;&emsp;“你干嘛给我借口……”\n\n&emsp;&emsp;“你的人身目标是什么，追求是什么？”\n\n&emsp;&emsp;……\n\n","source":"_posts/2010-01-12-头晕.md","raw":"---\ntitle: 头晕\ncategories:\n  - 日记\ntags:\nabbrlink: 54283\ndate: 2010-01-12 23:23:39\n---\n\n&emsp;&emsp;《avatar》很火。不是火辣的火，呃，也不一定，也许在那威人的眼里面他们身材十分火辣也说不一定。反正最近每天打开网页都能见到avatar的宣传，上映，观后感铺天盖地的映入眼帘。\n\n&emsp;&emsp;下午去电影院看了3D的avatar，确切的来讲是“被看”。因为大伙儿都看，都在谈论。自己不看，不谈论就会落伍。顺着朋友的观点，我就得到了以上的结论和推论。而我是冲着3D去看的，但不能不说没有受到舆论和宣传的影响。\n\n&emsp;&emsp;同学问为什么看完电影回来没有激烈的讨论，基于我说这部片子很感人很震撼？我只能说，当时看的时候真的很感人很震撼，至于为什么看完以后就没了热情，只能说太完美啦！当然，完美不是指故事情节，这一点是针对于那些说故事情节老套，各种漫画动画用老了的而言。\n\n&emsp;&emsp;还有，我想说的就是，头好晕。因为今天和小白去准备买15好以后的票，结果一问说只能买三天之内的。可是三天之后又考试，三天内还是不要看，好好复习为好。但是一问，三天之内的各个好时段的票都空了。嗯，难得跑那么远来一次，看看今天有没有，有的话就看掉好了。有呃，不过中午1：30，而且只剩下第一排。好吧，还是将就将就勉强勉强。于是把其他5个家伙一起给招过来。\n\n&emsp;&emsp;开看啦。我的天，屏幕那么高，170分钟，看完下来脖子肯定断掉了。坚持一下，牺牲一回啦，为了这个传奇。挺清晰，活灵活现，有时觉得那些飞虫就在眼前，还想用手把它们赶走，还有那个催泪弹投过来时，感觉是快砸到我的头，身体不禁想躲。剧情发展速度也很合适，主要是蒙太奇用得比较好。不像有些电视，想用一两个镜头来表达十年发生的事情或者感情的发展变化，往往让人觉得太快，太迅速，难以接受。细节也是十分出色的。\n\n&emsp;&emsp;问题：1，几个科学家做实验，把人的意识转移到克隆的avatar身上，这个，难以说通吧！2，潘多拉星球的所有生命组成的超级网络把人类的意识和灵魂转移到avatar体内，不可思议啊！本来想用电脑的联网来解释的，这倒不错，但是转移意识就弄得魔幻了。3，那个大的网络可以召唤所有潘多拉生命起来反抗外族，不可思议啊，怎么交流的？有点魔幻。4，第一排啊，头晕，脖子痛，全身都麻了。对哦，这些都不能算是问题的，特别是在如此震撼的视觉下。\n\n&emsp;&emsp;哎呀，眼睛饱餐了一顿，时间杀死了一些，心震撼了一回，心情疏通了一些，中午吃的事物中的油脂沉积了些，钱砸了一些，头晕了一回，脚酸了一回……\n\n&emsp;&emsp;“明天该好好复习了吧？”\n\n&emsp;&emsp;“复习哪要那么久？”\n\n&emsp;&emsp;“你干嘛给我借口……”\n\n&emsp;&emsp;“你的人身目标是什么，追求是什么？”\n\n&emsp;&emsp;……\n\n","slug":"头晕","published":1,"updated":"2024-05-26T14:17:36.845Z","comments":1,"layout":"post","photos":[],"_id":"cmh498iop001ewvouhks419p6","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>&emsp;&emsp;《avatar》很火。不是火辣的火，呃，也不一定，也许在那威人的眼里面他们身材十分火辣也说不一定。反正最近每天打开网页都能见到avatar的宣传，上映，观后感铺天盖地的映入眼帘。</p>\n<p>&emsp;&emsp;下午去电影院看了3D的avatar，确切的来讲是“被看”。因为大伙儿都看，都在谈论。自己不看，不谈论就会落伍。顺着朋友的观点，我就得到了以上的结论和推论。而我是冲着3D去看的，但不能不说没有受到舆论和宣传的影响。</p>\n<p>&emsp;&emsp;同学问为什么看完电影回来没有激烈的讨论，基于我说这部片子很感人很震撼？我只能说，当时看的时候真的很感人很震撼，至于为什么看完以后就没了热情，只能说太完美啦！当然，完美不是指故事情节，这一点是针对于那些说故事情节老套，各种漫画动画用老了的而言。</p>\n<p>&emsp;&emsp;还有，我想说的就是，头好晕。因为今天和小白去准备买15好以后的票，结果一问说只能买三天之内的。可是三天之后又考试，三天内还是不要看，好好复习为好。但是一问，三天之内的各个好时段的票都空了。嗯，难得跑那么远来一次，看看今天有没有，有的话就看掉好了。有呃，不过中午1：30，而且只剩下第一排。好吧，还是将就将就勉强勉强。于是把其他5个家伙一起给招过来。</p>\n<p>&emsp;&emsp;开看啦。我的天，屏幕那么高，170分钟，看完下来脖子肯定断掉了。坚持一下，牺牲一回啦，为了这个传奇。挺清晰，活灵活现，有时觉得那些飞虫就在眼前，还想用手把它们赶走，还有那个催泪弹投过来时，感觉是快砸到我的头，身体不禁想躲。剧情发展速度也很合适，主要是蒙太奇用得比较好。不像有些电视，想用一两个镜头来表达十年发生的事情或者感情的发展变化，往往让人觉得太快，太迅速，难以接受。细节也是十分出色的。</p>\n<p>&emsp;&emsp;问题：1，几个科学家做实验，把人的意识转移到克隆的avatar身上，这个，难以说通吧！2，潘多拉星球的所有生命组成的超级网络把人类的意识和灵魂转移到avatar体内，不可思议啊！本来想用电脑的联网来解释的，这倒不错，但是转移意识就弄得魔幻了。3，那个大的网络可以召唤所有潘多拉生命起来反抗外族，不可思议啊，怎么交流的？有点魔幻。4，第一排啊，头晕，脖子痛，全身都麻了。对哦，这些都不能算是问题的，特别是在如此震撼的视觉下。</p>\n<p>&emsp;&emsp;哎呀，眼睛饱餐了一顿，时间杀死了一些，心震撼了一回，心情疏通了一些，中午吃的事物中的油脂沉积了些，钱砸了一些，头晕了一回，脚酸了一回……</p>\n<p>&emsp;&emsp;“明天该好好复习了吧？”</p>\n<p>&emsp;&emsp;“复习哪要那么久？”</p>\n<p>&emsp;&emsp;“你干嘛给我借口……”</p>\n<p>&emsp;&emsp;“你的人身目标是什么，追求是什么？”</p>\n<p>&emsp;&emsp;……</p>\n","related_posts":[],"length":1162,"excerpt":"","more":"<p>&emsp;&emsp;《avatar》很火。不是火辣的火，呃，也不一定，也许在那威人的眼里面他们身材十分火辣也说不一定。反正最近每天打开网页都能见到avatar的宣传，上映，观后感铺天盖地的映入眼帘。</p>\n<p>&emsp;&emsp;下午去电影院看了3D的avatar，确切的来讲是“被看”。因为大伙儿都看，都在谈论。自己不看，不谈论就会落伍。顺着朋友的观点，我就得到了以上的结论和推论。而我是冲着3D去看的，但不能不说没有受到舆论和宣传的影响。</p>\n<p>&emsp;&emsp;同学问为什么看完电影回来没有激烈的讨论，基于我说这部片子很感人很震撼？我只能说，当时看的时候真的很感人很震撼，至于为什么看完以后就没了热情，只能说太完美啦！当然，完美不是指故事情节，这一点是针对于那些说故事情节老套，各种漫画动画用老了的而言。</p>\n<p>&emsp;&emsp;还有，我想说的就是，头好晕。因为今天和小白去准备买15好以后的票，结果一问说只能买三天之内的。可是三天之后又考试，三天内还是不要看，好好复习为好。但是一问，三天之内的各个好时段的票都空了。嗯，难得跑那么远来一次，看看今天有没有，有的话就看掉好了。有呃，不过中午1：30，而且只剩下第一排。好吧，还是将就将就勉强勉强。于是把其他5个家伙一起给招过来。</p>\n<p>&emsp;&emsp;开看啦。我的天，屏幕那么高，170分钟，看完下来脖子肯定断掉了。坚持一下，牺牲一回啦，为了这个传奇。挺清晰，活灵活现，有时觉得那些飞虫就在眼前，还想用手把它们赶走，还有那个催泪弹投过来时，感觉是快砸到我的头，身体不禁想躲。剧情发展速度也很合适，主要是蒙太奇用得比较好。不像有些电视，想用一两个镜头来表达十年发生的事情或者感情的发展变化，往往让人觉得太快，太迅速，难以接受。细节也是十分出色的。</p>\n<p>&emsp;&emsp;问题：1，几个科学家做实验，把人的意识转移到克隆的avatar身上，这个，难以说通吧！2，潘多拉星球的所有生命组成的超级网络把人类的意识和灵魂转移到avatar体内，不可思议啊！本来想用电脑的联网来解释的，这倒不错，但是转移意识就弄得魔幻了。3，那个大的网络可以召唤所有潘多拉生命起来反抗外族，不可思议啊，怎么交流的？有点魔幻。4，第一排啊，头晕，脖子痛，全身都麻了。对哦，这些都不能算是问题的，特别是在如此震撼的视觉下。</p>\n<p>&emsp;&emsp;哎呀，眼睛饱餐了一顿，时间杀死了一些，心震撼了一回，心情疏通了一些，中午吃的事物中的油脂沉积了些，钱砸了一些，头晕了一回，脚酸了一回……</p>\n<p>&emsp;&emsp;“明天该好好复习了吧？”</p>\n<p>&emsp;&emsp;“复习哪要那么久？”</p>\n<p>&emsp;&emsp;“你干嘛给我借口……”</p>\n<p>&emsp;&emsp;“你的人身目标是什么，追求是什么？”</p>\n<p>&emsp;&emsp;……</p>\n"},{"title":"饭后感2","abbrlink":2694,"date":"2010-02-06T05:42:35.000Z","_content":"\n&emsp;&emsp;吃过晚饭，忽然想起有通电话未打，于是下楼拨通了号码，有事忙，待会儿打来。于是决定出去转转。\n\n&emsp;&emsp;不知不觉到了街边的小公园。其实冬天寒冷的夜晚没有几个露天的好地方可以用于人们晚上饭后游览。\n\n&emsp;&emsp;我也不知道这算不算个公园，公园的意思大概就是公开的用于大家游览的地方。公园中间有一个人工小湖，其他的花草树木小设施都是围绕着这个湖簇拥着。湖中心象征似的修了个小岛，岛上除了和岸边相同的树木的装饰，还有一个比较显眼的小屋子。见到了事实真相就缺少了几分想象，那个屋子是几只黑天鹅的黑色小屋子。白天也没见里面住过天鹅，大概里面的居住条件不好吧，估计晚上也不会把它们关在里面，因为据说一只黑天鹅价值6000块。各处少不了照的四处通明，小偷无处可藏的霓虹灯，使得这公园才有晚上这许多人的光顾。\n\n&emsp;&emsp;最显眼的要数西边的一个转动的水车，据我们多次观察，一致断定，水车不是电动的。它的半径有大概7至8米宽，时刻不停地被水流带动着转动，水车上装有装水的竹筒，只可惜没有一个引水的小沟，竹筒里的水随着水车的转动来到半空，然后被无情的抛弃，直落下来，像被抛弃的婴儿，有的溅到他母亲的身上像是手脚有力气抓住母亲衣角，有的直接落在了母亲脚下随着水流而下，发出几声哄哄的哀鸣。对了，这像泉水一样泄入小湖里带动水车转动的水是哪里来的？三岁小孩也能思索的出，是用水泵时刻不停来回抽取的。因为站在离泉眼附近还能感觉到水泵的震动，仿佛是汶川地震的余震。东边也如此炮制，只是少了个水车，只剩下拙略的剩有人类加工过的瀑布，发出嚯嚯嚯的噪音，似乎纪律缺管的刚成立的地下组织在召开激烈的讨论会。\n\n&emsp;&emsp;绕这个椭圆形的小湖快步一圈大概要花二十分钟左右，因为刚刚有一个白运动衫胖大阿姨快步从我身边经过，如今过了将近二十分钟，白色胖大身影又从我眼前掠过，若不是我眼花或者看到了鬼，又或者那个阿姨在那个凳子上面歇息过，我的估计就应该是比较准确的。她第三次经过我的身边时我真好正对着她，看了个仔细，人家哪是阿姨啊，反正女士的年龄总跟她们的心思一样是个谜。我沿着湖走了一圈，花了三十多分钟，然后发现，的确走不动了，结论是，这双鞋确实买的小了，伤脚。于是找了湖男岸木质小路上的一个金属冷条凳坐下。身上带有刚刚步行时附着在身上的余温，还可以抵御的了这条凳的寒，这如白天一样的黑夜的冷。\n\n&emsp;&emsp;今天是农历十三，我抬头望了望天，月面的一边少了一圈，像被馋嘴偷吃的小孩沿着边掉了，月亮光洁的挂不住任何云彩做成的面纱，像接掉红头巾的新娘，但是她却独守空房，因为今天的天空没有一丝云彩，新郎大概被亲朋好友拉去灌酒了。仔细瞧才发现不远处有一个星，若不是有点儿高中的天文知识谁也不会想到那个便是著名的太白金星，因为它的光亮全被皎洁的月夺去了，但是它却依然不依不舍的守在月的身旁，看样子对月一片真心。\n\n&emsp;&emsp;远处天边升起了一个孔明灯，大概是孔明灯，在天空中往西斜飘了一阵便熄灭了，大概放孔明灯的人的愿望实现不了了，好失望伤心啊！过了一会儿另一个孔明灯又升起来了，这次也是向西，似乎在追寻前一个似的，它追了好远好远，但是心上人已经不在了。黑暗一点点的吞没了孤单的它，然后天幕就只是黑暗的天下。\n\n&emsp;&emsp;公园北边是一些居民楼，还有一栋灯火通明的教学楼，那是我初中时上课的地方。窗口正对着我，日光灯根根可数，灯光下大概又是困顿发倦的自习生。对岸霓虹灯的灯光照在湖面反射进双眼，水面承载着大量的面波震动信息，波光粼粼照的人有些眩晕。几个晚上锻炼身体的小孩子不时的从我眼前跑过，喘着粗气。我想告诉他们晚饭过后不适宜跑，逛逛就行了。顺着他们跑过去的方向看去，一个穿着单薄迷彩服蓬乱头发的小伙子从路上走到湖边的大石头上坐了下来，一动不动的看着湖面，像是有心事。又或者他本来就是一个疯子。也许他看着我傻傻的坐在这儿也以为是一个疯子呢！过了一会儿他向我这边走过来，靠近我时从岸边地上捡起一块鹅卵石，我以为他听到我心里说他是疯子要赶过来报复呢，我的脚因为寒冷而哆嗦着，要跑的话估计也来不及了。谁知他把鹅卵石向湖中一仍，然后傻兮兮的冲我笑了一笑，然后跑掉了。\n\n&emsp;&emsp;突然水面扰动起来，水纹显示从湖心小岛方向有东西向我这边游过来，像电影中鳄鱼游动留下的激起的水面。不过这里哪来鳄鱼啊，我为自己的想法而发笑，好奇心驱使我起来去看个究竟。一看，发现是一只在水面游动的老鼠，正思索着它游过来的目的，它看到了我，吓得来了个大潜水，等再起来时已经到岸了，然后迅速找了自己的老洞躲了起来。我靠近岸边，想看看它是否因为心急紧张而跑错了路。过了一会儿又一只老鼠从湖心游过来，这次这只小一些，游得慢一些，像刚学会游泳。我故意跺了一脚，像上一只一样的，它也潜进了水里，不过它起来的时候还在原地，远没有上一只灵敏矫捷。我不忍心再吓它，万一要是这只是上一只的媳妇儿，我吓了她，待会儿她的老公来找我报仇就麻烦了。终于她费了九牛二虎之力游到了岸边。\n\n&emsp;&emsp;电话响起了，我酝酿了好多话要讲，可是讲话可不比写文章啊，说起来什么都忘了。\n\n","source":"_posts/2010-02-06-饭后感2.md","raw":"---\ntitle: 饭后感2\ncategories:\n  - 某日记\ntags:\n  - 饭后感\nabbrlink: 2694\ndate: 2010-02-06 13:42:35\n---\n\n&emsp;&emsp;吃过晚饭，忽然想起有通电话未打，于是下楼拨通了号码，有事忙，待会儿打来。于是决定出去转转。\n\n&emsp;&emsp;不知不觉到了街边的小公园。其实冬天寒冷的夜晚没有几个露天的好地方可以用于人们晚上饭后游览。\n\n&emsp;&emsp;我也不知道这算不算个公园，公园的意思大概就是公开的用于大家游览的地方。公园中间有一个人工小湖，其他的花草树木小设施都是围绕着这个湖簇拥着。湖中心象征似的修了个小岛，岛上除了和岸边相同的树木的装饰，还有一个比较显眼的小屋子。见到了事实真相就缺少了几分想象，那个屋子是几只黑天鹅的黑色小屋子。白天也没见里面住过天鹅，大概里面的居住条件不好吧，估计晚上也不会把它们关在里面，因为据说一只黑天鹅价值6000块。各处少不了照的四处通明，小偷无处可藏的霓虹灯，使得这公园才有晚上这许多人的光顾。\n\n&emsp;&emsp;最显眼的要数西边的一个转动的水车，据我们多次观察，一致断定，水车不是电动的。它的半径有大概7至8米宽，时刻不停地被水流带动着转动，水车上装有装水的竹筒，只可惜没有一个引水的小沟，竹筒里的水随着水车的转动来到半空，然后被无情的抛弃，直落下来，像被抛弃的婴儿，有的溅到他母亲的身上像是手脚有力气抓住母亲衣角，有的直接落在了母亲脚下随着水流而下，发出几声哄哄的哀鸣。对了，这像泉水一样泄入小湖里带动水车转动的水是哪里来的？三岁小孩也能思索的出，是用水泵时刻不停来回抽取的。因为站在离泉眼附近还能感觉到水泵的震动，仿佛是汶川地震的余震。东边也如此炮制，只是少了个水车，只剩下拙略的剩有人类加工过的瀑布，发出嚯嚯嚯的噪音，似乎纪律缺管的刚成立的地下组织在召开激烈的讨论会。\n\n&emsp;&emsp;绕这个椭圆形的小湖快步一圈大概要花二十分钟左右，因为刚刚有一个白运动衫胖大阿姨快步从我身边经过，如今过了将近二十分钟，白色胖大身影又从我眼前掠过，若不是我眼花或者看到了鬼，又或者那个阿姨在那个凳子上面歇息过，我的估计就应该是比较准确的。她第三次经过我的身边时我真好正对着她，看了个仔细，人家哪是阿姨啊，反正女士的年龄总跟她们的心思一样是个谜。我沿着湖走了一圈，花了三十多分钟，然后发现，的确走不动了，结论是，这双鞋确实买的小了，伤脚。于是找了湖男岸木质小路上的一个金属冷条凳坐下。身上带有刚刚步行时附着在身上的余温，还可以抵御的了这条凳的寒，这如白天一样的黑夜的冷。\n\n&emsp;&emsp;今天是农历十三，我抬头望了望天，月面的一边少了一圈，像被馋嘴偷吃的小孩沿着边掉了，月亮光洁的挂不住任何云彩做成的面纱，像接掉红头巾的新娘，但是她却独守空房，因为今天的天空没有一丝云彩，新郎大概被亲朋好友拉去灌酒了。仔细瞧才发现不远处有一个星，若不是有点儿高中的天文知识谁也不会想到那个便是著名的太白金星，因为它的光亮全被皎洁的月夺去了，但是它却依然不依不舍的守在月的身旁，看样子对月一片真心。\n\n&emsp;&emsp;远处天边升起了一个孔明灯，大概是孔明灯，在天空中往西斜飘了一阵便熄灭了，大概放孔明灯的人的愿望实现不了了，好失望伤心啊！过了一会儿另一个孔明灯又升起来了，这次也是向西，似乎在追寻前一个似的，它追了好远好远，但是心上人已经不在了。黑暗一点点的吞没了孤单的它，然后天幕就只是黑暗的天下。\n\n&emsp;&emsp;公园北边是一些居民楼，还有一栋灯火通明的教学楼，那是我初中时上课的地方。窗口正对着我，日光灯根根可数，灯光下大概又是困顿发倦的自习生。对岸霓虹灯的灯光照在湖面反射进双眼，水面承载着大量的面波震动信息，波光粼粼照的人有些眩晕。几个晚上锻炼身体的小孩子不时的从我眼前跑过，喘着粗气。我想告诉他们晚饭过后不适宜跑，逛逛就行了。顺着他们跑过去的方向看去，一个穿着单薄迷彩服蓬乱头发的小伙子从路上走到湖边的大石头上坐了下来，一动不动的看着湖面，像是有心事。又或者他本来就是一个疯子。也许他看着我傻傻的坐在这儿也以为是一个疯子呢！过了一会儿他向我这边走过来，靠近我时从岸边地上捡起一块鹅卵石，我以为他听到我心里说他是疯子要赶过来报复呢，我的脚因为寒冷而哆嗦着，要跑的话估计也来不及了。谁知他把鹅卵石向湖中一仍，然后傻兮兮的冲我笑了一笑，然后跑掉了。\n\n&emsp;&emsp;突然水面扰动起来，水纹显示从湖心小岛方向有东西向我这边游过来，像电影中鳄鱼游动留下的激起的水面。不过这里哪来鳄鱼啊，我为自己的想法而发笑，好奇心驱使我起来去看个究竟。一看，发现是一只在水面游动的老鼠，正思索着它游过来的目的，它看到了我，吓得来了个大潜水，等再起来时已经到岸了，然后迅速找了自己的老洞躲了起来。我靠近岸边，想看看它是否因为心急紧张而跑错了路。过了一会儿又一只老鼠从湖心游过来，这次这只小一些，游得慢一些，像刚学会游泳。我故意跺了一脚，像上一只一样的，它也潜进了水里，不过它起来的时候还在原地，远没有上一只灵敏矫捷。我不忍心再吓它，万一要是这只是上一只的媳妇儿，我吓了她，待会儿她的老公来找我报仇就麻烦了。终于她费了九牛二虎之力游到了岸边。\n\n&emsp;&emsp;电话响起了，我酝酿了好多话要讲，可是讲话可不比写文章啊，说起来什么都忘了。\n\n","slug":"饭后感2","published":1,"updated":"2024-05-26T14:17:36.845Z","comments":1,"layout":"post","photos":[],"_id":"cmh498iop001iwvoubyxeg7ne","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>&emsp;&emsp;吃过晚饭，忽然想起有通电话未打，于是下楼拨通了号码，有事忙，待会儿打来。于是决定出去转转。</p>\n<p>&emsp;&emsp;不知不觉到了街边的小公园。其实冬天寒冷的夜晚没有几个露天的好地方可以用于人们晚上饭后游览。</p>\n<p>&emsp;&emsp;我也不知道这算不算个公园，公园的意思大概就是公开的用于大家游览的地方。公园中间有一个人工小湖，其他的花草树木小设施都是围绕着这个湖簇拥着。湖中心象征似的修了个小岛，岛上除了和岸边相同的树木的装饰，还有一个比较显眼的小屋子。见到了事实真相就缺少了几分想象，那个屋子是几只黑天鹅的黑色小屋子。白天也没见里面住过天鹅，大概里面的居住条件不好吧，估计晚上也不会把它们关在里面，因为据说一只黑天鹅价值6000块。各处少不了照的四处通明，小偷无处可藏的霓虹灯，使得这公园才有晚上这许多人的光顾。</p>\n<p>&emsp;&emsp;最显眼的要数西边的一个转动的水车，据我们多次观察，一致断定，水车不是电动的。它的半径有大概7至8米宽，时刻不停地被水流带动着转动，水车上装有装水的竹筒，只可惜没有一个引水的小沟，竹筒里的水随着水车的转动来到半空，然后被无情的抛弃，直落下来，像被抛弃的婴儿，有的溅到他母亲的身上像是手脚有力气抓住母亲衣角，有的直接落在了母亲脚下随着水流而下，发出几声哄哄的哀鸣。对了，这像泉水一样泄入小湖里带动水车转动的水是哪里来的？三岁小孩也能思索的出，是用水泵时刻不停来回抽取的。因为站在离泉眼附近还能感觉到水泵的震动，仿佛是汶川地震的余震。东边也如此炮制，只是少了个水车，只剩下拙略的剩有人类加工过的瀑布，发出嚯嚯嚯的噪音，似乎纪律缺管的刚成立的地下组织在召开激烈的讨论会。</p>\n<p>&emsp;&emsp;绕这个椭圆形的小湖快步一圈大概要花二十分钟左右，因为刚刚有一个白运动衫胖大阿姨快步从我身边经过，如今过了将近二十分钟，白色胖大身影又从我眼前掠过，若不是我眼花或者看到了鬼，又或者那个阿姨在那个凳子上面歇息过，我的估计就应该是比较准确的。她第三次经过我的身边时我真好正对着她，看了个仔细，人家哪是阿姨啊，反正女士的年龄总跟她们的心思一样是个谜。我沿着湖走了一圈，花了三十多分钟，然后发现，的确走不动了，结论是，这双鞋确实买的小了，伤脚。于是找了湖男岸木质小路上的一个金属冷条凳坐下。身上带有刚刚步行时附着在身上的余温，还可以抵御的了这条凳的寒，这如白天一样的黑夜的冷。</p>\n<p>&emsp;&emsp;今天是农历十三，我抬头望了望天，月面的一边少了一圈，像被馋嘴偷吃的小孩沿着边掉了，月亮光洁的挂不住任何云彩做成的面纱，像接掉红头巾的新娘，但是她却独守空房，因为今天的天空没有一丝云彩，新郎大概被亲朋好友拉去灌酒了。仔细瞧才发现不远处有一个星，若不是有点儿高中的天文知识谁也不会想到那个便是著名的太白金星，因为它的光亮全被皎洁的月夺去了，但是它却依然不依不舍的守在月的身旁，看样子对月一片真心。</p>\n<p>&emsp;&emsp;远处天边升起了一个孔明灯，大概是孔明灯，在天空中往西斜飘了一阵便熄灭了，大概放孔明灯的人的愿望实现不了了，好失望伤心啊！过了一会儿另一个孔明灯又升起来了，这次也是向西，似乎在追寻前一个似的，它追了好远好远，但是心上人已经不在了。黑暗一点点的吞没了孤单的它，然后天幕就只是黑暗的天下。</p>\n<p>&emsp;&emsp;公园北边是一些居民楼，还有一栋灯火通明的教学楼，那是我初中时上课的地方。窗口正对着我，日光灯根根可数，灯光下大概又是困顿发倦的自习生。对岸霓虹灯的灯光照在湖面反射进双眼，水面承载着大量的面波震动信息，波光粼粼照的人有些眩晕。几个晚上锻炼身体的小孩子不时的从我眼前跑过，喘着粗气。我想告诉他们晚饭过后不适宜跑，逛逛就行了。顺着他们跑过去的方向看去，一个穿着单薄迷彩服蓬乱头发的小伙子从路上走到湖边的大石头上坐了下来，一动不动的看着湖面，像是有心事。又或者他本来就是一个疯子。也许他看着我傻傻的坐在这儿也以为是一个疯子呢！过了一会儿他向我这边走过来，靠近我时从岸边地上捡起一块鹅卵石，我以为他听到我心里说他是疯子要赶过来报复呢，我的脚因为寒冷而哆嗦着，要跑的话估计也来不及了。谁知他把鹅卵石向湖中一仍，然后傻兮兮的冲我笑了一笑，然后跑掉了。</p>\n<p>&emsp;&emsp;突然水面扰动起来，水纹显示从湖心小岛方向有东西向我这边游过来，像电影中鳄鱼游动留下的激起的水面。不过这里哪来鳄鱼啊，我为自己的想法而发笑，好奇心驱使我起来去看个究竟。一看，发现是一只在水面游动的老鼠，正思索着它游过来的目的，它看到了我，吓得来了个大潜水，等再起来时已经到岸了，然后迅速找了自己的老洞躲了起来。我靠近岸边，想看看它是否因为心急紧张而跑错了路。过了一会儿又一只老鼠从湖心游过来，这次这只小一些，游得慢一些，像刚学会游泳。我故意跺了一脚，像上一只一样的，它也潜进了水里，不过它起来的时候还在原地，远没有上一只灵敏矫捷。我不忍心再吓它，万一要是这只是上一只的媳妇儿，我吓了她，待会儿她的老公来找我报仇就麻烦了。终于她费了九牛二虎之力游到了岸边。</p>\n<p>&emsp;&emsp;电话响起了，我酝酿了好多话要讲，可是讲话可不比写文章啊，说起来什么都忘了。</p>\n","related_posts":[],"length":2133,"excerpt":"","more":"<p>&emsp;&emsp;吃过晚饭，忽然想起有通电话未打，于是下楼拨通了号码，有事忙，待会儿打来。于是决定出去转转。</p>\n<p>&emsp;&emsp;不知不觉到了街边的小公园。其实冬天寒冷的夜晚没有几个露天的好地方可以用于人们晚上饭后游览。</p>\n<p>&emsp;&emsp;我也不知道这算不算个公园，公园的意思大概就是公开的用于大家游览的地方。公园中间有一个人工小湖，其他的花草树木小设施都是围绕着这个湖簇拥着。湖中心象征似的修了个小岛，岛上除了和岸边相同的树木的装饰，还有一个比较显眼的小屋子。见到了事实真相就缺少了几分想象，那个屋子是几只黑天鹅的黑色小屋子。白天也没见里面住过天鹅，大概里面的居住条件不好吧，估计晚上也不会把它们关在里面，因为据说一只黑天鹅价值6000块。各处少不了照的四处通明，小偷无处可藏的霓虹灯，使得这公园才有晚上这许多人的光顾。</p>\n<p>&emsp;&emsp;最显眼的要数西边的一个转动的水车，据我们多次观察，一致断定，水车不是电动的。它的半径有大概7至8米宽，时刻不停地被水流带动着转动，水车上装有装水的竹筒，只可惜没有一个引水的小沟，竹筒里的水随着水车的转动来到半空，然后被无情的抛弃，直落下来，像被抛弃的婴儿，有的溅到他母亲的身上像是手脚有力气抓住母亲衣角，有的直接落在了母亲脚下随着水流而下，发出几声哄哄的哀鸣。对了，这像泉水一样泄入小湖里带动水车转动的水是哪里来的？三岁小孩也能思索的出，是用水泵时刻不停来回抽取的。因为站在离泉眼附近还能感觉到水泵的震动，仿佛是汶川地震的余震。东边也如此炮制，只是少了个水车，只剩下拙略的剩有人类加工过的瀑布，发出嚯嚯嚯的噪音，似乎纪律缺管的刚成立的地下组织在召开激烈的讨论会。</p>\n<p>&emsp;&emsp;绕这个椭圆形的小湖快步一圈大概要花二十分钟左右，因为刚刚有一个白运动衫胖大阿姨快步从我身边经过，如今过了将近二十分钟，白色胖大身影又从我眼前掠过，若不是我眼花或者看到了鬼，又或者那个阿姨在那个凳子上面歇息过，我的估计就应该是比较准确的。她第三次经过我的身边时我真好正对着她，看了个仔细，人家哪是阿姨啊，反正女士的年龄总跟她们的心思一样是个谜。我沿着湖走了一圈，花了三十多分钟，然后发现，的确走不动了，结论是，这双鞋确实买的小了，伤脚。于是找了湖男岸木质小路上的一个金属冷条凳坐下。身上带有刚刚步行时附着在身上的余温，还可以抵御的了这条凳的寒，这如白天一样的黑夜的冷。</p>\n<p>&emsp;&emsp;今天是农历十三，我抬头望了望天，月面的一边少了一圈，像被馋嘴偷吃的小孩沿着边掉了，月亮光洁的挂不住任何云彩做成的面纱，像接掉红头巾的新娘，但是她却独守空房，因为今天的天空没有一丝云彩，新郎大概被亲朋好友拉去灌酒了。仔细瞧才发现不远处有一个星，若不是有点儿高中的天文知识谁也不会想到那个便是著名的太白金星，因为它的光亮全被皎洁的月夺去了，但是它却依然不依不舍的守在月的身旁，看样子对月一片真心。</p>\n<p>&emsp;&emsp;远处天边升起了一个孔明灯，大概是孔明灯，在天空中往西斜飘了一阵便熄灭了，大概放孔明灯的人的愿望实现不了了，好失望伤心啊！过了一会儿另一个孔明灯又升起来了，这次也是向西，似乎在追寻前一个似的，它追了好远好远，但是心上人已经不在了。黑暗一点点的吞没了孤单的它，然后天幕就只是黑暗的天下。</p>\n<p>&emsp;&emsp;公园北边是一些居民楼，还有一栋灯火通明的教学楼，那是我初中时上课的地方。窗口正对着我，日光灯根根可数，灯光下大概又是困顿发倦的自习生。对岸霓虹灯的灯光照在湖面反射进双眼，水面承载着大量的面波震动信息，波光粼粼照的人有些眩晕。几个晚上锻炼身体的小孩子不时的从我眼前跑过，喘着粗气。我想告诉他们晚饭过后不适宜跑，逛逛就行了。顺着他们跑过去的方向看去，一个穿着单薄迷彩服蓬乱头发的小伙子从路上走到湖边的大石头上坐了下来，一动不动的看着湖面，像是有心事。又或者他本来就是一个疯子。也许他看着我傻傻的坐在这儿也以为是一个疯子呢！过了一会儿他向我这边走过来，靠近我时从岸边地上捡起一块鹅卵石，我以为他听到我心里说他是疯子要赶过来报复呢，我的脚因为寒冷而哆嗦着，要跑的话估计也来不及了。谁知他把鹅卵石向湖中一仍，然后傻兮兮的冲我笑了一笑，然后跑掉了。</p>\n<p>&emsp;&emsp;突然水面扰动起来，水纹显示从湖心小岛方向有东西向我这边游过来，像电影中鳄鱼游动留下的激起的水面。不过这里哪来鳄鱼啊，我为自己的想法而发笑，好奇心驱使我起来去看个究竟。一看，发现是一只在水面游动的老鼠，正思索着它游过来的目的，它看到了我，吓得来了个大潜水，等再起来时已经到岸了，然后迅速找了自己的老洞躲了起来。我靠近岸边，想看看它是否因为心急紧张而跑错了路。过了一会儿又一只老鼠从湖心游过来，这次这只小一些，游得慢一些，像刚学会游泳。我故意跺了一脚，像上一只一样的，它也潜进了水里，不过它起来的时候还在原地，远没有上一只灵敏矫捷。我不忍心再吓它，万一要是这只是上一只的媳妇儿，我吓了她，待会儿她的老公来找我报仇就麻烦了。终于她费了九牛二虎之力游到了岸边。</p>\n<p>&emsp;&emsp;电话响起了，我酝酿了好多话要讲，可是讲话可不比写文章啊，说起来什么都忘了。</p>\n"},{"title":"流水三","abbrlink":39483,"date":"2010-04-30T05:19:32.000Z","_content":"\n&emsp;&emsp;“阿三，我打你的电话试一下，你别接！”小白转过身对阿三说道。\n\n&emsp;&emsp;“好！”阿三正专心的在魔兽世界里镇压敌军。手机铃声响了两声，然后停了。\n\n&emsp;&emsp;“我刚充了话费，所以打你的电话试一下。”\n\n&emsp;&emsp;“充上了吗？”\n\n&emsp;&emsp;“充上了啊，要不然怎么能打通你的手机？”\n\n&emsp;&emsp;“你打了我手机吗？”\n\n&emsp;&emsp;每天早上从床上爬起来都是一件让人烦恼的事情，不，那种感觉不应该叫做烦恼，床就像人的恋人，让你离开你的恋人的感觉总归是难以割舍。不过我们对这个恋人倒是残忍至极，晚上回来睡他，白天却留她孤零零一个。\n\n&emsp;&emsp;总会在清晨醒一次，但那个时候的我大概只是在睡魔的疏忽下溜出梦的监牢出来透透风。天已经大亮。只是不知道太阳有没有游览到这块院子。以为已经八九点光景。然后打开手机，原来只六点多，迅速编辑一条短信，通常在我来不及意识到短信是否发出的那一刻睡魔就抓住了我，再次陷入朦胧的梦境，很难忆起梦境的人事。\n\n&emsp;&emsp;如果课是在上午，下午或者晚上，那么我肯定会在上午，下午或者晚上打瞌睡，简而言之就是，上课的时候我总会不知不觉不能自已的打瞌睡。曾经有人拿老鼠做过实验，想方设法让老鼠不能睡觉，结果老鼠在第13天的时候就死掉了，因为没有睡觉的缘故，呃，这家伙真是残忍。我在想要是再这么下去我会不会也尽快的死掉了。呵呵，还是得认真调整一下生物钟了，拿一个整天来睡觉或许是个比较好的办法。\n\n&emsp;&emsp;我试着给自己写一首打油诗的评语，不过还没有完成，因为我不知道自己以后会是怎么样的，所以那首打油诗一直都没有完成，也许人本来就无法知道自己以后的路该怎么走。\n\n&emsp;&emsp;我把自行车推去校园自行车行修了，我不会记恨因为他儿摔过，呵呵，大概我只会畏惧。\n\n&emsp;&emsp;在看正负2摄氏度的视频，突然觉得人类是多么无知渺小啊，活着真好，真糟糕！\n\n","source":"_posts/2010-04-30-流水三.md","raw":"---\ntitle: 流水三\ncategories:\n  - 日记\ntags:\nabbrlink: 39483\ndate: 2010-04-30 13:19:32\n---\n\n&emsp;&emsp;“阿三，我打你的电话试一下，你别接！”小白转过身对阿三说道。\n\n&emsp;&emsp;“好！”阿三正专心的在魔兽世界里镇压敌军。手机铃声响了两声，然后停了。\n\n&emsp;&emsp;“我刚充了话费，所以打你的电话试一下。”\n\n&emsp;&emsp;“充上了吗？”\n\n&emsp;&emsp;“充上了啊，要不然怎么能打通你的手机？”\n\n&emsp;&emsp;“你打了我手机吗？”\n\n&emsp;&emsp;每天早上从床上爬起来都是一件让人烦恼的事情，不，那种感觉不应该叫做烦恼，床就像人的恋人，让你离开你的恋人的感觉总归是难以割舍。不过我们对这个恋人倒是残忍至极，晚上回来睡他，白天却留她孤零零一个。\n\n&emsp;&emsp;总会在清晨醒一次，但那个时候的我大概只是在睡魔的疏忽下溜出梦的监牢出来透透风。天已经大亮。只是不知道太阳有没有游览到这块院子。以为已经八九点光景。然后打开手机，原来只六点多，迅速编辑一条短信，通常在我来不及意识到短信是否发出的那一刻睡魔就抓住了我，再次陷入朦胧的梦境，很难忆起梦境的人事。\n\n&emsp;&emsp;如果课是在上午，下午或者晚上，那么我肯定会在上午，下午或者晚上打瞌睡，简而言之就是，上课的时候我总会不知不觉不能自已的打瞌睡。曾经有人拿老鼠做过实验，想方设法让老鼠不能睡觉，结果老鼠在第13天的时候就死掉了，因为没有睡觉的缘故，呃，这家伙真是残忍。我在想要是再这么下去我会不会也尽快的死掉了。呵呵，还是得认真调整一下生物钟了，拿一个整天来睡觉或许是个比较好的办法。\n\n&emsp;&emsp;我试着给自己写一首打油诗的评语，不过还没有完成，因为我不知道自己以后会是怎么样的，所以那首打油诗一直都没有完成，也许人本来就无法知道自己以后的路该怎么走。\n\n&emsp;&emsp;我把自行车推去校园自行车行修了，我不会记恨因为他儿摔过，呵呵，大概我只会畏惧。\n\n&emsp;&emsp;在看正负2摄氏度的视频，突然觉得人类是多么无知渺小啊，活着真好，真糟糕！\n\n","slug":"流水三","published":1,"updated":"2024-05-26T14:17:36.845Z","comments":1,"layout":"post","photos":[],"_id":"cmh498ioq001lwvoua3jq3kua","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>&emsp;&emsp;“阿三，我打你的电话试一下，你别接！”小白转过身对阿三说道。</p>\n<p>&emsp;&emsp;“好！”阿三正专心的在魔兽世界里镇压敌军。手机铃声响了两声，然后停了。</p>\n<p>&emsp;&emsp;“我刚充了话费，所以打你的电话试一下。”</p>\n<p>&emsp;&emsp;“充上了吗？”</p>\n<p>&emsp;&emsp;“充上了啊，要不然怎么能打通你的手机？”</p>\n<p>&emsp;&emsp;“你打了我手机吗？”</p>\n<p>&emsp;&emsp;每天早上从床上爬起来都是一件让人烦恼的事情，不，那种感觉不应该叫做烦恼，床就像人的恋人，让你离开你的恋人的感觉总归是难以割舍。不过我们对这个恋人倒是残忍至极，晚上回来睡他，白天却留她孤零零一个。</p>\n<p>&emsp;&emsp;总会在清晨醒一次，但那个时候的我大概只是在睡魔的疏忽下溜出梦的监牢出来透透风。天已经大亮。只是不知道太阳有没有游览到这块院子。以为已经八九点光景。然后打开手机，原来只六点多，迅速编辑一条短信，通常在我来不及意识到短信是否发出的那一刻睡魔就抓住了我，再次陷入朦胧的梦境，很难忆起梦境的人事。</p>\n<p>&emsp;&emsp;如果课是在上午，下午或者晚上，那么我肯定会在上午，下午或者晚上打瞌睡，简而言之就是，上课的时候我总会不知不觉不能自已的打瞌睡。曾经有人拿老鼠做过实验，想方设法让老鼠不能睡觉，结果老鼠在第13天的时候就死掉了，因为没有睡觉的缘故，呃，这家伙真是残忍。我在想要是再这么下去我会不会也尽快的死掉了。呵呵，还是得认真调整一下生物钟了，拿一个整天来睡觉或许是个比较好的办法。</p>\n<p>&emsp;&emsp;我试着给自己写一首打油诗的评语，不过还没有完成，因为我不知道自己以后会是怎么样的，所以那首打油诗一直都没有完成，也许人本来就无法知道自己以后的路该怎么走。</p>\n<p>&emsp;&emsp;我把自行车推去校园自行车行修了，我不会记恨因为他儿摔过，呵呵，大概我只会畏惧。</p>\n<p>&emsp;&emsp;在看正负2摄氏度的视频，突然觉得人类是多么无知渺小啊，活着真好，真糟糕！</p>\n","related_posts":[],"length":841,"excerpt":"","more":"<p>&emsp;&emsp;“阿三，我打你的电话试一下，你别接！”小白转过身对阿三说道。</p>\n<p>&emsp;&emsp;“好！”阿三正专心的在魔兽世界里镇压敌军。手机铃声响了两声，然后停了。</p>\n<p>&emsp;&emsp;“我刚充了话费，所以打你的电话试一下。”</p>\n<p>&emsp;&emsp;“充上了吗？”</p>\n<p>&emsp;&emsp;“充上了啊，要不然怎么能打通你的手机？”</p>\n<p>&emsp;&emsp;“你打了我手机吗？”</p>\n<p>&emsp;&emsp;每天早上从床上爬起来都是一件让人烦恼的事情，不，那种感觉不应该叫做烦恼，床就像人的恋人，让你离开你的恋人的感觉总归是难以割舍。不过我们对这个恋人倒是残忍至极，晚上回来睡他，白天却留她孤零零一个。</p>\n<p>&emsp;&emsp;总会在清晨醒一次，但那个时候的我大概只是在睡魔的疏忽下溜出梦的监牢出来透透风。天已经大亮。只是不知道太阳有没有游览到这块院子。以为已经八九点光景。然后打开手机，原来只六点多，迅速编辑一条短信，通常在我来不及意识到短信是否发出的那一刻睡魔就抓住了我，再次陷入朦胧的梦境，很难忆起梦境的人事。</p>\n<p>&emsp;&emsp;如果课是在上午，下午或者晚上，那么我肯定会在上午，下午或者晚上打瞌睡，简而言之就是，上课的时候我总会不知不觉不能自已的打瞌睡。曾经有人拿老鼠做过实验，想方设法让老鼠不能睡觉，结果老鼠在第13天的时候就死掉了，因为没有睡觉的缘故，呃，这家伙真是残忍。我在想要是再这么下去我会不会也尽快的死掉了。呵呵，还是得认真调整一下生物钟了，拿一个整天来睡觉或许是个比较好的办法。</p>\n<p>&emsp;&emsp;我试着给自己写一首打油诗的评语，不过还没有完成，因为我不知道自己以后会是怎么样的，所以那首打油诗一直都没有完成，也许人本来就无法知道自己以后的路该怎么走。</p>\n<p>&emsp;&emsp;我把自行车推去校园自行车行修了，我不会记恨因为他儿摔过，呵呵，大概我只会畏惧。</p>\n<p>&emsp;&emsp;在看正负2摄氏度的视频，突然觉得人类是多么无知渺小啊，活着真好，真糟糕！</p>\n"},{"title":"扑克","abbrlink":9684,"date":"2010-08-10T05:39:52.000Z","_content":"\n&emsp;&emsp;“诶～你又耍赖啊！”木斯灰白的眉毛往上挑动了一下，用奇怪的眼神看着坐在眼前的小佳。\n\n&emsp;&emsp;小佳身子有些发福了，脸圆圆的，头发花白遗留着很久以前烫染过的痕迹。她不敢看木斯的眼睛，只盯着手里握着的几张扑克，学小女生的样子撅了一下嘴，柔声说：“我哪有啊！”仍然没有敢看木斯的眼。\n\n&emsp;&emsp;木斯的眼睛躲在一副棕色镜框厚厚镜片的老花镜后面，眼里泛着些浑浊的光，说到：“欺负我的眼神不好，是不是？刚才明明看见你换牌了，还有，上一把也是……你说大牌作弊换牌还有什么……”\n\n&emsp;&emsp;“喂喂，我好心考考你的眼力，你却在这里罗哩罗嗦的一大通废话，太过分了吧！小心我捶你哦！”小佳抬起了肥胖的右手，手掌握成了松散的拳头，瞄准着木斯的肩膀，准备把这一拳像炮弹一样投过去。\n\n&emsp;&emsp;“呃，打牌嘛，何必那么认真呢，呵呵！”木斯被小佳的拳头震慑住了显得有些胆怯，做出妥协的样子。小佳忽然放下了手中的拳头，两个人开始笑起来，开怀的笑着。木斯的花白头发在灯光的照耀下反射出阵阵油光。\n\n&emsp;&emsp;木斯今年67岁，已经退休两年了，其实他早可以退掉的，只是单位新苗子都能力欠佳，上级也不放心木斯走了以后单位落到一群光吃饭不干事的家伙手里，于是千方百计的要留下木斯这个老资历。其实木斯心里明白，上级说的话有一半可信就不错了。单位好只狼都盯着他的位置，明争暗斗，自己要是一下台，单位准被这群狼弄得支离破碎。所以上级是需要木斯这个老好人在局长这个位置上再撑几年的。一方面为了稳定大局，一方面木斯也老了，许多事情管不过来，上级也可以好好过过瞎眼牧人的日子。\n\n&emsp;&emsp;可是现在，所有这些都不关木斯的事情了。为了工作，他已经耽误了太多的时间。他终身没有娶亲，因为他和小佳说好了：要是35岁之前，我未娶你未嫁，那么我们就在一起。\n\n&emsp;&emsp;他欠小佳太多太多。35岁时他本想辞掉工作去找小佳的，可是那是正是他工作事业的上升期，上级准备提木斯，升他的职。他咬咬牙，心想，也许小佳早已经嫁人了。自己去找她也许会落的一鼻子的灰，会伤透自己的心，而且现在事业蒸蒸日上，如何能离开？于是，在他的岗位上一干就是32年。这32年来，如何好好工作，好好表现无时无刻不在他的生活中交织。因为工作的关系，他很少停下来想，想自己真正想要的是什么，真正的幸福是什么！有时候夜里为莫名的噩梦惊醒，会忽然想起自己脑海的深处原来藏着一个时刻惦记自己的人。那个人时隐时现，木斯想伸手抓住，可是她却越飘越远。\n\n&emsp;&emsp;小佳是在34岁时辞掉工作的，木斯那时候35岁。她回到了当初他们相识的地方，她怀着满心的欢喜，心想，木斯肯定会在那里等她的。可当她来到这里时，木斯根本就不在。小佳很伤心，伤心过后又是一阵担心。然后又在内心琢磨，自我安慰，自我嘲笑，当初是说过你未娶我未嫁，然后就在一起的，但也许木斯已经和别人组成了家，过着幸福的生活。自己的愿望是彼此过着幸福的生活，即使不在一起那又有什么关系呢！于是，她擦掉了眼泪，开始过着自己想要的生活。她喜欢写作，于是就观察生活，写生活，如今她的作品已经在市面上大卖，成了一个知名的作家。她爱画画，于是也认真学画画，画自己的内心世界，她的画也价值不匪。\n\n&emsp;&emsp;等了这许多年，她终于等到了那个久违的木斯。木斯也为见到玲而开心不已。他以为自己的幽默风趣会被几十年的腐奢生活工作磨耗，他还有好多话要说给玲听。是的，他终于有机会把心里的话说给她听，她也终于不用在夜深了却孤单入眠。\n\n&emsp;&emsp;只要他们在一起，生命就还有好长好长，他们不用在因为怕没有事情忘记做而遗憾而悔恨。\n\n&emsp;&emsp;8月7日在望江路和金寨路交口的地下通道碰到一对玩扑克的老妪和老头。呵呵，愿他们永远幸福^_^\n\n","source":"_posts/2010-08-10-扑克.md","raw":"---\ntitle: 扑克\ncategories:\n  - 乱笔\ntags:\nabbrlink: 9684\ndate: 2010-08-10 13:39:52\n---\n\n&emsp;&emsp;“诶～你又耍赖啊！”木斯灰白的眉毛往上挑动了一下，用奇怪的眼神看着坐在眼前的小佳。\n\n&emsp;&emsp;小佳身子有些发福了，脸圆圆的，头发花白遗留着很久以前烫染过的痕迹。她不敢看木斯的眼睛，只盯着手里握着的几张扑克，学小女生的样子撅了一下嘴，柔声说：“我哪有啊！”仍然没有敢看木斯的眼。\n\n&emsp;&emsp;木斯的眼睛躲在一副棕色镜框厚厚镜片的老花镜后面，眼里泛着些浑浊的光，说到：“欺负我的眼神不好，是不是？刚才明明看见你换牌了，还有，上一把也是……你说大牌作弊换牌还有什么……”\n\n&emsp;&emsp;“喂喂，我好心考考你的眼力，你却在这里罗哩罗嗦的一大通废话，太过分了吧！小心我捶你哦！”小佳抬起了肥胖的右手，手掌握成了松散的拳头，瞄准着木斯的肩膀，准备把这一拳像炮弹一样投过去。\n\n&emsp;&emsp;“呃，打牌嘛，何必那么认真呢，呵呵！”木斯被小佳的拳头震慑住了显得有些胆怯，做出妥协的样子。小佳忽然放下了手中的拳头，两个人开始笑起来，开怀的笑着。木斯的花白头发在灯光的照耀下反射出阵阵油光。\n\n&emsp;&emsp;木斯今年67岁，已经退休两年了，其实他早可以退掉的，只是单位新苗子都能力欠佳，上级也不放心木斯走了以后单位落到一群光吃饭不干事的家伙手里，于是千方百计的要留下木斯这个老资历。其实木斯心里明白，上级说的话有一半可信就不错了。单位好只狼都盯着他的位置，明争暗斗，自己要是一下台，单位准被这群狼弄得支离破碎。所以上级是需要木斯这个老好人在局长这个位置上再撑几年的。一方面为了稳定大局，一方面木斯也老了，许多事情管不过来，上级也可以好好过过瞎眼牧人的日子。\n\n&emsp;&emsp;可是现在，所有这些都不关木斯的事情了。为了工作，他已经耽误了太多的时间。他终身没有娶亲，因为他和小佳说好了：要是35岁之前，我未娶你未嫁，那么我们就在一起。\n\n&emsp;&emsp;他欠小佳太多太多。35岁时他本想辞掉工作去找小佳的，可是那是正是他工作事业的上升期，上级准备提木斯，升他的职。他咬咬牙，心想，也许小佳早已经嫁人了。自己去找她也许会落的一鼻子的灰，会伤透自己的心，而且现在事业蒸蒸日上，如何能离开？于是，在他的岗位上一干就是32年。这32年来，如何好好工作，好好表现无时无刻不在他的生活中交织。因为工作的关系，他很少停下来想，想自己真正想要的是什么，真正的幸福是什么！有时候夜里为莫名的噩梦惊醒，会忽然想起自己脑海的深处原来藏着一个时刻惦记自己的人。那个人时隐时现，木斯想伸手抓住，可是她却越飘越远。\n\n&emsp;&emsp;小佳是在34岁时辞掉工作的，木斯那时候35岁。她回到了当初他们相识的地方，她怀着满心的欢喜，心想，木斯肯定会在那里等她的。可当她来到这里时，木斯根本就不在。小佳很伤心，伤心过后又是一阵担心。然后又在内心琢磨，自我安慰，自我嘲笑，当初是说过你未娶我未嫁，然后就在一起的，但也许木斯已经和别人组成了家，过着幸福的生活。自己的愿望是彼此过着幸福的生活，即使不在一起那又有什么关系呢！于是，她擦掉了眼泪，开始过着自己想要的生活。她喜欢写作，于是就观察生活，写生活，如今她的作品已经在市面上大卖，成了一个知名的作家。她爱画画，于是也认真学画画，画自己的内心世界，她的画也价值不匪。\n\n&emsp;&emsp;等了这许多年，她终于等到了那个久违的木斯。木斯也为见到玲而开心不已。他以为自己的幽默风趣会被几十年的腐奢生活工作磨耗，他还有好多话要说给玲听。是的，他终于有机会把心里的话说给她听，她也终于不用在夜深了却孤单入眠。\n\n&emsp;&emsp;只要他们在一起，生命就还有好长好长，他们不用在因为怕没有事情忘记做而遗憾而悔恨。\n\n&emsp;&emsp;8月7日在望江路和金寨路交口的地下通道碰到一对玩扑克的老妪和老头。呵呵，愿他们永远幸福^_^\n\n","slug":"扑克","published":1,"updated":"2024-05-26T14:17:36.845Z","comments":1,"layout":"post","photos":[],"_id":"cmh498ioq001pwvou2ksyf3ab","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>&emsp;&emsp;“诶～你又耍赖啊！”木斯灰白的眉毛往上挑动了一下，用奇怪的眼神看着坐在眼前的小佳。</p>\n<p>&emsp;&emsp;小佳身子有些发福了，脸圆圆的，头发花白遗留着很久以前烫染过的痕迹。她不敢看木斯的眼睛，只盯着手里握着的几张扑克，学小女生的样子撅了一下嘴，柔声说：“我哪有啊！”仍然没有敢看木斯的眼。</p>\n<p>&emsp;&emsp;木斯的眼睛躲在一副棕色镜框厚厚镜片的老花镜后面，眼里泛着些浑浊的光，说到：“欺负我的眼神不好，是不是？刚才明明看见你换牌了，还有，上一把也是……你说大牌作弊换牌还有什么……”</p>\n<p>&emsp;&emsp;“喂喂，我好心考考你的眼力，你却在这里罗哩罗嗦的一大通废话，太过分了吧！小心我捶你哦！”小佳抬起了肥胖的右手，手掌握成了松散的拳头，瞄准着木斯的肩膀，准备把这一拳像炮弹一样投过去。</p>\n<p>&emsp;&emsp;“呃，打牌嘛，何必那么认真呢，呵呵！”木斯被小佳的拳头震慑住了显得有些胆怯，做出妥协的样子。小佳忽然放下了手中的拳头，两个人开始笑起来，开怀的笑着。木斯的花白头发在灯光的照耀下反射出阵阵油光。</p>\n<p>&emsp;&emsp;木斯今年67岁，已经退休两年了，其实他早可以退掉的，只是单位新苗子都能力欠佳，上级也不放心木斯走了以后单位落到一群光吃饭不干事的家伙手里，于是千方百计的要留下木斯这个老资历。其实木斯心里明白，上级说的话有一半可信就不错了。单位好只狼都盯着他的位置，明争暗斗，自己要是一下台，单位准被这群狼弄得支离破碎。所以上级是需要木斯这个老好人在局长这个位置上再撑几年的。一方面为了稳定大局，一方面木斯也老了，许多事情管不过来，上级也可以好好过过瞎眼牧人的日子。</p>\n<p>&emsp;&emsp;可是现在，所有这些都不关木斯的事情了。为了工作，他已经耽误了太多的时间。他终身没有娶亲，因为他和小佳说好了：要是35岁之前，我未娶你未嫁，那么我们就在一起。</p>\n<p>&emsp;&emsp;他欠小佳太多太多。35岁时他本想辞掉工作去找小佳的，可是那是正是他工作事业的上升期，上级准备提木斯，升他的职。他咬咬牙，心想，也许小佳早已经嫁人了。自己去找她也许会落的一鼻子的灰，会伤透自己的心，而且现在事业蒸蒸日上，如何能离开？于是，在他的岗位上一干就是32年。这32年来，如何好好工作，好好表现无时无刻不在他的生活中交织。因为工作的关系，他很少停下来想，想自己真正想要的是什么，真正的幸福是什么！有时候夜里为莫名的噩梦惊醒，会忽然想起自己脑海的深处原来藏着一个时刻惦记自己的人。那个人时隐时现，木斯想伸手抓住，可是她却越飘越远。</p>\n<p>&emsp;&emsp;小佳是在34岁时辞掉工作的，木斯那时候35岁。她回到了当初他们相识的地方，她怀着满心的欢喜，心想，木斯肯定会在那里等她的。可当她来到这里时，木斯根本就不在。小佳很伤心，伤心过后又是一阵担心。然后又在内心琢磨，自我安慰，自我嘲笑，当初是说过你未娶我未嫁，然后就在一起的，但也许木斯已经和别人组成了家，过着幸福的生活。自己的愿望是彼此过着幸福的生活，即使不在一起那又有什么关系呢！于是，她擦掉了眼泪，开始过着自己想要的生活。她喜欢写作，于是就观察生活，写生活，如今她的作品已经在市面上大卖，成了一个知名的作家。她爱画画，于是也认真学画画，画自己的内心世界，她的画也价值不匪。</p>\n<p>&emsp;&emsp;等了这许多年，她终于等到了那个久违的木斯。木斯也为见到玲而开心不已。他以为自己的幽默风趣会被几十年的腐奢生活工作磨耗，他还有好多话要说给玲听。是的，他终于有机会把心里的话说给她听，她也终于不用在夜深了却孤单入眠。</p>\n<p>&emsp;&emsp;只要他们在一起，生命就还有好长好长，他们不用在因为怕没有事情忘记做而遗憾而悔恨。</p>\n<p>&emsp;&emsp;8月7日在望江路和金寨路交口的地下通道碰到一对玩扑克的老妪和老头。呵呵，愿他们永远幸福^_^</p>\n","related_posts":[],"length":1594,"excerpt":"","more":"<p>&emsp;&emsp;“诶～你又耍赖啊！”木斯灰白的眉毛往上挑动了一下，用奇怪的眼神看着坐在眼前的小佳。</p>\n<p>&emsp;&emsp;小佳身子有些发福了，脸圆圆的，头发花白遗留着很久以前烫染过的痕迹。她不敢看木斯的眼睛，只盯着手里握着的几张扑克，学小女生的样子撅了一下嘴，柔声说：“我哪有啊！”仍然没有敢看木斯的眼。</p>\n<p>&emsp;&emsp;木斯的眼睛躲在一副棕色镜框厚厚镜片的老花镜后面，眼里泛着些浑浊的光，说到：“欺负我的眼神不好，是不是？刚才明明看见你换牌了，还有，上一把也是……你说大牌作弊换牌还有什么……”</p>\n<p>&emsp;&emsp;“喂喂，我好心考考你的眼力，你却在这里罗哩罗嗦的一大通废话，太过分了吧！小心我捶你哦！”小佳抬起了肥胖的右手，手掌握成了松散的拳头，瞄准着木斯的肩膀，准备把这一拳像炮弹一样投过去。</p>\n<p>&emsp;&emsp;“呃，打牌嘛，何必那么认真呢，呵呵！”木斯被小佳的拳头震慑住了显得有些胆怯，做出妥协的样子。小佳忽然放下了手中的拳头，两个人开始笑起来，开怀的笑着。木斯的花白头发在灯光的照耀下反射出阵阵油光。</p>\n<p>&emsp;&emsp;木斯今年67岁，已经退休两年了，其实他早可以退掉的，只是单位新苗子都能力欠佳，上级也不放心木斯走了以后单位落到一群光吃饭不干事的家伙手里，于是千方百计的要留下木斯这个老资历。其实木斯心里明白，上级说的话有一半可信就不错了。单位好只狼都盯着他的位置，明争暗斗，自己要是一下台，单位准被这群狼弄得支离破碎。所以上级是需要木斯这个老好人在局长这个位置上再撑几年的。一方面为了稳定大局，一方面木斯也老了，许多事情管不过来，上级也可以好好过过瞎眼牧人的日子。</p>\n<p>&emsp;&emsp;可是现在，所有这些都不关木斯的事情了。为了工作，他已经耽误了太多的时间。他终身没有娶亲，因为他和小佳说好了：要是35岁之前，我未娶你未嫁，那么我们就在一起。</p>\n<p>&emsp;&emsp;他欠小佳太多太多。35岁时他本想辞掉工作去找小佳的，可是那是正是他工作事业的上升期，上级准备提木斯，升他的职。他咬咬牙，心想，也许小佳早已经嫁人了。自己去找她也许会落的一鼻子的灰，会伤透自己的心，而且现在事业蒸蒸日上，如何能离开？于是，在他的岗位上一干就是32年。这32年来，如何好好工作，好好表现无时无刻不在他的生活中交织。因为工作的关系，他很少停下来想，想自己真正想要的是什么，真正的幸福是什么！有时候夜里为莫名的噩梦惊醒，会忽然想起自己脑海的深处原来藏着一个时刻惦记自己的人。那个人时隐时现，木斯想伸手抓住，可是她却越飘越远。</p>\n<p>&emsp;&emsp;小佳是在34岁时辞掉工作的，木斯那时候35岁。她回到了当初他们相识的地方，她怀着满心的欢喜，心想，木斯肯定会在那里等她的。可当她来到这里时，木斯根本就不在。小佳很伤心，伤心过后又是一阵担心。然后又在内心琢磨，自我安慰，自我嘲笑，当初是说过你未娶我未嫁，然后就在一起的，但也许木斯已经和别人组成了家，过着幸福的生活。自己的愿望是彼此过着幸福的生活，即使不在一起那又有什么关系呢！于是，她擦掉了眼泪，开始过着自己想要的生活。她喜欢写作，于是就观察生活，写生活，如今她的作品已经在市面上大卖，成了一个知名的作家。她爱画画，于是也认真学画画，画自己的内心世界，她的画也价值不匪。</p>\n<p>&emsp;&emsp;等了这许多年，她终于等到了那个久违的木斯。木斯也为见到玲而开心不已。他以为自己的幽默风趣会被几十年的腐奢生活工作磨耗，他还有好多话要说给玲听。是的，他终于有机会把心里的话说给她听，她也终于不用在夜深了却孤单入眠。</p>\n<p>&emsp;&emsp;只要他们在一起，生命就还有好长好长，他们不用在因为怕没有事情忘记做而遗憾而悔恨。</p>\n<p>&emsp;&emsp;8月7日在望江路和金寨路交口的地下通道碰到一对玩扑克的老妪和老头。呵呵，愿他们永远幸福^_^</p>\n"},{"title":"消失的几天","abbrlink":10871,"date":"2010-10-11T05:12:12.000Z","_content":"\n&emsp;&emsp;顺便交代一下这个国庆是怎么过的吧！因为似乎这几天对好多人来说我都音信全无呢！\n\n&emsp;&emsp;九月二十几号接到一个任务，那就是：国庆节出差；更值得开心的是，出差地点是家乡。本来准备国庆依然决然的宅在办公室的，接到这份差事的我无疑是欣喜若狂。\n\n&emsp;&emsp;不过我们准备的不是很充分，而且单单讲求效率了，确切来讲是做了最好的打算以及相对于这个打算的最好的准备，当然这个准备扩大了实际达到的效果与预期的目标之间的差距与麻烦。一路上吃的还算不错都是家乡的口味，只是一路肚子都不舒服，说拉肚子倒又不是，总之胃部和肠道很是不给力。身上不知哪里来了几处伤疤，就像梦一样，因为梦也是不知道从哪里时开始。三四天前被蚊子叮的疮口现在都是猩红，这些蚊子难道就是传说中的外星来客？坐车对于我是最苦的差事，前后总共10天，总共算来大概有3天多时间是在车上呆着的。我自小是不晕车的（除了学前班时去动物园，看见隔座的同学晕车呕吐不觉也似乎干呕了一阵。），而此次坐车坐得我直想吐。\n\n&emsp;&emsp;值得夸耀开心的是在家乡见到了几年未见的老友。我们还一起在火锅前叙了旧。（顺便说一下，我现在这个身体这个胃是吃不了火锅的，吃不消，实在是吃不消！）还有有一晚的住宿问题是得到另一个好友的女朋友秋秋的帮忙解决的，还免费做了她的哥哥一回，这应该提提的，毕竟我比她大三天，不算亏的。末了还得谢谢他们俩的帮忙。另外就是见到了爸妈，见到了外公外婆，见到了舅舅舅妈，见到了小姨，见到了二姨父，很开心。还有就是在火车上闷着没事看完了三本阿加莎.克里斯蒂的悬疑侦探小说，还看了季羡林散文全编第五本的一半。阿加莎克里斯蒂的小说果然构思严谨缜密，总是出奇不意，种种结果总是让人始料未及，却又合情合理，故事也总是有条不紊的展开。然后昨晚没睡就想到也要写一个悬疑故事。（当然不睡也不完全是因为在构思这个故事，一大半原因是吵闹，还有本就在车上睡了一晚，睡得脑热头疼如何能入眠。）这也就是《爱妻之死》啦，我会慢慢写的，呵呵，第一次写这种类型，就当写着玩吧！\n\n&emsp;&emsp;刚刚洗了个澡。发现自己瘦了些。好吧，事实是，我也不清楚我是不是真的瘦了，也许只是因为三的一句玩笑。我发现自己的胳膊还有腿在变细（比之前细），肚子的赘肉在凸显，肉在变软，这正朝着我害怕的老年以后变得肉松皮皱，四肢小肚子大的趋势发展，这是多么恐怖啊，如果发生在自己身上。具体有没有变瘦还得经过磅秤的检验以后再说。总之之后的健身是少不了的了。\n\n&emsp;&emsp;这次出差欢喜甚多，收获不少，我们积累了一些野外布台的经验，许多都是自己吃了亏得来的。不过这些也不算亏，因为我们既没有被谁敲诈也没被骗，许多都是自己欠考虑，还得多坐了几次车，多跑了些路而已。读万卷书，行万里路，路跑多了总是没有错的。路跑多了就会知道以后想办法怎么让自己尽量少跑路，少走弯道。但是接下来就有麻烦了。因为出差的缘故，好多事情都堆在一起了，不过事是要一件一件做的，脚踏实地就好。还有就是出差或多或少是有补助的。既有补助又获得锻炼以及经验经历还能增进感情，所以大家都是愿意去的，但是却只让我们三人去。如果换作我不在这三个人里面我总是会眼红好一阵的。而我却实实在在的是在这三个人里面，如果别人问我，出差开心吗？我说好也不是，坏也不是。说好，别人就更加羡慕嫉妒恨，换作是我，我也会这样。说不好不开心，别人就会说你虚伪等等。总之左也不是右也难为。呵呵，早知道把请客吃饭摆在见面的招呼寒暄中了。\n\n&emsp;&emsp;头还是晕，睡不着，马上就上课了，别胡思乱想了，愿一切都好^_^\n\n","source":"_posts/2010-10-11-消失的几天.md","raw":"---\ntitle: 消失的几天\ncategories:\n  - 日记\ntags:\nabbrlink: 10871\ndate: 2010-10-11 13:12:12\n---\n\n&emsp;&emsp;顺便交代一下这个国庆是怎么过的吧！因为似乎这几天对好多人来说我都音信全无呢！\n\n&emsp;&emsp;九月二十几号接到一个任务，那就是：国庆节出差；更值得开心的是，出差地点是家乡。本来准备国庆依然决然的宅在办公室的，接到这份差事的我无疑是欣喜若狂。\n\n&emsp;&emsp;不过我们准备的不是很充分，而且单单讲求效率了，确切来讲是做了最好的打算以及相对于这个打算的最好的准备，当然这个准备扩大了实际达到的效果与预期的目标之间的差距与麻烦。一路上吃的还算不错都是家乡的口味，只是一路肚子都不舒服，说拉肚子倒又不是，总之胃部和肠道很是不给力。身上不知哪里来了几处伤疤，就像梦一样，因为梦也是不知道从哪里时开始。三四天前被蚊子叮的疮口现在都是猩红，这些蚊子难道就是传说中的外星来客？坐车对于我是最苦的差事，前后总共10天，总共算来大概有3天多时间是在车上呆着的。我自小是不晕车的（除了学前班时去动物园，看见隔座的同学晕车呕吐不觉也似乎干呕了一阵。），而此次坐车坐得我直想吐。\n\n&emsp;&emsp;值得夸耀开心的是在家乡见到了几年未见的老友。我们还一起在火锅前叙了旧。（顺便说一下，我现在这个身体这个胃是吃不了火锅的，吃不消，实在是吃不消！）还有有一晚的住宿问题是得到另一个好友的女朋友秋秋的帮忙解决的，还免费做了她的哥哥一回，这应该提提的，毕竟我比她大三天，不算亏的。末了还得谢谢他们俩的帮忙。另外就是见到了爸妈，见到了外公外婆，见到了舅舅舅妈，见到了小姨，见到了二姨父，很开心。还有就是在火车上闷着没事看完了三本阿加莎.克里斯蒂的悬疑侦探小说，还看了季羡林散文全编第五本的一半。阿加莎克里斯蒂的小说果然构思严谨缜密，总是出奇不意，种种结果总是让人始料未及，却又合情合理，故事也总是有条不紊的展开。然后昨晚没睡就想到也要写一个悬疑故事。（当然不睡也不完全是因为在构思这个故事，一大半原因是吵闹，还有本就在车上睡了一晚，睡得脑热头疼如何能入眠。）这也就是《爱妻之死》啦，我会慢慢写的，呵呵，第一次写这种类型，就当写着玩吧！\n\n&emsp;&emsp;刚刚洗了个澡。发现自己瘦了些。好吧，事实是，我也不清楚我是不是真的瘦了，也许只是因为三的一句玩笑。我发现自己的胳膊还有腿在变细（比之前细），肚子的赘肉在凸显，肉在变软，这正朝着我害怕的老年以后变得肉松皮皱，四肢小肚子大的趋势发展，这是多么恐怖啊，如果发生在自己身上。具体有没有变瘦还得经过磅秤的检验以后再说。总之之后的健身是少不了的了。\n\n&emsp;&emsp;这次出差欢喜甚多，收获不少，我们积累了一些野外布台的经验，许多都是自己吃了亏得来的。不过这些也不算亏，因为我们既没有被谁敲诈也没被骗，许多都是自己欠考虑，还得多坐了几次车，多跑了些路而已。读万卷书，行万里路，路跑多了总是没有错的。路跑多了就会知道以后想办法怎么让自己尽量少跑路，少走弯道。但是接下来就有麻烦了。因为出差的缘故，好多事情都堆在一起了，不过事是要一件一件做的，脚踏实地就好。还有就是出差或多或少是有补助的。既有补助又获得锻炼以及经验经历还能增进感情，所以大家都是愿意去的，但是却只让我们三人去。如果换作我不在这三个人里面我总是会眼红好一阵的。而我却实实在在的是在这三个人里面，如果别人问我，出差开心吗？我说好也不是，坏也不是。说好，别人就更加羡慕嫉妒恨，换作是我，我也会这样。说不好不开心，别人就会说你虚伪等等。总之左也不是右也难为。呵呵，早知道把请客吃饭摆在见面的招呼寒暄中了。\n\n&emsp;&emsp;头还是晕，睡不着，马上就上课了，别胡思乱想了，愿一切都好^_^\n\n","slug":"消失的几天","published":1,"updated":"2024-05-26T14:17:36.845Z","comments":1,"layout":"post","photos":[],"_id":"cmh498ior001rwvoue9f3fk8b","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>&emsp;&emsp;顺便交代一下这个国庆是怎么过的吧！因为似乎这几天对好多人来说我都音信全无呢！</p>\n<p>&emsp;&emsp;九月二十几号接到一个任务，那就是：国庆节出差；更值得开心的是，出差地点是家乡。本来准备国庆依然决然的宅在办公室的，接到这份差事的我无疑是欣喜若狂。</p>\n<p>&emsp;&emsp;不过我们准备的不是很充分，而且单单讲求效率了，确切来讲是做了最好的打算以及相对于这个打算的最好的准备，当然这个准备扩大了实际达到的效果与预期的目标之间的差距与麻烦。一路上吃的还算不错都是家乡的口味，只是一路肚子都不舒服，说拉肚子倒又不是，总之胃部和肠道很是不给力。身上不知哪里来了几处伤疤，就像梦一样，因为梦也是不知道从哪里时开始。三四天前被蚊子叮的疮口现在都是猩红，这些蚊子难道就是传说中的外星来客？坐车对于我是最苦的差事，前后总共10天，总共算来大概有3天多时间是在车上呆着的。我自小是不晕车的（除了学前班时去动物园，看见隔座的同学晕车呕吐不觉也似乎干呕了一阵。），而此次坐车坐得我直想吐。</p>\n<p>&emsp;&emsp;值得夸耀开心的是在家乡见到了几年未见的老友。我们还一起在火锅前叙了旧。（顺便说一下，我现在这个身体这个胃是吃不了火锅的，吃不消，实在是吃不消！）还有有一晚的住宿问题是得到另一个好友的女朋友秋秋的帮忙解决的，还免费做了她的哥哥一回，这应该提提的，毕竟我比她大三天，不算亏的。末了还得谢谢他们俩的帮忙。另外就是见到了爸妈，见到了外公外婆，见到了舅舅舅妈，见到了小姨，见到了二姨父，很开心。还有就是在火车上闷着没事看完了三本阿加莎.克里斯蒂的悬疑侦探小说，还看了季羡林散文全编第五本的一半。阿加莎克里斯蒂的小说果然构思严谨缜密，总是出奇不意，种种结果总是让人始料未及，却又合情合理，故事也总是有条不紊的展开。然后昨晚没睡就想到也要写一个悬疑故事。（当然不睡也不完全是因为在构思这个故事，一大半原因是吵闹，还有本就在车上睡了一晚，睡得脑热头疼如何能入眠。）这也就是《爱妻之死》啦，我会慢慢写的，呵呵，第一次写这种类型，就当写着玩吧！</p>\n<p>&emsp;&emsp;刚刚洗了个澡。发现自己瘦了些。好吧，事实是，我也不清楚我是不是真的瘦了，也许只是因为三的一句玩笑。我发现自己的胳膊还有腿在变细（比之前细），肚子的赘肉在凸显，肉在变软，这正朝着我害怕的老年以后变得肉松皮皱，四肢小肚子大的趋势发展，这是多么恐怖啊，如果发生在自己身上。具体有没有变瘦还得经过磅秤的检验以后再说。总之之后的健身是少不了的了。</p>\n<p>&emsp;&emsp;这次出差欢喜甚多，收获不少，我们积累了一些野外布台的经验，许多都是自己吃了亏得来的。不过这些也不算亏，因为我们既没有被谁敲诈也没被骗，许多都是自己欠考虑，还得多坐了几次车，多跑了些路而已。读万卷书，行万里路，路跑多了总是没有错的。路跑多了就会知道以后想办法怎么让自己尽量少跑路，少走弯道。但是接下来就有麻烦了。因为出差的缘故，好多事情都堆在一起了，不过事是要一件一件做的，脚踏实地就好。还有就是出差或多或少是有补助的。既有补助又获得锻炼以及经验经历还能增进感情，所以大家都是愿意去的，但是却只让我们三人去。如果换作我不在这三个人里面我总是会眼红好一阵的。而我却实实在在的是在这三个人里面，如果别人问我，出差开心吗？我说好也不是，坏也不是。说好，别人就更加羡慕嫉妒恨，换作是我，我也会这样。说不好不开心，别人就会说你虚伪等等。总之左也不是右也难为。呵呵，早知道把请客吃饭摆在见面的招呼寒暄中了。</p>\n<p>&emsp;&emsp;头还是晕，睡不着，马上就上课了，别胡思乱想了，愿一切都好^_^</p>\n","related_posts":[],"length":1499,"excerpt":"","more":"<p>&emsp;&emsp;顺便交代一下这个国庆是怎么过的吧！因为似乎这几天对好多人来说我都音信全无呢！</p>\n<p>&emsp;&emsp;九月二十几号接到一个任务，那就是：国庆节出差；更值得开心的是，出差地点是家乡。本来准备国庆依然决然的宅在办公室的，接到这份差事的我无疑是欣喜若狂。</p>\n<p>&emsp;&emsp;不过我们准备的不是很充分，而且单单讲求效率了，确切来讲是做了最好的打算以及相对于这个打算的最好的准备，当然这个准备扩大了实际达到的效果与预期的目标之间的差距与麻烦。一路上吃的还算不错都是家乡的口味，只是一路肚子都不舒服，说拉肚子倒又不是，总之胃部和肠道很是不给力。身上不知哪里来了几处伤疤，就像梦一样，因为梦也是不知道从哪里时开始。三四天前被蚊子叮的疮口现在都是猩红，这些蚊子难道就是传说中的外星来客？坐车对于我是最苦的差事，前后总共10天，总共算来大概有3天多时间是在车上呆着的。我自小是不晕车的（除了学前班时去动物园，看见隔座的同学晕车呕吐不觉也似乎干呕了一阵。），而此次坐车坐得我直想吐。</p>\n<p>&emsp;&emsp;值得夸耀开心的是在家乡见到了几年未见的老友。我们还一起在火锅前叙了旧。（顺便说一下，我现在这个身体这个胃是吃不了火锅的，吃不消，实在是吃不消！）还有有一晚的住宿问题是得到另一个好友的女朋友秋秋的帮忙解决的，还免费做了她的哥哥一回，这应该提提的，毕竟我比她大三天，不算亏的。末了还得谢谢他们俩的帮忙。另外就是见到了爸妈，见到了外公外婆，见到了舅舅舅妈，见到了小姨，见到了二姨父，很开心。还有就是在火车上闷着没事看完了三本阿加莎.克里斯蒂的悬疑侦探小说，还看了季羡林散文全编第五本的一半。阿加莎克里斯蒂的小说果然构思严谨缜密，总是出奇不意，种种结果总是让人始料未及，却又合情合理，故事也总是有条不紊的展开。然后昨晚没睡就想到也要写一个悬疑故事。（当然不睡也不完全是因为在构思这个故事，一大半原因是吵闹，还有本就在车上睡了一晚，睡得脑热头疼如何能入眠。）这也就是《爱妻之死》啦，我会慢慢写的，呵呵，第一次写这种类型，就当写着玩吧！</p>\n<p>&emsp;&emsp;刚刚洗了个澡。发现自己瘦了些。好吧，事实是，我也不清楚我是不是真的瘦了，也许只是因为三的一句玩笑。我发现自己的胳膊还有腿在变细（比之前细），肚子的赘肉在凸显，肉在变软，这正朝着我害怕的老年以后变得肉松皮皱，四肢小肚子大的趋势发展，这是多么恐怖啊，如果发生在自己身上。具体有没有变瘦还得经过磅秤的检验以后再说。总之之后的健身是少不了的了。</p>\n<p>&emsp;&emsp;这次出差欢喜甚多，收获不少，我们积累了一些野外布台的经验，许多都是自己吃了亏得来的。不过这些也不算亏，因为我们既没有被谁敲诈也没被骗，许多都是自己欠考虑，还得多坐了几次车，多跑了些路而已。读万卷书，行万里路，路跑多了总是没有错的。路跑多了就会知道以后想办法怎么让自己尽量少跑路，少走弯道。但是接下来就有麻烦了。因为出差的缘故，好多事情都堆在一起了，不过事是要一件一件做的，脚踏实地就好。还有就是出差或多或少是有补助的。既有补助又获得锻炼以及经验经历还能增进感情，所以大家都是愿意去的，但是却只让我们三人去。如果换作我不在这三个人里面我总是会眼红好一阵的。而我却实实在在的是在这三个人里面，如果别人问我，出差开心吗？我说好也不是，坏也不是。说好，别人就更加羡慕嫉妒恨，换作是我，我也会这样。说不好不开心，别人就会说你虚伪等等。总之左也不是右也难为。呵呵，早知道把请客吃饭摆在见面的招呼寒暄中了。</p>\n<p>&emsp;&emsp;头还是晕，睡不着，马上就上课了，别胡思乱想了，愿一切都好^_^</p>\n"},{"title":"\\@宁波","abbrlink":646,"date":"2010-10-21T06:11:24.000Z","_content":"\n&emsp;&emsp;之前的五天是同同组的同学一起去宁波参加了一个国际地球物理会议去了。这个会议以前是不叫国际会议的，只是因为今年请来了几位台湾和日本的某专家学者用蹩脚的英语做了几个报告于是也叫国际会议了。\n\n&emsp;&emsp;宁波这个城市，以大胡的观点来讲是算个小城市的。因为从最繁华的地方打的士坐到火车站只用时5分钟左右。通常人们会把听到的自己觉得有道理的或者与自己世界观人生观爱情观相近的话当作固有事实或者固有历史加以深信不移的。我觉得大胡说的有道理，所以我也觉得宁波是个小城市。\n\n&emsp;&emsp;宁波人的穿衣是……好吧，我不能简单用一个词语来形容。去宁波的天一广场逛过两次。见到的女人穿衣都十分时髦时尚。事实上我并不知道时髦时尚是什么意思，总之，吸引眼球就对了。男人穿什么衣服我就不清楚了，因为男人可不会吸引我。汗！颇为难忘的是在广场上遇到的两个帅哥。其中一个穿着白衬衣，黑裤子，皮鞋（也许是皮鞋。）。他朝我们走过来，我以为是流氓或者小偷预对我们有所不轨。当他接近我们时，忽然摊开了自己的左手，我发现他的手心里躺着几枚硬币。愤青忽然就说，‘没没没！’，然后往前走掉了，我们也迅速跟上，把衬衣男甩在后面。只听愤青说道：“我最讨厌向我伸手要钱的乞丐了！”于是我稍有震惊，原来宁波这个小城市的乞丐也是需要穿戴整齐的。另一个就是大胡的一张名为《帅哥与puppy》的相片的男二号了。照片上风中一只小长毛北京犬（也许是吧，就当自己是行家好了。）在广场的阶梯上往下寻路，十分活泼可爱。它的旁边有一个穿着帅气的头发飘逸的帅哥，是这张很有feel的相片的极好烘托啊！圆形广场周围最多的是金银首饰等的奢侈品店。我们还专门进了一家，目的是打击一下自己。在橱窗里，我见到一只185块的手表，然后遭到愤青的鄙视，因为我看掉了一个逗号，那只我觉得差之又差的手表实际标价是18万五千块。好吧，那也许是我们毕业以后头三年的工资，大胡说。后来上到二楼三楼，衣服一件是几千块，一个小玩具也是好几百。看完这些，我的想法，用不真实的话讲就是，这些算什么，无非是小菜一叠，改明儿个有钱了，这些啥都不是；真实的想法就是 ，算了，有钱人的奢侈生活，咱们不跟他们一般见识。\n\n&emsp;&emsp;宁波的吃的东西，呃。我不能因为自己只吃了几顿饭的经历而片面的判断宁波的食物之好坏，这叫以偏概全。总之呢，四星级饭店里面的自助餐还是不错的。只是不管怎么样大家也都认为那么一顿值不了60块。因为靠海的关系，海产品是比较多的。超市里好多有卖。有一个叫做泥螺什么的，据大胡说是十分好吃的。一吃之下全是酒味，终于明白他说的只是酒。极为痛苦的是，有一天晚餐，大胡因为午餐吃多了的缘故没吃，于是晚上点了肯德基。我喝了冰的奶茶，然后接下来的两天都是在肚子痛食欲不振的状态下度过的。由于文化交流交通的便利，吃的口味在任何地方几乎都是可以满足所有人的需求的，所以没有什么过多的需要评价的。\n\n&emsp;&emsp;本以为我们可以住在会场所在的四星级宾馆里头。结果宾馆住的人满为患，我们被安排在了同一条街上的三星级宾馆里面。三星级宾馆的房间价格与四星级的只差40块。看样子我们的待遇很是不错了。市内的房子都挺高，干净整洁，错落有致，挺有大城市的范。靠近海的原因吧，空气也很好，秋天这时还暖暖的。\n\n&emsp;&emsp;的士的起步价是10块。的士司机是绝不会和乘客搭讪的，一点也不像合肥和成都。道路十分干净没有一点白色污染，黑黝黝的柏油路面很有绅士风度。人们十分遵守交通规则。交通灯的路口，非机动车道上会有一个遮雨蓬。我觉得那个是多此一举，要是下大雨人被淋成落汤，那蓬也起不了什么作用，要说用来躲雨，也躲不了几人；小白觉得挺人性化，因为人总是有一会儿不被淋到雨，那多好。摩托车应该是被取缔了，所以见不到一辆。非机动车道里人和电动车争着先，是挺恐怖的。到处可见的都是一些高档车，什么宝马奔驰还有法拉利的，看样子大家都好有钱，都是小康富裕家庭。一次坐的士在四星级宾馆门前下车，保安递过来一张原以为是名片的卡，一看原来是刚才坐的的士车的车牌号，是为了如果有东西落在车上，联系的士方便。果真是高端洋气上档次。\n\n&emsp;&emsp;好吧，我总算是回来了。每个城市总有每个城市的可爱的地方。我说错了，应该说，每个城市总有人喜欢，总有喜欢的理由。而我……好吧，该干正事了，干正事之前先休息，休息一下。\n\n","source":"_posts/2010-10-21-宁波.md","raw":"---\ntitle: \\@宁波\ncategories:\n  - 某日记\ntags:\n  - 宁波\nabbrlink: 646\ndate: 2010-10-21 14:11:24\n---\n\n&emsp;&emsp;之前的五天是同同组的同学一起去宁波参加了一个国际地球物理会议去了。这个会议以前是不叫国际会议的，只是因为今年请来了几位台湾和日本的某专家学者用蹩脚的英语做了几个报告于是也叫国际会议了。\n\n&emsp;&emsp;宁波这个城市，以大胡的观点来讲是算个小城市的。因为从最繁华的地方打的士坐到火车站只用时5分钟左右。通常人们会把听到的自己觉得有道理的或者与自己世界观人生观爱情观相近的话当作固有事实或者固有历史加以深信不移的。我觉得大胡说的有道理，所以我也觉得宁波是个小城市。\n\n&emsp;&emsp;宁波人的穿衣是……好吧，我不能简单用一个词语来形容。去宁波的天一广场逛过两次。见到的女人穿衣都十分时髦时尚。事实上我并不知道时髦时尚是什么意思，总之，吸引眼球就对了。男人穿什么衣服我就不清楚了，因为男人可不会吸引我。汗！颇为难忘的是在广场上遇到的两个帅哥。其中一个穿着白衬衣，黑裤子，皮鞋（也许是皮鞋。）。他朝我们走过来，我以为是流氓或者小偷预对我们有所不轨。当他接近我们时，忽然摊开了自己的左手，我发现他的手心里躺着几枚硬币。愤青忽然就说，‘没没没！’，然后往前走掉了，我们也迅速跟上，把衬衣男甩在后面。只听愤青说道：“我最讨厌向我伸手要钱的乞丐了！”于是我稍有震惊，原来宁波这个小城市的乞丐也是需要穿戴整齐的。另一个就是大胡的一张名为《帅哥与puppy》的相片的男二号了。照片上风中一只小长毛北京犬（也许是吧，就当自己是行家好了。）在广场的阶梯上往下寻路，十分活泼可爱。它的旁边有一个穿着帅气的头发飘逸的帅哥，是这张很有feel的相片的极好烘托啊！圆形广场周围最多的是金银首饰等的奢侈品店。我们还专门进了一家，目的是打击一下自己。在橱窗里，我见到一只185块的手表，然后遭到愤青的鄙视，因为我看掉了一个逗号，那只我觉得差之又差的手表实际标价是18万五千块。好吧，那也许是我们毕业以后头三年的工资，大胡说。后来上到二楼三楼，衣服一件是几千块，一个小玩具也是好几百。看完这些，我的想法，用不真实的话讲就是，这些算什么，无非是小菜一叠，改明儿个有钱了，这些啥都不是；真实的想法就是 ，算了，有钱人的奢侈生活，咱们不跟他们一般见识。\n\n&emsp;&emsp;宁波的吃的东西，呃。我不能因为自己只吃了几顿饭的经历而片面的判断宁波的食物之好坏，这叫以偏概全。总之呢，四星级饭店里面的自助餐还是不错的。只是不管怎么样大家也都认为那么一顿值不了60块。因为靠海的关系，海产品是比较多的。超市里好多有卖。有一个叫做泥螺什么的，据大胡说是十分好吃的。一吃之下全是酒味，终于明白他说的只是酒。极为痛苦的是，有一天晚餐，大胡因为午餐吃多了的缘故没吃，于是晚上点了肯德基。我喝了冰的奶茶，然后接下来的两天都是在肚子痛食欲不振的状态下度过的。由于文化交流交通的便利，吃的口味在任何地方几乎都是可以满足所有人的需求的，所以没有什么过多的需要评价的。\n\n&emsp;&emsp;本以为我们可以住在会场所在的四星级宾馆里头。结果宾馆住的人满为患，我们被安排在了同一条街上的三星级宾馆里面。三星级宾馆的房间价格与四星级的只差40块。看样子我们的待遇很是不错了。市内的房子都挺高，干净整洁，错落有致，挺有大城市的范。靠近海的原因吧，空气也很好，秋天这时还暖暖的。\n\n&emsp;&emsp;的士的起步价是10块。的士司机是绝不会和乘客搭讪的，一点也不像合肥和成都。道路十分干净没有一点白色污染，黑黝黝的柏油路面很有绅士风度。人们十分遵守交通规则。交通灯的路口，非机动车道上会有一个遮雨蓬。我觉得那个是多此一举，要是下大雨人被淋成落汤，那蓬也起不了什么作用，要说用来躲雨，也躲不了几人；小白觉得挺人性化，因为人总是有一会儿不被淋到雨，那多好。摩托车应该是被取缔了，所以见不到一辆。非机动车道里人和电动车争着先，是挺恐怖的。到处可见的都是一些高档车，什么宝马奔驰还有法拉利的，看样子大家都好有钱，都是小康富裕家庭。一次坐的士在四星级宾馆门前下车，保安递过来一张原以为是名片的卡，一看原来是刚才坐的的士车的车牌号，是为了如果有东西落在车上，联系的士方便。果真是高端洋气上档次。\n\n&emsp;&emsp;好吧，我总算是回来了。每个城市总有每个城市的可爱的地方。我说错了，应该说，每个城市总有人喜欢，总有喜欢的理由。而我……好吧，该干正事了，干正事之前先休息，休息一下。\n\n","slug":"宁波","published":1,"updated":"2024-05-26T14:17:36.845Z","comments":1,"layout":"post","photos":[],"_id":"cmh498ior001uwvouhyjj0p2g","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>&emsp;&emsp;之前的五天是同同组的同学一起去宁波参加了一个国际地球物理会议去了。这个会议以前是不叫国际会议的，只是因为今年请来了几位台湾和日本的某专家学者用蹩脚的英语做了几个报告于是也叫国际会议了。</p>\n<p>&emsp;&emsp;宁波这个城市，以大胡的观点来讲是算个小城市的。因为从最繁华的地方打的士坐到火车站只用时5分钟左右。通常人们会把听到的自己觉得有道理的或者与自己世界观人生观爱情观相近的话当作固有事实或者固有历史加以深信不移的。我觉得大胡说的有道理，所以我也觉得宁波是个小城市。</p>\n<p>&emsp;&emsp;宁波人的穿衣是……好吧，我不能简单用一个词语来形容。去宁波的天一广场逛过两次。见到的女人穿衣都十分时髦时尚。事实上我并不知道时髦时尚是什么意思，总之，吸引眼球就对了。男人穿什么衣服我就不清楚了，因为男人可不会吸引我。汗！颇为难忘的是在广场上遇到的两个帅哥。其中一个穿着白衬衣，黑裤子，皮鞋（也许是皮鞋。）。他朝我们走过来，我以为是流氓或者小偷预对我们有所不轨。当他接近我们时，忽然摊开了自己的左手，我发现他的手心里躺着几枚硬币。愤青忽然就说，‘没没没！’，然后往前走掉了，我们也迅速跟上，把衬衣男甩在后面。只听愤青说道：“我最讨厌向我伸手要钱的乞丐了！”于是我稍有震惊，原来宁波这个小城市的乞丐也是需要穿戴整齐的。另一个就是大胡的一张名为《帅哥与puppy》的相片的男二号了。照片上风中一只小长毛北京犬（也许是吧，就当自己是行家好了。）在广场的阶梯上往下寻路，十分活泼可爱。它的旁边有一个穿着帅气的头发飘逸的帅哥，是这张很有feel的相片的极好烘托啊！圆形广场周围最多的是金银首饰等的奢侈品店。我们还专门进了一家，目的是打击一下自己。在橱窗里，我见到一只185块的手表，然后遭到愤青的鄙视，因为我看掉了一个逗号，那只我觉得差之又差的手表实际标价是18万五千块。好吧，那也许是我们毕业以后头三年的工资，大胡说。后来上到二楼三楼，衣服一件是几千块，一个小玩具也是好几百。看完这些，我的想法，用不真实的话讲就是，这些算什么，无非是小菜一叠，改明儿个有钱了，这些啥都不是；真实的想法就是 ，算了，有钱人的奢侈生活，咱们不跟他们一般见识。</p>\n<p>&emsp;&emsp;宁波的吃的东西，呃。我不能因为自己只吃了几顿饭的经历而片面的判断宁波的食物之好坏，这叫以偏概全。总之呢，四星级饭店里面的自助餐还是不错的。只是不管怎么样大家也都认为那么一顿值不了60块。因为靠海的关系，海产品是比较多的。超市里好多有卖。有一个叫做泥螺什么的，据大胡说是十分好吃的。一吃之下全是酒味，终于明白他说的只是酒。极为痛苦的是，有一天晚餐，大胡因为午餐吃多了的缘故没吃，于是晚上点了肯德基。我喝了冰的奶茶，然后接下来的两天都是在肚子痛食欲不振的状态下度过的。由于文化交流交通的便利，吃的口味在任何地方几乎都是可以满足所有人的需求的，所以没有什么过多的需要评价的。</p>\n<p>&emsp;&emsp;本以为我们可以住在会场所在的四星级宾馆里头。结果宾馆住的人满为患，我们被安排在了同一条街上的三星级宾馆里面。三星级宾馆的房间价格与四星级的只差40块。看样子我们的待遇很是不错了。市内的房子都挺高，干净整洁，错落有致，挺有大城市的范。靠近海的原因吧，空气也很好，秋天这时还暖暖的。</p>\n<p>&emsp;&emsp;的士的起步价是10块。的士司机是绝不会和乘客搭讪的，一点也不像合肥和成都。道路十分干净没有一点白色污染，黑黝黝的柏油路面很有绅士风度。人们十分遵守交通规则。交通灯的路口，非机动车道上会有一个遮雨蓬。我觉得那个是多此一举，要是下大雨人被淋成落汤，那蓬也起不了什么作用，要说用来躲雨，也躲不了几人；小白觉得挺人性化，因为人总是有一会儿不被淋到雨，那多好。摩托车应该是被取缔了，所以见不到一辆。非机动车道里人和电动车争着先，是挺恐怖的。到处可见的都是一些高档车，什么宝马奔驰还有法拉利的，看样子大家都好有钱，都是小康富裕家庭。一次坐的士在四星级宾馆门前下车，保安递过来一张原以为是名片的卡，一看原来是刚才坐的的士车的车牌号，是为了如果有东西落在车上，联系的士方便。果真是高端洋气上档次。</p>\n<p>&emsp;&emsp;好吧，我总算是回来了。每个城市总有每个城市的可爱的地方。我说错了，应该说，每个城市总有人喜欢，总有喜欢的理由。而我……好吧，该干正事了，干正事之前先休息，休息一下。</p>\n","related_posts":[],"length":1813,"excerpt":"","more":"<p>&emsp;&emsp;之前的五天是同同组的同学一起去宁波参加了一个国际地球物理会议去了。这个会议以前是不叫国际会议的，只是因为今年请来了几位台湾和日本的某专家学者用蹩脚的英语做了几个报告于是也叫国际会议了。</p>\n<p>&emsp;&emsp;宁波这个城市，以大胡的观点来讲是算个小城市的。因为从最繁华的地方打的士坐到火车站只用时5分钟左右。通常人们会把听到的自己觉得有道理的或者与自己世界观人生观爱情观相近的话当作固有事实或者固有历史加以深信不移的。我觉得大胡说的有道理，所以我也觉得宁波是个小城市。</p>\n<p>&emsp;&emsp;宁波人的穿衣是……好吧，我不能简单用一个词语来形容。去宁波的天一广场逛过两次。见到的女人穿衣都十分时髦时尚。事实上我并不知道时髦时尚是什么意思，总之，吸引眼球就对了。男人穿什么衣服我就不清楚了，因为男人可不会吸引我。汗！颇为难忘的是在广场上遇到的两个帅哥。其中一个穿着白衬衣，黑裤子，皮鞋（也许是皮鞋。）。他朝我们走过来，我以为是流氓或者小偷预对我们有所不轨。当他接近我们时，忽然摊开了自己的左手，我发现他的手心里躺着几枚硬币。愤青忽然就说，‘没没没！’，然后往前走掉了，我们也迅速跟上，把衬衣男甩在后面。只听愤青说道：“我最讨厌向我伸手要钱的乞丐了！”于是我稍有震惊，原来宁波这个小城市的乞丐也是需要穿戴整齐的。另一个就是大胡的一张名为《帅哥与puppy》的相片的男二号了。照片上风中一只小长毛北京犬（也许是吧，就当自己是行家好了。）在广场的阶梯上往下寻路，十分活泼可爱。它的旁边有一个穿着帅气的头发飘逸的帅哥，是这张很有feel的相片的极好烘托啊！圆形广场周围最多的是金银首饰等的奢侈品店。我们还专门进了一家，目的是打击一下自己。在橱窗里，我见到一只185块的手表，然后遭到愤青的鄙视，因为我看掉了一个逗号，那只我觉得差之又差的手表实际标价是18万五千块。好吧，那也许是我们毕业以后头三年的工资，大胡说。后来上到二楼三楼，衣服一件是几千块，一个小玩具也是好几百。看完这些，我的想法，用不真实的话讲就是，这些算什么，无非是小菜一叠，改明儿个有钱了，这些啥都不是；真实的想法就是 ，算了，有钱人的奢侈生活，咱们不跟他们一般见识。</p>\n<p>&emsp;&emsp;宁波的吃的东西，呃。我不能因为自己只吃了几顿饭的经历而片面的判断宁波的食物之好坏，这叫以偏概全。总之呢，四星级饭店里面的自助餐还是不错的。只是不管怎么样大家也都认为那么一顿值不了60块。因为靠海的关系，海产品是比较多的。超市里好多有卖。有一个叫做泥螺什么的，据大胡说是十分好吃的。一吃之下全是酒味，终于明白他说的只是酒。极为痛苦的是，有一天晚餐，大胡因为午餐吃多了的缘故没吃，于是晚上点了肯德基。我喝了冰的奶茶，然后接下来的两天都是在肚子痛食欲不振的状态下度过的。由于文化交流交通的便利，吃的口味在任何地方几乎都是可以满足所有人的需求的，所以没有什么过多的需要评价的。</p>\n<p>&emsp;&emsp;本以为我们可以住在会场所在的四星级宾馆里头。结果宾馆住的人满为患，我们被安排在了同一条街上的三星级宾馆里面。三星级宾馆的房间价格与四星级的只差40块。看样子我们的待遇很是不错了。市内的房子都挺高，干净整洁，错落有致，挺有大城市的范。靠近海的原因吧，空气也很好，秋天这时还暖暖的。</p>\n<p>&emsp;&emsp;的士的起步价是10块。的士司机是绝不会和乘客搭讪的，一点也不像合肥和成都。道路十分干净没有一点白色污染，黑黝黝的柏油路面很有绅士风度。人们十分遵守交通规则。交通灯的路口，非机动车道上会有一个遮雨蓬。我觉得那个是多此一举，要是下大雨人被淋成落汤，那蓬也起不了什么作用，要说用来躲雨，也躲不了几人；小白觉得挺人性化，因为人总是有一会儿不被淋到雨，那多好。摩托车应该是被取缔了，所以见不到一辆。非机动车道里人和电动车争着先，是挺恐怖的。到处可见的都是一些高档车，什么宝马奔驰还有法拉利的，看样子大家都好有钱，都是小康富裕家庭。一次坐的士在四星级宾馆门前下车，保安递过来一张原以为是名片的卡，一看原来是刚才坐的的士车的车牌号，是为了如果有东西落在车上，联系的士方便。果真是高端洋气上档次。</p>\n<p>&emsp;&emsp;好吧，我总算是回来了。每个城市总有每个城市的可爱的地方。我说错了，应该说，每个城市总有人喜欢，总有喜欢的理由。而我……好吧，该干正事了，干正事之前先休息，休息一下。</p>\n"},{"title":"怪癖","abbrlink":2412,"date":"2010-11-12T05:03:25.000Z","_content":"\n&emsp;&emsp;盥洗池洗漱时遇到一个家伙在刷牙，刷的很卖力认真，就像所有的人生真理和责任都掌握在手把的牙刷上。于是，他刷的格外的仔细，以至于当我刷完牙洗完脸时，他还在刷。这还不算什么，当我洗完头以后发现，他仍然坚守自己的人生阵地，始终坚持不懈的刷，真佩服他的这种持之以恒的精神……\n\n&emsp;&emsp;人们通常会自言自语，比如没有别人在身边的时候，他也许会不经意间把自己的想法从嘴巴泄漏出来。也许并不是“人们”都这样，至少我是偶尔这样。当有人在身边却又不会理会你在做什么在想什么，嘴更有可能泄漏你的想法。同样在盥洗池，遇到了这样一个人。我们一起在刷牙，盥洗池就我们俩。起初我以为他在嘟囔，在抱怨。当他第二次发出奇怪的嘟囔和一种人类难以理解的语言时，我着实吓了一大跳。只是盼望希冀他的思考不是因为奇怪的变异或者外星人的插手产生。\n\n&emsp;&emsp;每次醒的到早不晚的便会听见盥洗池传来的震耳发溃，声如洪钟的擤鼻声音。就像他擤的不是自己的鼻子，而是在蹂躏一种玩腻了的原来可以发出动听声音的玩具，或者在鞭笞审讯训练有素嘴巴极严的叛变特工。一天极为不巧的起的早了一些，我本该查查黄历然后再决定去洗漱的时间，可是我没有，我只比平时早去了一两个小时，然后壮烈的悲惨的事情发生在了我的面前。那个人十分庞大，大约有200磅重，尤其是对比我的身量以后，更觉得他是石山上落下的一大块滚石。他滚动时，会引发三级地震。随后，他便开始执行他的酷刑，严惩他的鼻子。任何人看到这种惨状也会于心不忍，心有余悸的逃离现场。\n\n&emsp;&emsp;我并不是有喜欢收集奇异份子怪癖的人，但是总有一些人像携带巨量细沙的西北风吹向眼睛一样的出现在你眼前，你躲也躲开。食堂就有那许多怪异分子。其中那个穿着一双黄拖。我有点憎恨黄拖，原因不是因为我某一次约会赶不及穿着黄拖见女友结果被女友甩掉，也不是因为某一天穿着黄拖参加运动会结果被猜到摔了个四角朝天。事实上我根本就没有女朋友，所以黄拖并不会让我失恋。憎恨黄拖的原因我也说不清楚，在内心深处似乎有个声音，或者有个行为准则，他说，‘黄拖低俗，无教养，像某钟动物的排泄物，鄙视穿黄拖的……’于是我就讨厌黄拖了。他还会穿短裤，露着惨白，像是患白化病死掉的干瘦的腿。衣服是蓝色短袖，就像已经穿过几个世纪，从来没有换过，已经掉色，布??????疏，变得半透明。像失宠的中年妇人为了吸引丈夫的目光穿的透明装。他的脸像一个骷髅为了伪装在世上证明自己是个活物而包装的画皮。他的剃须刀是新式的三D的带有菱角的，因为他的胡子从来都是没有形状的。他的头发像是楼道大妈扫厕所用的扫帚一样，从来都是乱糟糟脏兮兮。他在食堂的神秘出现，通常会让人的胃口大减，瘦身信心大增。\n\n&emsp;&emsp;澡堂是那种公共的。大家会脱的精光，相对而望，不过大家都没有什么心思去审视别人的身材形状，因为怀有这种兴趣的人还是为数不多的，也许这些人的数目众多，只是我没有意识到，而且他们隐藏的很深。有一次去洗澡，不小心瞟到一个苗条的背影。拥有苗条身材的男性不一定少，不过让我受惊的不是他苗条的身材，而是他一头飘逸齐腰的乌黑秀发。让我忽然以为自己走错门，或者“他”走错了门。事实证明，“他”是货真价实的他。只是xx人文专业的……\n\n","source":"_posts/2010-11-12-怪癖.md","raw":"---\ntitle: 怪癖\ncategories:\n  - 乱笔\ntags:\n  - 憎恨\nabbrlink: 2412\ndate: 2010-11-12 13:03:25\n---\n\n&emsp;&emsp;盥洗池洗漱时遇到一个家伙在刷牙，刷的很卖力认真，就像所有的人生真理和责任都掌握在手把的牙刷上。于是，他刷的格外的仔细，以至于当我刷完牙洗完脸时，他还在刷。这还不算什么，当我洗完头以后发现，他仍然坚守自己的人生阵地，始终坚持不懈的刷，真佩服他的这种持之以恒的精神……\n\n&emsp;&emsp;人们通常会自言自语，比如没有别人在身边的时候，他也许会不经意间把自己的想法从嘴巴泄漏出来。也许并不是“人们”都这样，至少我是偶尔这样。当有人在身边却又不会理会你在做什么在想什么，嘴更有可能泄漏你的想法。同样在盥洗池，遇到了这样一个人。我们一起在刷牙，盥洗池就我们俩。起初我以为他在嘟囔，在抱怨。当他第二次发出奇怪的嘟囔和一种人类难以理解的语言时，我着实吓了一大跳。只是盼望希冀他的思考不是因为奇怪的变异或者外星人的插手产生。\n\n&emsp;&emsp;每次醒的到早不晚的便会听见盥洗池传来的震耳发溃，声如洪钟的擤鼻声音。就像他擤的不是自己的鼻子，而是在蹂躏一种玩腻了的原来可以发出动听声音的玩具，或者在鞭笞审讯训练有素嘴巴极严的叛变特工。一天极为不巧的起的早了一些，我本该查查黄历然后再决定去洗漱的时间，可是我没有，我只比平时早去了一两个小时，然后壮烈的悲惨的事情发生在了我的面前。那个人十分庞大，大约有200磅重，尤其是对比我的身量以后，更觉得他是石山上落下的一大块滚石。他滚动时，会引发三级地震。随后，他便开始执行他的酷刑，严惩他的鼻子。任何人看到这种惨状也会于心不忍，心有余悸的逃离现场。\n\n&emsp;&emsp;我并不是有喜欢收集奇异份子怪癖的人，但是总有一些人像携带巨量细沙的西北风吹向眼睛一样的出现在你眼前，你躲也躲开。食堂就有那许多怪异分子。其中那个穿着一双黄拖。我有点憎恨黄拖，原因不是因为我某一次约会赶不及穿着黄拖见女友结果被女友甩掉，也不是因为某一天穿着黄拖参加运动会结果被猜到摔了个四角朝天。事实上我根本就没有女朋友，所以黄拖并不会让我失恋。憎恨黄拖的原因我也说不清楚，在内心深处似乎有个声音，或者有个行为准则，他说，‘黄拖低俗，无教养，像某钟动物的排泄物，鄙视穿黄拖的……’于是我就讨厌黄拖了。他还会穿短裤，露着惨白，像是患白化病死掉的干瘦的腿。衣服是蓝色短袖，就像已经穿过几个世纪，从来没有换过，已经掉色，布??????疏，变得半透明。像失宠的中年妇人为了吸引丈夫的目光穿的透明装。他的脸像一个骷髅为了伪装在世上证明自己是个活物而包装的画皮。他的剃须刀是新式的三D的带有菱角的，因为他的胡子从来都是没有形状的。他的头发像是楼道大妈扫厕所用的扫帚一样，从来都是乱糟糟脏兮兮。他在食堂的神秘出现，通常会让人的胃口大减，瘦身信心大增。\n\n&emsp;&emsp;澡堂是那种公共的。大家会脱的精光，相对而望，不过大家都没有什么心思去审视别人的身材形状，因为怀有这种兴趣的人还是为数不多的，也许这些人的数目众多，只是我没有意识到，而且他们隐藏的很深。有一次去洗澡，不小心瞟到一个苗条的背影。拥有苗条身材的男性不一定少，不过让我受惊的不是他苗条的身材，而是他一头飘逸齐腰的乌黑秀发。让我忽然以为自己走错门，或者“他”走错了门。事实证明，“他”是货真价实的他。只是xx人文专业的……\n\n","slug":"怪癖","published":1,"updated":"2024-05-26T14:17:36.845Z","comments":1,"layout":"post","photos":[],"_id":"cmh498ios001xwvou589f7xmh","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>&emsp;&emsp;盥洗池洗漱时遇到一个家伙在刷牙，刷的很卖力认真，就像所有的人生真理和责任都掌握在手把的牙刷上。于是，他刷的格外的仔细，以至于当我刷完牙洗完脸时，他还在刷。这还不算什么，当我洗完头以后发现，他仍然坚守自己的人生阵地，始终坚持不懈的刷，真佩服他的这种持之以恒的精神……</p>\n<p>&emsp;&emsp;人们通常会自言自语，比如没有别人在身边的时候，他也许会不经意间把自己的想法从嘴巴泄漏出来。也许并不是“人们”都这样，至少我是偶尔这样。当有人在身边却又不会理会你在做什么在想什么，嘴更有可能泄漏你的想法。同样在盥洗池，遇到了这样一个人。我们一起在刷牙，盥洗池就我们俩。起初我以为他在嘟囔，在抱怨。当他第二次发出奇怪的嘟囔和一种人类难以理解的语言时，我着实吓了一大跳。只是盼望希冀他的思考不是因为奇怪的变异或者外星人的插手产生。</p>\n<p>&emsp;&emsp;每次醒的到早不晚的便会听见盥洗池传来的震耳发溃，声如洪钟的擤鼻声音。就像他擤的不是自己的鼻子，而是在蹂躏一种玩腻了的原来可以发出动听声音的玩具，或者在鞭笞审讯训练有素嘴巴极严的叛变特工。一天极为不巧的起的早了一些，我本该查查黄历然后再决定去洗漱的时间，可是我没有，我只比平时早去了一两个小时，然后壮烈的悲惨的事情发生在了我的面前。那个人十分庞大，大约有200磅重，尤其是对比我的身量以后，更觉得他是石山上落下的一大块滚石。他滚动时，会引发三级地震。随后，他便开始执行他的酷刑，严惩他的鼻子。任何人看到这种惨状也会于心不忍，心有余悸的逃离现场。</p>\n<p>&emsp;&emsp;我并不是有喜欢收集奇异份子怪癖的人，但是总有一些人像携带巨量细沙的西北风吹向眼睛一样的出现在你眼前，你躲也躲开。食堂就有那许多怪异分子。其中那个穿着一双黄拖。我有点憎恨黄拖，原因不是因为我某一次约会赶不及穿着黄拖见女友结果被女友甩掉，也不是因为某一天穿着黄拖参加运动会结果被猜到摔了个四角朝天。事实上我根本就没有女朋友，所以黄拖并不会让我失恋。憎恨黄拖的原因我也说不清楚，在内心深处似乎有个声音，或者有个行为准则，他说，‘黄拖低俗，无教养，像某钟动物的排泄物，鄙视穿黄拖的……’于是我就讨厌黄拖了。他还会穿短裤，露着惨白，像是患白化病死掉的干瘦的腿。衣服是蓝色短袖，就像已经穿过几个世纪，从来没有换过，已经掉色，布??????疏，变得半透明。像失宠的中年妇人为了吸引丈夫的目光穿的透明装。他的脸像一个骷髅为了伪装在世上证明自己是个活物而包装的画皮。他的剃须刀是新式的三D的带有菱角的，因为他的胡子从来都是没有形状的。他的头发像是楼道大妈扫厕所用的扫帚一样，从来都是乱糟糟脏兮兮。他在食堂的神秘出现，通常会让人的胃口大减，瘦身信心大增。</p>\n<p>&emsp;&emsp;澡堂是那种公共的。大家会脱的精光，相对而望，不过大家都没有什么心思去审视别人的身材形状，因为怀有这种兴趣的人还是为数不多的，也许这些人的数目众多，只是我没有意识到，而且他们隐藏的很深。有一次去洗澡，不小心瞟到一个苗条的背影。拥有苗条身材的男性不一定少，不过让我受惊的不是他苗条的身材，而是他一头飘逸齐腰的乌黑秀发。让我忽然以为自己走错门，或者“他”走错了门。事实证明，“他”是货真价实的他。只是xx人文专业的……</p>\n","related_posts":[],"length":1348,"excerpt":"","more":"<p>&emsp;&emsp;盥洗池洗漱时遇到一个家伙在刷牙，刷的很卖力认真，就像所有的人生真理和责任都掌握在手把的牙刷上。于是，他刷的格外的仔细，以至于当我刷完牙洗完脸时，他还在刷。这还不算什么，当我洗完头以后发现，他仍然坚守自己的人生阵地，始终坚持不懈的刷，真佩服他的这种持之以恒的精神……</p>\n<p>&emsp;&emsp;人们通常会自言自语，比如没有别人在身边的时候，他也许会不经意间把自己的想法从嘴巴泄漏出来。也许并不是“人们”都这样，至少我是偶尔这样。当有人在身边却又不会理会你在做什么在想什么，嘴更有可能泄漏你的想法。同样在盥洗池，遇到了这样一个人。我们一起在刷牙，盥洗池就我们俩。起初我以为他在嘟囔，在抱怨。当他第二次发出奇怪的嘟囔和一种人类难以理解的语言时，我着实吓了一大跳。只是盼望希冀他的思考不是因为奇怪的变异或者外星人的插手产生。</p>\n<p>&emsp;&emsp;每次醒的到早不晚的便会听见盥洗池传来的震耳发溃，声如洪钟的擤鼻声音。就像他擤的不是自己的鼻子，而是在蹂躏一种玩腻了的原来可以发出动听声音的玩具，或者在鞭笞审讯训练有素嘴巴极严的叛变特工。一天极为不巧的起的早了一些，我本该查查黄历然后再决定去洗漱的时间，可是我没有，我只比平时早去了一两个小时，然后壮烈的悲惨的事情发生在了我的面前。那个人十分庞大，大约有200磅重，尤其是对比我的身量以后，更觉得他是石山上落下的一大块滚石。他滚动时，会引发三级地震。随后，他便开始执行他的酷刑，严惩他的鼻子。任何人看到这种惨状也会于心不忍，心有余悸的逃离现场。</p>\n<p>&emsp;&emsp;我并不是有喜欢收集奇异份子怪癖的人，但是总有一些人像携带巨量细沙的西北风吹向眼睛一样的出现在你眼前，你躲也躲开。食堂就有那许多怪异分子。其中那个穿着一双黄拖。我有点憎恨黄拖，原因不是因为我某一次约会赶不及穿着黄拖见女友结果被女友甩掉，也不是因为某一天穿着黄拖参加运动会结果被猜到摔了个四角朝天。事实上我根本就没有女朋友，所以黄拖并不会让我失恋。憎恨黄拖的原因我也说不清楚，在内心深处似乎有个声音，或者有个行为准则，他说，‘黄拖低俗，无教养，像某钟动物的排泄物，鄙视穿黄拖的……’于是我就讨厌黄拖了。他还会穿短裤，露着惨白，像是患白化病死掉的干瘦的腿。衣服是蓝色短袖，就像已经穿过几个世纪，从来没有换过，已经掉色，布??????疏，变得半透明。像失宠的中年妇人为了吸引丈夫的目光穿的透明装。他的脸像一个骷髅为了伪装在世上证明自己是个活物而包装的画皮。他的剃须刀是新式的三D的带有菱角的，因为他的胡子从来都是没有形状的。他的头发像是楼道大妈扫厕所用的扫帚一样，从来都是乱糟糟脏兮兮。他在食堂的神秘出现，通常会让人的胃口大减，瘦身信心大增。</p>\n<p>&emsp;&emsp;澡堂是那种公共的。大家会脱的精光，相对而望，不过大家都没有什么心思去审视别人的身材形状，因为怀有这种兴趣的人还是为数不多的，也许这些人的数目众多，只是我没有意识到，而且他们隐藏的很深。有一次去洗澡，不小心瞟到一个苗条的背影。拥有苗条身材的男性不一定少，不过让我受惊的不是他苗条的身材，而是他一头飘逸齐腰的乌黑秀发。让我忽然以为自己走错门，或者“他”走错了门。事实证明，“他”是货真价实的他。只是xx人文专业的……</p>\n"},{"title":"愿逝者安息","abbrlink":37262,"date":"2011-01-12T19:39:57.000Z","_content":"\n&emsp;&emsp;刚刚得知高中好友母亲去世的消息，内心有太多东西哽咽着。我不懂得如何安慰人，以至于好友母亲病重中都没有给于他足够的关怀和支持。做人做到这个份上算是老差劲的了。\n\n&emsp;&emsp;映像里，映像里好友的母亲鲜活依旧。她温柔慈祥的脸庞清晰的浮现在眼前。她算是一位成功的母亲了，把女儿和儿子养大，尤其把我的好友培养的聪明好学又有领导才能，她把家庭维护的和和睦睦，而且她还是一位为祖国培育下一代的小学教师。\n\n&emsp;&emsp;为伯母的去世我感到十分惋惜和痛心，同时也觉得人生真是世事无常。生活在这世上，我真不知道明天将发生什么。\n\n&emsp;&emsp;厌倦了同baorihan同志的争论。在他的观点里，人只要修行达到一定境界，就能放下一切，就能解脱，就能掌控生死。我是极厌恶只关注自己注重自己休养（简而言之，自私）的人的。人在世上只短短几时年，为自己考虑，为自己的生存而考虑无可厚非。但要是单单的做某些事以谋求自己心里的安慰比完完全全为自己的利益考虑而自私自利为事还要来的低劣。完完全全自私自利行事的人属于没有灵魂，做事以谋求安慰拥有的是浑浊的灵魂。\n\n&emsp;&emsp;当然，这世上没有纯粹的灵魂，没有一个完全不为自己考虑的人。要是哪个人不为自己考虑的活着，那我们看到的只是一副躯壳，躯壳下隐藏的是空或者谎。这样的一副躯壳根本就不能算是人，而是禽兽或是虚构幻想了。\n\n&emsp;&emsp;谁知道明天将发生什么呢？也许世界末日就是明天了也犹未可知。但不管明天怎么样，我们都应该好好过好每一天，认真做自己该做的事。\n\n&emsp;&emsp;愿好友尽快走出低谷，愿伯母走好……\n\n","source":"_posts/2011-01-13-愿逝者安息.md","raw":"---\ntitle: 愿逝者安息\ncategories:\n  - 某日记\ntags:\n  - 躯壳\n  - 逝者\n  - 安息\n  - 好友\nabbrlink: 37262\ndate: 2011-01-13 03:39:57\n---\n\n&emsp;&emsp;刚刚得知高中好友母亲去世的消息，内心有太多东西哽咽着。我不懂得如何安慰人，以至于好友母亲病重中都没有给于他足够的关怀和支持。做人做到这个份上算是老差劲的了。\n\n&emsp;&emsp;映像里，映像里好友的母亲鲜活依旧。她温柔慈祥的脸庞清晰的浮现在眼前。她算是一位成功的母亲了，把女儿和儿子养大，尤其把我的好友培养的聪明好学又有领导才能，她把家庭维护的和和睦睦，而且她还是一位为祖国培育下一代的小学教师。\n\n&emsp;&emsp;为伯母的去世我感到十分惋惜和痛心，同时也觉得人生真是世事无常。生活在这世上，我真不知道明天将发生什么。\n\n&emsp;&emsp;厌倦了同baorihan同志的争论。在他的观点里，人只要修行达到一定境界，就能放下一切，就能解脱，就能掌控生死。我是极厌恶只关注自己注重自己休养（简而言之，自私）的人的。人在世上只短短几时年，为自己考虑，为自己的生存而考虑无可厚非。但要是单单的做某些事以谋求自己心里的安慰比完完全全为自己的利益考虑而自私自利为事还要来的低劣。完完全全自私自利行事的人属于没有灵魂，做事以谋求安慰拥有的是浑浊的灵魂。\n\n&emsp;&emsp;当然，这世上没有纯粹的灵魂，没有一个完全不为自己考虑的人。要是哪个人不为自己考虑的活着，那我们看到的只是一副躯壳，躯壳下隐藏的是空或者谎。这样的一副躯壳根本就不能算是人，而是禽兽或是虚构幻想了。\n\n&emsp;&emsp;谁知道明天将发生什么呢？也许世界末日就是明天了也犹未可知。但不管明天怎么样，我们都应该好好过好每一天，认真做自己该做的事。\n\n&emsp;&emsp;愿好友尽快走出低谷，愿伯母走好……\n\n","slug":"愿逝者安息","published":1,"updated":"2024-05-26T14:17:36.845Z","comments":1,"layout":"post","photos":[],"_id":"cmh498iot0020wvou3ak11fag","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>&emsp;&emsp;刚刚得知高中好友母亲去世的消息，内心有太多东西哽咽着。我不懂得如何安慰人，以至于好友母亲病重中都没有给于他足够的关怀和支持。做人做到这个份上算是老差劲的了。</p>\n<p>&emsp;&emsp;映像里，映像里好友的母亲鲜活依旧。她温柔慈祥的脸庞清晰的浮现在眼前。她算是一位成功的母亲了，把女儿和儿子养大，尤其把我的好友培养的聪明好学又有领导才能，她把家庭维护的和和睦睦，而且她还是一位为祖国培育下一代的小学教师。</p>\n<p>&emsp;&emsp;为伯母的去世我感到十分惋惜和痛心，同时也觉得人生真是世事无常。生活在这世上，我真不知道明天将发生什么。</p>\n<p>&emsp;&emsp;厌倦了同baorihan同志的争论。在他的观点里，人只要修行达到一定境界，就能放下一切，就能解脱，就能掌控生死。我是极厌恶只关注自己注重自己休养（简而言之，自私）的人的。人在世上只短短几时年，为自己考虑，为自己的生存而考虑无可厚非。但要是单单的做某些事以谋求自己心里的安慰比完完全全为自己的利益考虑而自私自利为事还要来的低劣。完完全全自私自利行事的人属于没有灵魂，做事以谋求安慰拥有的是浑浊的灵魂。</p>\n<p>&emsp;&emsp;当然，这世上没有纯粹的灵魂，没有一个完全不为自己考虑的人。要是哪个人不为自己考虑的活着，那我们看到的只是一副躯壳，躯壳下隐藏的是空或者谎。这样的一副躯壳根本就不能算是人，而是禽兽或是虚构幻想了。</p>\n<p>&emsp;&emsp;谁知道明天将发生什么呢？也许世界末日就是明天了也犹未可知。但不管明天怎么样，我们都应该好好过好每一天，认真做自己该做的事。</p>\n<p>&emsp;&emsp;愿好友尽快走出低谷，愿伯母走好……</p>\n","related_posts":[],"length":696,"excerpt":"","more":"<p>&emsp;&emsp;刚刚得知高中好友母亲去世的消息，内心有太多东西哽咽着。我不懂得如何安慰人，以至于好友母亲病重中都没有给于他足够的关怀和支持。做人做到这个份上算是老差劲的了。</p>\n<p>&emsp;&emsp;映像里，映像里好友的母亲鲜活依旧。她温柔慈祥的脸庞清晰的浮现在眼前。她算是一位成功的母亲了，把女儿和儿子养大，尤其把我的好友培养的聪明好学又有领导才能，她把家庭维护的和和睦睦，而且她还是一位为祖国培育下一代的小学教师。</p>\n<p>&emsp;&emsp;为伯母的去世我感到十分惋惜和痛心，同时也觉得人生真是世事无常。生活在这世上，我真不知道明天将发生什么。</p>\n<p>&emsp;&emsp;厌倦了同baorihan同志的争论。在他的观点里，人只要修行达到一定境界，就能放下一切，就能解脱，就能掌控生死。我是极厌恶只关注自己注重自己休养（简而言之，自私）的人的。人在世上只短短几时年，为自己考虑，为自己的生存而考虑无可厚非。但要是单单的做某些事以谋求自己心里的安慰比完完全全为自己的利益考虑而自私自利为事还要来的低劣。完完全全自私自利行事的人属于没有灵魂，做事以谋求安慰拥有的是浑浊的灵魂。</p>\n<p>&emsp;&emsp;当然，这世上没有纯粹的灵魂，没有一个完全不为自己考虑的人。要是哪个人不为自己考虑的活着，那我们看到的只是一副躯壳，躯壳下隐藏的是空或者谎。这样的一副躯壳根本就不能算是人，而是禽兽或是虚构幻想了。</p>\n<p>&emsp;&emsp;谁知道明天将发生什么呢？也许世界末日就是明天了也犹未可知。但不管明天怎么样，我们都应该好好过好每一天，认真做自己该做的事。</p>\n<p>&emsp;&emsp;愿好友尽快走出低谷，愿伯母走好……</p>\n"},{"title":"成都印象","abbrlink":62880,"date":"2011-02-18T15:23:38.000Z","_content":"\n&emsp;&emsp;我想说说我对成都的印象。因为我毕竟也是一个成都人。我是在这儿出生长大学习的,经历的不多,耳濡目染的却不少。有句话叫做少不如蜀,老不出川。意思就是讲成都很好,年少时呆在成都,人就不会奋斗单图享乐了,而老了以后就在这里养老吧,还出去干什么呢?当然成都也不是所有的都好完了哈。\n\n&emsp;&emsp;先说说成都的自然环境。成都处在四川盆地里,盆地里的天总是十分阴沉的,一年中难得见到几次艳阳的天。不怪古有蜀犬吠日的说法。常年在成都呆着或许对阴沉的天并没有什么感觉,只是自然而然的认为,天就是这样的。在其他地方呆过,见过真正的算是明亮的蔚蓝的天,以及没有丝毫云彩阻挡的阳光,如果这时候来成都见到如此阴沉的天气的话是让人的心里有说不出的抑郁的。所以我是劝一些性格内向,敏感,心情容易受外界影响的人不要来成都居住的哈。因为这里的被阴云笼罩的阴沉沉的天,足以让人抑郁到想要自杀的。开玩笑的哈,如果有成都人做你的朋友,你就不会那么郁闷了哈。成都的水算是比丰富的,所以空气中的水汽很重,而且是盆地缘故,水汽也不容易散去。所以这里很潮湿,也许不像江边城市如重庆长沙和海边城市如海南那么湿。瓜子花生如果不密封放在空气中,只一天就潮了。鞋子如果晚上没有放进屋里,第二天也像是刚洗过不久的。冬天洗的衣服晾在外面不管多久,都没有真正干的感觉。被子如果不时常拿出去晒晒是很快会发霉的。冬天气温并不算低,通常在零度以上,但是因为湿冷的关系,人会感觉冷的刺骨。所以很多人生冻疮,患风湿。成都的地是很肥沃的,不像北大仓的黑土那么肥,但也相当肥了。所以物产十分丰富,种类也十分繁多。所以就有天府之国的美称了。\n\n&emsp;&emsp;再说说成都的人哈。非常抱歉我不能像林语堂的《吾国吾民》里讲中国人一样的罗列出成都人的所有特点。因为我对成都人的了解不及林语堂对中国人研究的十分之一。我也不太懂得成都的自然环境对成都人性格影响的微妙关系。成都处在一个盆地里,物产丰富,自给自足,也许因为这样所以造就的是安逸自得,及时行乐,容易满足,自我感觉良好,容易相处亲近,拿得起放得下,没有太多大志的成都人。成都人特别爱打牌。他们不管男女老少都会在茶余饭后,在街头巷尾,在农忙间隙,围成一桌开始打牌。几乎在任何场合,任何地方都可以听到打牌的声音,看到打牌人的身影。打牌不为输赢,只为耗磨时间,也许也体现出成都人的素质比较低吧,找不到其他更有意思的娱乐方式。不过打牌又有什么不好,既娱乐又加强了大家的感情交流。成都人对打牌到底有多热爱?记得那天到车站坐公交,上车时离发车时间还有大约15分钟。只见此车的司机和售票员正和另一车的司机在司机座位旁边兴高采烈的打斗地主,旁边还有两个其他车的司机或售票员观战。直到公交车调度人员过来催促,他们才收起家什,可口中还叫喊着:瞧我的一手好牌啊......成都的人爱喝茶。也许现在喝茶已经成了老年人的专利了。因为我看到的只是茶铺里头满满的全是老头儿。拿我外公来说,不管刮风下雨,早上起来用完早饭后的唯一一件事就是去茶铺喝茶,闲聊,直到午饭时间。从他铿锵的步伐到现在蹒跚的行走,一直都没有变过。(除了有农忙或者重要的事情。)成都人自我感觉良好。在亲人的聊天中,时常听到的就是:放眼全国望去,就我们成都最好,水好,土好,人好,吃的好,会享乐。成都的男人都是耙耳朵。他们具有女性的一些气质,包容,能忍耐,不好斗。在家里总是听妻子的话。难怪国学大师文怀沙开玩笑的说,如果他是一个女子,他一定嫁给成都小伙子。成都的女子都是温柔体贴的。不仅人长的漂亮,皮肤好,而且说话也是柔柔的。结了婚以后会把老公麻得很干（就是母老虎的意思）,但对老公却是一心一意。一个结了婚的师兄老是强调说,一定要娶四川的女子做老婆。这样的女孩子你可千万别去惹怒她们,否则你可遭罪了,呵呵。成都人容易满足,比如我。他们做事也会很努力,但是不强求,会顺其自然。他们有了一些成果就容易坐享其成。等到坐吃山空才又开始努力。所以,成都人有很多积蓄的很少吧,呵呵。成都的电视会放街头巷尾拍到的美女，电视台的主持人会带着你到各处去吃好吃的，名字叫吃八方。\n\n&emsp;&emsp;我所了解的就这么多了。也许因为我是成都人,对家乡有特别的情感的缘故,以及我的经历有限,所以我的理解多有偏颇哈。对了,成都人也是很好客的哈,希望朋友常到这里坐坐。\n\n","source":"_posts/2011-02-18-成都印象.md","raw":"---\ntitle: 成都印象\ncategories:\n  - 乱笔\ntags:\n  - 成都\n  - 打牌\n  - 盆地\n  - 茶铺\nabbrlink: 62880\ndate: 2011-02-18 23:23:38\n---\n\n&emsp;&emsp;我想说说我对成都的印象。因为我毕竟也是一个成都人。我是在这儿出生长大学习的,经历的不多,耳濡目染的却不少。有句话叫做少不如蜀,老不出川。意思就是讲成都很好,年少时呆在成都,人就不会奋斗单图享乐了,而老了以后就在这里养老吧,还出去干什么呢?当然成都也不是所有的都好完了哈。\n\n&emsp;&emsp;先说说成都的自然环境。成都处在四川盆地里,盆地里的天总是十分阴沉的,一年中难得见到几次艳阳的天。不怪古有蜀犬吠日的说法。常年在成都呆着或许对阴沉的天并没有什么感觉,只是自然而然的认为,天就是这样的。在其他地方呆过,见过真正的算是明亮的蔚蓝的天,以及没有丝毫云彩阻挡的阳光,如果这时候来成都见到如此阴沉的天气的话是让人的心里有说不出的抑郁的。所以我是劝一些性格内向,敏感,心情容易受外界影响的人不要来成都居住的哈。因为这里的被阴云笼罩的阴沉沉的天,足以让人抑郁到想要自杀的。开玩笑的哈,如果有成都人做你的朋友,你就不会那么郁闷了哈。成都的水算是比丰富的,所以空气中的水汽很重,而且是盆地缘故,水汽也不容易散去。所以这里很潮湿,也许不像江边城市如重庆长沙和海边城市如海南那么湿。瓜子花生如果不密封放在空气中,只一天就潮了。鞋子如果晚上没有放进屋里,第二天也像是刚洗过不久的。冬天洗的衣服晾在外面不管多久,都没有真正干的感觉。被子如果不时常拿出去晒晒是很快会发霉的。冬天气温并不算低,通常在零度以上,但是因为湿冷的关系,人会感觉冷的刺骨。所以很多人生冻疮,患风湿。成都的地是很肥沃的,不像北大仓的黑土那么肥,但也相当肥了。所以物产十分丰富,种类也十分繁多。所以就有天府之国的美称了。\n\n&emsp;&emsp;再说说成都的人哈。非常抱歉我不能像林语堂的《吾国吾民》里讲中国人一样的罗列出成都人的所有特点。因为我对成都人的了解不及林语堂对中国人研究的十分之一。我也不太懂得成都的自然环境对成都人性格影响的微妙关系。成都处在一个盆地里,物产丰富,自给自足,也许因为这样所以造就的是安逸自得,及时行乐,容易满足,自我感觉良好,容易相处亲近,拿得起放得下,没有太多大志的成都人。成都人特别爱打牌。他们不管男女老少都会在茶余饭后,在街头巷尾,在农忙间隙,围成一桌开始打牌。几乎在任何场合,任何地方都可以听到打牌的声音,看到打牌人的身影。打牌不为输赢,只为耗磨时间,也许也体现出成都人的素质比较低吧,找不到其他更有意思的娱乐方式。不过打牌又有什么不好,既娱乐又加强了大家的感情交流。成都人对打牌到底有多热爱?记得那天到车站坐公交,上车时离发车时间还有大约15分钟。只见此车的司机和售票员正和另一车的司机在司机座位旁边兴高采烈的打斗地主,旁边还有两个其他车的司机或售票员观战。直到公交车调度人员过来催促,他们才收起家什,可口中还叫喊着:瞧我的一手好牌啊......成都的人爱喝茶。也许现在喝茶已经成了老年人的专利了。因为我看到的只是茶铺里头满满的全是老头儿。拿我外公来说,不管刮风下雨,早上起来用完早饭后的唯一一件事就是去茶铺喝茶,闲聊,直到午饭时间。从他铿锵的步伐到现在蹒跚的行走,一直都没有变过。(除了有农忙或者重要的事情。)成都人自我感觉良好。在亲人的聊天中,时常听到的就是:放眼全国望去,就我们成都最好,水好,土好,人好,吃的好,会享乐。成都的男人都是耙耳朵。他们具有女性的一些气质,包容,能忍耐,不好斗。在家里总是听妻子的话。难怪国学大师文怀沙开玩笑的说,如果他是一个女子,他一定嫁给成都小伙子。成都的女子都是温柔体贴的。不仅人长的漂亮,皮肤好,而且说话也是柔柔的。结了婚以后会把老公麻得很干（就是母老虎的意思）,但对老公却是一心一意。一个结了婚的师兄老是强调说,一定要娶四川的女子做老婆。这样的女孩子你可千万别去惹怒她们,否则你可遭罪了,呵呵。成都人容易满足,比如我。他们做事也会很努力,但是不强求,会顺其自然。他们有了一些成果就容易坐享其成。等到坐吃山空才又开始努力。所以,成都人有很多积蓄的很少吧,呵呵。成都的电视会放街头巷尾拍到的美女，电视台的主持人会带着你到各处去吃好吃的，名字叫吃八方。\n\n&emsp;&emsp;我所了解的就这么多了。也许因为我是成都人,对家乡有特别的情感的缘故,以及我的经历有限,所以我的理解多有偏颇哈。对了,成都人也是很好客的哈,希望朋友常到这里坐坐。\n\n","slug":"成都印象","published":1,"updated":"2024-05-26T14:17:36.845Z","comments":1,"layout":"post","photos":[],"_id":"cmh498iot0023wvou9rkcep4f","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>&emsp;&emsp;我想说说我对成都的印象。因为我毕竟也是一个成都人。我是在这儿出生长大学习的,经历的不多,耳濡目染的却不少。有句话叫做少不如蜀,老不出川。意思就是讲成都很好,年少时呆在成都,人就不会奋斗单图享乐了,而老了以后就在这里养老吧,还出去干什么呢?当然成都也不是所有的都好完了哈。</p>\n<p>&emsp;&emsp;先说说成都的自然环境。成都处在四川盆地里,盆地里的天总是十分阴沉的,一年中难得见到几次艳阳的天。不怪古有蜀犬吠日的说法。常年在成都呆着或许对阴沉的天并没有什么感觉,只是自然而然的认为,天就是这样的。在其他地方呆过,见过真正的算是明亮的蔚蓝的天,以及没有丝毫云彩阻挡的阳光,如果这时候来成都见到如此阴沉的天气的话是让人的心里有说不出的抑郁的。所以我是劝一些性格内向,敏感,心情容易受外界影响的人不要来成都居住的哈。因为这里的被阴云笼罩的阴沉沉的天,足以让人抑郁到想要自杀的。开玩笑的哈,如果有成都人做你的朋友,你就不会那么郁闷了哈。成都的水算是比丰富的,所以空气中的水汽很重,而且是盆地缘故,水汽也不容易散去。所以这里很潮湿,也许不像江边城市如重庆长沙和海边城市如海南那么湿。瓜子花生如果不密封放在空气中,只一天就潮了。鞋子如果晚上没有放进屋里,第二天也像是刚洗过不久的。冬天洗的衣服晾在外面不管多久,都没有真正干的感觉。被子如果不时常拿出去晒晒是很快会发霉的。冬天气温并不算低,通常在零度以上,但是因为湿冷的关系,人会感觉冷的刺骨。所以很多人生冻疮,患风湿。成都的地是很肥沃的,不像北大仓的黑土那么肥,但也相当肥了。所以物产十分丰富,种类也十分繁多。所以就有天府之国的美称了。</p>\n<p>&emsp;&emsp;再说说成都的人哈。非常抱歉我不能像林语堂的《吾国吾民》里讲中国人一样的罗列出成都人的所有特点。因为我对成都人的了解不及林语堂对中国人研究的十分之一。我也不太懂得成都的自然环境对成都人性格影响的微妙关系。成都处在一个盆地里,物产丰富,自给自足,也许因为这样所以造就的是安逸自得,及时行乐,容易满足,自我感觉良好,容易相处亲近,拿得起放得下,没有太多大志的成都人。成都人特别爱打牌。他们不管男女老少都会在茶余饭后,在街头巷尾,在农忙间隙,围成一桌开始打牌。几乎在任何场合,任何地方都可以听到打牌的声音,看到打牌人的身影。打牌不为输赢,只为耗磨时间,也许也体现出成都人的素质比较低吧,找不到其他更有意思的娱乐方式。不过打牌又有什么不好,既娱乐又加强了大家的感情交流。成都人对打牌到底有多热爱?记得那天到车站坐公交,上车时离发车时间还有大约15分钟。只见此车的司机和售票员正和另一车的司机在司机座位旁边兴高采烈的打斗地主,旁边还有两个其他车的司机或售票员观战。直到公交车调度人员过来催促,他们才收起家什,可口中还叫喊着:瞧我的一手好牌啊……成都的人爱喝茶。也许现在喝茶已经成了老年人的专利了。因为我看到的只是茶铺里头满满的全是老头儿。拿我外公来说,不管刮风下雨,早上起来用完早饭后的唯一一件事就是去茶铺喝茶,闲聊,直到午饭时间。从他铿锵的步伐到现在蹒跚的行走,一直都没有变过。(除了有农忙或者重要的事情。)成都人自我感觉良好。在亲人的聊天中,时常听到的就是:放眼全国望去,就我们成都最好,水好,土好,人好,吃的好,会享乐。成都的男人都是耙耳朵。他们具有女性的一些气质,包容,能忍耐,不好斗。在家里总是听妻子的话。难怪国学大师文怀沙开玩笑的说,如果他是一个女子,他一定嫁给成都小伙子。成都的女子都是温柔体贴的。不仅人长的漂亮,皮肤好,而且说话也是柔柔的。结了婚以后会把老公麻得很干（就是母老虎的意思）,但对老公却是一心一意。一个结了婚的师兄老是强调说,一定要娶四川的女子做老婆。这样的女孩子你可千万别去惹怒她们,否则你可遭罪了,呵呵。成都人容易满足,比如我。他们做事也会很努力,但是不强求,会顺其自然。他们有了一些成果就容易坐享其成。等到坐吃山空才又开始努力。所以,成都人有很多积蓄的很少吧,呵呵。成都的电视会放街头巷尾拍到的美女，电视台的主持人会带着你到各处去吃好吃的，名字叫吃八方。</p>\n<p>&emsp;&emsp;我所了解的就这么多了。也许因为我是成都人,对家乡有特别的情感的缘故,以及我的经历有限,所以我的理解多有偏颇哈。对了,成都人也是很好客的哈,希望朋友常到这里坐坐。</p>\n","related_posts":[],"length":1789,"excerpt":"","more":"<p>&emsp;&emsp;我想说说我对成都的印象。因为我毕竟也是一个成都人。我是在这儿出生长大学习的,经历的不多,耳濡目染的却不少。有句话叫做少不如蜀,老不出川。意思就是讲成都很好,年少时呆在成都,人就不会奋斗单图享乐了,而老了以后就在这里养老吧,还出去干什么呢?当然成都也不是所有的都好完了哈。</p>\n<p>&emsp;&emsp;先说说成都的自然环境。成都处在四川盆地里,盆地里的天总是十分阴沉的,一年中难得见到几次艳阳的天。不怪古有蜀犬吠日的说法。常年在成都呆着或许对阴沉的天并没有什么感觉,只是自然而然的认为,天就是这样的。在其他地方呆过,见过真正的算是明亮的蔚蓝的天,以及没有丝毫云彩阻挡的阳光,如果这时候来成都见到如此阴沉的天气的话是让人的心里有说不出的抑郁的。所以我是劝一些性格内向,敏感,心情容易受外界影响的人不要来成都居住的哈。因为这里的被阴云笼罩的阴沉沉的天,足以让人抑郁到想要自杀的。开玩笑的哈,如果有成都人做你的朋友,你就不会那么郁闷了哈。成都的水算是比丰富的,所以空气中的水汽很重,而且是盆地缘故,水汽也不容易散去。所以这里很潮湿,也许不像江边城市如重庆长沙和海边城市如海南那么湿。瓜子花生如果不密封放在空气中,只一天就潮了。鞋子如果晚上没有放进屋里,第二天也像是刚洗过不久的。冬天洗的衣服晾在外面不管多久,都没有真正干的感觉。被子如果不时常拿出去晒晒是很快会发霉的。冬天气温并不算低,通常在零度以上,但是因为湿冷的关系,人会感觉冷的刺骨。所以很多人生冻疮,患风湿。成都的地是很肥沃的,不像北大仓的黑土那么肥,但也相当肥了。所以物产十分丰富,种类也十分繁多。所以就有天府之国的美称了。</p>\n<p>&emsp;&emsp;再说说成都的人哈。非常抱歉我不能像林语堂的《吾国吾民》里讲中国人一样的罗列出成都人的所有特点。因为我对成都人的了解不及林语堂对中国人研究的十分之一。我也不太懂得成都的自然环境对成都人性格影响的微妙关系。成都处在一个盆地里,物产丰富,自给自足,也许因为这样所以造就的是安逸自得,及时行乐,容易满足,自我感觉良好,容易相处亲近,拿得起放得下,没有太多大志的成都人。成都人特别爱打牌。他们不管男女老少都会在茶余饭后,在街头巷尾,在农忙间隙,围成一桌开始打牌。几乎在任何场合,任何地方都可以听到打牌的声音,看到打牌人的身影。打牌不为输赢,只为耗磨时间,也许也体现出成都人的素质比较低吧,找不到其他更有意思的娱乐方式。不过打牌又有什么不好,既娱乐又加强了大家的感情交流。成都人对打牌到底有多热爱?记得那天到车站坐公交,上车时离发车时间还有大约15分钟。只见此车的司机和售票员正和另一车的司机在司机座位旁边兴高采烈的打斗地主,旁边还有两个其他车的司机或售票员观战。直到公交车调度人员过来催促,他们才收起家什,可口中还叫喊着:瞧我的一手好牌啊……成都的人爱喝茶。也许现在喝茶已经成了老年人的专利了。因为我看到的只是茶铺里头满满的全是老头儿。拿我外公来说,不管刮风下雨,早上起来用完早饭后的唯一一件事就是去茶铺喝茶,闲聊,直到午饭时间。从他铿锵的步伐到现在蹒跚的行走,一直都没有变过。(除了有农忙或者重要的事情。)成都人自我感觉良好。在亲人的聊天中,时常听到的就是:放眼全国望去,就我们成都最好,水好,土好,人好,吃的好,会享乐。成都的男人都是耙耳朵。他们具有女性的一些气质,包容,能忍耐,不好斗。在家里总是听妻子的话。难怪国学大师文怀沙开玩笑的说,如果他是一个女子,他一定嫁给成都小伙子。成都的女子都是温柔体贴的。不仅人长的漂亮,皮肤好,而且说话也是柔柔的。结了婚以后会把老公麻得很干（就是母老虎的意思）,但对老公却是一心一意。一个结了婚的师兄老是强调说,一定要娶四川的女子做老婆。这样的女孩子你可千万别去惹怒她们,否则你可遭罪了,呵呵。成都人容易满足,比如我。他们做事也会很努力,但是不强求,会顺其自然。他们有了一些成果就容易坐享其成。等到坐吃山空才又开始努力。所以,成都人有很多积蓄的很少吧,呵呵。成都的电视会放街头巷尾拍到的美女，电视台的主持人会带着你到各处去吃好吃的，名字叫吃八方。</p>\n<p>&emsp;&emsp;我所了解的就这么多了。也许因为我是成都人,对家乡有特别的情感的缘故,以及我的经历有限,所以我的理解多有偏颇哈。对了,成都人也是很好客的哈,希望朋友常到这里坐坐。</p>\n"},{"title":"读后感","abbrlink":43216,"date":"2011-02-22T06:29:42.000Z","_content":"\n&emsp;&emsp;夏看了L写的新的日志了。真的很开心。并且夏还惊奇的发现，喜欢L的另一个原因是她看事情的独特的观点。当夏了解到L的对于好多问题的看法以后，觉得世上的事都是可笑的呀。\n\n&emsp;&emsp;对了，夏还要无力的辩驳一下，他说他并没有把感情等等的事情放到公式里面来计算，他现在的脑子里面的公式少之又少。不，也许L是对的，夏活在公式里面。但我想他的心还是想摆脱这些公式堆砌的框架的。但夏至少是活在一层壳里面的，他自己也不知道这层壳是什么时候覆在自己的表面（不是污垢哦，洗过澡的哈。）的。\n\n&emsp;&emsp;夏很听话的。他肯定会活的好好的。特别是有L这样的好朋友在心灵上给予的支持和帮助。所以，夏会很尊重L的决定的，会与她保持安全的距离。虽然夏很明白，女生都是比较犹豫不安的，特别是当男生在死缠烂打的情况下。但夏一点儿也不懂，不会死缠烂打的招数。夏就是一个“好人”，nice guy！（有一次英语作文，夏把guy写成了gay，笑死人了，呵呵。）不过他正在试着变成坏人。嗯！\n\n&emsp;&emsp;夏活的很肤浅，很糊涂。但是很自在。至于北京那个女孩儿，大约也只是简单做朋友了吧，呵呵。\n\n&emsp;&emsp;夏已经开始渐渐相信L说生活是不需要爱情这种调味剂也可以继续的那句话了。他只需要L以及他的朋友过的好就很开心了。嘿嘿^\\_^\n\n","source":"_posts/2011-02-22-读后感.md","raw":"---\ntitle: 读后感\ncategories:\n  - 日记\ntags:\n  - 读后感\nabbrlink: 43216\ndate: 2011-02-22 14:29:42\n---\n\n&emsp;&emsp;夏看了L写的新的日志了。真的很开心。并且夏还惊奇的发现，喜欢L的另一个原因是她看事情的独特的观点。当夏了解到L的对于好多问题的看法以后，觉得世上的事都是可笑的呀。\n\n&emsp;&emsp;对了，夏还要无力的辩驳一下，他说他并没有把感情等等的事情放到公式里面来计算，他现在的脑子里面的公式少之又少。不，也许L是对的，夏活在公式里面。但我想他的心还是想摆脱这些公式堆砌的框架的。但夏至少是活在一层壳里面的，他自己也不知道这层壳是什么时候覆在自己的表面（不是污垢哦，洗过澡的哈。）的。\n\n&emsp;&emsp;夏很听话的。他肯定会活的好好的。特别是有L这样的好朋友在心灵上给予的支持和帮助。所以，夏会很尊重L的决定的，会与她保持安全的距离。虽然夏很明白，女生都是比较犹豫不安的，特别是当男生在死缠烂打的情况下。但夏一点儿也不懂，不会死缠烂打的招数。夏就是一个“好人”，nice guy！（有一次英语作文，夏把guy写成了gay，笑死人了，呵呵。）不过他正在试着变成坏人。嗯！\n\n&emsp;&emsp;夏活的很肤浅，很糊涂。但是很自在。至于北京那个女孩儿，大约也只是简单做朋友了吧，呵呵。\n\n&emsp;&emsp;夏已经开始渐渐相信L说生活是不需要爱情这种调味剂也可以继续的那句话了。他只需要L以及他的朋友过的好就很开心了。嘿嘿^\\_^\n\n","slug":"读后感","published":1,"updated":"2024-05-26T14:17:36.845Z","comments":1,"layout":"post","photos":[],"_id":"cmh498iou0027wvoueas44p0s","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>&emsp;&emsp;夏看了L写的新的日志了。真的很开心。并且夏还惊奇的发现，喜欢L的另一个原因是她看事情的独特的观点。当夏了解到L的对于好多问题的看法以后，觉得世上的事都是可笑的呀。</p>\n<p>&emsp;&emsp;对了，夏还要无力的辩驳一下，他说他并没有把感情等等的事情放到公式里面来计算，他现在的脑子里面的公式少之又少。不，也许L是对的，夏活在公式里面。但我想他的心还是想摆脱这些公式堆砌的框架的。但夏至少是活在一层壳里面的，他自己也不知道这层壳是什么时候覆在自己的表面（不是污垢哦，洗过澡的哈。）的。</p>\n<p>&emsp;&emsp;夏很听话的。他肯定会活的好好的。特别是有L这样的好朋友在心灵上给予的支持和帮助。所以，夏会很尊重L的决定的，会与她保持安全的距离。虽然夏很明白，女生都是比较犹豫不安的，特别是当男生在死缠烂打的情况下。但夏一点儿也不懂，不会死缠烂打的招数。夏就是一个“好人”，nice guy！（有一次英语作文，夏把guy写成了gay，笑死人了，呵呵。）不过他正在试着变成坏人。嗯！</p>\n<p>&emsp;&emsp;夏活的很肤浅，很糊涂。但是很自在。至于北京那个女孩儿，大约也只是简单做朋友了吧，呵呵。</p>\n<p>&emsp;&emsp;夏已经开始渐渐相信L说生活是不需要爱情这种调味剂也可以继续的那句话了。他只需要L以及他的朋友过的好就很开心了。嘿嘿^_^</p>\n","related_posts":[],"length":570,"excerpt":"","more":"<p>&emsp;&emsp;夏看了L写的新的日志了。真的很开心。并且夏还惊奇的发现，喜欢L的另一个原因是她看事情的独特的观点。当夏了解到L的对于好多问题的看法以后，觉得世上的事都是可笑的呀。</p>\n<p>&emsp;&emsp;对了，夏还要无力的辩驳一下，他说他并没有把感情等等的事情放到公式里面来计算，他现在的脑子里面的公式少之又少。不，也许L是对的，夏活在公式里面。但我想他的心还是想摆脱这些公式堆砌的框架的。但夏至少是活在一层壳里面的，他自己也不知道这层壳是什么时候覆在自己的表面（不是污垢哦，洗过澡的哈。）的。</p>\n<p>&emsp;&emsp;夏很听话的。他肯定会活的好好的。特别是有L这样的好朋友在心灵上给予的支持和帮助。所以，夏会很尊重L的决定的，会与她保持安全的距离。虽然夏很明白，女生都是比较犹豫不安的，特别是当男生在死缠烂打的情况下。但夏一点儿也不懂，不会死缠烂打的招数。夏就是一个“好人”，nice guy！（有一次英语作文，夏把guy写成了gay，笑死人了，呵呵。）不过他正在试着变成坏人。嗯！</p>\n<p>&emsp;&emsp;夏活的很肤浅，很糊涂。但是很自在。至于北京那个女孩儿，大约也只是简单做朋友了吧，呵呵。</p>\n<p>&emsp;&emsp;夏已经开始渐渐相信L说生活是不需要爱情这种调味剂也可以继续的那句话了。他只需要L以及他的朋友过的好就很开心了。嘿嘿^_^</p>\n"},{"title":"猫","abbrlink":18581,"date":"2011-02-26T14:39:08.000Z","_content":"\n&emsp;&emsp;L给我出了一个心理测试。按喜欢的多少程度依次说出三种动物。第三种是真正的自己。而我，就是一只猫了。\n\n&emsp;&emsp;通常许多时候许多东西信则是则有，不信则无了。比如星座学说。里面对人的性格的描述语言都比较中立。它的每一种星座描述的性格也许每个人都具有。而看到他的描述以后你就会在身上找自己的相印的性格特点，把它们放大，于是觉得自己原来就是这样的人。\n\n&emsp;&emsp;现在我相信我是一只猫了。\n\n&emsp;&emsp;猫是一种比较灵异的动物。之前看到的一个新闻，说国外的一个老人院里面养了一只猫，这只猫非常奇怪。当一个老人寿命将尽的前几个星期，这只猫都会匍匐在老人的床边，陪伴着他，直到他去世。而同样的事情在这只猫身上发生了十几次。这算很诡异了吧。当然我也不算很诡异，除了偶尔眼前会闪现诡异的东西，估计是玻璃体里面的沉浊物吧！初中的时候，老妈帮我在街边的算命先生那里算过一次命。具体我不记得了，只说我的一个亲戚会去世，我会戴孝。结果把我外婆吓得够呛，她寻思着是不是两老的寿命将近了。结果后来拜祭了一个干妈，没多久，干爹就死掉了。说到干妈就好玩了。她也在我算命不久前去算过命，算命的说她有两个儿子。而事实上她只生了一个儿子，而自己都60好几岁了，哪来什么第二个儿子？然后我就横空的成了她的第二个儿子。呵呵，这些东西真的好诡异。不信他却无法解释他啊。。。\n\n&emsp;&emsp;猫这种动物，你对它好它就对你好，赖着你，有一天你对它不好，它就记恨着你，不理你，离开你，没准一辈子就不见你。外婆家养了一只猫。它是外婆养的，从它的妈妈到它一直养着。所以它只对外婆一个人好。只有外婆进的它身，可以摸它，听到外婆的声音它都会跑过来。但是别人都不行。我想外婆和那只猫有很深厚的感情的。过年的时候，舅舅和表弟放了好多好多鞭炮，那只猫被吓着了，躲了起来。第二天，外婆唤了它好久，它才战战兢兢的叫几声。然后外婆担心的给它喂了食。第二天再唤，它再也没出现。外婆伤心了好久。后来不时念叨那只可爱的猫。那天是它来见的外婆最后一面吧。其实人也是这样的啊，你对他好他也就对你好。\n\n&emsp;&emsp;猫是有洁癖的吧。它会自己清理自己的抓子毛发，用口水，呵呵，放心，我是不会用口水来清洗自己的。以前我家也养过一只猫。开始没有养过猫的我将猫的脖子拴起来养。结果差一点把它勒死。是的啊，如果猫被拴起来又怎么会有自由怎么去捉老鼠呢？不知道是因为报复我拴它还是因为它爱干净的缘故。后来它总是在我的房间里面解决问题。虽然异味不重，但是总要打扫，而且看着想着又比较恶心。所以老妈总对它有不喜欢的情绪。也许猫它感觉到了吧，不久后它就离家出走了，老妈说它定是吃到毒药死掉了。希望它好好的。\n\n&emsp;&emsp;猫的弹跳力很好。这很像以前蹦蹦跳跳的我啊，可惜现在比较缺乏锻炼，都跳不高了。\n\n&emsp;&emsp;猫走起路来没有声音。我也是这样，有一次回家，老妈也在。我就跟在老妈后面一步步上楼梯，她一点儿也没发现，她转过脸来，看到我，吓了一大跳，呵呵。\n\n&emsp;&emsp;猫吃饱了会把玩嘴里的猎物。嗯，我还没有想到我与这一点相关的事情。不过确实有点可怕，当你看到一只吃饱了的猫，把老鼠咬的半死，放在地上逗着玩的时候，你会不寒而栗的。\n\n&emsp;&emsp;猫会傻傻的自娱自乐。比如有一个圆圆的球，猫儿看到了，它会去追逐它。球不动了，它又用抓子推它挠它，玩得很开心很专注。我也可以这样，呵呵。\n\n&emsp;&emsp;猫也许会胡思乱想吧，就像我。我想现在L应该会以为我已经在记恨她了吧。因为她总是把“你别恨我，别怪我”之类的挂在嘴边。我好久都没有和她联系了。为的是不去打搅她。嗯，希望她不要胡斯乱想。希望她好好的。呵呵，也许就我一个人在胡思乱想而已。猫也许真的会胡思乱想，只是它不能像我们一样把不开心的事情说出来。当它不开心的时候它只会趴在地上，用无神迷茫的眼神望着，或者闭着眼假装在睡觉。\n\n&emsp;&emsp;这周都是六点多起床，然后看半小时左右的书，然后到操场跑步。精神还算不错。不过老板交代要看文献的，总是没有进展。\n\n&emsp;&emsp;今天下完雨过后陪师兄去买手机了，中国的手机怎么会是这样的呢？山寨，翻新机，水货，港航，行货，欧版……哪个才是真的啊？师兄还真有种不折不挠的精神，他是给老爸买的手机，买了以后是要寄到家里的，所以非要到邮局旁边的餐馆吃饭。所以我们1点多才吃饭。我的胃又饿过了头。午饭以后已经2点。睡了一下午的觉。睡的好畅快，把这一周的觉都补回来了，因为我之前都不睡午觉，睡眠严重不足啊。。。\n\n&emsp;&emsp;明天要主持会议，看我这只病猫发威吧，嘿嘿^\\_^\n\n","source":"_posts/2011-02-26-猫.md","raw":"---\ntitle: 猫\ncategories:\n  - 日记\ntags:\n  - 猫\n  - 诡异\nabbrlink: 18581\ndate: 2011-02-26 22:39:08\n---\n\n&emsp;&emsp;L给我出了一个心理测试。按喜欢的多少程度依次说出三种动物。第三种是真正的自己。而我，就是一只猫了。\n\n&emsp;&emsp;通常许多时候许多东西信则是则有，不信则无了。比如星座学说。里面对人的性格的描述语言都比较中立。它的每一种星座描述的性格也许每个人都具有。而看到他的描述以后你就会在身上找自己的相印的性格特点，把它们放大，于是觉得自己原来就是这样的人。\n\n&emsp;&emsp;现在我相信我是一只猫了。\n\n&emsp;&emsp;猫是一种比较灵异的动物。之前看到的一个新闻，说国外的一个老人院里面养了一只猫，这只猫非常奇怪。当一个老人寿命将尽的前几个星期，这只猫都会匍匐在老人的床边，陪伴着他，直到他去世。而同样的事情在这只猫身上发生了十几次。这算很诡异了吧。当然我也不算很诡异，除了偶尔眼前会闪现诡异的东西，估计是玻璃体里面的沉浊物吧！初中的时候，老妈帮我在街边的算命先生那里算过一次命。具体我不记得了，只说我的一个亲戚会去世，我会戴孝。结果把我外婆吓得够呛，她寻思着是不是两老的寿命将近了。结果后来拜祭了一个干妈，没多久，干爹就死掉了。说到干妈就好玩了。她也在我算命不久前去算过命，算命的说她有两个儿子。而事实上她只生了一个儿子，而自己都60好几岁了，哪来什么第二个儿子？然后我就横空的成了她的第二个儿子。呵呵，这些东西真的好诡异。不信他却无法解释他啊。。。\n\n&emsp;&emsp;猫这种动物，你对它好它就对你好，赖着你，有一天你对它不好，它就记恨着你，不理你，离开你，没准一辈子就不见你。外婆家养了一只猫。它是外婆养的，从它的妈妈到它一直养着。所以它只对外婆一个人好。只有外婆进的它身，可以摸它，听到外婆的声音它都会跑过来。但是别人都不行。我想外婆和那只猫有很深厚的感情的。过年的时候，舅舅和表弟放了好多好多鞭炮，那只猫被吓着了，躲了起来。第二天，外婆唤了它好久，它才战战兢兢的叫几声。然后外婆担心的给它喂了食。第二天再唤，它再也没出现。外婆伤心了好久。后来不时念叨那只可爱的猫。那天是它来见的外婆最后一面吧。其实人也是这样的啊，你对他好他也就对你好。\n\n&emsp;&emsp;猫是有洁癖的吧。它会自己清理自己的抓子毛发，用口水，呵呵，放心，我是不会用口水来清洗自己的。以前我家也养过一只猫。开始没有养过猫的我将猫的脖子拴起来养。结果差一点把它勒死。是的啊，如果猫被拴起来又怎么会有自由怎么去捉老鼠呢？不知道是因为报复我拴它还是因为它爱干净的缘故。后来它总是在我的房间里面解决问题。虽然异味不重，但是总要打扫，而且看着想着又比较恶心。所以老妈总对它有不喜欢的情绪。也许猫它感觉到了吧，不久后它就离家出走了，老妈说它定是吃到毒药死掉了。希望它好好的。\n\n&emsp;&emsp;猫的弹跳力很好。这很像以前蹦蹦跳跳的我啊，可惜现在比较缺乏锻炼，都跳不高了。\n\n&emsp;&emsp;猫走起路来没有声音。我也是这样，有一次回家，老妈也在。我就跟在老妈后面一步步上楼梯，她一点儿也没发现，她转过脸来，看到我，吓了一大跳，呵呵。\n\n&emsp;&emsp;猫吃饱了会把玩嘴里的猎物。嗯，我还没有想到我与这一点相关的事情。不过确实有点可怕，当你看到一只吃饱了的猫，把老鼠咬的半死，放在地上逗着玩的时候，你会不寒而栗的。\n\n&emsp;&emsp;猫会傻傻的自娱自乐。比如有一个圆圆的球，猫儿看到了，它会去追逐它。球不动了，它又用抓子推它挠它，玩得很开心很专注。我也可以这样，呵呵。\n\n&emsp;&emsp;猫也许会胡思乱想吧，就像我。我想现在L应该会以为我已经在记恨她了吧。因为她总是把“你别恨我，别怪我”之类的挂在嘴边。我好久都没有和她联系了。为的是不去打搅她。嗯，希望她不要胡斯乱想。希望她好好的。呵呵，也许就我一个人在胡思乱想而已。猫也许真的会胡思乱想，只是它不能像我们一样把不开心的事情说出来。当它不开心的时候它只会趴在地上，用无神迷茫的眼神望着，或者闭着眼假装在睡觉。\n\n&emsp;&emsp;这周都是六点多起床，然后看半小时左右的书，然后到操场跑步。精神还算不错。不过老板交代要看文献的，总是没有进展。\n\n&emsp;&emsp;今天下完雨过后陪师兄去买手机了，中国的手机怎么会是这样的呢？山寨，翻新机，水货，港航，行货，欧版……哪个才是真的啊？师兄还真有种不折不挠的精神，他是给老爸买的手机，买了以后是要寄到家里的，所以非要到邮局旁边的餐馆吃饭。所以我们1点多才吃饭。我的胃又饿过了头。午饭以后已经2点。睡了一下午的觉。睡的好畅快，把这一周的觉都补回来了，因为我之前都不睡午觉，睡眠严重不足啊。。。\n\n&emsp;&emsp;明天要主持会议，看我这只病猫发威吧，嘿嘿^\\_^\n\n","slug":"猫","published":1,"updated":"2024-05-26T14:17:36.845Z","comments":1,"layout":"post","photos":[],"_id":"cmh498iou0029wvou96pp777i","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>&emsp;&emsp;L给我出了一个心理测试。按喜欢的多少程度依次说出三种动物。第三种是真正的自己。而我，就是一只猫了。</p>\n<p>&emsp;&emsp;通常许多时候许多东西信则是则有，不信则无了。比如星座学说。里面对人的性格的描述语言都比较中立。它的每一种星座描述的性格也许每个人都具有。而看到他的描述以后你就会在身上找自己的相印的性格特点，把它们放大，于是觉得自己原来就是这样的人。</p>\n<p>&emsp;&emsp;现在我相信我是一只猫了。</p>\n<p>&emsp;&emsp;猫是一种比较灵异的动物。之前看到的一个新闻，说国外的一个老人院里面养了一只猫，这只猫非常奇怪。当一个老人寿命将尽的前几个星期，这只猫都会匍匐在老人的床边，陪伴着他，直到他去世。而同样的事情在这只猫身上发生了十几次。这算很诡异了吧。当然我也不算很诡异，除了偶尔眼前会闪现诡异的东西，估计是玻璃体里面的沉浊物吧！初中的时候，老妈帮我在街边的算命先生那里算过一次命。具体我不记得了，只说我的一个亲戚会去世，我会戴孝。结果把我外婆吓得够呛，她寻思着是不是两老的寿命将近了。结果后来拜祭了一个干妈，没多久，干爹就死掉了。说到干妈就好玩了。她也在我算命不久前去算过命，算命的说她有两个儿子。而事实上她只生了一个儿子，而自己都60好几岁了，哪来什么第二个儿子？然后我就横空的成了她的第二个儿子。呵呵，这些东西真的好诡异。不信他却无法解释他啊。。。</p>\n<p>&emsp;&emsp;猫这种动物，你对它好它就对你好，赖着你，有一天你对它不好，它就记恨着你，不理你，离开你，没准一辈子就不见你。外婆家养了一只猫。它是外婆养的，从它的妈妈到它一直养着。所以它只对外婆一个人好。只有外婆进的它身，可以摸它，听到外婆的声音它都会跑过来。但是别人都不行。我想外婆和那只猫有很深厚的感情的。过年的时候，舅舅和表弟放了好多好多鞭炮，那只猫被吓着了，躲了起来。第二天，外婆唤了它好久，它才战战兢兢的叫几声。然后外婆担心的给它喂了食。第二天再唤，它再也没出现。外婆伤心了好久。后来不时念叨那只可爱的猫。那天是它来见的外婆最后一面吧。其实人也是这样的啊，你对他好他也就对你好。</p>\n<p>&emsp;&emsp;猫是有洁癖的吧。它会自己清理自己的抓子毛发，用口水，呵呵，放心，我是不会用口水来清洗自己的。以前我家也养过一只猫。开始没有养过猫的我将猫的脖子拴起来养。结果差一点把它勒死。是的啊，如果猫被拴起来又怎么会有自由怎么去捉老鼠呢？不知道是因为报复我拴它还是因为它爱干净的缘故。后来它总是在我的房间里面解决问题。虽然异味不重，但是总要打扫，而且看着想着又比较恶心。所以老妈总对它有不喜欢的情绪。也许猫它感觉到了吧，不久后它就离家出走了，老妈说它定是吃到毒药死掉了。希望它好好的。</p>\n<p>&emsp;&emsp;猫的弹跳力很好。这很像以前蹦蹦跳跳的我啊，可惜现在比较缺乏锻炼，都跳不高了。</p>\n<p>&emsp;&emsp;猫走起路来没有声音。我也是这样，有一次回家，老妈也在。我就跟在老妈后面一步步上楼梯，她一点儿也没发现，她转过脸来，看到我，吓了一大跳，呵呵。</p>\n<p>&emsp;&emsp;猫吃饱了会把玩嘴里的猎物。嗯，我还没有想到我与这一点相关的事情。不过确实有点可怕，当你看到一只吃饱了的猫，把老鼠咬的半死，放在地上逗着玩的时候，你会不寒而栗的。</p>\n<p>&emsp;&emsp;猫会傻傻的自娱自乐。比如有一个圆圆的球，猫儿看到了，它会去追逐它。球不动了，它又用抓子推它挠它，玩得很开心很专注。我也可以这样，呵呵。</p>\n<p>&emsp;&emsp;猫也许会胡思乱想吧，就像我。我想现在L应该会以为我已经在记恨她了吧。因为她总是把“你别恨我，别怪我”之类的挂在嘴边。我好久都没有和她联系了。为的是不去打搅她。嗯，希望她不要胡斯乱想。希望她好好的。呵呵，也许就我一个人在胡思乱想而已。猫也许真的会胡思乱想，只是它不能像我们一样把不开心的事情说出来。当它不开心的时候它只会趴在地上，用无神迷茫的眼神望着，或者闭着眼假装在睡觉。</p>\n<p>&emsp;&emsp;这周都是六点多起床，然后看半小时左右的书，然后到操场跑步。精神还算不错。不过老板交代要看文献的，总是没有进展。</p>\n<p>&emsp;&emsp;今天下完雨过后陪师兄去买手机了，中国的手机怎么会是这样的呢？山寨，翻新机，水货，港航，行货，欧版……哪个才是真的啊？师兄还真有种不折不挠的精神，他是给老爸买的手机，买了以后是要寄到家里的，所以非要到邮局旁边的餐馆吃饭。所以我们1点多才吃饭。我的胃又饿过了头。午饭以后已经2点。睡了一下午的觉。睡的好畅快，把这一周的觉都补回来了，因为我之前都不睡午觉，睡眠严重不足啊。。。</p>\n<p>&emsp;&emsp;明天要主持会议，看我这只病猫发威吧，嘿嘿^_^</p>\n","related_posts":[],"length":1936,"excerpt":"","more":"<p>&emsp;&emsp;L给我出了一个心理测试。按喜欢的多少程度依次说出三种动物。第三种是真正的自己。而我，就是一只猫了。</p>\n<p>&emsp;&emsp;通常许多时候许多东西信则是则有，不信则无了。比如星座学说。里面对人的性格的描述语言都比较中立。它的每一种星座描述的性格也许每个人都具有。而看到他的描述以后你就会在身上找自己的相印的性格特点，把它们放大，于是觉得自己原来就是这样的人。</p>\n<p>&emsp;&emsp;现在我相信我是一只猫了。</p>\n<p>&emsp;&emsp;猫是一种比较灵异的动物。之前看到的一个新闻，说国外的一个老人院里面养了一只猫，这只猫非常奇怪。当一个老人寿命将尽的前几个星期，这只猫都会匍匐在老人的床边，陪伴着他，直到他去世。而同样的事情在这只猫身上发生了十几次。这算很诡异了吧。当然我也不算很诡异，除了偶尔眼前会闪现诡异的东西，估计是玻璃体里面的沉浊物吧！初中的时候，老妈帮我在街边的算命先生那里算过一次命。具体我不记得了，只说我的一个亲戚会去世，我会戴孝。结果把我外婆吓得够呛，她寻思着是不是两老的寿命将近了。结果后来拜祭了一个干妈，没多久，干爹就死掉了。说到干妈就好玩了。她也在我算命不久前去算过命，算命的说她有两个儿子。而事实上她只生了一个儿子，而自己都60好几岁了，哪来什么第二个儿子？然后我就横空的成了她的第二个儿子。呵呵，这些东西真的好诡异。不信他却无法解释他啊。。。</p>\n<p>&emsp;&emsp;猫这种动物，你对它好它就对你好，赖着你，有一天你对它不好，它就记恨着你，不理你，离开你，没准一辈子就不见你。外婆家养了一只猫。它是外婆养的，从它的妈妈到它一直养着。所以它只对外婆一个人好。只有外婆进的它身，可以摸它，听到外婆的声音它都会跑过来。但是别人都不行。我想外婆和那只猫有很深厚的感情的。过年的时候，舅舅和表弟放了好多好多鞭炮，那只猫被吓着了，躲了起来。第二天，外婆唤了它好久，它才战战兢兢的叫几声。然后外婆担心的给它喂了食。第二天再唤，它再也没出现。外婆伤心了好久。后来不时念叨那只可爱的猫。那天是它来见的外婆最后一面吧。其实人也是这样的啊，你对他好他也就对你好。</p>\n<p>&emsp;&emsp;猫是有洁癖的吧。它会自己清理自己的抓子毛发，用口水，呵呵，放心，我是不会用口水来清洗自己的。以前我家也养过一只猫。开始没有养过猫的我将猫的脖子拴起来养。结果差一点把它勒死。是的啊，如果猫被拴起来又怎么会有自由怎么去捉老鼠呢？不知道是因为报复我拴它还是因为它爱干净的缘故。后来它总是在我的房间里面解决问题。虽然异味不重，但是总要打扫，而且看着想着又比较恶心。所以老妈总对它有不喜欢的情绪。也许猫它感觉到了吧，不久后它就离家出走了，老妈说它定是吃到毒药死掉了。希望它好好的。</p>\n<p>&emsp;&emsp;猫的弹跳力很好。这很像以前蹦蹦跳跳的我啊，可惜现在比较缺乏锻炼，都跳不高了。</p>\n<p>&emsp;&emsp;猫走起路来没有声音。我也是这样，有一次回家，老妈也在。我就跟在老妈后面一步步上楼梯，她一点儿也没发现，她转过脸来，看到我，吓了一大跳，呵呵。</p>\n<p>&emsp;&emsp;猫吃饱了会把玩嘴里的猎物。嗯，我还没有想到我与这一点相关的事情。不过确实有点可怕，当你看到一只吃饱了的猫，把老鼠咬的半死，放在地上逗着玩的时候，你会不寒而栗的。</p>\n<p>&emsp;&emsp;猫会傻傻的自娱自乐。比如有一个圆圆的球，猫儿看到了，它会去追逐它。球不动了，它又用抓子推它挠它，玩得很开心很专注。我也可以这样，呵呵。</p>\n<p>&emsp;&emsp;猫也许会胡思乱想吧，就像我。我想现在L应该会以为我已经在记恨她了吧。因为她总是把“你别恨我，别怪我”之类的挂在嘴边。我好久都没有和她联系了。为的是不去打搅她。嗯，希望她不要胡斯乱想。希望她好好的。呵呵，也许就我一个人在胡思乱想而已。猫也许真的会胡思乱想，只是它不能像我们一样把不开心的事情说出来。当它不开心的时候它只会趴在地上，用无神迷茫的眼神望着，或者闭着眼假装在睡觉。</p>\n<p>&emsp;&emsp;这周都是六点多起床，然后看半小时左右的书，然后到操场跑步。精神还算不错。不过老板交代要看文献的，总是没有进展。</p>\n<p>&emsp;&emsp;今天下完雨过后陪师兄去买手机了，中国的手机怎么会是这样的呢？山寨，翻新机，水货，港航，行货，欧版……哪个才是真的啊？师兄还真有种不折不挠的精神，他是给老爸买的手机，买了以后是要寄到家里的，所以非要到邮局旁边的餐馆吃饭。所以我们1点多才吃饭。我的胃又饿过了头。午饭以后已经2点。睡了一下午的觉。睡的好畅快，把这一周的觉都补回来了，因为我之前都不睡午觉，睡眠严重不足啊。。。</p>\n<p>&emsp;&emsp;明天要主持会议，看我这只病猫发威吧，嘿嘿^_^</p>\n"},{"title":"活着or霸王别姬","abbrlink":37347,"date":"2012-02-09T13:13:01.000Z","_content":"\n&emsp;&emsp;先看的《活着》，然后看了《霸王别姬》。因为这两部电影被同寝室室友予以高度的评价，甚至说是中国最优秀的电影。所以就看了。\n\n&emsp;&emsp;看了很多电影，却不是很清楚大众的眼中最好的电影是什么样的。但在我的眼里，我觉得，如果一部电影，在看的时候可以让人聚精会神，而不想其他东西；让人影响深刻，眼前一亮；让人情绪高涨，感同身受；发人深省，豁然开朗；或者强烈的视觉震撼的，都算好的电影。而那种让人看着看着就想睡觉，没法集中注意力的电影算不得好的电影。这两部应该算好电影了。\n\n&emsp;&emsp;两部电影的时代和时间跨度比较相近，都是从半封建社会的中国到民国到抗战到解放战争到新中国到文化大革命。。。文章和为时而做，诗歌和为事而做。针砭时弊的东西都总会赢得大家的呼声，因为人是社会的人，人还是挑剔的人。所以聪明的人会看到这个社会的弊病，普通的人因为聪明人的暗示而欢呼雀跃，期待睿智的人来改变这些弊病。两部电影都用小人物的艺术人生，悲凉人生，比较全面的描述了近代中国的发展历程。给我们展示活在这个过度时期的人的形态，以及这个特殊的时期给人们带来的影响。看电影应该用娱乐的眼光来看，而不是政治的。因为电影只是一种娱乐。\n    两部电影描绘的主人公有所不同，但都与艺术有关。《活着》处处透着黑色的幽默，笑过以后显得无奈和无助。比如富家纨绔子，因为赌博，输掉了所有祖产，赢回妻儿的守候，在土改时还保住了自己的性命。主人公和好友凭着皮影戏在中共和国民党的战场死里逢生。被批斗的妇科大夫很久没东西吃得了馒头高兴的吃到撑死。儿子因为特殊的时代以外而死，女儿病得哑了。女儿生孩子的时候难产死掉了。《活着》的意思就是让主人公经历所有世事变迁仍然活着，承受所有的痛苦和折磨，活着比死了还不如。《霸王别姬》不同于《活着》的地方在于它直面的，不加修饰的把那些残忍的东西展现出来。民国前，京剧发达起来，人们追京剧。戏班严厉交学生，往死里大学生，小孩子学生恐惧到自杀。成了角儿，被公公调戏，心理扭曲。被地主欺压，被国民党打压，被文化大革命蹂躏。处处都是鲜血淋淋的。片中还有一处比较讽刺的对比。国民党看戏的时候无纪律，明摆着搞破坏；共产党看戏的时候纪律严谨规规矩矩，到了后来迫害人是到了骨子里。相对于《活着》中主人公的苟延残喘的活着，《霸王别姬》里的主人公选择了死。\n\n&emsp;&emsp;我们看到的对于电影这种表现形式的描述通常都是说，相对于小说，人物内心描绘的不够多，还把文字用实物展现出来。一百个人读一篇小说有一百种读法，一百个人看一部电影就只有一部电影。但我不这么认为。任何人眼中的世界都是与其他人不同的，都是专属于自己的认知的世界。所以，不同的人看同一部电影也是不同的。\n\n&emsp;&emsp;我喜欢看电影，因为电影虽然来源于生活，但总是比生活要高那么一点。\n\n&emsp;&emsp;完了。\n\n","source":"_posts/2012-02-09-活着or霸王别姬.md","raw":"---\ntitle: 活着or霸王别姬\ncategories: 杂\ntags:\n  - 电影\n  - 活着\n  - 霸王别姬\nabbrlink: 37347\ndate: 2012-02-09 21:13:01\n---\n\n&emsp;&emsp;先看的《活着》，然后看了《霸王别姬》。因为这两部电影被同寝室室友予以高度的评价，甚至说是中国最优秀的电影。所以就看了。\n\n&emsp;&emsp;看了很多电影，却不是很清楚大众的眼中最好的电影是什么样的。但在我的眼里，我觉得，如果一部电影，在看的时候可以让人聚精会神，而不想其他东西；让人影响深刻，眼前一亮；让人情绪高涨，感同身受；发人深省，豁然开朗；或者强烈的视觉震撼的，都算好的电影。而那种让人看着看着就想睡觉，没法集中注意力的电影算不得好的电影。这两部应该算好电影了。\n\n&emsp;&emsp;两部电影的时代和时间跨度比较相近，都是从半封建社会的中国到民国到抗战到解放战争到新中国到文化大革命。。。文章和为时而做，诗歌和为事而做。针砭时弊的东西都总会赢得大家的呼声，因为人是社会的人，人还是挑剔的人。所以聪明的人会看到这个社会的弊病，普通的人因为聪明人的暗示而欢呼雀跃，期待睿智的人来改变这些弊病。两部电影都用小人物的艺术人生，悲凉人生，比较全面的描述了近代中国的发展历程。给我们展示活在这个过度时期的人的形态，以及这个特殊的时期给人们带来的影响。看电影应该用娱乐的眼光来看，而不是政治的。因为电影只是一种娱乐。\n    两部电影描绘的主人公有所不同，但都与艺术有关。《活着》处处透着黑色的幽默，笑过以后显得无奈和无助。比如富家纨绔子，因为赌博，输掉了所有祖产，赢回妻儿的守候，在土改时还保住了自己的性命。主人公和好友凭着皮影戏在中共和国民党的战场死里逢生。被批斗的妇科大夫很久没东西吃得了馒头高兴的吃到撑死。儿子因为特殊的时代以外而死，女儿病得哑了。女儿生孩子的时候难产死掉了。《活着》的意思就是让主人公经历所有世事变迁仍然活着，承受所有的痛苦和折磨，活着比死了还不如。《霸王别姬》不同于《活着》的地方在于它直面的，不加修饰的把那些残忍的东西展现出来。民国前，京剧发达起来，人们追京剧。戏班严厉交学生，往死里大学生，小孩子学生恐惧到自杀。成了角儿，被公公调戏，心理扭曲。被地主欺压，被国民党打压，被文化大革命蹂躏。处处都是鲜血淋淋的。片中还有一处比较讽刺的对比。国民党看戏的时候无纪律，明摆着搞破坏；共产党看戏的时候纪律严谨规规矩矩，到了后来迫害人是到了骨子里。相对于《活着》中主人公的苟延残喘的活着，《霸王别姬》里的主人公选择了死。\n\n&emsp;&emsp;我们看到的对于电影这种表现形式的描述通常都是说，相对于小说，人物内心描绘的不够多，还把文字用实物展现出来。一百个人读一篇小说有一百种读法，一百个人看一部电影就只有一部电影。但我不这么认为。任何人眼中的世界都是与其他人不同的，都是专属于自己的认知的世界。所以，不同的人看同一部电影也是不同的。\n\n&emsp;&emsp;我喜欢看电影，因为电影虽然来源于生活，但总是比生活要高那么一点。\n\n&emsp;&emsp;完了。\n\n","slug":"活着or霸王别姬","published":1,"updated":"2024-05-26T14:17:36.845Z","comments":1,"layout":"post","photos":[],"_id":"cmh498iou002cwvouax8i09uw","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>&emsp;&emsp;先看的《活着》，然后看了《霸王别姬》。因为这两部电影被同寝室室友予以高度的评价，甚至说是中国最优秀的电影。所以就看了。</p>\n<p>&emsp;&emsp;看了很多电影，却不是很清楚大众的眼中最好的电影是什么样的。但在我的眼里，我觉得，如果一部电影，在看的时候可以让人聚精会神，而不想其他东西；让人影响深刻，眼前一亮；让人情绪高涨，感同身受；发人深省，豁然开朗；或者强烈的视觉震撼的，都算好的电影。而那种让人看着看着就想睡觉，没法集中注意力的电影算不得好的电影。这两部应该算好电影了。</p>\n<p>&emsp;&emsp;两部电影的时代和时间跨度比较相近，都是从半封建社会的中国到民国到抗战到解放战争到新中国到文化大革命。。。文章和为时而做，诗歌和为事而做。针砭时弊的东西都总会赢得大家的呼声，因为人是社会的人，人还是挑剔的人。所以聪明的人会看到这个社会的弊病，普通的人因为聪明人的暗示而欢呼雀跃，期待睿智的人来改变这些弊病。两部电影都用小人物的艺术人生，悲凉人生，比较全面的描述了近代中国的发展历程。给我们展示活在这个过度时期的人的形态，以及这个特殊的时期给人们带来的影响。看电影应该用娱乐的眼光来看，而不是政治的。因为电影只是一种娱乐。<br>    两部电影描绘的主人公有所不同，但都与艺术有关。《活着》处处透着黑色的幽默，笑过以后显得无奈和无助。比如富家纨绔子，因为赌博，输掉了所有祖产，赢回妻儿的守候，在土改时还保住了自己的性命。主人公和好友凭着皮影戏在中共和国民党的战场死里逢生。被批斗的妇科大夫很久没东西吃得了馒头高兴的吃到撑死。儿子因为特殊的时代以外而死，女儿病得哑了。女儿生孩子的时候难产死掉了。《活着》的意思就是让主人公经历所有世事变迁仍然活着，承受所有的痛苦和折磨，活着比死了还不如。《霸王别姬》不同于《活着》的地方在于它直面的，不加修饰的把那些残忍的东西展现出来。民国前，京剧发达起来，人们追京剧。戏班严厉交学生，往死里大学生，小孩子学生恐惧到自杀。成了角儿，被公公调戏，心理扭曲。被地主欺压，被国民党打压，被文化大革命蹂躏。处处都是鲜血淋淋的。片中还有一处比较讽刺的对比。国民党看戏的时候无纪律，明摆着搞破坏；共产党看戏的时候纪律严谨规规矩矩，到了后来迫害人是到了骨子里。相对于《活着》中主人公的苟延残喘的活着，《霸王别姬》里的主人公选择了死。</p>\n<p>&emsp;&emsp;我们看到的对于电影这种表现形式的描述通常都是说，相对于小说，人物内心描绘的不够多，还把文字用实物展现出来。一百个人读一篇小说有一百种读法，一百个人看一部电影就只有一部电影。但我不这么认为。任何人眼中的世界都是与其他人不同的，都是专属于自己的认知的世界。所以，不同的人看同一部电影也是不同的。</p>\n<p>&emsp;&emsp;我喜欢看电影，因为电影虽然来源于生活，但总是比生活要高那么一点。</p>\n<p>&emsp;&emsp;完了。</p>\n","related_posts":[],"length":1191,"excerpt":"","more":"<p>&emsp;&emsp;先看的《活着》，然后看了《霸王别姬》。因为这两部电影被同寝室室友予以高度的评价，甚至说是中国最优秀的电影。所以就看了。</p>\n<p>&emsp;&emsp;看了很多电影，却不是很清楚大众的眼中最好的电影是什么样的。但在我的眼里，我觉得，如果一部电影，在看的时候可以让人聚精会神，而不想其他东西；让人影响深刻，眼前一亮；让人情绪高涨，感同身受；发人深省，豁然开朗；或者强烈的视觉震撼的，都算好的电影。而那种让人看着看着就想睡觉，没法集中注意力的电影算不得好的电影。这两部应该算好电影了。</p>\n<p>&emsp;&emsp;两部电影的时代和时间跨度比较相近，都是从半封建社会的中国到民国到抗战到解放战争到新中国到文化大革命。。。文章和为时而做，诗歌和为事而做。针砭时弊的东西都总会赢得大家的呼声，因为人是社会的人，人还是挑剔的人。所以聪明的人会看到这个社会的弊病，普通的人因为聪明人的暗示而欢呼雀跃，期待睿智的人来改变这些弊病。两部电影都用小人物的艺术人生，悲凉人生，比较全面的描述了近代中国的发展历程。给我们展示活在这个过度时期的人的形态，以及这个特殊的时期给人们带来的影响。看电影应该用娱乐的眼光来看，而不是政治的。因为电影只是一种娱乐。<br>    两部电影描绘的主人公有所不同，但都与艺术有关。《活着》处处透着黑色的幽默，笑过以后显得无奈和无助。比如富家纨绔子，因为赌博，输掉了所有祖产，赢回妻儿的守候，在土改时还保住了自己的性命。主人公和好友凭着皮影戏在中共和国民党的战场死里逢生。被批斗的妇科大夫很久没东西吃得了馒头高兴的吃到撑死。儿子因为特殊的时代以外而死，女儿病得哑了。女儿生孩子的时候难产死掉了。《活着》的意思就是让主人公经历所有世事变迁仍然活着，承受所有的痛苦和折磨，活着比死了还不如。《霸王别姬》不同于《活着》的地方在于它直面的，不加修饰的把那些残忍的东西展现出来。民国前，京剧发达起来，人们追京剧。戏班严厉交学生，往死里大学生，小孩子学生恐惧到自杀。成了角儿，被公公调戏，心理扭曲。被地主欺压，被国民党打压，被文化大革命蹂躏。处处都是鲜血淋淋的。片中还有一处比较讽刺的对比。国民党看戏的时候无纪律，明摆着搞破坏；共产党看戏的时候纪律严谨规规矩矩，到了后来迫害人是到了骨子里。相对于《活着》中主人公的苟延残喘的活着，《霸王别姬》里的主人公选择了死。</p>\n<p>&emsp;&emsp;我们看到的对于电影这种表现形式的描述通常都是说，相对于小说，人物内心描绘的不够多，还把文字用实物展现出来。一百个人读一篇小说有一百种读法，一百个人看一部电影就只有一部电影。但我不这么认为。任何人眼中的世界都是与其他人不同的，都是专属于自己的认知的世界。所以，不同的人看同一部电影也是不同的。</p>\n<p>&emsp;&emsp;我喜欢看电影，因为电影虽然来源于生活，但总是比生活要高那么一点。</p>\n<p>&emsp;&emsp;完了。</p>\n"},{"title":"花卷","abbrlink":6813,"date":"2012-04-01T11:29:36.000Z","_content":"\n&emsp;&emsp;晚饭时，实验室只剩师妹了。她的一卡通忽然找不找，约莫买东西时落在了黑超。我说没事，要是找不着，我请吧。时间是17：40。快到东苑的时候，师妹说先去找她的卡。我建议和她一起去，以免找不到卡没法吃饭。但是一个东西突然钻进了我的脑袋，那就是：花卷。\n<!-- more -->\n\n&emsp;&emsp;师妹我得要先去买花卷，要不然待会儿就卖完了……但是你没卡吃饭……我对师妹说。她说，好的，没事，你先去吧，我带了钱。我想可能师妹并不知道有什么花卷是非买不可的。昨天和师弟一起吃晚饭，问到我为什么要去二楼，我说我要买花卷，当作早餐。师弟说，他不喜欢带回去，第二天吃冷的东西就不好了。他问，师兄你为什么不每天早点起床到食堂买早点吃呢？我笑了，然后什么都没有说……\n\n&emsp;&emsp;娘子在年后胆结石发作，剧痛使她彻夜不能安寝，还间杂腹泻和呕吐。第二天奄奄一息的娘子被我们带到了传说中的做保胆取石的最好的医院去做手术。被一颗小小的黄绿色恶魔精灵折磨的生不如死的娘子心理和身理都脆弱的像块悬挂的冰块。从娘子被推进手术室到接下来的15个小时，我的心也是一直悬着的。当然，手术并没有做那么久，只有3个多小时。只是这三个小时都不见人，只能希望什么事都不会发生。只在那时才体会到电视剧中主角眼睁睁自己的亲人被送进手术室，然后自己在走廊里除了焦急等待以外什么都不能做的如热锅上的蚂蚁心理。只不过走廊里的热锅蚂蚁不是一只，是好多只。从手术室出来有12个小时娘子都必须要忍痛和困保持清醒，以免做过手术的部位粘连。然后我就一个劲儿的在娘子耳边唠叨不停，估计娘子耳朵也成茧几次，然后又被共振掉几次了。实在抱歉啊。\n\n&emsp;&emsp;虽说只是个小手术，却签了好多的恐怖的协议，自愿承担各种风险；况且是第一次被推进手术室，还被人动了刀子开了肚子。不过总算是顺利的进行了手术，取出了结石。娘子也认为那个小小的东西就是一个妖怪。几天以后娘子出院了，不过瘦了好几圈，比之前少了20多斤。\n\n&emsp;&emsp;从此，娘子再也不能大鱼大肉，连饭菜里面多一丝辣椒末也会让肚子难受，胆处生疼。馋坏了本来见好吃就吃的从不忌口的我家娘子，害的她只能每天吃清淡异常的饭菜，然后逛美食博客以慰馋心，苦了一个为麻辣美食而生的胃。另外，患了胆结石是需要少食多餐的，早餐尤其重要。\n\n&emsp;&emsp;我们试过早餐吃馒头还有汤圆。馒头总是没味，干瘪，难以下咽。汤圆就更不行，试过一次，娘子吃后就犯疼。对比了好多，我们还是决定吃花卷吧。因为花卷还是挺香挺有味的，比起馒头来。对了，可能你要问：为什么不吃面条？大概也许你没有吃过除盐以外什么都不放的面条吧。然而，早上起来买的街上的花卷不但个子小，而且就像得了白化病一样，吃着好不安心。所以决定每天晚饭时从食堂带几个回去，第二天早上热了吃。\n\n&emsp;&emsp;得了这胆的毛病，娘子身心受了好多的摧残。很多的痛我也无法替她分担，以至于好多的事都没有替娘子考虑周全。只怪我做事马虎啊。需要向娘子道歉之处甚多。盼娘子容我好好的改。\n\n&emsp;&emsp;希望娘子慢慢好起来。可以快快乐乐健健康康开开心心的做自己喜欢做的事情。\n\n&emsp;&emsp;阿门。\n\n","source":"_posts/2012-04-01-花卷.md","raw":"---\ntitle: 花卷\ncategories:\n  - 日记\ntags:\n  - 命题作文\nabbrlink: 6813\ndate: 2012-04-01 19:29:36\n---\n\n&emsp;&emsp;晚饭时，实验室只剩师妹了。她的一卡通忽然找不找，约莫买东西时落在了黑超。我说没事，要是找不着，我请吧。时间是17：40。快到东苑的时候，师妹说先去找她的卡。我建议和她一起去，以免找不到卡没法吃饭。但是一个东西突然钻进了我的脑袋，那就是：花卷。\n<!-- more -->\n\n&emsp;&emsp;师妹我得要先去买花卷，要不然待会儿就卖完了……但是你没卡吃饭……我对师妹说。她说，好的，没事，你先去吧，我带了钱。我想可能师妹并不知道有什么花卷是非买不可的。昨天和师弟一起吃晚饭，问到我为什么要去二楼，我说我要买花卷，当作早餐。师弟说，他不喜欢带回去，第二天吃冷的东西就不好了。他问，师兄你为什么不每天早点起床到食堂买早点吃呢？我笑了，然后什么都没有说……\n\n&emsp;&emsp;娘子在年后胆结石发作，剧痛使她彻夜不能安寝，还间杂腹泻和呕吐。第二天奄奄一息的娘子被我们带到了传说中的做保胆取石的最好的医院去做手术。被一颗小小的黄绿色恶魔精灵折磨的生不如死的娘子心理和身理都脆弱的像块悬挂的冰块。从娘子被推进手术室到接下来的15个小时，我的心也是一直悬着的。当然，手术并没有做那么久，只有3个多小时。只是这三个小时都不见人，只能希望什么事都不会发生。只在那时才体会到电视剧中主角眼睁睁自己的亲人被送进手术室，然后自己在走廊里除了焦急等待以外什么都不能做的如热锅上的蚂蚁心理。只不过走廊里的热锅蚂蚁不是一只，是好多只。从手术室出来有12个小时娘子都必须要忍痛和困保持清醒，以免做过手术的部位粘连。然后我就一个劲儿的在娘子耳边唠叨不停，估计娘子耳朵也成茧几次，然后又被共振掉几次了。实在抱歉啊。\n\n&emsp;&emsp;虽说只是个小手术，却签了好多的恐怖的协议，自愿承担各种风险；况且是第一次被推进手术室，还被人动了刀子开了肚子。不过总算是顺利的进行了手术，取出了结石。娘子也认为那个小小的东西就是一个妖怪。几天以后娘子出院了，不过瘦了好几圈，比之前少了20多斤。\n\n&emsp;&emsp;从此，娘子再也不能大鱼大肉，连饭菜里面多一丝辣椒末也会让肚子难受，胆处生疼。馋坏了本来见好吃就吃的从不忌口的我家娘子，害的她只能每天吃清淡异常的饭菜，然后逛美食博客以慰馋心，苦了一个为麻辣美食而生的胃。另外，患了胆结石是需要少食多餐的，早餐尤其重要。\n\n&emsp;&emsp;我们试过早餐吃馒头还有汤圆。馒头总是没味，干瘪，难以下咽。汤圆就更不行，试过一次，娘子吃后就犯疼。对比了好多，我们还是决定吃花卷吧。因为花卷还是挺香挺有味的，比起馒头来。对了，可能你要问：为什么不吃面条？大概也许你没有吃过除盐以外什么都不放的面条吧。然而，早上起来买的街上的花卷不但个子小，而且就像得了白化病一样，吃着好不安心。所以决定每天晚饭时从食堂带几个回去，第二天早上热了吃。\n\n&emsp;&emsp;得了这胆的毛病，娘子身心受了好多的摧残。很多的痛我也无法替她分担，以至于好多的事都没有替娘子考虑周全。只怪我做事马虎啊。需要向娘子道歉之处甚多。盼娘子容我好好的改。\n\n&emsp;&emsp;希望娘子慢慢好起来。可以快快乐乐健健康康开开心心的做自己喜欢做的事情。\n\n&emsp;&emsp;阿门。\n\n","slug":"花卷","published":1,"updated":"2024-05-26T14:17:36.845Z","comments":1,"layout":"post","photos":[],"_id":"cmh498iov002fwvouba99g50k","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>&emsp;&emsp;晚饭时，实验室只剩师妹了。她的一卡通忽然找不找，约莫买东西时落在了黑超。我说没事，要是找不着，我请吧。时间是17：40。快到东苑的时候，师妹说先去找她的卡。我建议和她一起去，以免找不到卡没法吃饭。但是一个东西突然钻进了我的脑袋，那就是：花卷。</p>\n<span id=\"more\"></span>\n\n<p>&emsp;&emsp;师妹我得要先去买花卷，要不然待会儿就卖完了……但是你没卡吃饭……我对师妹说。她说，好的，没事，你先去吧，我带了钱。我想可能师妹并不知道有什么花卷是非买不可的。昨天和师弟一起吃晚饭，问到我为什么要去二楼，我说我要买花卷，当作早餐。师弟说，他不喜欢带回去，第二天吃冷的东西就不好了。他问，师兄你为什么不每天早点起床到食堂买早点吃呢？我笑了，然后什么都没有说……</p>\n<p>&emsp;&emsp;娘子在年后胆结石发作，剧痛使她彻夜不能安寝，还间杂腹泻和呕吐。第二天奄奄一息的娘子被我们带到了传说中的做保胆取石的最好的医院去做手术。被一颗小小的黄绿色恶魔精灵折磨的生不如死的娘子心理和身理都脆弱的像块悬挂的冰块。从娘子被推进手术室到接下来的15个小时，我的心也是一直悬着的。当然，手术并没有做那么久，只有3个多小时。只是这三个小时都不见人，只能希望什么事都不会发生。只在那时才体会到电视剧中主角眼睁睁自己的亲人被送进手术室，然后自己在走廊里除了焦急等待以外什么都不能做的如热锅上的蚂蚁心理。只不过走廊里的热锅蚂蚁不是一只，是好多只。从手术室出来有12个小时娘子都必须要忍痛和困保持清醒，以免做过手术的部位粘连。然后我就一个劲儿的在娘子耳边唠叨不停，估计娘子耳朵也成茧几次，然后又被共振掉几次了。实在抱歉啊。</p>\n<p>&emsp;&emsp;虽说只是个小手术，却签了好多的恐怖的协议，自愿承担各种风险；况且是第一次被推进手术室，还被人动了刀子开了肚子。不过总算是顺利的进行了手术，取出了结石。娘子也认为那个小小的东西就是一个妖怪。几天以后娘子出院了，不过瘦了好几圈，比之前少了20多斤。</p>\n<p>&emsp;&emsp;从此，娘子再也不能大鱼大肉，连饭菜里面多一丝辣椒末也会让肚子难受，胆处生疼。馋坏了本来见好吃就吃的从不忌口的我家娘子，害的她只能每天吃清淡异常的饭菜，然后逛美食博客以慰馋心，苦了一个为麻辣美食而生的胃。另外，患了胆结石是需要少食多餐的，早餐尤其重要。</p>\n<p>&emsp;&emsp;我们试过早餐吃馒头还有汤圆。馒头总是没味，干瘪，难以下咽。汤圆就更不行，试过一次，娘子吃后就犯疼。对比了好多，我们还是决定吃花卷吧。因为花卷还是挺香挺有味的，比起馒头来。对了，可能你要问：为什么不吃面条？大概也许你没有吃过除盐以外什么都不放的面条吧。然而，早上起来买的街上的花卷不但个子小，而且就像得了白化病一样，吃着好不安心。所以决定每天晚饭时从食堂带几个回去，第二天早上热了吃。</p>\n<p>&emsp;&emsp;得了这胆的毛病，娘子身心受了好多的摧残。很多的痛我也无法替她分担，以至于好多的事都没有替娘子考虑周全。只怪我做事马虎啊。需要向娘子道歉之处甚多。盼娘子容我好好的改。</p>\n<p>&emsp;&emsp;希望娘子慢慢好起来。可以快快乐乐健健康康开开心心的做自己喜欢做的事情。</p>\n<p>&emsp;&emsp;阿门。</p>\n","related_posts":[],"length":1319,"excerpt":"<p>&emsp;&emsp;晚饭时，实验室只剩师妹了。她的一卡通忽然找不找，约莫买东西时落在了黑超。我说没事，要是找不着，我请吧。时间是17：40。快到东苑的时候，师妹说先去找她的卡。我建议和她一起去，以免找不到卡没法吃饭。但是一个东西突然钻进了我的脑袋，那就是：花卷。</p>","more":"<p>&emsp;&emsp;师妹我得要先去买花卷，要不然待会儿就卖完了……但是你没卡吃饭……我对师妹说。她说，好的，没事，你先去吧，我带了钱。我想可能师妹并不知道有什么花卷是非买不可的。昨天和师弟一起吃晚饭，问到我为什么要去二楼，我说我要买花卷，当作早餐。师弟说，他不喜欢带回去，第二天吃冷的东西就不好了。他问，师兄你为什么不每天早点起床到食堂买早点吃呢？我笑了，然后什么都没有说……</p>\n<p>&emsp;&emsp;娘子在年后胆结石发作，剧痛使她彻夜不能安寝，还间杂腹泻和呕吐。第二天奄奄一息的娘子被我们带到了传说中的做保胆取石的最好的医院去做手术。被一颗小小的黄绿色恶魔精灵折磨的生不如死的娘子心理和身理都脆弱的像块悬挂的冰块。从娘子被推进手术室到接下来的15个小时，我的心也是一直悬着的。当然，手术并没有做那么久，只有3个多小时。只是这三个小时都不见人，只能希望什么事都不会发生。只在那时才体会到电视剧中主角眼睁睁自己的亲人被送进手术室，然后自己在走廊里除了焦急等待以外什么都不能做的如热锅上的蚂蚁心理。只不过走廊里的热锅蚂蚁不是一只，是好多只。从手术室出来有12个小时娘子都必须要忍痛和困保持清醒，以免做过手术的部位粘连。然后我就一个劲儿的在娘子耳边唠叨不停，估计娘子耳朵也成茧几次，然后又被共振掉几次了。实在抱歉啊。</p>\n<p>&emsp;&emsp;虽说只是个小手术，却签了好多的恐怖的协议，自愿承担各种风险；况且是第一次被推进手术室，还被人动了刀子开了肚子。不过总算是顺利的进行了手术，取出了结石。娘子也认为那个小小的东西就是一个妖怪。几天以后娘子出院了，不过瘦了好几圈，比之前少了20多斤。</p>\n<p>&emsp;&emsp;从此，娘子再也不能大鱼大肉，连饭菜里面多一丝辣椒末也会让肚子难受，胆处生疼。馋坏了本来见好吃就吃的从不忌口的我家娘子，害的她只能每天吃清淡异常的饭菜，然后逛美食博客以慰馋心，苦了一个为麻辣美食而生的胃。另外，患了胆结石是需要少食多餐的，早餐尤其重要。</p>\n<p>&emsp;&emsp;我们试过早餐吃馒头还有汤圆。馒头总是没味，干瘪，难以下咽。汤圆就更不行，试过一次，娘子吃后就犯疼。对比了好多，我们还是决定吃花卷吧。因为花卷还是挺香挺有味的，比起馒头来。对了，可能你要问：为什么不吃面条？大概也许你没有吃过除盐以外什么都不放的面条吧。然而，早上起来买的街上的花卷不但个子小，而且就像得了白化病一样，吃着好不安心。所以决定每天晚饭时从食堂带几个回去，第二天早上热了吃。</p>\n<p>&emsp;&emsp;得了这胆的毛病，娘子身心受了好多的摧残。很多的痛我也无法替她分担，以至于好多的事都没有替娘子考虑周全。只怪我做事马虎啊。需要向娘子道歉之处甚多。盼娘子容我好好的改。</p>\n<p>&emsp;&emsp;希望娘子慢慢好起来。可以快快乐乐健健康康开开心心的做自己喜欢做的事情。</p>\n<p>&emsp;&emsp;阿门。</p>"},{"title":"雾霾齐步走","abbrlink":35510,"date":"2013-12-09T13:49:19.000Z","_content":"\n&emsp;&emsp;据传，雾霾的妈妈叫他回去吃饭了。\n\n&emsp;&emsp;连续几天各大新闻媒体都在大肆报道华北华东的雾霾天气，中央打响了雾霾攻坚战。发言人说：污染主要来自于急功近利的工业生产。我们很有进步，现在每个省市都毫不隐瞒地向人民群众公布具体的污染数字。。。\n\n&emsp;&emsp;我和妻不禁感叹：中国人果然还是有在变得更好啊，瞧，这种家丑也终于敢拿出来示人了。\n\n&emsp;&emsp;慢着，我和妻花了一晚上的功夫，并不是要来数落中国人的好的啊，而是为了自我安慰似的找到中国发展到今天这个样子的根源。\n\n&emsp;&emsp;为什么雾霾这么张狂的睡在我们身边，把我们生活的地盘都要挤没了？经过我俩的激烈争论，终于有了初步答案。那就是-------很多中国人目光短浅。（大概我也是如此。）并不是我在骂自己人。好吧，其实很多时候骂自己人有种推卸责任的快感。不过好的借口是，知己知彼百战不怠。目光短浅这个结论并不是我根据自己自身特点总结出的，而是经过很多负面报道还有眼见而得的。比如中国人在一个劲儿的重视遛进10%的人口袋里的GDP，忽视长期的发展，忽视环境的污染，就甭提医保社保神马了。一味的追寻产量业绩，产品的质量得不到保证，市场自然就没了。产业结构一直走劳动密集型，没有自己的自主高科技产品（品牌）。山寨货横行。（慢着，很多东西是我自己说的，和娘子无关啊。我们没有讨论到这儿。）举个最鲜活的例子，欧洲美国人建城市，规划基本奔着几百年方案做（比如下水道可以跑车子）。中国人。。。我不知道你们（我们）在干什么。。。除了拆还会什么？\n\n&emsp;&emsp;再等等，GDP如果真是进了10%的人的腰包。那么这些金字塔尖上的人儿，您们应该深谋远虑些吧您哪。利益都钻到亲们的口袋了难道就不思忖着如何长期的可持续的捻到更多的肥肉？非要立刻马上卷了所有祖产，不给长工们活路。\n\n&emsp;&emsp;好吧。我们是无论如何也揣踱不出他们的心机的。也许他们就是那样想的，完事之后跑到列强国家摇尾祈怜也说不一定。因为来自中学课本的鲁大师说过，中国人是有奴性的。这帮金字塔尖儿上的人们，在咱们这儿做不了奴隶，那只能。。。去给别的国捡肥皂。\n\n&emsp;&emsp;话说，中国人为什么目光那么短浅？中国的某些官儿为什么那么爱贪？在中国，关系为什么就是生产力？为什么在中国面子问题是大问题？中国为什么发展的没有别的某些国发展的那么好？\n\n&emsp;&emsp;娘子的话很精辟------因为中国人太多，东西太少了很久。你能明白吧，弱肉强食，人不为己天理难容。\n\n&emsp;&emsp;因为僧多粥少，我们不得不努力为自己的肚子奋斗，长此以往，这种基因会刻在中国人的DNA里。就像肥胖症，是在饥荒年代那些拥有囤积脂肪能力的人保存下来的能力，贪婪也是中国人在华夏土地上几千年的食物争夺战中习得的能力。按理说，消除这种贪污腐败现象完善的监督机制就能解决，就像欧美的多党执政。你还别说，在中国要这样也不是不可以。不过前提就是中国就不是中国了，只有中国联邦，中国联盟，那谁谁谁都会争先化为被小美蹂躏小国的吧。您说对了，原因还是中国人多，而且中国还没有发展到好到很多党派来同时治理国家。倘若中国有很多党派如美国并且依然那么统一，试想，就目前的短视（能见度极低）而言，那岂不换一个执政党地皮都会翻转一回。由此由我俩可见，目前的由我党领导的一党专政体制还是很适合15亿中国人的。\n\n&emsp;&emsp;封建社会，中国人也是很多的，要保存自己的DNA并且延续下去也是很激烈残酷的。要想获得更多的生活资料，比如钱财，房屋，女人，在同一个家族里面我们需要表现很好才能获得长辈的肯定。瞧，你也能分析出中国人爱面子的原因了。因为首先在父母长辈眼里，你很厉害，至少比其他八个儿子厉害，你就能获得更多的遗产。（先不考虑嫡出庶出带来的先天地位不均）在女人面前有面子才能让她们觉得爷们儿有让孩子成为亮丽富二代的资本，才能赢得觉得嫁了有面儿的老公自己有面儿的女人的小心脏。在封建体制的官场，拉帮结派，乌纱才可保，有面儿才能赢得更多觉得你很不错，觉得你后台硬的羽翼。要想在官场坐稳位子，同时配合自己遗传物质中的贪婪捞取些民脂民膏，怎么办呢？当然就找人咯，培育关系网啦。把自己的亲戚都弄成官党，肥水怎能流外人DNA。要晋升，上级干嘛用你？他自然要安排自己的亲戚。亲戚安排完了以后，又为什么要用你？当然啦，你给他的礼不匪，从你这里可以捞更多的好。那目光是怎么短浅的呢？因为生活资料争夺太激烈了，要是不在最短的时间里抢夺到最多的东西，那就没有你的分了，哪里还去管持不持续。也许你也有疑问，那些金字塔顶端的人应该有远见了吧。回答是，要有那也得多少代多少代的积累啊。你看中国历史，哪几个朝代不是农民革命成功翻身的啊。处在最底端的人翻身到了塔尖儿，你也别期望他们短时间里就变成目光如炬的人了啊。最终目的只有一个-------在激烈的物质资料争夺战中保全自己的DNA，于是导致了爱面子，自私自利，目光短浅，等等毛病的产生。\n\n&emsp;&emsp;对了还得说说中国人为我独尊的自大形象。从征服了长江黄河流域的始皇帝开始中国历代皇帝为了巩固统治不遗人口食通常都说自己是龙之子或者天子，自己就是神。而很多欧美人都有自己独特信仰，认为人人都是上帝子民人人平等。就算统治者教皇大人也不敢说自己就是神，而说自己只是神的代言人。足以看出中国人是以人为中心以自我为中心相信人定胜天。而别国多是以卑贱之心自视。中国为什么以前当世界的一哥当了那么久，原因除了归功于生产力地下的时代人多力量就大，其次就是以人为本。当然这里的以人为本并不是说人的权利和能动性得到最大限度的利用。相反，几乎所有人都被禁锢在儒家思想所倚仗的封建的严酷的等级制度下。能动性也都限制在很小的范围下，个人发挥的作用也都得到很大的限制。不过相对于人烟稀少的他国，信奉上帝的安排要好很多。他们自然也就无更多作为。但是思想启蒙运动（妻的历史显然要比我好几百倍）以后，某些国的人思想解放了。生产力飞升，我们自然也就不能比了。我们的思想还在干什么呢？雾埋了？\n\n&emsp;&emsp;好了，说到僧多粥少导致爱面子自私自立目光短，那僧少粥多的时候呢？发源于黄河流域的炎黄子孙难道从古猿人开始就多得如京城人一样没房子住？不是的。华夏人为什么那么自大，因为皇帝炎帝联军打败了蚩尤大军。胜王败寇啊。能打败蚩尤自然无所不能啊，信心爆蓬。我们是最厉害的，我们是世界的中心啊。所以我们叫中国。\n\n&emsp;&emsp;好了，最后的最后还是没有弄明白中国人为什么信自己不信上帝。我和妻只能推断，黄河流域土地太肥沃，人们风衣足食，在子孙蓬勃之前没有必要理会太多的不能被解释只能归功于上帝的自然现象而子孙无穷馈以后激烈的生活资料争夺使他们没有时间也无暇考虑那些神乎其神的事情。所以，我们不信上帝，我们也不讲科学。我们讲人。\n\n&emsp;&emsp;然而，我们的人呢？\n\n","source":"_posts/2013-12-09-雾霾齐步走.md","raw":"---\ntitle: 雾霾齐步走\ncategories:\n  - 乱笔\ntags:\n  - 雾霾\nabbrlink: 35510\ndate: 2013-12-09 21:49:19\n---\n\n&emsp;&emsp;据传，雾霾的妈妈叫他回去吃饭了。\n\n&emsp;&emsp;连续几天各大新闻媒体都在大肆报道华北华东的雾霾天气，中央打响了雾霾攻坚战。发言人说：污染主要来自于急功近利的工业生产。我们很有进步，现在每个省市都毫不隐瞒地向人民群众公布具体的污染数字。。。\n\n&emsp;&emsp;我和妻不禁感叹：中国人果然还是有在变得更好啊，瞧，这种家丑也终于敢拿出来示人了。\n\n&emsp;&emsp;慢着，我和妻花了一晚上的功夫，并不是要来数落中国人的好的啊，而是为了自我安慰似的找到中国发展到今天这个样子的根源。\n\n&emsp;&emsp;为什么雾霾这么张狂的睡在我们身边，把我们生活的地盘都要挤没了？经过我俩的激烈争论，终于有了初步答案。那就是-------很多中国人目光短浅。（大概我也是如此。）并不是我在骂自己人。好吧，其实很多时候骂自己人有种推卸责任的快感。不过好的借口是，知己知彼百战不怠。目光短浅这个结论并不是我根据自己自身特点总结出的，而是经过很多负面报道还有眼见而得的。比如中国人在一个劲儿的重视遛进10%的人口袋里的GDP，忽视长期的发展，忽视环境的污染，就甭提医保社保神马了。一味的追寻产量业绩，产品的质量得不到保证，市场自然就没了。产业结构一直走劳动密集型，没有自己的自主高科技产品（品牌）。山寨货横行。（慢着，很多东西是我自己说的，和娘子无关啊。我们没有讨论到这儿。）举个最鲜活的例子，欧洲美国人建城市，规划基本奔着几百年方案做（比如下水道可以跑车子）。中国人。。。我不知道你们（我们）在干什么。。。除了拆还会什么？\n\n&emsp;&emsp;再等等，GDP如果真是进了10%的人的腰包。那么这些金字塔尖上的人儿，您们应该深谋远虑些吧您哪。利益都钻到亲们的口袋了难道就不思忖着如何长期的可持续的捻到更多的肥肉？非要立刻马上卷了所有祖产，不给长工们活路。\n\n&emsp;&emsp;好吧。我们是无论如何也揣踱不出他们的心机的。也许他们就是那样想的，完事之后跑到列强国家摇尾祈怜也说不一定。因为来自中学课本的鲁大师说过，中国人是有奴性的。这帮金字塔尖儿上的人们，在咱们这儿做不了奴隶，那只能。。。去给别的国捡肥皂。\n\n&emsp;&emsp;话说，中国人为什么目光那么短浅？中国的某些官儿为什么那么爱贪？在中国，关系为什么就是生产力？为什么在中国面子问题是大问题？中国为什么发展的没有别的某些国发展的那么好？\n\n&emsp;&emsp;娘子的话很精辟------因为中国人太多，东西太少了很久。你能明白吧，弱肉强食，人不为己天理难容。\n\n&emsp;&emsp;因为僧多粥少，我们不得不努力为自己的肚子奋斗，长此以往，这种基因会刻在中国人的DNA里。就像肥胖症，是在饥荒年代那些拥有囤积脂肪能力的人保存下来的能力，贪婪也是中国人在华夏土地上几千年的食物争夺战中习得的能力。按理说，消除这种贪污腐败现象完善的监督机制就能解决，就像欧美的多党执政。你还别说，在中国要这样也不是不可以。不过前提就是中国就不是中国了，只有中国联邦，中国联盟，那谁谁谁都会争先化为被小美蹂躏小国的吧。您说对了，原因还是中国人多，而且中国还没有发展到好到很多党派来同时治理国家。倘若中国有很多党派如美国并且依然那么统一，试想，就目前的短视（能见度极低）而言，那岂不换一个执政党地皮都会翻转一回。由此由我俩可见，目前的由我党领导的一党专政体制还是很适合15亿中国人的。\n\n&emsp;&emsp;封建社会，中国人也是很多的，要保存自己的DNA并且延续下去也是很激烈残酷的。要想获得更多的生活资料，比如钱财，房屋，女人，在同一个家族里面我们需要表现很好才能获得长辈的肯定。瞧，你也能分析出中国人爱面子的原因了。因为首先在父母长辈眼里，你很厉害，至少比其他八个儿子厉害，你就能获得更多的遗产。（先不考虑嫡出庶出带来的先天地位不均）在女人面前有面子才能让她们觉得爷们儿有让孩子成为亮丽富二代的资本，才能赢得觉得嫁了有面儿的老公自己有面儿的女人的小心脏。在封建体制的官场，拉帮结派，乌纱才可保，有面儿才能赢得更多觉得你很不错，觉得你后台硬的羽翼。要想在官场坐稳位子，同时配合自己遗传物质中的贪婪捞取些民脂民膏，怎么办呢？当然就找人咯，培育关系网啦。把自己的亲戚都弄成官党，肥水怎能流外人DNA。要晋升，上级干嘛用你？他自然要安排自己的亲戚。亲戚安排完了以后，又为什么要用你？当然啦，你给他的礼不匪，从你这里可以捞更多的好。那目光是怎么短浅的呢？因为生活资料争夺太激烈了，要是不在最短的时间里抢夺到最多的东西，那就没有你的分了，哪里还去管持不持续。也许你也有疑问，那些金字塔顶端的人应该有远见了吧。回答是，要有那也得多少代多少代的积累啊。你看中国历史，哪几个朝代不是农民革命成功翻身的啊。处在最底端的人翻身到了塔尖儿，你也别期望他们短时间里就变成目光如炬的人了啊。最终目的只有一个-------在激烈的物质资料争夺战中保全自己的DNA，于是导致了爱面子，自私自利，目光短浅，等等毛病的产生。\n\n&emsp;&emsp;对了还得说说中国人为我独尊的自大形象。从征服了长江黄河流域的始皇帝开始中国历代皇帝为了巩固统治不遗人口食通常都说自己是龙之子或者天子，自己就是神。而很多欧美人都有自己独特信仰，认为人人都是上帝子民人人平等。就算统治者教皇大人也不敢说自己就是神，而说自己只是神的代言人。足以看出中国人是以人为中心以自我为中心相信人定胜天。而别国多是以卑贱之心自视。中国为什么以前当世界的一哥当了那么久，原因除了归功于生产力地下的时代人多力量就大，其次就是以人为本。当然这里的以人为本并不是说人的权利和能动性得到最大限度的利用。相反，几乎所有人都被禁锢在儒家思想所倚仗的封建的严酷的等级制度下。能动性也都限制在很小的范围下，个人发挥的作用也都得到很大的限制。不过相对于人烟稀少的他国，信奉上帝的安排要好很多。他们自然也就无更多作为。但是思想启蒙运动（妻的历史显然要比我好几百倍）以后，某些国的人思想解放了。生产力飞升，我们自然也就不能比了。我们的思想还在干什么呢？雾埋了？\n\n&emsp;&emsp;好了，说到僧多粥少导致爱面子自私自立目光短，那僧少粥多的时候呢？发源于黄河流域的炎黄子孙难道从古猿人开始就多得如京城人一样没房子住？不是的。华夏人为什么那么自大，因为皇帝炎帝联军打败了蚩尤大军。胜王败寇啊。能打败蚩尤自然无所不能啊，信心爆蓬。我们是最厉害的，我们是世界的中心啊。所以我们叫中国。\n\n&emsp;&emsp;好了，最后的最后还是没有弄明白中国人为什么信自己不信上帝。我和妻只能推断，黄河流域土地太肥沃，人们风衣足食，在子孙蓬勃之前没有必要理会太多的不能被解释只能归功于上帝的自然现象而子孙无穷馈以后激烈的生活资料争夺使他们没有时间也无暇考虑那些神乎其神的事情。所以，我们不信上帝，我们也不讲科学。我们讲人。\n\n&emsp;&emsp;然而，我们的人呢？\n\n","slug":"雾霾齐步走","published":1,"updated":"2024-05-26T14:17:36.845Z","comments":1,"layout":"post","photos":[],"_id":"cmh498iov002jwvou1sv3beo8","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>&emsp;&emsp;据传，雾霾的妈妈叫他回去吃饭了。</p>\n<p>&emsp;&emsp;连续几天各大新闻媒体都在大肆报道华北华东的雾霾天气，中央打响了雾霾攻坚战。发言人说：污染主要来自于急功近利的工业生产。我们很有进步，现在每个省市都毫不隐瞒地向人民群众公布具体的污染数字。。。</p>\n<p>&emsp;&emsp;我和妻不禁感叹：中国人果然还是有在变得更好啊，瞧，这种家丑也终于敢拿出来示人了。</p>\n<p>&emsp;&emsp;慢着，我和妻花了一晚上的功夫，并不是要来数落中国人的好的啊，而是为了自我安慰似的找到中国发展到今天这个样子的根源。</p>\n<p>&emsp;&emsp;为什么雾霾这么张狂的睡在我们身边，把我们生活的地盘都要挤没了？经过我俩的激烈争论，终于有了初步答案。那就是——-很多中国人目光短浅。（大概我也是如此。）并不是我在骂自己人。好吧，其实很多时候骂自己人有种推卸责任的快感。不过好的借口是，知己知彼百战不怠。目光短浅这个结论并不是我根据自己自身特点总结出的，而是经过很多负面报道还有眼见而得的。比如中国人在一个劲儿的重视遛进10%的人口袋里的GDP，忽视长期的发展，忽视环境的污染，就甭提医保社保神马了。一味的追寻产量业绩，产品的质量得不到保证，市场自然就没了。产业结构一直走劳动密集型，没有自己的自主高科技产品（品牌）。山寨货横行。（慢着，很多东西是我自己说的，和娘子无关啊。我们没有讨论到这儿。）举个最鲜活的例子，欧洲美国人建城市，规划基本奔着几百年方案做（比如下水道可以跑车子）。中国人。。。我不知道你们（我们）在干什么。。。除了拆还会什么？</p>\n<p>&emsp;&emsp;再等等，GDP如果真是进了10%的人的腰包。那么这些金字塔尖上的人儿，您们应该深谋远虑些吧您哪。利益都钻到亲们的口袋了难道就不思忖着如何长期的可持续的捻到更多的肥肉？非要立刻马上卷了所有祖产，不给长工们活路。</p>\n<p>&emsp;&emsp;好吧。我们是无论如何也揣踱不出他们的心机的。也许他们就是那样想的，完事之后跑到列强国家摇尾祈怜也说不一定。因为来自中学课本的鲁大师说过，中国人是有奴性的。这帮金字塔尖儿上的人们，在咱们这儿做不了奴隶，那只能。。。去给别的国捡肥皂。</p>\n<p>&emsp;&emsp;话说，中国人为什么目光那么短浅？中国的某些官儿为什么那么爱贪？在中国，关系为什么就是生产力？为什么在中国面子问题是大问题？中国为什么发展的没有别的某些国发展的那么好？</p>\n<p>&emsp;&emsp;娘子的话很精辟——因为中国人太多，东西太少了很久。你能明白吧，弱肉强食，人不为己天理难容。</p>\n<p>&emsp;&emsp;因为僧多粥少，我们不得不努力为自己的肚子奋斗，长此以往，这种基因会刻在中国人的DNA里。就像肥胖症，是在饥荒年代那些拥有囤积脂肪能力的人保存下来的能力，贪婪也是中国人在华夏土地上几千年的食物争夺战中习得的能力。按理说，消除这种贪污腐败现象完善的监督机制就能解决，就像欧美的多党执政。你还别说，在中国要这样也不是不可以。不过前提就是中国就不是中国了，只有中国联邦，中国联盟，那谁谁谁都会争先化为被小美蹂躏小国的吧。您说对了，原因还是中国人多，而且中国还没有发展到好到很多党派来同时治理国家。倘若中国有很多党派如美国并且依然那么统一，试想，就目前的短视（能见度极低）而言，那岂不换一个执政党地皮都会翻转一回。由此由我俩可见，目前的由我党领导的一党专政体制还是很适合15亿中国人的。</p>\n<p>&emsp;&emsp;封建社会，中国人也是很多的，要保存自己的DNA并且延续下去也是很激烈残酷的。要想获得更多的生活资料，比如钱财，房屋，女人，在同一个家族里面我们需要表现很好才能获得长辈的肯定。瞧，你也能分析出中国人爱面子的原因了。因为首先在父母长辈眼里，你很厉害，至少比其他八个儿子厉害，你就能获得更多的遗产。（先不考虑嫡出庶出带来的先天地位不均）在女人面前有面子才能让她们觉得爷们儿有让孩子成为亮丽富二代的资本，才能赢得觉得嫁了有面儿的老公自己有面儿的女人的小心脏。在封建体制的官场，拉帮结派，乌纱才可保，有面儿才能赢得更多觉得你很不错，觉得你后台硬的羽翼。要想在官场坐稳位子，同时配合自己遗传物质中的贪婪捞取些民脂民膏，怎么办呢？当然就找人咯，培育关系网啦。把自己的亲戚都弄成官党，肥水怎能流外人DNA。要晋升，上级干嘛用你？他自然要安排自己的亲戚。亲戚安排完了以后，又为什么要用你？当然啦，你给他的礼不匪，从你这里可以捞更多的好。那目光是怎么短浅的呢？因为生活资料争夺太激烈了，要是不在最短的时间里抢夺到最多的东西，那就没有你的分了，哪里还去管持不持续。也许你也有疑问，那些金字塔顶端的人应该有远见了吧。回答是，要有那也得多少代多少代的积累啊。你看中国历史，哪几个朝代不是农民革命成功翻身的啊。处在最底端的人翻身到了塔尖儿，你也别期望他们短时间里就变成目光如炬的人了啊。最终目的只有一个——-在激烈的物质资料争夺战中保全自己的DNA，于是导致了爱面子，自私自利，目光短浅，等等毛病的产生。</p>\n<p>&emsp;&emsp;对了还得说说中国人为我独尊的自大形象。从征服了长江黄河流域的始皇帝开始中国历代皇帝为了巩固统治不遗人口食通常都说自己是龙之子或者天子，自己就是神。而很多欧美人都有自己独特信仰，认为人人都是上帝子民人人平等。就算统治者教皇大人也不敢说自己就是神，而说自己只是神的代言人。足以看出中国人是以人为中心以自我为中心相信人定胜天。而别国多是以卑贱之心自视。中国为什么以前当世界的一哥当了那么久，原因除了归功于生产力地下的时代人多力量就大，其次就是以人为本。当然这里的以人为本并不是说人的权利和能动性得到最大限度的利用。相反，几乎所有人都被禁锢在儒家思想所倚仗的封建的严酷的等级制度下。能动性也都限制在很小的范围下，个人发挥的作用也都得到很大的限制。不过相对于人烟稀少的他国，信奉上帝的安排要好很多。他们自然也就无更多作为。但是思想启蒙运动（妻的历史显然要比我好几百倍）以后，某些国的人思想解放了。生产力飞升，我们自然也就不能比了。我们的思想还在干什么呢？雾埋了？</p>\n<p>&emsp;&emsp;好了，说到僧多粥少导致爱面子自私自立目光短，那僧少粥多的时候呢？发源于黄河流域的炎黄子孙难道从古猿人开始就多得如京城人一样没房子住？不是的。华夏人为什么那么自大，因为皇帝炎帝联军打败了蚩尤大军。胜王败寇啊。能打败蚩尤自然无所不能啊，信心爆蓬。我们是最厉害的，我们是世界的中心啊。所以我们叫中国。</p>\n<p>&emsp;&emsp;好了，最后的最后还是没有弄明白中国人为什么信自己不信上帝。我和妻只能推断，黄河流域土地太肥沃，人们风衣足食，在子孙蓬勃之前没有必要理会太多的不能被解释只能归功于上帝的自然现象而子孙无穷馈以后激烈的生活资料争夺使他们没有时间也无暇考虑那些神乎其神的事情。所以，我们不信上帝，我们也不讲科学。我们讲人。</p>\n<p>&emsp;&emsp;然而，我们的人呢？</p>\n","related_posts":[],"length":2838,"excerpt":"","more":"<p>&emsp;&emsp;据传，雾霾的妈妈叫他回去吃饭了。</p>\n<p>&emsp;&emsp;连续几天各大新闻媒体都在大肆报道华北华东的雾霾天气，中央打响了雾霾攻坚战。发言人说：污染主要来自于急功近利的工业生产。我们很有进步，现在每个省市都毫不隐瞒地向人民群众公布具体的污染数字。。。</p>\n<p>&emsp;&emsp;我和妻不禁感叹：中国人果然还是有在变得更好啊，瞧，这种家丑也终于敢拿出来示人了。</p>\n<p>&emsp;&emsp;慢着，我和妻花了一晚上的功夫，并不是要来数落中国人的好的啊，而是为了自我安慰似的找到中国发展到今天这个样子的根源。</p>\n<p>&emsp;&emsp;为什么雾霾这么张狂的睡在我们身边，把我们生活的地盘都要挤没了？经过我俩的激烈争论，终于有了初步答案。那就是——-很多中国人目光短浅。（大概我也是如此。）并不是我在骂自己人。好吧，其实很多时候骂自己人有种推卸责任的快感。不过好的借口是，知己知彼百战不怠。目光短浅这个结论并不是我根据自己自身特点总结出的，而是经过很多负面报道还有眼见而得的。比如中国人在一个劲儿的重视遛进10%的人口袋里的GDP，忽视长期的发展，忽视环境的污染，就甭提医保社保神马了。一味的追寻产量业绩，产品的质量得不到保证，市场自然就没了。产业结构一直走劳动密集型，没有自己的自主高科技产品（品牌）。山寨货横行。（慢着，很多东西是我自己说的，和娘子无关啊。我们没有讨论到这儿。）举个最鲜活的例子，欧洲美国人建城市，规划基本奔着几百年方案做（比如下水道可以跑车子）。中国人。。。我不知道你们（我们）在干什么。。。除了拆还会什么？</p>\n<p>&emsp;&emsp;再等等，GDP如果真是进了10%的人的腰包。那么这些金字塔尖上的人儿，您们应该深谋远虑些吧您哪。利益都钻到亲们的口袋了难道就不思忖着如何长期的可持续的捻到更多的肥肉？非要立刻马上卷了所有祖产，不给长工们活路。</p>\n<p>&emsp;&emsp;好吧。我们是无论如何也揣踱不出他们的心机的。也许他们就是那样想的，完事之后跑到列强国家摇尾祈怜也说不一定。因为来自中学课本的鲁大师说过，中国人是有奴性的。这帮金字塔尖儿上的人们，在咱们这儿做不了奴隶，那只能。。。去给别的国捡肥皂。</p>\n<p>&emsp;&emsp;话说，中国人为什么目光那么短浅？中国的某些官儿为什么那么爱贪？在中国，关系为什么就是生产力？为什么在中国面子问题是大问题？中国为什么发展的没有别的某些国发展的那么好？</p>\n<p>&emsp;&emsp;娘子的话很精辟——因为中国人太多，东西太少了很久。你能明白吧，弱肉强食，人不为己天理难容。</p>\n<p>&emsp;&emsp;因为僧多粥少，我们不得不努力为自己的肚子奋斗，长此以往，这种基因会刻在中国人的DNA里。就像肥胖症，是在饥荒年代那些拥有囤积脂肪能力的人保存下来的能力，贪婪也是中国人在华夏土地上几千年的食物争夺战中习得的能力。按理说，消除这种贪污腐败现象完善的监督机制就能解决，就像欧美的多党执政。你还别说，在中国要这样也不是不可以。不过前提就是中国就不是中国了，只有中国联邦，中国联盟，那谁谁谁都会争先化为被小美蹂躏小国的吧。您说对了，原因还是中国人多，而且中国还没有发展到好到很多党派来同时治理国家。倘若中国有很多党派如美国并且依然那么统一，试想，就目前的短视（能见度极低）而言，那岂不换一个执政党地皮都会翻转一回。由此由我俩可见，目前的由我党领导的一党专政体制还是很适合15亿中国人的。</p>\n<p>&emsp;&emsp;封建社会，中国人也是很多的，要保存自己的DNA并且延续下去也是很激烈残酷的。要想获得更多的生活资料，比如钱财，房屋，女人，在同一个家族里面我们需要表现很好才能获得长辈的肯定。瞧，你也能分析出中国人爱面子的原因了。因为首先在父母长辈眼里，你很厉害，至少比其他八个儿子厉害，你就能获得更多的遗产。（先不考虑嫡出庶出带来的先天地位不均）在女人面前有面子才能让她们觉得爷们儿有让孩子成为亮丽富二代的资本，才能赢得觉得嫁了有面儿的老公自己有面儿的女人的小心脏。在封建体制的官场，拉帮结派，乌纱才可保，有面儿才能赢得更多觉得你很不错，觉得你后台硬的羽翼。要想在官场坐稳位子，同时配合自己遗传物质中的贪婪捞取些民脂民膏，怎么办呢？当然就找人咯，培育关系网啦。把自己的亲戚都弄成官党，肥水怎能流外人DNA。要晋升，上级干嘛用你？他自然要安排自己的亲戚。亲戚安排完了以后，又为什么要用你？当然啦，你给他的礼不匪，从你这里可以捞更多的好。那目光是怎么短浅的呢？因为生活资料争夺太激烈了，要是不在最短的时间里抢夺到最多的东西，那就没有你的分了，哪里还去管持不持续。也许你也有疑问，那些金字塔顶端的人应该有远见了吧。回答是，要有那也得多少代多少代的积累啊。你看中国历史，哪几个朝代不是农民革命成功翻身的啊。处在最底端的人翻身到了塔尖儿，你也别期望他们短时间里就变成目光如炬的人了啊。最终目的只有一个——-在激烈的物质资料争夺战中保全自己的DNA，于是导致了爱面子，自私自利，目光短浅，等等毛病的产生。</p>\n<p>&emsp;&emsp;对了还得说说中国人为我独尊的自大形象。从征服了长江黄河流域的始皇帝开始中国历代皇帝为了巩固统治不遗人口食通常都说自己是龙之子或者天子，自己就是神。而很多欧美人都有自己独特信仰，认为人人都是上帝子民人人平等。就算统治者教皇大人也不敢说自己就是神，而说自己只是神的代言人。足以看出中国人是以人为中心以自我为中心相信人定胜天。而别国多是以卑贱之心自视。中国为什么以前当世界的一哥当了那么久，原因除了归功于生产力地下的时代人多力量就大，其次就是以人为本。当然这里的以人为本并不是说人的权利和能动性得到最大限度的利用。相反，几乎所有人都被禁锢在儒家思想所倚仗的封建的严酷的等级制度下。能动性也都限制在很小的范围下，个人发挥的作用也都得到很大的限制。不过相对于人烟稀少的他国，信奉上帝的安排要好很多。他们自然也就无更多作为。但是思想启蒙运动（妻的历史显然要比我好几百倍）以后，某些国的人思想解放了。生产力飞升，我们自然也就不能比了。我们的思想还在干什么呢？雾埋了？</p>\n<p>&emsp;&emsp;好了，说到僧多粥少导致爱面子自私自立目光短，那僧少粥多的时候呢？发源于黄河流域的炎黄子孙难道从古猿人开始就多得如京城人一样没房子住？不是的。华夏人为什么那么自大，因为皇帝炎帝联军打败了蚩尤大军。胜王败寇啊。能打败蚩尤自然无所不能啊，信心爆蓬。我们是最厉害的，我们是世界的中心啊。所以我们叫中国。</p>\n<p>&emsp;&emsp;好了，最后的最后还是没有弄明白中国人为什么信自己不信上帝。我和妻只能推断，黄河流域土地太肥沃，人们风衣足食，在子孙蓬勃之前没有必要理会太多的不能被解释只能归功于上帝的自然现象而子孙无穷馈以后激烈的生活资料争夺使他们没有时间也无暇考虑那些神乎其神的事情。所以，我们不信上帝，我们也不讲科学。我们讲人。</p>\n<p>&emsp;&emsp;然而，我们的人呢？</p>\n"},{"title":"Win7下格掉Linux盘如何启动windows","abbrlink":60954,"date":"2013-12-23T17:40:27.000Z","_content":"\n&emsp;&emsp;在win7下用系统的磁盘管理工具把原来的fedora14给格了，然后重启就只能进入grub，试了安装盘修复也不行。\n\n在grub中输入命令：\n\n``` bash\ngrub>rootnoverify (hd0,0) \ngrub>makeactive \ngrub>chainloader +1\ngrub>boot\n```\n\n&emsp;&emsp;奏效。进入了windows。然后下载clear mbr （还原清新畅快的mbr，大概格掉了grub）。\n\n然后大功告成。\n\n","source":"_posts/2013-12-24-Win7下格掉Linux盘如何启动windows.md","raw":"---\ntitle: Win7下格掉Linux盘如何启动windows\ncategories:\n  - Linux\ntags:\n  - grub\nabbrlink: 60954\ndate: 2013-12-24 01:40:27\n---\n\n&emsp;&emsp;在win7下用系统的磁盘管理工具把原来的fedora14给格了，然后重启就只能进入grub，试了安装盘修复也不行。\n\n在grub中输入命令：\n\n``` bash\ngrub>rootnoverify (hd0,0) \ngrub>makeactive \ngrub>chainloader +1\ngrub>boot\n```\n\n&emsp;&emsp;奏效。进入了windows。然后下载clear mbr （还原清新畅快的mbr，大概格掉了grub）。\n\n然后大功告成。\n\n","slug":"Win7下格掉Linux盘如何启动windows","published":1,"updated":"2024-05-26T14:17:36.845Z","comments":1,"layout":"post","photos":[],"_id":"cmh498iow002nwvoucc8h5nij","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>&emsp;&emsp;在win7下用系统的磁盘管理工具把原来的fedora14给格了，然后重启就只能进入grub，试了安装盘修复也不行。</p>\n<p>在grub中输入命令：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">grub&gt;rootnoverify (hd0,0) </span><br><span class=\"line\">grub&gt;makeactive </span><br><span class=\"line\">grub&gt;chainloader +1</span><br><span class=\"line\">grub&gt;boot</span><br></pre></td></tr></table></figure>\n\n<p>&emsp;&emsp;奏效。进入了windows。然后下载clear mbr （还原清新畅快的mbr，大概格掉了grub）。</p>\n<p>然后大功告成。</p>\n","related_posts":["word-count.html"],"length":230,"excerpt":"","more":"<p>&emsp;&emsp;在win7下用系统的磁盘管理工具把原来的fedora14给格了，然后重启就只能进入grub，试了安装盘修复也不行。</p>\n<p>在grub中输入命令：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">grub&gt;rootnoverify (hd0,0) </span><br><span class=\"line\">grub&gt;makeactive </span><br><span class=\"line\">grub&gt;chainloader +1</span><br><span class=\"line\">grub&gt;boot</span><br></pre></td></tr></table></figure>\n\n<p>&emsp;&emsp;奏效。进入了windows。然后下载clear mbr （还原清新畅快的mbr，大概格掉了grub）。</p>\n<p>然后大功告成。</p>\n"},{"title":"乱2","abbrlink":36882,"date":"2015-07-08T03:07:54.000Z","_content":"\n&emsp;&emsp;弯弯曲曲的阳光直直的照进屋外，熟睡的我高兴地蹦起来落在了天花板。窗台上留下了10年以后我的脚印。我重重的摔在软绵绵的岩石上，像蹦极一样来回颠簸。一只尖叫的青蛙从结冰的湖面窜出，湖面结了一个窟窿，天空泛起直直的嶙峋波纹。半空中横陈着的乐者手舞足蹈的吹奏着口中的琵琶，一只只曼妙的如箭的音符射向四周，箭尖着地处开出了美丽的蝴蝶。我泛舟湖底，领略着满天的繁星。一对鱼儿在空中划着拳，输了的那位颐指气使，赢了的那位红了双腮。忽然一阵微风袭来，将我卷进了透明的电话簿。可怜那船儿被卷成了一颗树苗。我花了一立方的时间睁开眼，发现树苗上结满了刀子。我摘下其中熟透了的一把，割下了我的一只脚趾。我将我剩下的部分扔进了雷电，那只脚趾开始慢慢的发了芽。\n\n","source":"_posts/2015-07-08-乱2.md","raw":"---\ntitle: 乱2\ncategories:\n  - 乱笔\ntags:\n  - 杂\nabbrlink: 36882\ndate: 2015-07-08 11:07:54\n---\n\n&emsp;&emsp;弯弯曲曲的阳光直直的照进屋外，熟睡的我高兴地蹦起来落在了天花板。窗台上留下了10年以后我的脚印。我重重的摔在软绵绵的岩石上，像蹦极一样来回颠簸。一只尖叫的青蛙从结冰的湖面窜出，湖面结了一个窟窿，天空泛起直直的嶙峋波纹。半空中横陈着的乐者手舞足蹈的吹奏着口中的琵琶，一只只曼妙的如箭的音符射向四周，箭尖着地处开出了美丽的蝴蝶。我泛舟湖底，领略着满天的繁星。一对鱼儿在空中划着拳，输了的那位颐指气使，赢了的那位红了双腮。忽然一阵微风袭来，将我卷进了透明的电话簿。可怜那船儿被卷成了一颗树苗。我花了一立方的时间睁开眼，发现树苗上结满了刀子。我摘下其中熟透了的一把，割下了我的一只脚趾。我将我剩下的部分扔进了雷电，那只脚趾开始慢慢的发了芽。\n\n","slug":"乱2","published":1,"updated":"2024-05-26T14:17:36.845Z","comments":1,"layout":"post","photos":[],"_id":"cmh498iow002pwvouh9276n5y","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>&emsp;&emsp;弯弯曲曲的阳光直直的照进屋外，熟睡的我高兴地蹦起来落在了天花板。窗台上留下了10年以后我的脚印。我重重的摔在软绵绵的岩石上，像蹦极一样来回颠簸。一只尖叫的青蛙从结冰的湖面窜出，湖面结了一个窟窿，天空泛起直直的嶙峋波纹。半空中横陈着的乐者手舞足蹈的吹奏着口中的琵琶，一只只曼妙的如箭的音符射向四周，箭尖着地处开出了美丽的蝴蝶。我泛舟湖底，领略着满天的繁星。一对鱼儿在空中划着拳，输了的那位颐指气使，赢了的那位红了双腮。忽然一阵微风袭来，将我卷进了透明的电话簿。可怜那船儿被卷成了一颗树苗。我花了一立方的时间睁开眼，发现树苗上结满了刀子。我摘下其中熟透了的一把，割下了我的一只脚趾。我将我剩下的部分扔进了雷电，那只脚趾开始慢慢的发了芽。</p>\n","related_posts":[],"length":328,"excerpt":"","more":"<p>&emsp;&emsp;弯弯曲曲的阳光直直的照进屋外，熟睡的我高兴地蹦起来落在了天花板。窗台上留下了10年以后我的脚印。我重重的摔在软绵绵的岩石上，像蹦极一样来回颠簸。一只尖叫的青蛙从结冰的湖面窜出，湖面结了一个窟窿，天空泛起直直的嶙峋波纹。半空中横陈着的乐者手舞足蹈的吹奏着口中的琵琶，一只只曼妙的如箭的音符射向四周，箭尖着地处开出了美丽的蝴蝶。我泛舟湖底，领略着满天的繁星。一对鱼儿在空中划着拳，输了的那位颐指气使，赢了的那位红了双腮。忽然一阵微风袭来，将我卷进了透明的电话簿。可怜那船儿被卷成了一颗树苗。我花了一立方的时间睁开眼，发现树苗上结满了刀子。我摘下其中熟透了的一把，割下了我的一只脚趾。我将我剩下的部分扔进了雷电，那只脚趾开始慢慢的发了芽。</p>\n"},{"title":"启程去玛雅一","abbrlink":47069,"date":"2015-11-01T00:18:22.000Z","_content":"\n&emsp;&emsp;“你不是开玩笑吧蕊。。。哈哈哈。。。”电话那头尖叫起来：“真的替你感到高兴啊。。。”\n\n&emsp;&emsp;“谢谢你萱萱”，蕊高兴的说到，仿佛两只小熊一同分享着超甜的蜜。\n\n&emsp;&emsp;“找到财宝可不要忘了我啊。。。呵呵。。。”电话那头开始寒暄起来，玩笑的说到。\n\n&emsp;&emsp;“当然不会啦，话说，你说的财宝恐怕早已经被别人挖空了。。。哎。。。不管怎么样我一定要找到它的秘密。。。”\n\n&emsp;&emsp;“诶诶诶。。。别认真啊。。。我最怕你认真了。。。想当年念书那会儿你是整天泡在图书馆。要不是老娘当初看你有几分姿色是个可塑之材，把你从学海那个什么深渊旁边拉上来，还不知道你会变成怎么样的书呆子呢。你看看你今天，要风得风，要雨得雨。。。呃。。。尽管还是被学术给套牢了，那至少还是一个知性大龄剩女青年啊。。。”\n\n&emsp;&emsp;“喂喂喂。。。就你厉害，谁也胜不了你的乌鸦嘴行了吧。”\n\n&emsp;&emsp;“话说，你一走我就成孤家寡人了啊。。。这精神损失费你自个儿掂量掂量啊。。。”\n\n&emsp;&emsp;“嗯，知道，我也会想你的。。。”\n\n&emsp;&emsp;“你会想才怪呐。。。改明儿个见了个石头都当情人，你要是会记得我那石头都讲人话了。呵呵。。。”\n\n&emsp;&emsp;电话两头同时响起笑声，房间里的空气也欢乐的共振起来。蕊的眼睛凝神在博古架上的一块透明不规则水晶石上面。那块石头是校领导从美洲带回来的，据说是在蒂卡尔城的金字塔旁边捡的。这块不起眼的石头被其他来自各个地方的地质矿物石头所簇拥着。其他堆满博古架的颜色各异，形态各具的石头都是蕊随地质考察队在野外采集的标本。除了这一块，其他的任何一块石头蕊都知道来历，能道出是形成于哪个地质年代，还能知道每一块石头形成的环境，经历的世事。唯独那块水晶她不知道。不是不知道它的组成------无非是一堆二氧化硅晶体；也不是不明白它的生长条件-----要有足够的压力和温度，最重要的是硅酸盐富集液。令她不安的是她不知道这块水晶长在哪块晶洞，被来自哪里的营养液滋养。也就是说她不知道这块水晶的家在哪里，不知道这块水晶的“父母”是谁，就像她自己一样。在她看来每块石头都是鲜活的生命，都能够和她对话。其他蕊亲手收集的标本石头都是开朗活泼的，而这一块从来到她的这个小公寓里尽管与满屋的书香，满屋的石气书香气混在一起，但是从来都显得格格不入，因为与其他石头不同伴随着它的是孤独和无助。看到这块水晶就像蕊看着天真无助的自己。尽管所有其他石头都是她亲手挖掘、把玩、测量，像极了自己的孩子，然而这一块却像极了自己。对于孩子她可以献出所有，然而对于自己她却无所适从。\n\n&emsp;&emsp;“对了，你哪天的飞机啊？”电话中的询问把蕊拉回现实。气氛变得严肃了一秒钟。\n\n&emsp;&emsp;“哦，具体时间我还不清楚，公司那边安排的专机，到时候会通知我的。” \n\n&emsp;&emsp;“专机啊，小妮子还真气派啊。。。能不能捎上我啊？小女子给您烧火做饭暖床，如何啊？”\n\n&emsp;&emsp;“我倒是想啊，不过这次经费全是高德公司提供，所以一切都得听他们安排。仪器、资料、行李什么的据说都不用带，带上我的人就够了。”\n\n&emsp;&emsp;“听起来怎么那么像包养啊？我仿佛看到了李美美啊。。。”\n\n&emsp;&emsp;“狗嘴里果然是吐不出象牙来。。。”\n\n&emsp;&emsp;呵呵呵。房间里又是一通笑声。两人许久未长聊，如今相谈甚欢。萱萱的存在能够些许的慰藉她的孤独的心。\n\n&emsp;&emsp;“人家为什么要给你经费啊？哦，我明白了，不是仰慕你的文材学问就是为了劫色。哈哈哈。。。”\n\n&emsp;&emsp;“都是我争取来的啊。。。是我的梦想。。。他们看了我的关于玛雅文明的研究论文，觉得很出色。。。”其实在蕊的心里，她更觉得这是她的宿命。\n\n&emsp;&emsp;“得得得，又来劲了不是。”\n\n&emsp;&emsp;高德司这家跨国企业为了加强与南美州国家经贸关系才有此次的投入。蕊清楚高德司是做古董生意，在签合同前她对这家公司做了仔细的调研。认为其还算是一家合法正当的盈利机构，并没有收购非法国家珍宝的勾当，更没有联合盗墓贼做见不得光的事。\n\n&emsp;&emsp;“好了，时间不早了，我也不打搅你科研了，大科学家。” \n\n&emsp;&emsp;“我才不是什么大科学家呢。。。算了不和你说了，改天吃践行饭再细说。好了，晚安。。。”\n\n&emsp;&emsp;蕊挂了电话，忽然想起住在疗养院的母亲。母亲是孤儿院的老院长，在疗养院已经住了有十年。十年前操劳过度的母亲患上了帕金森综合症，也就是老年痴呆。以前的所有事情都不记得，连亲手带大的孩子也不记得。要是母亲没有生病就好了，她想，没有病的话说不一定还能记得我的可恶的生生父母是谁，还记得我的身世。不过母亲生病前她也问过，她并不知道她的身世，只知道一天她莫名其妙就出现在孤儿院门前，身上连纸条都没有。有时候蕊又忽然觉得自己好可笑。人为什么要知道自己的生生父母是谁？有一个爱自己的养母不是很好吗？有自己喜欢做的事情不是很好吗？尽管如此想着，心里的那一丝绳结仍然解不开。总有一节疙瘩化不开，像是血液里的一块坚硬的血栓，总是时不时的碰撞她的柔软的心脏瓣膜。\n\n&emsp;&emsp;她翻看着《失落的印加文明》，书的扉页已被她翻得发黄，可仍然找不到她想要的答案。因为除了那块石头的秘密，她还有许多的疑问：玛雅文明、阿兹特科帝国、印加帝国曾经如此辉煌为何轻易被蛮夷的西班牙人摧毁？印加帝国的国徽为什么看起来似曾相似？为什么三个文明都隐藏于深山，放着广袤的平原不去利用？关于2012灭亡的预言是他们的历法的错误还是他给后代人的玩笑？好多好多的疑问等待她去揭示，像揭开美丽新娘的面纱。\n\n&emsp;&emsp;算了，她和上了书，心里即期待又兴奋，终于有机会亲自去揭露这些秘密了。\n\n","source":"_posts/2015-11-01-启程去玛雅.md","raw":"---\ntitle: 启程去玛雅一\ncategories:\n  - 乱笔\ntags:\nabbrlink: 47069\ndate: 2015-11-01 08:18:22\n---\n\n&emsp;&emsp;“你不是开玩笑吧蕊。。。哈哈哈。。。”电话那头尖叫起来：“真的替你感到高兴啊。。。”\n\n&emsp;&emsp;“谢谢你萱萱”，蕊高兴的说到，仿佛两只小熊一同分享着超甜的蜜。\n\n&emsp;&emsp;“找到财宝可不要忘了我啊。。。呵呵。。。”电话那头开始寒暄起来，玩笑的说到。\n\n&emsp;&emsp;“当然不会啦，话说，你说的财宝恐怕早已经被别人挖空了。。。哎。。。不管怎么样我一定要找到它的秘密。。。”\n\n&emsp;&emsp;“诶诶诶。。。别认真啊。。。我最怕你认真了。。。想当年念书那会儿你是整天泡在图书馆。要不是老娘当初看你有几分姿色是个可塑之材，把你从学海那个什么深渊旁边拉上来，还不知道你会变成怎么样的书呆子呢。你看看你今天，要风得风，要雨得雨。。。呃。。。尽管还是被学术给套牢了，那至少还是一个知性大龄剩女青年啊。。。”\n\n&emsp;&emsp;“喂喂喂。。。就你厉害，谁也胜不了你的乌鸦嘴行了吧。”\n\n&emsp;&emsp;“话说，你一走我就成孤家寡人了啊。。。这精神损失费你自个儿掂量掂量啊。。。”\n\n&emsp;&emsp;“嗯，知道，我也会想你的。。。”\n\n&emsp;&emsp;“你会想才怪呐。。。改明儿个见了个石头都当情人，你要是会记得我那石头都讲人话了。呵呵。。。”\n\n&emsp;&emsp;电话两头同时响起笑声，房间里的空气也欢乐的共振起来。蕊的眼睛凝神在博古架上的一块透明不规则水晶石上面。那块石头是校领导从美洲带回来的，据说是在蒂卡尔城的金字塔旁边捡的。这块不起眼的石头被其他来自各个地方的地质矿物石头所簇拥着。其他堆满博古架的颜色各异，形态各具的石头都是蕊随地质考察队在野外采集的标本。除了这一块，其他的任何一块石头蕊都知道来历，能道出是形成于哪个地质年代，还能知道每一块石头形成的环境，经历的世事。唯独那块水晶她不知道。不是不知道它的组成------无非是一堆二氧化硅晶体；也不是不明白它的生长条件-----要有足够的压力和温度，最重要的是硅酸盐富集液。令她不安的是她不知道这块水晶长在哪块晶洞，被来自哪里的营养液滋养。也就是说她不知道这块水晶的家在哪里，不知道这块水晶的“父母”是谁，就像她自己一样。在她看来每块石头都是鲜活的生命，都能够和她对话。其他蕊亲手收集的标本石头都是开朗活泼的，而这一块从来到她的这个小公寓里尽管与满屋的书香，满屋的石气书香气混在一起，但是从来都显得格格不入，因为与其他石头不同伴随着它的是孤独和无助。看到这块水晶就像蕊看着天真无助的自己。尽管所有其他石头都是她亲手挖掘、把玩、测量，像极了自己的孩子，然而这一块却像极了自己。对于孩子她可以献出所有，然而对于自己她却无所适从。\n\n&emsp;&emsp;“对了，你哪天的飞机啊？”电话中的询问把蕊拉回现实。气氛变得严肃了一秒钟。\n\n&emsp;&emsp;“哦，具体时间我还不清楚，公司那边安排的专机，到时候会通知我的。” \n\n&emsp;&emsp;“专机啊，小妮子还真气派啊。。。能不能捎上我啊？小女子给您烧火做饭暖床，如何啊？”\n\n&emsp;&emsp;“我倒是想啊，不过这次经费全是高德公司提供，所以一切都得听他们安排。仪器、资料、行李什么的据说都不用带，带上我的人就够了。”\n\n&emsp;&emsp;“听起来怎么那么像包养啊？我仿佛看到了李美美啊。。。”\n\n&emsp;&emsp;“狗嘴里果然是吐不出象牙来。。。”\n\n&emsp;&emsp;呵呵呵。房间里又是一通笑声。两人许久未长聊，如今相谈甚欢。萱萱的存在能够些许的慰藉她的孤独的心。\n\n&emsp;&emsp;“人家为什么要给你经费啊？哦，我明白了，不是仰慕你的文材学问就是为了劫色。哈哈哈。。。”\n\n&emsp;&emsp;“都是我争取来的啊。。。是我的梦想。。。他们看了我的关于玛雅文明的研究论文，觉得很出色。。。”其实在蕊的心里，她更觉得这是她的宿命。\n\n&emsp;&emsp;“得得得，又来劲了不是。”\n\n&emsp;&emsp;高德司这家跨国企业为了加强与南美州国家经贸关系才有此次的投入。蕊清楚高德司是做古董生意，在签合同前她对这家公司做了仔细的调研。认为其还算是一家合法正当的盈利机构，并没有收购非法国家珍宝的勾当，更没有联合盗墓贼做见不得光的事。\n\n&emsp;&emsp;“好了，时间不早了，我也不打搅你科研了，大科学家。” \n\n&emsp;&emsp;“我才不是什么大科学家呢。。。算了不和你说了，改天吃践行饭再细说。好了，晚安。。。”\n\n&emsp;&emsp;蕊挂了电话，忽然想起住在疗养院的母亲。母亲是孤儿院的老院长，在疗养院已经住了有十年。十年前操劳过度的母亲患上了帕金森综合症，也就是老年痴呆。以前的所有事情都不记得，连亲手带大的孩子也不记得。要是母亲没有生病就好了，她想，没有病的话说不一定还能记得我的可恶的生生父母是谁，还记得我的身世。不过母亲生病前她也问过，她并不知道她的身世，只知道一天她莫名其妙就出现在孤儿院门前，身上连纸条都没有。有时候蕊又忽然觉得自己好可笑。人为什么要知道自己的生生父母是谁？有一个爱自己的养母不是很好吗？有自己喜欢做的事情不是很好吗？尽管如此想着，心里的那一丝绳结仍然解不开。总有一节疙瘩化不开，像是血液里的一块坚硬的血栓，总是时不时的碰撞她的柔软的心脏瓣膜。\n\n&emsp;&emsp;她翻看着《失落的印加文明》，书的扉页已被她翻得发黄，可仍然找不到她想要的答案。因为除了那块石头的秘密，她还有许多的疑问：玛雅文明、阿兹特科帝国、印加帝国曾经如此辉煌为何轻易被蛮夷的西班牙人摧毁？印加帝国的国徽为什么看起来似曾相似？为什么三个文明都隐藏于深山，放着广袤的平原不去利用？关于2012灭亡的预言是他们的历法的错误还是他给后代人的玩笑？好多好多的疑问等待她去揭示，像揭开美丽新娘的面纱。\n\n&emsp;&emsp;算了，她和上了书，心里即期待又兴奋，终于有机会亲自去揭露这些秘密了。\n\n","slug":"启程去玛雅","published":1,"updated":"2024-05-26T14:17:36.845Z","comments":1,"layout":"post","photos":[],"_id":"cmh498iox002twvoueryycrim","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>&emsp;&emsp;“你不是开玩笑吧蕊。。。哈哈哈。。。”电话那头尖叫起来：“真的替你感到高兴啊。。。”</p>\n<p>&emsp;&emsp;“谢谢你萱萱”，蕊高兴的说到，仿佛两只小熊一同分享着超甜的蜜。</p>\n<p>&emsp;&emsp;“找到财宝可不要忘了我啊。。。呵呵。。。”电话那头开始寒暄起来，玩笑的说到。</p>\n<p>&emsp;&emsp;“当然不会啦，话说，你说的财宝恐怕早已经被别人挖空了。。。哎。。。不管怎么样我一定要找到它的秘密。。。”</p>\n<p>&emsp;&emsp;“诶诶诶。。。别认真啊。。。我最怕你认真了。。。想当年念书那会儿你是整天泡在图书馆。要不是老娘当初看你有几分姿色是个可塑之材，把你从学海那个什么深渊旁边拉上来，还不知道你会变成怎么样的书呆子呢。你看看你今天，要风得风，要雨得雨。。。呃。。。尽管还是被学术给套牢了，那至少还是一个知性大龄剩女青年啊。。。”</p>\n<p>&emsp;&emsp;“喂喂喂。。。就你厉害，谁也胜不了你的乌鸦嘴行了吧。”</p>\n<p>&emsp;&emsp;“话说，你一走我就成孤家寡人了啊。。。这精神损失费你自个儿掂量掂量啊。。。”</p>\n<p>&emsp;&emsp;“嗯，知道，我也会想你的。。。”</p>\n<p>&emsp;&emsp;“你会想才怪呐。。。改明儿个见了个石头都当情人，你要是会记得我那石头都讲人话了。呵呵。。。”</p>\n<p>&emsp;&emsp;电话两头同时响起笑声，房间里的空气也欢乐的共振起来。蕊的眼睛凝神在博古架上的一块透明不规则水晶石上面。那块石头是校领导从美洲带回来的，据说是在蒂卡尔城的金字塔旁边捡的。这块不起眼的石头被其他来自各个地方的地质矿物石头所簇拥着。其他堆满博古架的颜色各异，形态各具的石头都是蕊随地质考察队在野外采集的标本。除了这一块，其他的任何一块石头蕊都知道来历，能道出是形成于哪个地质年代，还能知道每一块石头形成的环境，经历的世事。唯独那块水晶她不知道。不是不知道它的组成——无非是一堆二氧化硅晶体；也不是不明白它的生长条件—–要有足够的压力和温度，最重要的是硅酸盐富集液。令她不安的是她不知道这块水晶长在哪块晶洞，被来自哪里的营养液滋养。也就是说她不知道这块水晶的家在哪里，不知道这块水晶的“父母”是谁，就像她自己一样。在她看来每块石头都是鲜活的生命，都能够和她对话。其他蕊亲手收集的标本石头都是开朗活泼的，而这一块从来到她的这个小公寓里尽管与满屋的书香，满屋的石气书香气混在一起，但是从来都显得格格不入，因为与其他石头不同伴随着它的是孤独和无助。看到这块水晶就像蕊看着天真无助的自己。尽管所有其他石头都是她亲手挖掘、把玩、测量，像极了自己的孩子，然而这一块却像极了自己。对于孩子她可以献出所有，然而对于自己她却无所适从。</p>\n<p>&emsp;&emsp;“对了，你哪天的飞机啊？”电话中的询问把蕊拉回现实。气氛变得严肃了一秒钟。</p>\n<p>&emsp;&emsp;“哦，具体时间我还不清楚，公司那边安排的专机，到时候会通知我的。” </p>\n<p>&emsp;&emsp;“专机啊，小妮子还真气派啊。。。能不能捎上我啊？小女子给您烧火做饭暖床，如何啊？”</p>\n<p>&emsp;&emsp;“我倒是想啊，不过这次经费全是高德公司提供，所以一切都得听他们安排。仪器、资料、行李什么的据说都不用带，带上我的人就够了。”</p>\n<p>&emsp;&emsp;“听起来怎么那么像包养啊？我仿佛看到了李美美啊。。。”</p>\n<p>&emsp;&emsp;“狗嘴里果然是吐不出象牙来。。。”</p>\n<p>&emsp;&emsp;呵呵呵。房间里又是一通笑声。两人许久未长聊，如今相谈甚欢。萱萱的存在能够些许的慰藉她的孤独的心。</p>\n<p>&emsp;&emsp;“人家为什么要给你经费啊？哦，我明白了，不是仰慕你的文材学问就是为了劫色。哈哈哈。。。”</p>\n<p>&emsp;&emsp;“都是我争取来的啊。。。是我的梦想。。。他们看了我的关于玛雅文明的研究论文，觉得很出色。。。”其实在蕊的心里，她更觉得这是她的宿命。</p>\n<p>&emsp;&emsp;“得得得，又来劲了不是。”</p>\n<p>&emsp;&emsp;高德司这家跨国企业为了加强与南美州国家经贸关系才有此次的投入。蕊清楚高德司是做古董生意，在签合同前她对这家公司做了仔细的调研。认为其还算是一家合法正当的盈利机构，并没有收购非法国家珍宝的勾当，更没有联合盗墓贼做见不得光的事。</p>\n<p>&emsp;&emsp;“好了，时间不早了，我也不打搅你科研了，大科学家。” </p>\n<p>&emsp;&emsp;“我才不是什么大科学家呢。。。算了不和你说了，改天吃践行饭再细说。好了，晚安。。。”</p>\n<p>&emsp;&emsp;蕊挂了电话，忽然想起住在疗养院的母亲。母亲是孤儿院的老院长，在疗养院已经住了有十年。十年前操劳过度的母亲患上了帕金森综合症，也就是老年痴呆。以前的所有事情都不记得，连亲手带大的孩子也不记得。要是母亲没有生病就好了，她想，没有病的话说不一定还能记得我的可恶的生生父母是谁，还记得我的身世。不过母亲生病前她也问过，她并不知道她的身世，只知道一天她莫名其妙就出现在孤儿院门前，身上连纸条都没有。有时候蕊又忽然觉得自己好可笑。人为什么要知道自己的生生父母是谁？有一个爱自己的养母不是很好吗？有自己喜欢做的事情不是很好吗？尽管如此想着，心里的那一丝绳结仍然解不开。总有一节疙瘩化不开，像是血液里的一块坚硬的血栓，总是时不时的碰撞她的柔软的心脏瓣膜。</p>\n<p>&emsp;&emsp;她翻看着《失落的印加文明》，书的扉页已被她翻得发黄，可仍然找不到她想要的答案。因为除了那块石头的秘密，她还有许多的疑问：玛雅文明、阿兹特科帝国、印加帝国曾经如此辉煌为何轻易被蛮夷的西班牙人摧毁？印加帝国的国徽为什么看起来似曾相似？为什么三个文明都隐藏于深山，放着广袤的平原不去利用？关于2012灭亡的预言是他们的历法的错误还是他给后代人的玩笑？好多好多的疑问等待她去揭示，像揭开美丽新娘的面纱。</p>\n<p>&emsp;&emsp;算了，她和上了书，心里即期待又兴奋，终于有机会亲自去揭露这些秘密了。</p>\n","related_posts":[],"length":2426,"excerpt":"","more":"<p>&emsp;&emsp;“你不是开玩笑吧蕊。。。哈哈哈。。。”电话那头尖叫起来：“真的替你感到高兴啊。。。”</p>\n<p>&emsp;&emsp;“谢谢你萱萱”，蕊高兴的说到，仿佛两只小熊一同分享着超甜的蜜。</p>\n<p>&emsp;&emsp;“找到财宝可不要忘了我啊。。。呵呵。。。”电话那头开始寒暄起来，玩笑的说到。</p>\n<p>&emsp;&emsp;“当然不会啦，话说，你说的财宝恐怕早已经被别人挖空了。。。哎。。。不管怎么样我一定要找到它的秘密。。。”</p>\n<p>&emsp;&emsp;“诶诶诶。。。别认真啊。。。我最怕你认真了。。。想当年念书那会儿你是整天泡在图书馆。要不是老娘当初看你有几分姿色是个可塑之材，把你从学海那个什么深渊旁边拉上来，还不知道你会变成怎么样的书呆子呢。你看看你今天，要风得风，要雨得雨。。。呃。。。尽管还是被学术给套牢了，那至少还是一个知性大龄剩女青年啊。。。”</p>\n<p>&emsp;&emsp;“喂喂喂。。。就你厉害，谁也胜不了你的乌鸦嘴行了吧。”</p>\n<p>&emsp;&emsp;“话说，你一走我就成孤家寡人了啊。。。这精神损失费你自个儿掂量掂量啊。。。”</p>\n<p>&emsp;&emsp;“嗯，知道，我也会想你的。。。”</p>\n<p>&emsp;&emsp;“你会想才怪呐。。。改明儿个见了个石头都当情人，你要是会记得我那石头都讲人话了。呵呵。。。”</p>\n<p>&emsp;&emsp;电话两头同时响起笑声，房间里的空气也欢乐的共振起来。蕊的眼睛凝神在博古架上的一块透明不规则水晶石上面。那块石头是校领导从美洲带回来的，据说是在蒂卡尔城的金字塔旁边捡的。这块不起眼的石头被其他来自各个地方的地质矿物石头所簇拥着。其他堆满博古架的颜色各异，形态各具的石头都是蕊随地质考察队在野外采集的标本。除了这一块，其他的任何一块石头蕊都知道来历，能道出是形成于哪个地质年代，还能知道每一块石头形成的环境，经历的世事。唯独那块水晶她不知道。不是不知道它的组成——无非是一堆二氧化硅晶体；也不是不明白它的生长条件—–要有足够的压力和温度，最重要的是硅酸盐富集液。令她不安的是她不知道这块水晶长在哪块晶洞，被来自哪里的营养液滋养。也就是说她不知道这块水晶的家在哪里，不知道这块水晶的“父母”是谁，就像她自己一样。在她看来每块石头都是鲜活的生命，都能够和她对话。其他蕊亲手收集的标本石头都是开朗活泼的，而这一块从来到她的这个小公寓里尽管与满屋的书香，满屋的石气书香气混在一起，但是从来都显得格格不入，因为与其他石头不同伴随着它的是孤独和无助。看到这块水晶就像蕊看着天真无助的自己。尽管所有其他石头都是她亲手挖掘、把玩、测量，像极了自己的孩子，然而这一块却像极了自己。对于孩子她可以献出所有，然而对于自己她却无所适从。</p>\n<p>&emsp;&emsp;“对了，你哪天的飞机啊？”电话中的询问把蕊拉回现实。气氛变得严肃了一秒钟。</p>\n<p>&emsp;&emsp;“哦，具体时间我还不清楚，公司那边安排的专机，到时候会通知我的。” </p>\n<p>&emsp;&emsp;“专机啊，小妮子还真气派啊。。。能不能捎上我啊？小女子给您烧火做饭暖床，如何啊？”</p>\n<p>&emsp;&emsp;“我倒是想啊，不过这次经费全是高德公司提供，所以一切都得听他们安排。仪器、资料、行李什么的据说都不用带，带上我的人就够了。”</p>\n<p>&emsp;&emsp;“听起来怎么那么像包养啊？我仿佛看到了李美美啊。。。”</p>\n<p>&emsp;&emsp;“狗嘴里果然是吐不出象牙来。。。”</p>\n<p>&emsp;&emsp;呵呵呵。房间里又是一通笑声。两人许久未长聊，如今相谈甚欢。萱萱的存在能够些许的慰藉她的孤独的心。</p>\n<p>&emsp;&emsp;“人家为什么要给你经费啊？哦，我明白了，不是仰慕你的文材学问就是为了劫色。哈哈哈。。。”</p>\n<p>&emsp;&emsp;“都是我争取来的啊。。。是我的梦想。。。他们看了我的关于玛雅文明的研究论文，觉得很出色。。。”其实在蕊的心里，她更觉得这是她的宿命。</p>\n<p>&emsp;&emsp;“得得得，又来劲了不是。”</p>\n<p>&emsp;&emsp;高德司这家跨国企业为了加强与南美州国家经贸关系才有此次的投入。蕊清楚高德司是做古董生意，在签合同前她对这家公司做了仔细的调研。认为其还算是一家合法正当的盈利机构，并没有收购非法国家珍宝的勾当，更没有联合盗墓贼做见不得光的事。</p>\n<p>&emsp;&emsp;“好了，时间不早了，我也不打搅你科研了，大科学家。” </p>\n<p>&emsp;&emsp;“我才不是什么大科学家呢。。。算了不和你说了，改天吃践行饭再细说。好了，晚安。。。”</p>\n<p>&emsp;&emsp;蕊挂了电话，忽然想起住在疗养院的母亲。母亲是孤儿院的老院长，在疗养院已经住了有十年。十年前操劳过度的母亲患上了帕金森综合症，也就是老年痴呆。以前的所有事情都不记得，连亲手带大的孩子也不记得。要是母亲没有生病就好了，她想，没有病的话说不一定还能记得我的可恶的生生父母是谁，还记得我的身世。不过母亲生病前她也问过，她并不知道她的身世，只知道一天她莫名其妙就出现在孤儿院门前，身上连纸条都没有。有时候蕊又忽然觉得自己好可笑。人为什么要知道自己的生生父母是谁？有一个爱自己的养母不是很好吗？有自己喜欢做的事情不是很好吗？尽管如此想着，心里的那一丝绳结仍然解不开。总有一节疙瘩化不开，像是血液里的一块坚硬的血栓，总是时不时的碰撞她的柔软的心脏瓣膜。</p>\n<p>&emsp;&emsp;她翻看着《失落的印加文明》，书的扉页已被她翻得发黄，可仍然找不到她想要的答案。因为除了那块石头的秘密，她还有许多的疑问：玛雅文明、阿兹特科帝国、印加帝国曾经如此辉煌为何轻易被蛮夷的西班牙人摧毁？印加帝国的国徽为什么看起来似曾相似？为什么三个文明都隐藏于深山，放着广袤的平原不去利用？关于2012灭亡的预言是他们的历法的错误还是他给后代人的玩笑？好多好多的疑问等待她去揭示，像揭开美丽新娘的面纱。</p>\n<p>&emsp;&emsp;算了，她和上了书，心里即期待又兴奋，终于有机会亲自去揭露这些秘密了。</p>\n"},{"title":"血色乎浪漫","abbrlink":53953,"date":"2015-11-01T00:17:27.000Z","_content":"\n&emsp;&emsp;人活着该削平自己将自己融入社会大染缸，还是该看清事实从中跳出来，或者该坚持自我暴力抵抗，还是怀揣着希望守护自己的安全岛？\n\n&emsp;&emsp;《血色浪漫》里面所演绎的人生几乎统统都是悲剧。剧中毫不夸张甚至说是完全真实的展示了几乎社会所有阶层人的艰苦历程（不管是心灵的还是肉身的。），尽管我们不敢说自己能完全体会到其他阶层人的艰辛和苦难，也不能全体会他们的心情。不过作为一个观影的旁观者，作为一个血色的参与者，我们能感受到的是那种骨子里的无奈。“阶层”，这个词说起来如此顺口，但听起来却如此刺耳。这是出生在中国大地的人们一出生就有的东西，烙在骨头上，烂在骨髓里头的东西。“阶层”演化和包装下成为如今的“拼爹”。李奎勇说的那个时代自己能干的大概和自己的爹干的差不多。大概就是这个意思吧。我已经不想去讨论这个社会变态到什么样子（又或者变态的只是我）。\n\n&emsp;&emsp;主人公钟跃民有个“好爹”所以遇事都有权贵相扶。但他终究没有超人的能力能够与这个变态的恶魔抗争。然而这些变态的特质与他的自由的人生价值观（这是他的么？不是每个人都有的么？）相背离。他选择的路是不屈服，但却无作为。这个恶魔无处不在，只要与人打交道，他就来骚扰你，甚至吃了你。在现实生活中，钟跃民无处遁形，他只能逃避。逃到隔壁沙漠，人越少越好。然后最好还有一批被这个社会排斥并且定义为罪无可恕的恶徒可以作为他发泄情绪的消遣对象。他无法让自己屈服于怪兽的淫威，甚至连与怪兽有关的人都成为他惧怕的对象，所以他几乎不可能“接受”任何人（朋友除外哦）。\n\n&emsp;&emsp;宁伟是个危险分子， 我们每个人身上大概都有像宁伟性格这样的不安分情绪。面对变态社会的侵蚀，他的作为是奋力的充满暴力的反抗斗争。就像被变态的父母养大的孩子孕育出的暴戾性格。只要给它合适的契机他就会破壳而出，势不可挡的占据你的全部。不过剧末告诉我们一个残酷的事实：不管你有多暴力，那个变态的恶魔终究会把你像蚂蚁一样捏得粉碎，连骨灰都不剩下。\n\n&emsp;&emsp;大多数出现在剧中的人无非都是平凡的小市民，农民，工人。面对猛兽，他们并没有十足的精神洁癖，没有表现出臣服并且屈居人下的怨念。又或者因为他们的精神领地被恶魔消磨殆尽。他们有的只是一副孱弱的驱壳，经受着怪物实施的各种残酷的刑罚，按部就班的服刑着妖魔的窑役。\n\n&emsp;&emsp;这个妖魔势力过于强大，我们都不能逃脱，更没有力量去战胜。然而于众人的道路中，我们愿选择怀揣希望的活法。就像郑桐与蒋碧云。不管这个希望是自欺欺人还是一片渺茫，尽管在削平了自己成为恶魔的狗腿子的人的眼里他们是傻的可爱，蠢的可怜。但只要有固执的希望扎根，他们过的尽快清苦，但却乐在其中。 \n\n&emsp;&emsp;有一种情是慰藉，是救命稻草，那就是友情。钟跃民什么都想抛弃，唯独友情伴随其左右。可能如果周晓白不牵挂，李奎勇不出现，宁伟不出事，高钥不守候，钟可能会提早出家修行。不，也许是因为李奎勇去世，宁伟赴黄泉才促使钟对社会丧失了希望。友谊无价那是因为没有负担。又或者双方彼此都是被欺压的奴隶，一起生活就像出生入死的战友。然而这种好的战友，好的精神慰藉是可遇而不可求的。\n\n&emsp;&emsp;生活并不可怕，有了恶魔才慎人。恶魔在世为生活涂上了血色。怀揣着希望于血色中找寻浪漫。\n\n","source":"_posts/2015-11-01-血色乎浪漫.md","raw":"---\ntitle: 血色乎浪漫\ncategories:\n  - 某日记\ntags:\n  - 电视剧\nabbrlink: 53953\ndate: 2015-11-01 08:17:27\n---\n\n&emsp;&emsp;人活着该削平自己将自己融入社会大染缸，还是该看清事实从中跳出来，或者该坚持自我暴力抵抗，还是怀揣着希望守护自己的安全岛？\n\n&emsp;&emsp;《血色浪漫》里面所演绎的人生几乎统统都是悲剧。剧中毫不夸张甚至说是完全真实的展示了几乎社会所有阶层人的艰苦历程（不管是心灵的还是肉身的。），尽管我们不敢说自己能完全体会到其他阶层人的艰辛和苦难，也不能全体会他们的心情。不过作为一个观影的旁观者，作为一个血色的参与者，我们能感受到的是那种骨子里的无奈。“阶层”，这个词说起来如此顺口，但听起来却如此刺耳。这是出生在中国大地的人们一出生就有的东西，烙在骨头上，烂在骨髓里头的东西。“阶层”演化和包装下成为如今的“拼爹”。李奎勇说的那个时代自己能干的大概和自己的爹干的差不多。大概就是这个意思吧。我已经不想去讨论这个社会变态到什么样子（又或者变态的只是我）。\n\n&emsp;&emsp;主人公钟跃民有个“好爹”所以遇事都有权贵相扶。但他终究没有超人的能力能够与这个变态的恶魔抗争。然而这些变态的特质与他的自由的人生价值观（这是他的么？不是每个人都有的么？）相背离。他选择的路是不屈服，但却无作为。这个恶魔无处不在，只要与人打交道，他就来骚扰你，甚至吃了你。在现实生活中，钟跃民无处遁形，他只能逃避。逃到隔壁沙漠，人越少越好。然后最好还有一批被这个社会排斥并且定义为罪无可恕的恶徒可以作为他发泄情绪的消遣对象。他无法让自己屈服于怪兽的淫威，甚至连与怪兽有关的人都成为他惧怕的对象，所以他几乎不可能“接受”任何人（朋友除外哦）。\n\n&emsp;&emsp;宁伟是个危险分子， 我们每个人身上大概都有像宁伟性格这样的不安分情绪。面对变态社会的侵蚀，他的作为是奋力的充满暴力的反抗斗争。就像被变态的父母养大的孩子孕育出的暴戾性格。只要给它合适的契机他就会破壳而出，势不可挡的占据你的全部。不过剧末告诉我们一个残酷的事实：不管你有多暴力，那个变态的恶魔终究会把你像蚂蚁一样捏得粉碎，连骨灰都不剩下。\n\n&emsp;&emsp;大多数出现在剧中的人无非都是平凡的小市民，农民，工人。面对猛兽，他们并没有十足的精神洁癖，没有表现出臣服并且屈居人下的怨念。又或者因为他们的精神领地被恶魔消磨殆尽。他们有的只是一副孱弱的驱壳，经受着怪物实施的各种残酷的刑罚，按部就班的服刑着妖魔的窑役。\n\n&emsp;&emsp;这个妖魔势力过于强大，我们都不能逃脱，更没有力量去战胜。然而于众人的道路中，我们愿选择怀揣希望的活法。就像郑桐与蒋碧云。不管这个希望是自欺欺人还是一片渺茫，尽管在削平了自己成为恶魔的狗腿子的人的眼里他们是傻的可爱，蠢的可怜。但只要有固执的希望扎根，他们过的尽快清苦，但却乐在其中。 \n\n&emsp;&emsp;有一种情是慰藉，是救命稻草，那就是友情。钟跃民什么都想抛弃，唯独友情伴随其左右。可能如果周晓白不牵挂，李奎勇不出现，宁伟不出事，高钥不守候，钟可能会提早出家修行。不，也许是因为李奎勇去世，宁伟赴黄泉才促使钟对社会丧失了希望。友谊无价那是因为没有负担。又或者双方彼此都是被欺压的奴隶，一起生活就像出生入死的战友。然而这种好的战友，好的精神慰藉是可遇而不可求的。\n\n&emsp;&emsp;生活并不可怕，有了恶魔才慎人。恶魔在世为生活涂上了血色。怀揣着希望于血色中找寻浪漫。\n\n","slug":"血色乎浪漫","published":1,"updated":"2024-05-26T14:17:36.845Z","comments":1,"layout":"post","photos":[],"_id":"cmh498ioy002wwvou4yvyavgn","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>&emsp;&emsp;人活着该削平自己将自己融入社会大染缸，还是该看清事实从中跳出来，或者该坚持自我暴力抵抗，还是怀揣着希望守护自己的安全岛？</p>\n<p>&emsp;&emsp;《血色浪漫》里面所演绎的人生几乎统统都是悲剧。剧中毫不夸张甚至说是完全真实的展示了几乎社会所有阶层人的艰苦历程（不管是心灵的还是肉身的。），尽管我们不敢说自己能完全体会到其他阶层人的艰辛和苦难，也不能全体会他们的心情。不过作为一个观影的旁观者，作为一个血色的参与者，我们能感受到的是那种骨子里的无奈。“阶层”，这个词说起来如此顺口，但听起来却如此刺耳。这是出生在中国大地的人们一出生就有的东西，烙在骨头上，烂在骨髓里头的东西。“阶层”演化和包装下成为如今的“拼爹”。李奎勇说的那个时代自己能干的大概和自己的爹干的差不多。大概就是这个意思吧。我已经不想去讨论这个社会变态到什么样子（又或者变态的只是我）。</p>\n<p>&emsp;&emsp;主人公钟跃民有个“好爹”所以遇事都有权贵相扶。但他终究没有超人的能力能够与这个变态的恶魔抗争。然而这些变态的特质与他的自由的人生价值观（这是他的么？不是每个人都有的么？）相背离。他选择的路是不屈服，但却无作为。这个恶魔无处不在，只要与人打交道，他就来骚扰你，甚至吃了你。在现实生活中，钟跃民无处遁形，他只能逃避。逃到隔壁沙漠，人越少越好。然后最好还有一批被这个社会排斥并且定义为罪无可恕的恶徒可以作为他发泄情绪的消遣对象。他无法让自己屈服于怪兽的淫威，甚至连与怪兽有关的人都成为他惧怕的对象，所以他几乎不可能“接受”任何人（朋友除外哦）。</p>\n<p>&emsp;&emsp;宁伟是个危险分子， 我们每个人身上大概都有像宁伟性格这样的不安分情绪。面对变态社会的侵蚀，他的作为是奋力的充满暴力的反抗斗争。就像被变态的父母养大的孩子孕育出的暴戾性格。只要给它合适的契机他就会破壳而出，势不可挡的占据你的全部。不过剧末告诉我们一个残酷的事实：不管你有多暴力，那个变态的恶魔终究会把你像蚂蚁一样捏得粉碎，连骨灰都不剩下。</p>\n<p>&emsp;&emsp;大多数出现在剧中的人无非都是平凡的小市民，农民，工人。面对猛兽，他们并没有十足的精神洁癖，没有表现出臣服并且屈居人下的怨念。又或者因为他们的精神领地被恶魔消磨殆尽。他们有的只是一副孱弱的驱壳，经受着怪物实施的各种残酷的刑罚，按部就班的服刑着妖魔的窑役。</p>\n<p>&emsp;&emsp;这个妖魔势力过于强大，我们都不能逃脱，更没有力量去战胜。然而于众人的道路中，我们愿选择怀揣希望的活法。就像郑桐与蒋碧云。不管这个希望是自欺欺人还是一片渺茫，尽管在削平了自己成为恶魔的狗腿子的人的眼里他们是傻的可爱，蠢的可怜。但只要有固执的希望扎根，他们过的尽快清苦，但却乐在其中。 </p>\n<p>&emsp;&emsp;有一种情是慰藉，是救命稻草，那就是友情。钟跃民什么都想抛弃，唯独友情伴随其左右。可能如果周晓白不牵挂，李奎勇不出现，宁伟不出事，高钥不守候，钟可能会提早出家修行。不，也许是因为李奎勇去世，宁伟赴黄泉才促使钟对社会丧失了希望。友谊无价那是因为没有负担。又或者双方彼此都是被欺压的奴隶，一起生活就像出生入死的战友。然而这种好的战友，好的精神慰藉是可遇而不可求的。</p>\n<p>&emsp;&emsp;生活并不可怕，有了恶魔才慎人。恶魔在世为生活涂上了血色。怀揣着希望于血色中找寻浪漫。</p>\n","related_posts":[],"length":1380,"excerpt":"","more":"<p>&emsp;&emsp;人活着该削平自己将自己融入社会大染缸，还是该看清事实从中跳出来，或者该坚持自我暴力抵抗，还是怀揣着希望守护自己的安全岛？</p>\n<p>&emsp;&emsp;《血色浪漫》里面所演绎的人生几乎统统都是悲剧。剧中毫不夸张甚至说是完全真实的展示了几乎社会所有阶层人的艰苦历程（不管是心灵的还是肉身的。），尽管我们不敢说自己能完全体会到其他阶层人的艰辛和苦难，也不能全体会他们的心情。不过作为一个观影的旁观者，作为一个血色的参与者，我们能感受到的是那种骨子里的无奈。“阶层”，这个词说起来如此顺口，但听起来却如此刺耳。这是出生在中国大地的人们一出生就有的东西，烙在骨头上，烂在骨髓里头的东西。“阶层”演化和包装下成为如今的“拼爹”。李奎勇说的那个时代自己能干的大概和自己的爹干的差不多。大概就是这个意思吧。我已经不想去讨论这个社会变态到什么样子（又或者变态的只是我）。</p>\n<p>&emsp;&emsp;主人公钟跃民有个“好爹”所以遇事都有权贵相扶。但他终究没有超人的能力能够与这个变态的恶魔抗争。然而这些变态的特质与他的自由的人生价值观（这是他的么？不是每个人都有的么？）相背离。他选择的路是不屈服，但却无作为。这个恶魔无处不在，只要与人打交道，他就来骚扰你，甚至吃了你。在现实生活中，钟跃民无处遁形，他只能逃避。逃到隔壁沙漠，人越少越好。然后最好还有一批被这个社会排斥并且定义为罪无可恕的恶徒可以作为他发泄情绪的消遣对象。他无法让自己屈服于怪兽的淫威，甚至连与怪兽有关的人都成为他惧怕的对象，所以他几乎不可能“接受”任何人（朋友除外哦）。</p>\n<p>&emsp;&emsp;宁伟是个危险分子， 我们每个人身上大概都有像宁伟性格这样的不安分情绪。面对变态社会的侵蚀，他的作为是奋力的充满暴力的反抗斗争。就像被变态的父母养大的孩子孕育出的暴戾性格。只要给它合适的契机他就会破壳而出，势不可挡的占据你的全部。不过剧末告诉我们一个残酷的事实：不管你有多暴力，那个变态的恶魔终究会把你像蚂蚁一样捏得粉碎，连骨灰都不剩下。</p>\n<p>&emsp;&emsp;大多数出现在剧中的人无非都是平凡的小市民，农民，工人。面对猛兽，他们并没有十足的精神洁癖，没有表现出臣服并且屈居人下的怨念。又或者因为他们的精神领地被恶魔消磨殆尽。他们有的只是一副孱弱的驱壳，经受着怪物实施的各种残酷的刑罚，按部就班的服刑着妖魔的窑役。</p>\n<p>&emsp;&emsp;这个妖魔势力过于强大，我们都不能逃脱，更没有力量去战胜。然而于众人的道路中，我们愿选择怀揣希望的活法。就像郑桐与蒋碧云。不管这个希望是自欺欺人还是一片渺茫，尽管在削平了自己成为恶魔的狗腿子的人的眼里他们是傻的可爱，蠢的可怜。但只要有固执的希望扎根，他们过的尽快清苦，但却乐在其中。 </p>\n<p>&emsp;&emsp;有一种情是慰藉，是救命稻草，那就是友情。钟跃民什么都想抛弃，唯独友情伴随其左右。可能如果周晓白不牵挂，李奎勇不出现，宁伟不出事，高钥不守候，钟可能会提早出家修行。不，也许是因为李奎勇去世，宁伟赴黄泉才促使钟对社会丧失了希望。友谊无价那是因为没有负担。又或者双方彼此都是被欺压的奴隶，一起生活就像出生入死的战友。然而这种好的战友，好的精神慰藉是可遇而不可求的。</p>\n<p>&emsp;&emsp;生活并不可怕，有了恶魔才慎人。恶魔在世为生活涂上了血色。怀揣着希望于血色中找寻浪漫。</p>\n"},{"title":"跟伴","abbrlink":42749,"date":"2015-11-01T00:20:59.000Z","_content":"\n&emsp;&emsp;这是一种路上游荡的魂魄。\n\n&emsp;&emsp;因为生前性格孤僻十分孤单，没有一个朋友，所以容易走极端。遇到人生的重大挫折没有地方需求帮助，没有人来帮忙分担，最后在绝望中选择各种手段结束自己的生命。\n\n&emsp;&emsp;死后由于怨气未散，所以不愿到阴曹，傍晚十分喜欢在偏僻小路上飘荡。\n\n&emsp;&emsp;最喜欢跟踪单独一个人行走的路人。通常能感知孤独，可化作路人的熟人面目，但又让路人无法辨认出是哪个人。路人若是回头发现，并且警觉，快速行走。。。\n\n&emsp;&emsp;当路人以为自己已经甩开跟踪者，回头看时。。。什么也看不见。。。。。。因为跟伴紧贴着路人的后背。。。。。。他露出诡异的笑。。。准备把你拉到阴间。。。作伴。。。\n\n","source":"_posts/2015-11-01-跟伴.md","raw":"---\ntitle: 跟伴\ncategories:\n  - 乱笔\ntags:\n  - 妖怪\nabbrlink: 42749\ndate: 2015-11-01 08:20:59\n---\n\n&emsp;&emsp;这是一种路上游荡的魂魄。\n\n&emsp;&emsp;因为生前性格孤僻十分孤单，没有一个朋友，所以容易走极端。遇到人生的重大挫折没有地方需求帮助，没有人来帮忙分担，最后在绝望中选择各种手段结束自己的生命。\n\n&emsp;&emsp;死后由于怨气未散，所以不愿到阴曹，傍晚十分喜欢在偏僻小路上飘荡。\n\n&emsp;&emsp;最喜欢跟踪单独一个人行走的路人。通常能感知孤独，可化作路人的熟人面目，但又让路人无法辨认出是哪个人。路人若是回头发现，并且警觉，快速行走。。。\n\n&emsp;&emsp;当路人以为自己已经甩开跟踪者，回头看时。。。什么也看不见。。。。。。因为跟伴紧贴着路人的后背。。。。。。他露出诡异的笑。。。准备把你拉到阴间。。。作伴。。。\n\n","slug":"跟伴","published":1,"updated":"2024-05-26T14:17:36.845Z","comments":1,"layout":"post","photos":[],"_id":"cmh498ioy0030wvou6ogid0sc","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>&emsp;&emsp;这是一种路上游荡的魂魄。</p>\n<p>&emsp;&emsp;因为生前性格孤僻十分孤单，没有一个朋友，所以容易走极端。遇到人生的重大挫折没有地方需求帮助，没有人来帮忙分担，最后在绝望中选择各种手段结束自己的生命。</p>\n<p>&emsp;&emsp;死后由于怨气未散，所以不愿到阴曹，傍晚十分喜欢在偏僻小路上飘荡。</p>\n<p>&emsp;&emsp;最喜欢跟踪单独一个人行走的路人。通常能感知孤独，可化作路人的熟人面目，但又让路人无法辨认出是哪个人。路人若是回头发现，并且警觉，快速行走。。。</p>\n<p>&emsp;&emsp;当路人以为自己已经甩开跟踪者，回头看时。。。什么也看不见。。。。。。因为跟伴紧贴着路人的后背。。。。。。他露出诡异的笑。。。准备把你拉到阴间。。。作伴。。。</p>\n","related_posts":[],"length":328,"excerpt":"","more":"<p>&emsp;&emsp;这是一种路上游荡的魂魄。</p>\n<p>&emsp;&emsp;因为生前性格孤僻十分孤单，没有一个朋友，所以容易走极端。遇到人生的重大挫折没有地方需求帮助，没有人来帮忙分担，最后在绝望中选择各种手段结束自己的生命。</p>\n<p>&emsp;&emsp;死后由于怨气未散，所以不愿到阴曹，傍晚十分喜欢在偏僻小路上飘荡。</p>\n<p>&emsp;&emsp;最喜欢跟踪单独一个人行走的路人。通常能感知孤独，可化作路人的熟人面目，但又让路人无法辨认出是哪个人。路人若是回头发现，并且警觉，快速行走。。。</p>\n<p>&emsp;&emsp;当路人以为自己已经甩开跟踪者，回头看时。。。什么也看不见。。。。。。因为跟伴紧贴着路人的后背。。。。。。他露出诡异的笑。。。准备把你拉到阴间。。。作伴。。。</p>\n"},{"title":"这个网站是怎么来的","abbrlink":25921,"date":"2020-05-25T17:21:16.000Z","_content":"目的：心血来潮，漫无目的。\n方法：利用Hexo+Github构建。\n花费：1块钱用于腾讯云买域名+6块用于阿里云买域名+宝宝睡了之后的晚上。\n用途：好记性不如烂笔头。用手敲敲还可锻炼一下。\n时间：2020年5月26日晚。\n步骤：参见[这里](https://cloud.tencent.com/developer/article/1423783)，具体如下：\n<!-- more -->\n## 一、建立repo\n\n建一个和自己的github用户名一样的repo。\n\n## 二、安装必要的程序\n\n需要安装的程序有Git，node.js，hexo\n\n### 1，安装Git\n\n``` bash\n$ sudo apt install git\n```\n### 2，安装node.js\n\n``` bash\n$ sudo apt install nodejs \n```\n### 3，安装hexo&&初始化\n\n``` bash\n$ npm install -g hexo\n$ hexo init [dir] #当前目录或新建[dir]\n```\n## 三、设置\n\n### 1，设置文件为_config.yml，自行修改例如\n\ntitle 博客名字\nsubtitle 副标题\nauthor 作者\n等等。遇到问题多看看[hexo的官方文档](https://hexo.io/zh-cn/docs)。\n### 2，主题配置\n\n想要自己的博客好看那就需要配置主题theme,我用的是Next。\n具体设置可以到google搜索关键字hexo+next。\n## 四、部署网站到github\n\n### 1，在_config.yml中添加\n\ndeploy:\n  type: git\n  repository: https://github.com/你的名字/你的名字.github.io.git\n  branch: master \n### 2，安装部署工具\n\n``` bash\n$ npm install hexo-deployer-git  --save\n```\n### 3，发布\n\n``` bash\n$ hexo cl && hexo g && hexo d\n```\n现在可以打开网址：你的名字.github.io访问。\n\n## 五、绑定域名\n### 1，购买域名\n\n### 2，域名解析\n\n找到域名解析选项添加两条记录:\nCNAME www 你的名字.github.io\nCNAME @ 你的名字.github.io\n### 3，添加CNAME文件\n\n在hexo文件夹的source目录中新建CNAME文件，将你的域名写入。然后就大功告成。\n完结撒花。\n\n","source":"_posts/2020-05-26-how-I-build-this-web.md","raw":"---\ntitle: 这个网站是怎么来的\ncategories: web\ntags:\n  - web\n  - next\nabbrlink: 25921\ndate: 2020-05-26 01:21:16\n---\n目的：心血来潮，漫无目的。\n方法：利用Hexo+Github构建。\n花费：1块钱用于腾讯云买域名+6块用于阿里云买域名+宝宝睡了之后的晚上。\n用途：好记性不如烂笔头。用手敲敲还可锻炼一下。\n时间：2020年5月26日晚。\n步骤：参见[这里](https://cloud.tencent.com/developer/article/1423783)，具体如下：\n<!-- more -->\n## 一、建立repo\n\n建一个和自己的github用户名一样的repo。\n\n## 二、安装必要的程序\n\n需要安装的程序有Git，node.js，hexo\n\n### 1，安装Git\n\n``` bash\n$ sudo apt install git\n```\n### 2，安装node.js\n\n``` bash\n$ sudo apt install nodejs \n```\n### 3，安装hexo&&初始化\n\n``` bash\n$ npm install -g hexo\n$ hexo init [dir] #当前目录或新建[dir]\n```\n## 三、设置\n\n### 1，设置文件为_config.yml，自行修改例如\n\ntitle 博客名字\nsubtitle 副标题\nauthor 作者\n等等。遇到问题多看看[hexo的官方文档](https://hexo.io/zh-cn/docs)。\n### 2，主题配置\n\n想要自己的博客好看那就需要配置主题theme,我用的是Next。\n具体设置可以到google搜索关键字hexo+next。\n## 四、部署网站到github\n\n### 1，在_config.yml中添加\n\ndeploy:\n  type: git\n  repository: https://github.com/你的名字/你的名字.github.io.git\n  branch: master \n### 2，安装部署工具\n\n``` bash\n$ npm install hexo-deployer-git  --save\n```\n### 3，发布\n\n``` bash\n$ hexo cl && hexo g && hexo d\n```\n现在可以打开网址：你的名字.github.io访问。\n\n## 五、绑定域名\n### 1，购买域名\n\n### 2，域名解析\n\n找到域名解析选项添加两条记录:\nCNAME www 你的名字.github.io\nCNAME @ 你的名字.github.io\n### 3，添加CNAME文件\n\n在hexo文件夹的source目录中新建CNAME文件，将你的域名写入。然后就大功告成。\n完结撒花。\n\n","slug":"how-I-build-this-web","published":1,"updated":"2024-05-26T14:17:36.845Z","comments":1,"layout":"post","photos":[],"_id":"cmh498ioz0033wvoufssygo7p","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>目的：心血来潮，漫无目的。<br>方法：利用Hexo+Github构建。<br>花费：1块钱用于腾讯云买域名+6块用于阿里云买域名+宝宝睡了之后的晚上。<br>用途：好记性不如烂笔头。用手敲敲还可锻炼一下。<br>时间：2020年5月26日晚。<br>步骤：参见<a href=\"https://cloud.tencent.com/developer/article/1423783\">这里</a>，具体如下：</p>\n<span id=\"more\"></span>\n<h2 id=\"一、建立repo\"><a href=\"#一、建立repo\" class=\"headerlink\" title=\"一、建立repo\"></a>一、建立repo</h2><p>建一个和自己的github用户名一样的repo。</p>\n<h2 id=\"二、安装必要的程序\"><a href=\"#二、安装必要的程序\" class=\"headerlink\" title=\"二、安装必要的程序\"></a>二、安装必要的程序</h2><p>需要安装的程序有Git，node.js，hexo</p>\n<h3 id=\"1，安装Git\"><a href=\"#1，安装Git\" class=\"headerlink\" title=\"1，安装Git\"></a>1，安装Git</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ <span class=\"built_in\">sudo</span> apt install git</span><br></pre></td></tr></table></figure>\n<h3 id=\"2，安装node-js\"><a href=\"#2，安装node-js\" class=\"headerlink\" title=\"2，安装node.js\"></a>2，安装node.js</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ <span class=\"built_in\">sudo</span> apt install nodejs </span><br></pre></td></tr></table></figure>\n<h3 id=\"3，安装hexo-初始化\"><a href=\"#3，安装hexo-初始化\" class=\"headerlink\" title=\"3，安装hexo&amp;&amp;初始化\"></a>3，安装hexo&amp;&amp;初始化</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ npm install -g hexo</span><br><span class=\"line\">$ hexo init [<span class=\"built_in\">dir</span>] <span class=\"comment\">#当前目录或新建[dir]</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"三、设置\"><a href=\"#三、设置\" class=\"headerlink\" title=\"三、设置\"></a>三、设置</h2><h3 id=\"1，设置文件为-config-yml，自行修改例如\"><a href=\"#1，设置文件为-config-yml，自行修改例如\" class=\"headerlink\" title=\"1，设置文件为_config.yml，自行修改例如\"></a>1，设置文件为_config.yml，自行修改例如</h3><p>title 博客名字<br>subtitle 副标题<br>author 作者<br>等等。遇到问题多看看<a href=\"https://hexo.io/zh-cn/docs\">hexo的官方文档</a>。</p>\n<h3 id=\"2，主题配置\"><a href=\"#2，主题配置\" class=\"headerlink\" title=\"2，主题配置\"></a>2，主题配置</h3><p>想要自己的博客好看那就需要配置主题theme,我用的是Next。<br>具体设置可以到google搜索关键字hexo+next。</p>\n<h2 id=\"四、部署网站到github\"><a href=\"#四、部署网站到github\" class=\"headerlink\" title=\"四、部署网站到github\"></a>四、部署网站到github</h2><h3 id=\"1，在-config-yml中添加\"><a href=\"#1，在-config-yml中添加\" class=\"headerlink\" title=\"1，在_config.yml中添加\"></a>1，在_config.yml中添加</h3><p>deploy:<br>  type: git<br>  repository: <a href=\"https://github.com/%E4%BD%A0%E7%9A%84%E5%90%8D%E5%AD%97/%E4%BD%A0%E7%9A%84%E5%90%8D%E5%AD%97.github.io.git\">https://github.com/你的名字/你的名字.github.io.git</a><br>  branch: master </p>\n<h3 id=\"2，安装部署工具\"><a href=\"#2，安装部署工具\" class=\"headerlink\" title=\"2，安装部署工具\"></a>2，安装部署工具</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ npm install hexo-deployer-git  --save</span><br></pre></td></tr></table></figure>\n<h3 id=\"3，发布\"><a href=\"#3，发布\" class=\"headerlink\" title=\"3，发布\"></a>3，发布</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo cl &amp;&amp; hexo g &amp;&amp; hexo d</span><br></pre></td></tr></table></figure>\n<p>现在可以打开网址：你的名字.github.io访问。</p>\n<h2 id=\"五、绑定域名\"><a href=\"#五、绑定域名\" class=\"headerlink\" title=\"五、绑定域名\"></a>五、绑定域名</h2><h3 id=\"1，购买域名\"><a href=\"#1，购买域名\" class=\"headerlink\" title=\"1，购买域名\"></a>1，购买域名</h3><h3 id=\"2，域名解析\"><a href=\"#2，域名解析\" class=\"headerlink\" title=\"2，域名解析\"></a>2，域名解析</h3><p>找到域名解析选项添加两条记录:<br>CNAME www 你的名字.github.io<br>CNAME @ 你的名字.github.io</p>\n<h3 id=\"3，添加CNAME文件\"><a href=\"#3，添加CNAME文件\" class=\"headerlink\" title=\"3，添加CNAME文件\"></a>3，添加CNAME文件</h3><p>在hexo文件夹的source目录中新建CNAME文件，将你的域名写入。然后就大功告成。<br>完结撒花。</p>\n","related_posts":["add_counter.html","how-to-encrypt.html","git-error.html","object-detection.html","passwd-free-for-deployment.html"],"length":810,"excerpt":"<p>目的：心血来潮，漫无目的。<br>方法：利用Hexo+Github构建。<br>花费：1块钱用于腾讯云买域名+6块用于阿里云买域名+宝宝睡了之后的晚上。<br>用途：好记性不如烂笔头。用手敲敲还可锻炼一下。<br>时间：2020年5月26日晚。<br>步骤：参见<a href=\"https://cloud.tencent.com/developer/article/1423783\">这里</a>，具体如下：</p>","more":"<h2 id=\"一、建立repo\"><a href=\"#一、建立repo\" class=\"headerlink\" title=\"一、建立repo\"></a>一、建立repo</h2><p>建一个和自己的github用户名一样的repo。</p>\n<h2 id=\"二、安装必要的程序\"><a href=\"#二、安装必要的程序\" class=\"headerlink\" title=\"二、安装必要的程序\"></a>二、安装必要的程序</h2><p>需要安装的程序有Git，node.js，hexo</p>\n<h3 id=\"1，安装Git\"><a href=\"#1，安装Git\" class=\"headerlink\" title=\"1，安装Git\"></a>1，安装Git</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ <span class=\"built_in\">sudo</span> apt install git</span><br></pre></td></tr></table></figure>\n<h3 id=\"2，安装node-js\"><a href=\"#2，安装node-js\" class=\"headerlink\" title=\"2，安装node.js\"></a>2，安装node.js</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ <span class=\"built_in\">sudo</span> apt install nodejs </span><br></pre></td></tr></table></figure>\n<h3 id=\"3，安装hexo-初始化\"><a href=\"#3，安装hexo-初始化\" class=\"headerlink\" title=\"3，安装hexo&amp;&amp;初始化\"></a>3，安装hexo&amp;&amp;初始化</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ npm install -g hexo</span><br><span class=\"line\">$ hexo init [<span class=\"built_in\">dir</span>] <span class=\"comment\">#当前目录或新建[dir]</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"三、设置\"><a href=\"#三、设置\" class=\"headerlink\" title=\"三、设置\"></a>三、设置</h2><h3 id=\"1，设置文件为-config-yml，自行修改例如\"><a href=\"#1，设置文件为-config-yml，自行修改例如\" class=\"headerlink\" title=\"1，设置文件为_config.yml，自行修改例如\"></a>1，设置文件为_config.yml，自行修改例如</h3><p>title 博客名字<br>subtitle 副标题<br>author 作者<br>等等。遇到问题多看看<a href=\"https://hexo.io/zh-cn/docs\">hexo的官方文档</a>。</p>\n<h3 id=\"2，主题配置\"><a href=\"#2，主题配置\" class=\"headerlink\" title=\"2，主题配置\"></a>2，主题配置</h3><p>想要自己的博客好看那就需要配置主题theme,我用的是Next。<br>具体设置可以到google搜索关键字hexo+next。</p>\n<h2 id=\"四、部署网站到github\"><a href=\"#四、部署网站到github\" class=\"headerlink\" title=\"四、部署网站到github\"></a>四、部署网站到github</h2><h3 id=\"1，在-config-yml中添加\"><a href=\"#1，在-config-yml中添加\" class=\"headerlink\" title=\"1，在_config.yml中添加\"></a>1，在_config.yml中添加</h3><p>deploy:<br>  type: git<br>  repository: <a href=\"https://github.com/%E4%BD%A0%E7%9A%84%E5%90%8D%E5%AD%97/%E4%BD%A0%E7%9A%84%E5%90%8D%E5%AD%97.github.io.git\">https://github.com/你的名字/你的名字.github.io.git</a><br>  branch: master </p>\n<h3 id=\"2，安装部署工具\"><a href=\"#2，安装部署工具\" class=\"headerlink\" title=\"2，安装部署工具\"></a>2，安装部署工具</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ npm install hexo-deployer-git  --save</span><br></pre></td></tr></table></figure>\n<h3 id=\"3，发布\"><a href=\"#3，发布\" class=\"headerlink\" title=\"3，发布\"></a>3，发布</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo cl &amp;&amp; hexo g &amp;&amp; hexo d</span><br></pre></td></tr></table></figure>\n<p>现在可以打开网址：你的名字.github.io访问。</p>\n<h2 id=\"五、绑定域名\"><a href=\"#五、绑定域名\" class=\"headerlink\" title=\"五、绑定域名\"></a>五、绑定域名</h2><h3 id=\"1，购买域名\"><a href=\"#1，购买域名\" class=\"headerlink\" title=\"1，购买域名\"></a>1，购买域名</h3><h3 id=\"2，域名解析\"><a href=\"#2，域名解析\" class=\"headerlink\" title=\"2，域名解析\"></a>2，域名解析</h3><p>找到域名解析选项添加两条记录:<br>CNAME www 你的名字.github.io<br>CNAME @ 你的名字.github.io</p>\n<h3 id=\"3，添加CNAME文件\"><a href=\"#3，添加CNAME文件\" class=\"headerlink\" title=\"3，添加CNAME文件\"></a>3，添加CNAME文件</h3><p>在hexo文件夹的source目录中新建CNAME文件，将你的域名写入。然后就大功告成。<br>完结撒花。</p>"},{"title":"如何回复审稿人意见？","abbrlink":64628,"date":"2020-05-29T17:21:16.000Z","_content":"SCI文章是否得以发表，生杀大权很大一部分都在peer reviewer手上。文章投出去如果收到了审稿人意见，那么恭喜，机会大大的有。那么如何回复审稿人意见就是关键了。下面是一些要点。\n\n<!-- more -->\n---\n## 主旨\n 0. 给编辑单独回复意见，说改了哪里，改的用什么标出来的。\n 1. 对审稿人表示感谢。人家花时间和精力看你的文章，不求回报，指出你的问题和不足让你得到提升让科学进步难道不该感谢?\n 2. 认真回复编辑和审稿人的每一条意见/疑问/陈述，具体就是指每一句话，每一个模糊描述，每一个疑问句。\n 3. 作为意见/疑问/陈述的回应，必要要在正文稿件中有所体现。以表明对审稿人意见的尊重。\n 4. 回复的文字量尽量要与审稿人意见差不多，最好更多，但不要重复或者罗嗦，要直接。\n 5. 尽量不要辩驳(你证据充分，你业界大佬怼人我没意见)，多做工作，审稿人让做的都要尽量测试/计算。实在搞不定的就说我们认同你的观点，然而这个还需要未来大量的工作。\n 6. 文章修改的部分要在回复意见中提及，例如，我们修改了那句话，为“xxx”，或者我们重新描述了该问题在linexxx-xxx。我认为前者更好。这样做是为了免得审稿人再去看你的文章。浪费人家时间不说，万一给你整更多问题就哈皮了。\n 7. 大修修改文章50%以上，中修30%以上，小修10%左右，显得自己足够认真。话说目前这篇文章已经修改了70%左右了。审稿人意见加回复意见比正文还长。\n 8. 一般先回应意见，再提及正文做了那些修改。\n\n## 具体\n\n 1. 审稿人称赞：感谢鼓励。\n 2. 审稿人疑问：表示自己表述不清，改。\n 3. 表示有问题：感谢指出，赞同，承认错误，修改。\n 4. 迂回的战术：通过充分考虑觉得审稿人的意见有问题，先肯定在部分情况下审稿人的看法是对的。然而。。。。肯定是自己没有描述清楚。改。\n\n","source":"_posts/2020-05-30-how-to-reply-to-reviewer.md","raw":"---\ntitle: 如何回复审稿人意见？\ncategories: work\ntags:\n  - paper\nabbrlink: 64628\ndate: 2020-05-30 01:21:16\n---\nSCI文章是否得以发表，生杀大权很大一部分都在peer reviewer手上。文章投出去如果收到了审稿人意见，那么恭喜，机会大大的有。那么如何回复审稿人意见就是关键了。下面是一些要点。\n\n<!-- more -->\n---\n## 主旨\n 0. 给编辑单独回复意见，说改了哪里，改的用什么标出来的。\n 1. 对审稿人表示感谢。人家花时间和精力看你的文章，不求回报，指出你的问题和不足让你得到提升让科学进步难道不该感谢?\n 2. 认真回复编辑和审稿人的每一条意见/疑问/陈述，具体就是指每一句话，每一个模糊描述，每一个疑问句。\n 3. 作为意见/疑问/陈述的回应，必要要在正文稿件中有所体现。以表明对审稿人意见的尊重。\n 4. 回复的文字量尽量要与审稿人意见差不多，最好更多，但不要重复或者罗嗦，要直接。\n 5. 尽量不要辩驳(你证据充分，你业界大佬怼人我没意见)，多做工作，审稿人让做的都要尽量测试/计算。实在搞不定的就说我们认同你的观点，然而这个还需要未来大量的工作。\n 6. 文章修改的部分要在回复意见中提及，例如，我们修改了那句话，为“xxx”，或者我们重新描述了该问题在linexxx-xxx。我认为前者更好。这样做是为了免得审稿人再去看你的文章。浪费人家时间不说，万一给你整更多问题就哈皮了。\n 7. 大修修改文章50%以上，中修30%以上，小修10%左右，显得自己足够认真。话说目前这篇文章已经修改了70%左右了。审稿人意见加回复意见比正文还长。\n 8. 一般先回应意见，再提及正文做了那些修改。\n\n## 具体\n\n 1. 审稿人称赞：感谢鼓励。\n 2. 审稿人疑问：表示自己表述不清，改。\n 3. 表示有问题：感谢指出，赞同，承认错误，修改。\n 4. 迂回的战术：通过充分考虑觉得审稿人的意见有问题，先肯定在部分情况下审稿人的看法是对的。然而。。。。肯定是自己没有描述清楚。改。\n\n","slug":"how-to-reply-to-reviewer","published":1,"updated":"2024-05-26T14:17:36.845Z","comments":1,"layout":"post","photos":[],"_id":"cmh498ioz0036wvouc1gceybh","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>SCI文章是否得以发表，生杀大权很大一部分都在peer reviewer手上。文章投出去如果收到了审稿人意见，那么恭喜，机会大大的有。那么如何回复审稿人意见就是关键了。下面是一些要点。</p>\n<span id=\"more\"></span>\n<hr>\n<h2 id=\"主旨\"><a href=\"#主旨\" class=\"headerlink\" title=\"主旨\"></a>主旨</h2><ol start=\"0\">\n<li>给编辑单独回复意见，说改了哪里，改的用什么标出来的。</li>\n<li>对审稿人表示感谢。人家花时间和精力看你的文章，不求回报，指出你的问题和不足让你得到提升让科学进步难道不该感谢?</li>\n<li>认真回复编辑和审稿人的每一条意见&#x2F;疑问&#x2F;陈述，具体就是指每一句话，每一个模糊描述，每一个疑问句。</li>\n<li>作为意见&#x2F;疑问&#x2F;陈述的回应，必要要在正文稿件中有所体现。以表明对审稿人意见的尊重。</li>\n<li>回复的文字量尽量要与审稿人意见差不多，最好更多，但不要重复或者罗嗦，要直接。</li>\n<li>尽量不要辩驳(你证据充分，你业界大佬怼人我没意见)，多做工作，审稿人让做的都要尽量测试&#x2F;计算。实在搞不定的就说我们认同你的观点，然而这个还需要未来大量的工作。</li>\n<li>文章修改的部分要在回复意见中提及，例如，我们修改了那句话，为“xxx”，或者我们重新描述了该问题在linexxx-xxx。我认为前者更好。这样做是为了免得审稿人再去看你的文章。浪费人家时间不说，万一给你整更多问题就哈皮了。</li>\n<li>大修修改文章50%以上，中修30%以上，小修10%左右，显得自己足够认真。话说目前这篇文章已经修改了70%左右了。审稿人意见加回复意见比正文还长。</li>\n<li>一般先回应意见，再提及正文做了那些修改。</li>\n</ol>\n<h2 id=\"具体\"><a href=\"#具体\" class=\"headerlink\" title=\"具体\"></a>具体</h2><ol>\n<li>审稿人称赞：感谢鼓励。</li>\n<li>审稿人疑问：表示自己表述不清，改。</li>\n<li>表示有问题：感谢指出，赞同，承认错误，修改。</li>\n<li>迂回的战术：通过充分考虑觉得审稿人的意见有问题，先肯定在部分情况下审稿人的看法是对的。然而。。。。肯定是自己没有描述清楚。改。</li>\n</ol>\n","related_posts":[],"length":724,"excerpt":"<p>SCI文章是否得以发表，生杀大权很大一部分都在peer reviewer手上。文章投出去如果收到了审稿人意见，那么恭喜，机会大大的有。那么如何回复审稿人意见就是关键了。下面是一些要点。</p>","more":"<hr>\n<h2 id=\"主旨\"><a href=\"#主旨\" class=\"headerlink\" title=\"主旨\"></a>主旨</h2><ol start=\"0\">\n<li>给编辑单独回复意见，说改了哪里，改的用什么标出来的。</li>\n<li>对审稿人表示感谢。人家花时间和精力看你的文章，不求回报，指出你的问题和不足让你得到提升让科学进步难道不该感谢?</li>\n<li>认真回复编辑和审稿人的每一条意见&#x2F;疑问&#x2F;陈述，具体就是指每一句话，每一个模糊描述，每一个疑问句。</li>\n<li>作为意见&#x2F;疑问&#x2F;陈述的回应，必要要在正文稿件中有所体现。以表明对审稿人意见的尊重。</li>\n<li>回复的文字量尽量要与审稿人意见差不多，最好更多，但不要重复或者罗嗦，要直接。</li>\n<li>尽量不要辩驳(你证据充分，你业界大佬怼人我没意见)，多做工作，审稿人让做的都要尽量测试&#x2F;计算。实在搞不定的就说我们认同你的观点，然而这个还需要未来大量的工作。</li>\n<li>文章修改的部分要在回复意见中提及，例如，我们修改了那句话，为“xxx”，或者我们重新描述了该问题在linexxx-xxx。我认为前者更好。这样做是为了免得审稿人再去看你的文章。浪费人家时间不说，万一给你整更多问题就哈皮了。</li>\n<li>大修修改文章50%以上，中修30%以上，小修10%左右，显得自己足够认真。话说目前这篇文章已经修改了70%左右了。审稿人意见加回复意见比正文还长。</li>\n<li>一般先回应意见，再提及正文做了那些修改。</li>\n</ol>\n<h2 id=\"具体\"><a href=\"#具体\" class=\"headerlink\" title=\"具体\"></a>具体</h2><ol>\n<li>审稿人称赞：感谢鼓励。</li>\n<li>审稿人疑问：表示自己表述不清，改。</li>\n<li>表示有问题：感谢指出，赞同，承认错误，修改。</li>\n<li>迂回的战术：通过充分考虑觉得审稿人的意见有问题，先肯定在部分情况下审稿人的看法是对的。然而。。。。肯定是自己没有描述清楚。改。</li>\n</ol>"},{"title":"如何备份hexo","abbrlink":61239,"date":"2020-05-31T05:52:53.000Z","_content":"要是换了电脑网站怎么办？那当然是需要备份的了。u盘什么的，网盘什么的也不错。不过搜到大神的[博文](https://notes.doublemine.me/2015-04-06-%E5%A4%87%E4%BB%BDHexo%E5%8D%9A%E5%AE%A2%E6%BA%90%E6%96%87%E4%BB%B6.html)介绍说放到githup的repo里面就可以了。于是试了一下，果然可以啊。步骤如下：\n## 创建github的repository\n\n创建一个和你的hexo目录一样的repo。我的就是hexo。在hexo主目录下执行如下命令：\n<!-- more -->\n\n``` bash\n$echo \"# hexo\" >>README.md\n$git init\n$git commit -m \"\"\n$git add README.md \n$git commit -m \"README\"\n$git remote add origin https://github.com/junxie01/hexo.git\n$git push -u origin master\n```\n\n## 备份/推送\n\n每次完成hexo的更新或者新博文的建立就可以运行如下命令进行推送/备份。\n\n``` bash\n$git add .\n$git commit -m \"hexo备份\"\n$git push origin master\n```\n\n## 新电脑网站移植\n\n需要在新电脑写博客需要安装npm，node.js，hexo。然后把github的repo克隆到本地就好了。\n\n```bash\n$git clone git@github.com:junxie01/hexo.git\n```\n\n## 同步本地网站\n\n当github中的repo有更新时，执行一下命令可以同步到本地。\n``` bash\n$git pull origin master\n```\n\n## 自动推送/备份\n\n那位牛人博主还有一篇博文[利用nodejs脚本自动备份](https://notes.doublemine.me/2015-07-06-%E8%87%AA%E5%8A%A8%E5%A4%87%E4%BB%BDHexo%E5%8D%9A%E5%AE%A2%E6%BA%90%E6%96%87%E4%BB%B6.html)。我不太懂，省得麻烦。干脆写一个bash脚本(例如do_deploy_push.bash)就可以解决这些问题。脚本如下:\n``` bash\nhexo cl && hexo g && hexo d\ngit add .\ngit commit -m \"backup hexo at `date` \"\ngit push origin master\n```\n在hexo主目录下面运行 bash do_deploy_push.bash就大功告成了。\n\n","source":"_posts/2020-05-31-how-to-backup-hexo.md","raw":"---\ntitle: 如何备份hexo\ncategories: web\ntags:\n  - web\nabbrlink: 61239\ndate: 2020-05-31 13:52:53\n---\n要是换了电脑网站怎么办？那当然是需要备份的了。u盘什么的，网盘什么的也不错。不过搜到大神的[博文](https://notes.doublemine.me/2015-04-06-%E5%A4%87%E4%BB%BDHexo%E5%8D%9A%E5%AE%A2%E6%BA%90%E6%96%87%E4%BB%B6.html)介绍说放到githup的repo里面就可以了。于是试了一下，果然可以啊。步骤如下：\n## 创建github的repository\n\n创建一个和你的hexo目录一样的repo。我的就是hexo。在hexo主目录下执行如下命令：\n<!-- more -->\n\n``` bash\n$echo \"# hexo\" >>README.md\n$git init\n$git commit -m \"\"\n$git add README.md \n$git commit -m \"README\"\n$git remote add origin https://github.com/junxie01/hexo.git\n$git push -u origin master\n```\n\n## 备份/推送\n\n每次完成hexo的更新或者新博文的建立就可以运行如下命令进行推送/备份。\n\n``` bash\n$git add .\n$git commit -m \"hexo备份\"\n$git push origin master\n```\n\n## 新电脑网站移植\n\n需要在新电脑写博客需要安装npm，node.js，hexo。然后把github的repo克隆到本地就好了。\n\n```bash\n$git clone git@github.com:junxie01/hexo.git\n```\n\n## 同步本地网站\n\n当github中的repo有更新时，执行一下命令可以同步到本地。\n``` bash\n$git pull origin master\n```\n\n## 自动推送/备份\n\n那位牛人博主还有一篇博文[利用nodejs脚本自动备份](https://notes.doublemine.me/2015-07-06-%E8%87%AA%E5%8A%A8%E5%A4%87%E4%BB%BDHexo%E5%8D%9A%E5%AE%A2%E6%BA%90%E6%96%87%E4%BB%B6.html)。我不太懂，省得麻烦。干脆写一个bash脚本(例如do_deploy_push.bash)就可以解决这些问题。脚本如下:\n``` bash\nhexo cl && hexo g && hexo d\ngit add .\ngit commit -m \"backup hexo at `date` \"\ngit push origin master\n```\n在hexo主目录下面运行 bash do_deploy_push.bash就大功告成了。\n\n","slug":"how-to-backup-hexo","published":1,"updated":"2024-05-26T14:17:36.845Z","comments":1,"layout":"post","photos":[],"_id":"cmh498ip00039wvou21594zk6","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>要是换了电脑网站怎么办？那当然是需要备份的了。u盘什么的，网盘什么的也不错。不过搜到大神的<a href=\"https://notes.doublemine.me/2015-04-06-%E5%A4%87%E4%BB%BDHexo%E5%8D%9A%E5%AE%A2%E6%BA%90%E6%96%87%E4%BB%B6.html\">博文</a>介绍说放到githup的repo里面就可以了。于是试了一下，果然可以啊。步骤如下：</p>\n<h2 id=\"创建github的repository\"><a href=\"#创建github的repository\" class=\"headerlink\" title=\"创建github的repository\"></a>创建github的repository</h2><p>创建一个和你的hexo目录一样的repo。我的就是hexo。在hexo主目录下执行如下命令：</p>\n<span id=\"more\"></span>\n\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"variable\">$echo</span> <span class=\"string\">&quot;# hexo&quot;</span> &gt;&gt;README.md</span><br><span class=\"line\"><span class=\"variable\">$git</span> init</span><br><span class=\"line\"><span class=\"variable\">$git</span> commit -m <span class=\"string\">&quot;&quot;</span></span><br><span class=\"line\"><span class=\"variable\">$git</span> add README.md </span><br><span class=\"line\"><span class=\"variable\">$git</span> commit -m <span class=\"string\">&quot;README&quot;</span></span><br><span class=\"line\"><span class=\"variable\">$git</span> remote add origin https://github.com/junxie01/hexo.git</span><br><span class=\"line\"><span class=\"variable\">$git</span> push -u origin master</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"备份-推送\"><a href=\"#备份-推送\" class=\"headerlink\" title=\"备份&#x2F;推送\"></a>备份&#x2F;推送</h2><p>每次完成hexo的更新或者新博文的建立就可以运行如下命令进行推送&#x2F;备份。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"variable\">$git</span> add .</span><br><span class=\"line\"><span class=\"variable\">$git</span> commit -m <span class=\"string\">&quot;hexo备份&quot;</span></span><br><span class=\"line\"><span class=\"variable\">$git</span> push origin master</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"新电脑网站移植\"><a href=\"#新电脑网站移植\" class=\"headerlink\" title=\"新电脑网站移植\"></a>新电脑网站移植</h2><p>需要在新电脑写博客需要安装npm，node.js，hexo。然后把github的repo克隆到本地就好了。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"variable\">$git</span> <span class=\"built_in\">clone</span> git@github.com:junxie01/hexo.git</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"同步本地网站\"><a href=\"#同步本地网站\" class=\"headerlink\" title=\"同步本地网站\"></a>同步本地网站</h2><p>当github中的repo有更新时，执行一下命令可以同步到本地。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"variable\">$git</span> pull origin master</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"自动推送-备份\"><a href=\"#自动推送-备份\" class=\"headerlink\" title=\"自动推送&#x2F;备份\"></a>自动推送&#x2F;备份</h2><p>那位牛人博主还有一篇博文<a href=\"https://notes.doublemine.me/2015-07-06-%E8%87%AA%E5%8A%A8%E5%A4%87%E4%BB%BDHexo%E5%8D%9A%E5%AE%A2%E6%BA%90%E6%96%87%E4%BB%B6.html\">利用nodejs脚本自动备份</a>。我不太懂，省得麻烦。干脆写一个bash脚本(例如do_deploy_push.bash)就可以解决这些问题。脚本如下:</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hexo cl &amp;&amp; hexo g &amp;&amp; hexo d</span><br><span class=\"line\">git add .</span><br><span class=\"line\">git commit -m <span class=\"string\">&quot;backup hexo at `date` &quot;</span></span><br><span class=\"line\">git push origin master</span><br></pre></td></tr></table></figure>\n<p>在hexo主目录下面运行 bash do_deploy_push.bash就大功告成了。</p>\n","related_posts":["passwd-free-for-deployment.html","how-I-build-this-web.html"],"length":874,"excerpt":"<p>要是换了电脑网站怎么办？那当然是需要备份的了。u盘什么的，网盘什么的也不错。不过搜到大神的<a href=\"https://notes.doublemine.me/2015-04-06-%E5%A4%87%E4%BB%BDHexo%E5%8D%9A%E5%AE%A2%E6%BA%90%E6%96%87%E4%BB%B6.html\">博文</a>介绍说放到githup的repo里面就可以了。于是试了一下，果然可以啊。步骤如下：</p>\n<h2 id=\"创建github的repository\"><a href=\"#创建github的repository\" class=\"headerlink\" title=\"创建github的repository\"></a>创建github的repository</h2><p>创建一个和你的hexo目录一样的repo。我的就是hexo。在hexo主目录下执行如下命令：</p>","more":"<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"variable\">$echo</span> <span class=\"string\">&quot;# hexo&quot;</span> &gt;&gt;README.md</span><br><span class=\"line\"><span class=\"variable\">$git</span> init</span><br><span class=\"line\"><span class=\"variable\">$git</span> commit -m <span class=\"string\">&quot;&quot;</span></span><br><span class=\"line\"><span class=\"variable\">$git</span> add README.md </span><br><span class=\"line\"><span class=\"variable\">$git</span> commit -m <span class=\"string\">&quot;README&quot;</span></span><br><span class=\"line\"><span class=\"variable\">$git</span> remote add origin https://github.com/junxie01/hexo.git</span><br><span class=\"line\"><span class=\"variable\">$git</span> push -u origin master</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"备份-推送\"><a href=\"#备份-推送\" class=\"headerlink\" title=\"备份&#x2F;推送\"></a>备份&#x2F;推送</h2><p>每次完成hexo的更新或者新博文的建立就可以运行如下命令进行推送&#x2F;备份。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"variable\">$git</span> add .</span><br><span class=\"line\"><span class=\"variable\">$git</span> commit -m <span class=\"string\">&quot;hexo备份&quot;</span></span><br><span class=\"line\"><span class=\"variable\">$git</span> push origin master</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"新电脑网站移植\"><a href=\"#新电脑网站移植\" class=\"headerlink\" title=\"新电脑网站移植\"></a>新电脑网站移植</h2><p>需要在新电脑写博客需要安装npm，node.js，hexo。然后把github的repo克隆到本地就好了。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"variable\">$git</span> <span class=\"built_in\">clone</span> git@github.com:junxie01/hexo.git</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"同步本地网站\"><a href=\"#同步本地网站\" class=\"headerlink\" title=\"同步本地网站\"></a>同步本地网站</h2><p>当github中的repo有更新时，执行一下命令可以同步到本地。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"variable\">$git</span> pull origin master</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"自动推送-备份\"><a href=\"#自动推送-备份\" class=\"headerlink\" title=\"自动推送&#x2F;备份\"></a>自动推送&#x2F;备份</h2><p>那位牛人博主还有一篇博文<a href=\"https://notes.doublemine.me/2015-07-06-%E8%87%AA%E5%8A%A8%E5%A4%87%E4%BB%BDHexo%E5%8D%9A%E5%AE%A2%E6%BA%90%E6%96%87%E4%BB%B6.html\">利用nodejs脚本自动备份</a>。我不太懂，省得麻烦。干脆写一个bash脚本(例如do_deploy_push.bash)就可以解决这些问题。脚本如下:</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hexo cl &amp;&amp; hexo g &amp;&amp; hexo d</span><br><span class=\"line\">git add .</span><br><span class=\"line\">git commit -m <span class=\"string\">&quot;backup hexo at `date` &quot;</span></span><br><span class=\"line\">git push origin master</span><br></pre></td></tr></table></figure>\n<p>在hexo主目录下面运行 bash do_deploy_push.bash就大功告成了。</p>"},{"title":"hexo免密发布","abbrlink":55505,"date":"2020-05-30T19:23:55.000Z","_content":"每次发布都得输入用户名和密码，挺麻烦费事。网上[大神](https://blog.csdn.net/hhgggggg/article/details/77853665)可真多，搜搜就能解决。和ssh登录服务器类似，步骤如下：\n\n<!-- more -->\n## 生成SSH密钥\n\n\n使用ssh-kergen生成密钥：\n``` bash\n$ssh-keygen -t rsa -C \"junxie01@gmail.com\"\n```\n\n一路enter就行了。生成的秘钥在主目录的.ssh/id_rsa.pub中。复制一下。\n\n## 添加Github项目的Deploy keys\n\n在项目junxie01.github.io点击settings-->Deploy keys-->Add deploy key.把拷贝好的秘钥粘贴在这里。然后勾选可写。\n\n测试是否配置成功。\n``` bash\n$ssh -T git@github.com\n```\n如果出现如下内容则表示配置成功。\n```\nHi junxie01/junxie01.github.io! You've successfully authenticated, but GitHub does not provide shell access.\n```\n\n## 网站设置文件设置\n\n在网站设置文件deploy字段设置：\n```\ndeploy:\n  type: git\n  repository: git@github.com:junxie01/junxie01.github.io.git\n  branch: master\n```\n好了，发布网站时hexo d就不用输入用户名和密码了。大功告成。\n\n## Git自带配置文件\n\n这个方法是针对github的，配置好了推送克隆什么的都万事大吉了。是这位大神[博文](https://www.jianshu.com/p/28efda0555bb)里看到的。里面介绍了两种方法，我用的是第一种，因为它看起来更简单。\n\n``` bash\n$ git config --global credential.helper store  \n```\n如果有多个账号什么的去掉--global就好了。为安全性着想还要给store设置一个时限。\n\n``` bash\ngit config --global credential.helper 'cache --timeout=3600'\n```\n这个我就没有管了。问题不大吧。\n\n","source":"_posts/2020-05-31-passwd-free-for-deployment.md","raw":"---\ntitle: hexo免密发布\ntags:\n  - hexo\n  - web\nabbrlink: 55505\ndate: 2020-05-31 03:23:55\n---\n每次发布都得输入用户名和密码，挺麻烦费事。网上[大神](https://blog.csdn.net/hhgggggg/article/details/77853665)可真多，搜搜就能解决。和ssh登录服务器类似，步骤如下：\n\n<!-- more -->\n## 生成SSH密钥\n\n\n使用ssh-kergen生成密钥：\n``` bash\n$ssh-keygen -t rsa -C \"junxie01@gmail.com\"\n```\n\n一路enter就行了。生成的秘钥在主目录的.ssh/id_rsa.pub中。复制一下。\n\n## 添加Github项目的Deploy keys\n\n在项目junxie01.github.io点击settings-->Deploy keys-->Add deploy key.把拷贝好的秘钥粘贴在这里。然后勾选可写。\n\n测试是否配置成功。\n``` bash\n$ssh -T git@github.com\n```\n如果出现如下内容则表示配置成功。\n```\nHi junxie01/junxie01.github.io! You've successfully authenticated, but GitHub does not provide shell access.\n```\n\n## 网站设置文件设置\n\n在网站设置文件deploy字段设置：\n```\ndeploy:\n  type: git\n  repository: git@github.com:junxie01/junxie01.github.io.git\n  branch: master\n```\n好了，发布网站时hexo d就不用输入用户名和密码了。大功告成。\n\n## Git自带配置文件\n\n这个方法是针对github的，配置好了推送克隆什么的都万事大吉了。是这位大神[博文](https://www.jianshu.com/p/28efda0555bb)里看到的。里面介绍了两种方法，我用的是第一种，因为它看起来更简单。\n\n``` bash\n$ git config --global credential.helper store  \n```\n如果有多个账号什么的去掉--global就好了。为安全性着想还要给store设置一个时限。\n\n``` bash\ngit config --global credential.helper 'cache --timeout=3600'\n```\n这个我就没有管了。问题不大吧。\n\n","slug":"passwd-free-for-deployment","published":1,"updated":"2024-05-26T14:17:36.845Z","comments":1,"layout":"post","photos":[],"_id":"cmh498ip0003bwvou60orgw44","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>每次发布都得输入用户名和密码，挺麻烦费事。网上<a href=\"https://blog.csdn.net/hhgggggg/article/details/77853665\">大神</a>可真多，搜搜就能解决。和ssh登录服务器类似，步骤如下：</p>\n<span id=\"more\"></span>\n<h2 id=\"生成SSH密钥\"><a href=\"#生成SSH密钥\" class=\"headerlink\" title=\"生成SSH密钥\"></a>生成SSH密钥</h2><p>使用ssh-kergen生成密钥：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"variable\">$ssh</span>-keygen -t rsa -C <span class=\"string\">&quot;junxie01@gmail.com&quot;</span></span><br></pre></td></tr></table></figure>\n\n<p>一路enter就行了。生成的秘钥在主目录的.ssh&#x2F;id_rsa.pub中。复制一下。</p>\n<h2 id=\"添加Github项目的Deploy-keys\"><a href=\"#添加Github项目的Deploy-keys\" class=\"headerlink\" title=\"添加Github项目的Deploy keys\"></a>添加Github项目的Deploy keys</h2><p>在项目junxie01.github.io点击settings–&gt;Deploy keys–&gt;Add deploy key.把拷贝好的秘钥粘贴在这里。然后勾选可写。</p>\n<p>测试是否配置成功。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"variable\">$ssh</span> -T git@github.com</span><br></pre></td></tr></table></figure>\n<p>如果出现如下内容则表示配置成功。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Hi junxie01/junxie01.github.io! You&#x27;ve successfully authenticated, but GitHub does not provide shell access.</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"网站设置文件设置\"><a href=\"#网站设置文件设置\" class=\"headerlink\" title=\"网站设置文件设置\"></a>网站设置文件设置</h2><p>在网站设置文件deploy字段设置：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">deploy:</span><br><span class=\"line\">  type: git</span><br><span class=\"line\">  repository: git@github.com:junxie01/junxie01.github.io.git</span><br><span class=\"line\">  branch: master</span><br></pre></td></tr></table></figure>\n<p>好了，发布网站时hexo d就不用输入用户名和密码了。大功告成。</p>\n<h2 id=\"Git自带配置文件\"><a href=\"#Git自带配置文件\" class=\"headerlink\" title=\"Git自带配置文件\"></a>Git自带配置文件</h2><p>这个方法是针对github的，配置好了推送克隆什么的都万事大吉了。是这位大神<a href=\"https://www.jianshu.com/p/28efda0555bb\">博文</a>里看到的。里面介绍了两种方法，我用的是第一种，因为它看起来更简单。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ git config --global credential.helper store  </span><br></pre></td></tr></table></figure>\n<p>如果有多个账号什么的去掉–global就好了。为安全性着想还要给store设置一个时限。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git config --global credential.helper <span class=\"string\">&#x27;cache --timeout=3600&#x27;</span></span><br></pre></td></tr></table></figure>\n<p>这个我就没有管了。问题不大吧。</p>\n","related_posts":["how-I-build-this-web.html","how-to-backup-hexo.html","object-detection.html","jupyter-notebook-extensions.html"],"length":822,"excerpt":"<p>每次发布都得输入用户名和密码，挺麻烦费事。网上<a href=\"https://blog.csdn.net/hhgggggg/article/details/77853665\">大神</a>可真多，搜搜就能解决。和ssh登录服务器类似，步骤如下：</p>","more":"<h2 id=\"生成SSH密钥\"><a href=\"#生成SSH密钥\" class=\"headerlink\" title=\"生成SSH密钥\"></a>生成SSH密钥</h2><p>使用ssh-kergen生成密钥：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"variable\">$ssh</span>-keygen -t rsa -C <span class=\"string\">&quot;junxie01@gmail.com&quot;</span></span><br></pre></td></tr></table></figure>\n\n<p>一路enter就行了。生成的秘钥在主目录的.ssh&#x2F;id_rsa.pub中。复制一下。</p>\n<h2 id=\"添加Github项目的Deploy-keys\"><a href=\"#添加Github项目的Deploy-keys\" class=\"headerlink\" title=\"添加Github项目的Deploy keys\"></a>添加Github项目的Deploy keys</h2><p>在项目junxie01.github.io点击settings–&gt;Deploy keys–&gt;Add deploy key.把拷贝好的秘钥粘贴在这里。然后勾选可写。</p>\n<p>测试是否配置成功。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"variable\">$ssh</span> -T git@github.com</span><br></pre></td></tr></table></figure>\n<p>如果出现如下内容则表示配置成功。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Hi junxie01/junxie01.github.io! You&#x27;ve successfully authenticated, but GitHub does not provide shell access.</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"网站设置文件设置\"><a href=\"#网站设置文件设置\" class=\"headerlink\" title=\"网站设置文件设置\"></a>网站设置文件设置</h2><p>在网站设置文件deploy字段设置：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">deploy:</span><br><span class=\"line\">  type: git</span><br><span class=\"line\">  repository: git@github.com:junxie01/junxie01.github.io.git</span><br><span class=\"line\">  branch: master</span><br></pre></td></tr></table></figure>\n<p>好了，发布网站时hexo d就不用输入用户名和密码了。大功告成。</p>\n<h2 id=\"Git自带配置文件\"><a href=\"#Git自带配置文件\" class=\"headerlink\" title=\"Git自带配置文件\"></a>Git自带配置文件</h2><p>这个方法是针对github的，配置好了推送克隆什么的都万事大吉了。是这位大神<a href=\"https://www.jianshu.com/p/28efda0555bb\">博文</a>里看到的。里面介绍了两种方法，我用的是第一种，因为它看起来更简单。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ git config --global credential.helper store  </span><br></pre></td></tr></table></figure>\n<p>如果有多个账号什么的去掉–global就好了。为安全性着想还要给store设置一个时限。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git config --global credential.helper <span class=\"string\">&#x27;cache --timeout=3600&#x27;</span></span><br></pre></td></tr></table></figure>\n<p>这个我就没有管了。问题不大吧。</p>"},{"title":"hexo next开启打赏","abbrlink":14072,"date":"2020-05-30T18:04:57.000Z","_content":"厚颜无耻的开始想要打赏。如何配置打赏呢？原来next是有打赏的选项字段的。直接修改主题配置文件如下：\n<!--more -->\n![打赏字段](donate.png)\n然后把微信和支付宝的二维码图片放在/themes/next/source/images中。然后就大功告成了。\n\n","source":"_posts/2020-05-31-reward-configuration.md","raw":"---\ntitle: hexo next开启打赏\ncategories: web\ntags:\n  - web\n  - next\nabbrlink: 14072\ndate: 2020-05-31 02:04:57\n---\n厚颜无耻的开始想要打赏。如何配置打赏呢？原来next是有打赏的选项字段的。直接修改主题配置文件如下：\n<!--more -->\n![打赏字段](donate.png)\n然后把微信和支付宝的二维码图片放在/themes/next/source/images中。然后就大功告成了。\n\n","slug":"reward-configuration","published":1,"updated":"2024-05-26T14:17:36.845Z","comments":1,"layout":"post","photos":[],"_id":"cmh498ip1003ewvouezu14ivt","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>厚颜无耻的开始想要打赏。如何配置打赏呢？原来next是有打赏的选项字段的。直接修改主题配置文件如下：</p>\n<span id=\"more\"></span>\n<p><img src=\"/donate.png\" alt=\"打赏字段\"><br>然后把微信和支付宝的二维码图片放在&#x2F;themes&#x2F;next&#x2F;source&#x2F;images中。然后就大功告成了。</p>\n","related_posts":["how-to-add-frame.html","how-to-configure-chinese-for-gmt.html","what-did-I-do-to-this-blog.html","how-to-add-frame-in-hexo-next.html"],"length":124,"excerpt":"<p>厚颜无耻的开始想要打赏。如何配置打赏呢？原来next是有打赏的选项字段的。直接修改主题配置文件如下：</p>","more":"<p><img src=\"/donate.png\" alt=\"打赏字段\"><br>然后把微信和支付宝的二维码图片放在&#x2F;themes&#x2F;next&#x2F;source&#x2F;images中。然后就大功告成了。</p>"},{"title":"hexo图片显示","abbrlink":25823,"date":"2020-05-30T18:26:29.000Z","_content":"网站上没有图片是不行的，无图无真相。解决办法在[这里](https://blog.csdn.net/qq_38148394/article/details/79997971)，主要是利用了插件hexo-assrt-image。所以先安装这个插件：\n``` bash\nnpm install hexo-asset-image --save\n```\n安装完以后将网站配置文件的post_assrt_folder字段的值改为true。每次在利用hexo new name 建新文章时，在source/_posts目录下会生成一个name的文件夹。把要调用的图放在该文件夹里，写文章的时候直接用该图的名字进行调用就行了。像这样：\n```\n![插图](a.png)\n```\n大功告成。\n\n后来听来的说要让google搜到自己，博客的层级就不能太多。于是将\n```\npermalink: :year/:month/:day/:title/\n```\n改为了：\n```\npermalink: :title.html\n```\n结果图片怎么都显示不了。果然permalink和post_assrt_folder是相互影响的。最后还得改回来。结果又不行了。将node_modules/hexo-asset-image/index.js替换一下[^1]然后才行。\n\n当然我还是喜欢简洁一点的地址。我又将permalink改为了：\n```\npermalink: :title.html\n```\n如此，在运行\n```\nhexo g\n```\n的时候程序会将图片拷贝到public/name 下面。然而，引用的时候图片的地址会变为blogip/image.png自然就无法显示。\n在node_modules/hexo-asset-image/index.js里可以看到这句话\n```\n  console.info&&console.info(\"update link as:-->\"+config.root + link + src);\n```\n表明图片的地址是blogip+link+图片名称。所以这里是link出错了。\n在link赋值的部分找到：\n```\nvar beginPos = getPosition(link, '/', 3) + 1;\nvar endPos = link.lastIndexOf('/') + 1;\nlink = link.substring(beginPos, endPos);\n```\n之前的link是博客的位置。begionPos是'/'在link中第三次出现的位置下一位。这个定义是我需要的。endPos就不需要了。\n所以改为：\n```\nlink = link.substring(beginPos);\n```\n然后link后面没有'/'，就加一个：\n```\nlink = link.concat(\"/\");\n```\n然后图片位置就准备了。然后就大功告成。\n[^1]:https://blog.csdn.net/xjm850552586/article/details/84101345\n","source":"_posts/2020-05-31-show-picture-in-hexo.md","raw":"---\ntitle: hexo图片显示\ncategories: web\ntags:\n  - next\n  - web\nabbrlink: 25823\ndate: 2020-05-31 02:26:29\n---\n网站上没有图片是不行的，无图无真相。解决办法在[这里](https://blog.csdn.net/qq_38148394/article/details/79997971)，主要是利用了插件hexo-assrt-image。所以先安装这个插件：\n``` bash\nnpm install hexo-asset-image --save\n```\n安装完以后将网站配置文件的post_assrt_folder字段的值改为true。每次在利用hexo new name 建新文章时，在source/_posts目录下会生成一个name的文件夹。把要调用的图放在该文件夹里，写文章的时候直接用该图的名字进行调用就行了。像这样：\n```\n![插图](a.png)\n```\n大功告成。\n\n后来听来的说要让google搜到自己，博客的层级就不能太多。于是将\n```\npermalink: :year/:month/:day/:title/\n```\n改为了：\n```\npermalink: :title.html\n```\n结果图片怎么都显示不了。果然permalink和post_assrt_folder是相互影响的。最后还得改回来。结果又不行了。将node_modules/hexo-asset-image/index.js替换一下[^1]然后才行。\n\n当然我还是喜欢简洁一点的地址。我又将permalink改为了：\n```\npermalink: :title.html\n```\n如此，在运行\n```\nhexo g\n```\n的时候程序会将图片拷贝到public/name 下面。然而，引用的时候图片的地址会变为blogip/image.png自然就无法显示。\n在node_modules/hexo-asset-image/index.js里可以看到这句话\n```\n  console.info&&console.info(\"update link as:-->\"+config.root + link + src);\n```\n表明图片的地址是blogip+link+图片名称。所以这里是link出错了。\n在link赋值的部分找到：\n```\nvar beginPos = getPosition(link, '/', 3) + 1;\nvar endPos = link.lastIndexOf('/') + 1;\nlink = link.substring(beginPos, endPos);\n```\n之前的link是博客的位置。begionPos是'/'在link中第三次出现的位置下一位。这个定义是我需要的。endPos就不需要了。\n所以改为：\n```\nlink = link.substring(beginPos);\n```\n然后link后面没有'/'，就加一个：\n```\nlink = link.concat(\"/\");\n```\n然后图片位置就准备了。然后就大功告成。\n[^1]:https://blog.csdn.net/xjm850552586/article/details/84101345\n","slug":"show-picture-in-hexo","published":1,"updated":"2024-05-26T14:17:36.845Z","comments":1,"layout":"post","photos":[],"_id":"cmh498ip1003hwvouer8ncrf9","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>网站上没有图片是不行的，无图无真相。解决办法在<a href=\"https://blog.csdn.net/qq_38148394/article/details/79997971\">这里</a>，主要是利用了插件hexo-assrt-image。所以先安装这个插件：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">npm install hexo-asset-image --save</span><br></pre></td></tr></table></figure>\n<p>安装完以后将网站配置文件的post_assrt_folder字段的值改为true。每次在利用hexo new name 建新文章时，在source&#x2F;_posts目录下会生成一个name的文件夹。把要调用的图放在该文件夹里，写文章的时候直接用该图的名字进行调用就行了。像这样：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">![插图](a.png)</span><br></pre></td></tr></table></figure>\n<p>大功告成。</p>\n<p>后来听来的说要让google搜到自己，博客的层级就不能太多。于是将</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">permalink: :year/:month/:day/:title/</span><br></pre></td></tr></table></figure>\n<p>改为了：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">permalink: :title.html</span><br></pre></td></tr></table></figure>\n<p>结果图片怎么都显示不了。果然permalink和post_assrt_folder是相互影响的。最后还得改回来。结果又不行了。将node_modules&#x2F;hexo-asset-image&#x2F;index.js替换一下<sup id=\"fnref:1\"><a href=\"#fn:1\" rel=\"footnote\"><span class=\"hint--top hint--error hint--medium hint--rounded hint--bounce\" aria-label=\"https://blog.csdn.net/xjm850552586/article/details/84101345\n\">[1]</span></a></sup>然后才行。</p>\n<p>当然我还是喜欢简洁一点的地址。我又将permalink改为了：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">permalink: :title.html</span><br></pre></td></tr></table></figure>\n<p>如此，在运行</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hexo g</span><br></pre></td></tr></table></figure>\n<p>的时候程序会将图片拷贝到public&#x2F;name 下面。然而，引用的时候图片的地址会变为blogip&#x2F;image.png自然就无法显示。<br>在node_modules&#x2F;hexo-asset-image&#x2F;index.js里可以看到这句话</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">console.info&amp;&amp;console.info(&quot;update link as:--&gt;&quot;+config.root + link + src);</span><br></pre></td></tr></table></figure>\n<p>表明图片的地址是blogip+link+图片名称。所以这里是link出错了。<br>在link赋值的部分找到：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">var beginPos = getPosition(link, &#x27;/&#x27;, 3) + 1;</span><br><span class=\"line\">var endPos = link.lastIndexOf(&#x27;/&#x27;) + 1;</span><br><span class=\"line\">link = link.substring(beginPos, endPos);</span><br></pre></td></tr></table></figure>\n<p>之前的link是博客的位置。begionPos是’&#x2F;‘在link中第三次出现的位置下一位。这个定义是我需要的。endPos就不需要了。<br>所以改为：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">link = link.substring(beginPos);</span><br></pre></td></tr></table></figure>\n<p>然后link后面没有’&#x2F;‘，就加一个：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">link = link.concat(&quot;/&quot;);</span><br></pre></td></tr></table></figure>\n<p>然后图片位置就准备了。然后就大功告成。</p>\n<div id=\"footnotes\"><hr><div id=\"footnotelist\"><ol style=\"list-style: none; padding-left: 0; margin-left: 40px\"><li id=\"fn:1\"><span style=\"display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px\">1.</span><span style=\"display: inline-block; vertical-align: top; margin-left: 10px;\">https://blog.csdn.net/xjm850552586/article/details/84101345<a href=\"#fnref:1\" rev=\"footnote\"> ↩</a></span></li></ol></div></div>","related_posts":["how-to-add-frame.html"],"length":1187,"excerpt":"","more":"<p>网站上没有图片是不行的，无图无真相。解决办法在<a href=\"https://blog.csdn.net/qq_38148394/article/details/79997971\">这里</a>，主要是利用了插件hexo-assrt-image。所以先安装这个插件：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">npm install hexo-asset-image --save</span><br></pre></td></tr></table></figure>\n<p>安装完以后将网站配置文件的post_assrt_folder字段的值改为true。每次在利用hexo new name 建新文章时，在source&#x2F;_posts目录下会生成一个name的文件夹。把要调用的图放在该文件夹里，写文章的时候直接用该图的名字进行调用就行了。像这样：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">![插图](a.png)</span><br></pre></td></tr></table></figure>\n<p>大功告成。</p>\n<p>后来听来的说要让google搜到自己，博客的层级就不能太多。于是将</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">permalink: :year/:month/:day/:title/</span><br></pre></td></tr></table></figure>\n<p>改为了：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">permalink: :title.html</span><br></pre></td></tr></table></figure>\n<p>结果图片怎么都显示不了。果然permalink和post_assrt_folder是相互影响的。最后还得改回来。结果又不行了。将node_modules&#x2F;hexo-asset-image&#x2F;index.js替换一下<sup id=\"fnref:1\"><a href=\"#fn:1\" rel=\"footnote\"><span class=\"hint--top hint--error hint--medium hint--rounded hint--bounce\" aria-label=\"https://blog.csdn.net/xjm850552586/article/details/84101345\n\">[1]</span></a></sup>然后才行。</p>\n<p>当然我还是喜欢简洁一点的地址。我又将permalink改为了：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">permalink: :title.html</span><br></pre></td></tr></table></figure>\n<p>如此，在运行</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hexo g</span><br></pre></td></tr></table></figure>\n<p>的时候程序会将图片拷贝到public&#x2F;name 下面。然而，引用的时候图片的地址会变为blogip&#x2F;image.png自然就无法显示。<br>在node_modules&#x2F;hexo-asset-image&#x2F;index.js里可以看到这句话</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">console.info&amp;&amp;console.info(&quot;update link as:--&gt;&quot;+config.root + link + src);</span><br></pre></td></tr></table></figure>\n<p>表明图片的地址是blogip+link+图片名称。所以这里是link出错了。<br>在link赋值的部分找到：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">var beginPos = getPosition(link, &#x27;/&#x27;, 3) + 1;</span><br><span class=\"line\">var endPos = link.lastIndexOf(&#x27;/&#x27;) + 1;</span><br><span class=\"line\">link = link.substring(beginPos, endPos);</span><br></pre></td></tr></table></figure>\n<p>之前的link是博客的位置。begionPos是’&#x2F;‘在link中第三次出现的位置下一位。这个定义是我需要的。endPos就不需要了。<br>所以改为：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">link = link.substring(beginPos);</span><br></pre></td></tr></table></figure>\n<p>然后link后面没有’&#x2F;‘，就加一个：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">link = link.concat(&quot;/&quot;);</span><br></pre></td></tr></table></figure>\n<p>然后图片位置就准备了。然后就大功告成。</p>\n<div id=\"footnotes\"><hr><div id=\"footnotelist\"><ol style=\"list-style: none; padding-left: 0; margin-left: 40px\"><li id=\"fn:1\"><span style=\"display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px\">1.</span><span style=\"display: inline-block; vertical-align: top; margin-left: 10px;\">https://blog.csdn.net/xjm850552586/article/details/84101345<a href=\"#fnref:1\" rev=\"footnote\"> ↩</a></span></li></ol></div></div>"},{"title":"next网站字数统计","abbrlink":22869,"date":"2020-05-30T17:29:36.000Z","_content":"想给网站显示字数统计，搜到[这里](https://www.jianshu.com/p/baea8c95e39b)。根据说明开始设置。结果网站都差点挂掉。检查了好久也没有发现问题，以为玩完了。然后马上开始重新建hexo。结果还是有问题。后来终于发现在网站设置文件插入功能字段时误插到其他字段导致出错。注销以后问题就修复了。然后又搜索到[这里](https://blog.csdn.net/mqdxiaoxiao/article/details/93670772)。没想到搞定了，使用的插件是hexo-symbols-count-time。设置步骤如下：\n\n<!-- more -->\n## 1. 安装插件\n\n``` bash\n$ npm install hexo-symbols-count-time --save\n```\n\n## 2. 配置文件设置\n\n在网站配置文件中加入如下字段：\n```\nsymbols_count_time:\n  symbols: true                # 文章字数统计\n  time: true                   # 文章阅读时长\n  total_symbols: true          # 站点总字数统计\n  total_time: true             # 站点总阅读时长\n  exclude_codeblock: false     # 排除代码字数统计\n```\n\n## 3. 主题配置文件设置\n\n在主题配置文件加入如下字段：\n```\n# Post wordcount display settings\n# Dependencies: https://github.com/theme-next/hexo-symbols-count-time\nsymbols_count_time:\n  separated_meta: true     # 是否另起一行（true的话不和发表时间等同一行）\n  item_text_post: true     # 首页文章统计数量前是否显示文字描述（本文字数、阅读时长）\n  item_text_total: false   # 页面底部统计数量前是否显示文字描述（站点总字数、站点阅读时长）\n  awl: 4                   # Average Word Length\n  wpm: 275                 # Words Per Minute（每分钟阅读词数）\n  suffix: mins\n```\n\n然后大功告成。\n\n","source":"_posts/2020-05-31-word-count.md","raw":"---\ntitle: next网站字数统计\ncategories: web\ntags:\n  - next\n  - web\nabbrlink: 22869\ndate: 2020-05-31 01:29:36\n---\n想给网站显示字数统计，搜到[这里](https://www.jianshu.com/p/baea8c95e39b)。根据说明开始设置。结果网站都差点挂掉。检查了好久也没有发现问题，以为玩完了。然后马上开始重新建hexo。结果还是有问题。后来终于发现在网站设置文件插入功能字段时误插到其他字段导致出错。注销以后问题就修复了。然后又搜索到[这里](https://blog.csdn.net/mqdxiaoxiao/article/details/93670772)。没想到搞定了，使用的插件是hexo-symbols-count-time。设置步骤如下：\n\n<!-- more -->\n## 1. 安装插件\n\n``` bash\n$ npm install hexo-symbols-count-time --save\n```\n\n## 2. 配置文件设置\n\n在网站配置文件中加入如下字段：\n```\nsymbols_count_time:\n  symbols: true                # 文章字数统计\n  time: true                   # 文章阅读时长\n  total_symbols: true          # 站点总字数统计\n  total_time: true             # 站点总阅读时长\n  exclude_codeblock: false     # 排除代码字数统计\n```\n\n## 3. 主题配置文件设置\n\n在主题配置文件加入如下字段：\n```\n# Post wordcount display settings\n# Dependencies: https://github.com/theme-next/hexo-symbols-count-time\nsymbols_count_time:\n  separated_meta: true     # 是否另起一行（true的话不和发表时间等同一行）\n  item_text_post: true     # 首页文章统计数量前是否显示文字描述（本文字数、阅读时长）\n  item_text_total: false   # 页面底部统计数量前是否显示文字描述（站点总字数、站点阅读时长）\n  awl: 4                   # Average Word Length\n  wpm: 275                 # Words Per Minute（每分钟阅读词数）\n  suffix: mins\n```\n\n然后大功告成。\n\n","slug":"word-count","published":1,"updated":"2024-05-26T14:17:36.845Z","comments":1,"layout":"post","photos":[],"_id":"cmh498ip2003kwvouas2b8vph","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>想给网站显示字数统计，搜到<a href=\"https://www.jianshu.com/p/baea8c95e39b\">这里</a>。根据说明开始设置。结果网站都差点挂掉。检查了好久也没有发现问题，以为玩完了。然后马上开始重新建hexo。结果还是有问题。后来终于发现在网站设置文件插入功能字段时误插到其他字段导致出错。注销以后问题就修复了。然后又搜索到<a href=\"https://blog.csdn.net/mqdxiaoxiao/article/details/93670772\">这里</a>。没想到搞定了，使用的插件是hexo-symbols-count-time。设置步骤如下：</p>\n<span id=\"more\"></span>\n<h2 id=\"1-安装插件\"><a href=\"#1-安装插件\" class=\"headerlink\" title=\"1. 安装插件\"></a>1. 安装插件</h2><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ npm install hexo-symbols-count-time --save</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"2-配置文件设置\"><a href=\"#2-配置文件设置\" class=\"headerlink\" title=\"2. 配置文件设置\"></a>2. 配置文件设置</h2><p>在网站配置文件中加入如下字段：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">symbols_count_time:</span><br><span class=\"line\">  symbols: true                # 文章字数统计</span><br><span class=\"line\">  time: true                   # 文章阅读时长</span><br><span class=\"line\">  total_symbols: true          # 站点总字数统计</span><br><span class=\"line\">  total_time: true             # 站点总阅读时长</span><br><span class=\"line\">  exclude_codeblock: false     # 排除代码字数统计</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"3-主题配置文件设置\"><a href=\"#3-主题配置文件设置\" class=\"headerlink\" title=\"3. 主题配置文件设置\"></a>3. 主题配置文件设置</h2><p>在主题配置文件加入如下字段：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># Post wordcount display settings</span><br><span class=\"line\"># Dependencies: https://github.com/theme-next/hexo-symbols-count-time</span><br><span class=\"line\">symbols_count_time:</span><br><span class=\"line\">  separated_meta: true     # 是否另起一行（true的话不和发表时间等同一行）</span><br><span class=\"line\">  item_text_post: true     # 首页文章统计数量前是否显示文字描述（本文字数、阅读时长）</span><br><span class=\"line\">  item_text_total: false   # 页面底部统计数量前是否显示文字描述（站点总字数、站点阅读时长）</span><br><span class=\"line\">  awl: 4                   # Average Word Length</span><br><span class=\"line\">  wpm: 275                 # Words Per Minute（每分钟阅读词数）</span><br><span class=\"line\">  suffix: mins</span><br></pre></td></tr></table></figure>\n\n<p>然后大功告成。</p>\n","related_posts":["Win7下格掉Linux盘如何启动windows.html"],"length":748,"excerpt":"<p>想给网站显示字数统计，搜到<a href=\"https://www.jianshu.com/p/baea8c95e39b\">这里</a>。根据说明开始设置。结果网站都差点挂掉。检查了好久也没有发现问题，以为玩完了。然后马上开始重新建hexo。结果还是有问题。后来终于发现在网站设置文件插入功能字段时误插到其他字段导致出错。注销以后问题就修复了。然后又搜索到<a href=\"https://blog.csdn.net/mqdxiaoxiao/article/details/93670772\">这里</a>。没想到搞定了，使用的插件是hexo-symbols-count-time。设置步骤如下：</p>","more":"<h2 id=\"1-安装插件\"><a href=\"#1-安装插件\" class=\"headerlink\" title=\"1. 安装插件\"></a>1. 安装插件</h2><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ npm install hexo-symbols-count-time --save</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"2-配置文件设置\"><a href=\"#2-配置文件设置\" class=\"headerlink\" title=\"2. 配置文件设置\"></a>2. 配置文件设置</h2><p>在网站配置文件中加入如下字段：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">symbols_count_time:</span><br><span class=\"line\">  symbols: true                # 文章字数统计</span><br><span class=\"line\">  time: true                   # 文章阅读时长</span><br><span class=\"line\">  total_symbols: true          # 站点总字数统计</span><br><span class=\"line\">  total_time: true             # 站点总阅读时长</span><br><span class=\"line\">  exclude_codeblock: false     # 排除代码字数统计</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"3-主题配置文件设置\"><a href=\"#3-主题配置文件设置\" class=\"headerlink\" title=\"3. 主题配置文件设置\"></a>3. 主题配置文件设置</h2><p>在主题配置文件加入如下字段：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># Post wordcount display settings</span><br><span class=\"line\"># Dependencies: https://github.com/theme-next/hexo-symbols-count-time</span><br><span class=\"line\">symbols_count_time:</span><br><span class=\"line\">  separated_meta: true     # 是否另起一行（true的话不和发表时间等同一行）</span><br><span class=\"line\">  item_text_post: true     # 首页文章统计数量前是否显示文字描述（本文字数、阅读时长）</span><br><span class=\"line\">  item_text_total: false   # 页面底部统计数量前是否显示文字描述（站点总字数、站点阅读时长）</span><br><span class=\"line\">  awl: 4                   # Average Word Length</span><br><span class=\"line\">  wpm: 275                 # Words Per Minute（每分钟阅读词数）</span><br><span class=\"line\">  suffix: mins</span><br></pre></td></tr></table></figure>\n\n<p>然后大功告成。</p>"},{"title":"关于写日记","abbrlink":60083,"date":"2020-06-03T14:54:38.000Z","_content":"\n&emsp;&emsp;好久都没有写日记的习惯了。今天勉强写一些吧。\n<!-- more -->\n\n&emsp;&emsp;上周鬼使神差的建了这个个人网站。其实不是心血来潮，是一直都有建站的想法。只是不知道为啥中途就没有建过。可能这次只是收到了来自腾讯云广告的蛊惑。看样子广告还真是有用啊。用处就是让一直没有下定决心的人迈出临门一脚。腾讯云让我耗费了１块钱，但整这个博客的时间花了我一周了。\n\n&emsp;&emsp;今天又不知哪根筋不对劲，忽然想起网易博客里面还有我以前的博文。翻出来看看居然有270多条。从2005年一直到2015年都有。（其中一部分是QQ转移过去的。）看样子我写字的习惯还不错。然而2015年之后就没有怎么写过了。想想也挺可惜的。不过回想自己没有坚持写文字，挺遗憾。可能大约是没有时间吧。\n\n&emsp;&emsp;嗯。也不对。时间从来都是像药膏一样挤挤就会有的。这是借口。文字通常是人用来发牢骚的东西。牢骚多发的猛的就成了巨匠。例如鲁迅。牢骚发的弱的就凑不够字数。我是说每个人都牢骚，有的人发到了文字上，但有些人通过嘴巴，拳头，脑子什么都就发泄完了。大概这些年我的牢骚都从其他地方发了吧。\n\n&emsp;&emsp;以后还想好好发发。不过还是别叫日记的好。自从看到大伙儿对委员长记日记习惯的调侃后就觉得“日记”变了味啊。\n\n&emsp;&emsp;另一个目的就是还是继续写文字锻炼脑子吧。锻炼脑子准没有错的。说不定还能防老年痴呆。\n\n&emsp;&emsp;不过也不要发宏愿，这类东西从来都是麻痹自己，让当时的自己产生多巴胺，且长不大的青少年才玩的玩意。\n\n&emsp;&emsp;所以就这样吧。爱写写写写。\n\n","source":"_posts/2020-06-03-about-diary.md","raw":"---\ntitle: 关于写日记\ncategories:\n  - 日记\ntags:\n  - 日记\nabbrlink: 60083\ndate: 2020-06-03 22:54:38\n---\n\n&emsp;&emsp;好久都没有写日记的习惯了。今天勉强写一些吧。\n<!-- more -->\n\n&emsp;&emsp;上周鬼使神差的建了这个个人网站。其实不是心血来潮，是一直都有建站的想法。只是不知道为啥中途就没有建过。可能这次只是收到了来自腾讯云广告的蛊惑。看样子广告还真是有用啊。用处就是让一直没有下定决心的人迈出临门一脚。腾讯云让我耗费了１块钱，但整这个博客的时间花了我一周了。\n\n&emsp;&emsp;今天又不知哪根筋不对劲，忽然想起网易博客里面还有我以前的博文。翻出来看看居然有270多条。从2005年一直到2015年都有。（其中一部分是QQ转移过去的。）看样子我写字的习惯还不错。然而2015年之后就没有怎么写过了。想想也挺可惜的。不过回想自己没有坚持写文字，挺遗憾。可能大约是没有时间吧。\n\n&emsp;&emsp;嗯。也不对。时间从来都是像药膏一样挤挤就会有的。这是借口。文字通常是人用来发牢骚的东西。牢骚多发的猛的就成了巨匠。例如鲁迅。牢骚发的弱的就凑不够字数。我是说每个人都牢骚，有的人发到了文字上，但有些人通过嘴巴，拳头，脑子什么都就发泄完了。大概这些年我的牢骚都从其他地方发了吧。\n\n&emsp;&emsp;以后还想好好发发。不过还是别叫日记的好。自从看到大伙儿对委员长记日记习惯的调侃后就觉得“日记”变了味啊。\n\n&emsp;&emsp;另一个目的就是还是继续写文字锻炼脑子吧。锻炼脑子准没有错的。说不定还能防老年痴呆。\n\n&emsp;&emsp;不过也不要发宏愿，这类东西从来都是麻痹自己，让当时的自己产生多巴胺，且长不大的青少年才玩的玩意。\n\n&emsp;&emsp;所以就这样吧。爱写写写写。\n\n","slug":"about-diary","published":1,"updated":"2024-05-26T14:17:36.846Z","comments":1,"layout":"post","photos":[],"_id":"cmh498ip2003nwvou0y6vdlwi","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>&emsp;&emsp;好久都没有写日记的习惯了。今天勉强写一些吧。</p>\n<span id=\"more\"></span>\n\n<p>&emsp;&emsp;上周鬼使神差的建了这个个人网站。其实不是心血来潮，是一直都有建站的想法。只是不知道为啥中途就没有建过。可能这次只是收到了来自腾讯云广告的蛊惑。看样子广告还真是有用啊。用处就是让一直没有下定决心的人迈出临门一脚。腾讯云让我耗费了１块钱，但整这个博客的时间花了我一周了。</p>\n<p>&emsp;&emsp;今天又不知哪根筋不对劲，忽然想起网易博客里面还有我以前的博文。翻出来看看居然有270多条。从2005年一直到2015年都有。（其中一部分是QQ转移过去的。）看样子我写字的习惯还不错。然而2015年之后就没有怎么写过了。想想也挺可惜的。不过回想自己没有坚持写文字，挺遗憾。可能大约是没有时间吧。</p>\n<p>&emsp;&emsp;嗯。也不对。时间从来都是像药膏一样挤挤就会有的。这是借口。文字通常是人用来发牢骚的东西。牢骚多发的猛的就成了巨匠。例如鲁迅。牢骚发的弱的就凑不够字数。我是说每个人都牢骚，有的人发到了文字上，但有些人通过嘴巴，拳头，脑子什么都就发泄完了。大概这些年我的牢骚都从其他地方发了吧。</p>\n<p>&emsp;&emsp;以后还想好好发发。不过还是别叫日记的好。自从看到大伙儿对委员长记日记习惯的调侃后就觉得“日记”变了味啊。</p>\n<p>&emsp;&emsp;另一个目的就是还是继续写文字锻炼脑子吧。锻炼脑子准没有错的。说不定还能防老年痴呆。</p>\n<p>&emsp;&emsp;不过也不要发宏愿，这类东西从来都是麻痹自己，让当时的自己产生多巴胺，且长不大的青少年才玩的玩意。</p>\n<p>&emsp;&emsp;所以就这样吧。爱写写写写。</p>\n","related_posts":[],"length":688,"excerpt":"<p>&emsp;&emsp;好久都没有写日记的习惯了。今天勉强写一些吧。</p>","more":"<p>&emsp;&emsp;上周鬼使神差的建了这个个人网站。其实不是心血来潮，是一直都有建站的想法。只是不知道为啥中途就没有建过。可能这次只是收到了来自腾讯云广告的蛊惑。看样子广告还真是有用啊。用处就是让一直没有下定决心的人迈出临门一脚。腾讯云让我耗费了１块钱，但整这个博客的时间花了我一周了。</p>\n<p>&emsp;&emsp;今天又不知哪根筋不对劲，忽然想起网易博客里面还有我以前的博文。翻出来看看居然有270多条。从2005年一直到2015年都有。（其中一部分是QQ转移过去的。）看样子我写字的习惯还不错。然而2015年之后就没有怎么写过了。想想也挺可惜的。不过回想自己没有坚持写文字，挺遗憾。可能大约是没有时间吧。</p>\n<p>&emsp;&emsp;嗯。也不对。时间从来都是像药膏一样挤挤就会有的。这是借口。文字通常是人用来发牢骚的东西。牢骚多发的猛的就成了巨匠。例如鲁迅。牢骚发的弱的就凑不够字数。我是说每个人都牢骚，有的人发到了文字上，但有些人通过嘴巴，拳头，脑子什么都就发泄完了。大概这些年我的牢骚都从其他地方发了吧。</p>\n<p>&emsp;&emsp;以后还想好好发发。不过还是别叫日记的好。自从看到大伙儿对委员长记日记习惯的调侃后就觉得“日记”变了味啊。</p>\n<p>&emsp;&emsp;另一个目的就是还是继续写文字锻炼脑子吧。锻炼脑子准没有错的。说不定还能防老年痴呆。</p>\n<p>&emsp;&emsp;不过也不要发宏愿，这类东西从来都是麻痹自己，让当时的自己产生多巴胺，且长不大的青少年才玩的玩意。</p>\n<p>&emsp;&emsp;所以就这样吧。爱写写写写。</p>"},{"title":"网易博客迁移","abbrlink":23445,"date":"2020-06-03T15:23:36.000Z","_content":"\n&emsp;&emsp;今天想到自己在网易上的博客。翻出来一看，乖乖人家网易在2018年就把博客给停了。估计是看我不在上面更新了，伤心欲绝了吧。笑。\n<!-- more -->\n\n&emsp;&emsp;我的那些怪文扔了怪可惜的。于是就想都搬到这里来吧。没法直接搬啊。看看网易怎么说吧。可以下载到xml文件里，或者搬迁到Lofter里面。都试一下。xml里面是个啥。果然有博文，但乱码一大堆。咋行。搬到Lofter里面吧。显示得要７天左右。\n\n&emsp;&emsp;好吧，趁此机会在网上搜索吧。我疯狂的搜了从xml到wordpress, 网易到hexo，网易到其他博客，等等等等。为此还在csdn建了自己的账号。因为搜到说可以一键从网易搬到那里。结果迟了啊。这都0202年了，人家的网易搬家功能早都扔了。对了hexo博文都是markdown格式。岂不将xml转换到markdown格式就完美了。\n\n&emsp;&emsp;于是我又疯狂开始搜索xml转移到markdown。倒是搜到了一些有用的。比如[墨问非名](https://zhuanlan.zhihu.com/p/67765274)的项目[Lofter2Hexo](https://github.com/alicewish/Lofter2Hexo)，[北方之塔](https://himring.top/lofter-expo-repo/)的脚本[lofter2Jekyll](https://github.com/FromEndWorld/lofter2Jekyll)。两个程序的名字居然一样叫readxml。这本来没啥问题。\n\n&emsp;&emsp;问题是我的网速慢啊。程序名字一样是我安装好之后才知道的啊。安装其中一个结果安装好久。安装空挡就看了另一个，也来试一下。开了两个terminal同时安装两个程序。有些依赖包啊什么的没安装。于是又另开两个terminal继续安装。搞了半天，真的搞了半天。因为中间吃饭去了。\n\n&emsp;&emsp;然后我也不记得哪个安装好了。算了先看看网易博客有没有导入到Lofter里面吧。点开看，完成了。太好了，下载了Lofter的xml文件。看起来还不错。然后，试试吧。不知道用的哪个readxml，总之是把某个程序的windows文本结果的\\r换成Linux以后就可以用了。然后就试了。果然可以，虽然有几张图没有下载下来。不过没关系了。\n\n&emsp;&emsp;我迫不及待的打开了LOFTER文件夹中的md文件查看。我的乖乖，全都是乱码。title乱码，标签乱码，日期是今天。简直没办法看。此外我的博文显示有270篇，转换过来只有220篇，估计还有50多篇都被认为不和谐吧。但我写的东西很和谐啊。一点也不愤青。\n\n&emsp;&emsp;心想，算了。嘴巴也说算了。妻说，别。以后整理出来可以给儿子看看啊。\n\n&emsp;&emsp;于是晚上娃睡了以后花了一个多小时，才搬了40篇到这里来。下次再继续吧。\n\n","source":"_posts/2020-06-03-wangyi-blog-transfer.md","raw":"---\ntitle: 网易博客迁移\ncategories:\n  - 日记\ntags:\n  - 博客\n  - 网易\nabbrlink: 23445\ndate: 2020-06-03 23:23:36\n---\n\n&emsp;&emsp;今天想到自己在网易上的博客。翻出来一看，乖乖人家网易在2018年就把博客给停了。估计是看我不在上面更新了，伤心欲绝了吧。笑。\n<!-- more -->\n\n&emsp;&emsp;我的那些怪文扔了怪可惜的。于是就想都搬到这里来吧。没法直接搬啊。看看网易怎么说吧。可以下载到xml文件里，或者搬迁到Lofter里面。都试一下。xml里面是个啥。果然有博文，但乱码一大堆。咋行。搬到Lofter里面吧。显示得要７天左右。\n\n&emsp;&emsp;好吧，趁此机会在网上搜索吧。我疯狂的搜了从xml到wordpress, 网易到hexo，网易到其他博客，等等等等。为此还在csdn建了自己的账号。因为搜到说可以一键从网易搬到那里。结果迟了啊。这都0202年了，人家的网易搬家功能早都扔了。对了hexo博文都是markdown格式。岂不将xml转换到markdown格式就完美了。\n\n&emsp;&emsp;于是我又疯狂开始搜索xml转移到markdown。倒是搜到了一些有用的。比如[墨问非名](https://zhuanlan.zhihu.com/p/67765274)的项目[Lofter2Hexo](https://github.com/alicewish/Lofter2Hexo)，[北方之塔](https://himring.top/lofter-expo-repo/)的脚本[lofter2Jekyll](https://github.com/FromEndWorld/lofter2Jekyll)。两个程序的名字居然一样叫readxml。这本来没啥问题。\n\n&emsp;&emsp;问题是我的网速慢啊。程序名字一样是我安装好之后才知道的啊。安装其中一个结果安装好久。安装空挡就看了另一个，也来试一下。开了两个terminal同时安装两个程序。有些依赖包啊什么的没安装。于是又另开两个terminal继续安装。搞了半天，真的搞了半天。因为中间吃饭去了。\n\n&emsp;&emsp;然后我也不记得哪个安装好了。算了先看看网易博客有没有导入到Lofter里面吧。点开看，完成了。太好了，下载了Lofter的xml文件。看起来还不错。然后，试试吧。不知道用的哪个readxml，总之是把某个程序的windows文本结果的\\r换成Linux以后就可以用了。然后就试了。果然可以，虽然有几张图没有下载下来。不过没关系了。\n\n&emsp;&emsp;我迫不及待的打开了LOFTER文件夹中的md文件查看。我的乖乖，全都是乱码。title乱码，标签乱码，日期是今天。简直没办法看。此外我的博文显示有270篇，转换过来只有220篇，估计还有50多篇都被认为不和谐吧。但我写的东西很和谐啊。一点也不愤青。\n\n&emsp;&emsp;心想，算了。嘴巴也说算了。妻说，别。以后整理出来可以给儿子看看啊。\n\n&emsp;&emsp;于是晚上娃睡了以后花了一个多小时，才搬了40篇到这里来。下次再继续吧。\n\n","slug":"wangyi-blog-transfer","published":1,"updated":"2024-05-26T14:17:36.846Z","comments":1,"layout":"post","photos":[],"_id":"cmh498ip3003qwvou53sfaf2c","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>&emsp;&emsp;今天想到自己在网易上的博客。翻出来一看，乖乖人家网易在2018年就把博客给停了。估计是看我不在上面更新了，伤心欲绝了吧。笑。</p>\n<span id=\"more\"></span>\n\n<p>&emsp;&emsp;我的那些怪文扔了怪可惜的。于是就想都搬到这里来吧。没法直接搬啊。看看网易怎么说吧。可以下载到xml文件里，或者搬迁到Lofter里面。都试一下。xml里面是个啥。果然有博文，但乱码一大堆。咋行。搬到Lofter里面吧。显示得要７天左右。</p>\n<p>&emsp;&emsp;好吧，趁此机会在网上搜索吧。我疯狂的搜了从xml到wordpress, 网易到hexo，网易到其他博客，等等等等。为此还在csdn建了自己的账号。因为搜到说可以一键从网易搬到那里。结果迟了啊。这都0202年了，人家的网易搬家功能早都扔了。对了hexo博文都是markdown格式。岂不将xml转换到markdown格式就完美了。</p>\n<p>&emsp;&emsp;于是我又疯狂开始搜索xml转移到markdown。倒是搜到了一些有用的。比如<a href=\"https://zhuanlan.zhihu.com/p/67765274\">墨问非名</a>的项目<a href=\"https://github.com/alicewish/Lofter2Hexo\">Lofter2Hexo</a>，<a href=\"https://himring.top/lofter-expo-repo/\">北方之塔</a>的脚本<a href=\"https://github.com/FromEndWorld/lofter2Jekyll\">lofter2Jekyll</a>。两个程序的名字居然一样叫readxml。这本来没啥问题。</p>\n<p>&emsp;&emsp;问题是我的网速慢啊。程序名字一样是我安装好之后才知道的啊。安装其中一个结果安装好久。安装空挡就看了另一个，也来试一下。开了两个terminal同时安装两个程序。有些依赖包啊什么的没安装。于是又另开两个terminal继续安装。搞了半天，真的搞了半天。因为中间吃饭去了。</p>\n<p>&emsp;&emsp;然后我也不记得哪个安装好了。算了先看看网易博客有没有导入到Lofter里面吧。点开看，完成了。太好了，下载了Lofter的xml文件。看起来还不错。然后，试试吧。不知道用的哪个readxml，总之是把某个程序的windows文本结果的\\r换成Linux以后就可以用了。然后就试了。果然可以，虽然有几张图没有下载下来。不过没关系了。</p>\n<p>&emsp;&emsp;我迫不及待的打开了LOFTER文件夹中的md文件查看。我的乖乖，全都是乱码。title乱码，标签乱码，日期是今天。简直没办法看。此外我的博文显示有270篇，转换过来只有220篇，估计还有50多篇都被认为不和谐吧。但我写的东西很和谐啊。一点也不愤青。</p>\n<p>&emsp;&emsp;心想，算了。嘴巴也说算了。妻说，别。以后整理出来可以给儿子看看啊。</p>\n<p>&emsp;&emsp;于是晚上娃睡了以后花了一个多小时，才搬了40篇到这里来。下次再继续吧。</p>\n","related_posts":[],"length":1048,"excerpt":"<p>&emsp;&emsp;今天想到自己在网易上的博客。翻出来一看，乖乖人家网易在2018年就把博客给停了。估计是看我不在上面更新了，伤心欲绝了吧。笑。</p>","more":"<p>&emsp;&emsp;我的那些怪文扔了怪可惜的。于是就想都搬到这里来吧。没法直接搬啊。看看网易怎么说吧。可以下载到xml文件里，或者搬迁到Lofter里面。都试一下。xml里面是个啥。果然有博文，但乱码一大堆。咋行。搬到Lofter里面吧。显示得要７天左右。</p>\n<p>&emsp;&emsp;好吧，趁此机会在网上搜索吧。我疯狂的搜了从xml到wordpress, 网易到hexo，网易到其他博客，等等等等。为此还在csdn建了自己的账号。因为搜到说可以一键从网易搬到那里。结果迟了啊。这都0202年了，人家的网易搬家功能早都扔了。对了hexo博文都是markdown格式。岂不将xml转换到markdown格式就完美了。</p>\n<p>&emsp;&emsp;于是我又疯狂开始搜索xml转移到markdown。倒是搜到了一些有用的。比如<a href=\"https://zhuanlan.zhihu.com/p/67765274\">墨问非名</a>的项目<a href=\"https://github.com/alicewish/Lofter2Hexo\">Lofter2Hexo</a>，<a href=\"https://himring.top/lofter-expo-repo/\">北方之塔</a>的脚本<a href=\"https://github.com/FromEndWorld/lofter2Jekyll\">lofter2Jekyll</a>。两个程序的名字居然一样叫readxml。这本来没啥问题。</p>\n<p>&emsp;&emsp;问题是我的网速慢啊。程序名字一样是我安装好之后才知道的啊。安装其中一个结果安装好久。安装空挡就看了另一个，也来试一下。开了两个terminal同时安装两个程序。有些依赖包啊什么的没安装。于是又另开两个terminal继续安装。搞了半天，真的搞了半天。因为中间吃饭去了。</p>\n<p>&emsp;&emsp;然后我也不记得哪个安装好了。算了先看看网易博客有没有导入到Lofter里面吧。点开看，完成了。太好了，下载了Lofter的xml文件。看起来还不错。然后，试试吧。不知道用的哪个readxml，总之是把某个程序的windows文本结果的\\r换成Linux以后就可以用了。然后就试了。果然可以，虽然有几张图没有下载下来。不过没关系了。</p>\n<p>&emsp;&emsp;我迫不及待的打开了LOFTER文件夹中的md文件查看。我的乖乖，全都是乱码。title乱码，标签乱码，日期是今天。简直没办法看。此外我的博文显示有270篇，转换过来只有220篇，估计还有50多篇都被认为不和谐吧。但我写的东西很和谐啊。一点也不愤青。</p>\n<p>&emsp;&emsp;心想，算了。嘴巴也说算了。妻说，别。以后整理出来可以给儿子看看啊。</p>\n<p>&emsp;&emsp;于是晚上娃睡了以后花了一个多小时，才搬了40篇到这里来。下次再继续吧。</p>"},{"title":"Eric的趣事","abbrlink":14404,"date":"2020-06-03T17:00:58.000Z","_content":"\n&emsp;&emsp;记录一下儿子好玩的事情，以免以后忘记了。以后他看到应该会觉得好玩吧。\n<!-- more -->\n\n## Eric的深刻发问\n\nEric四岁零两个月，一些问题问的特别深刻啊。得好好引导一下，说不定未来成为科学家了。笑。\n\n1. 我们为什么能看到五颜六色的东西？\n2. 为什么地球会转？\n3. 为什么会有白天和晚上？\n4. 人是从哪里来的？\n5. 我们什么时候死啊？\n\n## Eric的优秀品质\n\nEric有好多优点。罗列一些想到的如下：\n1. 每次都说Lady first让妈妈先尝东西，先进门。\n2. 爱分享食物。\n3. 爱帮忙。会说，妈妈需要我帮忙吗？每次叫他帮忙他总会帮。\n4. 爱干净，玩完玩具一般都会分类收拾。有一丝垃圾都会扔到垃圾桶。\n5. 爱看故事书。有时候自己一个人抱着书看。\n6. 记忆力不错，读了挺久的英文书还记得一些句子。\n7. 英文比较可以了，有时和我只讲英文。一般自己玩玩具自言自语都讲英文。\n8. 每次结巴完了之后，语言能力就会有比较大的提升。这次又开始结巴了。\n9. 刷牙习惯很好。每天都自己刷。\n10. Eric可以自己擦屁股了。\n11. 很早就开始自己穿脱衣服和鞋子了。\n12. 很早就开始自己吃饭了。\n13. 十分会拼乐高玩具。比较有创意。\n14. 意志力比较坚定。说好了买ninjago的船一直都念着。\n15. 钝感力比较高。能吃亏。\n\n## Eric的不足之处\n\n1. 有些时候有些着急。完成不了东西就叫唤，烦躁。可能是小孩子的通病。\n2. 有些时候会动手动脚，激动了会打人。可能小孩子比较难以控制。\n3. 有些时候有点拖沓，比如每次让洗澡都拖的比较久。\n4. 有时候情绪不太稳定。不开心的时候沉默不语。可能语言和情绪控制能力还没有发育好。\n5. 过于喜欢乐高玩具，天天都想买，天天抱着手机搜乐高玩具，收藏，说要买。\n\n&emsp;&emsp;希望宝宝越长越好。\n\n","source":"_posts/2020-06-04-funny-thing-about-Eric.md","raw":"---\ntitle: Eric的趣事\ncategories:\n  - 日记\ntags:\n  - 儿子\nabbrlink: 14404\ndate: 2020-06-04 01:00:58\n---\n\n&emsp;&emsp;记录一下儿子好玩的事情，以免以后忘记了。以后他看到应该会觉得好玩吧。\n<!-- more -->\n\n## Eric的深刻发问\n\nEric四岁零两个月，一些问题问的特别深刻啊。得好好引导一下，说不定未来成为科学家了。笑。\n\n1. 我们为什么能看到五颜六色的东西？\n2. 为什么地球会转？\n3. 为什么会有白天和晚上？\n4. 人是从哪里来的？\n5. 我们什么时候死啊？\n\n## Eric的优秀品质\n\nEric有好多优点。罗列一些想到的如下：\n1. 每次都说Lady first让妈妈先尝东西，先进门。\n2. 爱分享食物。\n3. 爱帮忙。会说，妈妈需要我帮忙吗？每次叫他帮忙他总会帮。\n4. 爱干净，玩完玩具一般都会分类收拾。有一丝垃圾都会扔到垃圾桶。\n5. 爱看故事书。有时候自己一个人抱着书看。\n6. 记忆力不错，读了挺久的英文书还记得一些句子。\n7. 英文比较可以了，有时和我只讲英文。一般自己玩玩具自言自语都讲英文。\n8. 每次结巴完了之后，语言能力就会有比较大的提升。这次又开始结巴了。\n9. 刷牙习惯很好。每天都自己刷。\n10. Eric可以自己擦屁股了。\n11. 很早就开始自己穿脱衣服和鞋子了。\n12. 很早就开始自己吃饭了。\n13. 十分会拼乐高玩具。比较有创意。\n14. 意志力比较坚定。说好了买ninjago的船一直都念着。\n15. 钝感力比较高。能吃亏。\n\n## Eric的不足之处\n\n1. 有些时候有些着急。完成不了东西就叫唤，烦躁。可能是小孩子的通病。\n2. 有些时候会动手动脚，激动了会打人。可能小孩子比较难以控制。\n3. 有些时候有点拖沓，比如每次让洗澡都拖的比较久。\n4. 有时候情绪不太稳定。不开心的时候沉默不语。可能语言和情绪控制能力还没有发育好。\n5. 过于喜欢乐高玩具，天天都想买，天天抱着手机搜乐高玩具，收藏，说要买。\n\n&emsp;&emsp;希望宝宝越长越好。\n\n","slug":"funny-thing-about-Eric","published":1,"updated":"2024-05-26T14:17:36.846Z","comments":1,"layout":"post","photos":[],"_id":"cmh498ip3003twvoud0vl2eog","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>&emsp;&emsp;记录一下儿子好玩的事情，以免以后忘记了。以后他看到应该会觉得好玩吧。</p>\n<span id=\"more\"></span>\n\n<h2 id=\"Eric的深刻发问\"><a href=\"#Eric的深刻发问\" class=\"headerlink\" title=\"Eric的深刻发问\"></a>Eric的深刻发问</h2><p>Eric四岁零两个月，一些问题问的特别深刻啊。得好好引导一下，说不定未来成为科学家了。笑。</p>\n<ol>\n<li>我们为什么能看到五颜六色的东西？</li>\n<li>为什么地球会转？</li>\n<li>为什么会有白天和晚上？</li>\n<li>人是从哪里来的？</li>\n<li>我们什么时候死啊？</li>\n</ol>\n<h2 id=\"Eric的优秀品质\"><a href=\"#Eric的优秀品质\" class=\"headerlink\" title=\"Eric的优秀品质\"></a>Eric的优秀品质</h2><p>Eric有好多优点。罗列一些想到的如下：</p>\n<ol>\n<li>每次都说Lady first让妈妈先尝东西，先进门。</li>\n<li>爱分享食物。</li>\n<li>爱帮忙。会说，妈妈需要我帮忙吗？每次叫他帮忙他总会帮。</li>\n<li>爱干净，玩完玩具一般都会分类收拾。有一丝垃圾都会扔到垃圾桶。</li>\n<li>爱看故事书。有时候自己一个人抱着书看。</li>\n<li>记忆力不错，读了挺久的英文书还记得一些句子。</li>\n<li>英文比较可以了，有时和我只讲英文。一般自己玩玩具自言自语都讲英文。</li>\n<li>每次结巴完了之后，语言能力就会有比较大的提升。这次又开始结巴了。</li>\n<li>刷牙习惯很好。每天都自己刷。</li>\n<li>Eric可以自己擦屁股了。</li>\n<li>很早就开始自己穿脱衣服和鞋子了。</li>\n<li>很早就开始自己吃饭了。</li>\n<li>十分会拼乐高玩具。比较有创意。</li>\n<li>意志力比较坚定。说好了买ninjago的船一直都念着。</li>\n<li>钝感力比较高。能吃亏。</li>\n</ol>\n<h2 id=\"Eric的不足之处\"><a href=\"#Eric的不足之处\" class=\"headerlink\" title=\"Eric的不足之处\"></a>Eric的不足之处</h2><ol>\n<li>有些时候有些着急。完成不了东西就叫唤，烦躁。可能是小孩子的通病。</li>\n<li>有些时候会动手动脚，激动了会打人。可能小孩子比较难以控制。</li>\n<li>有些时候有点拖沓，比如每次让洗澡都拖的比较久。</li>\n<li>有时候情绪不太稳定。不开心的时候沉默不语。可能语言和情绪控制能力还没有发育好。</li>\n<li>过于喜欢乐高玩具，天天都想买，天天抱着手机搜乐高玩具，收藏，说要买。</li>\n</ol>\n<p>&emsp;&emsp;希望宝宝越长越好。</p>\n","related_posts":[],"length":669,"excerpt":"<p>&emsp;&emsp;记录一下儿子好玩的事情，以免以后忘记了。以后他看到应该会觉得好玩吧。</p>","more":"<h2 id=\"Eric的深刻发问\"><a href=\"#Eric的深刻发问\" class=\"headerlink\" title=\"Eric的深刻发问\"></a>Eric的深刻发问</h2><p>Eric四岁零两个月，一些问题问的特别深刻啊。得好好引导一下，说不定未来成为科学家了。笑。</p>\n<ol>\n<li>我们为什么能看到五颜六色的东西？</li>\n<li>为什么地球会转？</li>\n<li>为什么会有白天和晚上？</li>\n<li>人是从哪里来的？</li>\n<li>我们什么时候死啊？</li>\n</ol>\n<h2 id=\"Eric的优秀品质\"><a href=\"#Eric的优秀品质\" class=\"headerlink\" title=\"Eric的优秀品质\"></a>Eric的优秀品质</h2><p>Eric有好多优点。罗列一些想到的如下：</p>\n<ol>\n<li>每次都说Lady first让妈妈先尝东西，先进门。</li>\n<li>爱分享食物。</li>\n<li>爱帮忙。会说，妈妈需要我帮忙吗？每次叫他帮忙他总会帮。</li>\n<li>爱干净，玩完玩具一般都会分类收拾。有一丝垃圾都会扔到垃圾桶。</li>\n<li>爱看故事书。有时候自己一个人抱着书看。</li>\n<li>记忆力不错，读了挺久的英文书还记得一些句子。</li>\n<li>英文比较可以了，有时和我只讲英文。一般自己玩玩具自言自语都讲英文。</li>\n<li>每次结巴完了之后，语言能力就会有比较大的提升。这次又开始结巴了。</li>\n<li>刷牙习惯很好。每天都自己刷。</li>\n<li>Eric可以自己擦屁股了。</li>\n<li>很早就开始自己穿脱衣服和鞋子了。</li>\n<li>很早就开始自己吃饭了。</li>\n<li>十分会拼乐高玩具。比较有创意。</li>\n<li>意志力比较坚定。说好了买ninjago的船一直都念着。</li>\n<li>钝感力比较高。能吃亏。</li>\n</ol>\n<h2 id=\"Eric的不足之处\"><a href=\"#Eric的不足之处\" class=\"headerlink\" title=\"Eric的不足之处\"></a>Eric的不足之处</h2><ol>\n<li>有些时候有些着急。完成不了东西就叫唤，烦躁。可能是小孩子的通病。</li>\n<li>有些时候会动手动脚，激动了会打人。可能小孩子比较难以控制。</li>\n<li>有些时候有点拖沓，比如每次让洗澡都拖的比较久。</li>\n<li>有时候情绪不太稳定。不开心的时候沉默不语。可能语言和情绪控制能力还没有发育好。</li>\n<li>过于喜欢乐高玩具，天天都想买，天天抱着手机搜乐高玩具，收藏，说要买。</li>\n</ol>\n<p>&emsp;&emsp;希望宝宝越长越好。</p>"},{"title":"历史和反演","abbrlink":52263,"date":"2020-06-04T16:57:47.000Z","_content":"\n&emsp;&emsp;研一的时候上过一节外系的选修课。现在已经想不起来是什么课了。那为啥我还记得这个课呢？\n<!-- more -->\n\n&emsp;&emsp;有两个原因，第一，课上有一个女生的眼睛比较好看。这千万不要被老婆发现了(嘘)。另一个重要原因就是老师布置了一个讨论作业。\n\n&emsp;&emsp;说是十年前有一个地区要建垃圾处理场。政府的意思是要建，大部分群众的意见是不建。具体老师让我们讨论什么记不太清了。我起来回答，第一，群众是愚昧的；第二，历史就像反演一样。过了十年了，当时的很多事情我们是不清楚的。有个同学起来反驳我说，历史怎么是不清楚的呢？历史资料是很清楚的啊。\n\n&emsp;&emsp;其实历史就和反演一样。我们记录的资料只是历史当中的很小一部分。就像地球物理里的观测资料，台站稀疏，资料就少。另外历史是人记录的，难免带有感情色彩，主观因素。就像地震仪器会有仪器响应。知道了仪器响应还可以反卷积掉，那人为因素怎么定量，如何扣除？\n\n&emsp;&emsp;历史是无法回去重新观摩的，就像是地下介质的结构基本没有办法挖进去一探究竟。以记录到的少量资料想要去描绘历史图景，与反演过程一样，是具有非唯一性的。因而我们并不知道真正的历史是什么样的。我甚至认为作为历史参与者的我们，连此时此刻发生的事情的全貌都不清楚，就更别提不是我们书写也不是我们缔造的历史了。\n\n&emsp;&emsp;反演和历史是一样的。忽然想到一个可怕的比喻－－历史就像是任人打扮的小姑娘。由于这个非唯一性，大家拿到了一部分资料就可以按照自己的理解，站在自己的角度，根据自己的学识，经验，立场去解释历史。反演不也是这样吗？你拿到一部分资料来做一个反演，反演出结构或震源机制，便可给一通解释。他也可以。要是解释的人位高权重，或者权威泰斗，那大伙儿就信了。但事实真的就是这样的吗？\n\n&emsp;&emsp;有人说，没有一个模型是对的，只有有些是有用的，是有参考价值的。\n\n\n","source":"_posts/2020-06-05-history-and-inversion.md","raw":"---\ntitle: 历史和反演\ncategories:\n  - 乱笔\ntags:\n  - 反演\n  - 历史\nabbrlink: 52263\ndate: 2020-06-05 00:57:47\n---\n\n&emsp;&emsp;研一的时候上过一节外系的选修课。现在已经想不起来是什么课了。那为啥我还记得这个课呢？\n<!-- more -->\n\n&emsp;&emsp;有两个原因，第一，课上有一个女生的眼睛比较好看。这千万不要被老婆发现了(嘘)。另一个重要原因就是老师布置了一个讨论作业。\n\n&emsp;&emsp;说是十年前有一个地区要建垃圾处理场。政府的意思是要建，大部分群众的意见是不建。具体老师让我们讨论什么记不太清了。我起来回答，第一，群众是愚昧的；第二，历史就像反演一样。过了十年了，当时的很多事情我们是不清楚的。有个同学起来反驳我说，历史怎么是不清楚的呢？历史资料是很清楚的啊。\n\n&emsp;&emsp;其实历史就和反演一样。我们记录的资料只是历史当中的很小一部分。就像地球物理里的观测资料，台站稀疏，资料就少。另外历史是人记录的，难免带有感情色彩，主观因素。就像地震仪器会有仪器响应。知道了仪器响应还可以反卷积掉，那人为因素怎么定量，如何扣除？\n\n&emsp;&emsp;历史是无法回去重新观摩的，就像是地下介质的结构基本没有办法挖进去一探究竟。以记录到的少量资料想要去描绘历史图景，与反演过程一样，是具有非唯一性的。因而我们并不知道真正的历史是什么样的。我甚至认为作为历史参与者的我们，连此时此刻发生的事情的全貌都不清楚，就更别提不是我们书写也不是我们缔造的历史了。\n\n&emsp;&emsp;反演和历史是一样的。忽然想到一个可怕的比喻－－历史就像是任人打扮的小姑娘。由于这个非唯一性，大家拿到了一部分资料就可以按照自己的理解，站在自己的角度，根据自己的学识，经验，立场去解释历史。反演不也是这样吗？你拿到一部分资料来做一个反演，反演出结构或震源机制，便可给一通解释。他也可以。要是解释的人位高权重，或者权威泰斗，那大伙儿就信了。但事实真的就是这样的吗？\n\n&emsp;&emsp;有人说，没有一个模型是对的，只有有些是有用的，是有参考价值的。\n\n\n","slug":"history-and-inversion","published":1,"updated":"2025-05-10T07:31:08.051Z","comments":1,"layout":"post","photos":[],"_id":"cmh498ip4003xwvou2p5pcvxo","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>&emsp;&emsp;研一的时候上过一节外系的选修课。现在已经想不起来是什么课了。那为啥我还记得这个课呢？</p>\n<span id=\"more\"></span>\n\n<p>&emsp;&emsp;有两个原因，第一，课上有一个女生的眼睛比较好看。这千万不要被老婆发现了(嘘)。另一个重要原因就是老师布置了一个讨论作业。</p>\n<p>&emsp;&emsp;说是十年前有一个地区要建垃圾处理场。政府的意思是要建，大部分群众的意见是不建。具体老师让我们讨论什么记不太清了。我起来回答，第一，群众是愚昧的；第二，历史就像反演一样。过了十年了，当时的很多事情我们是不清楚的。有个同学起来反驳我说，历史怎么是不清楚的呢？历史资料是很清楚的啊。</p>\n<p>&emsp;&emsp;其实历史就和反演一样。我们记录的资料只是历史当中的很小一部分。就像地球物理里的观测资料，台站稀疏，资料就少。另外历史是人记录的，难免带有感情色彩，主观因素。就像地震仪器会有仪器响应。知道了仪器响应还可以反卷积掉，那人为因素怎么定量，如何扣除？</p>\n<p>&emsp;&emsp;历史是无法回去重新观摩的，就像是地下介质的结构基本没有办法挖进去一探究竟。以记录到的少量资料想要去描绘历史图景，与反演过程一样，是具有非唯一性的。因而我们并不知道真正的历史是什么样的。我甚至认为作为历史参与者的我们，连此时此刻发生的事情的全貌都不清楚，就更别提不是我们书写也不是我们缔造的历史了。</p>\n<p>&emsp;&emsp;反演和历史是一样的。忽然想到一个可怕的比喻－－历史就像是任人打扮的小姑娘。由于这个非唯一性，大家拿到了一部分资料就可以按照自己的理解，站在自己的角度，根据自己的学识，经验，立场去解释历史。反演不也是这样吗？你拿到一部分资料来做一个反演，反演出结构或震源机制，便可给一通解释。他也可以。要是解释的人位高权重，或者权威泰斗，那大伙儿就信了。但事实真的就是这样的吗？</p>\n<p>&emsp;&emsp;有人说，没有一个模型是对的，只有有些是有用的，是有参考价值的。</p>\n","related_posts":["happy-new-year.html"],"length":804,"excerpt":"<p>&emsp;&emsp;研一的时候上过一节外系的选修课。现在已经想不起来是什么课了。那为啥我还记得这个课呢？</p>","more":"<p>&emsp;&emsp;有两个原因，第一，课上有一个女生的眼睛比较好看。这千万不要被老婆发现了(嘘)。另一个重要原因就是老师布置了一个讨论作业。</p>\n<p>&emsp;&emsp;说是十年前有一个地区要建垃圾处理场。政府的意思是要建，大部分群众的意见是不建。具体老师让我们讨论什么记不太清了。我起来回答，第一，群众是愚昧的；第二，历史就像反演一样。过了十年了，当时的很多事情我们是不清楚的。有个同学起来反驳我说，历史怎么是不清楚的呢？历史资料是很清楚的啊。</p>\n<p>&emsp;&emsp;其实历史就和反演一样。我们记录的资料只是历史当中的很小一部分。就像地球物理里的观测资料，台站稀疏，资料就少。另外历史是人记录的，难免带有感情色彩，主观因素。就像地震仪器会有仪器响应。知道了仪器响应还可以反卷积掉，那人为因素怎么定量，如何扣除？</p>\n<p>&emsp;&emsp;历史是无法回去重新观摩的，就像是地下介质的结构基本没有办法挖进去一探究竟。以记录到的少量资料想要去描绘历史图景，与反演过程一样，是具有非唯一性的。因而我们并不知道真正的历史是什么样的。我甚至认为作为历史参与者的我们，连此时此刻发生的事情的全貌都不清楚，就更别提不是我们书写也不是我们缔造的历史了。</p>\n<p>&emsp;&emsp;反演和历史是一样的。忽然想到一个可怕的比喻－－历史就像是任人打扮的小姑娘。由于这个非唯一性，大家拿到了一部分资料就可以按照自己的理解，站在自己的角度，根据自己的学识，经验，立场去解释历史。反演不也是这样吗？你拿到一部分资料来做一个反演，反演出结构或震源机制，便可给一通解释。他也可以。要是解释的人位高权重，或者权威泰斗，那大伙儿就信了。但事实真的就是这样的吗？</p>\n<p>&emsp;&emsp;有人说，没有一个模型是对的，只有有些是有用的，是有参考价值的。</p>"},{"title":"不继续搬迁网易博客了","abbrlink":12006,"date":"2020-06-05T05:50:38.000Z","_content":"\n&emsp;&emsp;那个网易博客太多私人的话题和内容就不往这里搬了。自己也不是明星，八卦什么的也不值钱。这里还是用来记好玩的吧。\n<!-- more -->\n\n","source":"_posts/2020-06-05-no-more-blog-transfer.md","raw":"---\ntitle: 不继续搬迁网易博客了\ncategories:\n  - 杂\ntags:\n  - 杂\nabbrlink: 12006\ndate: 2020-06-05 13:50:38\n---\n\n&emsp;&emsp;那个网易博客太多私人的话题和内容就不往这里搬了。自己也不是明星，八卦什么的也不值钱。这里还是用来记好玩的吧。\n<!-- more -->\n\n","slug":"no-more-blog-transfer","published":1,"updated":"2024-05-26T14:17:36.846Z","comments":1,"layout":"post","photos":[],"_id":"cmh498ip40040wvou06fj7cp5","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>&emsp;&emsp;那个网易博客太多私人的话题和内容就不往这里搬了。自己也不是明星，八卦什么的也不值钱。这里还是用来记好玩的吧。</p>\n<span id=\"more\"></span>\n\n","related_posts":[],"length":66,"excerpt":"<p>&emsp;&emsp;那个网易博客太多私人的话题和内容就不往这里搬了。自己也不是明星，八卦什么的也不值钱。这里还是用来记好玩的吧。</p>","more":""},{"title":"我对这个博客做了什么","abbrlink":58531,"date":"2020-06-10T03:18:16.000Z","_content":"\n&emsp;&emsp;原本是想记笔记，写一些技术性的东西。然而现在为止好像还没有干啥正事。那我对这个博客做了些什么呢？干了这些：\n<!-- more -->\n\n## 重新配置 \n按{% post_link how-I-build-this-web 这个步骤 %}重新配置了一遍。之前不知道从哪里下载的一个山寨版还是啥的，应该是老版本，很多东西都没有。所以重新下载了最新版本。折腾了好久。对了，还干了好多无用功。网上搜来的很多教程版本都比较老。别马上按着别人的办法干，先看看主题的配置文件，或官方的文档。\n\n## 插入脚注\n请参见此神仙[^1]。 \n\n## 封面模式\n参见[^11]。下载这个插件：\n```\nnpm install --save hexo-less\n```\n语法是在封面后面加上\n```\n<!--less-->\n```\n这样前面的部分不会显示到文章主题部分。可以搞一张图片就完美了。\n```\n![封面](图片地址)\n<!--less->\n```\n\n## 设置标签云\n按照这位大仙[^3]的操作弄好了标签云，但是发现它不在正中啊。于是找到了tag cloud的[github](https://github.com/MikeCoder/hexo-tag-cloud)。里面有一句：\n```\n<canvas width=\"250\" height=\"250\" id=\"resCanvas\" style=\"width:100%\">\n```\n那个100%前面是一个冒号，而大仙[^3]写做等号。我发现等号就偏右边，冒号就在正中，很奇怪。\n\n## 侧边栏圆角\n搜索到这位大神[^8]。我的Scheme选的是Pisces，所以先在next/source/css/_variables/Pisces.styl里面改一下变量\n```\n$border-radius                    = 5px;\n```\n然后到next/source/css/_schemes/Pisces/_layout.styl里面的.header-inner(对应菜单栏)字段改\n```\nborder-radius: $border-radius;\n```\n在.content-wrap(对应文章页面)字段改\n```\nborder-radius: $border-radius;\n```\n如此改完，然后......不对劲。在主页菜单栏和文章页面确实变圆角了，然而站点概况不是圆角。然而往下拖动，直到看不到菜单栏的时候，站点概况就变圆角了，不能忍。所以可能还要改siderbar字段。可惜_layout.styl里面木有。诶，我发现有next/source/css/_schemes/Pisces/_sidebar.styl文件。打开看。果然找到了。.sidebar字段是没有border-radius变量的，于是我添加了\n```\nborder-radius: $border-radius;\n```\n除此以外，还看到了.sidebar-inner字段。也一并改了。这下就大功告成了。忘了说。这些字段的另一个变量是background，把它替换成\n```\nbackground: rgba(255,255,255,0.9);\n```\n就可以让博客变透明了。\n\n## 站内引用语法\n这样:\n```\n{% post_link post_name %}\n```\n出来默认是博文题目，或者自己取个名字。\n```\n{% post_link post_name 点击查看%}\n```\n\n## 设置网站图标\n同样来自这位大神[^2]。最重要的是找到自己喜欢的图片放在next/source/images里，然后在next/_config.yml里这样干就好了：\n```\nfavicon:\n  small: /images/j-icon-16x16.png\n  medium: /images/j-icon-32x32.png\n  apple_touch_icon: /images/icon.png\n  safari_pinned_tab: /images/icon.png\n\n```\n\n## 首页文章加框\n设置请查看{% post_link how-to-add-frame-in-hexo-next %}\n\n## 添加版权信息\n根据此大仙[^5]的说明弄好了以后，发现署名”前面的cc图标老是乱码（一个叉）。那怎么可以，弄了半天没弄好。结果人家next已经集成了。在next/_config.yml里面这样就好了。\n```\ncreative_commons:\n  license: by-nc-sa\n  sidebar: true\n  post: true\n  language:\n```\n\n## 加动态背景图片\n根据这位大仙[^7]的方法弄的。\n动态图片感觉太慢了。我在百度下了一个，有阳光森林，人，牛。感觉还不错，希望不要侵权。\n\n## 点击头像回到主页\n设置请查看{% post_link avatar-to-homepage 这篇文章 %}\n\n## 永久链接permalink\n参见[^10]。首先安装程序：\n```\nnpm install hexo-abbrlink --save\n```\n然后在_config.yml中设置：\n```\npermalink: posts/:abbrlink/\nabbrlink:\n  alg: crc32\n  rep: hex\npermalink_defaults:\npretty_urls:\n  trailing_index: false # Set to false to remove trailing 'index.html' from permalinks\n  trailing_html: false # Set to false to remove trailing '.html' from permalinks\n```\n\n## footer添加运行时间\n\n参见[^9]。找到/next/layout/_partials/footer.swig，在里面添加：\n```\n<div>\n<span id=\"timeDate\">Loading days...</span><span id=\"times\">Loading sec....</span>\n<script>\n    var now = new Date();\n    function createtime() {\n        var grt= new Date(\"05/26/2020 00:00:00\");\n        now.setTime(now.getTime()+250);\n        days = (now - grt ) / 1000 / 60 / 60 / 24; dnum = Math.floor(days);\n        hours = (now - grt ) / 1000 / 60 / 60 - (24 * dnum); hnum = Math.floor(hours);\n        if(String(hnum).length ==1 ){hnum = \"0\" + hnum;} minutes = (now - grt ) / 1000 /60 - (24 * 60 * dnum) - (60 * hnum);\n        mnum = Math.floor(minutes); if(String(mnum).length ==1 ){mnum = \"0\" + mnum;}\n        seconds = (now - grt ) / 1000 - (24 * 60 * 60 * dnum) - (60 * 60 * hnum) - (60 * mnum);\n        snum = Math.round(seconds); if(String(snum).length ==1 ){snum = \"0\" + snum;}\n        document.getElementById(\"timeDate\").innerHTML = \"Running safely for: \"+dnum+\" d \";\n        document.getElementById(\"times\").innerHTML = hnum + \" h \" + mnum + \" m \" + snum + \" s\";\n    }\nsetInterval(\"createtime()\",250);\n</script>\n</div>\n```\n本来大神[^9]是写的中文，但我的出来是乱码，就改成了英文了。\n\n\n\n## 字数和阅读时长统计\n请参见[^4]，或者请查看{% post_link word-count %}。\n\n\n## 添加google广告到post\n参见[^6]。\n\n## 隐藏网页底部 powered By Hexo\n股沟出此大神[^2]的方法。\n但事实上next已经集成了这个功能，直接在next/_config.yml里将powered改为false就可以了，像这样：\n```\nfooter：\n   xxx\n   powered: false\n   xxx\n```\n\n\n\n [^1]:https://github.com/kchen0x/hexo-reference\n [^2]:https://blog.csdn.net/as480133937/article/details/100138838\n [^3]:https://blog.csdn.net/Aoman_Hao/article/details/89416634\n [^4]:https://github.com/theme-next/hexo-symbols-count-time\n [^5]:https://wylu.me/posts/e0424f3f/\n [^6]:https://juejin.im/post/5c95d230e51d45124e35cef6#comment\n [^7]:https://blog.diqigan.cn/posts/add-background-picture-for-next.html \n [^8]:http://eternalzttz.com/hexo-next.html\n [^9]:https://www.93bok.com/Hexo网站运行时间添加/\n[^10]:https://github.com/Rozbo/hexo-abbrlink\n[^11]:https://github.com/fuchen/hexo-less\n","source":"_posts/2020-06-10-what-did-I-do-to-this-blog.md","raw":"---\ntitle: 我对这个博客做了什么\ncategories:\n  - web\ntags:\n  - hexo\n  - next\nabbrlink: 58531\ndate: 2020-06-10 11:18:16\n---\n\n&emsp;&emsp;原本是想记笔记，写一些技术性的东西。然而现在为止好像还没有干啥正事。那我对这个博客做了些什么呢？干了这些：\n<!-- more -->\n\n## 重新配置 \n按{% post_link how-I-build-this-web 这个步骤 %}重新配置了一遍。之前不知道从哪里下载的一个山寨版还是啥的，应该是老版本，很多东西都没有。所以重新下载了最新版本。折腾了好久。对了，还干了好多无用功。网上搜来的很多教程版本都比较老。别马上按着别人的办法干，先看看主题的配置文件，或官方的文档。\n\n## 插入脚注\n请参见此神仙[^1]。 \n\n## 封面模式\n参见[^11]。下载这个插件：\n```\nnpm install --save hexo-less\n```\n语法是在封面后面加上\n```\n<!--less-->\n```\n这样前面的部分不会显示到文章主题部分。可以搞一张图片就完美了。\n```\n![封面](图片地址)\n<!--less->\n```\n\n## 设置标签云\n按照这位大仙[^3]的操作弄好了标签云，但是发现它不在正中啊。于是找到了tag cloud的[github](https://github.com/MikeCoder/hexo-tag-cloud)。里面有一句：\n```\n<canvas width=\"250\" height=\"250\" id=\"resCanvas\" style=\"width:100%\">\n```\n那个100%前面是一个冒号，而大仙[^3]写做等号。我发现等号就偏右边，冒号就在正中，很奇怪。\n\n## 侧边栏圆角\n搜索到这位大神[^8]。我的Scheme选的是Pisces，所以先在next/source/css/_variables/Pisces.styl里面改一下变量\n```\n$border-radius                    = 5px;\n```\n然后到next/source/css/_schemes/Pisces/_layout.styl里面的.header-inner(对应菜单栏)字段改\n```\nborder-radius: $border-radius;\n```\n在.content-wrap(对应文章页面)字段改\n```\nborder-radius: $border-radius;\n```\n如此改完，然后......不对劲。在主页菜单栏和文章页面确实变圆角了，然而站点概况不是圆角。然而往下拖动，直到看不到菜单栏的时候，站点概况就变圆角了，不能忍。所以可能还要改siderbar字段。可惜_layout.styl里面木有。诶，我发现有next/source/css/_schemes/Pisces/_sidebar.styl文件。打开看。果然找到了。.sidebar字段是没有border-radius变量的，于是我添加了\n```\nborder-radius: $border-radius;\n```\n除此以外，还看到了.sidebar-inner字段。也一并改了。这下就大功告成了。忘了说。这些字段的另一个变量是background，把它替换成\n```\nbackground: rgba(255,255,255,0.9);\n```\n就可以让博客变透明了。\n\n## 站内引用语法\n这样:\n```\n{% post_link post_name %}\n```\n出来默认是博文题目，或者自己取个名字。\n```\n{% post_link post_name 点击查看%}\n```\n\n## 设置网站图标\n同样来自这位大神[^2]。最重要的是找到自己喜欢的图片放在next/source/images里，然后在next/_config.yml里这样干就好了：\n```\nfavicon:\n  small: /images/j-icon-16x16.png\n  medium: /images/j-icon-32x32.png\n  apple_touch_icon: /images/icon.png\n  safari_pinned_tab: /images/icon.png\n\n```\n\n## 首页文章加框\n设置请查看{% post_link how-to-add-frame-in-hexo-next %}\n\n## 添加版权信息\n根据此大仙[^5]的说明弄好了以后，发现署名”前面的cc图标老是乱码（一个叉）。那怎么可以，弄了半天没弄好。结果人家next已经集成了。在next/_config.yml里面这样就好了。\n```\ncreative_commons:\n  license: by-nc-sa\n  sidebar: true\n  post: true\n  language:\n```\n\n## 加动态背景图片\n根据这位大仙[^7]的方法弄的。\n动态图片感觉太慢了。我在百度下了一个，有阳光森林，人，牛。感觉还不错，希望不要侵权。\n\n## 点击头像回到主页\n设置请查看{% post_link avatar-to-homepage 这篇文章 %}\n\n## 永久链接permalink\n参见[^10]。首先安装程序：\n```\nnpm install hexo-abbrlink --save\n```\n然后在_config.yml中设置：\n```\npermalink: posts/:abbrlink/\nabbrlink:\n  alg: crc32\n  rep: hex\npermalink_defaults:\npretty_urls:\n  trailing_index: false # Set to false to remove trailing 'index.html' from permalinks\n  trailing_html: false # Set to false to remove trailing '.html' from permalinks\n```\n\n## footer添加运行时间\n\n参见[^9]。找到/next/layout/_partials/footer.swig，在里面添加：\n```\n<div>\n<span id=\"timeDate\">Loading days...</span><span id=\"times\">Loading sec....</span>\n<script>\n    var now = new Date();\n    function createtime() {\n        var grt= new Date(\"05/26/2020 00:00:00\");\n        now.setTime(now.getTime()+250);\n        days = (now - grt ) / 1000 / 60 / 60 / 24; dnum = Math.floor(days);\n        hours = (now - grt ) / 1000 / 60 / 60 - (24 * dnum); hnum = Math.floor(hours);\n        if(String(hnum).length ==1 ){hnum = \"0\" + hnum;} minutes = (now - grt ) / 1000 /60 - (24 * 60 * dnum) - (60 * hnum);\n        mnum = Math.floor(minutes); if(String(mnum).length ==1 ){mnum = \"0\" + mnum;}\n        seconds = (now - grt ) / 1000 - (24 * 60 * 60 * dnum) - (60 * 60 * hnum) - (60 * mnum);\n        snum = Math.round(seconds); if(String(snum).length ==1 ){snum = \"0\" + snum;}\n        document.getElementById(\"timeDate\").innerHTML = \"Running safely for: \"+dnum+\" d \";\n        document.getElementById(\"times\").innerHTML = hnum + \" h \" + mnum + \" m \" + snum + \" s\";\n    }\nsetInterval(\"createtime()\",250);\n</script>\n</div>\n```\n本来大神[^9]是写的中文，但我的出来是乱码，就改成了英文了。\n\n\n\n## 字数和阅读时长统计\n请参见[^4]，或者请查看{% post_link word-count %}。\n\n\n## 添加google广告到post\n参见[^6]。\n\n## 隐藏网页底部 powered By Hexo\n股沟出此大神[^2]的方法。\n但事实上next已经集成了这个功能，直接在next/_config.yml里将powered改为false就可以了，像这样：\n```\nfooter：\n   xxx\n   powered: false\n   xxx\n```\n\n\n\n [^1]:https://github.com/kchen0x/hexo-reference\n [^2]:https://blog.csdn.net/as480133937/article/details/100138838\n [^3]:https://blog.csdn.net/Aoman_Hao/article/details/89416634\n [^4]:https://github.com/theme-next/hexo-symbols-count-time\n [^5]:https://wylu.me/posts/e0424f3f/\n [^6]:https://juejin.im/post/5c95d230e51d45124e35cef6#comment\n [^7]:https://blog.diqigan.cn/posts/add-background-picture-for-next.html \n [^8]:http://eternalzttz.com/hexo-next.html\n [^9]:https://www.93bok.com/Hexo网站运行时间添加/\n[^10]:https://github.com/Rozbo/hexo-abbrlink\n[^11]:https://github.com/fuchen/hexo-less\n","slug":"what-did-I-do-to-this-blog","published":1,"updated":"2024-05-26T14:17:36.846Z","comments":1,"layout":"post","photos":[],"_id":"cmh498ip40043wvouaas52xkg","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>&emsp;&emsp;原本是想记笔记，写一些技术性的东西。然而现在为止好像还没有干啥正事。那我对这个博客做了些什么呢？干了这些：</p>\n<span id=\"more\"></span>\n\n<h2 id=\"重新配置\"><a href=\"#重新配置\" class=\"headerlink\" title=\"重新配置\"></a>重新配置</h2><p>按<a href=\"/how-I-build-this-web\" title=\"这个网站是怎么来的\">这个步骤</a>重新配置了一遍。之前不知道从哪里下载的一个山寨版还是啥的，应该是老版本，很多东西都没有。所以重新下载了最新版本。折腾了好久。对了，还干了好多无用功。网上搜来的很多教程版本都比较老。别马上按着别人的办法干，先看看主题的配置文件，或官方的文档。</p>\n<h2 id=\"插入脚注\"><a href=\"#插入脚注\" class=\"headerlink\" title=\"插入脚注\"></a>插入脚注</h2><p>请参见此神仙<sup id=\"fnref:1\"><a href=\"#fn:1\" rel=\"footnote\"><span class=\"hint--top hint--error hint--medium hint--rounded hint--bounce\" aria-label=\"https://github.com/kchen0x/hexo-reference\n \">[1]</span></a></sup>。 </p>\n<h2 id=\"封面模式\"><a href=\"#封面模式\" class=\"headerlink\" title=\"封面模式\"></a>封面模式</h2><p>参见<sup id=\"fnref:11\"><a href=\"#fn:11\" rel=\"footnote\"><span class=\"hint--top hint--error hint--medium hint--rounded hint--bounce\" aria-label=\"https://github.com/fuchen/hexo-less\n\">[11]</span></a></sup>。下载这个插件：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">npm install --save hexo-less</span><br></pre></td></tr></table></figure>\n<p>语法是在封面后面加上</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;!--less--&gt;</span><br></pre></td></tr></table></figure>\n<p>这样前面的部分不会显示到文章主题部分。可以搞一张图片就完美了。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">![封面](图片地址)</span><br><span class=\"line\">&lt;!--less-&gt;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"设置标签云\"><a href=\"#设置标签云\" class=\"headerlink\" title=\"设置标签云\"></a>设置标签云</h2><p>按照这位大仙<sup id=\"fnref:3\"><a href=\"#fn:3\" rel=\"footnote\"><span class=\"hint--top hint--error hint--medium hint--rounded hint--bounce\" aria-label=\"https://blog.csdn.net/Aoman_Hao/article/details/89416634\n \">[3]</span></a></sup>的操作弄好了标签云，但是发现它不在正中啊。于是找到了tag cloud的<a href=\"https://github.com/MikeCoder/hexo-tag-cloud\">github</a>。里面有一句：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;canvas width=&quot;250&quot; height=&quot;250&quot; id=&quot;resCanvas&quot; style=&quot;width:100%&quot;&gt;</span><br></pre></td></tr></table></figure>\n<p>那个100%前面是一个冒号，而大仙<sup id=\"fnref:3\"><a href=\"#fn:3\" rel=\"footnote\"><span class=\"hint--top hint--error hint--medium hint--rounded hint--bounce\" aria-label=\"https://blog.csdn.net/Aoman_Hao/article/details/89416634\n \">[3]</span></a></sup>写做等号。我发现等号就偏右边，冒号就在正中，很奇怪。</p>\n<h2 id=\"侧边栏圆角\"><a href=\"#侧边栏圆角\" class=\"headerlink\" title=\"侧边栏圆角\"></a>侧边栏圆角</h2><p>搜索到这位大神<sup id=\"fnref:8\"><a href=\"#fn:8\" rel=\"footnote\"><span class=\"hint--top hint--error hint--medium hint--rounded hint--bounce\" aria-label=\"http://eternalzttz.com/hexo-next.html\n \">[8]</span></a></sup>。我的Scheme选的是Pisces，所以先在next&#x2F;source&#x2F;css&#x2F;_variables&#x2F;Pisces.styl里面改一下变量</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$border-radius                    = 5px;</span><br></pre></td></tr></table></figure>\n<p>然后到next&#x2F;source&#x2F;css&#x2F;_schemes&#x2F;Pisces&#x2F;_layout.styl里面的.header-inner(对应菜单栏)字段改</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">border-radius: $border-radius;</span><br></pre></td></tr></table></figure>\n<p>在.content-wrap(对应文章页面)字段改</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">border-radius: $border-radius;</span><br></pre></td></tr></table></figure>\n<p>如此改完，然后……不对劲。在主页菜单栏和文章页面确实变圆角了，然而站点概况不是圆角。然而往下拖动，直到看不到菜单栏的时候，站点概况就变圆角了，不能忍。所以可能还要改siderbar字段。可惜_layout.styl里面木有。诶，我发现有next&#x2F;source&#x2F;css&#x2F;_schemes&#x2F;Pisces&#x2F;_sidebar.styl文件。打开看。果然找到了。.sidebar字段是没有border-radius变量的，于是我添加了</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">border-radius: $border-radius;</span><br></pre></td></tr></table></figure>\n<p>除此以外，还看到了.sidebar-inner字段。也一并改了。这下就大功告成了。忘了说。这些字段的另一个变量是background，把它替换成</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">background: rgba(255,255,255,0.9);</span><br></pre></td></tr></table></figure>\n<p>就可以让博客变透明了。</p>\n<h2 id=\"站内引用语法\"><a href=\"#站内引用语法\" class=\"headerlink\" title=\"站内引用语法\"></a>站内引用语法</h2><p>这样:</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;% post_link post_name %&#125;</span><br></pre></td></tr></table></figure>\n<p>出来默认是博文题目，或者自己取个名字。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;% post_link post_name 点击查看%&#125;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"设置网站图标\"><a href=\"#设置网站图标\" class=\"headerlink\" title=\"设置网站图标\"></a>设置网站图标</h2><p>同样来自这位大神<sup id=\"fnref:2\"><a href=\"#fn:2\" rel=\"footnote\"><span class=\"hint--top hint--error hint--medium hint--rounded hint--bounce\" aria-label=\"https://blog.csdn.net/as480133937/article/details/100138838\n \">[2]</span></a></sup>。最重要的是找到自己喜欢的图片放在next&#x2F;source&#x2F;images里，然后在next&#x2F;_config.yml里这样干就好了：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">favicon:</span><br><span class=\"line\">  small: /images/j-icon-16x16.png</span><br><span class=\"line\">  medium: /images/j-icon-32x32.png</span><br><span class=\"line\">  apple_touch_icon: /images/icon.png</span><br><span class=\"line\">  safari_pinned_tab: /images/icon.png</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<h2 id=\"首页文章加框\"><a href=\"#首页文章加框\" class=\"headerlink\" title=\"首页文章加框\"></a>首页文章加框</h2><p>设置请查看<a href=\"/how-to-add-frame-in-hexo-next\" title=\"hexo next首页文章加框\">hexo next首页文章加框</a></p>\n<h2 id=\"添加版权信息\"><a href=\"#添加版权信息\" class=\"headerlink\" title=\"添加版权信息\"></a>添加版权信息</h2><p>根据此大仙<sup id=\"fnref:5\"><a href=\"#fn:5\" rel=\"footnote\"><span class=\"hint--top hint--error hint--medium hint--rounded hint--bounce\" aria-label=\"https://wylu.me/posts/e0424f3f/\n \">[5]</span></a></sup>的说明弄好了以后，发现署名”前面的cc图标老是乱码（一个叉）。那怎么可以，弄了半天没弄好。结果人家next已经集成了。在next&#x2F;_config.yml里面这样就好了。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">creative_commons:</span><br><span class=\"line\">  license: by-nc-sa</span><br><span class=\"line\">  sidebar: true</span><br><span class=\"line\">  post: true</span><br><span class=\"line\">  language:</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"加动态背景图片\"><a href=\"#加动态背景图片\" class=\"headerlink\" title=\"加动态背景图片\"></a>加动态背景图片</h2><p>根据这位大仙<sup id=\"fnref:7\"><a href=\"#fn:7\" rel=\"footnote\"><span class=\"hint--top hint--error hint--medium hint--rounded hint--bounce\" aria-label=\"https://blog.diqigan.cn/posts/add-background-picture-for-next.html \n \">[7]</span></a></sup>的方法弄的。<br>动态图片感觉太慢了。我在百度下了一个，有阳光森林，人，牛。感觉还不错，希望不要侵权。</p>\n<h2 id=\"点击头像回到主页\"><a href=\"#点击头像回到主页\" class=\"headerlink\" title=\"点击头像回到主页\"></a>点击头像回到主页</h2><p>设置请查看<a href=\"/avatar-to-homepage\" title=\"hexo next点击头像回到主页\">这篇文章</a></p>\n<h2 id=\"永久链接permalink\"><a href=\"#永久链接permalink\" class=\"headerlink\" title=\"永久链接permalink\"></a>永久链接permalink</h2><p>参见<sup id=\"fnref:10\"><a href=\"#fn:10\" rel=\"footnote\"><span class=\"hint--top hint--error hint--medium hint--rounded hint--bounce\" aria-label=\"https://github.com/Rozbo/hexo-abbrlink\n\">[10]</span></a></sup>。首先安装程序：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">npm install hexo-abbrlink --save</span><br></pre></td></tr></table></figure>\n<p>然后在_config.yml中设置：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">permalink: posts/:abbrlink/</span><br><span class=\"line\">abbrlink:</span><br><span class=\"line\">  alg: crc32</span><br><span class=\"line\">  rep: hex</span><br><span class=\"line\">permalink_defaults:</span><br><span class=\"line\">pretty_urls:</span><br><span class=\"line\">  trailing_index: false # Set to false to remove trailing &#x27;index.html&#x27; from permalinks</span><br><span class=\"line\">  trailing_html: false # Set to false to remove trailing &#x27;.html&#x27; from permalinks</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"footer添加运行时间\"><a href=\"#footer添加运行时间\" class=\"headerlink\" title=\"footer添加运行时间\"></a>footer添加运行时间</h2><p>参见<sup id=\"fnref:9\"><a href=\"#fn:9\" rel=\"footnote\"><span class=\"hint--top hint--error hint--medium hint--rounded hint--bounce\" aria-label=\"https://www.93bok.com/Hexo网站运行时间添加/\n\">[9]</span></a></sup>。找到&#x2F;next&#x2F;layout&#x2F;_partials&#x2F;footer.swig，在里面添加：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;div&gt;</span><br><span class=\"line\">&lt;span id=&quot;timeDate&quot;&gt;Loading days...&lt;/span&gt;&lt;span id=&quot;times&quot;&gt;Loading sec....&lt;/span&gt;</span><br><span class=\"line\">&lt;script&gt;</span><br><span class=\"line\">    var now = new Date();</span><br><span class=\"line\">    function createtime() &#123;</span><br><span class=\"line\">        var grt= new Date(&quot;05/26/2020 00:00:00&quot;);</span><br><span class=\"line\">        now.setTime(now.getTime()+250);</span><br><span class=\"line\">        days = (now - grt ) / 1000 / 60 / 60 / 24; dnum = Math.floor(days);</span><br><span class=\"line\">        hours = (now - grt ) / 1000 / 60 / 60 - (24 * dnum); hnum = Math.floor(hours);</span><br><span class=\"line\">        if(String(hnum).length ==1 )&#123;hnum = &quot;0&quot; + hnum;&#125; minutes = (now - grt ) / 1000 /60 - (24 * 60 * dnum) - (60 * hnum);</span><br><span class=\"line\">        mnum = Math.floor(minutes); if(String(mnum).length ==1 )&#123;mnum = &quot;0&quot; + mnum;&#125;</span><br><span class=\"line\">        seconds = (now - grt ) / 1000 - (24 * 60 * 60 * dnum) - (60 * 60 * hnum) - (60 * mnum);</span><br><span class=\"line\">        snum = Math.round(seconds); if(String(snum).length ==1 )&#123;snum = &quot;0&quot; + snum;&#125;</span><br><span class=\"line\">        document.getElementById(&quot;timeDate&quot;).innerHTML = &quot;Running safely for: &quot;+dnum+&quot; d &quot;;</span><br><span class=\"line\">        document.getElementById(&quot;times&quot;).innerHTML = hnum + &quot; h &quot; + mnum + &quot; m &quot; + snum + &quot; s&quot;;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">setInterval(&quot;createtime()&quot;,250);</span><br><span class=\"line\">&lt;/script&gt;</span><br><span class=\"line\">&lt;/div&gt;</span><br></pre></td></tr></table></figure>\n<p>本来大神<sup id=\"fnref:9\"><a href=\"#fn:9\" rel=\"footnote\"><span class=\"hint--top hint--error hint--medium hint--rounded hint--bounce\" aria-label=\"https://www.93bok.com/Hexo网站运行时间添加/\n\">[9]</span></a></sup>是写的中文，但我的出来是乱码，就改成了英文了。</p>\n<h2 id=\"字数和阅读时长统计\"><a href=\"#字数和阅读时长统计\" class=\"headerlink\" title=\"字数和阅读时长统计\"></a>字数和阅读时长统计</h2><p>请参见<sup id=\"fnref:4\"><a href=\"#fn:4\" rel=\"footnote\"><span class=\"hint--top hint--error hint--medium hint--rounded hint--bounce\" aria-label=\"https://github.com/theme-next/hexo-symbols-count-time\n \">[4]</span></a></sup>，或者请查看<a href=\"/word-count\" title=\"next网站字数统计\">next网站字数统计</a>。</p>\n<h2 id=\"添加google广告到post\"><a href=\"#添加google广告到post\" class=\"headerlink\" title=\"添加google广告到post\"></a>添加google广告到post</h2><p>参见<sup id=\"fnref:6\"><a href=\"#fn:6\" rel=\"footnote\"><span class=\"hint--top hint--error hint--medium hint--rounded hint--bounce\" aria-label=\"https://juejin.im/post/5c95d230e51d45124e35cef6#comment\n \">[6]</span></a></sup>。</p>\n<h2 id=\"隐藏网页底部-powered-By-Hexo\"><a href=\"#隐藏网页底部-powered-By-Hexo\" class=\"headerlink\" title=\"隐藏网页底部 powered By Hexo\"></a>隐藏网页底部 powered By Hexo</h2><p>股沟出此大神<sup id=\"fnref:2\"><a href=\"#fn:2\" rel=\"footnote\"><span class=\"hint--top hint--error hint--medium hint--rounded hint--bounce\" aria-label=\"https://blog.csdn.net/as480133937/article/details/100138838\n \">[2]</span></a></sup>的方法。<br>但事实上next已经集成了这个功能，直接在next&#x2F;_config.yml里将powered改为false就可以了，像这样：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">footer：</span><br><span class=\"line\">   xxx</span><br><span class=\"line\">   powered: false</span><br><span class=\"line\">   xxx</span><br></pre></td></tr></table></figure>\n\n\n\n <div id=\"footnotes\"><hr><div id=\"footnotelist\"><ol style=\"list-style: none; padding-left: 0; margin-left: 40px\"><li id=\"fn:1\"><span style=\"display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px\">1.</span><span style=\"display: inline-block; vertical-align: top; margin-left: 10px;\">https://github.com/kchen0x/hexo-reference<a href=\"#fnref:1\" rev=\"footnote\"> ↩</a></span></li><li id=\"fn:2\"><span style=\"display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px\">2.</span><span style=\"display: inline-block; vertical-align: top; margin-left: 10px;\">https://blog.csdn.net/as480133937/article/details/100138838<a href=\"#fnref:2\" rev=\"footnote\"> ↩</a></span></li><li id=\"fn:3\"><span style=\"display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px\">3.</span><span style=\"display: inline-block; vertical-align: top; margin-left: 10px;\">https://blog.csdn.net/Aoman_Hao/article/details/89416634<a href=\"#fnref:3\" rev=\"footnote\"> ↩</a></span></li><li id=\"fn:4\"><span style=\"display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px\">4.</span><span style=\"display: inline-block; vertical-align: top; margin-left: 10px;\">https://github.com/theme-next/hexo-symbols-count-time<a href=\"#fnref:4\" rev=\"footnote\"> ↩</a></span></li><li id=\"fn:5\"><span style=\"display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px\">5.</span><span style=\"display: inline-block; vertical-align: top; margin-left: 10px;\">https://wylu.me/posts/e0424f3f/<a href=\"#fnref:5\" rev=\"footnote\"> ↩</a></span></li><li id=\"fn:6\"><span style=\"display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px\">6.</span><span style=\"display: inline-block; vertical-align: top; margin-left: 10px;\">https://juejin.im/post/5c95d230e51d45124e35cef6#comment<a href=\"#fnref:6\" rev=\"footnote\"> ↩</a></span></li><li id=\"fn:7\"><span style=\"display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px\">7.</span><span style=\"display: inline-block; vertical-align: top; margin-left: 10px;\">https://blog.diqigan.cn/posts/add-background-picture-for-next.html<a href=\"#fnref:7\" rev=\"footnote\"> ↩</a></span></li><li id=\"fn:8\"><span style=\"display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px\">8.</span><span style=\"display: inline-block; vertical-align: top; margin-left: 10px;\">http://eternalzttz.com/hexo-next.html<a href=\"#fnref:8\" rev=\"footnote\"> ↩</a></span></li><li id=\"fn:9\"><span style=\"display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px\">9.</span><span style=\"display: inline-block; vertical-align: top; margin-left: 10px;\">https://www.93bok.com/Hexo网站运行时间添加/<a href=\"#fnref:9\" rev=\"footnote\"> ↩</a></span></li><li id=\"fn:10\"><span style=\"display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px\">10.</span><span style=\"display: inline-block; vertical-align: top; margin-left: 10px;\">https://github.com/Rozbo/hexo-abbrlink<a href=\"#fnref:10\" rev=\"footnote\"> ↩</a></span></li><li id=\"fn:11\"><span style=\"display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px\">11.</span><span style=\"display: inline-block; vertical-align: top; margin-left: 10px;\">https://github.com/fuchen/hexo-less<a href=\"#fnref:11\" rev=\"footnote\"> ↩</a></span></li></ol></div></div>","related_posts":["add_counter.html","how-to-encrypt.html","avatar-to-homepage.html","how-to-use-utterances.html","how-to-add-frame.html"],"length":4064,"excerpt":"<p>&emsp;&emsp;原本是想记笔记，写一些技术性的东西。然而现在为止好像还没有干啥正事。那我对这个博客做了些什么呢？干了这些：</p>","more":"<h2 id=\"重新配置\"><a href=\"#重新配置\" class=\"headerlink\" title=\"重新配置\"></a>重新配置</h2><p>按<a href=\"/how-I-build-this-web\" title=\"这个网站是怎么来的\">这个步骤</a>重新配置了一遍。之前不知道从哪里下载的一个山寨版还是啥的，应该是老版本，很多东西都没有。所以重新下载了最新版本。折腾了好久。对了，还干了好多无用功。网上搜来的很多教程版本都比较老。别马上按着别人的办法干，先看看主题的配置文件，或官方的文档。</p>\n<h2 id=\"插入脚注\"><a href=\"#插入脚注\" class=\"headerlink\" title=\"插入脚注\"></a>插入脚注</h2><p>请参见此神仙<sup id=\"fnref:1\"><a href=\"#fn:1\" rel=\"footnote\"><span class=\"hint--top hint--error hint--medium hint--rounded hint--bounce\" aria-label=\"https://github.com/kchen0x/hexo-reference\n \">[1]</span></a></sup>。 </p>\n<h2 id=\"封面模式\"><a href=\"#封面模式\" class=\"headerlink\" title=\"封面模式\"></a>封面模式</h2><p>参见<sup id=\"fnref:11\"><a href=\"#fn:11\" rel=\"footnote\"><span class=\"hint--top hint--error hint--medium hint--rounded hint--bounce\" aria-label=\"https://github.com/fuchen/hexo-less\n\">[11]</span></a></sup>。下载这个插件：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">npm install --save hexo-less</span><br></pre></td></tr></table></figure>\n<p>语法是在封面后面加上</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;!--less--&gt;</span><br></pre></td></tr></table></figure>\n<p>这样前面的部分不会显示到文章主题部分。可以搞一张图片就完美了。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">![封面](图片地址)</span><br><span class=\"line\">&lt;!--less-&gt;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"设置标签云\"><a href=\"#设置标签云\" class=\"headerlink\" title=\"设置标签云\"></a>设置标签云</h2><p>按照这位大仙<sup id=\"fnref:3\"><a href=\"#fn:3\" rel=\"footnote\"><span class=\"hint--top hint--error hint--medium hint--rounded hint--bounce\" aria-label=\"https://blog.csdn.net/Aoman_Hao/article/details/89416634\n \">[3]</span></a></sup>的操作弄好了标签云，但是发现它不在正中啊。于是找到了tag cloud的<a href=\"https://github.com/MikeCoder/hexo-tag-cloud\">github</a>。里面有一句：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;canvas width=&quot;250&quot; height=&quot;250&quot; id=&quot;resCanvas&quot; style=&quot;width:100%&quot;&gt;</span><br></pre></td></tr></table></figure>\n<p>那个100%前面是一个冒号，而大仙<sup id=\"fnref:3\"><a href=\"#fn:3\" rel=\"footnote\"><span class=\"hint--top hint--error hint--medium hint--rounded hint--bounce\" aria-label=\"https://blog.csdn.net/Aoman_Hao/article/details/89416634\n \">[3]</span></a></sup>写做等号。我发现等号就偏右边，冒号就在正中，很奇怪。</p>\n<h2 id=\"侧边栏圆角\"><a href=\"#侧边栏圆角\" class=\"headerlink\" title=\"侧边栏圆角\"></a>侧边栏圆角</h2><p>搜索到这位大神<sup id=\"fnref:8\"><a href=\"#fn:8\" rel=\"footnote\"><span class=\"hint--top hint--error hint--medium hint--rounded hint--bounce\" aria-label=\"http://eternalzttz.com/hexo-next.html\n \">[8]</span></a></sup>。我的Scheme选的是Pisces，所以先在next&#x2F;source&#x2F;css&#x2F;_variables&#x2F;Pisces.styl里面改一下变量</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$border-radius                    = 5px;</span><br></pre></td></tr></table></figure>\n<p>然后到next&#x2F;source&#x2F;css&#x2F;_schemes&#x2F;Pisces&#x2F;_layout.styl里面的.header-inner(对应菜单栏)字段改</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">border-radius: $border-radius;</span><br></pre></td></tr></table></figure>\n<p>在.content-wrap(对应文章页面)字段改</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">border-radius: $border-radius;</span><br></pre></td></tr></table></figure>\n<p>如此改完，然后……不对劲。在主页菜单栏和文章页面确实变圆角了，然而站点概况不是圆角。然而往下拖动，直到看不到菜单栏的时候，站点概况就变圆角了，不能忍。所以可能还要改siderbar字段。可惜_layout.styl里面木有。诶，我发现有next&#x2F;source&#x2F;css&#x2F;_schemes&#x2F;Pisces&#x2F;_sidebar.styl文件。打开看。果然找到了。.sidebar字段是没有border-radius变量的，于是我添加了</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">border-radius: $border-radius;</span><br></pre></td></tr></table></figure>\n<p>除此以外，还看到了.sidebar-inner字段。也一并改了。这下就大功告成了。忘了说。这些字段的另一个变量是background，把它替换成</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">background: rgba(255,255,255,0.9);</span><br></pre></td></tr></table></figure>\n<p>就可以让博客变透明了。</p>\n<h2 id=\"站内引用语法\"><a href=\"#站内引用语法\" class=\"headerlink\" title=\"站内引用语法\"></a>站内引用语法</h2><p>这样:</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;% post_link post_name %&#125;</span><br></pre></td></tr></table></figure>\n<p>出来默认是博文题目，或者自己取个名字。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;% post_link post_name 点击查看%&#125;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"设置网站图标\"><a href=\"#设置网站图标\" class=\"headerlink\" title=\"设置网站图标\"></a>设置网站图标</h2><p>同样来自这位大神<sup id=\"fnref:2\"><a href=\"#fn:2\" rel=\"footnote\"><span class=\"hint--top hint--error hint--medium hint--rounded hint--bounce\" aria-label=\"https://blog.csdn.net/as480133937/article/details/100138838\n \">[2]</span></a></sup>。最重要的是找到自己喜欢的图片放在next&#x2F;source&#x2F;images里，然后在next&#x2F;_config.yml里这样干就好了：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">favicon:</span><br><span class=\"line\">  small: /images/j-icon-16x16.png</span><br><span class=\"line\">  medium: /images/j-icon-32x32.png</span><br><span class=\"line\">  apple_touch_icon: /images/icon.png</span><br><span class=\"line\">  safari_pinned_tab: /images/icon.png</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<h2 id=\"首页文章加框\"><a href=\"#首页文章加框\" class=\"headerlink\" title=\"首页文章加框\"></a>首页文章加框</h2><p>设置请查看<a href=\"/how-to-add-frame-in-hexo-next\" title=\"hexo next首页文章加框\">hexo next首页文章加框</a></p>\n<h2 id=\"添加版权信息\"><a href=\"#添加版权信息\" class=\"headerlink\" title=\"添加版权信息\"></a>添加版权信息</h2><p>根据此大仙<sup id=\"fnref:5\"><a href=\"#fn:5\" rel=\"footnote\"><span class=\"hint--top hint--error hint--medium hint--rounded hint--bounce\" aria-label=\"https://wylu.me/posts/e0424f3f/\n \">[5]</span></a></sup>的说明弄好了以后，发现署名”前面的cc图标老是乱码（一个叉）。那怎么可以，弄了半天没弄好。结果人家next已经集成了。在next&#x2F;_config.yml里面这样就好了。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">creative_commons:</span><br><span class=\"line\">  license: by-nc-sa</span><br><span class=\"line\">  sidebar: true</span><br><span class=\"line\">  post: true</span><br><span class=\"line\">  language:</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"加动态背景图片\"><a href=\"#加动态背景图片\" class=\"headerlink\" title=\"加动态背景图片\"></a>加动态背景图片</h2><p>根据这位大仙<sup id=\"fnref:7\"><a href=\"#fn:7\" rel=\"footnote\"><span class=\"hint--top hint--error hint--medium hint--rounded hint--bounce\" aria-label=\"https://blog.diqigan.cn/posts/add-background-picture-for-next.html \n \">[7]</span></a></sup>的方法弄的。<br>动态图片感觉太慢了。我在百度下了一个，有阳光森林，人，牛。感觉还不错，希望不要侵权。</p>\n<h2 id=\"点击头像回到主页\"><a href=\"#点击头像回到主页\" class=\"headerlink\" title=\"点击头像回到主页\"></a>点击头像回到主页</h2><p>设置请查看<a href=\"/avatar-to-homepage\" title=\"hexo next点击头像回到主页\">这篇文章</a></p>\n<h2 id=\"永久链接permalink\"><a href=\"#永久链接permalink\" class=\"headerlink\" title=\"永久链接permalink\"></a>永久链接permalink</h2><p>参见<sup id=\"fnref:10\"><a href=\"#fn:10\" rel=\"footnote\"><span class=\"hint--top hint--error hint--medium hint--rounded hint--bounce\" aria-label=\"https://github.com/Rozbo/hexo-abbrlink\n\">[10]</span></a></sup>。首先安装程序：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">npm install hexo-abbrlink --save</span><br></pre></td></tr></table></figure>\n<p>然后在_config.yml中设置：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">permalink: posts/:abbrlink/</span><br><span class=\"line\">abbrlink:</span><br><span class=\"line\">  alg: crc32</span><br><span class=\"line\">  rep: hex</span><br><span class=\"line\">permalink_defaults:</span><br><span class=\"line\">pretty_urls:</span><br><span class=\"line\">  trailing_index: false # Set to false to remove trailing &#x27;index.html&#x27; from permalinks</span><br><span class=\"line\">  trailing_html: false # Set to false to remove trailing &#x27;.html&#x27; from permalinks</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"footer添加运行时间\"><a href=\"#footer添加运行时间\" class=\"headerlink\" title=\"footer添加运行时间\"></a>footer添加运行时间</h2><p>参见<sup id=\"fnref:9\"><a href=\"#fn:9\" rel=\"footnote\"><span class=\"hint--top hint--error hint--medium hint--rounded hint--bounce\" aria-label=\"https://www.93bok.com/Hexo网站运行时间添加/\n\">[9]</span></a></sup>。找到&#x2F;next&#x2F;layout&#x2F;_partials&#x2F;footer.swig，在里面添加：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;div&gt;</span><br><span class=\"line\">&lt;span id=&quot;timeDate&quot;&gt;Loading days...&lt;/span&gt;&lt;span id=&quot;times&quot;&gt;Loading sec....&lt;/span&gt;</span><br><span class=\"line\">&lt;script&gt;</span><br><span class=\"line\">    var now = new Date();</span><br><span class=\"line\">    function createtime() &#123;</span><br><span class=\"line\">        var grt= new Date(&quot;05/26/2020 00:00:00&quot;);</span><br><span class=\"line\">        now.setTime(now.getTime()+250);</span><br><span class=\"line\">        days = (now - grt ) / 1000 / 60 / 60 / 24; dnum = Math.floor(days);</span><br><span class=\"line\">        hours = (now - grt ) / 1000 / 60 / 60 - (24 * dnum); hnum = Math.floor(hours);</span><br><span class=\"line\">        if(String(hnum).length ==1 )&#123;hnum = &quot;0&quot; + hnum;&#125; minutes = (now - grt ) / 1000 /60 - (24 * 60 * dnum) - (60 * hnum);</span><br><span class=\"line\">        mnum = Math.floor(minutes); if(String(mnum).length ==1 )&#123;mnum = &quot;0&quot; + mnum;&#125;</span><br><span class=\"line\">        seconds = (now - grt ) / 1000 - (24 * 60 * 60 * dnum) - (60 * 60 * hnum) - (60 * mnum);</span><br><span class=\"line\">        snum = Math.round(seconds); if(String(snum).length ==1 )&#123;snum = &quot;0&quot; + snum;&#125;</span><br><span class=\"line\">        document.getElementById(&quot;timeDate&quot;).innerHTML = &quot;Running safely for: &quot;+dnum+&quot; d &quot;;</span><br><span class=\"line\">        document.getElementById(&quot;times&quot;).innerHTML = hnum + &quot; h &quot; + mnum + &quot; m &quot; + snum + &quot; s&quot;;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">setInterval(&quot;createtime()&quot;,250);</span><br><span class=\"line\">&lt;/script&gt;</span><br><span class=\"line\">&lt;/div&gt;</span><br></pre></td></tr></table></figure>\n<p>本来大神<sup id=\"fnref:9\"><a href=\"#fn:9\" rel=\"footnote\"><span class=\"hint--top hint--error hint--medium hint--rounded hint--bounce\" aria-label=\"https://www.93bok.com/Hexo网站运行时间添加/\n\">[9]</span></a></sup>是写的中文，但我的出来是乱码，就改成了英文了。</p>\n<h2 id=\"字数和阅读时长统计\"><a href=\"#字数和阅读时长统计\" class=\"headerlink\" title=\"字数和阅读时长统计\"></a>字数和阅读时长统计</h2><p>请参见<sup id=\"fnref:4\"><a href=\"#fn:4\" rel=\"footnote\"><span class=\"hint--top hint--error hint--medium hint--rounded hint--bounce\" aria-label=\"https://github.com/theme-next/hexo-symbols-count-time\n \">[4]</span></a></sup>，或者请查看<a href=\"/word-count\" title=\"next网站字数统计\">next网站字数统计</a>。</p>\n<h2 id=\"添加google广告到post\"><a href=\"#添加google广告到post\" class=\"headerlink\" title=\"添加google广告到post\"></a>添加google广告到post</h2><p>参见<sup id=\"fnref:6\"><a href=\"#fn:6\" rel=\"footnote\"><span class=\"hint--top hint--error hint--medium hint--rounded hint--bounce\" aria-label=\"https://juejin.im/post/5c95d230e51d45124e35cef6#comment\n \">[6]</span></a></sup>。</p>\n<h2 id=\"隐藏网页底部-powered-By-Hexo\"><a href=\"#隐藏网页底部-powered-By-Hexo\" class=\"headerlink\" title=\"隐藏网页底部 powered By Hexo\"></a>隐藏网页底部 powered By Hexo</h2><p>股沟出此大神<sup id=\"fnref:2\"><a href=\"#fn:2\" rel=\"footnote\"><span class=\"hint--top hint--error hint--medium hint--rounded hint--bounce\" aria-label=\"https://blog.csdn.net/as480133937/article/details/100138838\n \">[2]</span></a></sup>的方法。<br>但事实上next已经集成了这个功能，直接在next&#x2F;_config.yml里将powered改为false就可以了，像这样：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">footer：</span><br><span class=\"line\">   xxx</span><br><span class=\"line\">   powered: false</span><br><span class=\"line\">   xxx</span><br></pre></td></tr></table></figure>\n\n\n\n <div id=\"footnotes\"><hr><div id=\"footnotelist\"><ol style=\"list-style: none; padding-left: 0; margin-left: 40px\"><li id=\"fn:1\"><span style=\"display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px\">1.</span><span style=\"display: inline-block; vertical-align: top; margin-left: 10px;\">https://github.com/kchen0x/hexo-reference<a href=\"#fnref:1\" rev=\"footnote\"> ↩</a></span></li><li id=\"fn:2\"><span style=\"display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px\">2.</span><span style=\"display: inline-block; vertical-align: top; margin-left: 10px;\">https://blog.csdn.net/as480133937/article/details/100138838<a href=\"#fnref:2\" rev=\"footnote\"> ↩</a></span></li><li id=\"fn:3\"><span style=\"display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px\">3.</span><span style=\"display: inline-block; vertical-align: top; margin-left: 10px;\">https://blog.csdn.net/Aoman_Hao/article/details/89416634<a href=\"#fnref:3\" rev=\"footnote\"> ↩</a></span></li><li id=\"fn:4\"><span style=\"display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px\">4.</span><span style=\"display: inline-block; vertical-align: top; margin-left: 10px;\">https://github.com/theme-next/hexo-symbols-count-time<a href=\"#fnref:4\" rev=\"footnote\"> ↩</a></span></li><li id=\"fn:5\"><span style=\"display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px\">5.</span><span style=\"display: inline-block; vertical-align: top; margin-left: 10px;\">https://wylu.me/posts/e0424f3f/<a href=\"#fnref:5\" rev=\"footnote\"> ↩</a></span></li><li id=\"fn:6\"><span style=\"display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px\">6.</span><span style=\"display: inline-block; vertical-align: top; margin-left: 10px;\">https://juejin.im/post/5c95d230e51d45124e35cef6#comment<a href=\"#fnref:6\" rev=\"footnote\"> ↩</a></span></li><li id=\"fn:7\"><span style=\"display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px\">7.</span><span style=\"display: inline-block; vertical-align: top; margin-left: 10px;\">https://blog.diqigan.cn/posts/add-background-picture-for-next.html<a href=\"#fnref:7\" rev=\"footnote\"> ↩</a></span></li><li id=\"fn:8\"><span style=\"display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px\">8.</span><span style=\"display: inline-block; vertical-align: top; margin-left: 10px;\">http://eternalzttz.com/hexo-next.html<a href=\"#fnref:8\" rev=\"footnote\"> ↩</a></span></li><li id=\"fn:9\"><span style=\"display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px\">9.</span><span style=\"display: inline-block; vertical-align: top; margin-left: 10px;\">https://www.93bok.com/Hexo网站运行时间添加/<a href=\"#fnref:9\" rev=\"footnote\"> ↩</a></span></li><li id=\"fn:10\"><span style=\"display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px\">10.</span><span style=\"display: inline-block; vertical-align: top; margin-left: 10px;\">https://github.com/Rozbo/hexo-abbrlink<a href=\"#fnref:10\" rev=\"footnote\"> ↩</a></span></li><li id=\"fn:11\"><span style=\"display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px\">11.</span><span style=\"display: inline-block; vertical-align: top; margin-left: 10px;\">https://github.com/fuchen/hexo-less<a href=\"#fnref:11\" rev=\"footnote\"> ↩</a></span></li></ol></div></div>"},{"title":"sed插入和删除匹配行","abbrlink":51976,"date":"2020-06-12T15:09:54.000Z","_content":"\n&emsp;&emsp;sed功能非常强大，利用来处理文本文件不要太爽。要是能熟练掌握，在文本江湖简直随心所欲，无往而不利。我自然也想学学，不过入坑awk有点久。通常习惯了一种方式以后就难以醉心到另一种。这也大约是少林72绝技一般和尚难同时融汇多种的原因吧。一般人也很难精通多个领域。这两天在配置这个博客时遇到一些要对所有post处理的步骤。于是就尝试了sed的用法。倒是很方便。例如：\n<!-- more -->\n\n1. 匹配包含date行，在该行后添加copyright: true。\n\n``` bash\nsed -i '/date/a\\copyright: true' a.md \n```\n在行前添加就把a换做i。\n\n2. 删除包含copyright的行。\n\n``` bash\nsed -i '/copyright/d' a.md\n```\n\n3. 批量处理就这样。\n\n``` bash\nfor md in *md\ndo\n   sed -i '/copyright/d' $md\ndone\n```\n\n&emsp;&emsp;题外话，是不是觉得我找抽啊，插入了copyright之后又删掉。说来话长。我怕有人copy了我的东西不打声招呼，于是就想申明一下许可权益啊版权信息啊什么的（申明之后别人爱拿还得拿）。于是搜索到[上仙](https://juejin.im/post/5c7dd8675188251b6406e7b5)那里，根据教程开始弄。过程中就得来个批量处理，用sed添加copyright。结果出来还不错。可谁知那个“署名”前面的cc图标老是乱码（一个叉）。哎呀，我这个暴脾气（洁癖），如何受得了。于是就搜啊搜，怎么才能显示出来呢？结果，啥办法没有。最后只能根据另一位[上神](https://wylu.me/posts/e0424f3f/)的教程重新弄了一个简单的主题默认的版权信息。然后就得批处理copyright。啊，世界安静了。\n","source":"_posts/2020-06-12-learn-sed.md","raw":"---\ntitle: sed插入和删除匹配行\ncategories:\n  - Linux\ntags:\n  - sed\n  - hexo\n  - next\n  - web\nabbrlink: 51976\ndate: 2020-06-12 23:09:54\n---\n\n&emsp;&emsp;sed功能非常强大，利用来处理文本文件不要太爽。要是能熟练掌握，在文本江湖简直随心所欲，无往而不利。我自然也想学学，不过入坑awk有点久。通常习惯了一种方式以后就难以醉心到另一种。这也大约是少林72绝技一般和尚难同时融汇多种的原因吧。一般人也很难精通多个领域。这两天在配置这个博客时遇到一些要对所有post处理的步骤。于是就尝试了sed的用法。倒是很方便。例如：\n<!-- more -->\n\n1. 匹配包含date行，在该行后添加copyright: true。\n\n``` bash\nsed -i '/date/a\\copyright: true' a.md \n```\n在行前添加就把a换做i。\n\n2. 删除包含copyright的行。\n\n``` bash\nsed -i '/copyright/d' a.md\n```\n\n3. 批量处理就这样。\n\n``` bash\nfor md in *md\ndo\n   sed -i '/copyright/d' $md\ndone\n```\n\n&emsp;&emsp;题外话，是不是觉得我找抽啊，插入了copyright之后又删掉。说来话长。我怕有人copy了我的东西不打声招呼，于是就想申明一下许可权益啊版权信息啊什么的（申明之后别人爱拿还得拿）。于是搜索到[上仙](https://juejin.im/post/5c7dd8675188251b6406e7b5)那里，根据教程开始弄。过程中就得来个批量处理，用sed添加copyright。结果出来还不错。可谁知那个“署名”前面的cc图标老是乱码（一个叉）。哎呀，我这个暴脾气（洁癖），如何受得了。于是就搜啊搜，怎么才能显示出来呢？结果，啥办法没有。最后只能根据另一位[上神](https://wylu.me/posts/e0424f3f/)的教程重新弄了一个简单的主题默认的版权信息。然后就得批处理copyright。啊，世界安静了。\n","slug":"learn-sed","published":1,"updated":"2024-05-26T14:17:36.846Z","comments":1,"layout":"post","photos":[],"_id":"cmh498ip50047wvouh46p3e36","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>&emsp;&emsp;sed功能非常强大，利用来处理文本文件不要太爽。要是能熟练掌握，在文本江湖简直随心所欲，无往而不利。我自然也想学学，不过入坑awk有点久。通常习惯了一种方式以后就难以醉心到另一种。这也大约是少林72绝技一般和尚难同时融汇多种的原因吧。一般人也很难精通多个领域。这两天在配置这个博客时遇到一些要对所有post处理的步骤。于是就尝试了sed的用法。倒是很方便。例如：</p>\n<span id=\"more\"></span>\n\n<ol>\n<li>匹配包含date行，在该行后添加copyright: true。</li>\n</ol>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sed -i <span class=\"string\">&#x27;/date/a\\copyright: true&#x27;</span> a.md </span><br></pre></td></tr></table></figure>\n<p>在行前添加就把a换做i。</p>\n<ol start=\"2\">\n<li>删除包含copyright的行。</li>\n</ol>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sed -i <span class=\"string\">&#x27;/copyright/d&#x27;</span> a.md</span><br></pre></td></tr></table></figure>\n\n<ol start=\"3\">\n<li>批量处理就这样。</li>\n</ol>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">for</span> md <span class=\"keyword\">in</span> *md</span><br><span class=\"line\"><span class=\"keyword\">do</span></span><br><span class=\"line\">   sed -i <span class=\"string\">&#x27;/copyright/d&#x27;</span> <span class=\"variable\">$md</span></span><br><span class=\"line\"><span class=\"keyword\">done</span></span><br></pre></td></tr></table></figure>\n\n<p>&emsp;&emsp;题外话，是不是觉得我找抽啊，插入了copyright之后又删掉。说来话长。我怕有人copy了我的东西不打声招呼，于是就想申明一下许可权益啊版权信息啊什么的（申明之后别人爱拿还得拿）。于是搜索到<a href=\"https://juejin.im/post/5c7dd8675188251b6406e7b5\">上仙</a>那里，根据教程开始弄。过程中就得来个批量处理，用sed添加copyright。结果出来还不错。可谁知那个“署名”前面的cc图标老是乱码（一个叉）。哎呀，我这个暴脾气（洁癖），如何受得了。于是就搜啊搜，怎么才能显示出来呢？结果，啥办法没有。最后只能根据另一位<a href=\"https://wylu.me/posts/e0424f3f/\">上神</a>的教程重新弄了一个简单的主题默认的版权信息。然后就得批处理copyright。啊，世界安静了。</p>\n","related_posts":[],"length":677,"excerpt":"<p>&emsp;&emsp;sed功能非常强大，利用来处理文本文件不要太爽。要是能熟练掌握，在文本江湖简直随心所欲，无往而不利。我自然也想学学，不过入坑awk有点久。通常习惯了一种方式以后就难以醉心到另一种。这也大约是少林72绝技一般和尚难同时融汇多种的原因吧。一般人也很难精通多个领域。这两天在配置这个博客时遇到一些要对所有post处理的步骤。于是就尝试了sed的用法。倒是很方便。例如：</p>","more":"<ol>\n<li>匹配包含date行，在该行后添加copyright: true。</li>\n</ol>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sed -i <span class=\"string\">&#x27;/date/a\\copyright: true&#x27;</span> a.md </span><br></pre></td></tr></table></figure>\n<p>在行前添加就把a换做i。</p>\n<ol start=\"2\">\n<li>删除包含copyright的行。</li>\n</ol>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sed -i <span class=\"string\">&#x27;/copyright/d&#x27;</span> a.md</span><br></pre></td></tr></table></figure>\n\n<ol start=\"3\">\n<li>批量处理就这样。</li>\n</ol>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">for</span> md <span class=\"keyword\">in</span> *md</span><br><span class=\"line\"><span class=\"keyword\">do</span></span><br><span class=\"line\">   sed -i <span class=\"string\">&#x27;/copyright/d&#x27;</span> <span class=\"variable\">$md</span></span><br><span class=\"line\"><span class=\"keyword\">done</span></span><br></pre></td></tr></table></figure>\n\n<p>&emsp;&emsp;题外话，是不是觉得我找抽啊，插入了copyright之后又删掉。说来话长。我怕有人copy了我的东西不打声招呼，于是就想申明一下许可权益啊版权信息啊什么的（申明之后别人爱拿还得拿）。于是搜索到<a href=\"https://juejin.im/post/5c7dd8675188251b6406e7b5\">上仙</a>那里，根据教程开始弄。过程中就得来个批量处理，用sed添加copyright。结果出来还不错。可谁知那个“署名”前面的cc图标老是乱码（一个叉）。哎呀，我这个暴脾气（洁癖），如何受得了。于是就搜啊搜，怎么才能显示出来呢？结果，啥办法没有。最后只能根据另一位<a href=\"https://wylu.me/posts/e0424f3f/\">上神</a>的教程重新弄了一个简单的主题默认的版权信息。然后就得批处理copyright。啊，世界安静了。</p>"},{"title":"如何让Elementary OS取消自动更新检查","abbrlink":47982,"date":"2020-06-18T02:24:18.000Z","_content":"\n&emsp;&emsp;我的HP笔记本上的Linux系统安装的是Elementary OS。这是个基于Ubuntu的注重界面美观的系统。是挺漂亮的，但几乎每天那个引用中心都会跳出来，帮我检查更新。\n<!-- more -->\n![应用中心](app.png)\n&emsp;&emsp;这很烦人，尤其是还有出错，不能忍。所以必须让它停止自己更新啊。解决办法是这样。在文件/etc/apt/apt.conf.d/10periodic中将第一行的1改为0，成这样：\n```\nAPT::Periodic::Update-Package-Lists \"0\";\nAPT::Periodic::Download-Upgradeable-Packages \"0\";\nAPT::Periodic::AutocleanInterval \"0\";\n```\n0表示false，自然就不帮您自动更新了。\n","source":"_posts/2020-06-18-stop-os-update.md","raw":"---\ntitle: 如何让Elementary OS取消自动更新检查\ncategories: Linux\ntags:\n  - Linux\nabbrlink: 47982\ndate: 2020-06-18 10:24:18\n---\n\n&emsp;&emsp;我的HP笔记本上的Linux系统安装的是Elementary OS。这是个基于Ubuntu的注重界面美观的系统。是挺漂亮的，但几乎每天那个引用中心都会跳出来，帮我检查更新。\n<!-- more -->\n![应用中心](app.png)\n&emsp;&emsp;这很烦人，尤其是还有出错，不能忍。所以必须让它停止自己更新啊。解决办法是这样。在文件/etc/apt/apt.conf.d/10periodic中将第一行的1改为0，成这样：\n```\nAPT::Periodic::Update-Package-Lists \"0\";\nAPT::Periodic::Download-Upgradeable-Packages \"0\";\nAPT::Periodic::AutocleanInterval \"0\";\n```\n0表示false，自然就不帮您自动更新了。\n","slug":"stop-os-update","published":1,"updated":"2024-05-26T14:17:36.846Z","comments":1,"layout":"post","photos":[],"_id":"cmh498ip50049wvoufw2tby5o","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>&emsp;&emsp;我的HP笔记本上的Linux系统安装的是Elementary OS。这是个基于Ubuntu的注重界面美观的系统。是挺漂亮的，但几乎每天那个引用中心都会跳出来，帮我检查更新。</p>\n<span id=\"more\"></span>\n<p><img src=\"/app.png\" alt=\"应用中心\"><br>&emsp;&emsp;这很烦人，尤其是还有出错，不能忍。所以必须让它停止自己更新啊。解决办法是这样。在文件&#x2F;etc&#x2F;apt&#x2F;apt.conf.d&#x2F;10periodic中将第一行的1改为0，成这样：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">APT::Periodic::Update-Package-Lists &quot;0&quot;;</span><br><span class=\"line\">APT::Periodic::Download-Upgradeable-Packages &quot;0&quot;;</span><br><span class=\"line\">APT::Periodic::AutocleanInterval &quot;0&quot;;</span><br></pre></td></tr></table></figure>\n<p>0表示false，自然就不帮您自动更新了。</p>\n","related_posts":[],"length":393,"excerpt":"<p>&emsp;&emsp;我的HP笔记本上的Linux系统安装的是Elementary OS。这是个基于Ubuntu的注重界面美观的系统。是挺漂亮的，但几乎每天那个引用中心都会跳出来，帮我检查更新。</p>","more":"<p><img src=\"/app.png\" alt=\"应用中心\"><br>&emsp;&emsp;这很烦人，尤其是还有出错，不能忍。所以必须让它停止自己更新啊。解决办法是这样。在文件&#x2F;etc&#x2F;apt&#x2F;apt.conf.d&#x2F;10periodic中将第一行的1改为0，成这样：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">APT::Periodic::Update-Package-Lists &quot;0&quot;;</span><br><span class=\"line\">APT::Periodic::Download-Upgradeable-Packages &quot;0&quot;;</span><br><span class=\"line\">APT::Periodic::AutocleanInterval &quot;0&quot;;</span><br></pre></td></tr></table></figure>\n<p>0表示false，自然就不帮您自动更新了。</p>"},{"title":"hexo next首页文章加框","abbrlink":33070,"date":"2020-06-20T14:42:59.000Z","_content":"\n&emsp;&emsp;我的博客首页的文章列表一直是连起来的，看起来不爽。因而一直在搜索如何加边框，搜出来的是如何添加文章边框阴影效果。看起来也对。于是就开始照猫画虎。\n<!-- more -->\n\n例如这位[大仙](https://www.jianshu.com/p/428244cd2caa)说要在themes/next/source/css/\\_custom/custom.styl里面加入：\n```\n.post {\n   margin-top: 0px;\n   margin-bottom: 60px;\n   padding: 25px;\n   -webkit-box-shadow: 0 0 5px rgba(202, 203, 203, .5);\n   -moz-box-shadow: 0 0 5px rgba(202, 203, 204, .5);\n}\n\n```\n&emsp;&emsp;可是我没有custom.styl啊，连\\_custom文件夹都没有啊。咋办呢？直接建一个呗。建了以后也不行。我还一度怀疑自己的next版本不对，用不了custom.styl。\n\n&emsp;&emsp;后来又搜到这位[神仙](https://blog.csdn.net/qq_39119496/article/details/103372437?utm_medium=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.nonecase&depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.nonecase)。是这个样子干的。\n\n&emsp;&emsp;在themes/next/source/css/\\_common/components/post/post.styl中找到.post-block\n然后改成这个样子：\n```\n if xxxxx\n .post-block {\n   opacity: 0;\n   margin-top: 60px;\n   margin-bottom: 60px;\n   padding: 25px;\n   -webkit-box-shadow: 0 0 5px rgba(202, 203, 203, .5);\n   -moz-box-shadow: 0 0 5px rgba(202, 203, 204, .5);\n  }\n  .pgaination, xxxx\n```\n&emsp;&emsp;谁知我用的是copy，也没仔细看那个神仙的脚本里面可能估计将post-block中的短横线敲作了下划线。我拷贝过来试了，没用。一度以为这个边框是永远加不上了。谁知今天鬼使神差的对比了一下神仙贴出的图，发现了问题。于是改了过来，结果就可以了。我估计神仙是故意打错了，让我们这些小白出错了长记性。只可惜自己不懂css啊，懂的话就没那么麻烦了。\n\n![边框](frame.png)\n\n&emsp;&emsp;这个边框效果还凑合吧。\n","source":"_posts/2020-06-20-how-to-add-frame-in-hexo-next.md","raw":"---\ntitle: hexo next首页文章加框\ncategories: web\ntags:\n  - hexo\n  - blog\nabbrlink: 33070\ndate: 2020-06-20 22:42:59\n---\n\n&emsp;&emsp;我的博客首页的文章列表一直是连起来的，看起来不爽。因而一直在搜索如何加边框，搜出来的是如何添加文章边框阴影效果。看起来也对。于是就开始照猫画虎。\n<!-- more -->\n\n例如这位[大仙](https://www.jianshu.com/p/428244cd2caa)说要在themes/next/source/css/\\_custom/custom.styl里面加入：\n```\n.post {\n   margin-top: 0px;\n   margin-bottom: 60px;\n   padding: 25px;\n   -webkit-box-shadow: 0 0 5px rgba(202, 203, 203, .5);\n   -moz-box-shadow: 0 0 5px rgba(202, 203, 204, .5);\n}\n\n```\n&emsp;&emsp;可是我没有custom.styl啊，连\\_custom文件夹都没有啊。咋办呢？直接建一个呗。建了以后也不行。我还一度怀疑自己的next版本不对，用不了custom.styl。\n\n&emsp;&emsp;后来又搜到这位[神仙](https://blog.csdn.net/qq_39119496/article/details/103372437?utm_medium=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.nonecase&depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.nonecase)。是这个样子干的。\n\n&emsp;&emsp;在themes/next/source/css/\\_common/components/post/post.styl中找到.post-block\n然后改成这个样子：\n```\n if xxxxx\n .post-block {\n   opacity: 0;\n   margin-top: 60px;\n   margin-bottom: 60px;\n   padding: 25px;\n   -webkit-box-shadow: 0 0 5px rgba(202, 203, 203, .5);\n   -moz-box-shadow: 0 0 5px rgba(202, 203, 204, .5);\n  }\n  .pgaination, xxxx\n```\n&emsp;&emsp;谁知我用的是copy，也没仔细看那个神仙的脚本里面可能估计将post-block中的短横线敲作了下划线。我拷贝过来试了，没用。一度以为这个边框是永远加不上了。谁知今天鬼使神差的对比了一下神仙贴出的图，发现了问题。于是改了过来，结果就可以了。我估计神仙是故意打错了，让我们这些小白出错了长记性。只可惜自己不懂css啊，懂的话就没那么麻烦了。\n\n![边框](frame.png)\n\n&emsp;&emsp;这个边框效果还凑合吧。\n","slug":"how-to-add-frame-in-hexo-next","published":1,"updated":"2024-05-26T14:17:36.846Z","comments":1,"layout":"post","photos":[],"_id":"cmh498ip6004cwvou67j4f5om","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>&emsp;&emsp;我的博客首页的文章列表一直是连起来的，看起来不爽。因而一直在搜索如何加边框，搜出来的是如何添加文章边框阴影效果。看起来也对。于是就开始照猫画虎。</p>\n<span id=\"more\"></span>\n\n<p>例如这位<a href=\"https://www.jianshu.com/p/428244cd2caa\">大仙</a>说要在themes&#x2F;next&#x2F;source&#x2F;css&#x2F;_custom&#x2F;custom.styl里面加入：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">.post &#123;</span><br><span class=\"line\">   margin-top: 0px;</span><br><span class=\"line\">   margin-bottom: 60px;</span><br><span class=\"line\">   padding: 25px;</span><br><span class=\"line\">   -webkit-box-shadow: 0 0 5px rgba(202, 203, 203, .5);</span><br><span class=\"line\">   -moz-box-shadow: 0 0 5px rgba(202, 203, 204, .5);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<p>&emsp;&emsp;可是我没有custom.styl啊，连_custom文件夹都没有啊。咋办呢？直接建一个呗。建了以后也不行。我还一度怀疑自己的next版本不对，用不了custom.styl。</p>\n<p>&emsp;&emsp;后来又搜到这位<a href=\"https://blog.csdn.net/qq_39119496/article/details/103372437?utm_medium=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.nonecase&depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.nonecase\">神仙</a>。是这个样子干的。</p>\n<p>&emsp;&emsp;在themes&#x2F;next&#x2F;source&#x2F;css&#x2F;_common&#x2F;components&#x2F;post&#x2F;post.styl中找到.post-block<br>然后改成这个样子：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">if xxxxx</span><br><span class=\"line\">.post-block &#123;</span><br><span class=\"line\">  opacity: 0;</span><br><span class=\"line\">  margin-top: 60px;</span><br><span class=\"line\">  margin-bottom: 60px;</span><br><span class=\"line\">  padding: 25px;</span><br><span class=\"line\">  -webkit-box-shadow: 0 0 5px rgba(202, 203, 203, .5);</span><br><span class=\"line\">  -moz-box-shadow: 0 0 5px rgba(202, 203, 204, .5);</span><br><span class=\"line\"> &#125;</span><br><span class=\"line\"> .pgaination, xxxx</span><br></pre></td></tr></table></figure>\n<p>&emsp;&emsp;谁知我用的是copy，也没仔细看那个神仙的脚本里面可能估计将post-block中的短横线敲作了下划线。我拷贝过来试了，没用。一度以为这个边框是永远加不上了。谁知今天鬼使神差的对比了一下神仙贴出的图，发现了问题。于是改了过来，结果就可以了。我估计神仙是故意打错了，让我们这些小白出错了长记性。只可惜自己不懂css啊，懂的话就没那么麻烦了。</p>\n<p><img src=\"/frame.png\" alt=\"边框\"></p>\n<p>&emsp;&emsp;这个边框效果还凑合吧。</p>\n","related_posts":["how-to-add-frame.html","reward-configuration.html"],"length":985,"excerpt":"<p>&emsp;&emsp;我的博客首页的文章列表一直是连起来的，看起来不爽。因而一直在搜索如何加边框，搜出来的是如何添加文章边框阴影效果。看起来也对。于是就开始照猫画虎。</p>","more":"<p>例如这位<a href=\"https://www.jianshu.com/p/428244cd2caa\">大仙</a>说要在themes&#x2F;next&#x2F;source&#x2F;css&#x2F;_custom&#x2F;custom.styl里面加入：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">.post &#123;</span><br><span class=\"line\">   margin-top: 0px;</span><br><span class=\"line\">   margin-bottom: 60px;</span><br><span class=\"line\">   padding: 25px;</span><br><span class=\"line\">   -webkit-box-shadow: 0 0 5px rgba(202, 203, 203, .5);</span><br><span class=\"line\">   -moz-box-shadow: 0 0 5px rgba(202, 203, 204, .5);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<p>&emsp;&emsp;可是我没有custom.styl啊，连_custom文件夹都没有啊。咋办呢？直接建一个呗。建了以后也不行。我还一度怀疑自己的next版本不对，用不了custom.styl。</p>\n<p>&emsp;&emsp;后来又搜到这位<a href=\"https://blog.csdn.net/qq_39119496/article/details/103372437?utm_medium=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.nonecase&depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.nonecase\">神仙</a>。是这个样子干的。</p>\n<p>&emsp;&emsp;在themes&#x2F;next&#x2F;source&#x2F;css&#x2F;_common&#x2F;components&#x2F;post&#x2F;post.styl中找到.post-block<br>然后改成这个样子：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">if xxxxx</span><br><span class=\"line\">.post-block &#123;</span><br><span class=\"line\">  opacity: 0;</span><br><span class=\"line\">  margin-top: 60px;</span><br><span class=\"line\">  margin-bottom: 60px;</span><br><span class=\"line\">  padding: 25px;</span><br><span class=\"line\">  -webkit-box-shadow: 0 0 5px rgba(202, 203, 203, .5);</span><br><span class=\"line\">  -moz-box-shadow: 0 0 5px rgba(202, 203, 204, .5);</span><br><span class=\"line\"> &#125;</span><br><span class=\"line\"> .pgaination, xxxx</span><br></pre></td></tr></table></figure>\n<p>&emsp;&emsp;谁知我用的是copy，也没仔细看那个神仙的脚本里面可能估计将post-block中的短横线敲作了下划线。我拷贝过来试了，没用。一度以为这个边框是永远加不上了。谁知今天鬼使神差的对比了一下神仙贴出的图，发现了问题。于是改了过来，结果就可以了。我估计神仙是故意打错了，让我们这些小白出错了长记性。只可惜自己不懂css啊，懂的话就没那么麻烦了。</p>\n<p><img src=\"/frame.png\" alt=\"边框\"></p>\n<p>&emsp;&emsp;这个边框效果还凑合吧。</p>"},{"title":"How to install and backup mediawiki","abbrlink":10861,"date":"2020-06-22T02:18:19.000Z","_content":"Meidawiki is a good tool to organise the information and knowledge. I even use it to keep some notes. My first mediawiki was established like in 2012. There are some important informations in my database. Therefore I hope to keep it and run it in every Laptop. This blog keeps the steps on how to install and backup it.\n\n<!-- more -->\n\n## intall mediawiki \n\nI installed the mediawiki in Elementary OS (Ubuntu), so steps of installing mediawiki are like:\n\n### install dependents: \n```\nsudo apt-get install apache2 mysql-server php5 php5-mysql libapache2-mod-php5\n```\n\n### install mediawiki:\nThere are two ways to do that:\n\n#### The systematic way:\n```\n sudo apt-get install mediawiki (this will install a low version)\n```\n\n#### Manual:\n\nstep1: download an upgraded version:\n```\nwget https://releases.wikimedia.org/mediawiki/1.33/mediawiki-1.33.0.tar.gz\n```\nextract them and put them into /var/lib/mediawiki\n\nstep 2: Create a database ( in mysql )\n\n1. Check and see if the database server is running; for example, run \n```\n/usr/local/mysql/bin/mysqladmin status\n```\nIf it is not, run mysqld_safe to start it: \n```\nsudo /usr/local/mysql/bin/mysqld_safe &\n```\n\n2. Set a password for the \"root\" account on your database server. \n```\n/usr/local/mysql/bin/mysqladmin -u root password yourpassword\n```\n3. Run the MySQL command-line client: \n```\n/usr/local/mysql/bin/mysql -u root -p\n```\n4. Run command in the mysql command-line:\n\n```\ncreate database wikidb;\nGRANT ALL ON my_wiki.* TO 'new_mysql_user'@'localhost';\ngrant index, create, select, insert, update, delete, alter, lock tables on wikidb.* to 'wikiuser'@'localhost' identified by 'password’;\n```\nproblem? sometimes this message may show up: \n\n```\nconnection error: Access denied for user 'root'@'localhost' (localhost)\n```\n\nIn my case, I found a solvation:\n```\nsudo mysql -u root\nuse mysql;\nupdate user set plugin='mysql_native_password' where User='root';\nflush privileges;\nquit\nreboot\n```\n\nstep3: go to 127.0.0.1/mediawiki in your browser, follow the steps.\n\n## Back up wikidb:\nAll information are restored in mySQL database, so backup it with command:\n```\nmysqldump -u[user] -p[password] [databasename] > [dump_name]\n```\nIn my case, it goes like:\n```\nmysqldump -u root -p wikidb >wikidb.mysql\n```\nMy database is in wikidb.mysql. And I do not want to do this by typing them in the terminal. In replacement, I use crontab, edit crontab:\n```\ncrontab -e\n```\nwith a new task:\n```\n0 12 * * 1 mysqldump -u root -p wikidb >/home/junxie/work/wikidb.mysql\n```\nThis means to run backup command in the noon every Monday.\n\n## Restore a wikidb in a new computer:\nIf you move in to another computer, after installing the mediawiki, run the following commend to restore the backup one.\n```\nmysql -u[user] -p[password] [database_name] < [dump_name]\n```\nIn my case, it is:\n```\nmysql -u root -p wikidb <wikidb.mysql\n```\nHave fun ^_^\n","source":"_posts/2020-06-22-install-and-backup-mediawiki.md","raw":"---\ntitle: How to install and backup mediawiki\ncategories: Linux\ntags:\n  - wiki\nabbrlink: 10861\ndate: 2020-06-22 10:18:19\n---\nMeidawiki is a good tool to organise the information and knowledge. I even use it to keep some notes. My first mediawiki was established like in 2012. There are some important informations in my database. Therefore I hope to keep it and run it in every Laptop. This blog keeps the steps on how to install and backup it.\n\n<!-- more -->\n\n## intall mediawiki \n\nI installed the mediawiki in Elementary OS (Ubuntu), so steps of installing mediawiki are like:\n\n### install dependents: \n```\nsudo apt-get install apache2 mysql-server php5 php5-mysql libapache2-mod-php5\n```\n\n### install mediawiki:\nThere are two ways to do that:\n\n#### The systematic way:\n```\n sudo apt-get install mediawiki (this will install a low version)\n```\n\n#### Manual:\n\nstep1: download an upgraded version:\n```\nwget https://releases.wikimedia.org/mediawiki/1.33/mediawiki-1.33.0.tar.gz\n```\nextract them and put them into /var/lib/mediawiki\n\nstep 2: Create a database ( in mysql )\n\n1. Check and see if the database server is running; for example, run \n```\n/usr/local/mysql/bin/mysqladmin status\n```\nIf it is not, run mysqld_safe to start it: \n```\nsudo /usr/local/mysql/bin/mysqld_safe &\n```\n\n2. Set a password for the \"root\" account on your database server. \n```\n/usr/local/mysql/bin/mysqladmin -u root password yourpassword\n```\n3. Run the MySQL command-line client: \n```\n/usr/local/mysql/bin/mysql -u root -p\n```\n4. Run command in the mysql command-line:\n\n```\ncreate database wikidb;\nGRANT ALL ON my_wiki.* TO 'new_mysql_user'@'localhost';\ngrant index, create, select, insert, update, delete, alter, lock tables on wikidb.* to 'wikiuser'@'localhost' identified by 'password’;\n```\nproblem? sometimes this message may show up: \n\n```\nconnection error: Access denied for user 'root'@'localhost' (localhost)\n```\n\nIn my case, I found a solvation:\n```\nsudo mysql -u root\nuse mysql;\nupdate user set plugin='mysql_native_password' where User='root';\nflush privileges;\nquit\nreboot\n```\n\nstep3: go to 127.0.0.1/mediawiki in your browser, follow the steps.\n\n## Back up wikidb:\nAll information are restored in mySQL database, so backup it with command:\n```\nmysqldump -u[user] -p[password] [databasename] > [dump_name]\n```\nIn my case, it goes like:\n```\nmysqldump -u root -p wikidb >wikidb.mysql\n```\nMy database is in wikidb.mysql. And I do not want to do this by typing them in the terminal. In replacement, I use crontab, edit crontab:\n```\ncrontab -e\n```\nwith a new task:\n```\n0 12 * * 1 mysqldump -u root -p wikidb >/home/junxie/work/wikidb.mysql\n```\nThis means to run backup command in the noon every Monday.\n\n## Restore a wikidb in a new computer:\nIf you move in to another computer, after installing the mediawiki, run the following commend to restore the backup one.\n```\nmysql -u[user] -p[password] [database_name] < [dump_name]\n```\nIn my case, it is:\n```\nmysql -u root -p wikidb <wikidb.mysql\n```\nHave fun ^_^\n","slug":"install-and-backup-mediawiki","published":1,"updated":"2024-05-26T14:17:36.846Z","comments":1,"layout":"post","photos":[],"_id":"cmh498ip6004ewvouc2h623rn","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>Meidawiki is a good tool to organise the information and knowledge. I even use it to keep some notes. My first mediawiki was established like in 2012. There are some important informations in my database. Therefore I hope to keep it and run it in every Laptop. This blog keeps the steps on how to install and backup it.</p>\n<span id=\"more\"></span>\n\n<h2 id=\"intall-mediawiki\"><a href=\"#intall-mediawiki\" class=\"headerlink\" title=\"intall mediawiki\"></a>intall mediawiki</h2><p>I installed the mediawiki in Elementary OS (Ubuntu), so steps of installing mediawiki are like:</p>\n<h3 id=\"install-dependents\"><a href=\"#install-dependents\" class=\"headerlink\" title=\"install dependents:\"></a>install dependents:</h3><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo apt-get install apache2 mysql-server php5 php5-mysql libapache2-mod-php5</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"install-mediawiki\"><a href=\"#install-mediawiki\" class=\"headerlink\" title=\"install mediawiki:\"></a>install mediawiki:</h3><p>There are two ways to do that:</p>\n<h4 id=\"The-systematic-way\"><a href=\"#The-systematic-way\" class=\"headerlink\" title=\"The systematic way:\"></a>The systematic way:</h4><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo apt-get install mediawiki (this will install a low version)</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"Manual\"><a href=\"#Manual\" class=\"headerlink\" title=\"Manual:\"></a>Manual:</h4><p>step1: download an upgraded version:</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">wget https://releases.wikimedia.org/mediawiki/1.33/mediawiki-1.33.0.tar.gz</span><br></pre></td></tr></table></figure>\n<p>extract them and put them into &#x2F;var&#x2F;lib&#x2F;mediawiki</p>\n<p>step 2: Create a database ( in mysql )</p>\n<ol>\n<li><p>Check and see if the database server is running; for example, run </p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">/usr/local/mysql/bin/mysqladmin status</span><br></pre></td></tr></table></figure>\n<p>If it is not, run mysqld_safe to start it: </p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo /usr/local/mysql/bin/mysqld_safe &amp;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>Set a password for the “root” account on your database server. </p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">/usr/local/mysql/bin/mysqladmin -u root password yourpassword</span><br></pre></td></tr></table></figure></li>\n<li><p>Run the MySQL command-line client: </p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">/usr/local/mysql/bin/mysql -u root -p</span><br></pre></td></tr></table></figure></li>\n<li><p>Run command in the mysql command-line:</p>\n</li>\n</ol>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">create database wikidb;</span><br><span class=\"line\">GRANT ALL ON my_wiki.* TO &#x27;new_mysql_user&#x27;@&#x27;localhost&#x27;;</span><br><span class=\"line\">grant index, create, select, insert, update, delete, alter, lock tables on wikidb.* to &#x27;wikiuser&#x27;@&#x27;localhost&#x27; identified by &#x27;password’;</span><br></pre></td></tr></table></figure>\n<p>problem? sometimes this message may show up: </p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">connection error: Access denied for user &#x27;root&#x27;@&#x27;localhost&#x27; (localhost)</span><br></pre></td></tr></table></figure>\n\n<p>In my case, I found a solvation:</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo mysql -u root</span><br><span class=\"line\">use mysql;</span><br><span class=\"line\">update user set plugin=&#x27;mysql_native_password&#x27; where User=&#x27;root&#x27;;</span><br><span class=\"line\">flush privileges;</span><br><span class=\"line\">quit</span><br><span class=\"line\">reboot</span><br></pre></td></tr></table></figure>\n\n<p>step3: go to 127.0.0.1&#x2F;mediawiki in your browser, follow the steps.</p>\n<h2 id=\"Back-up-wikidb\"><a href=\"#Back-up-wikidb\" class=\"headerlink\" title=\"Back up wikidb:\"></a>Back up wikidb:</h2><p>All information are restored in mySQL database, so backup it with command:</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysqldump -u[user] -p[password] [databasename] &gt; [dump_name]</span><br></pre></td></tr></table></figure>\n<p>In my case, it goes like:</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysqldump -u root -p wikidb &gt;wikidb.mysql</span><br></pre></td></tr></table></figure>\n<p>My database is in wikidb.mysql. And I do not want to do this by typing them in the terminal. In replacement, I use crontab, edit crontab:</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">crontab -e</span><br></pre></td></tr></table></figure>\n<p>with a new task:</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">0 12 * * 1 mysqldump -u root -p wikidb &gt;/home/junxie/work/wikidb.mysql</span><br></pre></td></tr></table></figure>\n<p>This means to run backup command in the noon every Monday.</p>\n<h2 id=\"Restore-a-wikidb-in-a-new-computer\"><a href=\"#Restore-a-wikidb-in-a-new-computer\" class=\"headerlink\" title=\"Restore a wikidb in a new computer:\"></a>Restore a wikidb in a new computer:</h2><p>If you move in to another computer, after installing the mediawiki, run the following commend to restore the backup one.</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysql -u[user] -p[password] [database_name] &lt; [dump_name]</span><br></pre></td></tr></table></figure>\n<p>In my case, it is:</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysql -u root -p wikidb &lt;wikidb.mysql</span><br></pre></td></tr></table></figure>\n<p>Have fun ^_^</p>\n","related_posts":["efficient-shell-script.html","no-file-found-in-LaTeX.html","code-and-project1.html","how-to-set-X11-in-fedora.html","fedora-install-freshress.html"],"length":2411,"excerpt":"<p>Meidawiki is a good tool to organise the information and knowledge. I even use it to keep some notes. My first mediawiki was established like in 2012. There are some important informations in my database. Therefore I hope to keep it and run it in every Laptop. This blog keeps the steps on how to install and backup it.</p>","more":"<h2 id=\"intall-mediawiki\"><a href=\"#intall-mediawiki\" class=\"headerlink\" title=\"intall mediawiki\"></a>intall mediawiki</h2><p>I installed the mediawiki in Elementary OS (Ubuntu), so steps of installing mediawiki are like:</p>\n<h3 id=\"install-dependents\"><a href=\"#install-dependents\" class=\"headerlink\" title=\"install dependents:\"></a>install dependents:</h3><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo apt-get install apache2 mysql-server php5 php5-mysql libapache2-mod-php5</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"install-mediawiki\"><a href=\"#install-mediawiki\" class=\"headerlink\" title=\"install mediawiki:\"></a>install mediawiki:</h3><p>There are two ways to do that:</p>\n<h4 id=\"The-systematic-way\"><a href=\"#The-systematic-way\" class=\"headerlink\" title=\"The systematic way:\"></a>The systematic way:</h4><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo apt-get install mediawiki (this will install a low version)</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"Manual\"><a href=\"#Manual\" class=\"headerlink\" title=\"Manual:\"></a>Manual:</h4><p>step1: download an upgraded version:</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">wget https://releases.wikimedia.org/mediawiki/1.33/mediawiki-1.33.0.tar.gz</span><br></pre></td></tr></table></figure>\n<p>extract them and put them into &#x2F;var&#x2F;lib&#x2F;mediawiki</p>\n<p>step 2: Create a database ( in mysql )</p>\n<ol>\n<li><p>Check and see if the database server is running; for example, run </p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">/usr/local/mysql/bin/mysqladmin status</span><br></pre></td></tr></table></figure>\n<p>If it is not, run mysqld_safe to start it: </p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo /usr/local/mysql/bin/mysqld_safe &amp;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>Set a password for the “root” account on your database server. </p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">/usr/local/mysql/bin/mysqladmin -u root password yourpassword</span><br></pre></td></tr></table></figure></li>\n<li><p>Run the MySQL command-line client: </p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">/usr/local/mysql/bin/mysql -u root -p</span><br></pre></td></tr></table></figure></li>\n<li><p>Run command in the mysql command-line:</p>\n</li>\n</ol>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">create database wikidb;</span><br><span class=\"line\">GRANT ALL ON my_wiki.* TO &#x27;new_mysql_user&#x27;@&#x27;localhost&#x27;;</span><br><span class=\"line\">grant index, create, select, insert, update, delete, alter, lock tables on wikidb.* to &#x27;wikiuser&#x27;@&#x27;localhost&#x27; identified by &#x27;password’;</span><br></pre></td></tr></table></figure>\n<p>problem? sometimes this message may show up: </p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">connection error: Access denied for user &#x27;root&#x27;@&#x27;localhost&#x27; (localhost)</span><br></pre></td></tr></table></figure>\n\n<p>In my case, I found a solvation:</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo mysql -u root</span><br><span class=\"line\">use mysql;</span><br><span class=\"line\">update user set plugin=&#x27;mysql_native_password&#x27; where User=&#x27;root&#x27;;</span><br><span class=\"line\">flush privileges;</span><br><span class=\"line\">quit</span><br><span class=\"line\">reboot</span><br></pre></td></tr></table></figure>\n\n<p>step3: go to 127.0.0.1&#x2F;mediawiki in your browser, follow the steps.</p>\n<h2 id=\"Back-up-wikidb\"><a href=\"#Back-up-wikidb\" class=\"headerlink\" title=\"Back up wikidb:\"></a>Back up wikidb:</h2><p>All information are restored in mySQL database, so backup it with command:</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysqldump -u[user] -p[password] [databasename] &gt; [dump_name]</span><br></pre></td></tr></table></figure>\n<p>In my case, it goes like:</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysqldump -u root -p wikidb &gt;wikidb.mysql</span><br></pre></td></tr></table></figure>\n<p>My database is in wikidb.mysql. And I do not want to do this by typing them in the terminal. In replacement, I use crontab, edit crontab:</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">crontab -e</span><br></pre></td></tr></table></figure>\n<p>with a new task:</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">0 12 * * 1 mysqldump -u root -p wikidb &gt;/home/junxie/work/wikidb.mysql</span><br></pre></td></tr></table></figure>\n<p>This means to run backup command in the noon every Monday.</p>\n<h2 id=\"Restore-a-wikidb-in-a-new-computer\"><a href=\"#Restore-a-wikidb-in-a-new-computer\" class=\"headerlink\" title=\"Restore a wikidb in a new computer:\"></a>Restore a wikidb in a new computer:</h2><p>If you move in to another computer, after installing the mediawiki, run the following commend to restore the backup one.</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysql -u[user] -p[password] [database_name] &lt; [dump_name]</span><br></pre></td></tr></table></figure>\n<p>In my case, it is:</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysql -u root -p wikidb &lt;wikidb.mysql</span><br></pre></td></tr></table></figure>\n<p>Have fun ^_^</p>"},{"title":"hexo next点击头像回到主页","abbrlink":26129,"date":"2020-06-23T01:58:16.000Z","_content":"\n&emsp;&emsp;有了头像以后，看到头像一般就想点一点，点击了可以回到主页不是挺好的吗。\n<!-- more -->\n&emsp;&emsp;网上高手还是挺多。例如这位[上仙](http://eternalzttz.com/hexo-next.html)说要找到文件/themes/next/layout/_macro/sidebar.swig然后做修改。\n```\n+ <a href=\"/\">\n    <img class=\"site-author-image\" itemprop=\"image\"\n       src=\"{{ url_for( theme.avatar.url | default(theme.images + '/avatar.gif') ) }}\"\n       alt=\"{{ author }}\" />\n+ </a>\n```\n&emsp;&emsp;于是我也这么干。但是，然而，怎么我的sidebar.swig没有这个avatar.gif的语句呢。瞎折腾半天也没明白。后来试了一下：\n```\nfind . -name sidebar*\n```\n&emsp;&emsp;然后找到了themes/next/layout/_partials/sidebar/site-overview.swig。在里面做修改\n```\n+ <a href=\"/\">\n<img class=\"site-author-image\" itemprop=\"image\" alt=\"{{ author }}\"\nsrc=\"{{ url_for(theme.avatar.url) }}\">\n+ </a>\n```\nFinally, it works.\n","source":"_posts/2020-06-23-avatar-to-homepage.md","raw":"---\ntitle: hexo next点击头像回到主页\ncategories: web\ntags:\n  - web\n  - hexo\n  - next\nabbrlink: 26129\ndate: 2020-06-23 09:58:16\n---\n\n&emsp;&emsp;有了头像以后，看到头像一般就想点一点，点击了可以回到主页不是挺好的吗。\n<!-- more -->\n&emsp;&emsp;网上高手还是挺多。例如这位[上仙](http://eternalzttz.com/hexo-next.html)说要找到文件/themes/next/layout/_macro/sidebar.swig然后做修改。\n```\n+ <a href=\"/\">\n    <img class=\"site-author-image\" itemprop=\"image\"\n       src=\"{{ url_for( theme.avatar.url | default(theme.images + '/avatar.gif') ) }}\"\n       alt=\"{{ author }}\" />\n+ </a>\n```\n&emsp;&emsp;于是我也这么干。但是，然而，怎么我的sidebar.swig没有这个avatar.gif的语句呢。瞎折腾半天也没明白。后来试了一下：\n```\nfind . -name sidebar*\n```\n&emsp;&emsp;然后找到了themes/next/layout/_partials/sidebar/site-overview.swig。在里面做修改\n```\n+ <a href=\"/\">\n<img class=\"site-author-image\" itemprop=\"image\" alt=\"{{ author }}\"\nsrc=\"{{ url_for(theme.avatar.url) }}\">\n+ </a>\n```\nFinally, it works.\n","slug":"avatar-to-homepage","published":1,"updated":"2024-05-26T14:17:36.846Z","comments":1,"layout":"post","photos":[],"_id":"cmh498ip7004hwvouh3wudp4e","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>&emsp;&emsp;有了头像以后，看到头像一般就想点一点，点击了可以回到主页不是挺好的吗。</p>\n<span id=\"more\"></span>\n<p>&emsp;&emsp;网上高手还是挺多。例如这位<a href=\"http://eternalzttz.com/hexo-next.html\">上仙</a>说要找到文件&#x2F;themes&#x2F;next&#x2F;layout&#x2F;_macro&#x2F;sidebar.swig然后做修改。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">+ &lt;a href=&quot;/&quot;&gt;</span><br><span class=\"line\">    &lt;img class=&quot;site-author-image&quot; itemprop=&quot;image&quot;</span><br><span class=\"line\">       src=&quot;&#123;&#123; url_for( theme.avatar.url | default(theme.images + &#x27;/avatar.gif&#x27;) ) &#125;&#125;&quot;</span><br><span class=\"line\">       alt=&quot;&#123;&#123; author &#125;&#125;&quot; /&gt;</span><br><span class=\"line\">+ &lt;/a&gt;</span><br></pre></td></tr></table></figure>\n<p>&emsp;&emsp;于是我也这么干。但是，然而，怎么我的sidebar.swig没有这个avatar.gif的语句呢。瞎折腾半天也没明白。后来试了一下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">find . -name sidebar*</span><br></pre></td></tr></table></figure>\n<p>&emsp;&emsp;然后找到了themes&#x2F;next&#x2F;layout&#x2F;_partials&#x2F;sidebar&#x2F;site-overview.swig。在里面做修改</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">+ &lt;a href=&quot;/&quot;&gt;</span><br><span class=\"line\">&lt;img class=&quot;site-author-image&quot; itemprop=&quot;image&quot; alt=&quot;&#123;&#123; author &#125;&#125;&quot;</span><br><span class=\"line\">src=&quot;&#123;&#123; url_for(theme.avatar.url) &#125;&#125;&quot;&gt;</span><br><span class=\"line\">+ &lt;/a&gt;</span><br></pre></td></tr></table></figure>\n<p>Finally, it works.</p>\n","related_posts":["add_counter.html","what-did-I-do-to-this-blog.html","latex-math-express.html"],"length":867,"excerpt":"<p>&emsp;&emsp;有了头像以后，看到头像一般就想点一点，点击了可以回到主页不是挺好的吗。</p>","more":"<p>&emsp;&emsp;网上高手还是挺多。例如这位<a href=\"http://eternalzttz.com/hexo-next.html\">上仙</a>说要找到文件&#x2F;themes&#x2F;next&#x2F;layout&#x2F;_macro&#x2F;sidebar.swig然后做修改。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">+ &lt;a href=&quot;/&quot;&gt;</span><br><span class=\"line\">    &lt;img class=&quot;site-author-image&quot; itemprop=&quot;image&quot;</span><br><span class=\"line\">       src=&quot;&#123;&#123; url_for( theme.avatar.url | default(theme.images + &#x27;/avatar.gif&#x27;) ) &#125;&#125;&quot;</span><br><span class=\"line\">       alt=&quot;&#123;&#123; author &#125;&#125;&quot; /&gt;</span><br><span class=\"line\">+ &lt;/a&gt;</span><br></pre></td></tr></table></figure>\n<p>&emsp;&emsp;于是我也这么干。但是，然而，怎么我的sidebar.swig没有这个avatar.gif的语句呢。瞎折腾半天也没明白。后来试了一下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">find . -name sidebar*</span><br></pre></td></tr></table></figure>\n<p>&emsp;&emsp;然后找到了themes&#x2F;next&#x2F;layout&#x2F;_partials&#x2F;sidebar&#x2F;site-overview.swig。在里面做修改</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">+ &lt;a href=&quot;/&quot;&gt;</span><br><span class=\"line\">&lt;img class=&quot;site-author-image&quot; itemprop=&quot;image&quot; alt=&quot;&#123;&#123; author &#125;&#125;&quot;</span><br><span class=\"line\">src=&quot;&#123;&#123; url_for(theme.avatar.url) &#125;&#125;&quot;&gt;</span><br><span class=\"line\">+ &lt;/a&gt;</span><br></pre></td></tr></table></figure>\n<p>Finally, it works.</p>"},{"title":"gmt画时间轴","abbrlink":"b974c9ed","date":"2020-07-04T08:06:35.000Z","_content":"![gmt 时间轴](spec.png)\n<!-- less -->\n&emsp;&emsp;有些时候画图需要用到时间轴。gmt[^1]里面的时间轴是比较简单的。画basemap的时候对于对于rangeR来说加上T就好了。例如\n```\n-R1990T/1991T/0/1\n```\n&emsp;&emsp;就可以画1990年到1991年的图。然后重要的是横轴的标注annotation怎么设置，见下图：\n![时间轴单位](1.png)\n&emsp;&emsp;要让这些单位显示出来还涉及到FORMAT_DATE_MAP的设置。其设置如下图：\n![FORMAT_DATE_MAP设置](2.png)\n&emsp;&emsp;例如封面的标注就是将FORMAT_DATE_MAP设置成jjj\n```\ngmt set FORMAT_DATE_MAP jjj\n```\n&emsp;&emsp;然后在B选项用-Bsxa10D。\n[^1]:gmt版本为5.4.3，运行系统为ElmentaryOS 4.15.0-107-generic.\n","source":"_posts/2020-07-04-gmt-time-axes.md","raw":"---\ntitle: gmt画时间轴\ncategories:\n  - gmt\ntags:\n  - linux\n  - axes\nabbrlink: b974c9ed\ndate: 2020-07-04 16:06:35\n---\n![gmt 时间轴](spec.png)\n<!-- less -->\n&emsp;&emsp;有些时候画图需要用到时间轴。gmt[^1]里面的时间轴是比较简单的。画basemap的时候对于对于rangeR来说加上T就好了。例如\n```\n-R1990T/1991T/0/1\n```\n&emsp;&emsp;就可以画1990年到1991年的图。然后重要的是横轴的标注annotation怎么设置，见下图：\n![时间轴单位](1.png)\n&emsp;&emsp;要让这些单位显示出来还涉及到FORMAT_DATE_MAP的设置。其设置如下图：\n![FORMAT_DATE_MAP设置](2.png)\n&emsp;&emsp;例如封面的标注就是将FORMAT_DATE_MAP设置成jjj\n```\ngmt set FORMAT_DATE_MAP jjj\n```\n&emsp;&emsp;然后在B选项用-Bsxa10D。\n[^1]:gmt版本为5.4.3，运行系统为ElmentaryOS 4.15.0-107-generic.\n","slug":"gmt-time-axes","published":1,"updated":"2024-05-26T14:17:36.846Z","comments":1,"layout":"post","photos":[],"_id":"cmh498ip7004kwvou3ef626ye","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>&emsp;&emsp;有些时候画图需要用到时间轴。gmt<sup id=\"fnref:1\"><a href=\"#fn:1\" rel=\"footnote\"><span class=\"hint--top hint--error hint--medium hint--rounded hint--bounce\" aria-label=\"gmt版本为5.4.3，运行系统为ElmentaryOS 4.15.0-107-generic.\n\">[1]</span></a></sup>里面的时间轴是比较简单的。画basemap的时候对于对于rangeR来说加上T就好了。例如</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">-R1990T/1991T/0/1</span><br></pre></td></tr></table></figure>\n<p>&emsp;&emsp;就可以画1990年到1991年的图。然后重要的是横轴的标注annotation怎么设置，见下图：<br><img src=\"/1.png\" alt=\"时间轴单位\"><br>&emsp;&emsp;要让这些单位显示出来还涉及到FORMAT_DATE_MAP的设置。其设置如下图：<br><img src=\"/2.png\" alt=\"FORMAT_DATE_MAP设置\"><br>&emsp;&emsp;例如封面的标注就是将FORMAT_DATE_MAP设置成jjj</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">gmt set FORMAT_DATE_MAP jjj</span><br></pre></td></tr></table></figure>\n<p>&emsp;&emsp;然后在B选项用-Bsxa10D。</p>\n<div id=\"footnotes\"><hr><div id=\"footnotelist\"><ol style=\"list-style: none; padding-left: 0; margin-left: 40px\"><li id=\"fn:1\"><span style=\"display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px\">1.</span><span style=\"display: inline-block; vertical-align: top; margin-left: 10px;\">gmt版本为5.4.3，运行系统为ElmentaryOS 4.15.0-107-generic.<a href=\"#fnref:1\" rev=\"footnote\"> ↩</a></span></li></ol></div></div>","related_posts":[],"length":353,"excerpt":"<p><img src=\"/spec.png\" alt=\"gmt 时间轴\"></p>","more":"<p>&emsp;&emsp;有些时候画图需要用到时间轴。gmt<sup id=\"fnref:1\"><a href=\"#fn:1\" rel=\"footnote\"><span class=\"hint--top hint--error hint--medium hint--rounded hint--bounce\" aria-label=\"gmt版本为5.4.3，运行系统为ElmentaryOS 4.15.0-107-generic.\n\">[1]</span></a></sup>里面的时间轴是比较简单的。画basemap的时候对于对于rangeR来说加上T就好了。例如</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">-R1990T/1991T/0/1</span><br></pre></td></tr></table></figure>\n<p>&emsp;&emsp;就可以画1990年到1991年的图。然后重要的是横轴的标注annotation怎么设置，见下图：<br><img src=\"/1.png\" alt=\"时间轴单位\"><br>&emsp;&emsp;要让这些单位显示出来还涉及到FORMAT_DATE_MAP的设置。其设置如下图：<br><img src=\"/2.png\" alt=\"FORMAT_DATE_MAP设置\"><br>&emsp;&emsp;例如封面的标注就是将FORMAT_DATE_MAP设置成jjj</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">gmt set FORMAT_DATE_MAP jjj</span><br></pre></td></tr></table></figure>\n<p>&emsp;&emsp;然后在B选项用-Bsxa10D。</p>\n<div id=\"footnotes\"><hr><div id=\"footnotelist\"><ol style=\"list-style: none; padding-left: 0; margin-left: 40px\"><li id=\"fn:1\"><span style=\"display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px\">1.</span><span style=\"display: inline-block; vertical-align: top; margin-left: 10px;\">gmt版本为5.4.3，运行系统为ElmentaryOS 4.15.0-107-generic.<a href=\"#fnref:1\" rev=\"footnote\"> ↩</a></span></li></ol></div></div>"},{"title":"如何调用fftw进行Fast Fourier Transform","abbrlink":"7866e538","date":"2020-07-05T10:21:16.000Z","_content":"&emsp;&emsp;我们常常要看信号的振幅谱来进行分析，那傅里叶变换就必不可少。如果水平不错你可以试着自己写。当然有很多已经写好的包，非常方便，例如这里要讲到的fftw[^1]。\n<!-- more -->\n\n&emsp;&emsp;他的用法其实人家[主页](http://www.fftw.org/)说明文档讲的很清楚。我这里就记录一下怎么用之来对sac文件进行读取并计算fft。程序是用fortran写的，C的话可以参考fftw说明文档。\n首先把主程序贴出来：\n```\nprogram main\nuse globe_data  // 全局变量\nuse sacio       // sac 头变量\nimplicit none\ninteger i,nerr,itest\ncharacter (180) :: sacfile,tmp\ntype(sac_head) :: sachead\ncomplex(8),allocatable,dimension(:) :: s1,s2\nif (iargc().ne.2)stop 'Usage: fft sacfile '\ncall getarg(1,sacfile)    // 读参数到sacfile，即sac 文件\ncall read_sachead(trim(sacfile),sachead,nerr) //读sac文件头变量\nnpts=sachead%npts\ndt=sachead%delta\nnn=2\nnpow=1\ndo while(nn.le.npts)\n   nn=nn*2\n   npow=npow+1\nenddo\nnk=nn/2+1\nhalfn=20\ndom=dble(1.0/nn/dt)\nallocate(sig(nn,3))\ncall read_sac(trim(sacfile), sig(:,1),sachead,nerr) //读sac文件数据到sig(:,1)\nallocate(s1(nn),s2(nn))\ns1=czero\ns1(1:npts)=dcmplx(dble(sig(1:npts,1)),0.0d0)\ncall dfftw_plan_dft_1d(plan,nn,s1,s2,FFTW_FORWARD, FFTW_ESTIMATE)\ncall dfftw_execute(plan)\ncall dfftw_destroy_plan(plan)\nsachead%npts=nk\nsig(:,1)=real(dreal(s2))\ncall write_sac(trim(sacfile)//'_fft',sig(:,1),sachead,nerr) ! problem with nerr=-1\ndeallocate(sig,s1,s2)\nend program\n```\n这里sig(:,:)是个二维数组，其实用一维的就够了哈。\nsacio.f90 是一个module，定义了sac文件的头，并含有sac读写程序。需要的话给我发信息，或者邮件^_^。\nglobe_data.f90也是一个module，定义了全局变量：\n```\nmodule globe_data\ninteger,parameter :: nmax=2000000,nstmax=1000\nreal(4),dimension(4,2):: fre\nreal(4),allocatable,dimension(:,:):: sig,sigo\nreal(4),allocatable,dimension(:) :: sigt\nreal :: dt\nreal(8) :: dom\ninteger :: halfn\ninteger :: ncom,comb,npts\ninteger :: nn,npow,nk,nf\ncomplex(8),allocatable,dimension(:,:):: seisout\ncomplex(8),parameter:: czero=(0.0d0,0.0d0)\ninteger,parameter :: FFTW_ESTIMATE=64,FFTW_MEASURE=1\ninteger,parameter :: FFTW_FORWARD=-1,FFTW_BACKWARD=1\ninteger(8) :: plan,plan1,plan2,plan3\nend module\n```\n编译需要一个makefile：\n```\nFC=gfortran\nFFLAG=-lfftw3 -I /usr/include -L /usr/lib64 -fbounds-check\nobjects=call_fft.o sacio.o globe_data.o\nall:sacio.mod globe_data.mod call_fft\n.f.o:\n\t$(FC) $(FFLAG) $< -c\n%.o:%.f90\n\t$(FC) $(FFLAG) $< -c \nsacio.mod:sacio.f90\n\t$(FC) $< -c\nglobe_data.mod:globe_data.f90\n\t$(FC) $< -c\ncall_fft:$(objects)\n\t$(FC) $^ -o $@ $(FFLAG) -lm\nclean:\n\t-rm *.o *.mod \n```\n注意这里要加上-lfftw3表示调用fftw，-I给定fftw头的路径，-L给定fftw的lib。如果是按照默认路径安装的fftw，那一般都不用指定-I和-L，因为默认路径一般已经包含在编译环境里了。\n好了大功告成了，但不保证拷贝下来就能运行通过哦。有问题发邮件吧，我们再交流^_^\n\n\n\n[^1]: http://www.fftw.org/\n","source":"_posts/2020-07-05-how-to-use-fftw.md","raw":"---\ntitle: 如何调用fftw进行Fast Fourier Transform\nabbrlink: '7866e538'\ndate: 2020-07-05 18:21:16\ncategories:\ntags:\n---\n&emsp;&emsp;我们常常要看信号的振幅谱来进行分析，那傅里叶变换就必不可少。如果水平不错你可以试着自己写。当然有很多已经写好的包，非常方便，例如这里要讲到的fftw[^1]。\n<!-- more -->\n\n&emsp;&emsp;他的用法其实人家[主页](http://www.fftw.org/)说明文档讲的很清楚。我这里就记录一下怎么用之来对sac文件进行读取并计算fft。程序是用fortran写的，C的话可以参考fftw说明文档。\n首先把主程序贴出来：\n```\nprogram main\nuse globe_data  // 全局变量\nuse sacio       // sac 头变量\nimplicit none\ninteger i,nerr,itest\ncharacter (180) :: sacfile,tmp\ntype(sac_head) :: sachead\ncomplex(8),allocatable,dimension(:) :: s1,s2\nif (iargc().ne.2)stop 'Usage: fft sacfile '\ncall getarg(1,sacfile)    // 读参数到sacfile，即sac 文件\ncall read_sachead(trim(sacfile),sachead,nerr) //读sac文件头变量\nnpts=sachead%npts\ndt=sachead%delta\nnn=2\nnpow=1\ndo while(nn.le.npts)\n   nn=nn*2\n   npow=npow+1\nenddo\nnk=nn/2+1\nhalfn=20\ndom=dble(1.0/nn/dt)\nallocate(sig(nn,3))\ncall read_sac(trim(sacfile), sig(:,1),sachead,nerr) //读sac文件数据到sig(:,1)\nallocate(s1(nn),s2(nn))\ns1=czero\ns1(1:npts)=dcmplx(dble(sig(1:npts,1)),0.0d0)\ncall dfftw_plan_dft_1d(plan,nn,s1,s2,FFTW_FORWARD, FFTW_ESTIMATE)\ncall dfftw_execute(plan)\ncall dfftw_destroy_plan(plan)\nsachead%npts=nk\nsig(:,1)=real(dreal(s2))\ncall write_sac(trim(sacfile)//'_fft',sig(:,1),sachead,nerr) ! problem with nerr=-1\ndeallocate(sig,s1,s2)\nend program\n```\n这里sig(:,:)是个二维数组，其实用一维的就够了哈。\nsacio.f90 是一个module，定义了sac文件的头，并含有sac读写程序。需要的话给我发信息，或者邮件^_^。\nglobe_data.f90也是一个module，定义了全局变量：\n```\nmodule globe_data\ninteger,parameter :: nmax=2000000,nstmax=1000\nreal(4),dimension(4,2):: fre\nreal(4),allocatable,dimension(:,:):: sig,sigo\nreal(4),allocatable,dimension(:) :: sigt\nreal :: dt\nreal(8) :: dom\ninteger :: halfn\ninteger :: ncom,comb,npts\ninteger :: nn,npow,nk,nf\ncomplex(8),allocatable,dimension(:,:):: seisout\ncomplex(8),parameter:: czero=(0.0d0,0.0d0)\ninteger,parameter :: FFTW_ESTIMATE=64,FFTW_MEASURE=1\ninteger,parameter :: FFTW_FORWARD=-1,FFTW_BACKWARD=1\ninteger(8) :: plan,plan1,plan2,plan3\nend module\n```\n编译需要一个makefile：\n```\nFC=gfortran\nFFLAG=-lfftw3 -I /usr/include -L /usr/lib64 -fbounds-check\nobjects=call_fft.o sacio.o globe_data.o\nall:sacio.mod globe_data.mod call_fft\n.f.o:\n\t$(FC) $(FFLAG) $< -c\n%.o:%.f90\n\t$(FC) $(FFLAG) $< -c \nsacio.mod:sacio.f90\n\t$(FC) $< -c\nglobe_data.mod:globe_data.f90\n\t$(FC) $< -c\ncall_fft:$(objects)\n\t$(FC) $^ -o $@ $(FFLAG) -lm\nclean:\n\t-rm *.o *.mod \n```\n注意这里要加上-lfftw3表示调用fftw，-I给定fftw头的路径，-L给定fftw的lib。如果是按照默认路径安装的fftw，那一般都不用指定-I和-L，因为默认路径一般已经包含在编译环境里了。\n好了大功告成了，但不保证拷贝下来就能运行通过哦。有问题发邮件吧，我们再交流^_^\n\n\n\n[^1]: http://www.fftw.org/\n","slug":"how-to-use-fftw","published":1,"updated":"2024-05-26T14:17:36.846Z","comments":1,"layout":"post","photos":[],"_id":"cmh498ip7004owvoueyfjabr6","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>&emsp;&emsp;我们常常要看信号的振幅谱来进行分析，那傅里叶变换就必不可少。如果水平不错你可以试着自己写。当然有很多已经写好的包，非常方便，例如这里要讲到的fftw<sup id=\"fnref:1\"><a href=\"#fn:1\" rel=\"footnote\"><span class=\"hint--top hint--error hint--medium hint--rounded hint--bounce\" aria-label=\"http://www.fftw.org/\n\">[1]</span></a></sup>。</p>\n<span id=\"more\"></span>\n\n<p>&emsp;&emsp;他的用法其实人家<a href=\"http://www.fftw.org/\">主页</a>说明文档讲的很清楚。我这里就记录一下怎么用之来对sac文件进行读取并计算fft。程序是用fortran写的，C的话可以参考fftw说明文档。<br>首先把主程序贴出来：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">program main</span><br><span class=\"line\">use globe_data  // 全局变量</span><br><span class=\"line\">use sacio       // sac 头变量</span><br><span class=\"line\">implicit none</span><br><span class=\"line\">integer i,nerr,itest</span><br><span class=\"line\">character (180) :: sacfile,tmp</span><br><span class=\"line\">type(sac_head) :: sachead</span><br><span class=\"line\">complex(8),allocatable,dimension(:) :: s1,s2</span><br><span class=\"line\">if (iargc().ne.2)stop &#x27;Usage: fft sacfile &#x27;</span><br><span class=\"line\">call getarg(1,sacfile)    // 读参数到sacfile，即sac 文件</span><br><span class=\"line\">call read_sachead(trim(sacfile),sachead,nerr) //读sac文件头变量</span><br><span class=\"line\">npts=sachead%npts</span><br><span class=\"line\">dt=sachead%delta</span><br><span class=\"line\">nn=2</span><br><span class=\"line\">npow=1</span><br><span class=\"line\">do while(nn.le.npts)</span><br><span class=\"line\">   nn=nn*2</span><br><span class=\"line\">   npow=npow+1</span><br><span class=\"line\">enddo</span><br><span class=\"line\">nk=nn/2+1</span><br><span class=\"line\">halfn=20</span><br><span class=\"line\">dom=dble(1.0/nn/dt)</span><br><span class=\"line\">allocate(sig(nn,3))</span><br><span class=\"line\">call read_sac(trim(sacfile), sig(:,1),sachead,nerr) //读sac文件数据到sig(:,1)</span><br><span class=\"line\">allocate(s1(nn),s2(nn))</span><br><span class=\"line\">s1=czero</span><br><span class=\"line\">s1(1:npts)=dcmplx(dble(sig(1:npts,1)),0.0d0)</span><br><span class=\"line\">call dfftw_plan_dft_1d(plan,nn,s1,s2,FFTW_FORWARD, FFTW_ESTIMATE)</span><br><span class=\"line\">call dfftw_execute(plan)</span><br><span class=\"line\">call dfftw_destroy_plan(plan)</span><br><span class=\"line\">sachead%npts=nk</span><br><span class=\"line\">sig(:,1)=real(dreal(s2))</span><br><span class=\"line\">call write_sac(trim(sacfile)//&#x27;_fft&#x27;,sig(:,1),sachead,nerr) ! problem with nerr=-1</span><br><span class=\"line\">deallocate(sig,s1,s2)</span><br><span class=\"line\">end program</span><br></pre></td></tr></table></figure>\n<p>这里sig(:,:)是个二维数组，其实用一维的就够了哈。<br>sacio.f90 是一个module，定义了sac文件的头，并含有sac读写程序。需要的话给我发信息，或者邮件^_^。<br>globe_data.f90也是一个module，定义了全局变量：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">module globe_data</span><br><span class=\"line\">integer,parameter :: nmax=2000000,nstmax=1000</span><br><span class=\"line\">real(4),dimension(4,2):: fre</span><br><span class=\"line\">real(4),allocatable,dimension(:,:):: sig,sigo</span><br><span class=\"line\">real(4),allocatable,dimension(:) :: sigt</span><br><span class=\"line\">real :: dt</span><br><span class=\"line\">real(8) :: dom</span><br><span class=\"line\">integer :: halfn</span><br><span class=\"line\">integer :: ncom,comb,npts</span><br><span class=\"line\">integer :: nn,npow,nk,nf</span><br><span class=\"line\">complex(8),allocatable,dimension(:,:):: seisout</span><br><span class=\"line\">complex(8),parameter:: czero=(0.0d0,0.0d0)</span><br><span class=\"line\">integer,parameter :: FFTW_ESTIMATE=64,FFTW_MEASURE=1</span><br><span class=\"line\">integer,parameter :: FFTW_FORWARD=-1,FFTW_BACKWARD=1</span><br><span class=\"line\">integer(8) :: plan,plan1,plan2,plan3</span><br><span class=\"line\">end module</span><br></pre></td></tr></table></figure>\n<p>编译需要一个makefile：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">FC=gfortran</span><br><span class=\"line\">FFLAG=-lfftw3 -I /usr/include -L /usr/lib64 -fbounds-check</span><br><span class=\"line\">objects=call_fft.o sacio.o globe_data.o</span><br><span class=\"line\">all:sacio.mod globe_data.mod call_fft</span><br><span class=\"line\">.f.o:</span><br><span class=\"line\">\t$(FC) $(FFLAG) $&lt; -c</span><br><span class=\"line\">%.o:%.f90</span><br><span class=\"line\">\t$(FC) $(FFLAG) $&lt; -c </span><br><span class=\"line\">sacio.mod:sacio.f90</span><br><span class=\"line\">\t$(FC) $&lt; -c</span><br><span class=\"line\">globe_data.mod:globe_data.f90</span><br><span class=\"line\">\t$(FC) $&lt; -c</span><br><span class=\"line\">call_fft:$(objects)</span><br><span class=\"line\">\t$(FC) $^ -o $@ $(FFLAG) -lm</span><br><span class=\"line\">clean:</span><br><span class=\"line\">\t-rm *.o *.mod </span><br></pre></td></tr></table></figure>\n<p>注意这里要加上-lfftw3表示调用fftw，-I给定fftw头的路径，-L给定fftw的lib。如果是按照默认路径安装的fftw，那一般都不用指定-I和-L，因为默认路径一般已经包含在编译环境里了。<br>好了大功告成了，但不保证拷贝下来就能运行通过哦。有问题发邮件吧，我们再交流^_^</p>\n<div id=\"footnotes\"><hr><div id=\"footnotelist\"><ol style=\"list-style: none; padding-left: 0; margin-left: 40px\"><li id=\"fn:1\"><span style=\"display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px\">1.</span><span style=\"display: inline-block; vertical-align: top; margin-left: 10px;\">http://www.fftw.org/<a href=\"#fnref:1\" rev=\"footnote\"> ↩</a></span></li></ol></div></div>","related_posts":[],"length":2261,"excerpt":"<p>&emsp;&emsp;我们常常要看信号的振幅谱来进行分析，那傅里叶变换就必不可少。如果水平不错你可以试着自己写。当然有很多已经写好的包，非常方便，例如这里要讲到的fftw<sup id=\"fnref:1\"><a href=\"#fn:1\" rel=\"footnote\"><span class=\"hint--top hint--error hint--medium hint--rounded hint--bounce\" aria-label=\"http://www.fftw.org/\n\">[1]</span></a></sup>。</p>","more":"<p>&emsp;&emsp;他的用法其实人家<a href=\"http://www.fftw.org/\">主页</a>说明文档讲的很清楚。我这里就记录一下怎么用之来对sac文件进行读取并计算fft。程序是用fortran写的，C的话可以参考fftw说明文档。<br>首先把主程序贴出来：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">program main</span><br><span class=\"line\">use globe_data  // 全局变量</span><br><span class=\"line\">use sacio       // sac 头变量</span><br><span class=\"line\">implicit none</span><br><span class=\"line\">integer i,nerr,itest</span><br><span class=\"line\">character (180) :: sacfile,tmp</span><br><span class=\"line\">type(sac_head) :: sachead</span><br><span class=\"line\">complex(8),allocatable,dimension(:) :: s1,s2</span><br><span class=\"line\">if (iargc().ne.2)stop &#x27;Usage: fft sacfile &#x27;</span><br><span class=\"line\">call getarg(1,sacfile)    // 读参数到sacfile，即sac 文件</span><br><span class=\"line\">call read_sachead(trim(sacfile),sachead,nerr) //读sac文件头变量</span><br><span class=\"line\">npts=sachead%npts</span><br><span class=\"line\">dt=sachead%delta</span><br><span class=\"line\">nn=2</span><br><span class=\"line\">npow=1</span><br><span class=\"line\">do while(nn.le.npts)</span><br><span class=\"line\">   nn=nn*2</span><br><span class=\"line\">   npow=npow+1</span><br><span class=\"line\">enddo</span><br><span class=\"line\">nk=nn/2+1</span><br><span class=\"line\">halfn=20</span><br><span class=\"line\">dom=dble(1.0/nn/dt)</span><br><span class=\"line\">allocate(sig(nn,3))</span><br><span class=\"line\">call read_sac(trim(sacfile), sig(:,1),sachead,nerr) //读sac文件数据到sig(:,1)</span><br><span class=\"line\">allocate(s1(nn),s2(nn))</span><br><span class=\"line\">s1=czero</span><br><span class=\"line\">s1(1:npts)=dcmplx(dble(sig(1:npts,1)),0.0d0)</span><br><span class=\"line\">call dfftw_plan_dft_1d(plan,nn,s1,s2,FFTW_FORWARD, FFTW_ESTIMATE)</span><br><span class=\"line\">call dfftw_execute(plan)</span><br><span class=\"line\">call dfftw_destroy_plan(plan)</span><br><span class=\"line\">sachead%npts=nk</span><br><span class=\"line\">sig(:,1)=real(dreal(s2))</span><br><span class=\"line\">call write_sac(trim(sacfile)//&#x27;_fft&#x27;,sig(:,1),sachead,nerr) ! problem with nerr=-1</span><br><span class=\"line\">deallocate(sig,s1,s2)</span><br><span class=\"line\">end program</span><br></pre></td></tr></table></figure>\n<p>这里sig(:,:)是个二维数组，其实用一维的就够了哈。<br>sacio.f90 是一个module，定义了sac文件的头，并含有sac读写程序。需要的话给我发信息，或者邮件^_^。<br>globe_data.f90也是一个module，定义了全局变量：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">module globe_data</span><br><span class=\"line\">integer,parameter :: nmax=2000000,nstmax=1000</span><br><span class=\"line\">real(4),dimension(4,2):: fre</span><br><span class=\"line\">real(4),allocatable,dimension(:,:):: sig,sigo</span><br><span class=\"line\">real(4),allocatable,dimension(:) :: sigt</span><br><span class=\"line\">real :: dt</span><br><span class=\"line\">real(8) :: dom</span><br><span class=\"line\">integer :: halfn</span><br><span class=\"line\">integer :: ncom,comb,npts</span><br><span class=\"line\">integer :: nn,npow,nk,nf</span><br><span class=\"line\">complex(8),allocatable,dimension(:,:):: seisout</span><br><span class=\"line\">complex(8),parameter:: czero=(0.0d0,0.0d0)</span><br><span class=\"line\">integer,parameter :: FFTW_ESTIMATE=64,FFTW_MEASURE=1</span><br><span class=\"line\">integer,parameter :: FFTW_FORWARD=-1,FFTW_BACKWARD=1</span><br><span class=\"line\">integer(8) :: plan,plan1,plan2,plan3</span><br><span class=\"line\">end module</span><br></pre></td></tr></table></figure>\n<p>编译需要一个makefile：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">FC=gfortran</span><br><span class=\"line\">FFLAG=-lfftw3 -I /usr/include -L /usr/lib64 -fbounds-check</span><br><span class=\"line\">objects=call_fft.o sacio.o globe_data.o</span><br><span class=\"line\">all:sacio.mod globe_data.mod call_fft</span><br><span class=\"line\">.f.o:</span><br><span class=\"line\">\t$(FC) $(FFLAG) $&lt; -c</span><br><span class=\"line\">%.o:%.f90</span><br><span class=\"line\">\t$(FC) $(FFLAG) $&lt; -c </span><br><span class=\"line\">sacio.mod:sacio.f90</span><br><span class=\"line\">\t$(FC) $&lt; -c</span><br><span class=\"line\">globe_data.mod:globe_data.f90</span><br><span class=\"line\">\t$(FC) $&lt; -c</span><br><span class=\"line\">call_fft:$(objects)</span><br><span class=\"line\">\t$(FC) $^ -o $@ $(FFLAG) -lm</span><br><span class=\"line\">clean:</span><br><span class=\"line\">\t-rm *.o *.mod </span><br></pre></td></tr></table></figure>\n<p>注意这里要加上-lfftw3表示调用fftw，-I给定fftw头的路径，-L给定fftw的lib。如果是按照默认路径安装的fftw，那一般都不用指定-I和-L，因为默认路径一般已经包含在编译环境里了。<br>好了大功告成了，但不保证拷贝下来就能运行通过哦。有问题发邮件吧，我们再交流^_^</p>\n<div id=\"footnotes\"><hr><div id=\"footnotelist\"><ol style=\"list-style: none; padding-left: 0; margin-left: 40px\"><li id=\"fn:1\"><span style=\"display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px\">1.</span><span style=\"display: inline-block; vertical-align: top; margin-left: 10px;\">http://www.fftw.org/<a href=\"#fnref:1\" rev=\"footnote\"> ↩</a></span></li></ol></div></div>"},{"title":"如何访问google","abbrlink":"d02a7f6b","date":"2020-07-08T14:30:01.000Z","_content":"&emsp;&emsp;Google产品尤其是Google scholar非常的方便，对于我这种有完美主义倾向，不喜欢山寨的人来讲真的太必要了。但是由于某些原因，在国内上不了google怎么办呢？\n<!-- more -->\n&emsp;&emsp;很早就接触了google，自从墙了以后一直用的是IPv6进行访问，在号称网络配置顶尖的学校表示毫无影响。间或还尝试了一些lantern、firefly之类的，结果这些都是要钱的。去年IPv6也被强墙了。不得已花数十块钱买了一年的梯子（shadowsocks），结果因为特殊原因也给墙了。可怜我的数十块钱啊，才用了几个月，心塞。\n\n&emsp;&emsp;后来左搜右搜终于找到一个很好的方式。就是使用[ghelper插件](http://googlehelper.net/)。平时就用它来登录登录邮箱，上上google scholar，虽然稍慢，但非常方便。希望它不要被墙了啊。\n\n&emsp;&emsp;阿弥陀佛。\n","source":"_posts/2020-07-08-how-to-access-google.md","raw":"---\ntitle: 如何访问google\nabbrlink: d02a7f6b\ndate: 2020-07-08 22:30:01\ncategories:\ntags:\n---\n&emsp;&emsp;Google产品尤其是Google scholar非常的方便，对于我这种有完美主义倾向，不喜欢山寨的人来讲真的太必要了。但是由于某些原因，在国内上不了google怎么办呢？\n<!-- more -->\n&emsp;&emsp;很早就接触了google，自从墙了以后一直用的是IPv6进行访问，在号称网络配置顶尖的学校表示毫无影响。间或还尝试了一些lantern、firefly之类的，结果这些都是要钱的。去年IPv6也被强墙了。不得已花数十块钱买了一年的梯子（shadowsocks），结果因为特殊原因也给墙了。可怜我的数十块钱啊，才用了几个月，心塞。\n\n&emsp;&emsp;后来左搜右搜终于找到一个很好的方式。就是使用[ghelper插件](http://googlehelper.net/)。平时就用它来登录登录邮箱，上上google scholar，虽然稍慢，但非常方便。希望它不要被墙了啊。\n\n&emsp;&emsp;阿弥陀佛。\n","slug":"how-to-access-google","published":1,"updated":"2024-05-26T14:17:36.846Z","comments":1,"layout":"post","photos":[],"_id":"cmh498ip8004swvoug7vdh19b","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>&emsp;&emsp;Google产品尤其是Google scholar非常的方便，对于我这种有完美主义倾向，不喜欢山寨的人来讲真的太必要了。但是由于某些原因，在国内上不了google怎么办呢？</p>\n<span id=\"more\"></span>\n<p>&emsp;&emsp;很早就接触了google，自从墙了以后一直用的是IPv6进行访问，在号称网络配置顶尖的学校表示毫无影响。间或还尝试了一些lantern、firefly之类的，结果这些都是要钱的。去年IPv6也被强墙了。不得已花数十块钱买了一年的梯子（shadowsocks），结果因为特殊原因也给墙了。可怜我的数十块钱啊，才用了几个月，心塞。</p>\n<p>&emsp;&emsp;后来左搜右搜终于找到一个很好的方式。就是使用<a href=\"http://googlehelper.net/\">ghelper插件</a>。平时就用它来登录登录邮箱，上上google scholar，虽然稍慢，但非常方便。希望它不要被墙了啊。</p>\n<p>&emsp;&emsp;阿弥陀佛。</p>\n","related_posts":[],"length":383,"excerpt":"<p>&emsp;&emsp;Google产品尤其是Google scholar非常的方便，对于我这种有完美主义倾向，不喜欢山寨的人来讲真的太必要了。但是由于某些原因，在国内上不了google怎么办呢？</p>","more":"<p>&emsp;&emsp;很早就接触了google，自从墙了以后一直用的是IPv6进行访问，在号称网络配置顶尖的学校表示毫无影响。间或还尝试了一些lantern、firefly之类的，结果这些都是要钱的。去年IPv6也被强墙了。不得已花数十块钱买了一年的梯子（shadowsocks），结果因为特殊原因也给墙了。可怜我的数十块钱啊，才用了几个月，心塞。</p>\n<p>&emsp;&emsp;后来左搜右搜终于找到一个很好的方式。就是使用<a href=\"http://googlehelper.net/\">ghelper插件</a>。平时就用它来登录登录邮箱，上上google scholar，虽然稍慢，但非常方便。希望它不要被墙了啊。</p>\n<p>&emsp;&emsp;阿弥陀佛。</p>"},{"title":"现代人的智商在退步","abbrlink":"cb6f583d","date":"2020-07-10T09:10:54.000Z","_content":"![智商捉急](iq.jpg)\n图片来自一篇2018年PANS期刊的[文章](https://www.pnas.org/content/115/26/6674?fbclid=IwAR3CVcH75ppH836xV4c5s99p11421Puo6ljF9hlQtg7kcRcXDa9_mdPSfU0).\n<!-- less -->\n&emsp;&emsp;记得有一次和老板一起吃饭聊到一个疑问，就是现代人的智商比起以前的人谁的智商高？\n\n&emsp;&emsp;我记得我的想法是说现代人刺激多，所以感觉上会比以前，特别是古代人会更加聪明。老板的意思，我记得是说不见得现代人就比古代人聪明。我觉得也不无道理，特别是现代人接受太多碎片化的信息，往往难以深入思考问题，专心做事。要是像我所说一直在涨的话也总会有个头的啊，因为人的脑容量就那么多，再刺激也不能说无限的把脑容量给扩大。然而没有调查，谁也下不了结论。\n\n&emsp;&emsp;今天看到一篇发表于PNAS的文章（见封面链接），里面利用1962年到1991年挪威征兵的IQ测试数据分析智商变化。结论是近些年来人们的智商没有增高，反而在倒退。看样子还是老板对啊。笑。当然，这些数据来源于挪威，可能缺乏普遍意义，也许只能说明挪威当兵的人在变笨^_^。要得到较为严谨的结论还需要调研更多其他国家的人，以及时间跨度也得更大。\n\n&emsp;&emsp;话又说回来，IQ是用智力测试测量人在其年龄段的认知能力（“智力”）的分[^1]。他是一个测出来的分数，就有可能有测量误差，此外，测试题是否能真实反应人的智力水平也是一个巨大疑问。\n\n&emsp;&emsp;话话又说回来，IQ测试测准了又怎么样？IQ高能决定人更成功，还是能决定人快乐力更强啊？\n\n[^1]:https://zh.wikipedia.org/wiki/%E6%99%BA%E5%95%86\n","source":"_posts/2020-07-10-IQ-decrease.md","raw":"---\ntitle: 现代人的智商在退步\ncategories:\n  - 杂\ntags:\n  - 乱\nabbrlink: cb6f583d\ndate: 2020-07-10 17:10:54\n---\n![智商捉急](iq.jpg)\n图片来自一篇2018年PANS期刊的[文章](https://www.pnas.org/content/115/26/6674?fbclid=IwAR3CVcH75ppH836xV4c5s99p11421Puo6ljF9hlQtg7kcRcXDa9_mdPSfU0).\n<!-- less -->\n&emsp;&emsp;记得有一次和老板一起吃饭聊到一个疑问，就是现代人的智商比起以前的人谁的智商高？\n\n&emsp;&emsp;我记得我的想法是说现代人刺激多，所以感觉上会比以前，特别是古代人会更加聪明。老板的意思，我记得是说不见得现代人就比古代人聪明。我觉得也不无道理，特别是现代人接受太多碎片化的信息，往往难以深入思考问题，专心做事。要是像我所说一直在涨的话也总会有个头的啊，因为人的脑容量就那么多，再刺激也不能说无限的把脑容量给扩大。然而没有调查，谁也下不了结论。\n\n&emsp;&emsp;今天看到一篇发表于PNAS的文章（见封面链接），里面利用1962年到1991年挪威征兵的IQ测试数据分析智商变化。结论是近些年来人们的智商没有增高，反而在倒退。看样子还是老板对啊。笑。当然，这些数据来源于挪威，可能缺乏普遍意义，也许只能说明挪威当兵的人在变笨^_^。要得到较为严谨的结论还需要调研更多其他国家的人，以及时间跨度也得更大。\n\n&emsp;&emsp;话又说回来，IQ是用智力测试测量人在其年龄段的认知能力（“智力”）的分[^1]。他是一个测出来的分数，就有可能有测量误差，此外，测试题是否能真实反应人的智力水平也是一个巨大疑问。\n\n&emsp;&emsp;话话又说回来，IQ测试测准了又怎么样？IQ高能决定人更成功，还是能决定人快乐力更强啊？\n\n[^1]:https://zh.wikipedia.org/wiki/%E6%99%BA%E5%95%86\n","slug":"IQ-decrease","published":1,"updated":"2024-05-26T14:17:36.846Z","comments":1,"layout":"post","photos":[],"_id":"cmh498ip8004vwvouebu6bl2g","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>&emsp;&emsp;记得有一次和老板一起吃饭聊到一个疑问，就是现代人的智商比起以前的人谁的智商高？</p>\n<p>&emsp;&emsp;我记得我的想法是说现代人刺激多，所以感觉上会比以前，特别是古代人会更加聪明。老板的意思，我记得是说不见得现代人就比古代人聪明。我觉得也不无道理，特别是现代人接受太多碎片化的信息，往往难以深入思考问题，专心做事。要是像我所说一直在涨的话也总会有个头的啊，因为人的脑容量就那么多，再刺激也不能说无限的把脑容量给扩大。然而没有调查，谁也下不了结论。</p>\n<p>&emsp;&emsp;今天看到一篇发表于PNAS的文章（见封面链接），里面利用1962年到1991年挪威征兵的IQ测试数据分析智商变化。结论是近些年来人们的智商没有增高，反而在倒退。看样子还是老板对啊。笑。当然，这些数据来源于挪威，可能缺乏普遍意义，也许只能说明挪威当兵的人在变笨^_^。要得到较为严谨的结论还需要调研更多其他国家的人，以及时间跨度也得更大。</p>\n<p>&emsp;&emsp;话又说回来，IQ是用智力测试测量人在其年龄段的认知能力（“智力”）的分<sup id=\"fnref:1\"><a href=\"#fn:1\" rel=\"footnote\"><span class=\"hint--top hint--error hint--medium hint--rounded hint--bounce\" aria-label=\"https://zh.wikipedia.org/wiki/%E6%99%BA%E5%95%86\n\">[1]</span></a></sup>。他是一个测出来的分数，就有可能有测量误差，此外，测试题是否能真实反应人的智力水平也是一个巨大疑问。</p>\n<p>&emsp;&emsp;话话又说回来，IQ测试测准了又怎么样？IQ高能决定人更成功，还是能决定人快乐力更强啊？</p>\n<div id=\"footnotes\"><hr><div id=\"footnotelist\"><ol style=\"list-style: none; padding-left: 0; margin-left: 40px\"><li id=\"fn:1\"><span style=\"display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px\">1.</span><span style=\"display: inline-block; vertical-align: top; margin-left: 10px;\">https://zh.wikipedia.org/wiki/%E6%99%BA%E5%95%86<a href=\"#fnref:1\" rev=\"footnote\"> ↩</a></span></li></ol></div></div>","related_posts":[],"length":641,"excerpt":"<p><img src=\"/iq.jpg\" alt=\"智商捉急\"><br>图片来自一篇2018年PANS期刊的<a href=\"https://www.pnas.org/content/115/26/6674?fbclid=IwAR3CVcH75ppH836xV4c5s99p11421Puo6ljF9hlQtg7kcRcXDa9_mdPSfU0\">文章</a>.</p>","more":"<p>&emsp;&emsp;记得有一次和老板一起吃饭聊到一个疑问，就是现代人的智商比起以前的人谁的智商高？</p>\n<p>&emsp;&emsp;我记得我的想法是说现代人刺激多，所以感觉上会比以前，特别是古代人会更加聪明。老板的意思，我记得是说不见得现代人就比古代人聪明。我觉得也不无道理，特别是现代人接受太多碎片化的信息，往往难以深入思考问题，专心做事。要是像我所说一直在涨的话也总会有个头的啊，因为人的脑容量就那么多，再刺激也不能说无限的把脑容量给扩大。然而没有调查，谁也下不了结论。</p>\n<p>&emsp;&emsp;今天看到一篇发表于PNAS的文章（见封面链接），里面利用1962年到1991年挪威征兵的IQ测试数据分析智商变化。结论是近些年来人们的智商没有增高，反而在倒退。看样子还是老板对啊。笑。当然，这些数据来源于挪威，可能缺乏普遍意义，也许只能说明挪威当兵的人在变笨^_^。要得到较为严谨的结论还需要调研更多其他国家的人，以及时间跨度也得更大。</p>\n<p>&emsp;&emsp;话又说回来，IQ是用智力测试测量人在其年龄段的认知能力（“智力”）的分<sup id=\"fnref:1\"><a href=\"#fn:1\" rel=\"footnote\"><span class=\"hint--top hint--error hint--medium hint--rounded hint--bounce\" aria-label=\"https://zh.wikipedia.org/wiki/%E6%99%BA%E5%95%86\n\">[1]</span></a></sup>。他是一个测出来的分数，就有可能有测量误差，此外，测试题是否能真实反应人的智力水平也是一个巨大疑问。</p>\n<p>&emsp;&emsp;话话又说回来，IQ测试测准了又怎么样？IQ高能决定人更成功，还是能决定人快乐力更强啊？</p>\n<div id=\"footnotes\"><hr><div id=\"footnotelist\"><ol style=\"list-style: none; padding-left: 0; margin-left: 40px\"><li id=\"fn:1\"><span style=\"display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px\">1.</span><span style=\"display: inline-block; vertical-align: top; margin-left: 10px;\">https://zh.wikipedia.org/wiki/%E6%99%BA%E5%95%86<a href=\"#fnref:1\" rev=\"footnote\"> ↩</a></span></li></ol></div></div>"},{"title":"稍稍盘点地幔过渡带研究进展","abbrlink":"40ac122d","date":"2020-07-21T15:04:45.000Z","_content":"![地幔过渡带](Picture1.png)\n<!-- less -->\n&emsp;&emsp;不看不知道，一看吓一跳。地幔过渡带的研究热度要爆表。搜了一下2016年以来的文章，多如牛毛，而且乖乖，都是高影响因子期刊论文。\n![部分文献](Picture2.png)\n&emsp;&emsp;老板让想一下以后的方向，关于地幔结构，宜居性，热点。那就地幔过渡带的水咯。\n&emsp;&emsp;地幔过渡带是上地幔与下地幔的交接区域。深度大约为410-660公里。通过研究地幔过渡带结构以及其与上下地幔的相互作用的可以帮助我们认识地幔对流的模式，了解地幔的演化以及揭示地球内部的水循环过程。\n&emsp;&emsp;目前对地幔过渡的认识主要是认为它是相变层。上地幔中主要是橄榄石。410公里是橄榄石到瓦兹利石的相变。660是林伍德是到布里吉曼石的相变。另外过渡带中间约520km还有一个相变。两个相变面的克拉伯龙斜率是反的。意思是当温度高时410相变面会下降，660会上升，过渡带变薄，反之变厚。对地幔过渡带的研究提供的关键信息可以推断上地幔物质组成，过渡带含水量和温度。了解热柱和俯冲带与过渡带的相互作用等。\n&emsp;&emsp;大量的研究表明上地幔和下地幔的储水能力较低，可能含的水很少。而过渡带有很好的储水能力，可能包含有大量的水。Bercovici and karato(2003)认为地幔有一个广域的上涌趋势，上涌的过程因为脱水，会在410界面上面形成一个局部熔融层，表现为一个地震学的低速层。含水的地幔过渡带可以解释地球化学观测到的不相容元素和稳定同位素特性，从而支持全地幔对流模式。\n&emsp;&emsp;我们来看看近几年的地幔过渡带研究进展。刚刚提到的这个410km的低速层，近些年获得大量研究者的关注。Tauzin et al. (2010)认为全球普遍存在这个低速层，他们的观测台站较少，Wei and Shearer (2017)人发现他们的观测数据中只有30-40%有低速层。其他近些年的文章也都纷纷在不同的区域例如中国东南等发现这样的低速层(Tauzin et al., 2017; Li et al., 2019; Li et al., 2020; Xiao et al., 2020)。那这个低速层是否真的是普遍全球存在的，这个低速层的成因及与俯冲板块和热柱的关系都是研究的热点。\n&emsp;&emsp;地幔过渡带的地形和速度变化也是研究的热点。例如Ai and Zheng (2003)和Ai et al. (2003)利用接收函数对研究660间断面他们发现660不是单一的一个界面在有些地方存在小的间断面。Zhang et al. (2019)发现中国东南660界面速度增大有8%。Ishii et al. (2019)也发现660界面十分尖锐，速度的跳变在数公里范围内。Wu et al. (2019)利用散射波发现410比较平缓，推断410是一个温度控制的相变面。而660含有小尺度的地形，因而推断它是一个相变面加上化学界面。这些研究极大的推动了我们对于过渡带界面的认识。不过可能还有很多值得发掘的点，例如Wu et al. (2019)采样的区域是中国东部及南亚，地球上其他地方是否也是类似的结论。另外660的小间断面与俯冲板块，地幔热柱有什么关系也是值得研究的(Chu et al., 2012; Jenkins et al., 2016)。\n&emsp;&emsp;地幔过度带的水是大家十分关注的问题。高温高压实验证实地幔过渡带有储存大量水的能力。一些学者从地幔金刚石包裹体中的物质发现地幔过渡带的确含水(Pearson et al., 2014; Tschauner et al., 2018; Schulze et al., 2018)。不过这些例子较少，似乎不足以说明普遍情况。地震学的部分研究发现其实地幔过渡带含的水没有想象中的多(Houser, 2016)。因而地幔过渡带里的含水量还有一定争议。Thio et al. (2016)发现利用地震学的数据来研究地幔过渡带的含水量存在两个问题，一个就是误差较大，另一个就是温度与速度存在一定的折中关系。例如有些研究者直接将低速解释为含水导致，然而温度高也可以导致波速度低。尚需利用多种手段来进行研究，确认地幔过渡带的水含量及分布。\n&emsp;&emsp;近些年来660界面之下的低速获得了广泛关注(Liu et al., 2018; Sun et al., 2020;Panero et al., 2020)。例如Schmandt et al. (2014)利用接收函数研究了美国西部660界面。他们发现了660之下普遍存在一个低速。他们推测可能是俯冲的法拉隆板片进入下地幔时脱水造成的部分熔融。Liu et al. (2016)等在日本地区发现了660之下的低速，推测是地幔转换带滞留的东亚俯冲的太平洋板片造成。目前在世界其他地区，中国等尚缺乏相关研究。研究660低速有助于提升我们对俯冲板块与地幔过渡带关系的认识。\n&emsp;&emsp;地幔过渡带的地震学研究方法包括：非对称反射波的方法(Wu et al., 2019)，ScS多次反射波(Wang et al., 2017)以及上界面反射波的方法(Feng et al., 2017)。\n&emsp;&emsp;还有地震源区转换波法，该方法对深源地震区附近的成像精度高(Li et al., 2008)。中心点反射波法，这种方法空间覆盖好，可以得到可靠的大尺度平均结构(Yu et al., 2018)。\n&emsp;&emsp;此外还有三重震相法。该方法对垂直方向尚的速度结构非常敏感(Wang and Niu, 2010; Chu et al., 2012)。台站下方转换波法，该方法充分利用到时和振幅信息，但受限于台阵的孔径和台间距(Zhang and Schmandt, 2019)。\n","source":"_posts/2020-07-21-mantle-transition-zone.md","raw":"---\ntitle: 稍稍盘点地幔过渡带研究进展\ncategories:\n  - work\ntags:\n  - 过渡带\nabbrlink: 40ac122d\ndate: 2020-07-21 23:04:45\n---\n![地幔过渡带](Picture1.png)\n<!-- less -->\n&emsp;&emsp;不看不知道，一看吓一跳。地幔过渡带的研究热度要爆表。搜了一下2016年以来的文章，多如牛毛，而且乖乖，都是高影响因子期刊论文。\n![部分文献](Picture2.png)\n&emsp;&emsp;老板让想一下以后的方向，关于地幔结构，宜居性，热点。那就地幔过渡带的水咯。\n&emsp;&emsp;地幔过渡带是上地幔与下地幔的交接区域。深度大约为410-660公里。通过研究地幔过渡带结构以及其与上下地幔的相互作用的可以帮助我们认识地幔对流的模式，了解地幔的演化以及揭示地球内部的水循环过程。\n&emsp;&emsp;目前对地幔过渡的认识主要是认为它是相变层。上地幔中主要是橄榄石。410公里是橄榄石到瓦兹利石的相变。660是林伍德是到布里吉曼石的相变。另外过渡带中间约520km还有一个相变。两个相变面的克拉伯龙斜率是反的。意思是当温度高时410相变面会下降，660会上升，过渡带变薄，反之变厚。对地幔过渡带的研究提供的关键信息可以推断上地幔物质组成，过渡带含水量和温度。了解热柱和俯冲带与过渡带的相互作用等。\n&emsp;&emsp;大量的研究表明上地幔和下地幔的储水能力较低，可能含的水很少。而过渡带有很好的储水能力，可能包含有大量的水。Bercovici and karato(2003)认为地幔有一个广域的上涌趋势，上涌的过程因为脱水，会在410界面上面形成一个局部熔融层，表现为一个地震学的低速层。含水的地幔过渡带可以解释地球化学观测到的不相容元素和稳定同位素特性，从而支持全地幔对流模式。\n&emsp;&emsp;我们来看看近几年的地幔过渡带研究进展。刚刚提到的这个410km的低速层，近些年获得大量研究者的关注。Tauzin et al. (2010)认为全球普遍存在这个低速层，他们的观测台站较少，Wei and Shearer (2017)人发现他们的观测数据中只有30-40%有低速层。其他近些年的文章也都纷纷在不同的区域例如中国东南等发现这样的低速层(Tauzin et al., 2017; Li et al., 2019; Li et al., 2020; Xiao et al., 2020)。那这个低速层是否真的是普遍全球存在的，这个低速层的成因及与俯冲板块和热柱的关系都是研究的热点。\n&emsp;&emsp;地幔过渡带的地形和速度变化也是研究的热点。例如Ai and Zheng (2003)和Ai et al. (2003)利用接收函数对研究660间断面他们发现660不是单一的一个界面在有些地方存在小的间断面。Zhang et al. (2019)发现中国东南660界面速度增大有8%。Ishii et al. (2019)也发现660界面十分尖锐，速度的跳变在数公里范围内。Wu et al. (2019)利用散射波发现410比较平缓，推断410是一个温度控制的相变面。而660含有小尺度的地形，因而推断它是一个相变面加上化学界面。这些研究极大的推动了我们对于过渡带界面的认识。不过可能还有很多值得发掘的点，例如Wu et al. (2019)采样的区域是中国东部及南亚，地球上其他地方是否也是类似的结论。另外660的小间断面与俯冲板块，地幔热柱有什么关系也是值得研究的(Chu et al., 2012; Jenkins et al., 2016)。\n&emsp;&emsp;地幔过度带的水是大家十分关注的问题。高温高压实验证实地幔过渡带有储存大量水的能力。一些学者从地幔金刚石包裹体中的物质发现地幔过渡带的确含水(Pearson et al., 2014; Tschauner et al., 2018; Schulze et al., 2018)。不过这些例子较少，似乎不足以说明普遍情况。地震学的部分研究发现其实地幔过渡带含的水没有想象中的多(Houser, 2016)。因而地幔过渡带里的含水量还有一定争议。Thio et al. (2016)发现利用地震学的数据来研究地幔过渡带的含水量存在两个问题，一个就是误差较大，另一个就是温度与速度存在一定的折中关系。例如有些研究者直接将低速解释为含水导致，然而温度高也可以导致波速度低。尚需利用多种手段来进行研究，确认地幔过渡带的水含量及分布。\n&emsp;&emsp;近些年来660界面之下的低速获得了广泛关注(Liu et al., 2018; Sun et al., 2020;Panero et al., 2020)。例如Schmandt et al. (2014)利用接收函数研究了美国西部660界面。他们发现了660之下普遍存在一个低速。他们推测可能是俯冲的法拉隆板片进入下地幔时脱水造成的部分熔融。Liu et al. (2016)等在日本地区发现了660之下的低速，推测是地幔转换带滞留的东亚俯冲的太平洋板片造成。目前在世界其他地区，中国等尚缺乏相关研究。研究660低速有助于提升我们对俯冲板块与地幔过渡带关系的认识。\n&emsp;&emsp;地幔过渡带的地震学研究方法包括：非对称反射波的方法(Wu et al., 2019)，ScS多次反射波(Wang et al., 2017)以及上界面反射波的方法(Feng et al., 2017)。\n&emsp;&emsp;还有地震源区转换波法，该方法对深源地震区附近的成像精度高(Li et al., 2008)。中心点反射波法，这种方法空间覆盖好，可以得到可靠的大尺度平均结构(Yu et al., 2018)。\n&emsp;&emsp;此外还有三重震相法。该方法对垂直方向尚的速度结构非常敏感(Wang and Niu, 2010; Chu et al., 2012)。台站下方转换波法，该方法充分利用到时和振幅信息，但受限于台阵的孔径和台间距(Zhang and Schmandt, 2019)。\n","slug":"mantle-transition-zone","published":1,"updated":"2024-05-26T14:17:36.846Z","comments":1,"layout":"post","photos":[],"_id":"cmh498ip9004zwvou9nag711j","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>&emsp;&emsp;不看不知道，一看吓一跳。地幔过渡带的研究热度要爆表。搜了一下2016年以来的文章，多如牛毛，而且乖乖，都是高影响因子期刊论文。<br><img src=\"/Picture2.png\" alt=\"部分文献\"><br>&emsp;&emsp;老板让想一下以后的方向，关于地幔结构，宜居性，热点。那就地幔过渡带的水咯。<br>&emsp;&emsp;地幔过渡带是上地幔与下地幔的交接区域。深度大约为410-660公里。通过研究地幔过渡带结构以及其与上下地幔的相互作用的可以帮助我们认识地幔对流的模式，了解地幔的演化以及揭示地球内部的水循环过程。<br>&emsp;&emsp;目前对地幔过渡的认识主要是认为它是相变层。上地幔中主要是橄榄石。410公里是橄榄石到瓦兹利石的相变。660是林伍德是到布里吉曼石的相变。另外过渡带中间约520km还有一个相变。两个相变面的克拉伯龙斜率是反的。意思是当温度高时410相变面会下降，660会上升，过渡带变薄，反之变厚。对地幔过渡带的研究提供的关键信息可以推断上地幔物质组成，过渡带含水量和温度。了解热柱和俯冲带与过渡带的相互作用等。<br>&emsp;&emsp;大量的研究表明上地幔和下地幔的储水能力较低，可能含的水很少。而过渡带有很好的储水能力，可能包含有大量的水。Bercovici and karato(2003)认为地幔有一个广域的上涌趋势，上涌的过程因为脱水，会在410界面上面形成一个局部熔融层，表现为一个地震学的低速层。含水的地幔过渡带可以解释地球化学观测到的不相容元素和稳定同位素特性，从而支持全地幔对流模式。<br>&emsp;&emsp;我们来看看近几年的地幔过渡带研究进展。刚刚提到的这个410km的低速层，近些年获得大量研究者的关注。Tauzin et al. (2010)认为全球普遍存在这个低速层，他们的观测台站较少，Wei and Shearer (2017)人发现他们的观测数据中只有30-40%有低速层。其他近些年的文章也都纷纷在不同的区域例如中国东南等发现这样的低速层(Tauzin et al., 2017; Li et al., 2019; Li et al., 2020; Xiao et al., 2020)。那这个低速层是否真的是普遍全球存在的，这个低速层的成因及与俯冲板块和热柱的关系都是研究的热点。<br>&emsp;&emsp;地幔过渡带的地形和速度变化也是研究的热点。例如Ai and Zheng (2003)和Ai et al. (2003)利用接收函数对研究660间断面他们发现660不是单一的一个界面在有些地方存在小的间断面。Zhang et al. (2019)发现中国东南660界面速度增大有8%。Ishii et al. (2019)也发现660界面十分尖锐，速度的跳变在数公里范围内。Wu et al. (2019)利用散射波发现410比较平缓，推断410是一个温度控制的相变面。而660含有小尺度的地形，因而推断它是一个相变面加上化学界面。这些研究极大的推动了我们对于过渡带界面的认识。不过可能还有很多值得发掘的点，例如Wu et al. (2019)采样的区域是中国东部及南亚，地球上其他地方是否也是类似的结论。另外660的小间断面与俯冲板块，地幔热柱有什么关系也是值得研究的(Chu et al., 2012; Jenkins et al., 2016)。<br>&emsp;&emsp;地幔过度带的水是大家十分关注的问题。高温高压实验证实地幔过渡带有储存大量水的能力。一些学者从地幔金刚石包裹体中的物质发现地幔过渡带的确含水(Pearson et al., 2014; Tschauner et al., 2018; Schulze et al., 2018)。不过这些例子较少，似乎不足以说明普遍情况。地震学的部分研究发现其实地幔过渡带含的水没有想象中的多(Houser, 2016)。因而地幔过渡带里的含水量还有一定争议。Thio et al. (2016)发现利用地震学的数据来研究地幔过渡带的含水量存在两个问题，一个就是误差较大，另一个就是温度与速度存在一定的折中关系。例如有些研究者直接将低速解释为含水导致，然而温度高也可以导致波速度低。尚需利用多种手段来进行研究，确认地幔过渡带的水含量及分布。<br>&emsp;&emsp;近些年来660界面之下的低速获得了广泛关注(Liu et al., 2018; Sun et al., 2020;Panero et al., 2020)。例如Schmandt et al. (2014)利用接收函数研究了美国西部660界面。他们发现了660之下普遍存在一个低速。他们推测可能是俯冲的法拉隆板片进入下地幔时脱水造成的部分熔融。Liu et al. (2016)等在日本地区发现了660之下的低速，推测是地幔转换带滞留的东亚俯冲的太平洋板片造成。目前在世界其他地区，中国等尚缺乏相关研究。研究660低速有助于提升我们对俯冲板块与地幔过渡带关系的认识。<br>&emsp;&emsp;地幔过渡带的地震学研究方法包括：非对称反射波的方法(Wu et al., 2019)，ScS多次反射波(Wang et al., 2017)以及上界面反射波的方法(Feng et al., 2017)。<br>&emsp;&emsp;还有地震源区转换波法，该方法对深源地震区附近的成像精度高(Li et al., 2008)。中心点反射波法，这种方法空间覆盖好，可以得到可靠的大尺度平均结构(Yu et al., 2018)。<br>&emsp;&emsp;此外还有三重震相法。该方法对垂直方向尚的速度结构非常敏感(Wang and Niu, 2010; Chu et al., 2012)。台站下方转换波法，该方法充分利用到时和振幅信息，但受限于台阵的孔径和台间距(Zhang and Schmandt, 2019)。</p>","related_posts":[],"length":2306,"excerpt":"<p><img src=\"/Picture1.png\" alt=\"地幔过渡带\"></p>","more":"<p>&emsp;&emsp;不看不知道，一看吓一跳。地幔过渡带的研究热度要爆表。搜了一下2016年以来的文章，多如牛毛，而且乖乖，都是高影响因子期刊论文。<br><img src=\"/Picture2.png\" alt=\"部分文献\"><br>&emsp;&emsp;老板让想一下以后的方向，关于地幔结构，宜居性，热点。那就地幔过渡带的水咯。<br>&emsp;&emsp;地幔过渡带是上地幔与下地幔的交接区域。深度大约为410-660公里。通过研究地幔过渡带结构以及其与上下地幔的相互作用的可以帮助我们认识地幔对流的模式，了解地幔的演化以及揭示地球内部的水循环过程。<br>&emsp;&emsp;目前对地幔过渡的认识主要是认为它是相变层。上地幔中主要是橄榄石。410公里是橄榄石到瓦兹利石的相变。660是林伍德是到布里吉曼石的相变。另外过渡带中间约520km还有一个相变。两个相变面的克拉伯龙斜率是反的。意思是当温度高时410相变面会下降，660会上升，过渡带变薄，反之变厚。对地幔过渡带的研究提供的关键信息可以推断上地幔物质组成，过渡带含水量和温度。了解热柱和俯冲带与过渡带的相互作用等。<br>&emsp;&emsp;大量的研究表明上地幔和下地幔的储水能力较低，可能含的水很少。而过渡带有很好的储水能力，可能包含有大量的水。Bercovici and karato(2003)认为地幔有一个广域的上涌趋势，上涌的过程因为脱水，会在410界面上面形成一个局部熔融层，表现为一个地震学的低速层。含水的地幔过渡带可以解释地球化学观测到的不相容元素和稳定同位素特性，从而支持全地幔对流模式。<br>&emsp;&emsp;我们来看看近几年的地幔过渡带研究进展。刚刚提到的这个410km的低速层，近些年获得大量研究者的关注。Tauzin et al. (2010)认为全球普遍存在这个低速层，他们的观测台站较少，Wei and Shearer (2017)人发现他们的观测数据中只有30-40%有低速层。其他近些年的文章也都纷纷在不同的区域例如中国东南等发现这样的低速层(Tauzin et al., 2017; Li et al., 2019; Li et al., 2020; Xiao et al., 2020)。那这个低速层是否真的是普遍全球存在的，这个低速层的成因及与俯冲板块和热柱的关系都是研究的热点。<br>&emsp;&emsp;地幔过渡带的地形和速度变化也是研究的热点。例如Ai and Zheng (2003)和Ai et al. (2003)利用接收函数对研究660间断面他们发现660不是单一的一个界面在有些地方存在小的间断面。Zhang et al. (2019)发现中国东南660界面速度增大有8%。Ishii et al. (2019)也发现660界面十分尖锐，速度的跳变在数公里范围内。Wu et al. (2019)利用散射波发现410比较平缓，推断410是一个温度控制的相变面。而660含有小尺度的地形，因而推断它是一个相变面加上化学界面。这些研究极大的推动了我们对于过渡带界面的认识。不过可能还有很多值得发掘的点，例如Wu et al. (2019)采样的区域是中国东部及南亚，地球上其他地方是否也是类似的结论。另外660的小间断面与俯冲板块，地幔热柱有什么关系也是值得研究的(Chu et al., 2012; Jenkins et al., 2016)。<br>&emsp;&emsp;地幔过度带的水是大家十分关注的问题。高温高压实验证实地幔过渡带有储存大量水的能力。一些学者从地幔金刚石包裹体中的物质发现地幔过渡带的确含水(Pearson et al., 2014; Tschauner et al., 2018; Schulze et al., 2018)。不过这些例子较少，似乎不足以说明普遍情况。地震学的部分研究发现其实地幔过渡带含的水没有想象中的多(Houser, 2016)。因而地幔过渡带里的含水量还有一定争议。Thio et al. (2016)发现利用地震学的数据来研究地幔过渡带的含水量存在两个问题，一个就是误差较大，另一个就是温度与速度存在一定的折中关系。例如有些研究者直接将低速解释为含水导致，然而温度高也可以导致波速度低。尚需利用多种手段来进行研究，确认地幔过渡带的水含量及分布。<br>&emsp;&emsp;近些年来660界面之下的低速获得了广泛关注(Liu et al., 2018; Sun et al., 2020;Panero et al., 2020)。例如Schmandt et al. (2014)利用接收函数研究了美国西部660界面。他们发现了660之下普遍存在一个低速。他们推测可能是俯冲的法拉隆板片进入下地幔时脱水造成的部分熔融。Liu et al. (2016)等在日本地区发现了660之下的低速，推测是地幔转换带滞留的东亚俯冲的太平洋板片造成。目前在世界其他地区，中国等尚缺乏相关研究。研究660低速有助于提升我们对俯冲板块与地幔过渡带关系的认识。<br>&emsp;&emsp;地幔过渡带的地震学研究方法包括：非对称反射波的方法(Wu et al., 2019)，ScS多次反射波(Wang et al., 2017)以及上界面反射波的方法(Feng et al., 2017)。<br>&emsp;&emsp;还有地震源区转换波法，该方法对深源地震区附近的成像精度高(Li et al., 2008)。中心点反射波法，这种方法空间覆盖好，可以得到可靠的大尺度平均结构(Yu et al., 2018)。<br>&emsp;&emsp;此外还有三重震相法。该方法对垂直方向尚的速度结构非常敏感(Wang and Niu, 2010; Chu et al., 2012)。台站下方转换波法，该方法充分利用到时和振幅信息，但受限于台阵的孔径和台间距(Zhang and Schmandt, 2019)。</p>"},{"title":"基于宽频带背景噪声面波的美国三维上地幔横波速度结构模型","abbrlink":"77d4f89d","date":"2020-07-28T18:30:10.000Z","_content":"![Maps of Vs structure in the upper mantle and major geological units modified from Fenneman (1917). The color bar labels are V S in km/s (top) and perturbation in percentage (bottom).](figure5.png)\n<!-- less -->\n&emsp;&emsp;利用宽频带的背景噪声面波做了美国三维上地幔横波速度结构，该工作做了x年。我不会告诉你这项工作做了多久，说出来都害sao。文章终于在2018年发表，文章链接在[这里](https://link.springer.com/article/10.1007/s00024-018-1881-2)，如果有需要可以找我要全文。\n&emsp;&emsp;做模型真的是需要大量细致的工作。这篇文章的主要贡献是表明只用背景噪声面波也可以做的比较深，比较准，另外就是为community提供了一个新的模型。怎奈自己的地质背景太差，看不到啥突出的科学问题，还被审稿人批评说，‘你做的啥工作啊，像本科生的作业。’心塞。师兄说的对，应该多向可能对你的工作感兴趣的人请教，例如动力学方向的人啊之类的。\n&emsp;&emsp;老板建议把这个模型挂在[IRIS EMC](https://ds.iris.edu/ds/products/emc-earthmodels/)里头，推广推广，让大伙儿都用用。我觉得不错，于是今天终于把它放到了IRIS里面。点击[这里](https://ds.iris.edu/ds/products/emc-us-upper-mantle-vsxiechuyang2018/)就可以看到我的模型了。里面有netcdf格式的数据可以下载。如果有需要可以找我要更细致的结果。\n&emsp;&emsp;IRIS EMC需要的是netcdf格式的模型数据。IRIS有提供把txt文本格式的模型转换成netcdf的[python脚本](https://github.com/iris-edu/emc-tools)。另外向IRIS EMC提交模型的要求也可以这他们的[网页](https://ds.iris.edu/ds/products/emc-contributionguide/)看到，按照他们的要求把netcdf文件准备好，然后写一个说明文档一并发送给product@iris.washington.edu就完事了。\n&emsp;&emsp;netcdf是2进制文件。要查看其头段信息的话可以用命令ncdump -h xxx.nc（安装netcdf-bin），要读取其参数信息可以用命令ncks（安装nco）。其实IRIS EMC也提供了将netcdf转换成txt文本的[python脚本](https://github.com/iris-edu/emc-tools)，非常方便。\n&emsp;&emsp;求合作啊。我擅长处理数据，要是您能看到啥地学科学问题那真是求之不得啊。笑cry。\n","source":"_posts/2020-07-29-US-upper-mantle-vs-model.md","raw":"---\ntitle: 基于宽频带背景噪声面波的美国三维上地幔横波速度结构模型\ncategories:\n  - work\ntags:\n  - model\nabbrlink: 77d4f89d\ndate: 2020-07-29 02:30:10\n---\n![Maps of Vs structure in the upper mantle and major geological units modified from Fenneman (1917). The color bar labels are V S in km/s (top) and perturbation in percentage (bottom).](figure5.png)\n<!-- less -->\n&emsp;&emsp;利用宽频带的背景噪声面波做了美国三维上地幔横波速度结构，该工作做了x年。我不会告诉你这项工作做了多久，说出来都害sao。文章终于在2018年发表，文章链接在[这里](https://link.springer.com/article/10.1007/s00024-018-1881-2)，如果有需要可以找我要全文。\n&emsp;&emsp;做模型真的是需要大量细致的工作。这篇文章的主要贡献是表明只用背景噪声面波也可以做的比较深，比较准，另外就是为community提供了一个新的模型。怎奈自己的地质背景太差，看不到啥突出的科学问题，还被审稿人批评说，‘你做的啥工作啊，像本科生的作业。’心塞。师兄说的对，应该多向可能对你的工作感兴趣的人请教，例如动力学方向的人啊之类的。\n&emsp;&emsp;老板建议把这个模型挂在[IRIS EMC](https://ds.iris.edu/ds/products/emc-earthmodels/)里头，推广推广，让大伙儿都用用。我觉得不错，于是今天终于把它放到了IRIS里面。点击[这里](https://ds.iris.edu/ds/products/emc-us-upper-mantle-vsxiechuyang2018/)就可以看到我的模型了。里面有netcdf格式的数据可以下载。如果有需要可以找我要更细致的结果。\n&emsp;&emsp;IRIS EMC需要的是netcdf格式的模型数据。IRIS有提供把txt文本格式的模型转换成netcdf的[python脚本](https://github.com/iris-edu/emc-tools)。另外向IRIS EMC提交模型的要求也可以这他们的[网页](https://ds.iris.edu/ds/products/emc-contributionguide/)看到，按照他们的要求把netcdf文件准备好，然后写一个说明文档一并发送给product@iris.washington.edu就完事了。\n&emsp;&emsp;netcdf是2进制文件。要查看其头段信息的话可以用命令ncdump -h xxx.nc（安装netcdf-bin），要读取其参数信息可以用命令ncks（安装nco）。其实IRIS EMC也提供了将netcdf转换成txt文本的[python脚本](https://github.com/iris-edu/emc-tools)，非常方便。\n&emsp;&emsp;求合作啊。我擅长处理数据，要是您能看到啥地学科学问题那真是求之不得啊。笑cry。\n","slug":"US-upper-mantle-vs-model","published":1,"updated":"2024-05-26T14:17:36.846Z","comments":1,"layout":"post","photos":[],"_id":"cmh498ip90051wvoudvmd7r8s","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>&emsp;&emsp;利用宽频带的背景噪声面波做了美国三维上地幔横波速度结构，该工作做了x年。我不会告诉你这项工作做了多久，说出来都害sao。文章终于在2018年发表，文章链接在<a href=\"https://link.springer.com/article/10.1007/s00024-018-1881-2\">这里</a>，如果有需要可以找我要全文。<br>&emsp;&emsp;做模型真的是需要大量细致的工作。这篇文章的主要贡献是表明只用背景噪声面波也可以做的比较深，比较准，另外就是为community提供了一个新的模型。怎奈自己的地质背景太差，看不到啥突出的科学问题，还被审稿人批评说，‘你做的啥工作啊，像本科生的作业。’心塞。师兄说的对，应该多向可能对你的工作感兴趣的人请教，例如动力学方向的人啊之类的。<br>&emsp;&emsp;老板建议把这个模型挂在<a href=\"https://ds.iris.edu/ds/products/emc-earthmodels/\">IRIS EMC</a>里头，推广推广，让大伙儿都用用。我觉得不错，于是今天终于把它放到了IRIS里面。点击<a href=\"https://ds.iris.edu/ds/products/emc-us-upper-mantle-vsxiechuyang2018/\">这里</a>就可以看到我的模型了。里面有netcdf格式的数据可以下载。如果有需要可以找我要更细致的结果。<br>&emsp;&emsp;IRIS EMC需要的是netcdf格式的模型数据。IRIS有提供把txt文本格式的模型转换成netcdf的<a href=\"https://github.com/iris-edu/emc-tools\">python脚本</a>。另外向IRIS EMC提交模型的要求也可以这他们的<a href=\"https://ds.iris.edu/ds/products/emc-contributionguide/\">网页</a>看到，按照他们的要求把netcdf文件准备好，然后写一个说明文档一并发送给<a href=\"mailto:&#112;&#114;&#111;&#x64;&#117;&#99;&#116;&#x40;&#x69;&#x72;&#105;&#115;&#46;&#119;&#x61;&#115;&#x68;&#105;&#x6e;&#x67;&#116;&#x6f;&#x6e;&#x2e;&#x65;&#x64;&#x75;\">&#112;&#114;&#111;&#x64;&#117;&#99;&#116;&#x40;&#x69;&#x72;&#105;&#115;&#46;&#119;&#x61;&#115;&#x68;&#105;&#x6e;&#x67;&#116;&#x6f;&#x6e;&#x2e;&#x65;&#x64;&#x75;</a>就完事了。<br>&emsp;&emsp;netcdf是2进制文件。要查看其头段信息的话可以用命令ncdump -h xxx.nc（安装netcdf-bin），要读取其参数信息可以用命令ncks（安装nco）。其实IRIS EMC也提供了将netcdf转换成txt文本的<a href=\"https://github.com/iris-edu/emc-tools\">python脚本</a>，非常方便。<br>&emsp;&emsp;求合作啊。我擅长处理数据，要是您能看到啥地学科学问题那真是求之不得啊。笑cry。</p>","related_posts":[],"length":896,"excerpt":"<p><img src=\"/figure5.png\" alt=\"Maps of Vs structure in the upper mantle and major geological units modified from Fenneman (1917). The color bar labels are V S in km/s (top) and perturbation in percentage (bottom).\"></p>","more":"<p>&emsp;&emsp;利用宽频带的背景噪声面波做了美国三维上地幔横波速度结构，该工作做了x年。我不会告诉你这项工作做了多久，说出来都害sao。文章终于在2018年发表，文章链接在<a href=\"https://link.springer.com/article/10.1007/s00024-018-1881-2\">这里</a>，如果有需要可以找我要全文。<br>&emsp;&emsp;做模型真的是需要大量细致的工作。这篇文章的主要贡献是表明只用背景噪声面波也可以做的比较深，比较准，另外就是为community提供了一个新的模型。怎奈自己的地质背景太差，看不到啥突出的科学问题，还被审稿人批评说，‘你做的啥工作啊，像本科生的作业。’心塞。师兄说的对，应该多向可能对你的工作感兴趣的人请教，例如动力学方向的人啊之类的。<br>&emsp;&emsp;老板建议把这个模型挂在<a href=\"https://ds.iris.edu/ds/products/emc-earthmodels/\">IRIS EMC</a>里头，推广推广，让大伙儿都用用。我觉得不错，于是今天终于把它放到了IRIS里面。点击<a href=\"https://ds.iris.edu/ds/products/emc-us-upper-mantle-vsxiechuyang2018/\">这里</a>就可以看到我的模型了。里面有netcdf格式的数据可以下载。如果有需要可以找我要更细致的结果。<br>&emsp;&emsp;IRIS EMC需要的是netcdf格式的模型数据。IRIS有提供把txt文本格式的模型转换成netcdf的<a href=\"https://github.com/iris-edu/emc-tools\">python脚本</a>。另外向IRIS EMC提交模型的要求也可以这他们的<a href=\"https://ds.iris.edu/ds/products/emc-contributionguide/\">网页</a>看到，按照他们的要求把netcdf文件准备好，然后写一个说明文档一并发送给<a href=\"mailto:&#112;&#114;&#111;&#x64;&#117;&#99;&#116;&#x40;&#x69;&#x72;&#105;&#115;&#46;&#119;&#x61;&#115;&#x68;&#105;&#x6e;&#x67;&#116;&#x6f;&#x6e;&#x2e;&#x65;&#x64;&#x75;\">&#112;&#114;&#111;&#x64;&#117;&#99;&#116;&#x40;&#x69;&#x72;&#105;&#115;&#46;&#119;&#x61;&#115;&#x68;&#105;&#x6e;&#x67;&#116;&#x6f;&#x6e;&#x2e;&#x65;&#x64;&#x75;</a>就完事了。<br>&emsp;&emsp;netcdf是2进制文件。要查看其头段信息的话可以用命令ncdump -h xxx.nc（安装netcdf-bin），要读取其参数信息可以用命令ncks（安装nco）。其实IRIS EMC也提供了将netcdf转换成txt文本的<a href=\"https://github.com/iris-edu/emc-tools\">python脚本</a>，非常方便。<br>&emsp;&emsp;求合作啊。我擅长处理数据，要是您能看到啥地学科学问题那真是求之不得啊。笑cry。</p>"},{"title":"如何在elementaryOS下让gmt支持中文","abbrlink":"5bc68c30","date":"2020-07-31T15:03:04.000Z","_content":"&emsp;&emsp;有些时候用gmt画图需要添加一些中文标注。之前在fedora里用gmt4的时候配置过一次。现在用的是elementaryOS+gmt5.4.3怎么配置中文呢？\n<!-- more -->\n&emsp;&emsp;与centos啦fedora不一样,elementaryOS是基于ubuntu的。ghostscript中文配置文件不是在/usr/share/ghostscript/conf.d/cidfmap.zh_CN 而是在/etc/ghostscript/cidfmap.d/90gs-cjk-resource-gb1.conf[^1]。\n&emsp;&emsp;也不用像fedora下面需要安装ghostscript-chinese-zh_CN，而elementaryOS的中文支持已经预装了。知道了中文配置文件的位置以后就十分方便。我们只需要把自己需要的字体下载下来就好了。例如需要windows字体的话就把\\C:\\Windows\\Fonts下面的字体文件拷贝到/usr/share/fonts/winfonts下面。\n&emsp;&emsp;下面就是老套路了。在中文配置文件末尾加上：\n```\n/STSong-Light << /FileType /TrueType /Path (/usr/share/fonts/winfonts/simsun.ttc) /SubfontId 0 /CSI [(GB1) 4] >> ;\n/STFangsong-Light << /FileType /TrueType /Path (/usr/share/fonts/winfonts/simfang.ttf) /SubfontId 0 /CSI [(GB1) 4] >> ;\n/STHeiti-Regular << /FileType /TrueType /Path (/usr/share/fonts/winfonts/simhei.ttf) /SubfontId 0 /CSI [(GB1) 4] >> ;\n/STKaiti-Regular << /FileType /TrueType /Path (/usr/share/fonts/winfonts/simkai.ttf) /SubfontId 0 /CSI [(GB1) 4] >> ; \n```\n&emsp;&emsp;然后更新字体map：\n```\nsudo update-gsfontmap\n```\n&emsp;&emsp;最后在gmt的字体配置文件/usr/share/gmt/postscriptlight/PSL_custom_fonts.txt加上：\n```\nSTSong-Light--UniGB-UTF8-H 0.700 1\nSTFangsong-Light--UniGB-UTF8-H 0.700 1\nSTHeiti-Regular--UniGB-UTF8-H 0.700 1\nSTKaiti-Regular--UniGB-UTF8-H 0.700 1\n```\n&emsp;&emsp;用gmt pstext -L就可以看到添加的四中字体：\n![gmt pstext -L显示的新添加4种字体](pstext.png)\n&emsp;&emsp;然后就大功告成了。\n\n[^1]:https://www.cnblogs.com/gisalameda/p/6840662.html\n","source":"_posts/2020-07-31-how-to-configure-chinese-for-gmt.md","raw":"---\ntitle: 如何在elementaryOS下让gmt支持中文\ncategories:\n  - gmt\ntags:\n  - 中文\nabbrlink: 5bc68c30\ndate: 2020-07-31 23:03:04\n---\n&emsp;&emsp;有些时候用gmt画图需要添加一些中文标注。之前在fedora里用gmt4的时候配置过一次。现在用的是elementaryOS+gmt5.4.3怎么配置中文呢？\n<!-- more -->\n&emsp;&emsp;与centos啦fedora不一样,elementaryOS是基于ubuntu的。ghostscript中文配置文件不是在/usr/share/ghostscript/conf.d/cidfmap.zh_CN 而是在/etc/ghostscript/cidfmap.d/90gs-cjk-resource-gb1.conf[^1]。\n&emsp;&emsp;也不用像fedora下面需要安装ghostscript-chinese-zh_CN，而elementaryOS的中文支持已经预装了。知道了中文配置文件的位置以后就十分方便。我们只需要把自己需要的字体下载下来就好了。例如需要windows字体的话就把\\C:\\Windows\\Fonts下面的字体文件拷贝到/usr/share/fonts/winfonts下面。\n&emsp;&emsp;下面就是老套路了。在中文配置文件末尾加上：\n```\n/STSong-Light << /FileType /TrueType /Path (/usr/share/fonts/winfonts/simsun.ttc) /SubfontId 0 /CSI [(GB1) 4] >> ;\n/STFangsong-Light << /FileType /TrueType /Path (/usr/share/fonts/winfonts/simfang.ttf) /SubfontId 0 /CSI [(GB1) 4] >> ;\n/STHeiti-Regular << /FileType /TrueType /Path (/usr/share/fonts/winfonts/simhei.ttf) /SubfontId 0 /CSI [(GB1) 4] >> ;\n/STKaiti-Regular << /FileType /TrueType /Path (/usr/share/fonts/winfonts/simkai.ttf) /SubfontId 0 /CSI [(GB1) 4] >> ; \n```\n&emsp;&emsp;然后更新字体map：\n```\nsudo update-gsfontmap\n```\n&emsp;&emsp;最后在gmt的字体配置文件/usr/share/gmt/postscriptlight/PSL_custom_fonts.txt加上：\n```\nSTSong-Light--UniGB-UTF8-H 0.700 1\nSTFangsong-Light--UniGB-UTF8-H 0.700 1\nSTHeiti-Regular--UniGB-UTF8-H 0.700 1\nSTKaiti-Regular--UniGB-UTF8-H 0.700 1\n```\n&emsp;&emsp;用gmt pstext -L就可以看到添加的四中字体：\n![gmt pstext -L显示的新添加4种字体](pstext.png)\n&emsp;&emsp;然后就大功告成了。\n\n[^1]:https://www.cnblogs.com/gisalameda/p/6840662.html\n","slug":"how-to-configure-chinese-for-gmt","published":1,"updated":"2024-05-26T14:17:36.847Z","comments":1,"layout":"post","photos":[],"_id":"cmh498ipa0053wvou1y3b1bbw","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>&emsp;&emsp;有些时候用gmt画图需要添加一些中文标注。之前在fedora里用gmt4的时候配置过一次。现在用的是elementaryOS+gmt5.4.3怎么配置中文呢？</p>\n<span id=\"more\"></span>\n<p>&emsp;&emsp;与centos啦fedora不一样,elementaryOS是基于ubuntu的。ghostscript中文配置文件不是在&#x2F;usr&#x2F;share&#x2F;ghostscript&#x2F;conf.d&#x2F;cidfmap.zh_CN 而是在&#x2F;etc&#x2F;ghostscript&#x2F;cidfmap.d&#x2F;90gs-cjk-resource-gb1.conf<sup id=\"fnref:1\"><a href=\"#fn:1\" rel=\"footnote\"><span class=\"hint--top hint--error hint--medium hint--rounded hint--bounce\" aria-label=\"https://www.cnblogs.com/gisalameda/p/6840662.html\n\">[1]</span></a></sup>。<br>&emsp;&emsp;也不用像fedora下面需要安装ghostscript-chinese-zh_CN，而elementaryOS的中文支持已经预装了。知道了中文配置文件的位置以后就十分方便。我们只需要把自己需要的字体下载下来就好了。例如需要windows字体的话就把\\C:\\Windows\\Fonts下面的字体文件拷贝到&#x2F;usr&#x2F;share&#x2F;fonts&#x2F;winfonts下面。<br>&emsp;&emsp;下面就是老套路了。在中文配置文件末尾加上：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">/STSong-Light &lt;&lt; /FileType /TrueType /Path (/usr/share/fonts/winfonts/simsun.ttc) /SubfontId 0 /CSI [(GB1) 4] &gt;&gt; ;</span><br><span class=\"line\">/STFangsong-Light &lt;&lt; /FileType /TrueType /Path (/usr/share/fonts/winfonts/simfang.ttf) /SubfontId 0 /CSI [(GB1) 4] &gt;&gt; ;</span><br><span class=\"line\">/STHeiti-Regular &lt;&lt; /FileType /TrueType /Path (/usr/share/fonts/winfonts/simhei.ttf) /SubfontId 0 /CSI [(GB1) 4] &gt;&gt; ;</span><br><span class=\"line\">/STKaiti-Regular &lt;&lt; /FileType /TrueType /Path (/usr/share/fonts/winfonts/simkai.ttf) /SubfontId 0 /CSI [(GB1) 4] &gt;&gt; ; </span><br></pre></td></tr></table></figure>\n<p>&emsp;&emsp;然后更新字体map：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo update-gsfontmap</span><br></pre></td></tr></table></figure>\n<p>&emsp;&emsp;最后在gmt的字体配置文件&#x2F;usr&#x2F;share&#x2F;gmt&#x2F;postscriptlight&#x2F;PSL_custom_fonts.txt加上：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">STSong-Light--UniGB-UTF8-H 0.700 1</span><br><span class=\"line\">STFangsong-Light--UniGB-UTF8-H 0.700 1</span><br><span class=\"line\">STHeiti-Regular--UniGB-UTF8-H 0.700 1</span><br><span class=\"line\">STKaiti-Regular--UniGB-UTF8-H 0.700 1</span><br></pre></td></tr></table></figure>\n<p>&emsp;&emsp;用gmt pstext -L就可以看到添加的四中字体：<br><img src=\"/pstext.png\" alt=\"gmt pstext -L显示的新添加4种字体\"><br>&emsp;&emsp;然后就大功告成了。</p>\n<div id=\"footnotes\"><hr><div id=\"footnotelist\"><ol style=\"list-style: none; padding-left: 0; margin-left: 40px\"><li id=\"fn:1\"><span style=\"display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px\">1.</span><span style=\"display: inline-block; vertical-align: top; margin-left: 10px;\">https://www.cnblogs.com/gisalameda/p/6840662.html<a href=\"#fnref:1\" rev=\"footnote\"> ↩</a></span></li></ol></div></div>","related_posts":["to-desk.html","after-fedora32.html","reward-configuration.html","fedora-install-freshress.html","how-to-set-X11-in-fedora.html"],"length":1426,"excerpt":"<p>&emsp;&emsp;有些时候用gmt画图需要添加一些中文标注。之前在fedora里用gmt4的时候配置过一次。现在用的是elementaryOS+gmt5.4.3怎么配置中文呢？</p>","more":"<p>&emsp;&emsp;与centos啦fedora不一样,elementaryOS是基于ubuntu的。ghostscript中文配置文件不是在&#x2F;usr&#x2F;share&#x2F;ghostscript&#x2F;conf.d&#x2F;cidfmap.zh_CN 而是在&#x2F;etc&#x2F;ghostscript&#x2F;cidfmap.d&#x2F;90gs-cjk-resource-gb1.conf<sup id=\"fnref:1\"><a href=\"#fn:1\" rel=\"footnote\"><span class=\"hint--top hint--error hint--medium hint--rounded hint--bounce\" aria-label=\"https://www.cnblogs.com/gisalameda/p/6840662.html\n\">[1]</span></a></sup>。<br>&emsp;&emsp;也不用像fedora下面需要安装ghostscript-chinese-zh_CN，而elementaryOS的中文支持已经预装了。知道了中文配置文件的位置以后就十分方便。我们只需要把自己需要的字体下载下来就好了。例如需要windows字体的话就把\\C:\\Windows\\Fonts下面的字体文件拷贝到&#x2F;usr&#x2F;share&#x2F;fonts&#x2F;winfonts下面。<br>&emsp;&emsp;下面就是老套路了。在中文配置文件末尾加上：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">/STSong-Light &lt;&lt; /FileType /TrueType /Path (/usr/share/fonts/winfonts/simsun.ttc) /SubfontId 0 /CSI [(GB1) 4] &gt;&gt; ;</span><br><span class=\"line\">/STFangsong-Light &lt;&lt; /FileType /TrueType /Path (/usr/share/fonts/winfonts/simfang.ttf) /SubfontId 0 /CSI [(GB1) 4] &gt;&gt; ;</span><br><span class=\"line\">/STHeiti-Regular &lt;&lt; /FileType /TrueType /Path (/usr/share/fonts/winfonts/simhei.ttf) /SubfontId 0 /CSI [(GB1) 4] &gt;&gt; ;</span><br><span class=\"line\">/STKaiti-Regular &lt;&lt; /FileType /TrueType /Path (/usr/share/fonts/winfonts/simkai.ttf) /SubfontId 0 /CSI [(GB1) 4] &gt;&gt; ; </span><br></pre></td></tr></table></figure>\n<p>&emsp;&emsp;然后更新字体map：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo update-gsfontmap</span><br></pre></td></tr></table></figure>\n<p>&emsp;&emsp;最后在gmt的字体配置文件&#x2F;usr&#x2F;share&#x2F;gmt&#x2F;postscriptlight&#x2F;PSL_custom_fonts.txt加上：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">STSong-Light--UniGB-UTF8-H 0.700 1</span><br><span class=\"line\">STFangsong-Light--UniGB-UTF8-H 0.700 1</span><br><span class=\"line\">STHeiti-Regular--UniGB-UTF8-H 0.700 1</span><br><span class=\"line\">STKaiti-Regular--UniGB-UTF8-H 0.700 1</span><br></pre></td></tr></table></figure>\n<p>&emsp;&emsp;用gmt pstext -L就可以看到添加的四中字体：<br><img src=\"/pstext.png\" alt=\"gmt pstext -L显示的新添加4种字体\"><br>&emsp;&emsp;然后就大功告成了。</p>\n<div id=\"footnotes\"><hr><div id=\"footnotelist\"><ol style=\"list-style: none; padding-left: 0; margin-left: 40px\"><li id=\"fn:1\"><span style=\"display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px\">1.</span><span style=\"display: inline-block; vertical-align: top; margin-left: 10px;\">https://www.cnblogs.com/gisalameda/p/6840662.html<a href=\"#fnref:1\" rev=\"footnote\"> ↩</a></span></li></ol></div></div>"},{"title":"怎么计算理论的NCF？","abbrlink":"ce006a34","date":"2020-09-14T07:55:31.000Z","_content":"![Distribution of ambient noise sources (100-300 s) (Ermert et al., 2017 )](source_dis.png)\n<!-- less -->\n&emsp;&emsp;好久没有更新博客了。原因是上个月文章修改意见下来了，第二轮大修，这酸爽，难以言表。\n&emsp;&emsp;不知道啥时候开始（大概是Fichter和Ermert的文章发表之后），做噪声互相关工作总会被审稿人问：噪声源影响有多大啊？难为人啊。要是能像Ermert他们把源和结构一块儿做了不就结了。但那是人家的手艺，捡起来难啊。\n&emsp;&emsp;另一个方法就是做模拟。给定源，计算两点波形，做胡相关，叠加。一维，近距离还好做，全球的三维的咋办？\n&emsp;&emsp;还好有大神啊。人家Tromp et al. (2010)早都弄出来了。就是用Specfem3d_globe就可以了。\n&emsp;&emsp;其实specfem3d_globe的说明文档已经讲的很清楚了，我这里就简单说一下。一般，波形的正演模拟只需要一步，而ensemble average的NCF需要两步，要计算敏感核函数需要三步。需要注意的点主要有：\n&emsp;&emsp;1，NCF的模拟不需要CMTSOLUTION，需将其六分量设置为0。\n&emsp;&emsp;2，There are other parameters in DATA/Par_file which should be given specific values. For instance, NUMBER_OF_RUNS and NUMBER_OF_THIS_RUN must be 1; ROTATE_SEISMOGRAMS_RT, SAVE_ALL_SEISMOGRAMS_IN_ONE_FILES, USE_BINARY_FOR_LARGE_FILE and MOVIE_COARSE should be .false.. Moreover, since the first two steps for calculating noise cross-correlation kernels correspond to forward simulations, SIMULATION_TYPE must be 1 when NOISE_TOMOGRAPHY equals 1 or 2. Also, we have to reconstruct the ensemble forward wavefields in adjoint simulations, therefore we need to set SAVE_FORWARD to .true. for the second step, i.e., when NOISE_TOMOGRAPHY equals 2. The third step is for kernel constructions. Hence SIMULATION_TYPE should be 3, whereas SAVE_FORWARD must be .false.. （从使用手册抄的，关于Par_file的设置)\n&emsp;&emsp;3，利用EXAMPLES/noise_examples/NOISE_TOMOGRAPHY.m (main program)和EXAMPLES/noise_examples/PetersonNoiseModel.m两个matlab程序获得S_squared。运行该程序需要提供NSTEP和dt。这两个参数在编译之后运行xcreate_header_file会显示。\n&emsp;&emsp;4，Create a file called NOISE_TOMOGRAPHY/irec_master_noise. Note that this file should be put in directory NOISE_TOMOGRAPHY as well. This file contains only one integer, which is the ID of the 'maste' receiver. For example, if in this file shows 5, it means that the fifth receiver listed in DATA/STATIONS becomes the ‘master’. That’s why we mentioned previously that the order of receivers in DATA/STATIONS important. （该文件定义了是哪个台与其他台的互相关）\n&emsp;&emsp;5，Create a file called NOISE_TOMOGRAPHY/nu_master. This file holds three numbers, forming a (unit) vector. It describes which component we are cross-correlating at the ‘master’ receiv. （该文件定义了哪些分量做胡相关）\n&emsp;&emsp;6，Describe the noise direction and distributions in src/specfem3d/noise_tomography.f90. Search for a subroutine called noise_distribution_direction in noise_tomography.f90. It is actually located at the very beginning of noise_tomography.f90. The default assumes vertical noises and a uniform distribution across the whole physical domain. It should be quite self-explanatory for modifications. Should you modify this part, you have to re-compile the source code. (again, that’s why we recommend that you alwaysre-compile the code before you run simulations)（这里根据需要自己给定噪声源的分布。）\n&emsp;&emsp;接下来就可以运行了。要得到NCF需要运行要两步，在修改参数运行第二步的时候一定要重新编译一下。\n&emsp;&emsp;然后就可以跑了。结果我老是跑不通，老是出错。多番检查发现错误出在子程序print_stf_file()，即输出震源时间函数的子程序。但没有弄明白为什么会出错。这个程序没有产生后续需要调用的参数。大胆的将其注释掉了。然后程序就跑通了。其实在Par_file里面将PRINT_SOURCE_TIME_FUNCTION改为false应该就可以了。在噪声源均匀的情况下，跑出来的NCF与single force差了pi/4，以及一些微小的差异。移动pi/4之后基本能够对上，应该是正确的了。Hooray!\n&emsp;&emsp;第三步我是没跑通，估计是因为空间不足，因为我看到中间数据就已经接近900G。不过我要的是synthetic NCF，足够了，有空再试sensitivity kernel吧。\n&emsp;&emsp;封面图是我用来做模拟的噪声源分布。结果表明源的影响不大啊。乐。\n","source":"_posts/2020-09-14-how-to-calculate-synthetic-NCF.md","raw":"---\ntitle: 怎么计算理论的NCF？\nabbrlink: ce006a34\ndate: 2020-09-14 15:55:31\ncategories:\n  - work\ntags:\n  - sem\n  - NCF\n---\n![Distribution of ambient noise sources (100-300 s) (Ermert et al., 2017 )](source_dis.png)\n<!-- less -->\n&emsp;&emsp;好久没有更新博客了。原因是上个月文章修改意见下来了，第二轮大修，这酸爽，难以言表。\n&emsp;&emsp;不知道啥时候开始（大概是Fichter和Ermert的文章发表之后），做噪声互相关工作总会被审稿人问：噪声源影响有多大啊？难为人啊。要是能像Ermert他们把源和结构一块儿做了不就结了。但那是人家的手艺，捡起来难啊。\n&emsp;&emsp;另一个方法就是做模拟。给定源，计算两点波形，做胡相关，叠加。一维，近距离还好做，全球的三维的咋办？\n&emsp;&emsp;还好有大神啊。人家Tromp et al. (2010)早都弄出来了。就是用Specfem3d_globe就可以了。\n&emsp;&emsp;其实specfem3d_globe的说明文档已经讲的很清楚了，我这里就简单说一下。一般，波形的正演模拟只需要一步，而ensemble average的NCF需要两步，要计算敏感核函数需要三步。需要注意的点主要有：\n&emsp;&emsp;1，NCF的模拟不需要CMTSOLUTION，需将其六分量设置为0。\n&emsp;&emsp;2，There are other parameters in DATA/Par_file which should be given specific values. For instance, NUMBER_OF_RUNS and NUMBER_OF_THIS_RUN must be 1; ROTATE_SEISMOGRAMS_RT, SAVE_ALL_SEISMOGRAMS_IN_ONE_FILES, USE_BINARY_FOR_LARGE_FILE and MOVIE_COARSE should be .false.. Moreover, since the first two steps for calculating noise cross-correlation kernels correspond to forward simulations, SIMULATION_TYPE must be 1 when NOISE_TOMOGRAPHY equals 1 or 2. Also, we have to reconstruct the ensemble forward wavefields in adjoint simulations, therefore we need to set SAVE_FORWARD to .true. for the second step, i.e., when NOISE_TOMOGRAPHY equals 2. The third step is for kernel constructions. Hence SIMULATION_TYPE should be 3, whereas SAVE_FORWARD must be .false.. （从使用手册抄的，关于Par_file的设置)\n&emsp;&emsp;3，利用EXAMPLES/noise_examples/NOISE_TOMOGRAPHY.m (main program)和EXAMPLES/noise_examples/PetersonNoiseModel.m两个matlab程序获得S_squared。运行该程序需要提供NSTEP和dt。这两个参数在编译之后运行xcreate_header_file会显示。\n&emsp;&emsp;4，Create a file called NOISE_TOMOGRAPHY/irec_master_noise. Note that this file should be put in directory NOISE_TOMOGRAPHY as well. This file contains only one integer, which is the ID of the 'maste' receiver. For example, if in this file shows 5, it means that the fifth receiver listed in DATA/STATIONS becomes the ‘master’. That’s why we mentioned previously that the order of receivers in DATA/STATIONS important. （该文件定义了是哪个台与其他台的互相关）\n&emsp;&emsp;5，Create a file called NOISE_TOMOGRAPHY/nu_master. This file holds three numbers, forming a (unit) vector. It describes which component we are cross-correlating at the ‘master’ receiv. （该文件定义了哪些分量做胡相关）\n&emsp;&emsp;6，Describe the noise direction and distributions in src/specfem3d/noise_tomography.f90. Search for a subroutine called noise_distribution_direction in noise_tomography.f90. It is actually located at the very beginning of noise_tomography.f90. The default assumes vertical noises and a uniform distribution across the whole physical domain. It should be quite self-explanatory for modifications. Should you modify this part, you have to re-compile the source code. (again, that’s why we recommend that you alwaysre-compile the code before you run simulations)（这里根据需要自己给定噪声源的分布。）\n&emsp;&emsp;接下来就可以运行了。要得到NCF需要运行要两步，在修改参数运行第二步的时候一定要重新编译一下。\n&emsp;&emsp;然后就可以跑了。结果我老是跑不通，老是出错。多番检查发现错误出在子程序print_stf_file()，即输出震源时间函数的子程序。但没有弄明白为什么会出错。这个程序没有产生后续需要调用的参数。大胆的将其注释掉了。然后程序就跑通了。其实在Par_file里面将PRINT_SOURCE_TIME_FUNCTION改为false应该就可以了。在噪声源均匀的情况下，跑出来的NCF与single force差了pi/4，以及一些微小的差异。移动pi/4之后基本能够对上，应该是正确的了。Hooray!\n&emsp;&emsp;第三步我是没跑通，估计是因为空间不足，因为我看到中间数据就已经接近900G。不过我要的是synthetic NCF，足够了，有空再试sensitivity kernel吧。\n&emsp;&emsp;封面图是我用来做模拟的噪声源分布。结果表明源的影响不大啊。乐。\n","slug":"how-to-calculate-synthetic-NCF","published":1,"updated":"2024-05-26T14:17:36.847Z","comments":1,"layout":"post","photos":[],"_id":"cmh498ipa0056wvou9zu7dkzz","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>&emsp;&emsp;好久没有更新博客了。原因是上个月文章修改意见下来了，第二轮大修，这酸爽，难以言表。<br>&emsp;&emsp;不知道啥时候开始（大概是Fichter和Ermert的文章发表之后），做噪声互相关工作总会被审稿人问：噪声源影响有多大啊？难为人啊。要是能像Ermert他们把源和结构一块儿做了不就结了。但那是人家的手艺，捡起来难啊。<br>&emsp;&emsp;另一个方法就是做模拟。给定源，计算两点波形，做胡相关，叠加。一维，近距离还好做，全球的三维的咋办？<br>&emsp;&emsp;还好有大神啊。人家Tromp et al. (2010)早都弄出来了。就是用Specfem3d_globe就可以了。<br>&emsp;&emsp;其实specfem3d_globe的说明文档已经讲的很清楚了，我这里就简单说一下。一般，波形的正演模拟只需要一步，而ensemble average的NCF需要两步，要计算敏感核函数需要三步。需要注意的点主要有：<br>&emsp;&emsp;1，NCF的模拟不需要CMTSOLUTION，需将其六分量设置为0。<br>&emsp;&emsp;2，There are other parameters in DATA&#x2F;Par_file which should be given specific values. For instance, NUMBER_OF_RUNS and NUMBER_OF_THIS_RUN must be 1; ROTATE_SEISMOGRAMS_RT, SAVE_ALL_SEISMOGRAMS_IN_ONE_FILES, USE_BINARY_FOR_LARGE_FILE and MOVIE_COARSE should be .false.. Moreover, since the first two steps for calculating noise cross-correlation kernels correspond to forward simulations, SIMULATION_TYPE must be 1 when NOISE_TOMOGRAPHY equals 1 or 2. Also, we have to reconstruct the ensemble forward wavefields in adjoint simulations, therefore we need to set SAVE_FORWARD to .true. for the second step, i.e., when NOISE_TOMOGRAPHY equals 2. The third step is for kernel constructions. Hence SIMULATION_TYPE should be 3, whereas SAVE_FORWARD must be .false.. （从使用手册抄的，关于Par_file的设置)<br>&emsp;&emsp;3，利用EXAMPLES&#x2F;noise_examples&#x2F;NOISE_TOMOGRAPHY.m (main program)和EXAMPLES&#x2F;noise_examples&#x2F;PetersonNoiseModel.m两个matlab程序获得S_squared。运行该程序需要提供NSTEP和dt。这两个参数在编译之后运行xcreate_header_file会显示。<br>&emsp;&emsp;4，Create a file called NOISE_TOMOGRAPHY&#x2F;irec_master_noise. Note that this file should be put in directory NOISE_TOMOGRAPHY as well. This file contains only one integer, which is the ID of the ‘maste’ receiver. For example, if in this file shows 5, it means that the fifth receiver listed in DATA&#x2F;STATIONS becomes the ‘master’. That’s why we mentioned previously that the order of receivers in DATA&#x2F;STATIONS important. （该文件定义了是哪个台与其他台的互相关）<br>&emsp;&emsp;5，Create a file called NOISE_TOMOGRAPHY&#x2F;nu_master. This file holds three numbers, forming a (unit) vector. It describes which component we are cross-correlating at the ‘master’ receiv. （该文件定义了哪些分量做胡相关）<br>&emsp;&emsp;6，Describe the noise direction and distributions in src&#x2F;specfem3d&#x2F;noise_tomography.f90. Search for a subroutine called noise_distribution_direction in noise_tomography.f90. It is actually located at the very beginning of noise_tomography.f90. The default assumes vertical noises and a uniform distribution across the whole physical domain. It should be quite self-explanatory for modifications. Should you modify this part, you have to re-compile the source code. (again, that’s why we recommend that you alwaysre-compile the code before you run simulations)（这里根据需要自己给定噪声源的分布。）<br>&emsp;&emsp;接下来就可以运行了。要得到NCF需要运行要两步，在修改参数运行第二步的时候一定要重新编译一下。<br>&emsp;&emsp;然后就可以跑了。结果我老是跑不通，老是出错。多番检查发现错误出在子程序print_stf_file()，即输出震源时间函数的子程序。但没有弄明白为什么会出错。这个程序没有产生后续需要调用的参数。大胆的将其注释掉了。然后程序就跑通了。其实在Par_file里面将PRINT_SOURCE_TIME_FUNCTION改为false应该就可以了。在噪声源均匀的情况下，跑出来的NCF与single force差了pi&#x2F;4，以及一些微小的差异。移动pi&#x2F;4之后基本能够对上，应该是正确的了。Hooray!<br>&emsp;&emsp;第三步我是没跑通，估计是因为空间不足，因为我看到中间数据就已经接近900G。不过我要的是synthetic NCF，足够了，有空再试sensitivity kernel吧。<br>&emsp;&emsp;封面图是我用来做模拟的噪声源分布。结果表明源的影响不大啊。乐。</p>","related_posts":["git-error.html","how-to-add-frame.html","python-script2.html"],"length":2963,"excerpt":"<p><img src=\"/source_dis.png\" alt=\"Distribution of ambient noise sources (100-300 s) (Ermert et al., 2017 )\"></p>","more":"<p>&emsp;&emsp;好久没有更新博客了。原因是上个月文章修改意见下来了，第二轮大修，这酸爽，难以言表。<br>&emsp;&emsp;不知道啥时候开始（大概是Fichter和Ermert的文章发表之后），做噪声互相关工作总会被审稿人问：噪声源影响有多大啊？难为人啊。要是能像Ermert他们把源和结构一块儿做了不就结了。但那是人家的手艺，捡起来难啊。<br>&emsp;&emsp;另一个方法就是做模拟。给定源，计算两点波形，做胡相关，叠加。一维，近距离还好做，全球的三维的咋办？<br>&emsp;&emsp;还好有大神啊。人家Tromp et al. (2010)早都弄出来了。就是用Specfem3d_globe就可以了。<br>&emsp;&emsp;其实specfem3d_globe的说明文档已经讲的很清楚了，我这里就简单说一下。一般，波形的正演模拟只需要一步，而ensemble average的NCF需要两步，要计算敏感核函数需要三步。需要注意的点主要有：<br>&emsp;&emsp;1，NCF的模拟不需要CMTSOLUTION，需将其六分量设置为0。<br>&emsp;&emsp;2，There are other parameters in DATA&#x2F;Par_file which should be given specific values. For instance, NUMBER_OF_RUNS and NUMBER_OF_THIS_RUN must be 1; ROTATE_SEISMOGRAMS_RT, SAVE_ALL_SEISMOGRAMS_IN_ONE_FILES, USE_BINARY_FOR_LARGE_FILE and MOVIE_COARSE should be .false.. Moreover, since the first two steps for calculating noise cross-correlation kernels correspond to forward simulations, SIMULATION_TYPE must be 1 when NOISE_TOMOGRAPHY equals 1 or 2. Also, we have to reconstruct the ensemble forward wavefields in adjoint simulations, therefore we need to set SAVE_FORWARD to .true. for the second step, i.e., when NOISE_TOMOGRAPHY equals 2. The third step is for kernel constructions. Hence SIMULATION_TYPE should be 3, whereas SAVE_FORWARD must be .false.. （从使用手册抄的，关于Par_file的设置)<br>&emsp;&emsp;3，利用EXAMPLES&#x2F;noise_examples&#x2F;NOISE_TOMOGRAPHY.m (main program)和EXAMPLES&#x2F;noise_examples&#x2F;PetersonNoiseModel.m两个matlab程序获得S_squared。运行该程序需要提供NSTEP和dt。这两个参数在编译之后运行xcreate_header_file会显示。<br>&emsp;&emsp;4，Create a file called NOISE_TOMOGRAPHY&#x2F;irec_master_noise. Note that this file should be put in directory NOISE_TOMOGRAPHY as well. This file contains only one integer, which is the ID of the ‘maste’ receiver. For example, if in this file shows 5, it means that the fifth receiver listed in DATA&#x2F;STATIONS becomes the ‘master’. That’s why we mentioned previously that the order of receivers in DATA&#x2F;STATIONS important. （该文件定义了是哪个台与其他台的互相关）<br>&emsp;&emsp;5，Create a file called NOISE_TOMOGRAPHY&#x2F;nu_master. This file holds three numbers, forming a (unit) vector. It describes which component we are cross-correlating at the ‘master’ receiv. （该文件定义了哪些分量做胡相关）<br>&emsp;&emsp;6，Describe the noise direction and distributions in src&#x2F;specfem3d&#x2F;noise_tomography.f90. Search for a subroutine called noise_distribution_direction in noise_tomography.f90. It is actually located at the very beginning of noise_tomography.f90. The default assumes vertical noises and a uniform distribution across the whole physical domain. It should be quite self-explanatory for modifications. Should you modify this part, you have to re-compile the source code. (again, that’s why we recommend that you alwaysre-compile the code before you run simulations)（这里根据需要自己给定噪声源的分布。）<br>&emsp;&emsp;接下来就可以运行了。要得到NCF需要运行要两步，在修改参数运行第二步的时候一定要重新编译一下。<br>&emsp;&emsp;然后就可以跑了。结果我老是跑不通，老是出错。多番检查发现错误出在子程序print_stf_file()，即输出震源时间函数的子程序。但没有弄明白为什么会出错。这个程序没有产生后续需要调用的参数。大胆的将其注释掉了。然后程序就跑通了。其实在Par_file里面将PRINT_SOURCE_TIME_FUNCTION改为false应该就可以了。在噪声源均匀的情况下，跑出来的NCF与single force差了pi&#x2F;4，以及一些微小的差异。移动pi&#x2F;4之后基本能够对上，应该是正确的了。Hooray!<br>&emsp;&emsp;第三步我是没跑通，估计是因为空间不足，因为我看到中间数据就已经接近900G。不过我要的是synthetic NCF，足够了，有空再试sensitivity kernel吧。<br>&emsp;&emsp;封面图是我用来做模拟的噪声源分布。结果表明源的影响不大啊。乐。</p>"},{"title":"如何下载网上的视频","abbrlink":"e17f06b7","date":"2020-09-25T08:20:54.000Z","_content":"&emsp;&emsp;很多时候在线看视频遇到喜欢的就想下载下来慢慢欣赏。那如何下载呢？\n<!-- more -->\n&emsp;&emsp;每次都需要到某度搜索。结果大量的广告，烦银。搞定了吧，下次又给忘了。今天就记录一下，免得下次又去找某度，碍眼。\n&emsp;&emsp;估计以后某度会没得搞头吧，除了广告还充斥着各路货色。知乎里面回答那么多，那么详细，自然是用手投票啦。\n&emsp;&emsp;说回正题，总算搜到一个强大的python程序，叫做you-get。说是下啥平台的视频都行。安装命令是这个样子的：\n```\nsudo pip3 install you-get\n```\n&emsp;&emsp;然后要下载视频的话就运行这个命令：\n```\nyou-get 视频网址\n```\n&emsp;&emsp;就可以下载了。so easy。妈妈再也不用担心。。。慢着，下载下来是flv，虽然高清，但似乎一些视频软件打不开，编辑不能。咋办？转换格式呗。\n&emsp;&emsp;哎～我又不争气的用了某度。果然，浪费我大把时间还弄得不快。什么在线转换，要么只能转小视频（极小），要么买app咯，气人。转换个格式，我买个app干嘛。这样子就可以了：\n```\nffmpeg -i input.flv -c copy output.mp4\n```\n&emsp;&emsp;下载下来的视频太长了，想要剪切出其中的片段咋办？像这样：\n```\nffmpeg -ss 00:00:05 -t 00:00:10 -i input.mp4 -q 0 output.mp4\n```\n&emsp;&emsp;就可以从5秒开始剪出10秒的片段。哈，大功告成。\n","source":"_posts/2020-09-25-how-to-download-video-from-internet.md","raw":"---\ntitle: 如何下载网上的视频\ncategories:\n  - web\ntags:\n  - video\nabbrlink: e17f06b7\ndate: 2020-09-25 16:20:54\n---\n&emsp;&emsp;很多时候在线看视频遇到喜欢的就想下载下来慢慢欣赏。那如何下载呢？\n<!-- more -->\n&emsp;&emsp;每次都需要到某度搜索。结果大量的广告，烦银。搞定了吧，下次又给忘了。今天就记录一下，免得下次又去找某度，碍眼。\n&emsp;&emsp;估计以后某度会没得搞头吧，除了广告还充斥着各路货色。知乎里面回答那么多，那么详细，自然是用手投票啦。\n&emsp;&emsp;说回正题，总算搜到一个强大的python程序，叫做you-get。说是下啥平台的视频都行。安装命令是这个样子的：\n```\nsudo pip3 install you-get\n```\n&emsp;&emsp;然后要下载视频的话就运行这个命令：\n```\nyou-get 视频网址\n```\n&emsp;&emsp;就可以下载了。so easy。妈妈再也不用担心。。。慢着，下载下来是flv，虽然高清，但似乎一些视频软件打不开，编辑不能。咋办？转换格式呗。\n&emsp;&emsp;哎～我又不争气的用了某度。果然，浪费我大把时间还弄得不快。什么在线转换，要么只能转小视频（极小），要么买app咯，气人。转换个格式，我买个app干嘛。这样子就可以了：\n```\nffmpeg -i input.flv -c copy output.mp4\n```\n&emsp;&emsp;下载下来的视频太长了，想要剪切出其中的片段咋办？像这样：\n```\nffmpeg -ss 00:00:05 -t 00:00:10 -i input.mp4 -q 0 output.mp4\n```\n&emsp;&emsp;就可以从5秒开始剪出10秒的片段。哈，大功告成。\n","slug":"how-to-download-video-from-internet","published":1,"updated":"2024-05-26T14:17:36.847Z","comments":1,"layout":"post","photos":[],"_id":"cmh498ipb005awvou33w65i5m","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>&emsp;&emsp;很多时候在线看视频遇到喜欢的就想下载下来慢慢欣赏。那如何下载呢？</p>\n<span id=\"more\"></span>\n<p>&emsp;&emsp;每次都需要到某度搜索。结果大量的广告，烦银。搞定了吧，下次又给忘了。今天就记录一下，免得下次又去找某度，碍眼。<br>&emsp;&emsp;估计以后某度会没得搞头吧，除了广告还充斥着各路货色。知乎里面回答那么多，那么详细，自然是用手投票啦。<br>&emsp;&emsp;说回正题，总算搜到一个强大的python程序，叫做you-get。说是下啥平台的视频都行。安装命令是这个样子的：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo pip3 install you-get</span><br></pre></td></tr></table></figure>\n<p>&emsp;&emsp;然后要下载视频的话就运行这个命令：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">you-get 视频网址</span><br></pre></td></tr></table></figure>\n<p>&emsp;&emsp;就可以下载了。so easy。妈妈再也不用担心。。。慢着，下载下来是flv，虽然高清，但似乎一些视频软件打不开，编辑不能。咋办？转换格式呗。<br>&emsp;&emsp;哎～我又不争气的用了某度。果然，浪费我大把时间还弄得不快。什么在线转换，要么只能转小视频（极小），要么买app咯，气人。转换个格式，我买个app干嘛。这样子就可以了：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ffmpeg -i input.flv -c copy output.mp4</span><br></pre></td></tr></table></figure>\n<p>&emsp;&emsp;下载下来的视频太长了，想要剪切出其中的片段咋办？像这样：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ffmpeg -ss 00:00:05 -t 00:00:10 -i input.mp4 -q 0 output.mp4</span><br></pre></td></tr></table></figure>\n<p>&emsp;&emsp;就可以从5秒开始剪出10秒的片段。哈，大功告成。</p>\n","related_posts":[],"length":643,"excerpt":"<p>&emsp;&emsp;很多时候在线看视频遇到喜欢的就想下载下来慢慢欣赏。那如何下载呢？</p>","more":"<p>&emsp;&emsp;每次都需要到某度搜索。结果大量的广告，烦银。搞定了吧，下次又给忘了。今天就记录一下，免得下次又去找某度，碍眼。<br>&emsp;&emsp;估计以后某度会没得搞头吧，除了广告还充斥着各路货色。知乎里面回答那么多，那么详细，自然是用手投票啦。<br>&emsp;&emsp;说回正题，总算搜到一个强大的python程序，叫做you-get。说是下啥平台的视频都行。安装命令是这个样子的：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo pip3 install you-get</span><br></pre></td></tr></table></figure>\n<p>&emsp;&emsp;然后要下载视频的话就运行这个命令：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">you-get 视频网址</span><br></pre></td></tr></table></figure>\n<p>&emsp;&emsp;就可以下载了。so easy。妈妈再也不用担心。。。慢着，下载下来是flv，虽然高清，但似乎一些视频软件打不开，编辑不能。咋办？转换格式呗。<br>&emsp;&emsp;哎～我又不争气的用了某度。果然，浪费我大把时间还弄得不快。什么在线转换，要么只能转小视频（极小），要么买app咯，气人。转换个格式，我买个app干嘛。这样子就可以了：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ffmpeg -i input.flv -c copy output.mp4</span><br></pre></td></tr></table></figure>\n<p>&emsp;&emsp;下载下来的视频太长了，想要剪切出其中的片段咋办？像这样：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ffmpeg -ss 00:00:05 -t 00:00:10 -i input.mp4 -q 0 output.mp4</span><br></pre></td></tr></table></figure>\n<p>&emsp;&emsp;就可以从5秒开始剪出10秒的片段。哈，大功告成。</p>"},{"title":"文章第三轮大修","abbrlink":"9fea4b1b","date":"2020-11-07T08:56:45.000Z","_content":"&emsp;&emsp;文章的审稿意见今天又双叒下来了，值得记录一下。\n<!-- more -->\n&emsp;&emsp;这是一篇怼人的文章，连发表以后发moment的内容都想好了：我不是针对谁，只是各位的model都有问题。。。然而目前为止已经是第三次大修意见。首先要庆幸一下没有拒绝，因为有听过有人在大修中修之后又给据了的，相比起来还是给了希望啊。然而三次大修还是挺折磨。这次审稿人1觉得上次改的还不错建议小修，但审稿人2找不着了。主编找了另一个审稿人审，又提出大量问题和建议。虽然意见多到完成他的建议足够另写一篇，但很中肯，且留了大名。这是第一次审稿人留大名，值得纪念一下，且此人还是业内大牛，想想还是挺开心的。\n&emsp;&emsp;脑子里一直在纠结这篇文章到底怎么个改法。每次大修回来都感觉无从下手。而在老板眼里似乎跟已经接收了在proof一样。看到知乎的一个问题说：上了985为什么还焦虑？我回答，上985和焦不焦虑没有半毛钱关系。\n&emsp;&emsp;自己总是很难持之以恒的完成设定的小目标，例如每天看一片文献啥的。很羡慕这个[Steve Pavlina](https://www.stevepavlina.com/)博主，每天都坚持写一篇博文。他说要是做不到你的目标的话那就把目标做的更加容易一些。例如不能做到每天都念一篇文章，那就每天都看一篇文章的题目。之后，每天看一篇文章的摘要，完成以后每天就看introduction，逐渐增加。慢慢就能完成了。那就按照他的建议先试试^_^。\n","source":"_posts/2020-11-07-about-anti-paper.md","raw":"---\ntitle: 文章第三轮大修\ncategories:\n  - 日记\nabbrlink: 9fea4b1b\ndate: 2020-11-07 16:56:45\ntags:\n---\n&emsp;&emsp;文章的审稿意见今天又双叒下来了，值得记录一下。\n<!-- more -->\n&emsp;&emsp;这是一篇怼人的文章，连发表以后发moment的内容都想好了：我不是针对谁，只是各位的model都有问题。。。然而目前为止已经是第三次大修意见。首先要庆幸一下没有拒绝，因为有听过有人在大修中修之后又给据了的，相比起来还是给了希望啊。然而三次大修还是挺折磨。这次审稿人1觉得上次改的还不错建议小修，但审稿人2找不着了。主编找了另一个审稿人审，又提出大量问题和建议。虽然意见多到完成他的建议足够另写一篇，但很中肯，且留了大名。这是第一次审稿人留大名，值得纪念一下，且此人还是业内大牛，想想还是挺开心的。\n&emsp;&emsp;脑子里一直在纠结这篇文章到底怎么个改法。每次大修回来都感觉无从下手。而在老板眼里似乎跟已经接收了在proof一样。看到知乎的一个问题说：上了985为什么还焦虑？我回答，上985和焦不焦虑没有半毛钱关系。\n&emsp;&emsp;自己总是很难持之以恒的完成设定的小目标，例如每天看一片文献啥的。很羡慕这个[Steve Pavlina](https://www.stevepavlina.com/)博主，每天都坚持写一篇博文。他说要是做不到你的目标的话那就把目标做的更加容易一些。例如不能做到每天都念一篇文章，那就每天都看一篇文章的题目。之后，每天看一篇文章的摘要，完成以后每天就看introduction，逐渐增加。慢慢就能完成了。那就按照他的建议先试试^_^。\n","slug":"about-anti-paper","published":1,"updated":"2024-05-26T14:17:36.847Z","comments":1,"layout":"post","photos":[],"_id":"cmh498ipb005cwvoueg0y9kmy","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>&emsp;&emsp;文章的审稿意见今天又双叒下来了，值得记录一下。</p>\n<span id=\"more\"></span>\n<p>&emsp;&emsp;这是一篇怼人的文章，连发表以后发moment的内容都想好了：我不是针对谁，只是各位的model都有问题。。。然而目前为止已经是第三次大修意见。首先要庆幸一下没有拒绝，因为有听过有人在大修中修之后又给据了的，相比起来还是给了希望啊。然而三次大修还是挺折磨。这次审稿人1觉得上次改的还不错建议小修，但审稿人2找不着了。主编找了另一个审稿人审，又提出大量问题和建议。虽然意见多到完成他的建议足够另写一篇，但很中肯，且留了大名。这是第一次审稿人留大名，值得纪念一下，且此人还是业内大牛，想想还是挺开心的。<br>&emsp;&emsp;脑子里一直在纠结这篇文章到底怎么个改法。每次大修回来都感觉无从下手。而在老板眼里似乎跟已经接收了在proof一样。看到知乎的一个问题说：上了985为什么还焦虑？我回答，上985和焦不焦虑没有半毛钱关系。<br>&emsp;&emsp;自己总是很难持之以恒的完成设定的小目标，例如每天看一片文献啥的。很羡慕这个<a href=\"https://www.stevepavlina.com/\">Steve Pavlina</a>博主，每天都坚持写一篇博文。他说要是做不到你的目标的话那就把目标做的更加容易一些。例如不能做到每天都念一篇文章，那就每天都看一篇文章的题目。之后，每天看一篇文章的摘要，完成以后每天就看introduction，逐渐增加。慢慢就能完成了。那就按照他的建议先试试^_^。</p>\n","related_posts":["happy-new-year.html"],"length":602,"excerpt":"<p>&emsp;&emsp;文章的审稿意见今天又双叒下来了，值得记录一下。</p>","more":"<p>&emsp;&emsp;这是一篇怼人的文章，连发表以后发moment的内容都想好了：我不是针对谁，只是各位的model都有问题。。。然而目前为止已经是第三次大修意见。首先要庆幸一下没有拒绝，因为有听过有人在大修中修之后又给据了的，相比起来还是给了希望啊。然而三次大修还是挺折磨。这次审稿人1觉得上次改的还不错建议小修，但审稿人2找不着了。主编找了另一个审稿人审，又提出大量问题和建议。虽然意见多到完成他的建议足够另写一篇，但很中肯，且留了大名。这是第一次审稿人留大名，值得纪念一下，且此人还是业内大牛，想想还是挺开心的。<br>&emsp;&emsp;脑子里一直在纠结这篇文章到底怎么个改法。每次大修回来都感觉无从下手。而在老板眼里似乎跟已经接收了在proof一样。看到知乎的一个问题说：上了985为什么还焦虑？我回答，上985和焦不焦虑没有半毛钱关系。<br>&emsp;&emsp;自己总是很难持之以恒的完成设定的小目标，例如每天看一片文献啥的。很羡慕这个<a href=\"https://www.stevepavlina.com/\">Steve Pavlina</a>博主，每天都坚持写一篇博文。他说要是做不到你的目标的话那就把目标做的更加容易一些。例如不能做到每天都念一篇文章，那就每天都看一篇文章的题目。之后，每天看一篇文章的摘要，完成以后每天就看introduction，逐渐增加。慢慢就能完成了。那就按照他的建议先试试^_^。</p>"},{"title":"关于瘾","abbrlink":"7f26de1c","date":"2020-11-19T06:07:30.000Z","_content":"&emsp;&emsp;什么是瘾？\n<!-- more -->\n&emsp;&emsp;读了Steve Pavlina这篇博文[Pleasure Is Not Addictive](https://www.stevepavlina.com/blog/2020/11/pleasure-is-not-addictive/?utm_source=rss&utm_medium=rss&utm_campaign=pleasure-is-not-addictive)挺有感悟的。他说寻求快乐本身是没有什么危害的，也不会成瘾。成瘾的原因主要是因为逃避，逃避一个大的困难、问题、创伤、压力、恐惧或者羞愧。我觉得很有道理。例如逃避生活，逃避同行压力，没钱的状态等都会让你在其他的小事当中寻找所谓的快乐，例如有的人抽烟，有的人喝酒，有的人打游戏，有的人看视频。这种快乐是短暂的，不能解决更大的问题，而且通常会让大的问题更糟糕。\n&emsp;&emsp;成瘾时通常自己无法控制。拒绝承认自己逃避更大的问题是一种瘾，过度的去纠正去改掉这个瘾也是一种瘾。\n&emsp;&emsp;那怎么办呢？Steve Pavlina说“You do not need immediate solutions to life’s biggest challenges. What’s needed is an improvement in your relationships with those challenges. Instead of seeing them as curses or demons to be avoided, try framing them as invitations to learn, grow, and improve.”首先要想，我逃避的是什么？为什么我一定要逃避？我害怕的是啥？我该怎么去面对？这给了我一个怎样的提升的机会？直面生活的困难和挑战，而不要去逃避，寻找你的担忧和羞愧背后的好的美的一面。这会给你带来莫大的帮助。\n&emsp;&emsp;快乐是用来享受的，然而，如果你将寻求快乐当做了逃避问题的方式，更大的痛苦也将在快乐中植根。接受生活带给你的挑战，因为那也是一个机遇，拥抱生活带给你的快乐。\n","source":"_posts/2020-11-19-addiction.md","raw":"---\ntitle: 关于瘾\ncategories:\n  - 杂\ntags:\n  - 瘾\nabbrlink: 7f26de1c\ndate: 2020-11-19 14:07:30\n---\n&emsp;&emsp;什么是瘾？\n<!-- more -->\n&emsp;&emsp;读了Steve Pavlina这篇博文[Pleasure Is Not Addictive](https://www.stevepavlina.com/blog/2020/11/pleasure-is-not-addictive/?utm_source=rss&utm_medium=rss&utm_campaign=pleasure-is-not-addictive)挺有感悟的。他说寻求快乐本身是没有什么危害的，也不会成瘾。成瘾的原因主要是因为逃避，逃避一个大的困难、问题、创伤、压力、恐惧或者羞愧。我觉得很有道理。例如逃避生活，逃避同行压力，没钱的状态等都会让你在其他的小事当中寻找所谓的快乐，例如有的人抽烟，有的人喝酒，有的人打游戏，有的人看视频。这种快乐是短暂的，不能解决更大的问题，而且通常会让大的问题更糟糕。\n&emsp;&emsp;成瘾时通常自己无法控制。拒绝承认自己逃避更大的问题是一种瘾，过度的去纠正去改掉这个瘾也是一种瘾。\n&emsp;&emsp;那怎么办呢？Steve Pavlina说“You do not need immediate solutions to life’s biggest challenges. What’s needed is an improvement in your relationships with those challenges. Instead of seeing them as curses or demons to be avoided, try framing them as invitations to learn, grow, and improve.”首先要想，我逃避的是什么？为什么我一定要逃避？我害怕的是啥？我该怎么去面对？这给了我一个怎样的提升的机会？直面生活的困难和挑战，而不要去逃避，寻找你的担忧和羞愧背后的好的美的一面。这会给你带来莫大的帮助。\n&emsp;&emsp;快乐是用来享受的，然而，如果你将寻求快乐当做了逃避问题的方式，更大的痛苦也将在快乐中植根。接受生活带给你的挑战，因为那也是一个机遇，拥抱生活带给你的快乐。\n","slug":"addiction","published":1,"updated":"2024-05-26T14:17:36.847Z","comments":1,"layout":"post","photos":[],"_id":"cmh498ipc005fwvou5ihu2ewt","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>&emsp;&emsp;什么是瘾？</p>\n<span id=\"more\"></span>\n<p>&emsp;&emsp;读了Steve Pavlina这篇博文<a href=\"https://www.stevepavlina.com/blog/2020/11/pleasure-is-not-addictive/?utm_source=rss&utm_medium=rss&utm_campaign=pleasure-is-not-addictive\">Pleasure Is Not Addictive</a>挺有感悟的。他说寻求快乐本身是没有什么危害的，也不会成瘾。成瘾的原因主要是因为逃避，逃避一个大的困难、问题、创伤、压力、恐惧或者羞愧。我觉得很有道理。例如逃避生活，逃避同行压力，没钱的状态等都会让你在其他的小事当中寻找所谓的快乐，例如有的人抽烟，有的人喝酒，有的人打游戏，有的人看视频。这种快乐是短暂的，不能解决更大的问题，而且通常会让大的问题更糟糕。<br>&emsp;&emsp;成瘾时通常自己无法控制。拒绝承认自己逃避更大的问题是一种瘾，过度的去纠正去改掉这个瘾也是一种瘾。<br>&emsp;&emsp;那怎么办呢？Steve Pavlina说“You do not need immediate solutions to life’s biggest challenges. What’s needed is an improvement in your relationships with those challenges. Instead of seeing them as curses or demons to be avoided, try framing them as invitations to learn, grow, and improve.”首先要想，我逃避的是什么？为什么我一定要逃避？我害怕的是啥？我该怎么去面对？这给了我一个怎样的提升的机会？直面生活的困难和挑战，而不要去逃避，寻找你的担忧和羞愧背后的好的美的一面。这会给你带来莫大的帮助。<br>&emsp;&emsp;快乐是用来享受的，然而，如果你将寻求快乐当做了逃避问题的方式，更大的痛苦也将在快乐中植根。接受生活带给你的挑战，因为那也是一个机遇，拥抱生活带给你的快乐。</p>\n","related_posts":["code-and-project1.html"],"length":749,"excerpt":"<p>&emsp;&emsp;什么是瘾？</p>","more":"<p>&emsp;&emsp;读了Steve Pavlina这篇博文<a href=\"https://www.stevepavlina.com/blog/2020/11/pleasure-is-not-addictive/?utm_source=rss&utm_medium=rss&utm_campaign=pleasure-is-not-addictive\">Pleasure Is Not Addictive</a>挺有感悟的。他说寻求快乐本身是没有什么危害的，也不会成瘾。成瘾的原因主要是因为逃避，逃避一个大的困难、问题、创伤、压力、恐惧或者羞愧。我觉得很有道理。例如逃避生活，逃避同行压力，没钱的状态等都会让你在其他的小事当中寻找所谓的快乐，例如有的人抽烟，有的人喝酒，有的人打游戏，有的人看视频。这种快乐是短暂的，不能解决更大的问题，而且通常会让大的问题更糟糕。<br>&emsp;&emsp;成瘾时通常自己无法控制。拒绝承认自己逃避更大的问题是一种瘾，过度的去纠正去改掉这个瘾也是一种瘾。<br>&emsp;&emsp;那怎么办呢？Steve Pavlina说“You do not need immediate solutions to life’s biggest challenges. What’s needed is an improvement in your relationships with those challenges. Instead of seeing them as curses or demons to be avoided, try framing them as invitations to learn, grow, and improve.”首先要想，我逃避的是什么？为什么我一定要逃避？我害怕的是啥？我该怎么去面对？这给了我一个怎样的提升的机会？直面生活的困难和挑战，而不要去逃避，寻找你的担忧和羞愧背后的好的美的一面。这会给你带来莫大的帮助。<br>&emsp;&emsp;快乐是用来享受的，然而，如果你将寻求快乐当做了逃避问题的方式，更大的痛苦也将在快乐中植根。接受生活带给你的挑战，因为那也是一个机遇，拥抱生活带给你的快乐。</p>"},{"title":"为啥要这样安装FileZilla","abbrlink":"dea40c8a","date":"2020-11-20T15:27:46.000Z","_content":"&emsp;&emsp;本地到服务器的数据传输使用FileZilla程序比较方便和稳定。只是Linux下需要编译安装该程序，那还不易热儿，那就安装呗。然而安装过程让人迷糊，复杂程度让人难忘，特此记录一下。遗憾的是，花了我两天时间，到现在为止，该程序仍然没有安装成功。\n<!-- more -->\n&emsp;&emsp;首先在<https://filezilla-project.org/>下载了个可执行程序---显然是运行不了的。仔细看发现是在debian10.0下编译的。我的系统是Fedora和Elementary OS5，两个都运行不了。然后下载了源程序FileZilla_3.51.0_src.tar.bz2。\n&emsp;&emsp;解压，安装filezilla-3.51.0，编译过程出错，显示没有安装libfilezilla。\n&emsp;&emsp;于是下载libfilezilla-0.25.0.tar.bz2，解压，安装libfilezilla-0.25.0，编译过程出错，显示没有安装有nettle。\n&emsp;&emsp;于是下载nettle-3.6.tar.gz，解压编译安装nettle-3.6一次通过。\n&emsp;&emsp;然后在libfilezilla-0.25.0下预编译，出错，显示：\n``` bash\nconfigure: error: hogweed 3.3 greater was not found. You can get it from https://www.lysator.liu.se/~nisse/nettle/\n```\n&emsp;&emsp;于是重装nettle-3.6\n```bash\n./configure --enable-mini-gmp\nmake\nmake check\nmake install\n```\n&emsp;&emsp;安装成功，然后在libfilezilla-0.25.0下预编译，出错，显示：\n```bash\nconfigure: error: GnuTLS 3.5.8 or greater was not found. You can get it from https://gnutls.org/\n```\n&emsp;&emsp;然后下载gnutls-3.6.15.tar.xz，解压gnutls-3.6.15编译出错，显示：\n``` bash\nconfigure: error: \n***\n*** gmp was not found.\n```\n&emsp;&emsp;然后下载gmp-6.1.0.tar.bz2，解压gmp-6.1.0，编译安装完成。回到gnutls-3.6.15再次编译出错，显示：\n``` bash\nconfigure: error: \n  ***\n  *** Libtasn1 4.9 was not found. To use the included one, use --with-included-libtasn1\n```\n&emsp;&emsp;然后下载libtasn1-4.9.tar.gz，解压libtasn1-4.9，编译出错，显示：\n``` bash\nASN1.c: In function '_asn1_yyparse':\nASN1.y:152:47: error: '__builtin___snprintf_chk' output may be truncated before the last format character [-Werror=format-truncation=]\n neg_num : '-' NUM     {snprintf($$,sizeof($$),\"-%s\",$2);}\n                                               ^~~~~\nIn file included from /usr/include/stdio.h:862:0,\n                 from ./int.h:31,\n                 from ASN1.y:30:\n/usr/include/x86_64-linux-gnu/bits/stdio2.h:64:10: note: '__builtin___snprintf_chk' output between 2 and 66 bytes into a destination of size 65\n   return __builtin___snprintf_chk (__s, __n, __USE_FORTIFY_LEVEL - 1,\n          ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n        __bos (__s), __fmt, __va_arg_pack ());\n        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nASN1.y:164:47: error: '__builtin___snprintf_chk' output may be truncated before the last format character [-Werror=format-truncation=]\n                 | '-' NUM        {snprintf($$,sizeof($$),\"-%s\",$2);}\n                                               ^~~~~\nIn file included from /usr/include/stdio.h:862:0,\n                 from ./int.h:31,\n                 from ASN1.y:30:\n/usr/include/x86_64-linux-gnu/bits/stdio2.h:64:10: note: '__builtin___snprintf_chk' output between 2 and 66 bytes into a destination of size 65\n   return __builtin___snprintf_chk (__s, __n, __USE_FORTIFY_LEVEL - 1,\n          ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n        __bos (__s), __fmt, __va_arg_pack ());\n        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\ncc1: all warnings being treated as errors\nMakefile:1112: recipe for target 'ASN1.lo' failed\nmake[2]: *** [ASN1.lo] Error 1\nmake[2]: Leaving directory '/home/junxie/Downloads/libtasn1-4.9/lib'\nMakefile:1176: recipe for target 'check-recursive' failed\nmake[1]: *** [check-recursive] Error 1\nmake[1]: Leaving directory '/home/junxie/Downloads/libtasn1-4.9/lib'\nMakefile:1009: recipe for target 'check-recursive' failed\nmake: *** [check-recursive] Error 1\n```\n&emsp;&emsp;至此，我已几近崩溃，已经不知道自己在哪儿，是要干啥。网上已经几乎找不到相关问题词条，估计还没有人遇到过这些问题。\n&emsp;&emsp;很想吐槽一下Linux。虽然用户可以随心所欲DIY，但是起点似乎有点太高。所谓的DIY也不过是把好多人写的代码集合在自己电脑上编译，源代码长什么样我虽然比较关心，但哪有时间闲情和精力去看？\n&emsp;&emsp;像我这种需要用到Linux方便处理大量数据和程序编译的便利，又需要用到现成较为成熟程序包编译而不可得的情况，属实尴尬。\n&emsp;&emsp;我又想到了Python。这个脚本语言似乎厉害透顶，几乎所有人都在学，都在用。人们纷纷把以往用fortran，C写的代码转成python或者用python给他们穿身衣服、塑个金身，显得高大上，自诩又为代码社区立功劳。可结果用起来嘛，一言难尽。某些脚本只能用python2运行，另一些又只能用python3。有些程序首次用还总告诉你某某module找不到。安装起来还常常不成功。使用起来十分不友好。真是让人头疼、恼火、焦躁。也不知大家是怎么喜欢上的。只能怪自己太菜，还没对python开窍吧。\n&emsp;&emsp;谁能指条明路？\n","source":"_posts/2020-11-20-how-to-install-filezilla.md","raw":"---\ntitle: 为啥要这样安装FileZilla\ncategories:\n  - Linux\ntags:\n  - filezilla\nabbrlink: dea40c8a\ndate: 2020-11-20 23:27:46\n---\n&emsp;&emsp;本地到服务器的数据传输使用FileZilla程序比较方便和稳定。只是Linux下需要编译安装该程序，那还不易热儿，那就安装呗。然而安装过程让人迷糊，复杂程度让人难忘，特此记录一下。遗憾的是，花了我两天时间，到现在为止，该程序仍然没有安装成功。\n<!-- more -->\n&emsp;&emsp;首先在<https://filezilla-project.org/>下载了个可执行程序---显然是运行不了的。仔细看发现是在debian10.0下编译的。我的系统是Fedora和Elementary OS5，两个都运行不了。然后下载了源程序FileZilla_3.51.0_src.tar.bz2。\n&emsp;&emsp;解压，安装filezilla-3.51.0，编译过程出错，显示没有安装libfilezilla。\n&emsp;&emsp;于是下载libfilezilla-0.25.0.tar.bz2，解压，安装libfilezilla-0.25.0，编译过程出错，显示没有安装有nettle。\n&emsp;&emsp;于是下载nettle-3.6.tar.gz，解压编译安装nettle-3.6一次通过。\n&emsp;&emsp;然后在libfilezilla-0.25.0下预编译，出错，显示：\n``` bash\nconfigure: error: hogweed 3.3 greater was not found. You can get it from https://www.lysator.liu.se/~nisse/nettle/\n```\n&emsp;&emsp;于是重装nettle-3.6\n```bash\n./configure --enable-mini-gmp\nmake\nmake check\nmake install\n```\n&emsp;&emsp;安装成功，然后在libfilezilla-0.25.0下预编译，出错，显示：\n```bash\nconfigure: error: GnuTLS 3.5.8 or greater was not found. You can get it from https://gnutls.org/\n```\n&emsp;&emsp;然后下载gnutls-3.6.15.tar.xz，解压gnutls-3.6.15编译出错，显示：\n``` bash\nconfigure: error: \n***\n*** gmp was not found.\n```\n&emsp;&emsp;然后下载gmp-6.1.0.tar.bz2，解压gmp-6.1.0，编译安装完成。回到gnutls-3.6.15再次编译出错，显示：\n``` bash\nconfigure: error: \n  ***\n  *** Libtasn1 4.9 was not found. To use the included one, use --with-included-libtasn1\n```\n&emsp;&emsp;然后下载libtasn1-4.9.tar.gz，解压libtasn1-4.9，编译出错，显示：\n``` bash\nASN1.c: In function '_asn1_yyparse':\nASN1.y:152:47: error: '__builtin___snprintf_chk' output may be truncated before the last format character [-Werror=format-truncation=]\n neg_num : '-' NUM     {snprintf($$,sizeof($$),\"-%s\",$2);}\n                                               ^~~~~\nIn file included from /usr/include/stdio.h:862:0,\n                 from ./int.h:31,\n                 from ASN1.y:30:\n/usr/include/x86_64-linux-gnu/bits/stdio2.h:64:10: note: '__builtin___snprintf_chk' output between 2 and 66 bytes into a destination of size 65\n   return __builtin___snprintf_chk (__s, __n, __USE_FORTIFY_LEVEL - 1,\n          ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n        __bos (__s), __fmt, __va_arg_pack ());\n        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nASN1.y:164:47: error: '__builtin___snprintf_chk' output may be truncated before the last format character [-Werror=format-truncation=]\n                 | '-' NUM        {snprintf($$,sizeof($$),\"-%s\",$2);}\n                                               ^~~~~\nIn file included from /usr/include/stdio.h:862:0,\n                 from ./int.h:31,\n                 from ASN1.y:30:\n/usr/include/x86_64-linux-gnu/bits/stdio2.h:64:10: note: '__builtin___snprintf_chk' output between 2 and 66 bytes into a destination of size 65\n   return __builtin___snprintf_chk (__s, __n, __USE_FORTIFY_LEVEL - 1,\n          ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n        __bos (__s), __fmt, __va_arg_pack ());\n        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\ncc1: all warnings being treated as errors\nMakefile:1112: recipe for target 'ASN1.lo' failed\nmake[2]: *** [ASN1.lo] Error 1\nmake[2]: Leaving directory '/home/junxie/Downloads/libtasn1-4.9/lib'\nMakefile:1176: recipe for target 'check-recursive' failed\nmake[1]: *** [check-recursive] Error 1\nmake[1]: Leaving directory '/home/junxie/Downloads/libtasn1-4.9/lib'\nMakefile:1009: recipe for target 'check-recursive' failed\nmake: *** [check-recursive] Error 1\n```\n&emsp;&emsp;至此，我已几近崩溃，已经不知道自己在哪儿，是要干啥。网上已经几乎找不到相关问题词条，估计还没有人遇到过这些问题。\n&emsp;&emsp;很想吐槽一下Linux。虽然用户可以随心所欲DIY，但是起点似乎有点太高。所谓的DIY也不过是把好多人写的代码集合在自己电脑上编译，源代码长什么样我虽然比较关心，但哪有时间闲情和精力去看？\n&emsp;&emsp;像我这种需要用到Linux方便处理大量数据和程序编译的便利，又需要用到现成较为成熟程序包编译而不可得的情况，属实尴尬。\n&emsp;&emsp;我又想到了Python。这个脚本语言似乎厉害透顶，几乎所有人都在学，都在用。人们纷纷把以往用fortran，C写的代码转成python或者用python给他们穿身衣服、塑个金身，显得高大上，自诩又为代码社区立功劳。可结果用起来嘛，一言难尽。某些脚本只能用python2运行，另一些又只能用python3。有些程序首次用还总告诉你某某module找不到。安装起来还常常不成功。使用起来十分不友好。真是让人头疼、恼火、焦躁。也不知大家是怎么喜欢上的。只能怪自己太菜，还没对python开窍吧。\n&emsp;&emsp;谁能指条明路？\n","slug":"how-to-install-filezilla","published":1,"updated":"2024-05-26T14:17:36.847Z","comments":1,"layout":"post","photos":[],"_id":"cmh498ipc005iwvoud7rv8twu","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>&emsp;&emsp;本地到服务器的数据传输使用FileZilla程序比较方便和稳定。只是Linux下需要编译安装该程序，那还不易热儿，那就安装呗。然而安装过程让人迷糊，复杂程度让人难忘，特此记录一下。遗憾的是，花了我两天时间，到现在为止，该程序仍然没有安装成功。</p>\n<span id=\"more\"></span>\n<p>&emsp;&emsp;首先在<a href=\"https://filezilla-project.org/\">https://filezilla-project.org/</a>下载了个可执行程序—显然是运行不了的。仔细看发现是在debian10.0下编译的。我的系统是Fedora和Elementary OS5，两个都运行不了。然后下载了源程序FileZilla_3.51.0_src.tar.bz2。<br>&emsp;&emsp;解压，安装filezilla-3.51.0，编译过程出错，显示没有安装libfilezilla。<br>&emsp;&emsp;于是下载libfilezilla-0.25.0.tar.bz2，解压，安装libfilezilla-0.25.0，编译过程出错，显示没有安装有nettle。<br>&emsp;&emsp;于是下载nettle-3.6.tar.gz，解压编译安装nettle-3.6一次通过。<br>&emsp;&emsp;然后在libfilezilla-0.25.0下预编译，出错，显示：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">configure: error: hogweed 3.3 greater was not found. You can get it from https://www.lysator.liu.se/~nisse/nettle/</span><br></pre></td></tr></table></figure>\n<p>&emsp;&emsp;于是重装nettle-3.6</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">./configure --enable-mini-gmp</span><br><span class=\"line\">make</span><br><span class=\"line\">make check</span><br><span class=\"line\">make install</span><br></pre></td></tr></table></figure>\n<p>&emsp;&emsp;安装成功，然后在libfilezilla-0.25.0下预编译，出错，显示：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">configure: error: GnuTLS 3.5.8 or greater was not found. You can get it from https://gnutls.org/</span><br></pre></td></tr></table></figure>\n<p>&emsp;&emsp;然后下载gnutls-3.6.15.tar.xz，解压gnutls-3.6.15编译出错，显示：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">configure: error: </span><br><span class=\"line\">***</span><br><span class=\"line\">*** gmp was not found.</span><br></pre></td></tr></table></figure>\n<p>&emsp;&emsp;然后下载gmp-6.1.0.tar.bz2，解压gmp-6.1.0，编译安装完成。回到gnutls-3.6.15再次编译出错，显示：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">configure: error: </span><br><span class=\"line\">  ***</span><br><span class=\"line\">  *** Libtasn1 4.9 was not found. To use the included one, use --with-included-libtasn1</span><br></pre></td></tr></table></figure>\n<p>&emsp;&emsp;然后下载libtasn1-4.9.tar.gz，解压libtasn1-4.9，编译出错，显示：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ASN1.c: In <span class=\"keyword\">function</span> <span class=\"string\">&#x27;_asn1_yyparse&#x27;</span>:</span><br><span class=\"line\">ASN1.y:152:47: error: <span class=\"string\">&#x27;__builtin___snprintf_chk&#x27;</span> output may be truncated before the last format character [-Werror=format-truncation=]</span><br><span class=\"line\"> neg_num : <span class=\"string\">&#x27;-&#x27;</span> NUM     &#123;snprintf($$,sizeof($$),<span class=\"string\">&quot;-%s&quot;</span>,<span class=\"variable\">$2</span>);&#125;</span><br><span class=\"line\">                                               ^~~~~</span><br><span class=\"line\">In file included from /usr/include/stdio.h:862:0,</span><br><span class=\"line\">                 from ./int.h:31,</span><br><span class=\"line\">                 from ASN1.y:30:</span><br><span class=\"line\">/usr/include/x86_64-linux-gnu/bits/stdio2.h:64:10: note: <span class=\"string\">&#x27;__builtin___snprintf_chk&#x27;</span> output between 2 and 66 bytes into a destination of size 65</span><br><span class=\"line\">   <span class=\"built_in\">return</span> __builtin___snprintf_chk (__s, __n, __USE_FORTIFY_LEVEL - 1,</span><br><span class=\"line\">          ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~</span><br><span class=\"line\">        __bos (__s), __fmt, __va_arg_pack ());</span><br><span class=\"line\">        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~</span><br><span class=\"line\">ASN1.y:164:47: error: <span class=\"string\">&#x27;__builtin___snprintf_chk&#x27;</span> output may be truncated before the last format character [-Werror=format-truncation=]</span><br><span class=\"line\">                 | <span class=\"string\">&#x27;-&#x27;</span> NUM        &#123;snprintf($$,sizeof($$),<span class=\"string\">&quot;-%s&quot;</span>,<span class=\"variable\">$2</span>);&#125;</span><br><span class=\"line\">                                               ^~~~~</span><br><span class=\"line\">In file included from /usr/include/stdio.h:862:0,</span><br><span class=\"line\">                 from ./int.h:31,</span><br><span class=\"line\">                 from ASN1.y:30:</span><br><span class=\"line\">/usr/include/x86_64-linux-gnu/bits/stdio2.h:64:10: note: <span class=\"string\">&#x27;__builtin___snprintf_chk&#x27;</span> output between 2 and 66 bytes into a destination of size 65</span><br><span class=\"line\">   <span class=\"built_in\">return</span> __builtin___snprintf_chk (__s, __n, __USE_FORTIFY_LEVEL - 1,</span><br><span class=\"line\">          ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~</span><br><span class=\"line\">        __bos (__s), __fmt, __va_arg_pack ());</span><br><span class=\"line\">        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~</span><br><span class=\"line\">cc1: all warnings being treated as errors</span><br><span class=\"line\">Makefile:1112: recipe <span class=\"keyword\">for</span> target <span class=\"string\">&#x27;ASN1.lo&#x27;</span> failed</span><br><span class=\"line\">make[2]: *** [ASN1.lo] Error 1</span><br><span class=\"line\">make[2]: Leaving directory <span class=\"string\">&#x27;/home/junxie/Downloads/libtasn1-4.9/lib&#x27;</span></span><br><span class=\"line\">Makefile:1176: recipe <span class=\"keyword\">for</span> target <span class=\"string\">&#x27;check-recursive&#x27;</span> failed</span><br><span class=\"line\">make[1]: *** [check-recursive] Error 1</span><br><span class=\"line\">make[1]: Leaving directory <span class=\"string\">&#x27;/home/junxie/Downloads/libtasn1-4.9/lib&#x27;</span></span><br><span class=\"line\">Makefile:1009: recipe <span class=\"keyword\">for</span> target <span class=\"string\">&#x27;check-recursive&#x27;</span> failed</span><br><span class=\"line\">make: *** [check-recursive] Error 1</span><br></pre></td></tr></table></figure>\n<p>&emsp;&emsp;至此，我已几近崩溃，已经不知道自己在哪儿，是要干啥。网上已经几乎找不到相关问题词条，估计还没有人遇到过这些问题。<br>&emsp;&emsp;很想吐槽一下Linux。虽然用户可以随心所欲DIY，但是起点似乎有点太高。所谓的DIY也不过是把好多人写的代码集合在自己电脑上编译，源代码长什么样我虽然比较关心，但哪有时间闲情和精力去看？<br>&emsp;&emsp;像我这种需要用到Linux方便处理大量数据和程序编译的便利，又需要用到现成较为成熟程序包编译而不可得的情况，属实尴尬。<br>&emsp;&emsp;我又想到了Python。这个脚本语言似乎厉害透顶，几乎所有人都在学，都在用。人们纷纷把以往用fortran，C写的代码转成python或者用python给他们穿身衣服、塑个金身，显得高大上，自诩又为代码社区立功劳。可结果用起来嘛，一言难尽。某些脚本只能用python2运行，另一些又只能用python3。有些程序首次用还总告诉你某某module找不到。安装起来还常常不成功。使用起来十分不友好。真是让人头疼、恼火、焦躁。也不知大家是怎么喜欢上的。只能怪自己太菜，还没对python开窍吧。<br>&emsp;&emsp;谁能指条明路？</p>\n","related_posts":[],"length":3496,"excerpt":"<p>&emsp;&emsp;本地到服务器的数据传输使用FileZilla程序比较方便和稳定。只是Linux下需要编译安装该程序，那还不易热儿，那就安装呗。然而安装过程让人迷糊，复杂程度让人难忘，特此记录一下。遗憾的是，花了我两天时间，到现在为止，该程序仍然没有安装成功。</p>","more":"<p>&emsp;&emsp;首先在<a href=\"https://filezilla-project.org/\">https://filezilla-project.org/</a>下载了个可执行程序—显然是运行不了的。仔细看发现是在debian10.0下编译的。我的系统是Fedora和Elementary OS5，两个都运行不了。然后下载了源程序FileZilla_3.51.0_src.tar.bz2。<br>&emsp;&emsp;解压，安装filezilla-3.51.0，编译过程出错，显示没有安装libfilezilla。<br>&emsp;&emsp;于是下载libfilezilla-0.25.0.tar.bz2，解压，安装libfilezilla-0.25.0，编译过程出错，显示没有安装有nettle。<br>&emsp;&emsp;于是下载nettle-3.6.tar.gz，解压编译安装nettle-3.6一次通过。<br>&emsp;&emsp;然后在libfilezilla-0.25.0下预编译，出错，显示：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">configure: error: hogweed 3.3 greater was not found. You can get it from https://www.lysator.liu.se/~nisse/nettle/</span><br></pre></td></tr></table></figure>\n<p>&emsp;&emsp;于是重装nettle-3.6</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">./configure --enable-mini-gmp</span><br><span class=\"line\">make</span><br><span class=\"line\">make check</span><br><span class=\"line\">make install</span><br></pre></td></tr></table></figure>\n<p>&emsp;&emsp;安装成功，然后在libfilezilla-0.25.0下预编译，出错，显示：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">configure: error: GnuTLS 3.5.8 or greater was not found. You can get it from https://gnutls.org/</span><br></pre></td></tr></table></figure>\n<p>&emsp;&emsp;然后下载gnutls-3.6.15.tar.xz，解压gnutls-3.6.15编译出错，显示：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">configure: error: </span><br><span class=\"line\">***</span><br><span class=\"line\">*** gmp was not found.</span><br></pre></td></tr></table></figure>\n<p>&emsp;&emsp;然后下载gmp-6.1.0.tar.bz2，解压gmp-6.1.0，编译安装完成。回到gnutls-3.6.15再次编译出错，显示：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">configure: error: </span><br><span class=\"line\">  ***</span><br><span class=\"line\">  *** Libtasn1 4.9 was not found. To use the included one, use --with-included-libtasn1</span><br></pre></td></tr></table></figure>\n<p>&emsp;&emsp;然后下载libtasn1-4.9.tar.gz，解压libtasn1-4.9，编译出错，显示：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ASN1.c: In <span class=\"keyword\">function</span> <span class=\"string\">&#x27;_asn1_yyparse&#x27;</span>:</span><br><span class=\"line\">ASN1.y:152:47: error: <span class=\"string\">&#x27;__builtin___snprintf_chk&#x27;</span> output may be truncated before the last format character [-Werror=format-truncation=]</span><br><span class=\"line\"> neg_num : <span class=\"string\">&#x27;-&#x27;</span> NUM     &#123;snprintf($$,sizeof($$),<span class=\"string\">&quot;-%s&quot;</span>,<span class=\"variable\">$2</span>);&#125;</span><br><span class=\"line\">                                               ^~~~~</span><br><span class=\"line\">In file included from /usr/include/stdio.h:862:0,</span><br><span class=\"line\">                 from ./int.h:31,</span><br><span class=\"line\">                 from ASN1.y:30:</span><br><span class=\"line\">/usr/include/x86_64-linux-gnu/bits/stdio2.h:64:10: note: <span class=\"string\">&#x27;__builtin___snprintf_chk&#x27;</span> output between 2 and 66 bytes into a destination of size 65</span><br><span class=\"line\">   <span class=\"built_in\">return</span> __builtin___snprintf_chk (__s, __n, __USE_FORTIFY_LEVEL - 1,</span><br><span class=\"line\">          ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~</span><br><span class=\"line\">        __bos (__s), __fmt, __va_arg_pack ());</span><br><span class=\"line\">        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~</span><br><span class=\"line\">ASN1.y:164:47: error: <span class=\"string\">&#x27;__builtin___snprintf_chk&#x27;</span> output may be truncated before the last format character [-Werror=format-truncation=]</span><br><span class=\"line\">                 | <span class=\"string\">&#x27;-&#x27;</span> NUM        &#123;snprintf($$,sizeof($$),<span class=\"string\">&quot;-%s&quot;</span>,<span class=\"variable\">$2</span>);&#125;</span><br><span class=\"line\">                                               ^~~~~</span><br><span class=\"line\">In file included from /usr/include/stdio.h:862:0,</span><br><span class=\"line\">                 from ./int.h:31,</span><br><span class=\"line\">                 from ASN1.y:30:</span><br><span class=\"line\">/usr/include/x86_64-linux-gnu/bits/stdio2.h:64:10: note: <span class=\"string\">&#x27;__builtin___snprintf_chk&#x27;</span> output between 2 and 66 bytes into a destination of size 65</span><br><span class=\"line\">   <span class=\"built_in\">return</span> __builtin___snprintf_chk (__s, __n, __USE_FORTIFY_LEVEL - 1,</span><br><span class=\"line\">          ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~</span><br><span class=\"line\">        __bos (__s), __fmt, __va_arg_pack ());</span><br><span class=\"line\">        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~</span><br><span class=\"line\">cc1: all warnings being treated as errors</span><br><span class=\"line\">Makefile:1112: recipe <span class=\"keyword\">for</span> target <span class=\"string\">&#x27;ASN1.lo&#x27;</span> failed</span><br><span class=\"line\">make[2]: *** [ASN1.lo] Error 1</span><br><span class=\"line\">make[2]: Leaving directory <span class=\"string\">&#x27;/home/junxie/Downloads/libtasn1-4.9/lib&#x27;</span></span><br><span class=\"line\">Makefile:1176: recipe <span class=\"keyword\">for</span> target <span class=\"string\">&#x27;check-recursive&#x27;</span> failed</span><br><span class=\"line\">make[1]: *** [check-recursive] Error 1</span><br><span class=\"line\">make[1]: Leaving directory <span class=\"string\">&#x27;/home/junxie/Downloads/libtasn1-4.9/lib&#x27;</span></span><br><span class=\"line\">Makefile:1009: recipe <span class=\"keyword\">for</span> target <span class=\"string\">&#x27;check-recursive&#x27;</span> failed</span><br><span class=\"line\">make: *** [check-recursive] Error 1</span><br></pre></td></tr></table></figure>\n<p>&emsp;&emsp;至此，我已几近崩溃，已经不知道自己在哪儿，是要干啥。网上已经几乎找不到相关问题词条，估计还没有人遇到过这些问题。<br>&emsp;&emsp;很想吐槽一下Linux。虽然用户可以随心所欲DIY，但是起点似乎有点太高。所谓的DIY也不过是把好多人写的代码集合在自己电脑上编译，源代码长什么样我虽然比较关心，但哪有时间闲情和精力去看？<br>&emsp;&emsp;像我这种需要用到Linux方便处理大量数据和程序编译的便利，又需要用到现成较为成熟程序包编译而不可得的情况，属实尴尬。<br>&emsp;&emsp;我又想到了Python。这个脚本语言似乎厉害透顶，几乎所有人都在学，都在用。人们纷纷把以往用fortran，C写的代码转成python或者用python给他们穿身衣服、塑个金身，显得高大上，自诩又为代码社区立功劳。可结果用起来嘛，一言难尽。某些脚本只能用python2运行，另一些又只能用python3。有些程序首次用还总告诉你某某module找不到。安装起来还常常不成功。使用起来十分不友好。真是让人头疼、恼火、焦躁。也不知大家是怎么喜欢上的。只能怪自己太菜，还没对python开窍吧。<br>&emsp;&emsp;谁能指条明路？</p>"},{"title":"新年快乐","abbrlink":"eac80072","date":"2021-02-11T16:37:36.000Z","_content":"![文章接收](acce.png)\n<!-- less -->\n&emsp;&emsp;各位新年快乐。\n&emsp;&emsp;我不是针对谁，我是说在座各位的模型都有问题。开玩笑的，别当真。\n&emsp;&emsp;今天很高兴因为一篇文章刚刚接收了，收到了新年礼物。这篇文章经过了多重考验，三次大修。时间也长，文章从第一次投稿到接收用的时间二胎也都降世了。\n&emsp;&emsp;文章的意思就是经过检验发现现在的模型都有问题。有点惹众怒啊。请轻拍。我忘记是谁说的了，没有一个模型是对的，但都是有用的。大家和气生财(文章)。切勿动怒。\n&emsp;&emsp;下一步就是好好写本子了啊。哎。加了个油。\n","source":"_posts/2021-02-12-happy-new-year.md","raw":"---\ntitle: 新年快乐\nabbrlink: eac80072\ndate: 2021-02-12 00:37:36\ncategories:\n  - 日记\ntags:\n  - 日记\n---\n![文章接收](acce.png)\n<!-- less -->\n&emsp;&emsp;各位新年快乐。\n&emsp;&emsp;我不是针对谁，我是说在座各位的模型都有问题。开玩笑的，别当真。\n&emsp;&emsp;今天很高兴因为一篇文章刚刚接收了，收到了新年礼物。这篇文章经过了多重考验，三次大修。时间也长，文章从第一次投稿到接收用的时间二胎也都降世了。\n&emsp;&emsp;文章的意思就是经过检验发现现在的模型都有问题。有点惹众怒啊。请轻拍。我忘记是谁说的了，没有一个模型是对的，但都是有用的。大家和气生财(文章)。切勿动怒。\n&emsp;&emsp;下一步就是好好写本子了啊。哎。加了个油。\n","slug":"happy-new-year","published":1,"updated":"2024-05-26T14:17:36.847Z","comments":1,"layout":"post","photos":[],"_id":"cmh498ipd005lwvou4zlmhzy4","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>&emsp;&emsp;各位新年快乐。<br>&emsp;&emsp;我不是针对谁，我是说在座各位的模型都有问题。开玩笑的，别当真。<br>&emsp;&emsp;今天很高兴因为一篇文章刚刚接收了，收到了新年礼物。这篇文章经过了多重考验，三次大修。时间也长，文章从第一次投稿到接收用的时间二胎也都降世了。<br>&emsp;&emsp;文章的意思就是经过检验发现现在的模型都有问题。有点惹众怒啊。请轻拍。我忘记是谁说的了，没有一个模型是对的，但都是有用的。大家和气生财(文章)。切勿动怒。<br>&emsp;&emsp;下一步就是好好写本子了啊。哎。加了个油。</p>","related_posts":["about-anti-paper.html","history-and-inversion.html"],"length":264,"excerpt":"<p><img src=\"/acce.png\" alt=\"文章接收\"></p>","more":"<p>&emsp;&emsp;各位新年快乐。<br>&emsp;&emsp;我不是针对谁，我是说在座各位的模型都有问题。开玩笑的，别当真。<br>&emsp;&emsp;今天很高兴因为一篇文章刚刚接收了，收到了新年礼物。这篇文章经过了多重考验，三次大修。时间也长，文章从第一次投稿到接收用的时间二胎也都降世了。<br>&emsp;&emsp;文章的意思就是经过检验发现现在的模型都有问题。有点惹众怒啊。请轻拍。我忘记是谁说的了，没有一个模型是对的，但都是有用的。大家和气生财(文章)。切勿动怒。<br>&emsp;&emsp;下一步就是好好写本子了啊。哎。加了个油。</p>"},{"title":"安装完fedora32之后","abbrlink":"186eae32","date":"2021-03-02T06:54:16.000Z","_content":"&emsp;&emsp;话说这台工作站已经有点“老了”，于是重新买了一台，美滋滋。5分钟安装了个fedora32，记录一下干了些啥。\n<!-- more -->\n## 换阿里源并更新\n```bash\nsudo mv /etc/yum.repos.d/fedora.repo /etc/yum.repos.d/fedora.repo.backup\nsudo mv /etc/yum.repos.d/fedora-updates.repo /etc/yum.repos.d/fedora-updates.repo.backup\nsudo wget -O /etc/yum.repos.d/fedora.repo http://mirrors.aliyun.com/repo/fedora.repo\nsudo wget -O /etc/yum.repos.d/fedora-updates.repo http://mirrors.aliyun.com/repo/fedora-updates.repo\nsudo yum makecache\nsudo dnf update\n```\n## 给root设密码\n```bash\nsudo passwd root\n```\n\n## 改主机名\n```\nsudo hostnamectl set-hostname zbook7 --static\n```\n\n## 安装gmt6\n```\ndnf copr enable genericmappingtools/gmt\ndnf install gmt\n```\n## gmt6中文支持\n在这篇日志{% post_link how-to-configure-chinese-for-gmt %}里有对gmt中文支持的说明。然而现在安装的是fedora32，ghostscript的cidmap文件不一样，搞不定啊。于是按照[GMT中文社区](https://docs.gmt-china.org/)的说明，运行了[cjk-gs-integrate.pl](http://raw.githubusercontent.com/texjporg/cjk-gs-support/master/cjk-gs-integrate.pl)脚本之后果然可以用中文了。\n\n然而，如文档所说，gs果然不能用了。然后运行sudo perl cjk-gs-integrate.pl --remove，结果gs还是用不了。\n按照以前的经验，那就删掉ghostscript然后重装。于是运行了：\n```\nsudo dnf remove ghostscript\n```\n结果删除了一大堆东西，包括gmt等等，然后一一重装。\n回想在运行cjk-gs-integrate.pl脚本的时候有看到/usr/share/ghostscript/Resource/Init/cidmap*等文件信息出现。\n于是将这个文件当作以往编辑中文字体配置文件的方法:{% post_link how-to-configure-chinese-for-gmt %}，于是就OK了。\n## 安装npm\n在[这里](https://nodejs.org/en/download/)下载，然后安装。本来是想安装hexo，所以来安装这个软件。结果hexo一直搞不定。暂时就不理他了。\n\n## 安装sac\n在iris申请了一份sac102。源代码怎么都安装不成功，于是直接解压了可执行的二进制文件。\n","source":"_posts/2021-03-02-after-fedora32.md","raw":"---\ntitle: 安装完fedora32之后\ncategories: \n  - Linux\ntags: \n  - 日记\nabbrlink: 186eae32\ndate: 2021-03-02 14:54:16\n---\n&emsp;&emsp;话说这台工作站已经有点“老了”，于是重新买了一台，美滋滋。5分钟安装了个fedora32，记录一下干了些啥。\n<!-- more -->\n## 换阿里源并更新\n```bash\nsudo mv /etc/yum.repos.d/fedora.repo /etc/yum.repos.d/fedora.repo.backup\nsudo mv /etc/yum.repos.d/fedora-updates.repo /etc/yum.repos.d/fedora-updates.repo.backup\nsudo wget -O /etc/yum.repos.d/fedora.repo http://mirrors.aliyun.com/repo/fedora.repo\nsudo wget -O /etc/yum.repos.d/fedora-updates.repo http://mirrors.aliyun.com/repo/fedora-updates.repo\nsudo yum makecache\nsudo dnf update\n```\n## 给root设密码\n```bash\nsudo passwd root\n```\n\n## 改主机名\n```\nsudo hostnamectl set-hostname zbook7 --static\n```\n\n## 安装gmt6\n```\ndnf copr enable genericmappingtools/gmt\ndnf install gmt\n```\n## gmt6中文支持\n在这篇日志{% post_link how-to-configure-chinese-for-gmt %}里有对gmt中文支持的说明。然而现在安装的是fedora32，ghostscript的cidmap文件不一样，搞不定啊。于是按照[GMT中文社区](https://docs.gmt-china.org/)的说明，运行了[cjk-gs-integrate.pl](http://raw.githubusercontent.com/texjporg/cjk-gs-support/master/cjk-gs-integrate.pl)脚本之后果然可以用中文了。\n\n然而，如文档所说，gs果然不能用了。然后运行sudo perl cjk-gs-integrate.pl --remove，结果gs还是用不了。\n按照以前的经验，那就删掉ghostscript然后重装。于是运行了：\n```\nsudo dnf remove ghostscript\n```\n结果删除了一大堆东西，包括gmt等等，然后一一重装。\n回想在运行cjk-gs-integrate.pl脚本的时候有看到/usr/share/ghostscript/Resource/Init/cidmap*等文件信息出现。\n于是将这个文件当作以往编辑中文字体配置文件的方法:{% post_link how-to-configure-chinese-for-gmt %}，于是就OK了。\n## 安装npm\n在[这里](https://nodejs.org/en/download/)下载，然后安装。本来是想安装hexo，所以来安装这个软件。结果hexo一直搞不定。暂时就不理他了。\n\n## 安装sac\n在iris申请了一份sac102。源代码怎么都安装不成功，于是直接解压了可执行的二进制文件。\n","slug":"after-fedora32","published":1,"updated":"2024-05-26T14:17:36.847Z","comments":1,"layout":"post","photos":[],"_id":"cmh498ipd005pwvou44fjgpmo","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>&emsp;&emsp;话说这台工作站已经有点“老了”，于是重新买了一台，美滋滋。5分钟安装了个fedora32，记录一下干了些啥。</p>\n<span id=\"more\"></span>\n<h2 id=\"换阿里源并更新\"><a href=\"#换阿里源并更新\" class=\"headerlink\" title=\"换阿里源并更新\"></a>换阿里源并更新</h2><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">sudo</span> <span class=\"built_in\">mv</span> /etc/yum.repos.d/fedora.repo /etc/yum.repos.d/fedora.repo.backup</span><br><span class=\"line\"><span class=\"built_in\">sudo</span> <span class=\"built_in\">mv</span> /etc/yum.repos.d/fedora-updates.repo /etc/yum.repos.d/fedora-updates.repo.backup</span><br><span class=\"line\"><span class=\"built_in\">sudo</span> wget -O /etc/yum.repos.d/fedora.repo http://mirrors.aliyun.com/repo/fedora.repo</span><br><span class=\"line\"><span class=\"built_in\">sudo</span> wget -O /etc/yum.repos.d/fedora-updates.repo http://mirrors.aliyun.com/repo/fedora-updates.repo</span><br><span class=\"line\"><span class=\"built_in\">sudo</span> yum makecache</span><br><span class=\"line\"><span class=\"built_in\">sudo</span> dnf update</span><br></pre></td></tr></table></figure>\n<h2 id=\"给root设密码\"><a href=\"#给root设密码\" class=\"headerlink\" title=\"给root设密码\"></a>给root设密码</h2><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">sudo</span> passwd root</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"改主机名\"><a href=\"#改主机名\" class=\"headerlink\" title=\"改主机名\"></a>改主机名</h2><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo hostnamectl set-hostname zbook7 --static</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"安装gmt6\"><a href=\"#安装gmt6\" class=\"headerlink\" title=\"安装gmt6\"></a>安装gmt6</h2><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">dnf copr enable genericmappingtools/gmt</span><br><span class=\"line\">dnf install gmt</span><br></pre></td></tr></table></figure>\n<h2 id=\"gmt6中文支持\"><a href=\"#gmt6中文支持\" class=\"headerlink\" title=\"gmt6中文支持\"></a>gmt6中文支持</h2><p>在这篇日志<a href=\"/how-to-configure-chinese-for-gmt\" title=\"如何在elementaryOS下让gmt支持中文\">如何在elementaryOS下让gmt支持中文</a>里有对gmt中文支持的说明。然而现在安装的是fedora32，ghostscript的cidmap文件不一样，搞不定啊。于是按照<a href=\"https://docs.gmt-china.org/\">GMT中文社区</a>的说明，运行了<a href=\"http://raw.githubusercontent.com/texjporg/cjk-gs-support/master/cjk-gs-integrate.pl\">cjk-gs-integrate.pl</a>脚本之后果然可以用中文了。</p>\n<p>然而，如文档所说，gs果然不能用了。然后运行sudo perl cjk-gs-integrate.pl –remove，结果gs还是用不了。<br>按照以前的经验，那就删掉ghostscript然后重装。于是运行了：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo dnf remove ghostscript</span><br></pre></td></tr></table></figure>\n<p>结果删除了一大堆东西，包括gmt等等，然后一一重装。<br>回想在运行cjk-gs-integrate.pl脚本的时候有看到&#x2F;usr&#x2F;share&#x2F;ghostscript&#x2F;Resource&#x2F;Init&#x2F;cidmap*等文件信息出现。<br>于是将这个文件当作以往编辑中文字体配置文件的方法:<a href=\"/how-to-configure-chinese-for-gmt\" title=\"如何在elementaryOS下让gmt支持中文\">如何在elementaryOS下让gmt支持中文</a>，于是就OK了。</p>\n<h2 id=\"安装npm\"><a href=\"#安装npm\" class=\"headerlink\" title=\"安装npm\"></a>安装npm</h2><p>在<a href=\"https://nodejs.org/en/download/\">这里</a>下载，然后安装。本来是想安装hexo，所以来安装这个软件。结果hexo一直搞不定。暂时就不理他了。</p>\n<h2 id=\"安装sac\"><a href=\"#安装sac\" class=\"headerlink\" title=\"安装sac\"></a>安装sac</h2><p>在iris申请了一份sac102。源代码怎么都安装不成功，于是直接解压了可执行的二进制文件。</p>\n","related_posts":["how-to-configure-chinese-for-gmt.html","to-desk.html","fedora-install-freshress.html"],"length":1142,"excerpt":"<p>&emsp;&emsp;话说这台工作站已经有点“老了”，于是重新买了一台，美滋滋。5分钟安装了个fedora32，记录一下干了些啥。</p>","more":"<h2 id=\"换阿里源并更新\"><a href=\"#换阿里源并更新\" class=\"headerlink\" title=\"换阿里源并更新\"></a>换阿里源并更新</h2><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">sudo</span> <span class=\"built_in\">mv</span> /etc/yum.repos.d/fedora.repo /etc/yum.repos.d/fedora.repo.backup</span><br><span class=\"line\"><span class=\"built_in\">sudo</span> <span class=\"built_in\">mv</span> /etc/yum.repos.d/fedora-updates.repo /etc/yum.repos.d/fedora-updates.repo.backup</span><br><span class=\"line\"><span class=\"built_in\">sudo</span> wget -O /etc/yum.repos.d/fedora.repo http://mirrors.aliyun.com/repo/fedora.repo</span><br><span class=\"line\"><span class=\"built_in\">sudo</span> wget -O /etc/yum.repos.d/fedora-updates.repo http://mirrors.aliyun.com/repo/fedora-updates.repo</span><br><span class=\"line\"><span class=\"built_in\">sudo</span> yum makecache</span><br><span class=\"line\"><span class=\"built_in\">sudo</span> dnf update</span><br></pre></td></tr></table></figure>\n<h2 id=\"给root设密码\"><a href=\"#给root设密码\" class=\"headerlink\" title=\"给root设密码\"></a>给root设密码</h2><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">sudo</span> passwd root</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"改主机名\"><a href=\"#改主机名\" class=\"headerlink\" title=\"改主机名\"></a>改主机名</h2><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo hostnamectl set-hostname zbook7 --static</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"安装gmt6\"><a href=\"#安装gmt6\" class=\"headerlink\" title=\"安装gmt6\"></a>安装gmt6</h2><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">dnf copr enable genericmappingtools/gmt</span><br><span class=\"line\">dnf install gmt</span><br></pre></td></tr></table></figure>\n<h2 id=\"gmt6中文支持\"><a href=\"#gmt6中文支持\" class=\"headerlink\" title=\"gmt6中文支持\"></a>gmt6中文支持</h2><p>在这篇日志<a href=\"/how-to-configure-chinese-for-gmt\" title=\"如何在elementaryOS下让gmt支持中文\">如何在elementaryOS下让gmt支持中文</a>里有对gmt中文支持的说明。然而现在安装的是fedora32，ghostscript的cidmap文件不一样，搞不定啊。于是按照<a href=\"https://docs.gmt-china.org/\">GMT中文社区</a>的说明，运行了<a href=\"http://raw.githubusercontent.com/texjporg/cjk-gs-support/master/cjk-gs-integrate.pl\">cjk-gs-integrate.pl</a>脚本之后果然可以用中文了。</p>\n<p>然而，如文档所说，gs果然不能用了。然后运行sudo perl cjk-gs-integrate.pl –remove，结果gs还是用不了。<br>按照以前的经验，那就删掉ghostscript然后重装。于是运行了：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo dnf remove ghostscript</span><br></pre></td></tr></table></figure>\n<p>结果删除了一大堆东西，包括gmt等等，然后一一重装。<br>回想在运行cjk-gs-integrate.pl脚本的时候有看到&#x2F;usr&#x2F;share&#x2F;ghostscript&#x2F;Resource&#x2F;Init&#x2F;cidmap*等文件信息出现。<br>于是将这个文件当作以往编辑中文字体配置文件的方法:<a href=\"/how-to-configure-chinese-for-gmt\" title=\"如何在elementaryOS下让gmt支持中文\">如何在elementaryOS下让gmt支持中文</a>，于是就OK了。</p>\n<h2 id=\"安装npm\"><a href=\"#安装npm\" class=\"headerlink\" title=\"安装npm\"></a>安装npm</h2><p>在<a href=\"https://nodejs.org/en/download/\">这里</a>下载，然后安装。本来是想安装hexo，所以来安装这个软件。结果hexo一直搞不定。暂时就不理他了。</p>\n<h2 id=\"安装sac\"><a href=\"#安装sac\" class=\"headerlink\" title=\"安装sac\"></a>安装sac</h2><p>在iris申请了一份sac102。源代码怎么都安装不成功，于是直接解压了可执行的二进制文件。</p>"},{"title":"一起看星星","abbrlink":"fa89c0c1","date":"2021-03-08T07:28:20.000Z","_content":"![幽灵？人鱼？](https://i.loli.net/2021/03/08/8G6ODBE3FbZa4U2.png)\n<!-- less -->\n&emsp;&emsp;小时候的爱好之一是看天空。白天看天上的云朵，总感觉会有不可思议的事情发生，或者突然会有UFO窜出。晚上看天上的星星，希望能够看到特别的一颗，或者天外有神秘来客造访。以前夏日的晚上，天上星星真的是光彩夺目，数也数不清;现在的夜晚天空是朦朦胧胧，想看也看不清。\n&emsp;&emsp;幸好在[阮一峰的网络日志](http://ruanyifeng.com)里面看到了这个[看星空网址](https://viewer.legacysurvey.org)。我魔症的看了好几个小时。这里是全球多个天文台合作，经过多年合作观测，将天文望远镜拍摄的星空拼成的一张10万亿的图片。包含了10亿个星系，覆盖天空的1/3。\n&emsp;&emsp;不用怀疑，点进去。每一个亮点，可能都是一整个星系。起初我把图片放大到了30弧秒，遍历似的看。结果我发现我真低估了他的大小。用沧海一粟来形容人或地球都显得是对人或地球的极富夸张。后来发现很多星系已经被标了记，按顺序看就好了。总之是不舍眨眼。\n&emsp;&emsp;那里有幽灵，有美人鱼，有飞碟，还有宝石，充满了幻想。有些橙黄，有些惺红，有些翡翠绿，还有宝石蓝，看花了眼。\n&emsp;&emsp;有些有很多旋臂，像花瓣；有些只有两条，像手臂。有些还没有开始旋转，是青少年吧。另一些已经成了圆盘，垂垂老矣？\n&emsp;&emsp;有些在热情舞蹈，有些在调皮逗趣，有些在静静凝视，有些在拥抱彼此，有些在聚会宴请，有些寻求孤独宁静，还有一些可能是傲游的仙人。\n&emsp;&emsp;我们看到的是几十亿年前甚至更久远的他们，不知道他们现在是否依旧闪烁;而我们的光到达他们的时候，他们是否还能看到？\n![黑洞？](https://i.loli.net/2021/03/08/DBtUqGVew1lWgQC.png)\n![情侣？](https://i.loli.net/2021/03/08/1IuxsGyWAJTjQnl.png)\n![相依](https://i.loli.net/2021/03/08/SqhYyJQCXEBn8wT.png)\n![璀璨](https://i.loli.net/2021/03/08/9x3fXmA4z2tErQ1.png)\n![双镯](https://i.loli.net/2021/03/08/pVBg48UefoGtSNZ.png)\n![欢脱](https://i.loli.net/2021/03/08/7bj8uQZ5rI9UdBs.png)\n![亲吻](https://i.loli.net/2021/03/08/F46WaDXx5qweZBG.png)\n![九星联珠](https://i.loli.net/2021/03/09/6Sz4uihkbEw7TJR.png)\n![大哥小弟？](https://i.loli.net/2021/03/08/4cuZhPki853Te6U.png)\n","source":"_posts/2021-03-08-sky-and-universe.md","raw":"---\ntitle: 一起看星星\ncategories:\n  - 杂\ntags:\n  - 杂\nabbrlink: fa89c0c1\ndate: 2021-03-08 15:28:20\n---\n![幽灵？人鱼？](https://i.loli.net/2021/03/08/8G6ODBE3FbZa4U2.png)\n<!-- less -->\n&emsp;&emsp;小时候的爱好之一是看天空。白天看天上的云朵，总感觉会有不可思议的事情发生，或者突然会有UFO窜出。晚上看天上的星星，希望能够看到特别的一颗，或者天外有神秘来客造访。以前夏日的晚上，天上星星真的是光彩夺目，数也数不清;现在的夜晚天空是朦朦胧胧，想看也看不清。\n&emsp;&emsp;幸好在[阮一峰的网络日志](http://ruanyifeng.com)里面看到了这个[看星空网址](https://viewer.legacysurvey.org)。我魔症的看了好几个小时。这里是全球多个天文台合作，经过多年合作观测，将天文望远镜拍摄的星空拼成的一张10万亿的图片。包含了10亿个星系，覆盖天空的1/3。\n&emsp;&emsp;不用怀疑，点进去。每一个亮点，可能都是一整个星系。起初我把图片放大到了30弧秒，遍历似的看。结果我发现我真低估了他的大小。用沧海一粟来形容人或地球都显得是对人或地球的极富夸张。后来发现很多星系已经被标了记，按顺序看就好了。总之是不舍眨眼。\n&emsp;&emsp;那里有幽灵，有美人鱼，有飞碟，还有宝石，充满了幻想。有些橙黄，有些惺红，有些翡翠绿，还有宝石蓝，看花了眼。\n&emsp;&emsp;有些有很多旋臂，像花瓣；有些只有两条，像手臂。有些还没有开始旋转，是青少年吧。另一些已经成了圆盘，垂垂老矣？\n&emsp;&emsp;有些在热情舞蹈，有些在调皮逗趣，有些在静静凝视，有些在拥抱彼此，有些在聚会宴请，有些寻求孤独宁静，还有一些可能是傲游的仙人。\n&emsp;&emsp;我们看到的是几十亿年前甚至更久远的他们，不知道他们现在是否依旧闪烁;而我们的光到达他们的时候，他们是否还能看到？\n![黑洞？](https://i.loli.net/2021/03/08/DBtUqGVew1lWgQC.png)\n![情侣？](https://i.loli.net/2021/03/08/1IuxsGyWAJTjQnl.png)\n![相依](https://i.loli.net/2021/03/08/SqhYyJQCXEBn8wT.png)\n![璀璨](https://i.loli.net/2021/03/08/9x3fXmA4z2tErQ1.png)\n![双镯](https://i.loli.net/2021/03/08/pVBg48UefoGtSNZ.png)\n![欢脱](https://i.loli.net/2021/03/08/7bj8uQZ5rI9UdBs.png)\n![亲吻](https://i.loli.net/2021/03/08/F46WaDXx5qweZBG.png)\n![九星联珠](https://i.loli.net/2021/03/09/6Sz4uihkbEw7TJR.png)\n![大哥小弟？](https://i.loli.net/2021/03/08/4cuZhPki853Te6U.png)\n","slug":"sky-and-universe","published":1,"updated":"2024-05-26T14:17:36.847Z","comments":1,"layout":"post","photos":[],"_id":"cmh498ipe005swvou9posese6","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>&emsp;&emsp;小时候的爱好之一是看天空。白天看天上的云朵，总感觉会有不可思议的事情发生，或者突然会有UFO窜出。晚上看天上的星星，希望能够看到特别的一颗，或者天外有神秘来客造访。以前夏日的晚上，天上星星真的是光彩夺目，数也数不清;现在的夜晚天空是朦朦胧胧，想看也看不清。<br>&emsp;&emsp;幸好在<a href=\"http://ruanyifeng.com/\">阮一峰的网络日志</a>里面看到了这个<a href=\"https://viewer.legacysurvey.org/\">看星空网址</a>。我魔症的看了好几个小时。这里是全球多个天文台合作，经过多年合作观测，将天文望远镜拍摄的星空拼成的一张10万亿的图片。包含了10亿个星系，覆盖天空的1&#x2F;3。<br>&emsp;&emsp;不用怀疑，点进去。每一个亮点，可能都是一整个星系。起初我把图片放大到了30弧秒，遍历似的看。结果我发现我真低估了他的大小。用沧海一粟来形容人或地球都显得是对人或地球的极富夸张。后来发现很多星系已经被标了记，按顺序看就好了。总之是不舍眨眼。<br>&emsp;&emsp;那里有幽灵，有美人鱼，有飞碟，还有宝石，充满了幻想。有些橙黄，有些惺红，有些翡翠绿，还有宝石蓝，看花了眼。<br>&emsp;&emsp;有些有很多旋臂，像花瓣；有些只有两条，像手臂。有些还没有开始旋转，是青少年吧。另一些已经成了圆盘，垂垂老矣？<br>&emsp;&emsp;有些在热情舞蹈，有些在调皮逗趣，有些在静静凝视，有些在拥抱彼此，有些在聚会宴请，有些寻求孤独宁静，还有一些可能是傲游的仙人。<br>&emsp;&emsp;我们看到的是几十亿年前甚至更久远的他们，不知道他们现在是否依旧闪烁;而我们的光到达他们的时候，他们是否还能看到？<br><img src=\"https://i.loli.net/2021/03/08/DBtUqGVew1lWgQC.png\" alt=\"黑洞？\"><br><img src=\"https://i.loli.net/2021/03/08/1IuxsGyWAJTjQnl.png\" alt=\"情侣？\"><br><img src=\"https://i.loli.net/2021/03/08/SqhYyJQCXEBn8wT.png\" alt=\"相依\"><br><img src=\"https://i.loli.net/2021/03/08/9x3fXmA4z2tErQ1.png\" alt=\"璀璨\"><br><img src=\"https://i.loli.net/2021/03/08/pVBg48UefoGtSNZ.png\" alt=\"双镯\"><br><img src=\"https://i.loli.net/2021/03/08/7bj8uQZ5rI9UdBs.png\" alt=\"欢脱\"><br><img src=\"https://i.loli.net/2021/03/08/F46WaDXx5qweZBG.png\" alt=\"亲吻\"><br><img src=\"https://i.loli.net/2021/03/09/6Sz4uihkbEw7TJR.png\" alt=\"九星联珠\"><br><img src=\"https://i.loli.net/2021/03/08/4cuZhPki853Te6U.png\" alt=\"大哥小弟？\"></p>","related_posts":[],"length":662,"excerpt":"<p><img src=\"https://i.loli.net/2021/03/08/8G6ODBE3FbZa4U2.png\" alt=\"幽灵？人鱼？\"></p>","more":"<p>&emsp;&emsp;小时候的爱好之一是看天空。白天看天上的云朵，总感觉会有不可思议的事情发生，或者突然会有UFO窜出。晚上看天上的星星，希望能够看到特别的一颗，或者天外有神秘来客造访。以前夏日的晚上，天上星星真的是光彩夺目，数也数不清;现在的夜晚天空是朦朦胧胧，想看也看不清。<br>&emsp;&emsp;幸好在<a href=\"http://ruanyifeng.com/\">阮一峰的网络日志</a>里面看到了这个<a href=\"https://viewer.legacysurvey.org/\">看星空网址</a>。我魔症的看了好几个小时。这里是全球多个天文台合作，经过多年合作观测，将天文望远镜拍摄的星空拼成的一张10万亿的图片。包含了10亿个星系，覆盖天空的1&#x2F;3。<br>&emsp;&emsp;不用怀疑，点进去。每一个亮点，可能都是一整个星系。起初我把图片放大到了30弧秒，遍历似的看。结果我发现我真低估了他的大小。用沧海一粟来形容人或地球都显得是对人或地球的极富夸张。后来发现很多星系已经被标了记，按顺序看就好了。总之是不舍眨眼。<br>&emsp;&emsp;那里有幽灵，有美人鱼，有飞碟，还有宝石，充满了幻想。有些橙黄，有些惺红，有些翡翠绿，还有宝石蓝，看花了眼。<br>&emsp;&emsp;有些有很多旋臂，像花瓣；有些只有两条，像手臂。有些还没有开始旋转，是青少年吧。另一些已经成了圆盘，垂垂老矣？<br>&emsp;&emsp;有些在热情舞蹈，有些在调皮逗趣，有些在静静凝视，有些在拥抱彼此，有些在聚会宴请，有些寻求孤独宁静，还有一些可能是傲游的仙人。<br>&emsp;&emsp;我们看到的是几十亿年前甚至更久远的他们，不知道他们现在是否依旧闪烁;而我们的光到达他们的时候，他们是否还能看到？<br><img src=\"https://i.loli.net/2021/03/08/DBtUqGVew1lWgQC.png\" alt=\"黑洞？\"><br><img src=\"https://i.loli.net/2021/03/08/1IuxsGyWAJTjQnl.png\" alt=\"情侣？\"><br><img src=\"https://i.loli.net/2021/03/08/SqhYyJQCXEBn8wT.png\" alt=\"相依\"><br><img src=\"https://i.loli.net/2021/03/08/9x3fXmA4z2tErQ1.png\" alt=\"璀璨\"><br><img src=\"https://i.loli.net/2021/03/08/pVBg48UefoGtSNZ.png\" alt=\"双镯\"><br><img src=\"https://i.loli.net/2021/03/08/7bj8uQZ5rI9UdBs.png\" alt=\"欢脱\"><br><img src=\"https://i.loli.net/2021/03/08/F46WaDXx5qweZBG.png\" alt=\"亲吻\"><br><img src=\"https://i.loli.net/2021/03/09/6Sz4uihkbEw7TJR.png\" alt=\"九星联珠\"><br><img src=\"https://i.loli.net/2021/03/08/4cuZhPki853Te6U.png\" alt=\"大哥小弟？\"></p>"},{"title":"bash里如何循环读取文件","abbrlink":"e96b8da2","date":"2021-03-09T07:51:21.000Z","_content":"&emsp;&emsp;Bash操作简单，可以处理简单的计算等。有些时候会遇到文件的读取问题，那如何对文件进行循环逐行读取呢？\n<!-- more -->\n&emsp;&emsp;这样就可以了:\n```bash\nwhile read -r line\ndo\n   array=(${line///})  \n   echo ${array[1]}\ndone < the_file\n```\n","source":"_posts/2021-03-09-read-file-bash.md","raw":"---\ntitle: bash里如何循环读取文件\ncategories:\n  - Linux\ntags:\n  - Linux\nabbrlink: e96b8da2\ndate: 2021-03-09 15:51:21\n---\n&emsp;&emsp;Bash操作简单，可以处理简单的计算等。有些时候会遇到文件的读取问题，那如何对文件进行循环逐行读取呢？\n<!-- more -->\n&emsp;&emsp;这样就可以了:\n```bash\nwhile read -r line\ndo\n   array=(${line///})  \n   echo ${array[1]}\ndone < the_file\n```\n","slug":"read-file-bash","published":1,"updated":"2024-05-26T14:17:36.847Z","comments":1,"layout":"post","photos":[],"_id":"cmh498ipe005vwvou23ojbvbi","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>&emsp;&emsp;Bash操作简单，可以处理简单的计算等。有些时候会遇到文件的读取问题，那如何对文件进行循环逐行读取呢？</p>\n<span id=\"more\"></span>\n<p>&emsp;&emsp;这样就可以了:</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">while</span> <span class=\"built_in\">read</span> -r line</span><br><span class=\"line\"><span class=\"keyword\">do</span></span><br><span class=\"line\">   array=(<span class=\"variable\">$&#123;line///&#125;</span>)  </span><br><span class=\"line\">   <span class=\"built_in\">echo</span> <span class=\"variable\">$&#123;array[1]&#125;</span></span><br><span class=\"line\"><span class=\"keyword\">done</span> &lt; the_file</span><br></pre></td></tr></table></figure>\n","related_posts":["no-file-found-in-LaTeX.html"],"length":173,"excerpt":"<p>&emsp;&emsp;Bash操作简单，可以处理简单的计算等。有些时候会遇到文件的读取问题，那如何对文件进行循环逐行读取呢？</p>","more":"<p>&emsp;&emsp;这样就可以了:</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">while</span> <span class=\"built_in\">read</span> -r line</span><br><span class=\"line\"><span class=\"keyword\">do</span></span><br><span class=\"line\">   array=(<span class=\"variable\">$&#123;line///&#125;</span>)  </span><br><span class=\"line\">   <span class=\"built_in\">echo</span> <span class=\"variable\">$&#123;array[1]&#125;</span></span><br><span class=\"line\"><span class=\"keyword\">done</span> &lt; the_file</span><br></pre></td></tr></table></figure>"},{"title":"Power Spectral Density","abbrlink":"1fdb9bb8","date":"2021-03-29T06:52:08.000Z","_content":"![ANMO台2013年12月的能量谱密度](https://i.loli.net/2021/03/29/OXQhg3SjozrPT6e.png)\n<!-- less -->\n![](http://service.iris.edu/mustang/noise-pdf/1/query?target=IU.ANMO.00.BHZ.M&starttime=2013-12-01&endtime=2013-12-31&format=plot)\n&emsp;&emsp;封面图是IRIS提供的查看台站能量谱密度图，网址见[mustang](http://service.iris.edu/mustang/noise-pdf/1/query?target=IU.ANMO.00.BHZ.M&starttime=2013-12-01&endtime=2013-12-31&format=plot).\n&emsp;&emsp;咱们也得会啊，要不然怎么分析自己的数据？于是按照MacNamara and Buland (2004)的文章给的公式自己编了一个程序。同样计算了ANMO台2013年12月竖直分量BHZ的能量谱密度，是这个样子：\n![自己算的ANMO台BHZ分量2013年12月能量谱密度](https://i.loli.net/2021/03/29/rLfmZ1hWNleQKC8.png)\n&emsp;&emsp;对比看来好像形状差不多了，但是。。。怎么我算出来的比IRIS的整体高了20分贝呢？\n&emsp;&emsp;后来明白了，是公式里dt的原因。我是除的dt，其实应该是乘。乘上dt就对了，开森。\n","source":"_posts/2021-03-29-pdf.md","raw":"---\ntitle: Power Spectral Density\ncategories:\n  - work\ntags:\n  - work\nabbrlink: 1fdb9bb8\ndate: 2021-03-29 14:52:08\n---\n![ANMO台2013年12月的能量谱密度](https://i.loli.net/2021/03/29/OXQhg3SjozrPT6e.png)\n<!-- less -->\n![](http://service.iris.edu/mustang/noise-pdf/1/query?target=IU.ANMO.00.BHZ.M&starttime=2013-12-01&endtime=2013-12-31&format=plot)\n&emsp;&emsp;封面图是IRIS提供的查看台站能量谱密度图，网址见[mustang](http://service.iris.edu/mustang/noise-pdf/1/query?target=IU.ANMO.00.BHZ.M&starttime=2013-12-01&endtime=2013-12-31&format=plot).\n&emsp;&emsp;咱们也得会啊，要不然怎么分析自己的数据？于是按照MacNamara and Buland (2004)的文章给的公式自己编了一个程序。同样计算了ANMO台2013年12月竖直分量BHZ的能量谱密度，是这个样子：\n![自己算的ANMO台BHZ分量2013年12月能量谱密度](https://i.loli.net/2021/03/29/rLfmZ1hWNleQKC8.png)\n&emsp;&emsp;对比看来好像形状差不多了，但是。。。怎么我算出来的比IRIS的整体高了20分贝呢？\n&emsp;&emsp;后来明白了，是公式里dt的原因。我是除的dt，其实应该是乘。乘上dt就对了，开森。\n","slug":"pdf","published":1,"updated":"2024-05-26T14:17:36.847Z","comments":1,"layout":"post","photos":[],"_id":"cmh498ipf005ywvoudxnjftlh","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p><img src=\"http://service.iris.edu/mustang/noise-pdf/1/query?target=IU.ANMO.00.BHZ.M&starttime=2013-12-01&endtime=2013-12-31&format=plot\"><br>&emsp;&emsp;封面图是IRIS提供的查看台站能量谱密度图，网址见<a href=\"http://service.iris.edu/mustang/noise-pdf/1/query?target=IU.ANMO.00.BHZ.M&starttime=2013-12-01&endtime=2013-12-31&format=plot\">mustang</a>.<br>&emsp;&emsp;咱们也得会啊，要不然怎么分析自己的数据？于是按照MacNamara and Buland (2004)的文章给的公式自己编了一个程序。同样计算了ANMO台2013年12月竖直分量BHZ的能量谱密度，是这个样子：<br><img src=\"https://i.loli.net/2021/03/29/rLfmZ1hWNleQKC8.png\" alt=\"自己算的ANMO台BHZ分量2013年12月能量谱密度\"><br>&emsp;&emsp;对比看来好像形状差不多了，但是。。。怎么我算出来的比IRIS的整体高了20分贝呢？<br>&emsp;&emsp;后来明白了，是公式里dt的原因。我是除的dt，其实应该是乘。乘上dt就对了，开森。</p>","related_posts":[],"length":265,"excerpt":"<p><img src=\"https://i.loli.net/2021/03/29/OXQhg3SjozrPT6e.png\" alt=\"ANMO台2013年12月的能量谱密度\"></p>","more":"<p><img src=\"http://service.iris.edu/mustang/noise-pdf/1/query?target=IU.ANMO.00.BHZ.M&starttime=2013-12-01&endtime=2013-12-31&format=plot\"><br>&emsp;&emsp;封面图是IRIS提供的查看台站能量谱密度图，网址见<a href=\"http://service.iris.edu/mustang/noise-pdf/1/query?target=IU.ANMO.00.BHZ.M&starttime=2013-12-01&endtime=2013-12-31&format=plot\">mustang</a>.<br>&emsp;&emsp;咱们也得会啊，要不然怎么分析自己的数据？于是按照MacNamara and Buland (2004)的文章给的公式自己编了一个程序。同样计算了ANMO台2013年12月竖直分量BHZ的能量谱密度，是这个样子：<br><img src=\"https://i.loli.net/2021/03/29/rLfmZ1hWNleQKC8.png\" alt=\"自己算的ANMO台BHZ分量2013年12月能量谱密度\"><br>&emsp;&emsp;对比看来好像形状差不多了，但是。。。怎么我算出来的比IRIS的整体高了20分贝呢？<br>&emsp;&emsp;后来明白了，是公式里dt的原因。我是除的dt，其实应该是乘。乘上dt就对了，开森。</p>"},{"title":"重新安装Elementary OS系统","abbrlink":"b808b485","date":"2021-07-23T07:44:13.000Z","_content":"&emsp;&emsp;之前买的新电脑Zbook还行，安装了fedora 32（见{% post_link after-fedora32 %}）以后结果出现各种问题。包括，不能安装sac，rdseed，hexo，wikimedia。一气之下就安装回了Elementary OS。这里记录一下Elementary OS的配置。\n<!-- more -->\n## 软件更新管理器\n安装命令如下：\n```bash \nsudo apt update\nsudo apt install software-properties-common software-properties-gtk\n```\n安装完以后在application里面输入app就可以运行了。挑选合适的镜像，然后更新系统。\n\n## 中文输入法安装\n安装命令如下：\n```bash\nsudo apt-get remove ibus   # 卸载ibus\nsudo apt-get remove scim \nsudo apt-get autoremove   # 删除依赖包\nsudo add-apt-repository ppa:fcitx-team/nightly\nsudo apt-get update\nsudo apt-get install im-switch fcitx fcitx-config-gtk fcitx-sunpinyin fcitx-module-cloudpinyin fcitx-googlepinyin   \nsudo im-switch -s fcitx -z default\n```\n\n## 安装google-chrome浏览器\n```bash\nwget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb\nsudo dpkg -i google-chrome-stable_current_amd64.deb\nsudo apt install -f   # 自动安装依赖\n```\n\n## Hot corner快速显示桌面\n\n```bash\nsudo apt install wmctrl\nwmctrl -k on\n```\n命令wmctrl -k on为显示桌面，将其放在System Settings/Desktop/Hot Corners/Custom Command就可以了。\n\n## 安装hexo，SAC，rdseed，gmt一点问题都没有。\n\nto be continued.\n","source":"_posts/2021-07-23-install-elementary-os-again.md","raw":"---\ntitle: 重新安装Elementary OS系统\nabbrlink: b808b485\ncategories:\n  - Linux\ntags:\n  - 日记\ndate: 2021-07-23 15:44:13\n---\n&emsp;&emsp;之前买的新电脑Zbook还行，安装了fedora 32（见{% post_link after-fedora32 %}）以后结果出现各种问题。包括，不能安装sac，rdseed，hexo，wikimedia。一气之下就安装回了Elementary OS。这里记录一下Elementary OS的配置。\n<!-- more -->\n## 软件更新管理器\n安装命令如下：\n```bash \nsudo apt update\nsudo apt install software-properties-common software-properties-gtk\n```\n安装完以后在application里面输入app就可以运行了。挑选合适的镜像，然后更新系统。\n\n## 中文输入法安装\n安装命令如下：\n```bash\nsudo apt-get remove ibus   # 卸载ibus\nsudo apt-get remove scim \nsudo apt-get autoremove   # 删除依赖包\nsudo add-apt-repository ppa:fcitx-team/nightly\nsudo apt-get update\nsudo apt-get install im-switch fcitx fcitx-config-gtk fcitx-sunpinyin fcitx-module-cloudpinyin fcitx-googlepinyin   \nsudo im-switch -s fcitx -z default\n```\n\n## 安装google-chrome浏览器\n```bash\nwget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb\nsudo dpkg -i google-chrome-stable_current_amd64.deb\nsudo apt install -f   # 自动安装依赖\n```\n\n## Hot corner快速显示桌面\n\n```bash\nsudo apt install wmctrl\nwmctrl -k on\n```\n命令wmctrl -k on为显示桌面，将其放在System Settings/Desktop/Hot Corners/Custom Command就可以了。\n\n## 安装hexo，SAC，rdseed，gmt一点问题都没有。\n\nto be continued.\n","slug":"install-elementary-os-again","published":1,"updated":"2024-05-26T14:17:36.847Z","comments":1,"layout":"post","photos":[],"_id":"cmh498ipf0062wvouh3uo5rmk","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>&emsp;&emsp;之前买的新电脑Zbook还行，安装了fedora 32（见<a href=\"/after-fedora32\" title=\"安装完fedora32之后\">安装完fedora32之后</a>）以后结果出现各种问题。包括，不能安装sac，rdseed，hexo，wikimedia。一气之下就安装回了Elementary OS。这里记录一下Elementary OS的配置。</p>\n<span id=\"more\"></span>\n<h2 id=\"软件更新管理器\"><a href=\"#软件更新管理器\" class=\"headerlink\" title=\"软件更新管理器\"></a>软件更新管理器</h2><p>安装命令如下：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">sudo</span> apt update</span><br><span class=\"line\"><span class=\"built_in\">sudo</span> apt install software-properties-common software-properties-gtk</span><br></pre></td></tr></table></figure>\n<p>安装完以后在application里面输入app就可以运行了。挑选合适的镜像，然后更新系统。</p>\n<h2 id=\"中文输入法安装\"><a href=\"#中文输入法安装\" class=\"headerlink\" title=\"中文输入法安装\"></a>中文输入法安装</h2><p>安装命令如下：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">sudo</span> apt-get remove ibus   <span class=\"comment\"># 卸载ibus</span></span><br><span class=\"line\"><span class=\"built_in\">sudo</span> apt-get remove scim </span><br><span class=\"line\"><span class=\"built_in\">sudo</span> apt-get autoremove   <span class=\"comment\"># 删除依赖包</span></span><br><span class=\"line\"><span class=\"built_in\">sudo</span> add-apt-repository ppa:fcitx-team/nightly</span><br><span class=\"line\"><span class=\"built_in\">sudo</span> apt-get update</span><br><span class=\"line\"><span class=\"built_in\">sudo</span> apt-get install im-switch fcitx fcitx-config-gtk fcitx-sunpinyin fcitx-module-cloudpinyin fcitx-googlepinyin   </span><br><span class=\"line\"><span class=\"built_in\">sudo</span> im-switch -s fcitx -z default</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"安装google-chrome浏览器\"><a href=\"#安装google-chrome浏览器\" class=\"headerlink\" title=\"安装google-chrome浏览器\"></a>安装google-chrome浏览器</h2><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb</span><br><span class=\"line\"><span class=\"built_in\">sudo</span> dpkg -i google-chrome-stable_current_amd64.deb</span><br><span class=\"line\"><span class=\"built_in\">sudo</span> apt install -f   <span class=\"comment\"># 自动安装依赖</span></span><br></pre></td></tr></table></figure>\n\n<h2 id=\"Hot-corner快速显示桌面\"><a href=\"#Hot-corner快速显示桌面\" class=\"headerlink\" title=\"Hot corner快速显示桌面\"></a>Hot corner快速显示桌面</h2><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">sudo</span> apt install wmctrl</span><br><span class=\"line\">wmctrl -k on</span><br></pre></td></tr></table></figure>\n<p>命令wmctrl -k on为显示桌面，将其放在System Settings&#x2F;Desktop&#x2F;Hot Corners&#x2F;Custom Command就可以了。</p>\n<h2 id=\"安装hexo，SAC，rdseed，gmt一点问题都没有。\"><a href=\"#安装hexo，SAC，rdseed，gmt一点问题都没有。\" class=\"headerlink\" title=\"安装hexo，SAC，rdseed，gmt一点问题都没有。\"></a>安装hexo，SAC，rdseed，gmt一点问题都没有。</h2><p>to be continued.</p>\n","related_posts":["how-to-set-X11-in-fedora.html"],"length":920,"excerpt":"<p>&emsp;&emsp;之前买的新电脑Zbook还行，安装了fedora 32（见<a href=\"/after-fedora32\" title=\"安装完fedora32之后\">安装完fedora32之后</a>）以后结果出现各种问题。包括，不能安装sac，rdseed，hexo，wikimedia。一气之下就安装回了Elementary OS。这里记录一下Elementary OS的配置。</p>","more":"<h2 id=\"软件更新管理器\"><a href=\"#软件更新管理器\" class=\"headerlink\" title=\"软件更新管理器\"></a>软件更新管理器</h2><p>安装命令如下：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">sudo</span> apt update</span><br><span class=\"line\"><span class=\"built_in\">sudo</span> apt install software-properties-common software-properties-gtk</span><br></pre></td></tr></table></figure>\n<p>安装完以后在application里面输入app就可以运行了。挑选合适的镜像，然后更新系统。</p>\n<h2 id=\"中文输入法安装\"><a href=\"#中文输入法安装\" class=\"headerlink\" title=\"中文输入法安装\"></a>中文输入法安装</h2><p>安装命令如下：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">sudo</span> apt-get remove ibus   <span class=\"comment\"># 卸载ibus</span></span><br><span class=\"line\"><span class=\"built_in\">sudo</span> apt-get remove scim </span><br><span class=\"line\"><span class=\"built_in\">sudo</span> apt-get autoremove   <span class=\"comment\"># 删除依赖包</span></span><br><span class=\"line\"><span class=\"built_in\">sudo</span> add-apt-repository ppa:fcitx-team/nightly</span><br><span class=\"line\"><span class=\"built_in\">sudo</span> apt-get update</span><br><span class=\"line\"><span class=\"built_in\">sudo</span> apt-get install im-switch fcitx fcitx-config-gtk fcitx-sunpinyin fcitx-module-cloudpinyin fcitx-googlepinyin   </span><br><span class=\"line\"><span class=\"built_in\">sudo</span> im-switch -s fcitx -z default</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"安装google-chrome浏览器\"><a href=\"#安装google-chrome浏览器\" class=\"headerlink\" title=\"安装google-chrome浏览器\"></a>安装google-chrome浏览器</h2><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb</span><br><span class=\"line\"><span class=\"built_in\">sudo</span> dpkg -i google-chrome-stable_current_amd64.deb</span><br><span class=\"line\"><span class=\"built_in\">sudo</span> apt install -f   <span class=\"comment\"># 自动安装依赖</span></span><br></pre></td></tr></table></figure>\n\n<h2 id=\"Hot-corner快速显示桌面\"><a href=\"#Hot-corner快速显示桌面\" class=\"headerlink\" title=\"Hot corner快速显示桌面\"></a>Hot corner快速显示桌面</h2><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">sudo</span> apt install wmctrl</span><br><span class=\"line\">wmctrl -k on</span><br></pre></td></tr></table></figure>\n<p>命令wmctrl -k on为显示桌面，将其放在System Settings&#x2F;Desktop&#x2F;Hot Corners&#x2F;Custom Command就可以了。</p>\n<h2 id=\"安装hexo，SAC，rdseed，gmt一点问题都没有。\"><a href=\"#安装hexo，SAC，rdseed，gmt一点问题都没有。\" class=\"headerlink\" title=\"安装hexo，SAC，rdseed，gmt一点问题都没有。\"></a>安装hexo，SAC，rdseed，gmt一点问题都没有。</h2><p>to be continued.</p>"},{"title":"Hexo如何插入角注","abbrlink":"77352da3","date":"2024-05-26T14:22:57.000Z","_content":"在hexo中插入角注需要安装hexo-reference，命令：\n```\nnpm install hexo-reference\n```\n语法是：\n加入这个：\n[\\^1]\n在最后加入这个：\n[\\^1]:https://github.com/kchen0x/hexo-reference\n显示出来是：\n参见这样加入reference[^1]\n[^1]:https://github.com/kchen0x/hexo-reference\n\n","source":"_posts/2024-05-26-reference-mod.md","raw":"---\ntitle: Hexo如何插入角注\nabbrlink: 77352da3\ndate: 2024-05-26 22:22:57\ntags:\n---\n在hexo中插入角注需要安装hexo-reference，命令：\n```\nnpm install hexo-reference\n```\n语法是：\n加入这个：\n[\\^1]\n在最后加入这个：\n[\\^1]:https://github.com/kchen0x/hexo-reference\n显示出来是：\n参见这样加入reference[^1]\n[^1]:https://github.com/kchen0x/hexo-reference\n\n","slug":"reference-mod","published":1,"updated":"2024-05-27T06:27:38.006Z","comments":1,"layout":"post","photos":[],"_id":"cmh498ipg0065wvou2yxd7bnh","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>在hexo中插入角注需要安装hexo-reference，命令：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">npm install hexo-reference</span><br></pre></td></tr></table></figure>\n<p>语法是：<br>加入这个：<br>[^1]<br>在最后加入这个：<br>[^1]:<a href=\"https://github.com/kchen0x/hexo-reference\">https://github.com/kchen0x/hexo-reference</a><br>显示出来是：<br>参见这样加入reference<sup id=\"fnref:1\"><a href=\"#fn:1\" rel=\"footnote\"><span class=\"hint--top hint--error hint--medium hint--rounded hint--bounce\" aria-label=\"https://github.com/kchen0x/hexo-reference\">[1]</span></a></sup></p>\n<div id=\"footnotes\"><hr><div id=\"footnotelist\"><ol style=\"list-style: none; padding-left: 0; margin-left: 40px\"><li id=\"fn:1\"><span style=\"display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px\">1.</span><span style=\"display: inline-block; vertical-align: top; margin-left: 10px;\">https://github.com/kchen0x/hexo-reference<a href=\"#fnref:1\" rev=\"footnote\"> ↩</a></span></li></ol></div></div>","related_posts":[],"length":192,"excerpt":"","more":"<p>在hexo中插入角注需要安装hexo-reference，命令：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">npm install hexo-reference</span><br></pre></td></tr></table></figure>\n<p>语法是：<br>加入这个：<br>[^1]<br>在最后加入这个：<br>[^1]:<a href=\"https://github.com/kchen0x/hexo-reference\">https://github.com/kchen0x/hexo-reference</a><br>显示出来是：<br>参见这样加入reference<sup id=\"fnref:1\"><a href=\"#fn:1\" rel=\"footnote\"><span class=\"hint--top hint--error hint--medium hint--rounded hint--bounce\" aria-label=\"https://github.com/kchen0x/hexo-reference\">[1]</span></a></sup></p>\n<div id=\"footnotes\"><hr><div id=\"footnotelist\"><ol style=\"list-style: none; padding-left: 0; margin-left: 40px\"><li id=\"fn:1\"><span style=\"display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px\">1.</span><span style=\"display: inline-block; vertical-align: top; margin-left: 10px;\">https://github.com/kchen0x/hexo-reference<a href=\"#fnref:1\" rev=\"footnote\"> ↩</a></span></li></ol></div></div>"},{"title":"Hexo添加字数统计","abbrlink":"986e5406","date":"2024-05-27T08:50:09.000Z","_content":"1. 修改根目录下的_config.yml. 找到busuanzi_count:\nenable: true\n\n2. 修改themes下的_config.yml. 找到footer：\ncounter: true\n\n3. 修改themes/next/layout/_partials/footer.njk，添加:\n```\n{% if theme.footer.counter %}\n    <script async src=\"//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js\"></script>\n{% endif %}\n```\n","source":"_posts/2024-05-27-add_counter.md","raw":"---\ntitle: Hexo添加字数统计\nabbrlink: '986e5406'\ncategories: \n   - web\ndate: 2024-05-27 16:50:09\ntags:\n    - hexo\n    - web\n---\n1. 修改根目录下的_config.yml. 找到busuanzi_count:\nenable: true\n\n2. 修改themes下的_config.yml. 找到footer：\ncounter: true\n\n3. 修改themes/next/layout/_partials/footer.njk，添加:\n```\n{% if theme.footer.counter %}\n    <script async src=\"//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js\"></script>\n{% endif %}\n```\n","slug":"add_counter","published":1,"updated":"2024-05-28T11:41:51.234Z","comments":1,"layout":"post","photos":[],"_id":"cmh498ipg0068wvou4uqtgba7","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><ol>\n<li><p>修改根目录下的_config.yml. 找到busuanzi_count:<br>enable: true</p>\n</li>\n<li><p>修改themes下的_config.yml. 找到footer：<br>counter: true</p>\n</li>\n<li><p>修改themes&#x2F;next&#x2F;layout&#x2F;_partials&#x2F;footer.njk，添加:</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;% if theme.footer.counter %&#125;</span><br><span class=\"line\">    &lt;script async src=&quot;//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js&quot;&gt;&lt;/script&gt;</span><br><span class=\"line\">&#123;% endif %&#125;</span><br></pre></td></tr></table></figure></li>\n</ol>\n","related_posts":["how-to-encrypt.html","how-to-use-utterances.html","avatar-to-homepage.html","what-did-I-do-to-this-blog.html","how-I-build-this-web.html"],"length":320,"excerpt":"","more":"<ol>\n<li><p>修改根目录下的_config.yml. 找到busuanzi_count:<br>enable: true</p>\n</li>\n<li><p>修改themes下的_config.yml. 找到footer：<br>counter: true</p>\n</li>\n<li><p>修改themes&#x2F;next&#x2F;layout&#x2F;_partials&#x2F;footer.njk，添加:</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;% if theme.footer.counter %&#125;</span><br><span class=\"line\">    &lt;script async src=&quot;//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js&quot;&gt;&lt;/script&gt;</span><br><span class=\"line\">&#123;% endif %&#125;</span><br></pre></td></tr></table></figure></li>\n</ol>\n"},{"title":"fatal'\\:' 'origin' does not appear to be a git repository","abbrlink":"e8a33bf6","date":"2024-05-27T11:20:33.000Z","_content":"运行git push origin master -f 的时候显示这个错误:\n```\nfatal: 'origin' does not appear to be a git repository fatal: Could not read from remote repository.\n```\n解决办法是重新关联远程仓库：\n```\ngit remote add origin git@github.com:junxie01/junxie01.git\n```\n","source":"_posts/2024-05-27-git-error.md","raw":"---\ntitle: 'fatal''\\:'' ''origin'' does not appear to be a git repository'\ncategories:\n  - Linux\ntags:\n  - git\nabbrlink: e8a33bf6\ndate: 2024-05-27 19:20:33\n---\n运行git push origin master -f 的时候显示这个错误:\n```\nfatal: 'origin' does not appear to be a git repository fatal: Could not read from remote repository.\n```\n解决办法是重新关联远程仓库：\n```\ngit remote add origin git@github.com:junxie01/junxie01.git\n```\n","slug":"git-error","published":1,"updated":"2024-05-28T11:56:41.463Z","comments":1,"layout":"post","photos":[],"_id":"cmh498iph006bwvoufvjs5mwb","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>运行git push origin master -f 的时候显示这个错误:</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">fatal: &#x27;origin&#x27; does not appear to be a git repository fatal: Could not read from remote repository.</span><br></pre></td></tr></table></figure>\n<p>解决办法是重新关联远程仓库：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git remote add origin git@github.com:junxie01/junxie01.git</span><br></pre></td></tr></table></figure>\n","related_posts":["how-I-build-this-web.html","how-to-calculate-synthetic-NCF.html"],"length":197,"excerpt":"","more":"<p>运行git push origin master -f 的时候显示这个错误:</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">fatal: &#x27;origin&#x27; does not appear to be a git repository fatal: Could not read from remote repository.</span><br></pre></td></tr></table></figure>\n<p>解决办法是重新关联远程仓库：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git remote add origin git@github.com:junxie01/junxie01.git</span><br></pre></td></tr></table></figure>\n"},{"title":"任务管理","abbrlink":"7aa0f828","date":"2024-05-27T12:29:06.000Z","_content":"\n转载自[少数派](https://sspai.com/post/87071)\n<!-- less -->\n\n## 任务管理很难\n关键：Keep It Simple and Stupid.\n任务管理是决定什么时候应该做什么事。这么一个看似简单的问题，却难以找到最优解。\n作者运用专业知识，从计算机科学的角度去解决任务管理问题。\n\n##  背包问题\n   \"给定一个物品集合（多个物品），每个物品都有各自的重量和价格。存在一个背包，具有一定容量。我们应该将哪几个物品放进背包，使得物品总重量不超过背包的容量，并且背包中的物品总价格最高。\"\n   随着物品数量的增加，将所有方案尝试一遍会消耗大量时间，这就是背包问题很「难」的原因。\n   如果将任务看成物品，一天的时间看成背包，那么任务所需时间就对应物品的重量，任务完成收益就对应物品的价格，任务管理其实就是决定将哪些任务放进一天这个背包中，从而使一天内完成的任务价格最高。\n   如何优化任务管理？\n## 剪枝优化\n   对于每个任务，我需要决策是否将该任务列入「我的一天」。将这个决策过程具像化，就是一棵树（决策树）。每一个选项（是或者否）都像树枝一样，引出不同的结果，剪枝优化就是将决策树的枝桠剪去。\n也就是说不是所有任务都值得被放进 todo list 中简化自己的需求。\n\n如何保证剪枝的正确性？如何保证简化后的需求能够满足工作需要呢？首先明确任务管理的目的是提高工作效率，所以我将所有生活类的任务从 Todo list中移除。确保一个任务足够重要才会放入todo list中。\n要定期删除 Todo list 中的任务，因为如果一项任务一直存在，意味着它可能不重要，否则早就应该被完成了。\n\n最终，Todo list 中的所有任务通常不超过五个，我只需要选 2-3 个任务添加到「我的一天」，很快速，也很简单。\n\n## 局部性原理\n在设计程序时，计算机通常倾向于重复利用邻近的数据，这就是系统设计中的「局部性原理」。\n\n人脑也很健忘，很多事情转头就忘掉，所以应尽量将任务放在触手可及的地方，要具体。局部性原理保证了大脑注意力集中，不会因为频繁地上下文切换，忘记需要做什么，使跨天的工作更加流畅。\n\n## 任务完成时间期望\n背包问题中一个重要约束是背包的容量，对应任务管理：如何保证任务管理时，规划的任务能在当天完成。一天的工作时间很容易确定，但是没有完成任务的情况下，怎么知道任务所需时间呢？\n\n想要准确地推测任务完成时间比较难，但总会有人帮你确定任务完成时间。因为生活中会有很多deadline。按照小时为粒度进行规划，就可以在一个上午安排好几项任务。要有意识地去评估每个任务的所需时间，利用数学方法去锻炼评估能力。例如期望值，代表了多次实验后，可能出现状态的平均结果。\n\n记录下每次任务「评估完成时间」和「真实完成时间」，就可以知道每次推测是否准确。相应的差值称为「推测偏差」。如果推测偏差的期望为15%，那么一项需要120分钟完成的任务，实际完成时间很可能是 120+120*0.15=138 分钟。根据偏差值的数学期望，就能够有一个大概印象，每一项任务大概需要多久时间才能完成，便于更高效地规划「我的一天」。\n\n## 任务管理的本质和愚蠢的系统\n任务管理的本质是个人管理。如果人足够自律，就像一个精密的机器，那完全不需要各种花里胡哨的工具或方法论，只需要将任务列出来，一个接一个地完成。但是一般人都没有那么自律，执行力也不够强，时间表不断被打乱，需要不断的优化。\n","source":"_posts/2024-05-27-optimize-daily-task.md","raw":"---\ntitle: 任务管理\nabbrlink: 7aa0f828\ndate: 2024-05-27 20:29:06\ncategories:\n   - 学习\ntags:\n   - 学习\n---\n\n转载自[少数派](https://sspai.com/post/87071)\n<!-- less -->\n\n## 任务管理很难\n关键：Keep It Simple and Stupid.\n任务管理是决定什么时候应该做什么事。这么一个看似简单的问题，却难以找到最优解。\n作者运用专业知识，从计算机科学的角度去解决任务管理问题。\n\n##  背包问题\n   \"给定一个物品集合（多个物品），每个物品都有各自的重量和价格。存在一个背包，具有一定容量。我们应该将哪几个物品放进背包，使得物品总重量不超过背包的容量，并且背包中的物品总价格最高。\"\n   随着物品数量的增加，将所有方案尝试一遍会消耗大量时间，这就是背包问题很「难」的原因。\n   如果将任务看成物品，一天的时间看成背包，那么任务所需时间就对应物品的重量，任务完成收益就对应物品的价格，任务管理其实就是决定将哪些任务放进一天这个背包中，从而使一天内完成的任务价格最高。\n   如何优化任务管理？\n## 剪枝优化\n   对于每个任务，我需要决策是否将该任务列入「我的一天」。将这个决策过程具像化，就是一棵树（决策树）。每一个选项（是或者否）都像树枝一样，引出不同的结果，剪枝优化就是将决策树的枝桠剪去。\n也就是说不是所有任务都值得被放进 todo list 中简化自己的需求。\n\n如何保证剪枝的正确性？如何保证简化后的需求能够满足工作需要呢？首先明确任务管理的目的是提高工作效率，所以我将所有生活类的任务从 Todo list中移除。确保一个任务足够重要才会放入todo list中。\n要定期删除 Todo list 中的任务，因为如果一项任务一直存在，意味着它可能不重要，否则早就应该被完成了。\n\n最终，Todo list 中的所有任务通常不超过五个，我只需要选 2-3 个任务添加到「我的一天」，很快速，也很简单。\n\n## 局部性原理\n在设计程序时，计算机通常倾向于重复利用邻近的数据，这就是系统设计中的「局部性原理」。\n\n人脑也很健忘，很多事情转头就忘掉，所以应尽量将任务放在触手可及的地方，要具体。局部性原理保证了大脑注意力集中，不会因为频繁地上下文切换，忘记需要做什么，使跨天的工作更加流畅。\n\n## 任务完成时间期望\n背包问题中一个重要约束是背包的容量，对应任务管理：如何保证任务管理时，规划的任务能在当天完成。一天的工作时间很容易确定，但是没有完成任务的情况下，怎么知道任务所需时间呢？\n\n想要准确地推测任务完成时间比较难，但总会有人帮你确定任务完成时间。因为生活中会有很多deadline。按照小时为粒度进行规划，就可以在一个上午安排好几项任务。要有意识地去评估每个任务的所需时间，利用数学方法去锻炼评估能力。例如期望值，代表了多次实验后，可能出现状态的平均结果。\n\n记录下每次任务「评估完成时间」和「真实完成时间」，就可以知道每次推测是否准确。相应的差值称为「推测偏差」。如果推测偏差的期望为15%，那么一项需要120分钟完成的任务，实际完成时间很可能是 120+120*0.15=138 分钟。根据偏差值的数学期望，就能够有一个大概印象，每一项任务大概需要多久时间才能完成，便于更高效地规划「我的一天」。\n\n## 任务管理的本质和愚蠢的系统\n任务管理的本质是个人管理。如果人足够自律，就像一个精密的机器，那完全不需要各种花里胡哨的工具或方法论，只需要将任务列出来，一个接一个地完成。但是一般人都没有那么自律，执行力也不够强，时间表不断被打乱，需要不断的优化。\n","slug":"optimize-daily-task","published":1,"updated":"2024-05-28T11:40:41.309Z","comments":1,"layout":"post","photos":[],"_id":"cmh498iph006dwvou0qiz127b","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><h2 id=\"任务管理很难\"><a href=\"#任务管理很难\" class=\"headerlink\" title=\"任务管理很难\"></a>任务管理很难</h2><p>关键：Keep It Simple and Stupid.<br>任务管理是决定什么时候应该做什么事。这么一个看似简单的问题，却难以找到最优解。<br>作者运用专业知识，从计算机科学的角度去解决任务管理问题。</p>\n<h2 id=\"背包问题\"><a href=\"#背包问题\" class=\"headerlink\" title=\"背包问题\"></a>背包问题</h2><p>   “给定一个物品集合（多个物品），每个物品都有各自的重量和价格。存在一个背包，具有一定容量。我们应该将哪几个物品放进背包，使得物品总重量不超过背包的容量，并且背包中的物品总价格最高。”<br>   随着物品数量的增加，将所有方案尝试一遍会消耗大量时间，这就是背包问题很「难」的原因。<br>   如果将任务看成物品，一天的时间看成背包，那么任务所需时间就对应物品的重量，任务完成收益就对应物品的价格，任务管理其实就是决定将哪些任务放进一天这个背包中，从而使一天内完成的任务价格最高。<br>   如何优化任务管理？</p>\n<h2 id=\"剪枝优化\"><a href=\"#剪枝优化\" class=\"headerlink\" title=\"剪枝优化\"></a>剪枝优化</h2><p>   对于每个任务，我需要决策是否将该任务列入「我的一天」。将这个决策过程具像化，就是一棵树（决策树）。每一个选项（是或者否）都像树枝一样，引出不同的结果，剪枝优化就是将决策树的枝桠剪去。<br>也就是说不是所有任务都值得被放进 todo list 中简化自己的需求。</p>\n<p>如何保证剪枝的正确性？如何保证简化后的需求能够满足工作需要呢？首先明确任务管理的目的是提高工作效率，所以我将所有生活类的任务从 Todo list中移除。确保一个任务足够重要才会放入todo list中。<br>要定期删除 Todo list 中的任务，因为如果一项任务一直存在，意味着它可能不重要，否则早就应该被完成了。</p>\n<p>最终，Todo list 中的所有任务通常不超过五个，我只需要选 2-3 个任务添加到「我的一天」，很快速，也很简单。</p>\n<h2 id=\"局部性原理\"><a href=\"#局部性原理\" class=\"headerlink\" title=\"局部性原理\"></a>局部性原理</h2><p>在设计程序时，计算机通常倾向于重复利用邻近的数据，这就是系统设计中的「局部性原理」。</p>\n<p>人脑也很健忘，很多事情转头就忘掉，所以应尽量将任务放在触手可及的地方，要具体。局部性原理保证了大脑注意力集中，不会因为频繁地上下文切换，忘记需要做什么，使跨天的工作更加流畅。</p>\n<h2 id=\"任务完成时间期望\"><a href=\"#任务完成时间期望\" class=\"headerlink\" title=\"任务完成时间期望\"></a>任务完成时间期望</h2><p>背包问题中一个重要约束是背包的容量，对应任务管理：如何保证任务管理时，规划的任务能在当天完成。一天的工作时间很容易确定，但是没有完成任务的情况下，怎么知道任务所需时间呢？</p>\n<p>想要准确地推测任务完成时间比较难，但总会有人帮你确定任务完成时间。因为生活中会有很多deadline。按照小时为粒度进行规划，就可以在一个上午安排好几项任务。要有意识地去评估每个任务的所需时间，利用数学方法去锻炼评估能力。例如期望值，代表了多次实验后，可能出现状态的平均结果。</p>\n<p>记录下每次任务「评估完成时间」和「真实完成时间」，就可以知道每次推测是否准确。相应的差值称为「推测偏差」。如果推测偏差的期望为15%，那么一项需要120分钟完成的任务，实际完成时间很可能是 120+120*0.15&#x3D;138 分钟。根据偏差值的数学期望，就能够有一个大概印象，每一项任务大概需要多久时间才能完成，便于更高效地规划「我的一天」。</p>\n<h2 id=\"任务管理的本质和愚蠢的系统\"><a href=\"#任务管理的本质和愚蠢的系统\" class=\"headerlink\" title=\"任务管理的本质和愚蠢的系统\"></a>任务管理的本质和愚蠢的系统</h2><p>任务管理的本质是个人管理。如果人足够自律，就像一个精密的机器，那完全不需要各种花里胡哨的工具或方法论，只需要将任务列出来，一个接一个地完成。但是一般人都没有那么自律，执行力也不够强，时间表不断被打乱，需要不断的优化。</p>","related_posts":[],"length":1336,"excerpt":"<p>转载自<a href=\"https://sspai.com/post/87071\">少数派</a></p>","more":"<h2 id=\"任务管理很难\"><a href=\"#任务管理很难\" class=\"headerlink\" title=\"任务管理很难\"></a>任务管理很难</h2><p>关键：Keep It Simple and Stupid.<br>任务管理是决定什么时候应该做什么事。这么一个看似简单的问题，却难以找到最优解。<br>作者运用专业知识，从计算机科学的角度去解决任务管理问题。</p>\n<h2 id=\"背包问题\"><a href=\"#背包问题\" class=\"headerlink\" title=\"背包问题\"></a>背包问题</h2><p>   “给定一个物品集合（多个物品），每个物品都有各自的重量和价格。存在一个背包，具有一定容量。我们应该将哪几个物品放进背包，使得物品总重量不超过背包的容量，并且背包中的物品总价格最高。”<br>   随着物品数量的增加，将所有方案尝试一遍会消耗大量时间，这就是背包问题很「难」的原因。<br>   如果将任务看成物品，一天的时间看成背包，那么任务所需时间就对应物品的重量，任务完成收益就对应物品的价格，任务管理其实就是决定将哪些任务放进一天这个背包中，从而使一天内完成的任务价格最高。<br>   如何优化任务管理？</p>\n<h2 id=\"剪枝优化\"><a href=\"#剪枝优化\" class=\"headerlink\" title=\"剪枝优化\"></a>剪枝优化</h2><p>   对于每个任务，我需要决策是否将该任务列入「我的一天」。将这个决策过程具像化，就是一棵树（决策树）。每一个选项（是或者否）都像树枝一样，引出不同的结果，剪枝优化就是将决策树的枝桠剪去。<br>也就是说不是所有任务都值得被放进 todo list 中简化自己的需求。</p>\n<p>如何保证剪枝的正确性？如何保证简化后的需求能够满足工作需要呢？首先明确任务管理的目的是提高工作效率，所以我将所有生活类的任务从 Todo list中移除。确保一个任务足够重要才会放入todo list中。<br>要定期删除 Todo list 中的任务，因为如果一项任务一直存在，意味着它可能不重要，否则早就应该被完成了。</p>\n<p>最终，Todo list 中的所有任务通常不超过五个，我只需要选 2-3 个任务添加到「我的一天」，很快速，也很简单。</p>\n<h2 id=\"局部性原理\"><a href=\"#局部性原理\" class=\"headerlink\" title=\"局部性原理\"></a>局部性原理</h2><p>在设计程序时，计算机通常倾向于重复利用邻近的数据，这就是系统设计中的「局部性原理」。</p>\n<p>人脑也很健忘，很多事情转头就忘掉，所以应尽量将任务放在触手可及的地方，要具体。局部性原理保证了大脑注意力集中，不会因为频繁地上下文切换，忘记需要做什么，使跨天的工作更加流畅。</p>\n<h2 id=\"任务完成时间期望\"><a href=\"#任务完成时间期望\" class=\"headerlink\" title=\"任务完成时间期望\"></a>任务完成时间期望</h2><p>背包问题中一个重要约束是背包的容量，对应任务管理：如何保证任务管理时，规划的任务能在当天完成。一天的工作时间很容易确定，但是没有完成任务的情况下，怎么知道任务所需时间呢？</p>\n<p>想要准确地推测任务完成时间比较难，但总会有人帮你确定任务完成时间。因为生活中会有很多deadline。按照小时为粒度进行规划，就可以在一个上午安排好几项任务。要有意识地去评估每个任务的所需时间，利用数学方法去锻炼评估能力。例如期望值，代表了多次实验后，可能出现状态的平均结果。</p>\n<p>记录下每次任务「评估完成时间」和「真实完成时间」，就可以知道每次推测是否准确。相应的差值称为「推测偏差」。如果推测偏差的期望为15%，那么一项需要120分钟完成的任务，实际完成时间很可能是 120+120*0.15&#x3D;138 分钟。根据偏差值的数学期望，就能够有一个大概印象，每一项任务大概需要多久时间才能完成，便于更高效地规划「我的一天」。</p>\n<h2 id=\"任务管理的本质和愚蠢的系统\"><a href=\"#任务管理的本质和愚蠢的系统\" class=\"headerlink\" title=\"任务管理的本质和愚蠢的系统\"></a>任务管理的本质和愚蠢的系统</h2><p>任务管理的本质是个人管理。如果人足够自律，就像一个精密的机器，那完全不需要各种花里胡哨的工具或方法论，只需要将任务列出来，一个接一个地完成。但是一般人都没有那么自律，执行力也不够强，时间表不断被打乱，需要不断的优化。</p>"},{"title":"密码测试","password":123456,"message":"请输入秘密查看文章","abstract":"这是一篇加密的文章，想看得问我密码。","wrong_pass_message":"密码错了，再输一次试试。","abbrlink":"9daba997","date":"2024-05-28T06:11:59.000Z","_content":"\n这是一个测试。小凯的钥匙密码是：015872 还有一个13不知道是啥。\n","source":"_posts/2024-05-28-encrypt_test.md","raw":"---\ntitle: 密码测试\npassword: 123456\nmessage: 请输入秘密查看文章\nabstract: 这是一篇加密的文章，想看得问我密码。\nwrong_pass_message: 密码错了，再输一次试试。\nabbrlink: 9daba997\ndate: 2024-05-28 14:11:59\ntags:\n---\n\n这是一个测试。小凯的钥匙密码是：015872 还有一个13不知道是啥。\n","slug":"encrypt_test","published":1,"updated":"2025-06-18T03:23:26.181Z","comments":1,"layout":"post","photos":[],"_id":"cmh498ipi006hwvoue9xtgwaw","content":"<div class=\"hbe hbe-container\" id=\"hexo-blog-encrypt\" data-wpm=\"密码错了，再输一次试试。\" data-whm=\"OOPS, these decrypted content may changed, but you can still have a look.\">\n  <script id=\"hbeData\" type=\"hbeData\" data-hmacdigest=\"ccfc24db382e5425d6abf9060771ccb5dffb4e1a3b1f7fc4c3a2947365478299\">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</script>\n  <div class=\"hbe hbe-content\">\n    <div class=\"hbe hbe-input hbe-input-default\">\n      <input class=\"hbe hbe-input-field hbe-input-field-default\" type=\"password\" id=\"hbePass\">\n      <label class=\"hbe hbe-input-label hbe-input-label-default\" for=\"hbePass\">\n        <span class=\"hbe hbe-input-label-content hbe-input-label-content-default\">请输入秘密查看文章</span>\n      </label>\n    </div>\n    <!-- 添加确认按钮 -->\n    <button id=\"hbeConfirmBtn\" class=\"hbe hbe-confirm-btn\">Confirm</button>\n  </div>\n</div>\n<script data-pjax src=\"/lib/hbe.js\"></script><link href=\"/css/hbe.style.css\" rel=\"stylesheet\" type=\"text/css\">","related_posts":[],"length":34,"excerpt":"这是一篇加密的文章，想看得问我密码。","more":"这是一篇加密的文章，想看得问我密码。","origin":"<div class=\"hbe hbe-container\" id=\"hexo-blog-encrypt\" data-wpm=\"密码错了，再输一次试试。\" data-whm=\"OOPS, these decrypted content may changed, but you can still have a look.\">\n  <script id=\"hbeData\" type=\"hbeData\" data-hmacdigest=\"b247c49756db0153dd3193bc401d5187ffcd1a1a5861b6fc930e6f0bf41e3fc9\">4630436162ade97ba2718b7d0c4b3b630ef8b034c35893a7afa4c54a5752d90eba191a593f89497fdfca691efaf72d5c35796184ebf2d80300d9b43598d875a7a2ad0b9eb70415ef7e6791ce86b8d42bc2930d2449c14d85e7e73a6e9f9f15fa83d46e9ca1f99dd9edda0d8febda3026ec8d07820490faacb5620be656dfa84b711ea52636832f743afcdcb198855b1352fa89a98a7ed095f525f10754d93372dd1c12842a359133a045e1e4ad41e2f0717ffe96379757675a8025e6efa52fa11327478e11499c522d6966ab1aaff3e2f01a4802a0028dcf0f317ade6d02a609e9d3018f90a03a74b3e3afc958874ac6986b5ca706072a33eeb47d57f768286f695035463570f016f751b60d683adee284445b84160fa732ffd467e717c87e1c0afba16c5e87bb352b0ea6231ff13fde1026bffb3f22790a794e610e58d39ed53f3102d618d6a1546389b31c3505913172e71477645574ee123f7d4ab49787029bc46889f5c64b361135e13ff8ccad4fa7ca3a0be2338ef62611bd3482cb9e9dd9fa98602f52718d1ac28ce9816bb09c2812b81053b67339f438f7eb6776810d</script>\n  <div class=\"hbe hbe-content\">\n    <div class=\"hbe hbe-input hbe-input-default\">\n      <input class=\"hbe hbe-input-field hbe-input-field-default\" type=\"password\" id=\"hbePass\">\n      <label class=\"hbe hbe-input-label hbe-input-label-default\" for=\"hbePass\">\n        <span class=\"hbe hbe-input-label-content hbe-input-label-content-default\">请输入秘密查看文章</span>\n      </label>\n    </div>\n  </div>\n</div>\n<script data-pjax src=\"/lib/hbe.js\"></script><link href=\"/css/hbe.style.css\" rel=\"stylesheet\" type=\"text/css\">","encrypt":true},{"title":"第一性原理","abbrlink":"797f0f98","date":"2024-05-27T14:38:15.000Z","_content":"转载自[少数派](https://sspai.com/post/78279)\n每个系统中都存在第一性原理，它的存在是最基本的命题和假设，不能被省略，也不能被违反。---亚里士多德\n<!-- less -->\n## 第一步：定义问题\n要解决问题之前，一定要关注两件事情：\n1. 我所解决的问题是真的，而不是一个假的问题；\n2. 我所解决的问题有一个明确的范围。\n确保你的问题和别人的问题是同一个问题。\n## 第二步：拆解问题\n如果问题复杂，则需要将其拆分为若干个小问题，保证每一个小问题之间是独立的。独立就是无交集。\n## 第三步：为问题排序\n将问题拆解以后需要对子问题排序，方法有：\n1. 解决问题的困难程度；\n2. 问题被解决后的价值。\n根据这里两个维度可将问题划分到四个项限：\n![四项限图](https://s2.loli.net/2024/05/28/MBYKixZyqoACFsz.webp)\n只专注做右侧的事情。\n## 第四步：逐个解决\n第三步中已经评估了优先级，到第四步就按照顺序做就好了。\n## 苏格拉底的方法\n在对话中质疑其中的前提、推理过程、结论。直到找到最重要的问题和解决路径。类似的有5WHT：为什么发生、为什么没有发现、为什么没有预防三个角度发问。\n## 第一性原理误区\n1. 第一性原理思维=透过现象看本质\n看本质是指看到事物背后的原因，而第一性原理是透过本质看现象。\n2. 第一性原理是唯一的\n其实不是。\n3. 第一性原理获得的结论是稳定的\n其实不一定。\n## 问题：\n1. 第一性原理适合所有场景吗？\n2. 第一性原理能帮我们增加知识吗？\n## 结语\n第一性原理知识认识论的皮毛，别生搬硬套，别乱用。\n","source":"_posts/2024-05-27-rule-no1.md","raw":"---\ntitle: 第一性原理\ncategories:\n  - 学习\ntags: \n  - 学习\nabbrlink: 797f0f98\ndate: 2024-05-27 22:38:15\n---\n转载自[少数派](https://sspai.com/post/78279)\n每个系统中都存在第一性原理，它的存在是最基本的命题和假设，不能被省略，也不能被违反。---亚里士多德\n<!-- less -->\n## 第一步：定义问题\n要解决问题之前，一定要关注两件事情：\n1. 我所解决的问题是真的，而不是一个假的问题；\n2. 我所解决的问题有一个明确的范围。\n确保你的问题和别人的问题是同一个问题。\n## 第二步：拆解问题\n如果问题复杂，则需要将其拆分为若干个小问题，保证每一个小问题之间是独立的。独立就是无交集。\n## 第三步：为问题排序\n将问题拆解以后需要对子问题排序，方法有：\n1. 解决问题的困难程度；\n2. 问题被解决后的价值。\n根据这里两个维度可将问题划分到四个项限：\n![四项限图](https://s2.loli.net/2024/05/28/MBYKixZyqoACFsz.webp)\n只专注做右侧的事情。\n## 第四步：逐个解决\n第三步中已经评估了优先级，到第四步就按照顺序做就好了。\n## 苏格拉底的方法\n在对话中质疑其中的前提、推理过程、结论。直到找到最重要的问题和解决路径。类似的有5WHT：为什么发生、为什么没有发现、为什么没有预防三个角度发问。\n## 第一性原理误区\n1. 第一性原理思维=透过现象看本质\n看本质是指看到事物背后的原因，而第一性原理是透过本质看现象。\n2. 第一性原理是唯一的\n其实不是。\n3. 第一性原理获得的结论是稳定的\n其实不一定。\n## 问题：\n1. 第一性原理适合所有场景吗？\n2. 第一性原理能帮我们增加知识吗？\n## 结语\n第一性原理知识认识论的皮毛，别生搬硬套，别乱用。\n","slug":"rule-no1","published":1,"updated":"2024-05-28T11:40:19.495Z","comments":1,"layout":"post","photos":[],"_id":"cmh498ipi006kwvou29r26yjm","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><h2 id=\"第一步：定义问题\"><a href=\"#第一步：定义问题\" class=\"headerlink\" title=\"第一步：定义问题\"></a>第一步：定义问题</h2><p>要解决问题之前，一定要关注两件事情：</p>\n<ol>\n<li>我所解决的问题是真的，而不是一个假的问题；</li>\n<li>我所解决的问题有一个明确的范围。<br>确保你的问题和别人的问题是同一个问题。</li>\n</ol>\n<h2 id=\"第二步：拆解问题\"><a href=\"#第二步：拆解问题\" class=\"headerlink\" title=\"第二步：拆解问题\"></a>第二步：拆解问题</h2><p>如果问题复杂，则需要将其拆分为若干个小问题，保证每一个小问题之间是独立的。独立就是无交集。</p>\n<h2 id=\"第三步：为问题排序\"><a href=\"#第三步：为问题排序\" class=\"headerlink\" title=\"第三步：为问题排序\"></a>第三步：为问题排序</h2><p>将问题拆解以后需要对子问题排序，方法有：</p>\n<ol>\n<li>解决问题的困难程度；</li>\n<li>问题被解决后的价值。<br>根据这里两个维度可将问题划分到四个项限：<br><img src=\"https://s2.loli.net/2024/05/28/MBYKixZyqoACFsz.webp\" alt=\"四项限图\"><br>只专注做右侧的事情。</li>\n</ol>\n<h2 id=\"第四步：逐个解决\"><a href=\"#第四步：逐个解决\" class=\"headerlink\" title=\"第四步：逐个解决\"></a>第四步：逐个解决</h2><p>第三步中已经评估了优先级，到第四步就按照顺序做就好了。</p>\n<h2 id=\"苏格拉底的方法\"><a href=\"#苏格拉底的方法\" class=\"headerlink\" title=\"苏格拉底的方法\"></a>苏格拉底的方法</h2><p>在对话中质疑其中的前提、推理过程、结论。直到找到最重要的问题和解决路径。类似的有5WHT：为什么发生、为什么没有发现、为什么没有预防三个角度发问。</p>\n<h2 id=\"第一性原理误区\"><a href=\"#第一性原理误区\" class=\"headerlink\" title=\"第一性原理误区\"></a>第一性原理误区</h2><ol>\n<li>第一性原理思维&#x3D;透过现象看本质<br>看本质是指看到事物背后的原因，而第一性原理是透过本质看现象。</li>\n<li>第一性原理是唯一的<br>其实不是。</li>\n<li>第一性原理获得的结论是稳定的<br>其实不一定。</li>\n</ol>\n<h2 id=\"问题：\"><a href=\"#问题：\" class=\"headerlink\" title=\"问题：\"></a>问题：</h2><ol>\n<li>第一性原理适合所有场景吗？</li>\n<li>第一性原理能帮我们增加知识吗？</li>\n</ol>\n<h2 id=\"结语\"><a href=\"#结语\" class=\"headerlink\" title=\"结语\"></a>结语</h2><p>第一性原理知识认识论的皮毛，别生搬硬套，别乱用。</p>","related_posts":[],"length":531,"excerpt":"<p>转载自<a href=\"https://sspai.com/post/78279\">少数派</a><br>每个系统中都存在第一性原理，它的存在是最基本的命题和假设，不能被省略，也不能被违反。—亚里士多德</p>","more":"<h2 id=\"第一步：定义问题\"><a href=\"#第一步：定义问题\" class=\"headerlink\" title=\"第一步：定义问题\"></a>第一步：定义问题</h2><p>要解决问题之前，一定要关注两件事情：</p>\n<ol>\n<li>我所解决的问题是真的，而不是一个假的问题；</li>\n<li>我所解决的问题有一个明确的范围。<br>确保你的问题和别人的问题是同一个问题。</li>\n</ol>\n<h2 id=\"第二步：拆解问题\"><a href=\"#第二步：拆解问题\" class=\"headerlink\" title=\"第二步：拆解问题\"></a>第二步：拆解问题</h2><p>如果问题复杂，则需要将其拆分为若干个小问题，保证每一个小问题之间是独立的。独立就是无交集。</p>\n<h2 id=\"第三步：为问题排序\"><a href=\"#第三步：为问题排序\" class=\"headerlink\" title=\"第三步：为问题排序\"></a>第三步：为问题排序</h2><p>将问题拆解以后需要对子问题排序，方法有：</p>\n<ol>\n<li>解决问题的困难程度；</li>\n<li>问题被解决后的价值。<br>根据这里两个维度可将问题划分到四个项限：<br><img src=\"https://s2.loli.net/2024/05/28/MBYKixZyqoACFsz.webp\" alt=\"四项限图\"><br>只专注做右侧的事情。</li>\n</ol>\n<h2 id=\"第四步：逐个解决\"><a href=\"#第四步：逐个解决\" class=\"headerlink\" title=\"第四步：逐个解决\"></a>第四步：逐个解决</h2><p>第三步中已经评估了优先级，到第四步就按照顺序做就好了。</p>\n<h2 id=\"苏格拉底的方法\"><a href=\"#苏格拉底的方法\" class=\"headerlink\" title=\"苏格拉底的方法\"></a>苏格拉底的方法</h2><p>在对话中质疑其中的前提、推理过程、结论。直到找到最重要的问题和解决路径。类似的有5WHT：为什么发生、为什么没有发现、为什么没有预防三个角度发问。</p>\n<h2 id=\"第一性原理误区\"><a href=\"#第一性原理误区\" class=\"headerlink\" title=\"第一性原理误区\"></a>第一性原理误区</h2><ol>\n<li>第一性原理思维&#x3D;透过现象看本质<br>看本质是指看到事物背后的原因，而第一性原理是透过本质看现象。</li>\n<li>第一性原理是唯一的<br>其实不是。</li>\n<li>第一性原理获得的结论是稳定的<br>其实不一定。</li>\n</ol>\n<h2 id=\"问题：\"><a href=\"#问题：\" class=\"headerlink\" title=\"问题：\"></a>问题：</h2><ol>\n<li>第一性原理适合所有场景吗？</li>\n<li>第一性原理能帮我们增加知识吗？</li>\n</ol>\n<h2 id=\"结语\"><a href=\"#结语\" class=\"headerlink\" title=\"结语\"></a>结语</h2><p>第一性原理知识认识论的皮毛，别生搬硬套，别乱用。</p>"},{"title":"hexo如何给文章加框","abbrlink":"43f10f83","date":"2024-05-28T07:25:54.000Z","_content":"hexo next主题如何给文章加框？\n<!-- less -->\n找到hexo/themes/next/source/css/_common/components/post/index.styl\n将：\n```\n  if (hexo-config('motion.transition.post_block')) {\n    .post-block, .pagination, .comments {\n      visibility: hidden;\n    }\n  }\n```\n改为：\n```\n  if (hexo-config('motion.transition.post_block')) {\n   .post-block{\n     visibility: hidden;\n     margin-top: 60px;\n     margin-bottom: 60px;\n     padding: 25px;\n     -webkit-box-shadow: 0 0 5px rgba(202, 203, 203, 1);\n     -moz-box-shadow: 0 0 5px rgba(202, 203, 204, 1);\n     }\n   .pagination, .comments {\n      visibility: hidden;\n    }\n```\n","source":"_posts/2024-05-28-how-to-add-frame.md","raw":"---\ntitle: hexo如何给文章加框\ncategories:\n  - web\ntags:\n  - hexo\n  - web\nabbrlink: 43f10f83\ndate: 2024-05-28 15:25:54\n---\nhexo next主题如何给文章加框？\n<!-- less -->\n找到hexo/themes/next/source/css/_common/components/post/index.styl\n将：\n```\n  if (hexo-config('motion.transition.post_block')) {\n    .post-block, .pagination, .comments {\n      visibility: hidden;\n    }\n  }\n```\n改为：\n```\n  if (hexo-config('motion.transition.post_block')) {\n   .post-block{\n     visibility: hidden;\n     margin-top: 60px;\n     margin-bottom: 60px;\n     padding: 25px;\n     -webkit-box-shadow: 0 0 5px rgba(202, 203, 203, 1);\n     -moz-box-shadow: 0 0 5px rgba(202, 203, 204, 1);\n     }\n   .pagination, .comments {\n      visibility: hidden;\n    }\n```\n","slug":"how-to-add-frame","published":1,"updated":"2024-05-28T11:36:58.834Z","comments":1,"layout":"post","photos":[],"_id":"cmh498ipj006nwvou1qkt23l6","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>找到hexo&#x2F;themes&#x2F;next&#x2F;source&#x2F;css&#x2F;_common&#x2F;components&#x2F;post&#x2F;index.styl<br>将：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">if (hexo-config(&#x27;motion.transition.post_block&#x27;)) &#123;</span><br><span class=\"line\">  .post-block, .pagination, .comments &#123;</span><br><span class=\"line\">    visibility: hidden;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>改为：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">if (hexo-config(&#x27;motion.transition.post_block&#x27;)) &#123;</span><br><span class=\"line\"> .post-block&#123;</span><br><span class=\"line\">   visibility: hidden;</span><br><span class=\"line\">   margin-top: 60px;</span><br><span class=\"line\">   margin-bottom: 60px;</span><br><span class=\"line\">   padding: 25px;</span><br><span class=\"line\">   -webkit-box-shadow: 0 0 5px rgba(202, 203, 203, 1);</span><br><span class=\"line\">   -moz-box-shadow: 0 0 5px rgba(202, 203, 204, 1);</span><br><span class=\"line\">   &#125;</span><br><span class=\"line\"> .pagination, .comments &#123;</span><br><span class=\"line\">    visibility: hidden;</span><br><span class=\"line\">  &#125;</span><br></pre></td></tr></table></figure>","related_posts":["reward-configuration.html","how-to-add-frame-in-hexo-next.html","show-picture-in-hexo.html","statistic-data-download.html","what-did-I-do-to-this-blog.html"],"length":567,"excerpt":"<p>hexo next主题如何给文章加框？</p>","more":"<p>找到hexo&#x2F;themes&#x2F;next&#x2F;source&#x2F;css&#x2F;_common&#x2F;components&#x2F;post&#x2F;index.styl<br>将：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">if (hexo-config(&#x27;motion.transition.post_block&#x27;)) &#123;</span><br><span class=\"line\">  .post-block, .pagination, .comments &#123;</span><br><span class=\"line\">    visibility: hidden;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>改为：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">if (hexo-config(&#x27;motion.transition.post_block&#x27;)) &#123;</span><br><span class=\"line\"> .post-block&#123;</span><br><span class=\"line\">   visibility: hidden;</span><br><span class=\"line\">   margin-top: 60px;</span><br><span class=\"line\">   margin-bottom: 60px;</span><br><span class=\"line\">   padding: 25px;</span><br><span class=\"line\">   -webkit-box-shadow: 0 0 5px rgba(202, 203, 203, 1);</span><br><span class=\"line\">   -moz-box-shadow: 0 0 5px rgba(202, 203, 204, 1);</span><br><span class=\"line\">   &#125;</span><br><span class=\"line\"> .pagination, .comments &#123;</span><br><span class=\"line\">    visibility: hidden;</span><br><span class=\"line\">  &#125;</span><br></pre></td></tr></table></figure>"},{"title":"hexo 如何给文章设密码","abbrlink":"7c8ba603","date":"2024-05-28T06:15:34.000Z","_content":"有些文章写了，但不想要给别人看，那就设一个密码。\n<!-- less -->\n# 安装插件\n命令：\n```\nnpm install hexo-blog-encrypt\n```\n# 修改配置\n在本目录配置文件_config.yml加入：\n```\nencrypt:\n   enable: true\n```\n# 博客文章加密\n写新的文章时加入：\n```\npassword: xxxxx\nmessage: 输入密码的提示。\n```\n高级设置：\n```\npassword: xxxx\nabstract: here is something encrypted\nmessage: 请输入密码。\nwrong_pass_message: Oh, wrong password, please try again.\n```\n","source":"_posts/2024-05-28-how-to-encrypt.md","raw":"---\ntitle: hexo 如何给文章设密码\ncategories:\n  - web\ntags: \n  - web\n  - hexo\nabbrlink: 7c8ba603\ndate: 2024-05-28 14:15:34\n---\n有些文章写了，但不想要给别人看，那就设一个密码。\n<!-- less -->\n# 安装插件\n命令：\n```\nnpm install hexo-blog-encrypt\n```\n# 修改配置\n在本目录配置文件_config.yml加入：\n```\nencrypt:\n   enable: true\n```\n# 博客文章加密\n写新的文章时加入：\n```\npassword: xxxxx\nmessage: 输入密码的提示。\n```\n高级设置：\n```\npassword: xxxx\nabstract: here is something encrypted\nmessage: 请输入密码。\nwrong_pass_message: Oh, wrong password, please try again.\n```\n","slug":"how-to-encrypt","published":1,"updated":"2024-05-28T11:36:29.756Z","comments":1,"layout":"post","photos":[],"_id":"cmh498ipj006owvouagpj8aws","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><h1 id=\"安装插件\"><a href=\"#安装插件\" class=\"headerlink\" title=\"安装插件\"></a>安装插件</h1><p>命令：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">npm install hexo-blog-encrypt</span><br></pre></td></tr></table></figure>\n<h1 id=\"修改配置\"><a href=\"#修改配置\" class=\"headerlink\" title=\"修改配置\"></a>修改配置</h1><p>在本目录配置文件_config.yml加入：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">encrypt:</span><br><span class=\"line\">   enable: true</span><br></pre></td></tr></table></figure>\n<h1 id=\"博客文章加密\"><a href=\"#博客文章加密\" class=\"headerlink\" title=\"博客文章加密\"></a>博客文章加密</h1><p>写新的文章时加入：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">password: xxxxx</span><br><span class=\"line\">message: 输入密码的提示。</span><br></pre></td></tr></table></figure>\n<p>高级设置：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">password: xxxx</span><br><span class=\"line\">abstract: here is something encrypted</span><br><span class=\"line\">message: 请输入密码。</span><br><span class=\"line\">wrong_pass_message: Oh, wrong password, please try again.</span><br></pre></td></tr></table></figure>","related_posts":["add_counter.html","how-to-use-utterances.html","how-I-build-this-web.html","what-did-I-do-to-this-blog.html"],"length":273,"excerpt":"<p>有些文章写了，但不想要给别人看，那就设一个密码。</p>","more":"<h1 id=\"安装插件\"><a href=\"#安装插件\" class=\"headerlink\" title=\"安装插件\"></a>安装插件</h1><p>命令：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">npm install hexo-blog-encrypt</span><br></pre></td></tr></table></figure>\n<h1 id=\"修改配置\"><a href=\"#修改配置\" class=\"headerlink\" title=\"修改配置\"></a>修改配置</h1><p>在本目录配置文件_config.yml加入：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">encrypt:</span><br><span class=\"line\">   enable: true</span><br></pre></td></tr></table></figure>\n<h1 id=\"博客文章加密\"><a href=\"#博客文章加密\" class=\"headerlink\" title=\"博客文章加密\"></a>博客文章加密</h1><p>写新的文章时加入：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">password: xxxxx</span><br><span class=\"line\">message: 输入密码的提示。</span><br></pre></td></tr></table></figure>\n<p>高级设置：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">password: xxxx</span><br><span class=\"line\">abstract: here is something encrypted</span><br><span class=\"line\">message: 请输入密码。</span><br><span class=\"line\">wrong_pass_message: Oh, wrong password, please try again.</span><br></pre></td></tr></table></figure>"},{"title":"如何学习","abbrlink":"666d8748","date":"2024-05-28T05:06:34.000Z","_content":"转自[可能吧](https://kenengba.com/post/3721.html)\n可能吧讲的是如何让人觉得你都懂，感觉有点文不对题。内容更偏向于如何学习。其实学习方法很多，但重在实践。\n<!-- less -->\n# 放过自己\n知识进入大脑分为以下几种：\n1. 听过：有点印象\n2. 知道：对每一个环节比较熟悉，能回答相关问题\n3. 得到：你可以教别人\n4. 用到：抽象出规律，在生活中使用\n\n大多数情况、大多数东西都只在第一层，然而我们却想234。这是不现实的，强求也会痛苦。\n其实没有必要。我们没有必要知道所有事情。没必要也指在阅读和学习时没有必要强迫自己读完学完。同时也意味着你没必要把朋友圈、订阅号等等的文章全部看完。少知道一些东西你并不会损失什么。把这些时间留给234。\n\n# 在二手知识上做探索\n我们是站在巨人肩上生活的，或者至少也是站在强人身上。我们在“放过自己”以后就会去探索自己喜欢的事情了。那怎么办？去“请教”，去检索，例如google，wiki。通过一层层探索，我们就能把一个知识从“听过”变成知道。然后才有可能变成“得到”。然而还不够。\n\n# 梳理才能得到\n只探索，不梳理并没有“得到”。需要思考、总结，总结出一些规律。整理是学习过程最重要的一环。整理因果，然后自己写出摘要，才是”得到“。\n\n# 说出来\n一个知识点牵涉的点非常之多，我们难以全部掌握。如何知道自己的不足？两个方法：\n1. 给别人讲一遍\n2. 写一篇公众号\n\n获得了一些知识再讲给别人会获得成就和虚荣，另一方面能快速找到自己的知识漏洞。在给别人讲述过程，如果对方好奇就一定会问一些细节。对于你不懂的一般会被问到，或者至少你在讲的时候会心虚。这是很好的去完善自己的机会。不懂的记下来，然后再去检索，梳理。写公众号也是如此。\n\n# 不做笔记可能因为焦虑\n学习有时有点反人性，一般要克服懒惰。然而懒惰有时就是“放过自己”，特别是对于没有必要的事情。学习应该是一件好奇心驱使的事情，把精力放在自己好奇的事情上努力探索才能得到知识。\n","source":"_posts/2024-05-28-how-to-pretend-you-know.md","raw":"---\ntitle: 如何学习 \ncategories:\n  - 学习\ntags:\n  - 学习\nabbrlink: 666d8748\ndate: 2024-05-28 13:06:34\n---\n转自[可能吧](https://kenengba.com/post/3721.html)\n可能吧讲的是如何让人觉得你都懂，感觉有点文不对题。内容更偏向于如何学习。其实学习方法很多，但重在实践。\n<!-- less -->\n# 放过自己\n知识进入大脑分为以下几种：\n1. 听过：有点印象\n2. 知道：对每一个环节比较熟悉，能回答相关问题\n3. 得到：你可以教别人\n4. 用到：抽象出规律，在生活中使用\n\n大多数情况、大多数东西都只在第一层，然而我们却想234。这是不现实的，强求也会痛苦。\n其实没有必要。我们没有必要知道所有事情。没必要也指在阅读和学习时没有必要强迫自己读完学完。同时也意味着你没必要把朋友圈、订阅号等等的文章全部看完。少知道一些东西你并不会损失什么。把这些时间留给234。\n\n# 在二手知识上做探索\n我们是站在巨人肩上生活的，或者至少也是站在强人身上。我们在“放过自己”以后就会去探索自己喜欢的事情了。那怎么办？去“请教”，去检索，例如google，wiki。通过一层层探索，我们就能把一个知识从“听过”变成知道。然后才有可能变成“得到”。然而还不够。\n\n# 梳理才能得到\n只探索，不梳理并没有“得到”。需要思考、总结，总结出一些规律。整理是学习过程最重要的一环。整理因果，然后自己写出摘要，才是”得到“。\n\n# 说出来\n一个知识点牵涉的点非常之多，我们难以全部掌握。如何知道自己的不足？两个方法：\n1. 给别人讲一遍\n2. 写一篇公众号\n\n获得了一些知识再讲给别人会获得成就和虚荣，另一方面能快速找到自己的知识漏洞。在给别人讲述过程，如果对方好奇就一定会问一些细节。对于你不懂的一般会被问到，或者至少你在讲的时候会心虚。这是很好的去完善自己的机会。不懂的记下来，然后再去检索，梳理。写公众号也是如此。\n\n# 不做笔记可能因为焦虑\n学习有时有点反人性，一般要克服懒惰。然而懒惰有时就是“放过自己”，特别是对于没有必要的事情。学习应该是一件好奇心驱使的事情，把精力放在自己好奇的事情上努力探索才能得到知识。\n","slug":"how-to-pretend-you-know","published":1,"updated":"2024-05-28T11:35:46.552Z","comments":1,"layout":"post","photos":[],"_id":"cmh498ipk006rwvouflovbzzx","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><h1 id=\"放过自己\"><a href=\"#放过自己\" class=\"headerlink\" title=\"放过自己\"></a>放过自己</h1><p>知识进入大脑分为以下几种：</p>\n<ol>\n<li>听过：有点印象</li>\n<li>知道：对每一个环节比较熟悉，能回答相关问题</li>\n<li>得到：你可以教别人</li>\n<li>用到：抽象出规律，在生活中使用</li>\n</ol>\n<p>大多数情况、大多数东西都只在第一层，然而我们却想234。这是不现实的，强求也会痛苦。<br>其实没有必要。我们没有必要知道所有事情。没必要也指在阅读和学习时没有必要强迫自己读完学完。同时也意味着你没必要把朋友圈、订阅号等等的文章全部看完。少知道一些东西你并不会损失什么。把这些时间留给234。</p>\n<h1 id=\"在二手知识上做探索\"><a href=\"#在二手知识上做探索\" class=\"headerlink\" title=\"在二手知识上做探索\"></a>在二手知识上做探索</h1><p>我们是站在巨人肩上生活的，或者至少也是站在强人身上。我们在“放过自己”以后就会去探索自己喜欢的事情了。那怎么办？去“请教”，去检索，例如google，wiki。通过一层层探索，我们就能把一个知识从“听过”变成知道。然后才有可能变成“得到”。然而还不够。</p>\n<h1 id=\"梳理才能得到\"><a href=\"#梳理才能得到\" class=\"headerlink\" title=\"梳理才能得到\"></a>梳理才能得到</h1><p>只探索，不梳理并没有“得到”。需要思考、总结，总结出一些规律。整理是学习过程最重要的一环。整理因果，然后自己写出摘要，才是”得到“。</p>\n<h1 id=\"说出来\"><a href=\"#说出来\" class=\"headerlink\" title=\"说出来\"></a>说出来</h1><p>一个知识点牵涉的点非常之多，我们难以全部掌握。如何知道自己的不足？两个方法：</p>\n<ol>\n<li>给别人讲一遍</li>\n<li>写一篇公众号</li>\n</ol>\n<p>获得了一些知识再讲给别人会获得成就和虚荣，另一方面能快速找到自己的知识漏洞。在给别人讲述过程，如果对方好奇就一定会问一些细节。对于你不懂的一般会被问到，或者至少你在讲的时候会心虚。这是很好的去完善自己的机会。不懂的记下来，然后再去检索，梳理。写公众号也是如此。</p>\n<h1 id=\"不做笔记可能因为焦虑\"><a href=\"#不做笔记可能因为焦虑\" class=\"headerlink\" title=\"不做笔记可能因为焦虑\"></a>不做笔记可能因为焦虑</h1><p>学习有时有点反人性，一般要克服懒惰。然而懒惰有时就是“放过自己”，特别是对于没有必要的事情。学习应该是一件好奇心驱使的事情，把精力放在自己好奇的事情上努力探索才能得到知识。</p>","related_posts":[],"length":753,"excerpt":"<p>转自<a href=\"https://kenengba.com/post/3721.html\">可能吧</a><br>可能吧讲的是如何让人觉得你都懂，感觉有点文不对题。内容更偏向于如何学习。其实学习方法很多，但重在实践。</p>","more":"<h1 id=\"放过自己\"><a href=\"#放过自己\" class=\"headerlink\" title=\"放过自己\"></a>放过自己</h1><p>知识进入大脑分为以下几种：</p>\n<ol>\n<li>听过：有点印象</li>\n<li>知道：对每一个环节比较熟悉，能回答相关问题</li>\n<li>得到：你可以教别人</li>\n<li>用到：抽象出规律，在生活中使用</li>\n</ol>\n<p>大多数情况、大多数东西都只在第一层，然而我们却想234。这是不现实的，强求也会痛苦。<br>其实没有必要。我们没有必要知道所有事情。没必要也指在阅读和学习时没有必要强迫自己读完学完。同时也意味着你没必要把朋友圈、订阅号等等的文章全部看完。少知道一些东西你并不会损失什么。把这些时间留给234。</p>\n<h1 id=\"在二手知识上做探索\"><a href=\"#在二手知识上做探索\" class=\"headerlink\" title=\"在二手知识上做探索\"></a>在二手知识上做探索</h1><p>我们是站在巨人肩上生活的，或者至少也是站在强人身上。我们在“放过自己”以后就会去探索自己喜欢的事情了。那怎么办？去“请教”，去检索，例如google，wiki。通过一层层探索，我们就能把一个知识从“听过”变成知道。然后才有可能变成“得到”。然而还不够。</p>\n<h1 id=\"梳理才能得到\"><a href=\"#梳理才能得到\" class=\"headerlink\" title=\"梳理才能得到\"></a>梳理才能得到</h1><p>只探索，不梳理并没有“得到”。需要思考、总结，总结出一些规律。整理是学习过程最重要的一环。整理因果，然后自己写出摘要，才是”得到“。</p>\n<h1 id=\"说出来\"><a href=\"#说出来\" class=\"headerlink\" title=\"说出来\"></a>说出来</h1><p>一个知识点牵涉的点非常之多，我们难以全部掌握。如何知道自己的不足？两个方法：</p>\n<ol>\n<li>给别人讲一遍</li>\n<li>写一篇公众号</li>\n</ol>\n<p>获得了一些知识再讲给别人会获得成就和虚荣，另一方面能快速找到自己的知识漏洞。在给别人讲述过程，如果对方好奇就一定会问一些细节。对于你不懂的一般会被问到，或者至少你在讲的时候会心虚。这是很好的去完善自己的机会。不懂的记下来，然后再去检索，梳理。写公众号也是如此。</p>\n<h1 id=\"不做笔记可能因为焦虑\"><a href=\"#不做笔记可能因为焦虑\" class=\"headerlink\" title=\"不做笔记可能因为焦虑\"></a>不做笔记可能因为焦虑</h1><p>学习有时有点反人性，一般要克服懒惰。然而懒惰有时就是“放过自己”，特别是对于没有必要的事情。学习应该是一件好奇心驱使的事情，把精力放在自己好奇的事情上努力探索才能得到知识。</p>"},{"title":"Hexo next 使用utterances评论","abbrlink":"8d4b165c","date":"2024-05-28T11:25:39.000Z","_content":"之前next里用的是valine评论区，谁知这次怎么弄都配置不上，搜索之下发现新版next已经不支持valine了。好像是因为其安全问题。因此我准备用utterances。\n<!--less-->\n根据官网介绍步骤如下：\n1. 在github中新建一个仓库，例如较utt_comment.\n2. 点击https://github.com/apps/utterances安装Github App 关联的仓库要选刚刚建立的那个，例如：utt_comment.\n3. 在主题配置文件_config.yml中设置：\n```\n# Utterances\n# For more information: https://utteranc.es\nutterances:\n  enable: true\n  repo: your-name/your-repo # Github repository owner and name\n  # Available values: pathname | url | title | og:title\n  issue_term: pathname\n  # Available values: github-light | github-dark | preferred-color-scheme | github-dark-orange | icy-dark | dark-blue | photon-dark | boxy-light\n  theme: github-light\n```\n","source":"_posts/2024-05-28-how-to-use-utterances.md","raw":"---\ntitle: Hexo next 使用utterances评论\ncategories:\n  - web\ntags:\n  - web\n  - hexo\nabbrlink: 8d4b165c\ndate: 2024-05-28 19:25:39\n---\n之前next里用的是valine评论区，谁知这次怎么弄都配置不上，搜索之下发现新版next已经不支持valine了。好像是因为其安全问题。因此我准备用utterances。\n<!--less-->\n根据官网介绍步骤如下：\n1. 在github中新建一个仓库，例如较utt_comment.\n2. 点击https://github.com/apps/utterances安装Github App 关联的仓库要选刚刚建立的那个，例如：utt_comment.\n3. 在主题配置文件_config.yml中设置：\n```\n# Utterances\n# For more information: https://utteranc.es\nutterances:\n  enable: true\n  repo: your-name/your-repo # Github repository owner and name\n  # Available values: pathname | url | title | og:title\n  issue_term: pathname\n  # Available values: github-light | github-dark | preferred-color-scheme | github-dark-orange | icy-dark | dark-blue | photon-dark | boxy-light\n  theme: github-light\n```\n","slug":"how-to-use-utterances","published":1,"updated":"2024-05-28T11:35:02.796Z","comments":1,"layout":"post","photos":[],"_id":"cmh498ipk006twvou3qbr62hf","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>根据官网介绍步骤如下：</p>\n<ol>\n<li>在github中新建一个仓库，例如较utt_comment.</li>\n<li>点击<a href=\"https://github.com/apps/utterances%E5%AE%89%E8%A3%85Github\">https://github.com/apps/utterances安装Github</a> App 关联的仓库要选刚刚建立的那个，例如：utt_comment.</li>\n<li>在主题配置文件_config.yml中设置：<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># Utterances</span><br><span class=\"line\"># For more information: https://utteranc.es</span><br><span class=\"line\">utterances:</span><br><span class=\"line\">  enable: true</span><br><span class=\"line\">  repo: your-name/your-repo # Github repository owner and name</span><br><span class=\"line\">  # Available values: pathname | url | title | og:title</span><br><span class=\"line\">  issue_term: pathname</span><br><span class=\"line\">  # Available values: github-light | github-dark | preferred-color-scheme | github-dark-orange | icy-dark | dark-blue | photon-dark | boxy-light</span><br><span class=\"line\">  theme: github-light</span><br></pre></td></tr></table></figure></li>\n</ol>","related_posts":["add_counter.html","how-to-encrypt.html","how-I-build-this-web.html","what-did-I-do-to-this-blog.html"],"length":566,"excerpt":"<p>之前next里用的是valine评论区，谁知这次怎么弄都配置不上，搜索之下发现新版next已经不支持valine了。好像是因为其安全问题。因此我准备用utterances。</p>","more":"<p>根据官网介绍步骤如下：</p>\n<ol>\n<li>在github中新建一个仓库，例如较utt_comment.</li>\n<li>点击<a href=\"https://github.com/apps/utterances%E5%AE%89%E8%A3%85Github\">https://github.com/apps/utterances安装Github</a> App 关联的仓库要选刚刚建立的那个，例如：utt_comment.</li>\n<li>在主题配置文件_config.yml中设置：<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># Utterances</span><br><span class=\"line\"># For more information: https://utteranc.es</span><br><span class=\"line\">utterances:</span><br><span class=\"line\">  enable: true</span><br><span class=\"line\">  repo: your-name/your-repo # Github repository owner and name</span><br><span class=\"line\">  # Available values: pathname | url | title | og:title</span><br><span class=\"line\">  issue_term: pathname</span><br><span class=\"line\">  # Available values: github-light | github-dark | preferred-color-scheme | github-dark-orange | icy-dark | dark-blue | photon-dark | boxy-light</span><br><span class=\"line\">  theme: github-light</span><br></pre></td></tr></table></figure></li>\n</ol>"},{"title":"todesk的安装","abbrlink":"8b4e2642","date":"2024-05-29T13:32:47.000Z","_content":"&emsp;&emsp;远程登陆服务器进行工作是牛马必备技能。之前用的是teamviewer，老是掉线。从学生那里知道todesk还不错。于是就安装之。\n<!--less-->\n&emsp;&emsp;先从todesk[主页](https://www.todesk.com/linux.html)下载适合的Linux版本。然后用命令：\n\n```bash\nsudo dnf rpm Uvh todesk-v4.7.2.0-x86_64.rpm\n```\n&emsp;&emsp;此外还得安装一个库\n```\nsudo dnf install libappindicator-gtk3\n```\n&emsp;&emsp;然后运行todesk，结果显示“error while loading shared libraries: libappindicator3.so.1: cannot open shared object file: No such file or directory“,明明已经安装了。很奇怪。\n&emsp;&emsp;然后\n```\nfind / -name libappindicator3.so.1\n```\n&emsp;&emsp;找到在/usr/lib下。\n&emsp;&emsp;然后在.bashrc中加入\n```\nexport LD_LIBRARY_PATH:${LD_LIBRARY_PATH}:/usr/lib/\nsource ~/.bashrc\n```\n&emsp;&emsp;然后再运行todesk。结果显示安装的是libappindicator安装的是32位的，不匹配。\n然后\n```\nsudo dnf search libappindicator\n```\n&emsp;&emsp;找到libappindicator-gtk3.x86_64，然后：\n```\nsudo dnf install libappindicator-gtk3.x86_64\n```\n&emsp;&emsp;然后就可以了。\n","source":"_posts/2024-05-29-to-desk.md","raw":"---\ntitle: todesk的安装\ncategories:\n  - Linux\ntags:\n  - linux\nabbrlink: 8b4e2642\ndate: 2024-05-29 21:32:47\n---\n&emsp;&emsp;远程登陆服务器进行工作是牛马必备技能。之前用的是teamviewer，老是掉线。从学生那里知道todesk还不错。于是就安装之。\n<!--less-->\n&emsp;&emsp;先从todesk[主页](https://www.todesk.com/linux.html)下载适合的Linux版本。然后用命令：\n\n```bash\nsudo dnf rpm Uvh todesk-v4.7.2.0-x86_64.rpm\n```\n&emsp;&emsp;此外还得安装一个库\n```\nsudo dnf install libappindicator-gtk3\n```\n&emsp;&emsp;然后运行todesk，结果显示“error while loading shared libraries: libappindicator3.so.1: cannot open shared object file: No such file or directory“,明明已经安装了。很奇怪。\n&emsp;&emsp;然后\n```\nfind / -name libappindicator3.so.1\n```\n&emsp;&emsp;找到在/usr/lib下。\n&emsp;&emsp;然后在.bashrc中加入\n```\nexport LD_LIBRARY_PATH:${LD_LIBRARY_PATH}:/usr/lib/\nsource ~/.bashrc\n```\n&emsp;&emsp;然后再运行todesk。结果显示安装的是libappindicator安装的是32位的，不匹配。\n然后\n```\nsudo dnf search libappindicator\n```\n&emsp;&emsp;找到libappindicator-gtk3.x86_64，然后：\n```\nsudo dnf install libappindicator-gtk3.x86_64\n```\n&emsp;&emsp;然后就可以了。\n","slug":"to-desk","published":1,"updated":"2024-06-14T14:23:13.230Z","comments":1,"layout":"post","photos":[],"_id":"cmh498ipk006xwvou9spx2yug","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>&emsp;&emsp;先从todesk<a href=\"https://www.todesk.com/linux.html\">主页</a>下载适合的Linux版本。然后用命令：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">sudo</span> dnf rpm Uvh todesk-v4.7.2.0-x86_64.rpm</span><br></pre></td></tr></table></figure>\n<p>&emsp;&emsp;此外还得安装一个库</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo dnf install libappindicator-gtk3</span><br></pre></td></tr></table></figure>\n<p>&emsp;&emsp;然后运行todesk，结果显示“error while loading shared libraries: libappindicator3.so.1: cannot open shared object file: No such file or directory“,明明已经安装了。很奇怪。<br>&emsp;&emsp;然后</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">find / -name libappindicator3.so.1</span><br></pre></td></tr></table></figure>\n<p>&emsp;&emsp;找到在&#x2F;usr&#x2F;lib下。<br>&emsp;&emsp;然后在.bashrc中加入</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">export LD_LIBRARY_PATH:$&#123;LD_LIBRARY_PATH&#125;:/usr/lib/</span><br><span class=\"line\">source ~/.bashrc</span><br></pre></td></tr></table></figure>\n<p>&emsp;&emsp;然后再运行todesk。结果显示安装的是libappindicator安装的是32位的，不匹配。<br>然后</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo dnf search libappindicator</span><br></pre></td></tr></table></figure>\n<p>&emsp;&emsp;找到libappindicator-gtk3.x86_64，然后：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo dnf install libappindicator-gtk3.x86_64</span><br></pre></td></tr></table></figure>\n<p>&emsp;&emsp;然后就可以了。</p>","related_posts":["no-file-found-in-LaTeX.html","how-to-configure-chinese-for-gmt.html","object-detection.html","fedora-install-freshress.html","efficient-shell-script.html"],"length":738,"excerpt":"<p>&emsp;&emsp;远程登陆服务器进行工作是牛马必备技能。之前用的是teamviewer，老是掉线。从学生那里知道todesk还不错。于是就安装之。</p>","more":"<p>&emsp;&emsp;先从todesk<a href=\"https://www.todesk.com/linux.html\">主页</a>下载适合的Linux版本。然后用命令：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">sudo</span> dnf rpm Uvh todesk-v4.7.2.0-x86_64.rpm</span><br></pre></td></tr></table></figure>\n<p>&emsp;&emsp;此外还得安装一个库</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo dnf install libappindicator-gtk3</span><br></pre></td></tr></table></figure>\n<p>&emsp;&emsp;然后运行todesk，结果显示“error while loading shared libraries: libappindicator3.so.1: cannot open shared object file: No such file or directory“,明明已经安装了。很奇怪。<br>&emsp;&emsp;然后</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">find / -name libappindicator3.so.1</span><br></pre></td></tr></table></figure>\n<p>&emsp;&emsp;找到在&#x2F;usr&#x2F;lib下。<br>&emsp;&emsp;然后在.bashrc中加入</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">export LD_LIBRARY_PATH:$&#123;LD_LIBRARY_PATH&#125;:/usr/lib/</span><br><span class=\"line\">source ~/.bashrc</span><br></pre></td></tr></table></figure>\n<p>&emsp;&emsp;然后再运行todesk。结果显示安装的是libappindicator安装的是32位的，不匹配。<br>然后</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo dnf search libappindicator</span><br></pre></td></tr></table></figure>\n<p>&emsp;&emsp;找到libappindicator-gtk3.x86_64，然后：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo dnf install libappindicator-gtk3.x86_64</span><br></pre></td></tr></table></figure>\n<p>&emsp;&emsp;然后就可以了。</p>"},{"title":"Fedora下如何登陆X11桌面","abbrlink":"1d2a45f5","date":"2024-05-31T12:25:18.000Z","_content":"&emsp;&emsp;安装了todesk以后进行远程控制时卡在“connecting to free server 100%”，然后不动。怎么办？\n<!--less-->\n&emsp;&emsp;目前还不知道怎么办，todesk官网说要用x11桌面，现在的fedora已经默认用Wayland了。如何开启X11呢？编辑文件/etc/gdm/custom.conf就好了：\n```\nWaylandEnable=false\nDefaultSession=gnome-xorg.desktop\n```\n&emsp;&emsp;然后重新登陆就发现Settings->about显示Windowing System X11了。\n&emsp;&emsp;不过靠不靠谱还不知道，还没有将remote station修改成X11。切换成X11以后bilibili视频似乎看不了了。连自己电脑中的mp4视频也播放不了。x11落后了？\n","source":"_posts/2024-05-31-how-to-set-X11-in-fedora.md","raw":"---\ntitle: Fedora下如何登陆X11桌面\ncategories:\n  - Linux\ntags:\n  - linux\nabbrlink: 1d2a45f5\ndate: 2024-05-31 20:25:18\n---\n&emsp;&emsp;安装了todesk以后进行远程控制时卡在“connecting to free server 100%”，然后不动。怎么办？\n<!--less-->\n&emsp;&emsp;目前还不知道怎么办，todesk官网说要用x11桌面，现在的fedora已经默认用Wayland了。如何开启X11呢？编辑文件/etc/gdm/custom.conf就好了：\n```\nWaylandEnable=false\nDefaultSession=gnome-xorg.desktop\n```\n&emsp;&emsp;然后重新登陆就发现Settings->about显示Windowing System X11了。\n&emsp;&emsp;不过靠不靠谱还不知道，还没有将remote station修改成X11。切换成X11以后bilibili视频似乎看不了了。连自己电脑中的mp4视频也播放不了。x11落后了？\n","slug":"how-to-set-X11-in-fedora","published":1,"updated":"2024-06-14T14:22:28.443Z","comments":1,"layout":"post","photos":[],"_id":"cmh498ipl0070wvou6tf3c26x","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>&emsp;&emsp;目前还不知道怎么办，todesk官网说要用x11桌面，现在的fedora已经默认用Wayland了。如何开启X11呢？编辑文件&#x2F;etc&#x2F;gdm&#x2F;custom.conf就好了：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">WaylandEnable=false</span><br><span class=\"line\">DefaultSession=gnome-xorg.desktop</span><br></pre></td></tr></table></figure>\n<p>&emsp;&emsp;然后重新登陆就发现Settings-&gt;about显示Windowing System X11了。<br>&emsp;&emsp;不过靠不靠谱还不知道，还没有将remote station修改成X11。切换成X11以后bilibili视频似乎看不了了。连自己电脑中的mp4视频也播放不了。x11落后了？</p>","related_posts":["install-elementary-os-again.html","install-and-backup-mediawiki.html","how-to-configure-chinese-for-gmt.html"],"length":396,"excerpt":"<p>&emsp;&emsp;安装了todesk以后进行远程控制时卡在“connecting to free server 100%”，然后不动。怎么办？</p>","more":"<p>&emsp;&emsp;目前还不知道怎么办，todesk官网说要用x11桌面，现在的fedora已经默认用Wayland了。如何开启X11呢？编辑文件&#x2F;etc&#x2F;gdm&#x2F;custom.conf就好了：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">WaylandEnable=false</span><br><span class=\"line\">DefaultSession=gnome-xorg.desktop</span><br></pre></td></tr></table></figure>\n<p>&emsp;&emsp;然后重新登陆就发现Settings-&gt;about显示Windowing System X11了。<br>&emsp;&emsp;不过靠不靠谱还不知道，还没有将remote station修改成X11。切换成X11以后bilibili视频似乎看不了了。连自己电脑中的mp4视频也播放不了。x11落后了？</p>"},{"title":"AI工具网址","abbrlink":"30de1038","date":"2024-06-03T09:58:55.000Z","_content":"一些ai工具网址，方便查找。\n<!--less-->\n## 大语言\n1. [Chatgpt](https://chat.openai.com/chat)\n2. [Kimi](https://kimi.moonshot.cn/)\n3. [txyz](https://app.txyz.ai/)\n4. [chatpdf](https://www.chatpdf.com/)\n5. [SCIspace](https://typeset.io/)\n6. [Humata](https://www.humata.ai/)\n7. [PandaGPT](https://www.pandagpt.io/)\n8. [Googlegemini](https://chat.googlegemini.co/)\n## 翻译与润色\n1. [deepl](https://www.deepl.com/translator/files)\n2. [grammarly](https://app.grammarly.com/)\n## 视频处理\n1. [biliGTP](https://b.jimmylv.cn/)\n## ppt\n1. [sankki](https://ppt.sankki.com/#/works)\n2. [tomai](https://beta.tome.app/)\n3. [chatppt](https://chat-ppt.com/)\n","source":"_posts/2024-06-03-ai-tools.md","raw":"---\ntitle: AI工具网址\ncategories:\n  - Tools\ntags:\n  - ai\nabbrlink: 30de1038\ndate: 2024-06-03 17:58:55\n---\n一些ai工具网址，方便查找。\n<!--less-->\n## 大语言\n1. [Chatgpt](https://chat.openai.com/chat)\n2. [Kimi](https://kimi.moonshot.cn/)\n3. [txyz](https://app.txyz.ai/)\n4. [chatpdf](https://www.chatpdf.com/)\n5. [SCIspace](https://typeset.io/)\n6. [Humata](https://www.humata.ai/)\n7. [PandaGPT](https://www.pandagpt.io/)\n8. [Googlegemini](https://chat.googlegemini.co/)\n## 翻译与润色\n1. [deepl](https://www.deepl.com/translator/files)\n2. [grammarly](https://app.grammarly.com/)\n## 视频处理\n1. [biliGTP](https://b.jimmylv.cn/)\n## ppt\n1. [sankki](https://ppt.sankki.com/#/works)\n2. [tomai](https://beta.tome.app/)\n3. [chatppt](https://chat-ppt.com/)\n","slug":"ai-tools","published":1,"updated":"2024-06-03T10:15:42.880Z","comments":1,"layout":"post","photos":[],"_id":"cmh498ipl0073wvou8ilu4132","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><h2 id=\"大语言\"><a href=\"#大语言\" class=\"headerlink\" title=\"大语言\"></a>大语言</h2><ol>\n<li><a href=\"https://chat.openai.com/chat\">Chatgpt</a></li>\n<li><a href=\"https://kimi.moonshot.cn/\">Kimi</a></li>\n<li><a href=\"https://app.txyz.ai/\">txyz</a></li>\n<li><a href=\"https://www.chatpdf.com/\">chatpdf</a></li>\n<li><a href=\"https://typeset.io/\">SCIspace</a></li>\n<li><a href=\"https://www.humata.ai/\">Humata</a></li>\n<li><a href=\"https://www.pandagpt.io/\">PandaGPT</a></li>\n<li><a href=\"https://chat.googlegemini.co/\">Googlegemini</a></li>\n</ol>\n<h2 id=\"翻译与润色\"><a href=\"#翻译与润色\" class=\"headerlink\" title=\"翻译与润色\"></a>翻译与润色</h2><ol>\n<li><a href=\"https://www.deepl.com/translator/files\">deepl</a></li>\n<li><a href=\"https://app.grammarly.com/\">grammarly</a></li>\n</ol>\n<h2 id=\"视频处理\"><a href=\"#视频处理\" class=\"headerlink\" title=\"视频处理\"></a>视频处理</h2><ol>\n<li><a href=\"https://b.jimmylv.cn/\">biliGTP</a></li>\n</ol>\n<h2 id=\"ppt\"><a href=\"#ppt\" class=\"headerlink\" title=\"ppt\"></a>ppt</h2><ol>\n<li><a href=\"https://ppt.sankki.com/#/works\">sankki</a></li>\n<li><a href=\"https://beta.tome.app/\">tomai</a></li>\n<li><a href=\"https://chat-ppt.com/\">chatppt</a></li>\n</ol>","related_posts":[],"length":124,"excerpt":"<p>一些ai工具网址，方便查找。</p>","more":"<h2 id=\"大语言\"><a href=\"#大语言\" class=\"headerlink\" title=\"大语言\"></a>大语言</h2><ol>\n<li><a href=\"https://chat.openai.com/chat\">Chatgpt</a></li>\n<li><a href=\"https://kimi.moonshot.cn/\">Kimi</a></li>\n<li><a href=\"https://app.txyz.ai/\">txyz</a></li>\n<li><a href=\"https://www.chatpdf.com/\">chatpdf</a></li>\n<li><a href=\"https://typeset.io/\">SCIspace</a></li>\n<li><a href=\"https://www.humata.ai/\">Humata</a></li>\n<li><a href=\"https://www.pandagpt.io/\">PandaGPT</a></li>\n<li><a href=\"https://chat.googlegemini.co/\">Googlegemini</a></li>\n</ol>\n<h2 id=\"翻译与润色\"><a href=\"#翻译与润色\" class=\"headerlink\" title=\"翻译与润色\"></a>翻译与润色</h2><ol>\n<li><a href=\"https://www.deepl.com/translator/files\">deepl</a></li>\n<li><a href=\"https://app.grammarly.com/\">grammarly</a></li>\n</ol>\n<h2 id=\"视频处理\"><a href=\"#视频处理\" class=\"headerlink\" title=\"视频处理\"></a>视频处理</h2><ol>\n<li><a href=\"https://b.jimmylv.cn/\">biliGTP</a></li>\n</ol>\n<h2 id=\"ppt\"><a href=\"#ppt\" class=\"headerlink\" title=\"ppt\"></a>ppt</h2><ol>\n<li><a href=\"https://ppt.sankki.com/#/works\">sankki</a></li>\n<li><a href=\"https://beta.tome.app/\">tomai</a></li>\n<li><a href=\"https://chat-ppt.com/\">chatppt</a></li>\n</ol>"},{"title":"Fedora下没有音量控制了","abbrlink":"d79b32e9","date":"2024-06-06T01:00:12.000Z","_content":"之前安装todesk没有搞定，总是连不上，于是又把它卸载了。卸载的时候把pulseaudio.x86_64也给卸载了。然后发现没有音量控制条了。然后又给安装回来\n```\nsudo dnf install pulseaudio\n```\n结果mplayer也出问题了。播放视频的时候卡住，其中一个问题是：\n```\ndo_connect: could not connect to socket\n```\n于是在~/.mplayer/config中加入：\n```\nlirc=no\n```\n然后还是播放不了，出现问题：\n```\nMPlayer SVN-r38423-13 (C) 2000-2023 MPlayer Team\n\nPlaying let_it_go_original.mp4.\nlibavformat version 58.76.100 (external)\nlibavformat file format detected.\n[mov,mp4,m4a,3gp,3g2,mj2 @ 0x7f6043a46660]Protocol name not provided, cannot determine if input is local or a network protocol, buffers and access patterns cannot be configured optimally without knowing the protocol\n[lavf] stream 0: video (h264), -vid 0\n[lavf] stream 1: audio (aac), -aid 0, -alang und\nVIDEO:  [H264]  1280x720  24bpp  24.000 fps  1593.8 kbps (194.5 kbyte/s)\nX11 error: BadMatch (invalid parameter attributes)\nFailed to open VDPAU backend libvdpau_nvidia.so: cannot open shared object file: No such file or directory\n[vdpau] Error when calling vdp_device_create_x11: 1\n\n```\n然后目前还没搞定。不知哪位大神能帮忙啊。\n","source":"_posts/2024-06-06-no-audio-control.md","raw":"---\ntitle: Fedora下没有音量控制了\ncategories:\n  - Linux\ntags:\n  - linux\nabbrlink: d79b32e9\ndate: 2024-06-06 09:00:12\n---\n之前安装todesk没有搞定，总是连不上，于是又把它卸载了。卸载的时候把pulseaudio.x86_64也给卸载了。然后发现没有音量控制条了。然后又给安装回来\n```\nsudo dnf install pulseaudio\n```\n结果mplayer也出问题了。播放视频的时候卡住，其中一个问题是：\n```\ndo_connect: could not connect to socket\n```\n于是在~/.mplayer/config中加入：\n```\nlirc=no\n```\n然后还是播放不了，出现问题：\n```\nMPlayer SVN-r38423-13 (C) 2000-2023 MPlayer Team\n\nPlaying let_it_go_original.mp4.\nlibavformat version 58.76.100 (external)\nlibavformat file format detected.\n[mov,mp4,m4a,3gp,3g2,mj2 @ 0x7f6043a46660]Protocol name not provided, cannot determine if input is local or a network protocol, buffers and access patterns cannot be configured optimally without knowing the protocol\n[lavf] stream 0: video (h264), -vid 0\n[lavf] stream 1: audio (aac), -aid 0, -alang und\nVIDEO:  [H264]  1280x720  24bpp  24.000 fps  1593.8 kbps (194.5 kbyte/s)\nX11 error: BadMatch (invalid parameter attributes)\nFailed to open VDPAU backend libvdpau_nvidia.so: cannot open shared object file: No such file or directory\n[vdpau] Error when calling vdp_device_create_x11: 1\n\n```\n然后目前还没搞定。不知哪位大神能帮忙啊。\n","slug":"no-audio-control","published":1,"updated":"2024-06-06T01:43:13.742Z","comments":1,"layout":"post","photos":[],"_id":"cmh498ipm0076wvouhehmdye5","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>之前安装todesk没有搞定，总是连不上，于是又把它卸载了。卸载的时候把pulseaudio.x86_64也给卸载了。然后发现没有音量控制条了。然后又给安装回来</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo dnf install pulseaudio</span><br></pre></td></tr></table></figure>\n<p>结果mplayer也出问题了。播放视频的时候卡住，其中一个问题是：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">do_connect: could not connect to socket</span><br></pre></td></tr></table></figure>\n<p>于是在~&#x2F;.mplayer&#x2F;config中加入：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">lirc=no</span><br></pre></td></tr></table></figure>\n<p>然后还是播放不了，出现问题：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">MPlayer SVN-r38423-13 (C) 2000-2023 MPlayer Team</span><br><span class=\"line\"></span><br><span class=\"line\">Playing let_it_go_original.mp4.</span><br><span class=\"line\">libavformat version 58.76.100 (external)</span><br><span class=\"line\">libavformat file format detected.</span><br><span class=\"line\">[mov,mp4,m4a,3gp,3g2,mj2 @ 0x7f6043a46660]Protocol name not provided, cannot determine if input is local or a network protocol, buffers and access patterns cannot be configured optimally without knowing the protocol</span><br><span class=\"line\">[lavf] stream 0: video (h264), -vid 0</span><br><span class=\"line\">[lavf] stream 1: audio (aac), -aid 0, -alang und</span><br><span class=\"line\">VIDEO:  [H264]  1280x720  24bpp  24.000 fps  1593.8 kbps (194.5 kbyte/s)</span><br><span class=\"line\">X11 error: BadMatch (invalid parameter attributes)</span><br><span class=\"line\">Failed to open VDPAU backend libvdpau_nvidia.so: cannot open shared object file: No such file or directory</span><br><span class=\"line\">[vdpau] Error when calling vdp_device_create_x11: 1</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<p>然后目前还没搞定。不知哪位大神能帮忙啊。</p>\n","related_posts":[],"length":905,"excerpt":"","more":"<p>之前安装todesk没有搞定，总是连不上，于是又把它卸载了。卸载的时候把pulseaudio.x86_64也给卸载了。然后发现没有音量控制条了。然后又给安装回来</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo dnf install pulseaudio</span><br></pre></td></tr></table></figure>\n<p>结果mplayer也出问题了。播放视频的时候卡住，其中一个问题是：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">do_connect: could not connect to socket</span><br></pre></td></tr></table></figure>\n<p>于是在~&#x2F;.mplayer&#x2F;config中加入：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">lirc=no</span><br></pre></td></tr></table></figure>\n<p>然后还是播放不了，出现问题：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">MPlayer SVN-r38423-13 (C) 2000-2023 MPlayer Team</span><br><span class=\"line\"></span><br><span class=\"line\">Playing let_it_go_original.mp4.</span><br><span class=\"line\">libavformat version 58.76.100 (external)</span><br><span class=\"line\">libavformat file format detected.</span><br><span class=\"line\">[mov,mp4,m4a,3gp,3g2,mj2 @ 0x7f6043a46660]Protocol name not provided, cannot determine if input is local or a network protocol, buffers and access patterns cannot be configured optimally without knowing the protocol</span><br><span class=\"line\">[lavf] stream 0: video (h264), -vid 0</span><br><span class=\"line\">[lavf] stream 1: audio (aac), -aid 0, -alang und</span><br><span class=\"line\">VIDEO:  [H264]  1280x720  24bpp  24.000 fps  1593.8 kbps (194.5 kbyte/s)</span><br><span class=\"line\">X11 error: BadMatch (invalid parameter attributes)</span><br><span class=\"line\">Failed to open VDPAU backend libvdpau_nvidia.so: cannot open shared object file: No such file or directory</span><br><span class=\"line\">[vdpau] Error when calling vdp_device_create_x11: 1</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<p>然后目前还没搞定。不知哪位大神能帮忙啊。</p>\n"},{"title":"Fedora下浏览器播放视频卡住没有声音","abbrlink":"4a2f0c3d","date":"2024-06-06T04:29:49.000Z","_content":"之前整了nodesk之后就出现了视频播放的问题。用mplayer播放视频时，卡住。用浏览器播放视频的时候卡住，关掉音频之后视频正常播放了。但是没有声音。\n然后\n```\nsystemctl --user stop wireplumber\n```\n关掉了wireplumber以后mplayer和浏览器上都能正常播放了。但每次重启都得运行一次。多麻烦呀。\n然后\n```\nsudo dnf install --allowerasing pipewire-pulseaudio\n```\n就可以了。\n","source":"_posts/2024-06-06-no-audio-in-playing-browser-video.md","raw":"---\ntitle: Fedora下浏览器播放视频卡住没有声音\ncategories:\n  - Linux\ntags:\n  - linux\nabbrlink: 4a2f0c3d\ndate: 2024-06-06 12:29:49\n---\n之前整了nodesk之后就出现了视频播放的问题。用mplayer播放视频时，卡住。用浏览器播放视频的时候卡住，关掉音频之后视频正常播放了。但是没有声音。\n然后\n```\nsystemctl --user stop wireplumber\n```\n关掉了wireplumber以后mplayer和浏览器上都能正常播放了。但每次重启都得运行一次。多麻烦呀。\n然后\n```\nsudo dnf install --allowerasing pipewire-pulseaudio\n```\n就可以了。\n","slug":"no-audio-in-playing-browser-video","published":1,"updated":"2024-06-06T04:48:14.737Z","comments":1,"layout":"post","photos":[],"_id":"cmh498ipm0079wvougo3u3goc","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>之前整了nodesk之后就出现了视频播放的问题。用mplayer播放视频时，卡住。用浏览器播放视频的时候卡住，关掉音频之后视频正常播放了。但是没有声音。<br>然后</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">systemctl --user stop wireplumber</span><br></pre></td></tr></table></figure>\n<p>关掉了wireplumber以后mplayer和浏览器上都能正常播放了。但每次重启都得运行一次。多麻烦呀。<br>然后</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo dnf install --allowerasing pipewire-pulseaudio</span><br></pre></td></tr></table></figure>\n<p>就可以了。</p>\n","related_posts":[],"length":217,"excerpt":"","more":"<p>之前整了nodesk之后就出现了视频播放的问题。用mplayer播放视频时，卡住。用浏览器播放视频的时候卡住，关掉音频之后视频正常播放了。但是没有声音。<br>然后</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">systemctl --user stop wireplumber</span><br></pre></td></tr></table></figure>\n<p>关掉了wireplumber以后mplayer和浏览器上都能正常播放了。但每次重启都得运行一次。多麻烦呀。<br>然后</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo dnf install --allowerasing pipewire-pulseaudio</span><br></pre></td></tr></table></figure>\n<p>就可以了。</p>\n"},{"title":"运行LaTeX 遇到 ! LaTeX Error: File `xxx` not found.","abbrlink":"6cb6ca71","date":"2024-06-06T02:26:10.000Z","_content":"运行LaTeX的时候遇到! LaTeX Error: File `xxx' not found.这个错误的时候该怎么办？\n<!--less-->\n这样就可以了\n```\nsudo dnf install 'tex(xxx)'\n```\n然后就会帮你安装缺失的文件。\n","source":"_posts/2024-06-06-no-file-found-in-LaTeX.md","raw":"---\ntitle: '运行LaTeX 遇到 ! LaTeX Error: File `xxx` not found.'\ncategories:\n  - Linux\ntags:\n  - laTeX\nabbrlink: 6cb6ca71\ndate: 2024-06-06 10:26:10\n---\n运行LaTeX的时候遇到! LaTeX Error: File `xxx' not found.这个错误的时候该怎么办？\n<!--less-->\n这样就可以了\n```\nsudo dnf install 'tex(xxx)'\n```\n然后就会帮你安装缺失的文件。\n","slug":"no-file-found-in-LaTeX","published":1,"updated":"2024-06-06T02:31:17.929Z","comments":1,"layout":"post","photos":[],"_id":"cmh498ipn007cwvou4gjng4ag","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>这样就可以了</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo dnf install &#x27;tex(xxx)&#x27;</span><br></pre></td></tr></table></figure>\n<p>然后就会帮你安装缺失的文件。</p>","related_posts":["read-file-bash.html","latex-math-express.html","efficient-shell-script.html","to-desk.html","install-and-backup-mediawiki.html"],"length":113,"excerpt":"<p>运行LaTeX的时候遇到! LaTeX Error: File &#96;xxx’ not found.这个错误的时候该怎么办？</p>","more":"<p>这样就可以了</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo dnf install &#x27;tex(xxx)&#x27;</span><br></pre></td></tr></table></figure>\n<p>然后就会帮你安装缺失的文件。</p>"},{"title":"纪念BLUE","abbrlink":"3bb79851","date":"2024-06-11T01:09:06.000Z","_content":"&emsp;&emsp;BLUE过世了。\n<!--less-->\n&emsp;&emsp;BLUE是在端午节过世的，或许更早，因为回到家只看到她的尸体。BLUE是我们在疫情解封后邂逅的，我们把她请回家，做了我们家一员。很抱歉没有给她配备好的住宿条件。让她在房间里可以自由的跑，只在进食的时候放在脸盆里。我不知道她挑不挑食。曾经在脸盆里投喂了白菜，她没吃。她很喜欢鱼饲料。每次投喂都大块朵颐。身材也是看得见的长大。一开始BLUE很害羞，只要我们一靠近她就立马缩回去，可能是还不熟络。她经常在屋子里摸索，大约所有地方她都造访过，很多时候还担当了扫帚的职责，常常跑出来以后裹了一身的棉絮。常常我们也不知道她在哪个角落，只听她哆哆哆的脚步声，便知道她还在探索。\n\n&emsp;&emsp;天冷起来，她是要睡很长时间的。我买了个冬眠盒子。把她放在里面，她迫不及待地钻了进去。开始还有些动静，天冷一些就安静了。只能从盒子上的水汽知道她还在。她熬过了四个冬天，她总能在天暖和的时候醒来。加上把她带回家那一次，她一共搬了三次家。\n\n&emsp;&emsp;有时我们在工作，她跑到客厅，瞅一瞅我们，大概在不懈的嘲笑，然后就继续她的探索；有时我们在床上休息，她在房间里哆哆哆，大概在取笑我们还在赖床。\n后来我们碰到了更小只的purple男孩，把他带回来给BLUE做朋友。不知道他们相不相熟。有一次我们外出旅行了一周，他们两个一起躲到了厕所阴凉地方，靠在一块报团取暖。\n到了冬天把他们一起放在了冬眠盒子。各自安好。谁知天热起来把他们放出来，BLUE的眼睛是浮肿的，也茶饭不思。我买了眼药给他治竟也无好转。随后又多次买药。\n\n&emsp;&emsp;老婆说自己不太会养宠物，以前家里养过鸟，鱼，狗。他们去世时自己会十分悲痛，像失去了亲人一样不舍。我说对BLUE大可放心，因为到时候可能她会给我们送终。可是毕竟不能如愿。\n\n&emsp;&emsp;我和娃把BLUE埋在了路口。那里我们还埋葬了一只小鸟和一只仓鼠。娃似乎比以前坚强，麻雀和仓鼠过世的时候他哭得很伤心，而这次他很淡然。他说这宇宙所有东西所有东西都会死掉，都会消失的。不知道他是明白还是不明白。\n\n&emsp;&emsp;希望一切安好。我估计以后再也不养宠物。如果他成了你的宠物，你就是在掌控他的生死。\n","source":"_posts/2024-06-11-memorise-blue.md","raw":"---\ntitle: 纪念BLUE\ncategories:\n  - 某日记\ntags:\n  - 某日记\nabbrlink: 3bb79851\ndate: 2024-06-11 09:09:06\n---\n&emsp;&emsp;BLUE过世了。\n<!--less-->\n&emsp;&emsp;BLUE是在端午节过世的，或许更早，因为回到家只看到她的尸体。BLUE是我们在疫情解封后邂逅的，我们把她请回家，做了我们家一员。很抱歉没有给她配备好的住宿条件。让她在房间里可以自由的跑，只在进食的时候放在脸盆里。我不知道她挑不挑食。曾经在脸盆里投喂了白菜，她没吃。她很喜欢鱼饲料。每次投喂都大块朵颐。身材也是看得见的长大。一开始BLUE很害羞，只要我们一靠近她就立马缩回去，可能是还不熟络。她经常在屋子里摸索，大约所有地方她都造访过，很多时候还担当了扫帚的职责，常常跑出来以后裹了一身的棉絮。常常我们也不知道她在哪个角落，只听她哆哆哆的脚步声，便知道她还在探索。\n\n&emsp;&emsp;天冷起来，她是要睡很长时间的。我买了个冬眠盒子。把她放在里面，她迫不及待地钻了进去。开始还有些动静，天冷一些就安静了。只能从盒子上的水汽知道她还在。她熬过了四个冬天，她总能在天暖和的时候醒来。加上把她带回家那一次，她一共搬了三次家。\n\n&emsp;&emsp;有时我们在工作，她跑到客厅，瞅一瞅我们，大概在不懈的嘲笑，然后就继续她的探索；有时我们在床上休息，她在房间里哆哆哆，大概在取笑我们还在赖床。\n后来我们碰到了更小只的purple男孩，把他带回来给BLUE做朋友。不知道他们相不相熟。有一次我们外出旅行了一周，他们两个一起躲到了厕所阴凉地方，靠在一块报团取暖。\n到了冬天把他们一起放在了冬眠盒子。各自安好。谁知天热起来把他们放出来，BLUE的眼睛是浮肿的，也茶饭不思。我买了眼药给他治竟也无好转。随后又多次买药。\n\n&emsp;&emsp;老婆说自己不太会养宠物，以前家里养过鸟，鱼，狗。他们去世时自己会十分悲痛，像失去了亲人一样不舍。我说对BLUE大可放心，因为到时候可能她会给我们送终。可是毕竟不能如愿。\n\n&emsp;&emsp;我和娃把BLUE埋在了路口。那里我们还埋葬了一只小鸟和一只仓鼠。娃似乎比以前坚强，麻雀和仓鼠过世的时候他哭得很伤心，而这次他很淡然。他说这宇宙所有东西所有东西都会死掉，都会消失的。不知道他是明白还是不明白。\n\n&emsp;&emsp;希望一切安好。我估计以后再也不养宠物。如果他成了你的宠物，你就是在掌控他的生死。\n","slug":"memorise-blue","published":1,"updated":"2024-06-14T14:21:43.715Z","comments":1,"layout":"post","photos":[],"_id":"cmh498ipn007ewvou9x1g7htb","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>&emsp;&emsp;BLUE是在端午节过世的，或许更早，因为回到家只看到她的尸体。BLUE是我们在疫情解封后邂逅的，我们把她请回家，做了我们家一员。很抱歉没有给她配备好的住宿条件。让她在房间里可以自由的跑，只在进食的时候放在脸盆里。我不知道她挑不挑食。曾经在脸盆里投喂了白菜，她没吃。她很喜欢鱼饲料。每次投喂都大块朵颐。身材也是看得见的长大。一开始BLUE很害羞，只要我们一靠近她就立马缩回去，可能是还不熟络。她经常在屋子里摸索，大约所有地方她都造访过，很多时候还担当了扫帚的职责，常常跑出来以后裹了一身的棉絮。常常我们也不知道她在哪个角落，只听她哆哆哆的脚步声，便知道她还在探索。</p>\n<p>&emsp;&emsp;天冷起来，她是要睡很长时间的。我买了个冬眠盒子。把她放在里面，她迫不及待地钻了进去。开始还有些动静，天冷一些就安静了。只能从盒子上的水汽知道她还在。她熬过了四个冬天，她总能在天暖和的时候醒来。加上把她带回家那一次，她一共搬了三次家。</p>\n<p>&emsp;&emsp;有时我们在工作，她跑到客厅，瞅一瞅我们，大概在不懈的嘲笑，然后就继续她的探索；有时我们在床上休息，她在房间里哆哆哆，大概在取笑我们还在赖床。<br>后来我们碰到了更小只的purple男孩，把他带回来给BLUE做朋友。不知道他们相不相熟。有一次我们外出旅行了一周，他们两个一起躲到了厕所阴凉地方，靠在一块报团取暖。<br>到了冬天把他们一起放在了冬眠盒子。各自安好。谁知天热起来把他们放出来，BLUE的眼睛是浮肿的，也茶饭不思。我买了眼药给他治竟也无好转。随后又多次买药。</p>\n<p>&emsp;&emsp;老婆说自己不太会养宠物，以前家里养过鸟，鱼，狗。他们去世时自己会十分悲痛，像失去了亲人一样不舍。我说对BLUE大可放心，因为到时候可能她会给我们送终。可是毕竟不能如愿。</p>\n<p>&emsp;&emsp;我和娃把BLUE埋在了路口。那里我们还埋葬了一只小鸟和一只仓鼠。娃似乎比以前坚强，麻雀和仓鼠过世的时候他哭得很伤心，而这次他很淡然。他说这宇宙所有东西所有东西都会死掉，都会消失的。不知道他是明白还是不明白。</p>\n<p>&emsp;&emsp;希望一切安好。我估计以后再也不养宠物。如果他成了你的宠物，你就是在掌控他的生死。</p>","related_posts":[],"length":943,"excerpt":"<p>&emsp;&emsp;BLUE过世了。</p>","more":"<p>&emsp;&emsp;BLUE是在端午节过世的，或许更早，因为回到家只看到她的尸体。BLUE是我们在疫情解封后邂逅的，我们把她请回家，做了我们家一员。很抱歉没有给她配备好的住宿条件。让她在房间里可以自由的跑，只在进食的时候放在脸盆里。我不知道她挑不挑食。曾经在脸盆里投喂了白菜，她没吃。她很喜欢鱼饲料。每次投喂都大块朵颐。身材也是看得见的长大。一开始BLUE很害羞，只要我们一靠近她就立马缩回去，可能是还不熟络。她经常在屋子里摸索，大约所有地方她都造访过，很多时候还担当了扫帚的职责，常常跑出来以后裹了一身的棉絮。常常我们也不知道她在哪个角落，只听她哆哆哆的脚步声，便知道她还在探索。</p>\n<p>&emsp;&emsp;天冷起来，她是要睡很长时间的。我买了个冬眠盒子。把她放在里面，她迫不及待地钻了进去。开始还有些动静，天冷一些就安静了。只能从盒子上的水汽知道她还在。她熬过了四个冬天，她总能在天暖和的时候醒来。加上把她带回家那一次，她一共搬了三次家。</p>\n<p>&emsp;&emsp;有时我们在工作，她跑到客厅，瞅一瞅我们，大概在不懈的嘲笑，然后就继续她的探索；有时我们在床上休息，她在房间里哆哆哆，大概在取笑我们还在赖床。<br>后来我们碰到了更小只的purple男孩，把他带回来给BLUE做朋友。不知道他们相不相熟。有一次我们外出旅行了一周，他们两个一起躲到了厕所阴凉地方，靠在一块报团取暖。<br>到了冬天把他们一起放在了冬眠盒子。各自安好。谁知天热起来把他们放出来，BLUE的眼睛是浮肿的，也茶饭不思。我买了眼药给他治竟也无好转。随后又多次买药。</p>\n<p>&emsp;&emsp;老婆说自己不太会养宠物，以前家里养过鸟，鱼，狗。他们去世时自己会十分悲痛，像失去了亲人一样不舍。我说对BLUE大可放心，因为到时候可能她会给我们送终。可是毕竟不能如愿。</p>\n<p>&emsp;&emsp;我和娃把BLUE埋在了路口。那里我们还埋葬了一只小鸟和一只仓鼠。娃似乎比以前坚强，麻雀和仓鼠过世的时候他哭得很伤心，而这次他很淡然。他说这宇宙所有东西所有东西都会死掉，都会消失的。不知道他是明白还是不明白。</p>\n<p>&emsp;&emsp;希望一切安好。我估计以后再也不养宠物。如果他成了你的宠物，你就是在掌控他的生死。</p>"},{"title":"图像识别深度学习资料","abbrlink":"b663edf5","date":"2024-06-13T14:58:40.000Z","_content":"down来的机器学习图像识别资料。\n<!--less-->\n\n- R-CNN\n- Fast R-CNN\n- Faster R-CNN\n- Mask R-CNN\n- Light-Head R-CNN\n- Cascade R-CNN\n- SPP-Net\n- YOLO\n- YOLOv2\n- YOLOv3\n- YOLT\n- SSD\n- DSSD\n- FSSD\n- ESSD\n- MDSSD\n- Pelee\n- Fire SSD\n- R-FCN\n- FPN\n- DSOD\n- RetinaNet\n- MegDet\n- RefineNet\n- DetNet\n- SSOD\n- CornerNet\n- M2Det\n- 3D Object Detection\n- ZSD（Zero-Shot Object Detection）\n- OSD（One-Shot object Detection）\n- Weakly Supervised Object Detection\n- Softer-NMS\n- 2018\n- 2019\n- Other\n\nBased on handong1587's github: https://handong1587.github.io/deep_learning/2015/10/09/object-detection.html\n\n# Survey\n\n**Imbalance Problems in Object Detection: A Review**\n\n- intro: under review at TPAMI\n- arXiv: <https://arxiv.org/abs/1909.00169>\n\n**Recent Advances in Deep Learning for Object Detection**\n\n- intro: From 2013 (OverFeat) to 2019 (DetNAS)\n- arXiv: <https://arxiv.org/abs/1908.03673>\n\n**A Survey of Deep Learning-based Object Detection**\n\n- intro：From Fast R-CNN to NAS-FPN\n\n- arXiv：<https://arxiv.org/abs/1907.09408>\n\n**Object Detection in 20 Years: A Survey**\n\n- intro：This work has been submitted to the IEEE TPAMI for possible publication\n- arXiv：<https://arxiv.org/abs/1905.05055>\n\n**《Recent Advances in Object Detection in the Age of Deep Convolutional Neural Networks》**\n\n- intro: awesome\n\n\n- arXiv: https://arxiv.org/abs/1809.03193\n\n**《Deep Learning for Generic Object Detection: A Survey》**\n\n- intro: Submitted to IJCV 2018\n- arXiv: https://arxiv.org/abs/1809.02165\n\n# Papers&Codes\n\n## R-CNN\n\n**Rich feature hierarchies for accurate object detection and semantic segmentation**\n\n- intro: R-CNN\n- arxiv: <http://arxiv.org/abs/1311.2524>\n- supp: <http://people.eecs.berkeley.edu/~rbg/papers/r-cnn-cvpr-supp.pdf>\n- slides: <http://www.image-net.org/challenges/LSVRC/2013/slides/r-cnn-ilsvrc2013-workshop.pdf>\n- slides: <http://www.cs.berkeley.edu/~rbg/slides/rcnn-cvpr14-slides.pdf>\n- github: <https://github.com/rbgirshick/rcnn>\n- notes: <http://zhangliliang.com/2014/07/23/paper-note-rcnn/>\n- caffe-pr(\"Make R-CNN the Caffe detection example\"): <https://github.com/BVLC/caffe/pull/482>\n\n## Fast R-CNN\n\n**Fast R-CNN**\n\n- arxiv: <http://arxiv.org/abs/1504.08083>\n- slides: <http://tutorial.caffe.berkeleyvision.org/caffe-cvpr15-detection.pdf>\n- github: <https://github.com/rbgirshick/fast-rcnn>\n- github(COCO-branch): <https://github.com/rbgirshick/fast-rcnn/tree/coco>\n- webcam demo: <https://github.com/rbgirshick/fast-rcnn/pull/29>\n- notes: <http://zhangliliang.com/2015/05/17/paper-note-fast-rcnn/>\n- notes: <http://blog.csdn.net/linj_m/article/details/48930179>\n- github(\"Fast R-CNN in MXNet\"): <https://github.com/precedenceguo/mx-rcnn>\n- github: <https://github.com/mahyarnajibi/fast-rcnn-torch>\n- github: <https://github.com/apple2373/chainer-simple-fast-rnn>\n- github: <https://github.com/zplizzi/tensorflow-fast-rcnn>\n\n**A-Fast-RCNN: Hard Positive Generation via Adversary for Object Detection**\n\n- intro: CVPR 2017\n- arxiv: <https://arxiv.org/abs/1704.03414>\n- paper: <http://abhinavsh.info/papers/pdfs/adversarial_object_detection.pdf>\n- github(Caffe): <https://github.com/xiaolonw/adversarial-frcnn>\n\n## Faster R-CNN\n\n**Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks**\n\n- intro: NIPS 2015\n- arxiv: <http://arxiv.org/abs/1506.01497>\n- gitxiv: <http://www.gitxiv.com/posts/8pfpcvefDYn2gSgXk/faster-r-cnn-towards-real-time-object-detection-with-region>\n- slides: <http://web.cs.hacettepe.edu.tr/~aykut/classes/spring2016/bil722/slides/w05-FasterR-CNN.pdf>\n- github(official, Matlab): <https://github.com/ShaoqingRen/faster_rcnn>\n- github(Caffe): <https://github.com/rbgirshick/py-faster-rcnn>\n- github(MXNet): <https://github.com/msracver/Deformable-ConvNets/tree/master/faster_rcnn>\n- github(PyTorch--recommend): <https://github.com//jwyang/faster-rcnn.pytorch>\n- github: <https://github.com/mitmul/chainer-faster-rcnn>\n- github(Torch):: <https://github.com/andreaskoepf/faster-rcnn.torch>\n- github(Torch):: <https://github.com/ruotianluo/Faster-RCNN-Densecap-torch>\n- github(TensorFlow): <https://github.com/smallcorgi/Faster-RCNN_TF>\n- github(TensorFlow): <https://github.com/CharlesShang/TFFRCNN>\n- github(C++ demo): <https://github.com/YihangLou/FasterRCNN-Encapsulation-Cplusplus>\n- github(Keras): <https://github.com/yhenon/keras-frcnn>\n- github: <https://github.com/Eniac-Xie/faster-rcnn-resnet>\n- github(C++): <https://github.com/D-X-Y/caffe-faster-rcnn/tree/dev>\n\n**R-CNN minus R**\n\n- intro: BMVC 2015\n- arxiv: <http://arxiv.org/abs/1506.06981>\n\n**Faster R-CNN in MXNet with distributed implementation and data parallelization**\n\n- github: <https://github.com/dmlc/mxnet/tree/master/example/rcnn>\n\n**Contextual Priming and Feedback for Faster R-CNN**\n\n- intro: ECCV 2016. Carnegie Mellon University\n- paper: <http://abhinavsh.info/context_priming_feedback.pdf>\n- poster: <http://www.eccv2016.org/files/posters/P-1A-20.pdf>\n\n**An Implementation of Faster RCNN with Study for Region Sampling**\n\n- intro: Technical Report, 3 pages. CMU\n- arxiv: <https://arxiv.org/abs/1702.02138>\n- github: <https://github.com/endernewton/tf-faster-rcnn>\n- github: https://github.com/ruotianluo/pytorch-faster-rcnn\n\n**Interpretable R-CNN**\n\n- intro: North Carolina State University & Alibaba\n- keywords: AND-OR Graph (AOG)\n- arxiv: <https://arxiv.org/abs/1711.05226>\n\n**Domain Adaptive Faster R-CNN for Object Detection in the Wild**\n\n- intro: CVPR 2018. ETH Zurich & ESAT/PSI\n- arxiv: <https://arxiv.org/abs/1803.03243>\n\n## Mask R-CNN\n\n- arxiv: <http://arxiv.org/abs/1703.06870>\n- github(Keras): https://github.com/matterport/Mask_RCNN\n- github(Caffe2): https://github.com/facebookresearch/Detectron\n- github(Pytorch): <https://github.com/wannabeOG/Mask-RCNN>\n- github(MXNet): https://github.com/TuSimple/mx-maskrcnn\n- github(Chainer): https://github.com/DeNA/Chainer_Mask_R-CNN\n\n## Light-Head R-CNN\n\n**Light-Head R-CNN: In Defense of Two-Stage Object Detector**\n\n- intro: Tsinghua University & Megvii Inc\n- arxiv: <https://arxiv.org/abs/1711.07264>\n- github(offical): https://github.com/zengarden/light_head_rcnn\n- github: <https://github.com/terrychenism/Deformable-ConvNets/blob/master/rfcn/symbols/resnet_v1_101_rfcn_light.py#L784>\n\n## Cascade R-CNN\n\n**Cascade R-CNN: Delving into High Quality Object Detection**\n\n- arxiv: <https://arxiv.org/abs/1712.00726>\n- github: <https://github.com/zhaoweicai/cascade-rcnn>\n\n## SPP-Net\n\n**Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition**\n\n- intro: ECCV 2014 / TPAMI 2015\n- arxiv: <http://arxiv.org/abs/1406.4729>\n- github: <https://github.com/ShaoqingRen/SPP_net>\n- notes: <http://zhangliliang.com/2014/09/13/paper-note-sppnet/>\n\n**DeepID-Net: Deformable Deep Convolutional Neural Networks for Object Detection**\n\n- intro: PAMI 2016\n- intro: an extension of R-CNN. box pre-training, cascade on region proposals, deformation layers and context representations\n- project page: <http://www.ee.cuhk.edu.hk/%CB%9Cwlouyang/projects/imagenetDeepId/index.html>\n- arxiv: <http://arxiv.org/abs/1412.5661>\n\n**Object Detectors Emerge in Deep Scene CNNs**\n\n- intro: ICLR 2015\n- arxiv: <http://arxiv.org/abs/1412.6856>\n- paper: <https://www.robots.ox.ac.uk/~vgg/rg/papers/zhou_iclr15.pdf>\n- paper: <https://people.csail.mit.edu/khosla/papers/iclr2015_zhou.pdf>\n- slides: <http://places.csail.mit.edu/slide_iclr2015.pdf>\n\n**segDeepM: Exploiting Segmentation and Context in Deep Neural Networks for Object Detection**\n\n- intro: CVPR 2015\n- project(code+data): <https://www.cs.toronto.edu/~yukun/segdeepm.html>\n- arxiv: <https://arxiv.org/abs/1502.04275>\n- github: <https://github.com/YknZhu/segDeepM>\n\n**Object Detection Networks on Convolutional Feature Maps**\n\n- intro: TPAMI 2015\n- keywords: NoC\n- arxiv: <http://arxiv.org/abs/1504.06066>\n\n**Improving Object Detection with Deep Convolutional Networks via Bayesian Optimization and Structured Prediction**\n\n- arxiv: <http://arxiv.org/abs/1504.03293>\n- slides: <http://www.ytzhang.net/files/publications/2015-cvpr-det-slides.pdf>\n- github: <https://github.com/YutingZhang/fgs-obj>\n\n**DeepBox: Learning Objectness with Convolutional Networks**\n\n- keywords: DeepBox\n- arxiv: <http://arxiv.org/abs/1505.02146>\n- github: <https://github.com/weichengkuo/DeepBox>\n\n## YOLO\n\n**You Only Look Once: Unified, Real-Time Object Detection**\n\n[![img](https://camo.githubusercontent.com/e69d4118b20a42de4e23b9549f9a6ec6dbbb0814/687474703a2f2f706a7265646469652e636f6d2f6d656469612f66696c65732f6461726b6e65742d626c61636b2d736d616c6c2e706e67)](https://camo.githubusercontent.com/e69d4118b20a42de4e23b9549f9a6ec6dbbb0814/687474703a2f2f706a7265646469652e636f6d2f6d656469612f66696c65732f6461726b6e65742d626c61636b2d736d616c6c2e706e67)\n\n- arxiv: <http://arxiv.org/abs/1506.02640>\n- code: <https://pjreddie.com/darknet/yolov1/>\n- github: <https://github.com/pjreddie/darknet>\n- blog: <https://pjreddie.com/darknet/yolov1/>\n- slides: <https://docs.google.com/presentation/d/1aeRvtKG21KHdD5lg6Hgyhx5rPq_ZOsGjG5rJ1HP7BbA/pub?start=false&loop=false&delayms=3000&slide=id.p>\n- reddit: <https://www.reddit.com/r/MachineLearning/comments/3a3m0o/realtime_object_detection_with_yolo/>\n- github: <https://github.com/gliese581gg/YOLO_tensorflow>\n- github: <https://github.com/xingwangsfu/caffe-yolo>\n- github: <https://github.com/frankzhangrui/Darknet-Yolo>\n- github: <https://github.com/BriSkyHekun/py-darknet-yolo>\n- github: <https://github.com/tommy-qichang/yolo.torch>\n- github: <https://github.com/frischzenger/yolo-windows>\n- github: <https://github.com/AlexeyAB/yolo-windows>\n- github: <https://github.com/nilboy/tensorflow-yolo>\n\n**darkflow - translate darknet to tensorflow. Load trained weights, retrain/fine-tune them using tensorflow, export constant graph def to C++**\n\n- blog: <https://thtrieu.github.io/notes/yolo-tensorflow-graph-buffer-cpp>\n- github: <https://github.com/thtrieu/darkflow>\n\n**Start Training YOLO with Our Own Data**\n\n[![img](https://camo.githubusercontent.com/2f99b692dd7ce47d7832385f3e8a6654e680d92a/687474703a2f2f6775616e6768616e2e696e666f2f626c6f672f656e2f77702d636f6e74656e742f75706c6f6164732f323031352f31322f696d616765732d34302e6a7067)](https://camo.githubusercontent.com/2f99b692dd7ce47d7832385f3e8a6654e680d92a/687474703a2f2f6775616e6768616e2e696e666f2f626c6f672f656e2f77702d636f6e74656e742f75706c6f6164732f323031352f31322f696d616765732d34302e6a7067)\n\n- intro: train with customized data and class numbers/labels. Linux / Windows version for darknet.\n- blog: <http://guanghan.info/blog/en/my-works/train-yolo/>\n- github: <https://github.com/Guanghan/darknet>\n\n**YOLO: Core ML versus MPSNNGraph**\n\n- intro: Tiny YOLO for iOS implemented using CoreML but also using the new MPS graph API.\n- blog: <http://machinethink.net/blog/yolo-coreml-versus-mps-graph/>\n- github: <https://github.com/hollance/YOLO-CoreML-MPSNNGraph>\n\n**TensorFlow YOLO object detection on Android**\n\n- intro: Real-time object detection on Android using the YOLO network with TensorFlow\n- github: <https://github.com/natanielruiz/android-yolo>\n\n**Computer Vision in iOS – Object Detection**\n\n- blog: <https://sriraghu.com/2017/07/12/computer-vision-in-ios-object-detection/>\n- github:<https://github.com/r4ghu/iOS-CoreML-Yolo>\n\n## YOLOv2\n\n**YOLO9000: Better, Faster, Stronger**\n\n- arxiv: <https://arxiv.org/abs/1612.08242>\n- code: <http://pjreddie.com/yolo9000/>    https://pjreddie.com/darknet/yolov2/\n- github(Chainer): <https://github.com/leetenki/YOLOv2>\n- github(Keras): <https://github.com/allanzelener/YAD2K>\n- github(PyTorch): <https://github.com/longcw/yolo2-pytorch>\n- github(Tensorflow): <https://github.com/hizhangp/yolo_tensorflow>\n- github(Windows): <https://github.com/AlexeyAB/darknet>\n- github: <https://github.com/choasUp/caffe-yolo9000>\n- github: <https://github.com/philipperemy/yolo-9000>\n- github(TensorFlow): <https://github.com/KOD-Chen/YOLOv2-Tensorflow>\n- github(Keras): <https://github.com/yhcc/yolo2>\n- github(Keras): <https://github.com/experiencor/keras-yolo2>\n- github(TensorFlow): <https://github.com/WojciechMormul/yolo2>\n\n**darknet_scripts**\n\n- intro: Auxilary scripts to work with (YOLO) darknet deep learning famework. AKA -> How to generate YOLO anchors?\n- github: <https://github.com/Jumabek/darknet_scripts>\n\n**Yolo_mark: GUI for marking bounded boxes of objects in images for training Yolo v2**\n\n- github: <https://github.com/AlexeyAB/Yolo_mark>\n\n**LightNet: Bringing pjreddie's DarkNet out of the shadows**\n\n<https://github.com//explosion/lightnet>\n\n**YOLO v2 Bounding Box Tool**\n\n- intro: Bounding box labeler tool to generate the training data in the format YOLO v2 requires.\n- github: <https://github.com/Cartucho/yolo-boundingbox-labeler-GUI>\n\n**Loss Rank Mining: A General Hard Example Mining Method for Real-time Detectors**\n\n- intro: **LRM** is the first hard example mining strategy which could fit YOLOv2 perfectly and make it better applied in series of real scenarios where both real-time rates and accurate detection are strongly demanded.\n- arxiv: https://arxiv.org/abs/1804.04606\n\n**Object detection at 200 Frames Per Second**\n\n- intro: faster than Tiny-Yolo-v2\n- arxiv: https://arxiv.org/abs/1805.06361\n\n**Event-based Convolutional Networks for Object Detection in Neuromorphic Cameras**\n\n- intro: YOLE--Object Detection in Neuromorphic Cameras\n- arxiv:https://arxiv.org/abs/1805.07931\n\n**OmniDetector: With Neural Networks to Bounding Boxes**\n\n- intro: a person detector on n fish-eye images of indoor scenes（NIPS 2018）\n- arxiv:https://arxiv.org/abs/1805.08503\n- datasets:https://gitlab.com/omnidetector/omnidetector\n\n## YOLOv3\n\n**YOLOv3: An Incremental Improvement**\n\n- arxiv:https://arxiv.org/abs/1804.02767\n- paper:https://pjreddie.com/media/files/papers/YOLOv3.pdf\n- code: <https://pjreddie.com/darknet/yolo/>\n- github(Official):https://github.com/pjreddie/darknet\n- github:https://github.com/mystic123/tensorflow-yolo-v3\n- github:https://github.com/experiencor/keras-yolo3\n- github:https://github.com/qqwweee/keras-yolo3\n- github:https://github.com/marvis/pytorch-yolo3\n- github:https://github.com/ayooshkathuria/pytorch-yolo-v3\n- github:https://github.com/ayooshkathuria/YOLO_v3_tutorial_from_scratch\n- github:https://github.com/eriklindernoren/PyTorch-YOLOv3\n- github:https://github.com/ultralytics/yolov3\n- github:https://github.com/BobLiu20/YOLOv3_PyTorch\n- github:https://github.com/andy-yun/pytorch-0.4-yolov3\n- github:https://github.com/DeNA/PyTorch_YOLOv3\n\n## YOLT\n\n**You Only Look Twice: Rapid Multi-Scale Object Detection In Satellite Imagery**\n\n- intro: Small Object Detection\n\n\n- arxiv:https://arxiv.org/abs/1805.09512\n- github:https://github.com/avanetten/yolt\n\n## SSD\n\n**SSD: Single Shot MultiBox Detector**\n\n[![img](https://camo.githubusercontent.com/ad9b147ed3a5f48ffb7c3540711c15aa04ce49c6/687474703a2f2f7777772e63732e756e632e6564752f7e776c69752f7061706572732f7373642e706e67)](https://camo.githubusercontent.com/ad9b147ed3a5f48ffb7c3540711c15aa04ce49c6/687474703a2f2f7777772e63732e756e632e6564752f7e776c69752f7061706572732f7373642e706e67)\n\n- intro: ECCV 2016 Oral\n- arxiv: <http://arxiv.org/abs/1512.02325>\n- paper: <http://www.cs.unc.edu/~wliu/papers/ssd.pdf>\n- slides: [http://www.cs.unc.edu/%7Ewliu/papers/ssd_eccv2016_slide.pdf](http://www.cs.unc.edu/~wliu/papers/ssd_eccv2016_slide.pdf)\n- github(Official): <https://github.com/weiliu89/caffe/tree/ssd>\n- video: <http://weibo.com/p/2304447a2326da963254c963c97fb05dd3a973>\n- github: <https://github.com/zhreshold/mxnet-ssd>\n- github: <https://github.com/zhreshold/mxnet-ssd.cpp>\n- github: <https://github.com/rykov8/ssd_keras>\n- github: <https://github.com/balancap/SSD-Tensorflow>\n- github: <https://github.com/amdegroot/ssd.pytorch>\n- github(Caffe): <https://github.com/chuanqi305/MobileNet-SSD>\n\n**What's the diffience in performance between this new code you pushed and the previous code? #327**\n\n<https://github.com/weiliu89/caffe/issues/327>\n\n## DSSD\n\n**DSSD : Deconvolutional Single Shot Detector**\n\n- intro: UNC Chapel Hill & Amazon Inc\n- arxiv: <https://arxiv.org/abs/1701.06659>\n- github: <https://github.com/chengyangfu/caffe/tree/dssd>\n- github: <https://github.com/MTCloudVision/mxnet-dssd>\n- demo: <http://120.52.72.53/www.cs.unc.edu/c3pr90ntc0td/~cyfu/dssd_lalaland.mp4>\n\n**Enhancement of SSD by concatenating feature maps for object detection**\n\n- intro: rainbow SSD (R-SSD)\n- arxiv: <https://arxiv.org/abs/1705.09587>\n\n**Context-aware Single-Shot Detector**\n\n- keywords: CSSD, DiCSSD, DeCSSD, effective receptive fields (ERFs), theoretical receptive fields (TRFs)\n- arxiv: <https://arxiv.org/abs/1707.08682>\n\n**Feature-Fused SSD: Fast Detection for Small Objects**\n\n<https://arxiv.org/abs/1709.05054>\n\n## FSSD\n\n**FSSD: Feature Fusion Single Shot Multibox Detector**\n\n<https://arxiv.org/abs/1712.00960>\n\n**Weaving Multi-scale Context for Single Shot Detector**\n\n- intro: WeaveNet\n- keywords: fuse multi-scale information\n- arxiv: <https://arxiv.org/abs/1712.03149>\n\n## ESSD\n\n**Extend the shallow part of Single Shot MultiBox Detector via Convolutional Neural Network**\n\n<https://arxiv.org/abs/1801.05918>\n\n**Tiny SSD: A Tiny Single-shot Detection Deep Convolutional Neural Network for Real-time Embedded Object Detection**\n\n<https://arxiv.org/abs/1802.06488>\n\n## MDSSD\n\n**MDSSD: Multi-scale Deconvolutional Single Shot Detector for small objects**\n\n- arxiv: https://arxiv.org/abs/1805.07009\n\n## Pelee\n\n**Pelee: A Real-Time Object Detection System on Mobile Devices**\n\nhttps://github.com/Robert-JunWang/Pelee\n\n- intro: (ICLR 2018 workshop track)\n\n\n- arxiv: https://arxiv.org/abs/1804.06882\n- github: https://github.com/Robert-JunWang/Pelee\n\n## Fire SSD\n\n**Fire SSD: Wide Fire Modules based Single Shot Detector on Edge Device**\n\n- intro:low cost, fast speed and high mAP on  factor edge computing devices\n\n\n- arxiv:https://arxiv.org/abs/1806.05363\n\n## R-FCN\n\n**R-FCN: Object Detection via Region-based Fully Convolutional Networks**\n\n- arxiv: <http://arxiv.org/abs/1605.06409>\n- github: <https://github.com/daijifeng001/R-FCN>\n- github(MXNet): <https://github.com/msracver/Deformable-ConvNets/tree/master/rfcn>\n- github: <https://github.com/Orpine/py-R-FCN>\n- github: <https://github.com/PureDiors/pytorch_RFCN>\n- github: <https://github.com/bharatsingh430/py-R-FCN-multiGPU>\n- github: <https://github.com/xdever/RFCN-tensorflow>\n\n**R-FCN-3000 at 30fps: Decoupling Detection and Classification**\n\n<https://arxiv.org/abs/1712.01802>\n\n**Recycle deep features for better object detection**\n\n- arxiv: <http://arxiv.org/abs/1607.05066>\n\n## FPN\n\n**Feature Pyramid Networks for Object Detection**\n\n- intro: Facebook AI Research\n- arxiv: <https://arxiv.org/abs/1612.03144>\n\n**Action-Driven Object Detection with Top-Down Visual Attentions**\n\n- arxiv: <https://arxiv.org/abs/1612.06704>\n\n**Beyond Skip Connections: Top-Down Modulation for Object Detection**\n\n- intro: CMU & UC Berkeley & Google Research\n- arxiv: <https://arxiv.org/abs/1612.06851>\n\n**Wide-Residual-Inception Networks for Real-time Object Detection**\n\n- intro: Inha University\n- arxiv: <https://arxiv.org/abs/1702.01243>\n\n**Attentional Network for Visual Object Detection**\n\n- intro: University of Maryland & Mitsubishi Electric Research Laboratories\n- arxiv: <https://arxiv.org/abs/1702.01478>\n\n**Learning Chained Deep Features and Classifiers for Cascade in Object Detection**\n\n- keykwords: CC-Net\n- intro: chained cascade network (CC-Net). 81.1% mAP on PASCAL VOC 2007\n- arxiv: <https://arxiv.org/abs/1702.07054>\n\n**DeNet: Scalable Real-time Object Detection with Directed Sparse Sampling**\n\n- intro: ICCV 2017 (poster)\n- arxiv: <https://arxiv.org/abs/1703.10295>\n\n**Discriminative Bimodal Networks for Visual Localization and Detection with Natural Language Queries**\n\n- intro: CVPR 2017\n- arxiv: <https://arxiv.org/abs/1704.03944>\n\n**Spatial Memory for Context Reasoning in Object Detection**\n\n- arxiv: <https://arxiv.org/abs/1704.04224>\n\n**Accurate Single Stage Detector Using Recurrent Rolling Convolution**\n\n- intro: CVPR 2017. SenseTime\n- keywords: Recurrent Rolling Convolution (RRC)\n- arxiv: <https://arxiv.org/abs/1704.05776>\n- github: <https://github.com/xiaohaoChen/rrc_detection>\n\n**Deep Occlusion Reasoning for Multi-Camera Multi-Target Detection**\n\n<https://arxiv.org/abs/1704.05775>\n\n**LCDet: Low-Complexity Fully-Convolutional Neural Networks for Object Detection in Embedded Systems**\n\n- intro: Embedded Vision Workshop in CVPR. UC San Diego & Qualcomm Inc\n- arxiv: <https://arxiv.org/abs/1705.05922>\n\n**Point Linking Network for Object Detection**\n\n- intro: Point Linking Network (PLN)\n- arxiv: <https://arxiv.org/abs/1706.03646>\n\n**Perceptual Generative Adversarial Networks for Small Object Detection**\n\n<https://arxiv.org/abs/1706.05274>\n\n**Few-shot Object Detection**\n\n<https://arxiv.org/abs/1706.08249>\n\n**Yes-Net: An effective Detector Based on Global Information**\n\n<https://arxiv.org/abs/1706.09180>\n\n**SMC Faster R-CNN: Toward a scene-specialized multi-object detector**\n\n<https://arxiv.org/abs/1706.10217>\n\n**Towards lightweight convolutional neural networks for object detection**\n\n<https://arxiv.org/abs/1707.01395>\n\n**RON: Reverse Connection with Objectness Prior Networks for Object Detection**\n\n- intro: CVPR 2017\n- arxiv: <https://arxiv.org/abs/1707.01691>\n- github: <https://github.com/taokong/RON>\n\n**Mimicking Very Efficient Network for Object Detection**\n\n- intro: CVPR 2017. SenseTime & Beihang University\n- paper: <http://openaccess.thecvf.com/content_cvpr_2017/papers/Li_Mimicking_Very_Efficient_CVPR_2017_paper.pdf>\n\n**Residual Features and Unified Prediction Network for Single Stage Detection**\n\n<https://arxiv.org/abs/1707.05031>\n\n**Deformable Part-based Fully Convolutional Network for Object Detection**\n\n- intro: BMVC 2017 (oral). Sorbonne Universités & CEDRIC\n- arxiv: <https://arxiv.org/abs/1707.06175>\n\n**Adaptive Feeding: Achieving Fast and Accurate Detections by Adaptively Combining Object Detectors**\n\n- intro: ICCV 2017\n- arxiv: <https://arxiv.org/abs/1707.06399>\n\n**Recurrent Scale Approximation for Object Detection in CNN**\n\n- intro: ICCV 2017\n- keywords: Recurrent Scale Approximation (RSA)\n- arxiv: <https://arxiv.org/abs/1707.09531>\n- github: <https://github.com/sciencefans/RSA-for-object-detection>\n\n## DSOD\n\n**DSOD: Learning Deeply Supervised Object Detectors from Scratch**\n\n![img](https://user-images.githubusercontent.com/3794909/28934967-718c9302-78b5-11e7-89ee-8b514e53e23c.png)\n\n- intro: ICCV 2017. Fudan University & Tsinghua University & Intel Labs China\n- arxiv: <https://arxiv.org/abs/1708.01241>\n- github: <https://github.com/szq0214/DSOD>\n- github:https://github.com/Windaway/DSOD-Tensorflow\n- github:https://github.com/chenyuntc/dsod.pytorch\n\n**Learning Object Detectors from Scratch with Gated Recurrent Feature Pyramids**\n\n- arxiv:https://arxiv.org/abs/1712.00886\n- github:https://github.com/szq0214/GRP-DSOD\n\n**Tiny-DSOD: Lightweight Object Detection for Resource-Restricted Usages**\n\n- intro: BMVC 2018\n- arXiv: https://arxiv.org/abs/1807.11013\n\n**Object Detection from Scratch with Deep Supervision**\n\n- intro: This is an extended version of DSOD\n- arXiv: https://arxiv.org/abs/1809.09294\n\n## RetinaNet\n\n**Focal Loss for Dense Object Detection**\n\n- intro: ICCV 2017 Best student paper award. Facebook AI Research\n- keywords: RetinaNet\n- arxiv: <https://arxiv.org/abs/1708.02002>\n\n**CoupleNet: Coupling Global Structure with Local Parts for Object Detection**\n\n- intro: ICCV 2017\n- arxiv: <https://arxiv.org/abs/1708.02863>\n\n**Incremental Learning of Object Detectors without Catastrophic Forgetting**\n\n- intro: ICCV 2017. Inria\n- arxiv: <https://arxiv.org/abs/1708.06977>\n\n**Zoom Out-and-In Network with Map Attention Decision for Region Proposal and Object Detection**\n\n<https://arxiv.org/abs/1709.04347>\n\n**StairNet: Top-Down Semantic Aggregation for Accurate One Shot Detection**\n\n<https://arxiv.org/abs/1709.05788>\n\n**Dynamic Zoom-in Network for Fast Object Detection in Large Images**\n\n<https://arxiv.org/abs/1711.05187>\n\n**Zero-Annotation Object Detection with Web Knowledge Transfer**\n\n- intro: NTU, Singapore & Amazon\n- keywords: multi-instance multi-label domain adaption learning framework\n- arxiv: <https://arxiv.org/abs/1711.05954>\n\n## MegDet\n\n**MegDet: A Large Mini-Batch Object Detector**\n\n- intro: Peking University & Tsinghua University & Megvii Inc\n- arxiv: <https://arxiv.org/abs/1711.07240>\n\n**Receptive Field Block Net for Accurate and Fast Object Detection**\n\n- intro: RFBNet\n- arxiv: <https://arxiv.org/abs/1711.07767>\n- github: <https://github.com//ruinmessi/RFBNet>\n\n**An Analysis of Scale Invariance in Object Detection - SNIP**\n\n- arxiv: <https://arxiv.org/abs/1711.08189>\n- github: <https://github.com/bharatsingh430/snip>\n\n**Feature Selective Networks for Object Detection**\n\n<https://arxiv.org/abs/1711.08879>\n\n**Learning a Rotation Invariant Detector with Rotatable Bounding Box**\n\n- arxiv: <https://arxiv.org/abs/1711.09405>\n- github: <https://github.com/liulei01/DRBox>\n\n**Scalable Object Detection for Stylized Objects**\n\n- intro: Microsoft AI & Research Munich\n- arxiv: <https://arxiv.org/abs/1711.09822>\n\n**Learning Object Detectors from Scratch with Gated Recurrent Feature Pyramids**\n\n- arxiv: <https://arxiv.org/abs/1712.00886>\n- github: <https://github.com/szq0214/GRP-DSOD>\n\n**Deep Regionlets for Object Detection**\n\n- keywords: region selection network, gating network\n- arxiv: <https://arxiv.org/abs/1712.02408>\n\n**Training and Testing Object Detectors with Virtual Images**\n\n- intro: IEEE/CAA Journal of Automatica Sinica\n- arxiv: <https://arxiv.org/abs/1712.08470>\n\n**Large-Scale Object Discovery and Detector Adaptation from Unlabeled Video**\n\n- keywords: object mining, object tracking, unsupervised object discovery by appearance-based clustering, self-supervised detector adaptation\n- arxiv: <https://arxiv.org/abs/1712.08832>\n\n**Spot the Difference by Object Detection**\n\n- intro: Tsinghua University & JD Group\n- arxiv: <https://arxiv.org/abs/1801.01051>\n\n**Localization-Aware Active Learning for Object Detection**\n\n- arxiv: <https://arxiv.org/abs/1801.05124>\n\n**Object Detection with Mask-based Feature Encoding**\n\n- arxiv: <https://arxiv.org/abs/1802.03934>\n\n**LSTD: A Low-Shot Transfer Detector for Object Detection**\n\n- intro: AAAI 2018\n- arxiv: <https://arxiv.org/abs/1803.01529>\n\n**Pseudo Mask Augmented Object Detection**\n\n<https://arxiv.org/abs/1803.05858>\n\n**Revisiting RCNN: On Awakening the Classification Power of Faster RCNN**\n\n<https://arxiv.org/abs/1803.06799>\n\n**Learning Region Features for Object Detection**\n\n- intro: Peking University & MSRA\n- arxiv: <https://arxiv.org/abs/1803.07066>\n\n**Single-Shot Bidirectional Pyramid Networks for High-Quality Object Detection**\n\n- intro: Singapore Management University & Zhejiang University\n- arxiv: <https://arxiv.org/abs/1803.08208>\n\n**Object Detection for Comics using Manga109 Annotations**\n\n- intro: University of Tokyo & National Institute of Informatics, Japan\n- arxiv: <https://arxiv.org/abs/1803.08670>\n\n**Task-Driven Super Resolution: Object Detection in Low-resolution Images**\n\n- arxiv: <https://arxiv.org/abs/1803.11316>\n\n**Transferring Common-Sense Knowledge for Object Detection**\n\n- arxiv: <https://arxiv.org/abs/1804.01077>\n\n**Multi-scale Location-aware Kernel Representation for Object Detection**\n\n- intro: CVPR 2018\n- arxiv: <https://arxiv.org/abs/1804.00428>\n- github: <https://github.com/Hwang64/MLKP>\n\n\n**Loss Rank Mining: A General Hard Example Mining Method for Real-time Detectors**\n\n- intro: National University of Defense Technology\n- arxiv: https://arxiv.org/abs/1804.04606\n\n**Robust Physical Adversarial Attack on Faster R-CNN Object Detector**\n\n- arxiv: https://arxiv.org/abs/1804.05810\n\n## RefineNet\n\n**Single-Shot Refinement Neural Network for Object Detection**\n\n- intro: CVPR 2018\n\n- arxiv: <https://arxiv.org/abs/1711.06897>\n- github: <https://github.com/sfzhang15/RefineDet>\n- github: https://github.com/lzx1413/PytorchSSD\n- github: https://github.com/ddlee96/RefineDet_mxnet\n- github: https://github.com/MTCloudVision/RefineDet-Mxnet\n\n## DetNet\n\n**DetNet: A Backbone network for Object Detection**\n\n- intro: Tsinghua University & Face++\n- arxiv: https://arxiv.org/abs/1804.06215\n\n\n## SSOD\n\n**Self-supervisory Signals for Object Discovery and Detection**\n\n- Google Brain\n- arxiv:https://arxiv.org/abs/1806.03370\n\n## CornerNet\n\n**CornerNet: Detecting Objects as Paired Keypoints**\n\n- intro: ECCV 2018\n- arXiv: https://arxiv.org/abs/1808.01244\n- github: <https://github.com/umich-vl/CornerNet>\n\n## M2Det\n\n**M2Det: A Single-Shot Object Detector based on Multi-Level Feature Pyramid Network**\n\n- intro: AAAI 2019\n- arXiv: https://arxiv.org/abs/1811.04533\n- github: https://github.com/qijiezhao/M2Det\n\n## 3D Object Detection\n\n**3D Backbone Network for 3D Object Detection**\n\n- arXiv: https://arxiv.org/abs/1901.08373\n\n**LMNet: Real-time Multiclass Object Detection on CPU using 3D LiDARs**\n\n- arxiv: https://arxiv.org/abs/1805.04902\n- github: https://github.com/CPFL/Autoware/tree/feature/cnn_lidar_detection\n\n\n## ZSD（Zero-Shot Object Detection）\n\n**Zero-Shot Detection**\n\n- intro: Australian National University\n- keywords: YOLO\n- arxiv: <https://arxiv.org/abs/1803.07113>\n\n**Zero-Shot Object Detection**\n\n- arxiv: https://arxiv.org/abs/1804.04340\n\n**Zero-Shot Object Detection: Learning to Simultaneously Recognize and Localize Novel Concepts**\n\n- arxiv: https://arxiv.org/abs/1803.06049\n\n**Zero-Shot Object Detection by Hybrid Region Embedding**\n\n- arxiv: https://arxiv.org/abs/1805.06157\n\n## OSD（One-Shot Object Detection）\n\n**Comparison Network for One-Shot Conditional Object Detection**\n\n- arXiv: https://arxiv.org/abs/1904.02317\n\n**One-Shot Object Detection**\n\nRepMet: Representative-based metric learning for classification and one-shot object detection\n\n- intro: IBM Research AI\n- arxiv:https://arxiv.org/abs/1806.04728\n- github: TODO\n\n## Weakly Supervised Object Detection\n\n**Weakly Supervised Object Detection in Artworks**\n\n- intro: ECCV 2018 Workshop Computer Vision for Art Analysis\n- arXiv: https://arxiv.org/abs/1810.02569\n- Datasets: https://wsoda.telecom-paristech.fr/downloads/dataset/IconArt_v1.zip\n\n**Cross-Domain Weakly-Supervised Object Detection through Progressive Domain Adaptation**\n\n- intro: CVPR 2018\n- arXiv: https://arxiv.org/abs/1803.11365\n- homepage: https://naoto0804.github.io/cross_domain_detection/\n- paper: http://openaccess.thecvf.com/content_cvpr_2018/html/Inoue_Cross-Domain_Weakly-Supervised_Object_CVPR_2018_paper.html\n- github: https://github.com/naoto0804/cross-domain-detection\n\n## Softer-NMS\n\n**《Softer-NMS: Rethinking Bounding Box Regression for Accurate Object Detection》**\n\n- intro: CMU & Face++\n- arXiv: https://arxiv.org/abs/1809.08545\n- github: https://github.com/yihui-he/softer-NMS\n\n## 2019\n\n**Feature Selective Anchor-Free Module for Single-Shot Object Detection**\n\n- intro: CVPR 2019\n\n- arXiv: https://arxiv.org/abs/1903.00621\n\n**Object Detection based on Region Decomposition and Assembly**\n\n- intro: AAAI 2019\n\n- arXiv: https://arxiv.org/abs/1901.08225\n\n**Bottom-up Object Detection by Grouping Extreme and Center Points**\n\n- intro: one stage 43.2% on COCO test-dev\n- arXiv: https://arxiv.org/abs/1901.08043\n- github: https://github.com/xingyizhou/ExtremeNet\n\n**ORSIm Detector: A Novel Object Detection Framework in Optical Remote Sensing Imagery Using Spatial-Frequency Channel Features**\n\n- intro: IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING\n\n- arXiv: https://arxiv.org/abs/1901.07925\n\n**Consistent Optimization for Single-Shot Object Detection**\n\n- intro: improves RetinaNet from 39.1 AP to 40.1 AP on COCO datase\n\n- arXiv: https://arxiv.org/abs/1901.06563\n\n**Learning Pairwise Relationship for Multi-object Detection in Crowded Scenes**\n\n- arXiv: https://arxiv.org/abs/1901.03796\n\n**RetinaMask: Learning to predict masks improves state-of-the-art single-shot detection for free**\n\n- arXiv: https://arxiv.org/abs/1901.03353\n- github: https://github.com/chengyangfu/retinamask\n\n**Region Proposal by Guided Anchoring**\n\n- intro: CUHK - SenseTime Joint Lab\n- arXiv: https://arxiv.org/abs/1901.03278\n\n**Scale-Aware Trident Networks for Object Detection**\n\n- intro: mAP of **48.4** on the COCO dataset\n- arXiv: https://arxiv.org/abs/1901.01892\n\n## 2018\n\n**Large-Scale Object Detection of Images from Network Cameras in Variable Ambient Lighting Conditions**\n\n- arXiv: https://arxiv.org/abs/1812.11901\n\n**Strong-Weak Distribution Alignment for Adaptive Object Detection**\n\n- arXiv: https://arxiv.org/abs/1812.04798\n\n**AutoFocus: Efficient Multi-Scale Inference**\n\n- intro: AutoFocus obtains an **mAP of 47.9%** (68.3% at 50% overlap) on the **COCO test-dev** set while processing **6.4 images per second on a Titan X (Pascal) GPU** \n- arXiv: https://arxiv.org/abs/1812.01600\n\n**NOTE-RCNN: NOise Tolerant Ensemble RCNN for Semi-Supervised Object Detection**\n\n- intro: Google Could\n- arXiv: https://arxiv.org/abs/1812.00124\n\n**SPLAT: Semantic Pixel-Level Adaptation Transforms for Detection**\n\n- intro: UC Berkeley\n- arXiv: https://arxiv.org/abs/1812.00929\n\n**Grid R-CNN**\n\n- intro: SenseTime\n- arXiv: https://arxiv.org/abs/1811.12030\n\n**Deformable ConvNets v2: More Deformable, Better Results**\n\n- intro: Microsoft Research Asia\n\n- arXiv: https://arxiv.org/abs/1811.11168\n\n**Anchor Box Optimization for Object Detection**\n\n- intro: Microsoft Research\n- arXiv: https://arxiv.org/abs/1812.00469\n\n**Efficient Coarse-to-Fine Non-Local Module for the Detection of Small Objects**\n\n- intro: https://arxiv.org/abs/1811.12152\n\n**NOTE-RCNN: NOise Tolerant Ensemble RCNN for Semi-Supervised Object Detection**\n\n- arXiv: https://arxiv.org/abs/1812.00124\n\n**Learning RoI Transformer for Detecting Oriented Objects in Aerial Images**\n\n- arXiv: https://arxiv.org/abs/1812.00155\n\n**Integrated Object Detection and Tracking with Tracklet-Conditioned Detection**\n\n- intro: Microsoft Research Asia\n- arXiv: https://arxiv.org/abs/1811.11167\n\n**Deep Regionlets: Blended Representation and Deep Learning for Generic Object Detection**\n\n- arXiv: https://arxiv.org/abs/1811.11318\n\n **Gradient Harmonized Single-stage Detector**\n\n- intro: AAAI 2019\n- arXiv: https://arxiv.org/abs/1811.05181\n\n**CFENet: Object Detection with Comprehensive Feature Enhancement Module**\n\n- intro: ACCV 2018\n- github: https://github.com/qijiezhao/CFENet\n\n**DeRPN: Taking a further step toward more general object detection**\n\n- intro: AAAI 2019\n- arXiv: https://arxiv.org/abs/1811.06700\n- github: https://github.com/HCIILAB/DeRPN\n\n**Hybrid Knowledge Routed Modules for Large-scale Object Detection**\n\n- intro: Sun Yat-Sen University & Huawei Noah’s Ark Lab\n- arXiv: https://arxiv.org/abs/1810.12681\n- github: https://github.com/chanyn/HKRM\n\n**《Receptive Field Block Net for Accurate and Fast Object Detection》**\n\n- intro: ECCV 2018\n- arXiv: [https://arxiv.org/abs/1711.07767](https://arxiv.org/abs/1711.07767)\n- github: [https://github.com/ruinmessi/RFBNet](https://github.com/ruinmessi/RFBNet)\n\n**Deep Feature Pyramid Reconfiguration for Object Detection**\n\n- intro: ECCV 2018\n- arXiv: https://arxiv.org/abs/1808.07993\n\n**Unsupervised Hard Example Mining from Videos for Improved Object Detection**\n\n- intro: ECCV 2018\n- arXiv: https://arxiv.org/abs/1808.04285\n\n**Acquisition of Localization Confidence for Accurate Object Detection**\n\n- intro: ECCV 2018\n- arXiv: https://arxiv.org/abs/1807.11590\n- github: https://github.com/vacancy/PreciseRoIPooling\n\n**Toward Scale-Invariance and Position-Sensitive Region Proposal Networks**\n\n- intro: ECCV 2018\n- arXiv: https://arxiv.org/abs/1807.09528\n\n**MetaAnchor: Learning to Detect Objects with Customized Anchors**\n\n- arxiv: https://arxiv.org/abs/1807.00980\n\n**Relation Network for Object Detection**\n\n- intro: CVPR 2018\n- arxiv: https://arxiv.org/abs/1711.11575\n- github:https://github.com/msracver/Relation-Networks-for-Object-Detection\n\n**Quantization Mimic: Towards Very Tiny CNN for Object Detection**\n\n- Tsinghua University1 & The Chinese University of Hong Kong2 &SenseTime3\n- arxiv: https://arxiv.org/abs/1805.02152\n\n**Learning Rich Features for Image Manipulation Detection**\n\n- intro: CVPR 2018 Camera Ready\n- arxiv: https://arxiv.org/abs/1805.04953\n\n**SNIPER: Efficient Multi-Scale Training**\n\n- arxiv:https://arxiv.org/abs/1805.09300\n- github:https://github.com/mahyarnajibi/SNIPER\n\n**Soft Sampling for Robust Object Detection**\n\n- intro: the robustness of object detection under the presence of missing annotations\n- arxiv:https://arxiv.org/abs/1806.06986\n\n**Cost-effective Object Detection: Active Sample Mining with Switchable Selection Criteria**\n\n- intro: TNNLS 2018\n- arxiv:https://arxiv.org/abs/1807.00147\n- code: http://kezewang.com/codes/ASM_ver1.zip\n\n## Other\n\n**R3-Net: A Deep Network for Multi-oriented Vehicle Detection in Aerial Images and Videos**\n\n- arxiv: https://arxiv.org/abs/1808.05560\n- youtube: https://youtu.be/xCYD-tYudN0\n\n# Detection Toolbox\n\n- [Detectron(FAIR)](https://github.com/facebookresearch/Detectron): Detectron is Facebook AI Research's software system that implements state-of-the-art object detection algorithms, including [Mask R-CNN](https://arxiv.org/abs/1703.06870). It is written in Python and powered by the [Caffe2](https://github.com/caffe2/caffe2) deep learning framework.\n- [Detectron2](https://github.com/facebookresearch/detectron2): Detectron2 is FAIR's next-generation research platform for object detection and segmentation.\n- [maskrcnn-benchmark(FAIR)](https://github.com/facebookresearch/maskrcnn-benchmark): Fast, modular reference implementation of Instance Segmentation and Object Detection algorithms in PyTorch.\n- [mmdetection(SenseTime&CUHK)](https://github.com/open-mmlab/mmdetection): mmdetection is an open source object detection toolbox based on PyTorch. It is a part of the open-mmlab project developed by [Multimedia Laboratory, CUHK](http://mmlab.ie.cuhk.edu.hk/).\n","source":"_posts/2024-06-13-object-detection.md","raw":"---\ntitle: 图像识别深度学习资料\ntags:\n  - 学习\nabbrlink: b663edf5\ndate: 2024-06-13 22:58:40\n---\ndown来的机器学习图像识别资料。\n<!--less-->\n\n- R-CNN\n- Fast R-CNN\n- Faster R-CNN\n- Mask R-CNN\n- Light-Head R-CNN\n- Cascade R-CNN\n- SPP-Net\n- YOLO\n- YOLOv2\n- YOLOv3\n- YOLT\n- SSD\n- DSSD\n- FSSD\n- ESSD\n- MDSSD\n- Pelee\n- Fire SSD\n- R-FCN\n- FPN\n- DSOD\n- RetinaNet\n- MegDet\n- RefineNet\n- DetNet\n- SSOD\n- CornerNet\n- M2Det\n- 3D Object Detection\n- ZSD（Zero-Shot Object Detection）\n- OSD（One-Shot object Detection）\n- Weakly Supervised Object Detection\n- Softer-NMS\n- 2018\n- 2019\n- Other\n\nBased on handong1587's github: https://handong1587.github.io/deep_learning/2015/10/09/object-detection.html\n\n# Survey\n\n**Imbalance Problems in Object Detection: A Review**\n\n- intro: under review at TPAMI\n- arXiv: <https://arxiv.org/abs/1909.00169>\n\n**Recent Advances in Deep Learning for Object Detection**\n\n- intro: From 2013 (OverFeat) to 2019 (DetNAS)\n- arXiv: <https://arxiv.org/abs/1908.03673>\n\n**A Survey of Deep Learning-based Object Detection**\n\n- intro：From Fast R-CNN to NAS-FPN\n\n- arXiv：<https://arxiv.org/abs/1907.09408>\n\n**Object Detection in 20 Years: A Survey**\n\n- intro：This work has been submitted to the IEEE TPAMI for possible publication\n- arXiv：<https://arxiv.org/abs/1905.05055>\n\n**《Recent Advances in Object Detection in the Age of Deep Convolutional Neural Networks》**\n\n- intro: awesome\n\n\n- arXiv: https://arxiv.org/abs/1809.03193\n\n**《Deep Learning for Generic Object Detection: A Survey》**\n\n- intro: Submitted to IJCV 2018\n- arXiv: https://arxiv.org/abs/1809.02165\n\n# Papers&Codes\n\n## R-CNN\n\n**Rich feature hierarchies for accurate object detection and semantic segmentation**\n\n- intro: R-CNN\n- arxiv: <http://arxiv.org/abs/1311.2524>\n- supp: <http://people.eecs.berkeley.edu/~rbg/papers/r-cnn-cvpr-supp.pdf>\n- slides: <http://www.image-net.org/challenges/LSVRC/2013/slides/r-cnn-ilsvrc2013-workshop.pdf>\n- slides: <http://www.cs.berkeley.edu/~rbg/slides/rcnn-cvpr14-slides.pdf>\n- github: <https://github.com/rbgirshick/rcnn>\n- notes: <http://zhangliliang.com/2014/07/23/paper-note-rcnn/>\n- caffe-pr(\"Make R-CNN the Caffe detection example\"): <https://github.com/BVLC/caffe/pull/482>\n\n## Fast R-CNN\n\n**Fast R-CNN**\n\n- arxiv: <http://arxiv.org/abs/1504.08083>\n- slides: <http://tutorial.caffe.berkeleyvision.org/caffe-cvpr15-detection.pdf>\n- github: <https://github.com/rbgirshick/fast-rcnn>\n- github(COCO-branch): <https://github.com/rbgirshick/fast-rcnn/tree/coco>\n- webcam demo: <https://github.com/rbgirshick/fast-rcnn/pull/29>\n- notes: <http://zhangliliang.com/2015/05/17/paper-note-fast-rcnn/>\n- notes: <http://blog.csdn.net/linj_m/article/details/48930179>\n- github(\"Fast R-CNN in MXNet\"): <https://github.com/precedenceguo/mx-rcnn>\n- github: <https://github.com/mahyarnajibi/fast-rcnn-torch>\n- github: <https://github.com/apple2373/chainer-simple-fast-rnn>\n- github: <https://github.com/zplizzi/tensorflow-fast-rcnn>\n\n**A-Fast-RCNN: Hard Positive Generation via Adversary for Object Detection**\n\n- intro: CVPR 2017\n- arxiv: <https://arxiv.org/abs/1704.03414>\n- paper: <http://abhinavsh.info/papers/pdfs/adversarial_object_detection.pdf>\n- github(Caffe): <https://github.com/xiaolonw/adversarial-frcnn>\n\n## Faster R-CNN\n\n**Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks**\n\n- intro: NIPS 2015\n- arxiv: <http://arxiv.org/abs/1506.01497>\n- gitxiv: <http://www.gitxiv.com/posts/8pfpcvefDYn2gSgXk/faster-r-cnn-towards-real-time-object-detection-with-region>\n- slides: <http://web.cs.hacettepe.edu.tr/~aykut/classes/spring2016/bil722/slides/w05-FasterR-CNN.pdf>\n- github(official, Matlab): <https://github.com/ShaoqingRen/faster_rcnn>\n- github(Caffe): <https://github.com/rbgirshick/py-faster-rcnn>\n- github(MXNet): <https://github.com/msracver/Deformable-ConvNets/tree/master/faster_rcnn>\n- github(PyTorch--recommend): <https://github.com//jwyang/faster-rcnn.pytorch>\n- github: <https://github.com/mitmul/chainer-faster-rcnn>\n- github(Torch):: <https://github.com/andreaskoepf/faster-rcnn.torch>\n- github(Torch):: <https://github.com/ruotianluo/Faster-RCNN-Densecap-torch>\n- github(TensorFlow): <https://github.com/smallcorgi/Faster-RCNN_TF>\n- github(TensorFlow): <https://github.com/CharlesShang/TFFRCNN>\n- github(C++ demo): <https://github.com/YihangLou/FasterRCNN-Encapsulation-Cplusplus>\n- github(Keras): <https://github.com/yhenon/keras-frcnn>\n- github: <https://github.com/Eniac-Xie/faster-rcnn-resnet>\n- github(C++): <https://github.com/D-X-Y/caffe-faster-rcnn/tree/dev>\n\n**R-CNN minus R**\n\n- intro: BMVC 2015\n- arxiv: <http://arxiv.org/abs/1506.06981>\n\n**Faster R-CNN in MXNet with distributed implementation and data parallelization**\n\n- github: <https://github.com/dmlc/mxnet/tree/master/example/rcnn>\n\n**Contextual Priming and Feedback for Faster R-CNN**\n\n- intro: ECCV 2016. Carnegie Mellon University\n- paper: <http://abhinavsh.info/context_priming_feedback.pdf>\n- poster: <http://www.eccv2016.org/files/posters/P-1A-20.pdf>\n\n**An Implementation of Faster RCNN with Study for Region Sampling**\n\n- intro: Technical Report, 3 pages. CMU\n- arxiv: <https://arxiv.org/abs/1702.02138>\n- github: <https://github.com/endernewton/tf-faster-rcnn>\n- github: https://github.com/ruotianluo/pytorch-faster-rcnn\n\n**Interpretable R-CNN**\n\n- intro: North Carolina State University & Alibaba\n- keywords: AND-OR Graph (AOG)\n- arxiv: <https://arxiv.org/abs/1711.05226>\n\n**Domain Adaptive Faster R-CNN for Object Detection in the Wild**\n\n- intro: CVPR 2018. ETH Zurich & ESAT/PSI\n- arxiv: <https://arxiv.org/abs/1803.03243>\n\n## Mask R-CNN\n\n- arxiv: <http://arxiv.org/abs/1703.06870>\n- github(Keras): https://github.com/matterport/Mask_RCNN\n- github(Caffe2): https://github.com/facebookresearch/Detectron\n- github(Pytorch): <https://github.com/wannabeOG/Mask-RCNN>\n- github(MXNet): https://github.com/TuSimple/mx-maskrcnn\n- github(Chainer): https://github.com/DeNA/Chainer_Mask_R-CNN\n\n## Light-Head R-CNN\n\n**Light-Head R-CNN: In Defense of Two-Stage Object Detector**\n\n- intro: Tsinghua University & Megvii Inc\n- arxiv: <https://arxiv.org/abs/1711.07264>\n- github(offical): https://github.com/zengarden/light_head_rcnn\n- github: <https://github.com/terrychenism/Deformable-ConvNets/blob/master/rfcn/symbols/resnet_v1_101_rfcn_light.py#L784>\n\n## Cascade R-CNN\n\n**Cascade R-CNN: Delving into High Quality Object Detection**\n\n- arxiv: <https://arxiv.org/abs/1712.00726>\n- github: <https://github.com/zhaoweicai/cascade-rcnn>\n\n## SPP-Net\n\n**Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition**\n\n- intro: ECCV 2014 / TPAMI 2015\n- arxiv: <http://arxiv.org/abs/1406.4729>\n- github: <https://github.com/ShaoqingRen/SPP_net>\n- notes: <http://zhangliliang.com/2014/09/13/paper-note-sppnet/>\n\n**DeepID-Net: Deformable Deep Convolutional Neural Networks for Object Detection**\n\n- intro: PAMI 2016\n- intro: an extension of R-CNN. box pre-training, cascade on region proposals, deformation layers and context representations\n- project page: <http://www.ee.cuhk.edu.hk/%CB%9Cwlouyang/projects/imagenetDeepId/index.html>\n- arxiv: <http://arxiv.org/abs/1412.5661>\n\n**Object Detectors Emerge in Deep Scene CNNs**\n\n- intro: ICLR 2015\n- arxiv: <http://arxiv.org/abs/1412.6856>\n- paper: <https://www.robots.ox.ac.uk/~vgg/rg/papers/zhou_iclr15.pdf>\n- paper: <https://people.csail.mit.edu/khosla/papers/iclr2015_zhou.pdf>\n- slides: <http://places.csail.mit.edu/slide_iclr2015.pdf>\n\n**segDeepM: Exploiting Segmentation and Context in Deep Neural Networks for Object Detection**\n\n- intro: CVPR 2015\n- project(code+data): <https://www.cs.toronto.edu/~yukun/segdeepm.html>\n- arxiv: <https://arxiv.org/abs/1502.04275>\n- github: <https://github.com/YknZhu/segDeepM>\n\n**Object Detection Networks on Convolutional Feature Maps**\n\n- intro: TPAMI 2015\n- keywords: NoC\n- arxiv: <http://arxiv.org/abs/1504.06066>\n\n**Improving Object Detection with Deep Convolutional Networks via Bayesian Optimization and Structured Prediction**\n\n- arxiv: <http://arxiv.org/abs/1504.03293>\n- slides: <http://www.ytzhang.net/files/publications/2015-cvpr-det-slides.pdf>\n- github: <https://github.com/YutingZhang/fgs-obj>\n\n**DeepBox: Learning Objectness with Convolutional Networks**\n\n- keywords: DeepBox\n- arxiv: <http://arxiv.org/abs/1505.02146>\n- github: <https://github.com/weichengkuo/DeepBox>\n\n## YOLO\n\n**You Only Look Once: Unified, Real-Time Object Detection**\n\n[![img](https://camo.githubusercontent.com/e69d4118b20a42de4e23b9549f9a6ec6dbbb0814/687474703a2f2f706a7265646469652e636f6d2f6d656469612f66696c65732f6461726b6e65742d626c61636b2d736d616c6c2e706e67)](https://camo.githubusercontent.com/e69d4118b20a42de4e23b9549f9a6ec6dbbb0814/687474703a2f2f706a7265646469652e636f6d2f6d656469612f66696c65732f6461726b6e65742d626c61636b2d736d616c6c2e706e67)\n\n- arxiv: <http://arxiv.org/abs/1506.02640>\n- code: <https://pjreddie.com/darknet/yolov1/>\n- github: <https://github.com/pjreddie/darknet>\n- blog: <https://pjreddie.com/darknet/yolov1/>\n- slides: <https://docs.google.com/presentation/d/1aeRvtKG21KHdD5lg6Hgyhx5rPq_ZOsGjG5rJ1HP7BbA/pub?start=false&loop=false&delayms=3000&slide=id.p>\n- reddit: <https://www.reddit.com/r/MachineLearning/comments/3a3m0o/realtime_object_detection_with_yolo/>\n- github: <https://github.com/gliese581gg/YOLO_tensorflow>\n- github: <https://github.com/xingwangsfu/caffe-yolo>\n- github: <https://github.com/frankzhangrui/Darknet-Yolo>\n- github: <https://github.com/BriSkyHekun/py-darknet-yolo>\n- github: <https://github.com/tommy-qichang/yolo.torch>\n- github: <https://github.com/frischzenger/yolo-windows>\n- github: <https://github.com/AlexeyAB/yolo-windows>\n- github: <https://github.com/nilboy/tensorflow-yolo>\n\n**darkflow - translate darknet to tensorflow. Load trained weights, retrain/fine-tune them using tensorflow, export constant graph def to C++**\n\n- blog: <https://thtrieu.github.io/notes/yolo-tensorflow-graph-buffer-cpp>\n- github: <https://github.com/thtrieu/darkflow>\n\n**Start Training YOLO with Our Own Data**\n\n[![img](https://camo.githubusercontent.com/2f99b692dd7ce47d7832385f3e8a6654e680d92a/687474703a2f2f6775616e6768616e2e696e666f2f626c6f672f656e2f77702d636f6e74656e742f75706c6f6164732f323031352f31322f696d616765732d34302e6a7067)](https://camo.githubusercontent.com/2f99b692dd7ce47d7832385f3e8a6654e680d92a/687474703a2f2f6775616e6768616e2e696e666f2f626c6f672f656e2f77702d636f6e74656e742f75706c6f6164732f323031352f31322f696d616765732d34302e6a7067)\n\n- intro: train with customized data and class numbers/labels. Linux / Windows version for darknet.\n- blog: <http://guanghan.info/blog/en/my-works/train-yolo/>\n- github: <https://github.com/Guanghan/darknet>\n\n**YOLO: Core ML versus MPSNNGraph**\n\n- intro: Tiny YOLO for iOS implemented using CoreML but also using the new MPS graph API.\n- blog: <http://machinethink.net/blog/yolo-coreml-versus-mps-graph/>\n- github: <https://github.com/hollance/YOLO-CoreML-MPSNNGraph>\n\n**TensorFlow YOLO object detection on Android**\n\n- intro: Real-time object detection on Android using the YOLO network with TensorFlow\n- github: <https://github.com/natanielruiz/android-yolo>\n\n**Computer Vision in iOS – Object Detection**\n\n- blog: <https://sriraghu.com/2017/07/12/computer-vision-in-ios-object-detection/>\n- github:<https://github.com/r4ghu/iOS-CoreML-Yolo>\n\n## YOLOv2\n\n**YOLO9000: Better, Faster, Stronger**\n\n- arxiv: <https://arxiv.org/abs/1612.08242>\n- code: <http://pjreddie.com/yolo9000/>    https://pjreddie.com/darknet/yolov2/\n- github(Chainer): <https://github.com/leetenki/YOLOv2>\n- github(Keras): <https://github.com/allanzelener/YAD2K>\n- github(PyTorch): <https://github.com/longcw/yolo2-pytorch>\n- github(Tensorflow): <https://github.com/hizhangp/yolo_tensorflow>\n- github(Windows): <https://github.com/AlexeyAB/darknet>\n- github: <https://github.com/choasUp/caffe-yolo9000>\n- github: <https://github.com/philipperemy/yolo-9000>\n- github(TensorFlow): <https://github.com/KOD-Chen/YOLOv2-Tensorflow>\n- github(Keras): <https://github.com/yhcc/yolo2>\n- github(Keras): <https://github.com/experiencor/keras-yolo2>\n- github(TensorFlow): <https://github.com/WojciechMormul/yolo2>\n\n**darknet_scripts**\n\n- intro: Auxilary scripts to work with (YOLO) darknet deep learning famework. AKA -> How to generate YOLO anchors?\n- github: <https://github.com/Jumabek/darknet_scripts>\n\n**Yolo_mark: GUI for marking bounded boxes of objects in images for training Yolo v2**\n\n- github: <https://github.com/AlexeyAB/Yolo_mark>\n\n**LightNet: Bringing pjreddie's DarkNet out of the shadows**\n\n<https://github.com//explosion/lightnet>\n\n**YOLO v2 Bounding Box Tool**\n\n- intro: Bounding box labeler tool to generate the training data in the format YOLO v2 requires.\n- github: <https://github.com/Cartucho/yolo-boundingbox-labeler-GUI>\n\n**Loss Rank Mining: A General Hard Example Mining Method for Real-time Detectors**\n\n- intro: **LRM** is the first hard example mining strategy which could fit YOLOv2 perfectly and make it better applied in series of real scenarios where both real-time rates and accurate detection are strongly demanded.\n- arxiv: https://arxiv.org/abs/1804.04606\n\n**Object detection at 200 Frames Per Second**\n\n- intro: faster than Tiny-Yolo-v2\n- arxiv: https://arxiv.org/abs/1805.06361\n\n**Event-based Convolutional Networks for Object Detection in Neuromorphic Cameras**\n\n- intro: YOLE--Object Detection in Neuromorphic Cameras\n- arxiv:https://arxiv.org/abs/1805.07931\n\n**OmniDetector: With Neural Networks to Bounding Boxes**\n\n- intro: a person detector on n fish-eye images of indoor scenes（NIPS 2018）\n- arxiv:https://arxiv.org/abs/1805.08503\n- datasets:https://gitlab.com/omnidetector/omnidetector\n\n## YOLOv3\n\n**YOLOv3: An Incremental Improvement**\n\n- arxiv:https://arxiv.org/abs/1804.02767\n- paper:https://pjreddie.com/media/files/papers/YOLOv3.pdf\n- code: <https://pjreddie.com/darknet/yolo/>\n- github(Official):https://github.com/pjreddie/darknet\n- github:https://github.com/mystic123/tensorflow-yolo-v3\n- github:https://github.com/experiencor/keras-yolo3\n- github:https://github.com/qqwweee/keras-yolo3\n- github:https://github.com/marvis/pytorch-yolo3\n- github:https://github.com/ayooshkathuria/pytorch-yolo-v3\n- github:https://github.com/ayooshkathuria/YOLO_v3_tutorial_from_scratch\n- github:https://github.com/eriklindernoren/PyTorch-YOLOv3\n- github:https://github.com/ultralytics/yolov3\n- github:https://github.com/BobLiu20/YOLOv3_PyTorch\n- github:https://github.com/andy-yun/pytorch-0.4-yolov3\n- github:https://github.com/DeNA/PyTorch_YOLOv3\n\n## YOLT\n\n**You Only Look Twice: Rapid Multi-Scale Object Detection In Satellite Imagery**\n\n- intro: Small Object Detection\n\n\n- arxiv:https://arxiv.org/abs/1805.09512\n- github:https://github.com/avanetten/yolt\n\n## SSD\n\n**SSD: Single Shot MultiBox Detector**\n\n[![img](https://camo.githubusercontent.com/ad9b147ed3a5f48ffb7c3540711c15aa04ce49c6/687474703a2f2f7777772e63732e756e632e6564752f7e776c69752f7061706572732f7373642e706e67)](https://camo.githubusercontent.com/ad9b147ed3a5f48ffb7c3540711c15aa04ce49c6/687474703a2f2f7777772e63732e756e632e6564752f7e776c69752f7061706572732f7373642e706e67)\n\n- intro: ECCV 2016 Oral\n- arxiv: <http://arxiv.org/abs/1512.02325>\n- paper: <http://www.cs.unc.edu/~wliu/papers/ssd.pdf>\n- slides: [http://www.cs.unc.edu/%7Ewliu/papers/ssd_eccv2016_slide.pdf](http://www.cs.unc.edu/~wliu/papers/ssd_eccv2016_slide.pdf)\n- github(Official): <https://github.com/weiliu89/caffe/tree/ssd>\n- video: <http://weibo.com/p/2304447a2326da963254c963c97fb05dd3a973>\n- github: <https://github.com/zhreshold/mxnet-ssd>\n- github: <https://github.com/zhreshold/mxnet-ssd.cpp>\n- github: <https://github.com/rykov8/ssd_keras>\n- github: <https://github.com/balancap/SSD-Tensorflow>\n- github: <https://github.com/amdegroot/ssd.pytorch>\n- github(Caffe): <https://github.com/chuanqi305/MobileNet-SSD>\n\n**What's the diffience in performance between this new code you pushed and the previous code? #327**\n\n<https://github.com/weiliu89/caffe/issues/327>\n\n## DSSD\n\n**DSSD : Deconvolutional Single Shot Detector**\n\n- intro: UNC Chapel Hill & Amazon Inc\n- arxiv: <https://arxiv.org/abs/1701.06659>\n- github: <https://github.com/chengyangfu/caffe/tree/dssd>\n- github: <https://github.com/MTCloudVision/mxnet-dssd>\n- demo: <http://120.52.72.53/www.cs.unc.edu/c3pr90ntc0td/~cyfu/dssd_lalaland.mp4>\n\n**Enhancement of SSD by concatenating feature maps for object detection**\n\n- intro: rainbow SSD (R-SSD)\n- arxiv: <https://arxiv.org/abs/1705.09587>\n\n**Context-aware Single-Shot Detector**\n\n- keywords: CSSD, DiCSSD, DeCSSD, effective receptive fields (ERFs), theoretical receptive fields (TRFs)\n- arxiv: <https://arxiv.org/abs/1707.08682>\n\n**Feature-Fused SSD: Fast Detection for Small Objects**\n\n<https://arxiv.org/abs/1709.05054>\n\n## FSSD\n\n**FSSD: Feature Fusion Single Shot Multibox Detector**\n\n<https://arxiv.org/abs/1712.00960>\n\n**Weaving Multi-scale Context for Single Shot Detector**\n\n- intro: WeaveNet\n- keywords: fuse multi-scale information\n- arxiv: <https://arxiv.org/abs/1712.03149>\n\n## ESSD\n\n**Extend the shallow part of Single Shot MultiBox Detector via Convolutional Neural Network**\n\n<https://arxiv.org/abs/1801.05918>\n\n**Tiny SSD: A Tiny Single-shot Detection Deep Convolutional Neural Network for Real-time Embedded Object Detection**\n\n<https://arxiv.org/abs/1802.06488>\n\n## MDSSD\n\n**MDSSD: Multi-scale Deconvolutional Single Shot Detector for small objects**\n\n- arxiv: https://arxiv.org/abs/1805.07009\n\n## Pelee\n\n**Pelee: A Real-Time Object Detection System on Mobile Devices**\n\nhttps://github.com/Robert-JunWang/Pelee\n\n- intro: (ICLR 2018 workshop track)\n\n\n- arxiv: https://arxiv.org/abs/1804.06882\n- github: https://github.com/Robert-JunWang/Pelee\n\n## Fire SSD\n\n**Fire SSD: Wide Fire Modules based Single Shot Detector on Edge Device**\n\n- intro:low cost, fast speed and high mAP on  factor edge computing devices\n\n\n- arxiv:https://arxiv.org/abs/1806.05363\n\n## R-FCN\n\n**R-FCN: Object Detection via Region-based Fully Convolutional Networks**\n\n- arxiv: <http://arxiv.org/abs/1605.06409>\n- github: <https://github.com/daijifeng001/R-FCN>\n- github(MXNet): <https://github.com/msracver/Deformable-ConvNets/tree/master/rfcn>\n- github: <https://github.com/Orpine/py-R-FCN>\n- github: <https://github.com/PureDiors/pytorch_RFCN>\n- github: <https://github.com/bharatsingh430/py-R-FCN-multiGPU>\n- github: <https://github.com/xdever/RFCN-tensorflow>\n\n**R-FCN-3000 at 30fps: Decoupling Detection and Classification**\n\n<https://arxiv.org/abs/1712.01802>\n\n**Recycle deep features for better object detection**\n\n- arxiv: <http://arxiv.org/abs/1607.05066>\n\n## FPN\n\n**Feature Pyramid Networks for Object Detection**\n\n- intro: Facebook AI Research\n- arxiv: <https://arxiv.org/abs/1612.03144>\n\n**Action-Driven Object Detection with Top-Down Visual Attentions**\n\n- arxiv: <https://arxiv.org/abs/1612.06704>\n\n**Beyond Skip Connections: Top-Down Modulation for Object Detection**\n\n- intro: CMU & UC Berkeley & Google Research\n- arxiv: <https://arxiv.org/abs/1612.06851>\n\n**Wide-Residual-Inception Networks for Real-time Object Detection**\n\n- intro: Inha University\n- arxiv: <https://arxiv.org/abs/1702.01243>\n\n**Attentional Network for Visual Object Detection**\n\n- intro: University of Maryland & Mitsubishi Electric Research Laboratories\n- arxiv: <https://arxiv.org/abs/1702.01478>\n\n**Learning Chained Deep Features and Classifiers for Cascade in Object Detection**\n\n- keykwords: CC-Net\n- intro: chained cascade network (CC-Net). 81.1% mAP on PASCAL VOC 2007\n- arxiv: <https://arxiv.org/abs/1702.07054>\n\n**DeNet: Scalable Real-time Object Detection with Directed Sparse Sampling**\n\n- intro: ICCV 2017 (poster)\n- arxiv: <https://arxiv.org/abs/1703.10295>\n\n**Discriminative Bimodal Networks for Visual Localization and Detection with Natural Language Queries**\n\n- intro: CVPR 2017\n- arxiv: <https://arxiv.org/abs/1704.03944>\n\n**Spatial Memory for Context Reasoning in Object Detection**\n\n- arxiv: <https://arxiv.org/abs/1704.04224>\n\n**Accurate Single Stage Detector Using Recurrent Rolling Convolution**\n\n- intro: CVPR 2017. SenseTime\n- keywords: Recurrent Rolling Convolution (RRC)\n- arxiv: <https://arxiv.org/abs/1704.05776>\n- github: <https://github.com/xiaohaoChen/rrc_detection>\n\n**Deep Occlusion Reasoning for Multi-Camera Multi-Target Detection**\n\n<https://arxiv.org/abs/1704.05775>\n\n**LCDet: Low-Complexity Fully-Convolutional Neural Networks for Object Detection in Embedded Systems**\n\n- intro: Embedded Vision Workshop in CVPR. UC San Diego & Qualcomm Inc\n- arxiv: <https://arxiv.org/abs/1705.05922>\n\n**Point Linking Network for Object Detection**\n\n- intro: Point Linking Network (PLN)\n- arxiv: <https://arxiv.org/abs/1706.03646>\n\n**Perceptual Generative Adversarial Networks for Small Object Detection**\n\n<https://arxiv.org/abs/1706.05274>\n\n**Few-shot Object Detection**\n\n<https://arxiv.org/abs/1706.08249>\n\n**Yes-Net: An effective Detector Based on Global Information**\n\n<https://arxiv.org/abs/1706.09180>\n\n**SMC Faster R-CNN: Toward a scene-specialized multi-object detector**\n\n<https://arxiv.org/abs/1706.10217>\n\n**Towards lightweight convolutional neural networks for object detection**\n\n<https://arxiv.org/abs/1707.01395>\n\n**RON: Reverse Connection with Objectness Prior Networks for Object Detection**\n\n- intro: CVPR 2017\n- arxiv: <https://arxiv.org/abs/1707.01691>\n- github: <https://github.com/taokong/RON>\n\n**Mimicking Very Efficient Network for Object Detection**\n\n- intro: CVPR 2017. SenseTime & Beihang University\n- paper: <http://openaccess.thecvf.com/content_cvpr_2017/papers/Li_Mimicking_Very_Efficient_CVPR_2017_paper.pdf>\n\n**Residual Features and Unified Prediction Network for Single Stage Detection**\n\n<https://arxiv.org/abs/1707.05031>\n\n**Deformable Part-based Fully Convolutional Network for Object Detection**\n\n- intro: BMVC 2017 (oral). Sorbonne Universités & CEDRIC\n- arxiv: <https://arxiv.org/abs/1707.06175>\n\n**Adaptive Feeding: Achieving Fast and Accurate Detections by Adaptively Combining Object Detectors**\n\n- intro: ICCV 2017\n- arxiv: <https://arxiv.org/abs/1707.06399>\n\n**Recurrent Scale Approximation for Object Detection in CNN**\n\n- intro: ICCV 2017\n- keywords: Recurrent Scale Approximation (RSA)\n- arxiv: <https://arxiv.org/abs/1707.09531>\n- github: <https://github.com/sciencefans/RSA-for-object-detection>\n\n## DSOD\n\n**DSOD: Learning Deeply Supervised Object Detectors from Scratch**\n\n![img](https://user-images.githubusercontent.com/3794909/28934967-718c9302-78b5-11e7-89ee-8b514e53e23c.png)\n\n- intro: ICCV 2017. Fudan University & Tsinghua University & Intel Labs China\n- arxiv: <https://arxiv.org/abs/1708.01241>\n- github: <https://github.com/szq0214/DSOD>\n- github:https://github.com/Windaway/DSOD-Tensorflow\n- github:https://github.com/chenyuntc/dsod.pytorch\n\n**Learning Object Detectors from Scratch with Gated Recurrent Feature Pyramids**\n\n- arxiv:https://arxiv.org/abs/1712.00886\n- github:https://github.com/szq0214/GRP-DSOD\n\n**Tiny-DSOD: Lightweight Object Detection for Resource-Restricted Usages**\n\n- intro: BMVC 2018\n- arXiv: https://arxiv.org/abs/1807.11013\n\n**Object Detection from Scratch with Deep Supervision**\n\n- intro: This is an extended version of DSOD\n- arXiv: https://arxiv.org/abs/1809.09294\n\n## RetinaNet\n\n**Focal Loss for Dense Object Detection**\n\n- intro: ICCV 2017 Best student paper award. Facebook AI Research\n- keywords: RetinaNet\n- arxiv: <https://arxiv.org/abs/1708.02002>\n\n**CoupleNet: Coupling Global Structure with Local Parts for Object Detection**\n\n- intro: ICCV 2017\n- arxiv: <https://arxiv.org/abs/1708.02863>\n\n**Incremental Learning of Object Detectors without Catastrophic Forgetting**\n\n- intro: ICCV 2017. Inria\n- arxiv: <https://arxiv.org/abs/1708.06977>\n\n**Zoom Out-and-In Network with Map Attention Decision for Region Proposal and Object Detection**\n\n<https://arxiv.org/abs/1709.04347>\n\n**StairNet: Top-Down Semantic Aggregation for Accurate One Shot Detection**\n\n<https://arxiv.org/abs/1709.05788>\n\n**Dynamic Zoom-in Network for Fast Object Detection in Large Images**\n\n<https://arxiv.org/abs/1711.05187>\n\n**Zero-Annotation Object Detection with Web Knowledge Transfer**\n\n- intro: NTU, Singapore & Amazon\n- keywords: multi-instance multi-label domain adaption learning framework\n- arxiv: <https://arxiv.org/abs/1711.05954>\n\n## MegDet\n\n**MegDet: A Large Mini-Batch Object Detector**\n\n- intro: Peking University & Tsinghua University & Megvii Inc\n- arxiv: <https://arxiv.org/abs/1711.07240>\n\n**Receptive Field Block Net for Accurate and Fast Object Detection**\n\n- intro: RFBNet\n- arxiv: <https://arxiv.org/abs/1711.07767>\n- github: <https://github.com//ruinmessi/RFBNet>\n\n**An Analysis of Scale Invariance in Object Detection - SNIP**\n\n- arxiv: <https://arxiv.org/abs/1711.08189>\n- github: <https://github.com/bharatsingh430/snip>\n\n**Feature Selective Networks for Object Detection**\n\n<https://arxiv.org/abs/1711.08879>\n\n**Learning a Rotation Invariant Detector with Rotatable Bounding Box**\n\n- arxiv: <https://arxiv.org/abs/1711.09405>\n- github: <https://github.com/liulei01/DRBox>\n\n**Scalable Object Detection for Stylized Objects**\n\n- intro: Microsoft AI & Research Munich\n- arxiv: <https://arxiv.org/abs/1711.09822>\n\n**Learning Object Detectors from Scratch with Gated Recurrent Feature Pyramids**\n\n- arxiv: <https://arxiv.org/abs/1712.00886>\n- github: <https://github.com/szq0214/GRP-DSOD>\n\n**Deep Regionlets for Object Detection**\n\n- keywords: region selection network, gating network\n- arxiv: <https://arxiv.org/abs/1712.02408>\n\n**Training and Testing Object Detectors with Virtual Images**\n\n- intro: IEEE/CAA Journal of Automatica Sinica\n- arxiv: <https://arxiv.org/abs/1712.08470>\n\n**Large-Scale Object Discovery and Detector Adaptation from Unlabeled Video**\n\n- keywords: object mining, object tracking, unsupervised object discovery by appearance-based clustering, self-supervised detector adaptation\n- arxiv: <https://arxiv.org/abs/1712.08832>\n\n**Spot the Difference by Object Detection**\n\n- intro: Tsinghua University & JD Group\n- arxiv: <https://arxiv.org/abs/1801.01051>\n\n**Localization-Aware Active Learning for Object Detection**\n\n- arxiv: <https://arxiv.org/abs/1801.05124>\n\n**Object Detection with Mask-based Feature Encoding**\n\n- arxiv: <https://arxiv.org/abs/1802.03934>\n\n**LSTD: A Low-Shot Transfer Detector for Object Detection**\n\n- intro: AAAI 2018\n- arxiv: <https://arxiv.org/abs/1803.01529>\n\n**Pseudo Mask Augmented Object Detection**\n\n<https://arxiv.org/abs/1803.05858>\n\n**Revisiting RCNN: On Awakening the Classification Power of Faster RCNN**\n\n<https://arxiv.org/abs/1803.06799>\n\n**Learning Region Features for Object Detection**\n\n- intro: Peking University & MSRA\n- arxiv: <https://arxiv.org/abs/1803.07066>\n\n**Single-Shot Bidirectional Pyramid Networks for High-Quality Object Detection**\n\n- intro: Singapore Management University & Zhejiang University\n- arxiv: <https://arxiv.org/abs/1803.08208>\n\n**Object Detection for Comics using Manga109 Annotations**\n\n- intro: University of Tokyo & National Institute of Informatics, Japan\n- arxiv: <https://arxiv.org/abs/1803.08670>\n\n**Task-Driven Super Resolution: Object Detection in Low-resolution Images**\n\n- arxiv: <https://arxiv.org/abs/1803.11316>\n\n**Transferring Common-Sense Knowledge for Object Detection**\n\n- arxiv: <https://arxiv.org/abs/1804.01077>\n\n**Multi-scale Location-aware Kernel Representation for Object Detection**\n\n- intro: CVPR 2018\n- arxiv: <https://arxiv.org/abs/1804.00428>\n- github: <https://github.com/Hwang64/MLKP>\n\n\n**Loss Rank Mining: A General Hard Example Mining Method for Real-time Detectors**\n\n- intro: National University of Defense Technology\n- arxiv: https://arxiv.org/abs/1804.04606\n\n**Robust Physical Adversarial Attack on Faster R-CNN Object Detector**\n\n- arxiv: https://arxiv.org/abs/1804.05810\n\n## RefineNet\n\n**Single-Shot Refinement Neural Network for Object Detection**\n\n- intro: CVPR 2018\n\n- arxiv: <https://arxiv.org/abs/1711.06897>\n- github: <https://github.com/sfzhang15/RefineDet>\n- github: https://github.com/lzx1413/PytorchSSD\n- github: https://github.com/ddlee96/RefineDet_mxnet\n- github: https://github.com/MTCloudVision/RefineDet-Mxnet\n\n## DetNet\n\n**DetNet: A Backbone network for Object Detection**\n\n- intro: Tsinghua University & Face++\n- arxiv: https://arxiv.org/abs/1804.06215\n\n\n## SSOD\n\n**Self-supervisory Signals for Object Discovery and Detection**\n\n- Google Brain\n- arxiv:https://arxiv.org/abs/1806.03370\n\n## CornerNet\n\n**CornerNet: Detecting Objects as Paired Keypoints**\n\n- intro: ECCV 2018\n- arXiv: https://arxiv.org/abs/1808.01244\n- github: <https://github.com/umich-vl/CornerNet>\n\n## M2Det\n\n**M2Det: A Single-Shot Object Detector based on Multi-Level Feature Pyramid Network**\n\n- intro: AAAI 2019\n- arXiv: https://arxiv.org/abs/1811.04533\n- github: https://github.com/qijiezhao/M2Det\n\n## 3D Object Detection\n\n**3D Backbone Network for 3D Object Detection**\n\n- arXiv: https://arxiv.org/abs/1901.08373\n\n**LMNet: Real-time Multiclass Object Detection on CPU using 3D LiDARs**\n\n- arxiv: https://arxiv.org/abs/1805.04902\n- github: https://github.com/CPFL/Autoware/tree/feature/cnn_lidar_detection\n\n\n## ZSD（Zero-Shot Object Detection）\n\n**Zero-Shot Detection**\n\n- intro: Australian National University\n- keywords: YOLO\n- arxiv: <https://arxiv.org/abs/1803.07113>\n\n**Zero-Shot Object Detection**\n\n- arxiv: https://arxiv.org/abs/1804.04340\n\n**Zero-Shot Object Detection: Learning to Simultaneously Recognize and Localize Novel Concepts**\n\n- arxiv: https://arxiv.org/abs/1803.06049\n\n**Zero-Shot Object Detection by Hybrid Region Embedding**\n\n- arxiv: https://arxiv.org/abs/1805.06157\n\n## OSD（One-Shot Object Detection）\n\n**Comparison Network for One-Shot Conditional Object Detection**\n\n- arXiv: https://arxiv.org/abs/1904.02317\n\n**One-Shot Object Detection**\n\nRepMet: Representative-based metric learning for classification and one-shot object detection\n\n- intro: IBM Research AI\n- arxiv:https://arxiv.org/abs/1806.04728\n- github: TODO\n\n## Weakly Supervised Object Detection\n\n**Weakly Supervised Object Detection in Artworks**\n\n- intro: ECCV 2018 Workshop Computer Vision for Art Analysis\n- arXiv: https://arxiv.org/abs/1810.02569\n- Datasets: https://wsoda.telecom-paristech.fr/downloads/dataset/IconArt_v1.zip\n\n**Cross-Domain Weakly-Supervised Object Detection through Progressive Domain Adaptation**\n\n- intro: CVPR 2018\n- arXiv: https://arxiv.org/abs/1803.11365\n- homepage: https://naoto0804.github.io/cross_domain_detection/\n- paper: http://openaccess.thecvf.com/content_cvpr_2018/html/Inoue_Cross-Domain_Weakly-Supervised_Object_CVPR_2018_paper.html\n- github: https://github.com/naoto0804/cross-domain-detection\n\n## Softer-NMS\n\n**《Softer-NMS: Rethinking Bounding Box Regression for Accurate Object Detection》**\n\n- intro: CMU & Face++\n- arXiv: https://arxiv.org/abs/1809.08545\n- github: https://github.com/yihui-he/softer-NMS\n\n## 2019\n\n**Feature Selective Anchor-Free Module for Single-Shot Object Detection**\n\n- intro: CVPR 2019\n\n- arXiv: https://arxiv.org/abs/1903.00621\n\n**Object Detection based on Region Decomposition and Assembly**\n\n- intro: AAAI 2019\n\n- arXiv: https://arxiv.org/abs/1901.08225\n\n**Bottom-up Object Detection by Grouping Extreme and Center Points**\n\n- intro: one stage 43.2% on COCO test-dev\n- arXiv: https://arxiv.org/abs/1901.08043\n- github: https://github.com/xingyizhou/ExtremeNet\n\n**ORSIm Detector: A Novel Object Detection Framework in Optical Remote Sensing Imagery Using Spatial-Frequency Channel Features**\n\n- intro: IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING\n\n- arXiv: https://arxiv.org/abs/1901.07925\n\n**Consistent Optimization for Single-Shot Object Detection**\n\n- intro: improves RetinaNet from 39.1 AP to 40.1 AP on COCO datase\n\n- arXiv: https://arxiv.org/abs/1901.06563\n\n**Learning Pairwise Relationship for Multi-object Detection in Crowded Scenes**\n\n- arXiv: https://arxiv.org/abs/1901.03796\n\n**RetinaMask: Learning to predict masks improves state-of-the-art single-shot detection for free**\n\n- arXiv: https://arxiv.org/abs/1901.03353\n- github: https://github.com/chengyangfu/retinamask\n\n**Region Proposal by Guided Anchoring**\n\n- intro: CUHK - SenseTime Joint Lab\n- arXiv: https://arxiv.org/abs/1901.03278\n\n**Scale-Aware Trident Networks for Object Detection**\n\n- intro: mAP of **48.4** on the COCO dataset\n- arXiv: https://arxiv.org/abs/1901.01892\n\n## 2018\n\n**Large-Scale Object Detection of Images from Network Cameras in Variable Ambient Lighting Conditions**\n\n- arXiv: https://arxiv.org/abs/1812.11901\n\n**Strong-Weak Distribution Alignment for Adaptive Object Detection**\n\n- arXiv: https://arxiv.org/abs/1812.04798\n\n**AutoFocus: Efficient Multi-Scale Inference**\n\n- intro: AutoFocus obtains an **mAP of 47.9%** (68.3% at 50% overlap) on the **COCO test-dev** set while processing **6.4 images per second on a Titan X (Pascal) GPU** \n- arXiv: https://arxiv.org/abs/1812.01600\n\n**NOTE-RCNN: NOise Tolerant Ensemble RCNN for Semi-Supervised Object Detection**\n\n- intro: Google Could\n- arXiv: https://arxiv.org/abs/1812.00124\n\n**SPLAT: Semantic Pixel-Level Adaptation Transforms for Detection**\n\n- intro: UC Berkeley\n- arXiv: https://arxiv.org/abs/1812.00929\n\n**Grid R-CNN**\n\n- intro: SenseTime\n- arXiv: https://arxiv.org/abs/1811.12030\n\n**Deformable ConvNets v2: More Deformable, Better Results**\n\n- intro: Microsoft Research Asia\n\n- arXiv: https://arxiv.org/abs/1811.11168\n\n**Anchor Box Optimization for Object Detection**\n\n- intro: Microsoft Research\n- arXiv: https://arxiv.org/abs/1812.00469\n\n**Efficient Coarse-to-Fine Non-Local Module for the Detection of Small Objects**\n\n- intro: https://arxiv.org/abs/1811.12152\n\n**NOTE-RCNN: NOise Tolerant Ensemble RCNN for Semi-Supervised Object Detection**\n\n- arXiv: https://arxiv.org/abs/1812.00124\n\n**Learning RoI Transformer for Detecting Oriented Objects in Aerial Images**\n\n- arXiv: https://arxiv.org/abs/1812.00155\n\n**Integrated Object Detection and Tracking with Tracklet-Conditioned Detection**\n\n- intro: Microsoft Research Asia\n- arXiv: https://arxiv.org/abs/1811.11167\n\n**Deep Regionlets: Blended Representation and Deep Learning for Generic Object Detection**\n\n- arXiv: https://arxiv.org/abs/1811.11318\n\n **Gradient Harmonized Single-stage Detector**\n\n- intro: AAAI 2019\n- arXiv: https://arxiv.org/abs/1811.05181\n\n**CFENet: Object Detection with Comprehensive Feature Enhancement Module**\n\n- intro: ACCV 2018\n- github: https://github.com/qijiezhao/CFENet\n\n**DeRPN: Taking a further step toward more general object detection**\n\n- intro: AAAI 2019\n- arXiv: https://arxiv.org/abs/1811.06700\n- github: https://github.com/HCIILAB/DeRPN\n\n**Hybrid Knowledge Routed Modules for Large-scale Object Detection**\n\n- intro: Sun Yat-Sen University & Huawei Noah’s Ark Lab\n- arXiv: https://arxiv.org/abs/1810.12681\n- github: https://github.com/chanyn/HKRM\n\n**《Receptive Field Block Net for Accurate and Fast Object Detection》**\n\n- intro: ECCV 2018\n- arXiv: [https://arxiv.org/abs/1711.07767](https://arxiv.org/abs/1711.07767)\n- github: [https://github.com/ruinmessi/RFBNet](https://github.com/ruinmessi/RFBNet)\n\n**Deep Feature Pyramid Reconfiguration for Object Detection**\n\n- intro: ECCV 2018\n- arXiv: https://arxiv.org/abs/1808.07993\n\n**Unsupervised Hard Example Mining from Videos for Improved Object Detection**\n\n- intro: ECCV 2018\n- arXiv: https://arxiv.org/abs/1808.04285\n\n**Acquisition of Localization Confidence for Accurate Object Detection**\n\n- intro: ECCV 2018\n- arXiv: https://arxiv.org/abs/1807.11590\n- github: https://github.com/vacancy/PreciseRoIPooling\n\n**Toward Scale-Invariance and Position-Sensitive Region Proposal Networks**\n\n- intro: ECCV 2018\n- arXiv: https://arxiv.org/abs/1807.09528\n\n**MetaAnchor: Learning to Detect Objects with Customized Anchors**\n\n- arxiv: https://arxiv.org/abs/1807.00980\n\n**Relation Network for Object Detection**\n\n- intro: CVPR 2018\n- arxiv: https://arxiv.org/abs/1711.11575\n- github:https://github.com/msracver/Relation-Networks-for-Object-Detection\n\n**Quantization Mimic: Towards Very Tiny CNN for Object Detection**\n\n- Tsinghua University1 & The Chinese University of Hong Kong2 &SenseTime3\n- arxiv: https://arxiv.org/abs/1805.02152\n\n**Learning Rich Features for Image Manipulation Detection**\n\n- intro: CVPR 2018 Camera Ready\n- arxiv: https://arxiv.org/abs/1805.04953\n\n**SNIPER: Efficient Multi-Scale Training**\n\n- arxiv:https://arxiv.org/abs/1805.09300\n- github:https://github.com/mahyarnajibi/SNIPER\n\n**Soft Sampling for Robust Object Detection**\n\n- intro: the robustness of object detection under the presence of missing annotations\n- arxiv:https://arxiv.org/abs/1806.06986\n\n**Cost-effective Object Detection: Active Sample Mining with Switchable Selection Criteria**\n\n- intro: TNNLS 2018\n- arxiv:https://arxiv.org/abs/1807.00147\n- code: http://kezewang.com/codes/ASM_ver1.zip\n\n## Other\n\n**R3-Net: A Deep Network for Multi-oriented Vehicle Detection in Aerial Images and Videos**\n\n- arxiv: https://arxiv.org/abs/1808.05560\n- youtube: https://youtu.be/xCYD-tYudN0\n\n# Detection Toolbox\n\n- [Detectron(FAIR)](https://github.com/facebookresearch/Detectron): Detectron is Facebook AI Research's software system that implements state-of-the-art object detection algorithms, including [Mask R-CNN](https://arxiv.org/abs/1703.06870). It is written in Python and powered by the [Caffe2](https://github.com/caffe2/caffe2) deep learning framework.\n- [Detectron2](https://github.com/facebookresearch/detectron2): Detectron2 is FAIR's next-generation research platform for object detection and segmentation.\n- [maskrcnn-benchmark(FAIR)](https://github.com/facebookresearch/maskrcnn-benchmark): Fast, modular reference implementation of Instance Segmentation and Object Detection algorithms in PyTorch.\n- [mmdetection(SenseTime&CUHK)](https://github.com/open-mmlab/mmdetection): mmdetection is an open source object detection toolbox based on PyTorch. It is a part of the open-mmlab project developed by [Multimedia Laboratory, CUHK](http://mmlab.ie.cuhk.edu.hk/).\n","slug":"object-detection","published":1,"updated":"2024-06-13T15:00:51.493Z","comments":1,"layout":"post","photos":[],"_id":"cmh498ipo007iwvou1bf04qlm","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><ul>\n<li>R-CNN</li>\n<li>Fast R-CNN</li>\n<li>Faster R-CNN</li>\n<li>Mask R-CNN</li>\n<li>Light-Head R-CNN</li>\n<li>Cascade R-CNN</li>\n<li>SPP-Net</li>\n<li>YOLO</li>\n<li>YOLOv2</li>\n<li>YOLOv3</li>\n<li>YOLT</li>\n<li>SSD</li>\n<li>DSSD</li>\n<li>FSSD</li>\n<li>ESSD</li>\n<li>MDSSD</li>\n<li>Pelee</li>\n<li>Fire SSD</li>\n<li>R-FCN</li>\n<li>FPN</li>\n<li>DSOD</li>\n<li>RetinaNet</li>\n<li>MegDet</li>\n<li>RefineNet</li>\n<li>DetNet</li>\n<li>SSOD</li>\n<li>CornerNet</li>\n<li>M2Det</li>\n<li>3D Object Detection</li>\n<li>ZSD（Zero-Shot Object Detection）</li>\n<li>OSD（One-Shot object Detection）</li>\n<li>Weakly Supervised Object Detection</li>\n<li>Softer-NMS</li>\n<li>2018</li>\n<li>2019</li>\n<li>Other</li>\n</ul>\n<p>Based on handong1587’s github: <a href=\"https://handong1587.github.io/deep_learning/2015/10/09/object-detection.html\">https://handong1587.github.io/deep_learning/2015/10/09/object-detection.html</a></p>\n<h1 id=\"Survey\"><a href=\"#Survey\" class=\"headerlink\" title=\"Survey\"></a>Survey</h1><p><strong>Imbalance Problems in Object Detection: A Review</strong></p>\n<ul>\n<li>intro: under review at TPAMI</li>\n<li>arXiv: <a href=\"https://arxiv.org/abs/1909.00169\">https://arxiv.org/abs/1909.00169</a></li>\n</ul>\n<p><strong>Recent Advances in Deep Learning for Object Detection</strong></p>\n<ul>\n<li>intro: From 2013 (OverFeat) to 2019 (DetNAS)</li>\n<li>arXiv: <a href=\"https://arxiv.org/abs/1908.03673\">https://arxiv.org/abs/1908.03673</a></li>\n</ul>\n<p><strong>A Survey of Deep Learning-based Object Detection</strong></p>\n<ul>\n<li><p>intro：From Fast R-CNN to NAS-FPN</p>\n</li>\n<li><p>arXiv：<a href=\"https://arxiv.org/abs/1907.09408\">https://arxiv.org/abs/1907.09408</a></p>\n</li>\n</ul>\n<p><strong>Object Detection in 20 Years: A Survey</strong></p>\n<ul>\n<li>intro：This work has been submitted to the IEEE TPAMI for possible publication</li>\n<li>arXiv：<a href=\"https://arxiv.org/abs/1905.05055\">https://arxiv.org/abs/1905.05055</a></li>\n</ul>\n<p><strong>《Recent Advances in Object Detection in the Age of Deep Convolutional Neural Networks》</strong></p>\n<ul>\n<li><p>intro: awesome</p>\n</li>\n<li><p>arXiv: <a href=\"https://arxiv.org/abs/1809.03193\">https://arxiv.org/abs/1809.03193</a></p>\n</li>\n</ul>\n<p><strong>《Deep Learning for Generic Object Detection: A Survey》</strong></p>\n<ul>\n<li>intro: Submitted to IJCV 2018</li>\n<li>arXiv: <a href=\"https://arxiv.org/abs/1809.02165\">https://arxiv.org/abs/1809.02165</a></li>\n</ul>\n<h1 id=\"Papers-Codes\"><a href=\"#Papers-Codes\" class=\"headerlink\" title=\"Papers&amp;Codes\"></a>Papers&amp;Codes</h1><h2 id=\"R-CNN\"><a href=\"#R-CNN\" class=\"headerlink\" title=\"R-CNN\"></a>R-CNN</h2><p><strong>Rich feature hierarchies for accurate object detection and semantic segmentation</strong></p>\n<ul>\n<li>intro: R-CNN</li>\n<li>arxiv: <a href=\"http://arxiv.org/abs/1311.2524\">http://arxiv.org/abs/1311.2524</a></li>\n<li>supp: <a href=\"http://people.eecs.berkeley.edu/~rbg/papers/r-cnn-cvpr-supp.pdf\">http://people.eecs.berkeley.edu/~rbg/papers/r-cnn-cvpr-supp.pdf</a></li>\n<li>slides: <a href=\"http://www.image-net.org/challenges/LSVRC/2013/slides/r-cnn-ilsvrc2013-workshop.pdf\">http://www.image-net.org/challenges/LSVRC/2013/slides/r-cnn-ilsvrc2013-workshop.pdf</a></li>\n<li>slides: <a href=\"http://www.cs.berkeley.edu/~rbg/slides/rcnn-cvpr14-slides.pdf\">http://www.cs.berkeley.edu/~rbg/slides/rcnn-cvpr14-slides.pdf</a></li>\n<li>github: <a href=\"https://github.com/rbgirshick/rcnn\">https://github.com/rbgirshick/rcnn</a></li>\n<li>notes: <a href=\"http://zhangliliang.com/2014/07/23/paper-note-rcnn/\">http://zhangliliang.com/2014/07/23/paper-note-rcnn/</a></li>\n<li>caffe-pr(“Make R-CNN the Caffe detection example”): <a href=\"https://github.com/BVLC/caffe/pull/482\">https://github.com/BVLC/caffe/pull/482</a></li>\n</ul>\n<h2 id=\"Fast-R-CNN\"><a href=\"#Fast-R-CNN\" class=\"headerlink\" title=\"Fast R-CNN\"></a>Fast R-CNN</h2><p><strong>Fast R-CNN</strong></p>\n<ul>\n<li>arxiv: <a href=\"http://arxiv.org/abs/1504.08083\">http://arxiv.org/abs/1504.08083</a></li>\n<li>slides: <a href=\"http://tutorial.caffe.berkeleyvision.org/caffe-cvpr15-detection.pdf\">http://tutorial.caffe.berkeleyvision.org/caffe-cvpr15-detection.pdf</a></li>\n<li>github: <a href=\"https://github.com/rbgirshick/fast-rcnn\">https://github.com/rbgirshick/fast-rcnn</a></li>\n<li>github(COCO-branch): <a href=\"https://github.com/rbgirshick/fast-rcnn/tree/coco\">https://github.com/rbgirshick/fast-rcnn/tree/coco</a></li>\n<li>webcam demo: <a href=\"https://github.com/rbgirshick/fast-rcnn/pull/29\">https://github.com/rbgirshick/fast-rcnn/pull/29</a></li>\n<li>notes: <a href=\"http://zhangliliang.com/2015/05/17/paper-note-fast-rcnn/\">http://zhangliliang.com/2015/05/17/paper-note-fast-rcnn/</a></li>\n<li>notes: <a href=\"http://blog.csdn.net/linj_m/article/details/48930179\">http://blog.csdn.net/linj_m/article/details/48930179</a></li>\n<li>github(“Fast R-CNN in MXNet”): <a href=\"https://github.com/precedenceguo/mx-rcnn\">https://github.com/precedenceguo/mx-rcnn</a></li>\n<li>github: <a href=\"https://github.com/mahyarnajibi/fast-rcnn-torch\">https://github.com/mahyarnajibi/fast-rcnn-torch</a></li>\n<li>github: <a href=\"https://github.com/apple2373/chainer-simple-fast-rnn\">https://github.com/apple2373/chainer-simple-fast-rnn</a></li>\n<li>github: <a href=\"https://github.com/zplizzi/tensorflow-fast-rcnn\">https://github.com/zplizzi/tensorflow-fast-rcnn</a></li>\n</ul>\n<p><strong>A-Fast-RCNN: Hard Positive Generation via Adversary for Object Detection</strong></p>\n<ul>\n<li>intro: CVPR 2017</li>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1704.03414\">https://arxiv.org/abs/1704.03414</a></li>\n<li>paper: <a href=\"http://abhinavsh.info/papers/pdfs/adversarial_object_detection.pdf\">http://abhinavsh.info/papers/pdfs/adversarial_object_detection.pdf</a></li>\n<li>github(Caffe): <a href=\"https://github.com/xiaolonw/adversarial-frcnn\">https://github.com/xiaolonw/adversarial-frcnn</a></li>\n</ul>\n<h2 id=\"Faster-R-CNN\"><a href=\"#Faster-R-CNN\" class=\"headerlink\" title=\"Faster R-CNN\"></a>Faster R-CNN</h2><p><strong>Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks</strong></p>\n<ul>\n<li>intro: NIPS 2015</li>\n<li>arxiv: <a href=\"http://arxiv.org/abs/1506.01497\">http://arxiv.org/abs/1506.01497</a></li>\n<li>gitxiv: <a href=\"http://www.gitxiv.com/posts/8pfpcvefDYn2gSgXk/faster-r-cnn-towards-real-time-object-detection-with-region\">http://www.gitxiv.com/posts/8pfpcvefDYn2gSgXk/faster-r-cnn-towards-real-time-object-detection-with-region</a></li>\n<li>slides: <a href=\"http://web.cs.hacettepe.edu.tr/~aykut/classes/spring2016/bil722/slides/w05-FasterR-CNN.pdf\">http://web.cs.hacettepe.edu.tr/~aykut/classes/spring2016/bil722/slides/w05-FasterR-CNN.pdf</a></li>\n<li>github(official, Matlab): <a href=\"https://github.com/ShaoqingRen/faster_rcnn\">https://github.com/ShaoqingRen/faster_rcnn</a></li>\n<li>github(Caffe): <a href=\"https://github.com/rbgirshick/py-faster-rcnn\">https://github.com/rbgirshick/py-faster-rcnn</a></li>\n<li>github(MXNet): <a href=\"https://github.com/msracver/Deformable-ConvNets/tree/master/faster_rcnn\">https://github.com/msracver/Deformable-ConvNets/tree/master/faster_rcnn</a></li>\n<li>github(PyTorch–recommend): <a href=\"https://github.com//jwyang/faster-rcnn.pytorch\">https://github.com//jwyang/faster-rcnn.pytorch</a></li>\n<li>github: <a href=\"https://github.com/mitmul/chainer-faster-rcnn\">https://github.com/mitmul/chainer-faster-rcnn</a></li>\n<li>github(Torch):: <a href=\"https://github.com/andreaskoepf/faster-rcnn.torch\">https://github.com/andreaskoepf/faster-rcnn.torch</a></li>\n<li>github(Torch):: <a href=\"https://github.com/ruotianluo/Faster-RCNN-Densecap-torch\">https://github.com/ruotianluo/Faster-RCNN-Densecap-torch</a></li>\n<li>github(TensorFlow): <a href=\"https://github.com/smallcorgi/Faster-RCNN_TF\">https://github.com/smallcorgi/Faster-RCNN_TF</a></li>\n<li>github(TensorFlow): <a href=\"https://github.com/CharlesShang/TFFRCNN\">https://github.com/CharlesShang/TFFRCNN</a></li>\n<li>github(C++ demo): <a href=\"https://github.com/YihangLou/FasterRCNN-Encapsulation-Cplusplus\">https://github.com/YihangLou/FasterRCNN-Encapsulation-Cplusplus</a></li>\n<li>github(Keras): <a href=\"https://github.com/yhenon/keras-frcnn\">https://github.com/yhenon/keras-frcnn</a></li>\n<li>github: <a href=\"https://github.com/Eniac-Xie/faster-rcnn-resnet\">https://github.com/Eniac-Xie/faster-rcnn-resnet</a></li>\n<li>github(C++): <a href=\"https://github.com/D-X-Y/caffe-faster-rcnn/tree/dev\">https://github.com/D-X-Y/caffe-faster-rcnn/tree/dev</a></li>\n</ul>\n<p><strong>R-CNN minus R</strong></p>\n<ul>\n<li>intro: BMVC 2015</li>\n<li>arxiv: <a href=\"http://arxiv.org/abs/1506.06981\">http://arxiv.org/abs/1506.06981</a></li>\n</ul>\n<p><strong>Faster R-CNN in MXNet with distributed implementation and data parallelization</strong></p>\n<ul>\n<li>github: <a href=\"https://github.com/dmlc/mxnet/tree/master/example/rcnn\">https://github.com/dmlc/mxnet/tree/master/example/rcnn</a></li>\n</ul>\n<p><strong>Contextual Priming and Feedback for Faster R-CNN</strong></p>\n<ul>\n<li>intro: ECCV 2016. Carnegie Mellon University</li>\n<li>paper: <a href=\"http://abhinavsh.info/context_priming_feedback.pdf\">http://abhinavsh.info/context_priming_feedback.pdf</a></li>\n<li>poster: <a href=\"http://www.eccv2016.org/files/posters/P-1A-20.pdf\">http://www.eccv2016.org/files/posters/P-1A-20.pdf</a></li>\n</ul>\n<p><strong>An Implementation of Faster RCNN with Study for Region Sampling</strong></p>\n<ul>\n<li>intro: Technical Report, 3 pages. CMU</li>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1702.02138\">https://arxiv.org/abs/1702.02138</a></li>\n<li>github: <a href=\"https://github.com/endernewton/tf-faster-rcnn\">https://github.com/endernewton/tf-faster-rcnn</a></li>\n<li>github: <a href=\"https://github.com/ruotianluo/pytorch-faster-rcnn\">https://github.com/ruotianluo/pytorch-faster-rcnn</a></li>\n</ul>\n<p><strong>Interpretable R-CNN</strong></p>\n<ul>\n<li>intro: North Carolina State University &amp; Alibaba</li>\n<li>keywords: AND-OR Graph (AOG)</li>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1711.05226\">https://arxiv.org/abs/1711.05226</a></li>\n</ul>\n<p><strong>Domain Adaptive Faster R-CNN for Object Detection in the Wild</strong></p>\n<ul>\n<li>intro: CVPR 2018. ETH Zurich &amp; ESAT&#x2F;PSI</li>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1803.03243\">https://arxiv.org/abs/1803.03243</a></li>\n</ul>\n<h2 id=\"Mask-R-CNN\"><a href=\"#Mask-R-CNN\" class=\"headerlink\" title=\"Mask R-CNN\"></a>Mask R-CNN</h2><ul>\n<li>arxiv: <a href=\"http://arxiv.org/abs/1703.06870\">http://arxiv.org/abs/1703.06870</a></li>\n<li>github(Keras): <a href=\"https://github.com/matterport/Mask_RCNN\">https://github.com/matterport/Mask_RCNN</a></li>\n<li>github(Caffe2): <a href=\"https://github.com/facebookresearch/Detectron\">https://github.com/facebookresearch/Detectron</a></li>\n<li>github(Pytorch): <a href=\"https://github.com/wannabeOG/Mask-RCNN\">https://github.com/wannabeOG/Mask-RCNN</a></li>\n<li>github(MXNet): <a href=\"https://github.com/TuSimple/mx-maskrcnn\">https://github.com/TuSimple/mx-maskrcnn</a></li>\n<li>github(Chainer): <a href=\"https://github.com/DeNA/Chainer_Mask_R-CNN\">https://github.com/DeNA/Chainer_Mask_R-CNN</a></li>\n</ul>\n<h2 id=\"Light-Head-R-CNN\"><a href=\"#Light-Head-R-CNN\" class=\"headerlink\" title=\"Light-Head R-CNN\"></a>Light-Head R-CNN</h2><p><strong>Light-Head R-CNN: In Defense of Two-Stage Object Detector</strong></p>\n<ul>\n<li>intro: Tsinghua University &amp; Megvii Inc</li>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1711.07264\">https://arxiv.org/abs/1711.07264</a></li>\n<li>github(offical): <a href=\"https://github.com/zengarden/light_head_rcnn\">https://github.com/zengarden/light_head_rcnn</a></li>\n<li>github: <a href=\"https://github.com/terrychenism/Deformable-ConvNets/blob/master/rfcn/symbols/resnet_v1_101_rfcn_light.py#L784\">https://github.com/terrychenism/Deformable-ConvNets/blob/master/rfcn/symbols/resnet_v1_101_rfcn_light.py#L784</a></li>\n</ul>\n<h2 id=\"Cascade-R-CNN\"><a href=\"#Cascade-R-CNN\" class=\"headerlink\" title=\"Cascade R-CNN\"></a>Cascade R-CNN</h2><p><strong>Cascade R-CNN: Delving into High Quality Object Detection</strong></p>\n<ul>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1712.00726\">https://arxiv.org/abs/1712.00726</a></li>\n<li>github: <a href=\"https://github.com/zhaoweicai/cascade-rcnn\">https://github.com/zhaoweicai/cascade-rcnn</a></li>\n</ul>\n<h2 id=\"SPP-Net\"><a href=\"#SPP-Net\" class=\"headerlink\" title=\"SPP-Net\"></a>SPP-Net</h2><p><strong>Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition</strong></p>\n<ul>\n<li>intro: ECCV 2014 &#x2F; TPAMI 2015</li>\n<li>arxiv: <a href=\"http://arxiv.org/abs/1406.4729\">http://arxiv.org/abs/1406.4729</a></li>\n<li>github: <a href=\"https://github.com/ShaoqingRen/SPP_net\">https://github.com/ShaoqingRen/SPP_net</a></li>\n<li>notes: <a href=\"http://zhangliliang.com/2014/09/13/paper-note-sppnet/\">http://zhangliliang.com/2014/09/13/paper-note-sppnet/</a></li>\n</ul>\n<p><strong>DeepID-Net: Deformable Deep Convolutional Neural Networks for Object Detection</strong></p>\n<ul>\n<li>intro: PAMI 2016</li>\n<li>intro: an extension of R-CNN. box pre-training, cascade on region proposals, deformation layers and context representations</li>\n<li>project page: <a href=\"http://www.ee.cuhk.edu.hk/%CB%9Cwlouyang/projects/imagenetDeepId/index.html\">http://www.ee.cuhk.edu.hk/%CB%9Cwlouyang/projects/imagenetDeepId/index.html</a></li>\n<li>arxiv: <a href=\"http://arxiv.org/abs/1412.5661\">http://arxiv.org/abs/1412.5661</a></li>\n</ul>\n<p><strong>Object Detectors Emerge in Deep Scene CNNs</strong></p>\n<ul>\n<li>intro: ICLR 2015</li>\n<li>arxiv: <a href=\"http://arxiv.org/abs/1412.6856\">http://arxiv.org/abs/1412.6856</a></li>\n<li>paper: <a href=\"https://www.robots.ox.ac.uk/~vgg/rg/papers/zhou_iclr15.pdf\">https://www.robots.ox.ac.uk/~vgg/rg/papers/zhou_iclr15.pdf</a></li>\n<li>paper: <a href=\"https://people.csail.mit.edu/khosla/papers/iclr2015_zhou.pdf\">https://people.csail.mit.edu/khosla/papers/iclr2015_zhou.pdf</a></li>\n<li>slides: <a href=\"http://places.csail.mit.edu/slide_iclr2015.pdf\">http://places.csail.mit.edu/slide_iclr2015.pdf</a></li>\n</ul>\n<p><strong>segDeepM: Exploiting Segmentation and Context in Deep Neural Networks for Object Detection</strong></p>\n<ul>\n<li>intro: CVPR 2015</li>\n<li>project(code+data): <a href=\"https://www.cs.toronto.edu/~yukun/segdeepm.html\">https://www.cs.toronto.edu/~yukun/segdeepm.html</a></li>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1502.04275\">https://arxiv.org/abs/1502.04275</a></li>\n<li>github: <a href=\"https://github.com/YknZhu/segDeepM\">https://github.com/YknZhu/segDeepM</a></li>\n</ul>\n<p><strong>Object Detection Networks on Convolutional Feature Maps</strong></p>\n<ul>\n<li>intro: TPAMI 2015</li>\n<li>keywords: NoC</li>\n<li>arxiv: <a href=\"http://arxiv.org/abs/1504.06066\">http://arxiv.org/abs/1504.06066</a></li>\n</ul>\n<p><strong>Improving Object Detection with Deep Convolutional Networks via Bayesian Optimization and Structured Prediction</strong></p>\n<ul>\n<li>arxiv: <a href=\"http://arxiv.org/abs/1504.03293\">http://arxiv.org/abs/1504.03293</a></li>\n<li>slides: <a href=\"http://www.ytzhang.net/files/publications/2015-cvpr-det-slides.pdf\">http://www.ytzhang.net/files/publications/2015-cvpr-det-slides.pdf</a></li>\n<li>github: <a href=\"https://github.com/YutingZhang/fgs-obj\">https://github.com/YutingZhang/fgs-obj</a></li>\n</ul>\n<p><strong>DeepBox: Learning Objectness with Convolutional Networks</strong></p>\n<ul>\n<li>keywords: DeepBox</li>\n<li>arxiv: <a href=\"http://arxiv.org/abs/1505.02146\">http://arxiv.org/abs/1505.02146</a></li>\n<li>github: <a href=\"https://github.com/weichengkuo/DeepBox\">https://github.com/weichengkuo/DeepBox</a></li>\n</ul>\n<h2 id=\"YOLO\"><a href=\"#YOLO\" class=\"headerlink\" title=\"YOLO\"></a>YOLO</h2><p><strong>You Only Look Once: Unified, Real-Time Object Detection</strong></p>\n<p><a href=\"https://camo.githubusercontent.com/e69d4118b20a42de4e23b9549f9a6ec6dbbb0814/687474703a2f2f706a7265646469652e636f6d2f6d656469612f66696c65732f6461726b6e65742d626c61636b2d736d616c6c2e706e67\"><img src=\"https://camo.githubusercontent.com/e69d4118b20a42de4e23b9549f9a6ec6dbbb0814/687474703a2f2f706a7265646469652e636f6d2f6d656469612f66696c65732f6461726b6e65742d626c61636b2d736d616c6c2e706e67\" alt=\"img\"></a></p>\n<ul>\n<li>arxiv: <a href=\"http://arxiv.org/abs/1506.02640\">http://arxiv.org/abs/1506.02640</a></li>\n<li>code: <a href=\"https://pjreddie.com/darknet/yolov1/\">https://pjreddie.com/darknet/yolov1/</a></li>\n<li>github: <a href=\"https://github.com/pjreddie/darknet\">https://github.com/pjreddie/darknet</a></li>\n<li>blog: <a href=\"https://pjreddie.com/darknet/yolov1/\">https://pjreddie.com/darknet/yolov1/</a></li>\n<li>slides: <a href=\"https://docs.google.com/presentation/d/1aeRvtKG21KHdD5lg6Hgyhx5rPq_ZOsGjG5rJ1HP7BbA/pub?start=false&amp;loop=false&amp;delayms=3000&amp;slide=id.p\">https://docs.google.com/presentation/d/1aeRvtKG21KHdD5lg6Hgyhx5rPq_ZOsGjG5rJ1HP7BbA/pub?start=false&amp;loop=false&amp;delayms=3000&amp;slide=id.p</a></li>\n<li>reddit: <a href=\"https://www.reddit.com/r/MachineLearning/comments/3a3m0o/realtime_object_detection_with_yolo/\">https://www.reddit.com/r/MachineLearning/comments/3a3m0o/realtime_object_detection_with_yolo/</a></li>\n<li>github: <a href=\"https://github.com/gliese581gg/YOLO_tensorflow\">https://github.com/gliese581gg/YOLO_tensorflow</a></li>\n<li>github: <a href=\"https://github.com/xingwangsfu/caffe-yolo\">https://github.com/xingwangsfu/caffe-yolo</a></li>\n<li>github: <a href=\"https://github.com/frankzhangrui/Darknet-Yolo\">https://github.com/frankzhangrui/Darknet-Yolo</a></li>\n<li>github: <a href=\"https://github.com/BriSkyHekun/py-darknet-yolo\">https://github.com/BriSkyHekun/py-darknet-yolo</a></li>\n<li>github: <a href=\"https://github.com/tommy-qichang/yolo.torch\">https://github.com/tommy-qichang/yolo.torch</a></li>\n<li>github: <a href=\"https://github.com/frischzenger/yolo-windows\">https://github.com/frischzenger/yolo-windows</a></li>\n<li>github: <a href=\"https://github.com/AlexeyAB/yolo-windows\">https://github.com/AlexeyAB/yolo-windows</a></li>\n<li>github: <a href=\"https://github.com/nilboy/tensorflow-yolo\">https://github.com/nilboy/tensorflow-yolo</a></li>\n</ul>\n<p><strong>darkflow - translate darknet to tensorflow. Load trained weights, retrain&#x2F;fine-tune them using tensorflow, export constant graph def to C++</strong></p>\n<ul>\n<li>blog: <a href=\"https://thtrieu.github.io/notes/yolo-tensorflow-graph-buffer-cpp\">https://thtrieu.github.io/notes/yolo-tensorflow-graph-buffer-cpp</a></li>\n<li>github: <a href=\"https://github.com/thtrieu/darkflow\">https://github.com/thtrieu/darkflow</a></li>\n</ul>\n<p><strong>Start Training YOLO with Our Own Data</strong></p>\n<p><a href=\"https://camo.githubusercontent.com/2f99b692dd7ce47d7832385f3e8a6654e680d92a/687474703a2f2f6775616e6768616e2e696e666f2f626c6f672f656e2f77702d636f6e74656e742f75706c6f6164732f323031352f31322f696d616765732d34302e6a7067\"><img src=\"https://camo.githubusercontent.com/2f99b692dd7ce47d7832385f3e8a6654e680d92a/687474703a2f2f6775616e6768616e2e696e666f2f626c6f672f656e2f77702d636f6e74656e742f75706c6f6164732f323031352f31322f696d616765732d34302e6a7067\" alt=\"img\"></a></p>\n<ul>\n<li>intro: train with customized data and class numbers&#x2F;labels. Linux &#x2F; Windows version for darknet.</li>\n<li>blog: <a href=\"http://guanghan.info/blog/en/my-works/train-yolo/\">http://guanghan.info/blog/en/my-works/train-yolo/</a></li>\n<li>github: <a href=\"https://github.com/Guanghan/darknet\">https://github.com/Guanghan/darknet</a></li>\n</ul>\n<p><strong>YOLO: Core ML versus MPSNNGraph</strong></p>\n<ul>\n<li>intro: Tiny YOLO for iOS implemented using CoreML but also using the new MPS graph API.</li>\n<li>blog: <a href=\"http://machinethink.net/blog/yolo-coreml-versus-mps-graph/\">http://machinethink.net/blog/yolo-coreml-versus-mps-graph/</a></li>\n<li>github: <a href=\"https://github.com/hollance/YOLO-CoreML-MPSNNGraph\">https://github.com/hollance/YOLO-CoreML-MPSNNGraph</a></li>\n</ul>\n<p><strong>TensorFlow YOLO object detection on Android</strong></p>\n<ul>\n<li>intro: Real-time object detection on Android using the YOLO network with TensorFlow</li>\n<li>github: <a href=\"https://github.com/natanielruiz/android-yolo\">https://github.com/natanielruiz/android-yolo</a></li>\n</ul>\n<p><strong>Computer Vision in iOS – Object Detection</strong></p>\n<ul>\n<li>blog: <a href=\"https://sriraghu.com/2017/07/12/computer-vision-in-ios-object-detection/\">https://sriraghu.com/2017/07/12/computer-vision-in-ios-object-detection/</a></li>\n<li>github:<a href=\"https://github.com/r4ghu/iOS-CoreML-Yolo\">https://github.com/r4ghu/iOS-CoreML-Yolo</a></li>\n</ul>\n<h2 id=\"YOLOv2\"><a href=\"#YOLOv2\" class=\"headerlink\" title=\"YOLOv2\"></a>YOLOv2</h2><p><strong>YOLO9000: Better, Faster, Stronger</strong></p>\n<ul>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1612.08242\">https://arxiv.org/abs/1612.08242</a></li>\n<li>code: <a href=\"http://pjreddie.com/yolo9000/\">http://pjreddie.com/yolo9000/</a>    <a href=\"https://pjreddie.com/darknet/yolov2/\">https://pjreddie.com/darknet/yolov2/</a></li>\n<li>github(Chainer): <a href=\"https://github.com/leetenki/YOLOv2\">https://github.com/leetenki/YOLOv2</a></li>\n<li>github(Keras): <a href=\"https://github.com/allanzelener/YAD2K\">https://github.com/allanzelener/YAD2K</a></li>\n<li>github(PyTorch): <a href=\"https://github.com/longcw/yolo2-pytorch\">https://github.com/longcw/yolo2-pytorch</a></li>\n<li>github(Tensorflow): <a href=\"https://github.com/hizhangp/yolo_tensorflow\">https://github.com/hizhangp/yolo_tensorflow</a></li>\n<li>github(Windows): <a href=\"https://github.com/AlexeyAB/darknet\">https://github.com/AlexeyAB/darknet</a></li>\n<li>github: <a href=\"https://github.com/choasUp/caffe-yolo9000\">https://github.com/choasUp/caffe-yolo9000</a></li>\n<li>github: <a href=\"https://github.com/philipperemy/yolo-9000\">https://github.com/philipperemy/yolo-9000</a></li>\n<li>github(TensorFlow): <a href=\"https://github.com/KOD-Chen/YOLOv2-Tensorflow\">https://github.com/KOD-Chen/YOLOv2-Tensorflow</a></li>\n<li>github(Keras): <a href=\"https://github.com/yhcc/yolo2\">https://github.com/yhcc/yolo2</a></li>\n<li>github(Keras): <a href=\"https://github.com/experiencor/keras-yolo2\">https://github.com/experiencor/keras-yolo2</a></li>\n<li>github(TensorFlow): <a href=\"https://github.com/WojciechMormul/yolo2\">https://github.com/WojciechMormul/yolo2</a></li>\n</ul>\n<p><strong>darknet_scripts</strong></p>\n<ul>\n<li>intro: Auxilary scripts to work with (YOLO) darknet deep learning famework. AKA -&gt; How to generate YOLO anchors?</li>\n<li>github: <a href=\"https://github.com/Jumabek/darknet_scripts\">https://github.com/Jumabek/darknet_scripts</a></li>\n</ul>\n<p><strong>Yolo_mark: GUI for marking bounded boxes of objects in images for training Yolo v2</strong></p>\n<ul>\n<li>github: <a href=\"https://github.com/AlexeyAB/Yolo_mark\">https://github.com/AlexeyAB/Yolo_mark</a></li>\n</ul>\n<p><strong>LightNet: Bringing pjreddie’s DarkNet out of the shadows</strong></p>\n<p><a href=\"https://github.com//explosion/lightnet\">https://github.com//explosion/lightnet</a></p>\n<p><strong>YOLO v2 Bounding Box Tool</strong></p>\n<ul>\n<li>intro: Bounding box labeler tool to generate the training data in the format YOLO v2 requires.</li>\n<li>github: <a href=\"https://github.com/Cartucho/yolo-boundingbox-labeler-GUI\">https://github.com/Cartucho/yolo-boundingbox-labeler-GUI</a></li>\n</ul>\n<p><strong>Loss Rank Mining: A General Hard Example Mining Method for Real-time Detectors</strong></p>\n<ul>\n<li>intro: <strong>LRM</strong> is the first hard example mining strategy which could fit YOLOv2 perfectly and make it better applied in series of real scenarios where both real-time rates and accurate detection are strongly demanded.</li>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1804.04606\">https://arxiv.org/abs/1804.04606</a></li>\n</ul>\n<p><strong>Object detection at 200 Frames Per Second</strong></p>\n<ul>\n<li>intro: faster than Tiny-Yolo-v2</li>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1805.06361\">https://arxiv.org/abs/1805.06361</a></li>\n</ul>\n<p><strong>Event-based Convolutional Networks for Object Detection in Neuromorphic Cameras</strong></p>\n<ul>\n<li>intro: YOLE–Object Detection in Neuromorphic Cameras</li>\n<li>arxiv:<a href=\"https://arxiv.org/abs/1805.07931\">https://arxiv.org/abs/1805.07931</a></li>\n</ul>\n<p><strong>OmniDetector: With Neural Networks to Bounding Boxes</strong></p>\n<ul>\n<li>intro: a person detector on n fish-eye images of indoor scenes（NIPS 2018）</li>\n<li>arxiv:<a href=\"https://arxiv.org/abs/1805.08503\">https://arxiv.org/abs/1805.08503</a></li>\n<li>datasets:<a href=\"https://gitlab.com/omnidetector/omnidetector\">https://gitlab.com/omnidetector/omnidetector</a></li>\n</ul>\n<h2 id=\"YOLOv3\"><a href=\"#YOLOv3\" class=\"headerlink\" title=\"YOLOv3\"></a>YOLOv3</h2><p><strong>YOLOv3: An Incremental Improvement</strong></p>\n<ul>\n<li>arxiv:<a href=\"https://arxiv.org/abs/1804.02767\">https://arxiv.org/abs/1804.02767</a></li>\n<li>paper:<a href=\"https://pjreddie.com/media/files/papers/YOLOv3.pdf\">https://pjreddie.com/media/files/papers/YOLOv3.pdf</a></li>\n<li>code: <a href=\"https://pjreddie.com/darknet/yolo/\">https://pjreddie.com/darknet/yolo/</a></li>\n<li>github(Official):<a href=\"https://github.com/pjreddie/darknet\">https://github.com/pjreddie/darknet</a></li>\n<li>github:<a href=\"https://github.com/mystic123/tensorflow-yolo-v3\">https://github.com/mystic123/tensorflow-yolo-v3</a></li>\n<li>github:<a href=\"https://github.com/experiencor/keras-yolo3\">https://github.com/experiencor/keras-yolo3</a></li>\n<li>github:<a href=\"https://github.com/qqwweee/keras-yolo3\">https://github.com/qqwweee/keras-yolo3</a></li>\n<li>github:<a href=\"https://github.com/marvis/pytorch-yolo3\">https://github.com/marvis/pytorch-yolo3</a></li>\n<li>github:<a href=\"https://github.com/ayooshkathuria/pytorch-yolo-v3\">https://github.com/ayooshkathuria/pytorch-yolo-v3</a></li>\n<li>github:<a href=\"https://github.com/ayooshkathuria/YOLO_v3_tutorial_from_scratch\">https://github.com/ayooshkathuria/YOLO_v3_tutorial_from_scratch</a></li>\n<li>github:<a href=\"https://github.com/eriklindernoren/PyTorch-YOLOv3\">https://github.com/eriklindernoren/PyTorch-YOLOv3</a></li>\n<li>github:<a href=\"https://github.com/ultralytics/yolov3\">https://github.com/ultralytics/yolov3</a></li>\n<li>github:<a href=\"https://github.com/BobLiu20/YOLOv3_PyTorch\">https://github.com/BobLiu20/YOLOv3_PyTorch</a></li>\n<li>github:<a href=\"https://github.com/andy-yun/pytorch-0.4-yolov3\">https://github.com/andy-yun/pytorch-0.4-yolov3</a></li>\n<li>github:<a href=\"https://github.com/DeNA/PyTorch_YOLOv3\">https://github.com/DeNA/PyTorch_YOLOv3</a></li>\n</ul>\n<h2 id=\"YOLT\"><a href=\"#YOLT\" class=\"headerlink\" title=\"YOLT\"></a>YOLT</h2><p><strong>You Only Look Twice: Rapid Multi-Scale Object Detection In Satellite Imagery</strong></p>\n<ul>\n<li><p>intro: Small Object Detection</p>\n</li>\n<li><p>arxiv:<a href=\"https://arxiv.org/abs/1805.09512\">https://arxiv.org/abs/1805.09512</a></p>\n</li>\n<li><p>github:<a href=\"https://github.com/avanetten/yolt\">https://github.com/avanetten/yolt</a></p>\n</li>\n</ul>\n<h2 id=\"SSD\"><a href=\"#SSD\" class=\"headerlink\" title=\"SSD\"></a>SSD</h2><p><strong>SSD: Single Shot MultiBox Detector</strong></p>\n<p><a href=\"https://camo.githubusercontent.com/ad9b147ed3a5f48ffb7c3540711c15aa04ce49c6/687474703a2f2f7777772e63732e756e632e6564752f7e776c69752f7061706572732f7373642e706e67\"><img src=\"https://camo.githubusercontent.com/ad9b147ed3a5f48ffb7c3540711c15aa04ce49c6/687474703a2f2f7777772e63732e756e632e6564752f7e776c69752f7061706572732f7373642e706e67\" alt=\"img\"></a></p>\n<ul>\n<li>intro: ECCV 2016 Oral</li>\n<li>arxiv: <a href=\"http://arxiv.org/abs/1512.02325\">http://arxiv.org/abs/1512.02325</a></li>\n<li>paper: <a href=\"http://www.cs.unc.edu/~wliu/papers/ssd.pdf\">http://www.cs.unc.edu/~wliu/papers/ssd.pdf</a></li>\n<li>slides: <a href=\"http://www.cs.unc.edu/~wliu/papers/ssd_eccv2016_slide.pdf\">http://www.cs.unc.edu/%7Ewliu/papers/ssd_eccv2016_slide.pdf</a></li>\n<li>github(Official): <a href=\"https://github.com/weiliu89/caffe/tree/ssd\">https://github.com/weiliu89/caffe/tree/ssd</a></li>\n<li>video: <a href=\"http://weibo.com/p/2304447a2326da963254c963c97fb05dd3a973\">http://weibo.com/p/2304447a2326da963254c963c97fb05dd3a973</a></li>\n<li>github: <a href=\"https://github.com/zhreshold/mxnet-ssd\">https://github.com/zhreshold/mxnet-ssd</a></li>\n<li>github: <a href=\"https://github.com/zhreshold/mxnet-ssd.cpp\">https://github.com/zhreshold/mxnet-ssd.cpp</a></li>\n<li>github: <a href=\"https://github.com/rykov8/ssd_keras\">https://github.com/rykov8/ssd_keras</a></li>\n<li>github: <a href=\"https://github.com/balancap/SSD-Tensorflow\">https://github.com/balancap/SSD-Tensorflow</a></li>\n<li>github: <a href=\"https://github.com/amdegroot/ssd.pytorch\">https://github.com/amdegroot/ssd.pytorch</a></li>\n<li>github(Caffe): <a href=\"https://github.com/chuanqi305/MobileNet-SSD\">https://github.com/chuanqi305/MobileNet-SSD</a></li>\n</ul>\n<p><strong>What’s the diffience in performance between this new code you pushed and the previous code? #327</strong></p>\n<p><a href=\"https://github.com/weiliu89/caffe/issues/327\">https://github.com/weiliu89/caffe/issues/327</a></p>\n<h2 id=\"DSSD\"><a href=\"#DSSD\" class=\"headerlink\" title=\"DSSD\"></a>DSSD</h2><p><strong>DSSD : Deconvolutional Single Shot Detector</strong></p>\n<ul>\n<li>intro: UNC Chapel Hill &amp; Amazon Inc</li>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1701.06659\">https://arxiv.org/abs/1701.06659</a></li>\n<li>github: <a href=\"https://github.com/chengyangfu/caffe/tree/dssd\">https://github.com/chengyangfu/caffe/tree/dssd</a></li>\n<li>github: <a href=\"https://github.com/MTCloudVision/mxnet-dssd\">https://github.com/MTCloudVision/mxnet-dssd</a></li>\n<li>demo: <a href=\"http://120.52.72.53/www.cs.unc.edu/c3pr90ntc0td/~cyfu/dssd_lalaland.mp4\">http://120.52.72.53/www.cs.unc.edu/c3pr90ntc0td/~cyfu/dssd_lalaland.mp4</a></li>\n</ul>\n<p><strong>Enhancement of SSD by concatenating feature maps for object detection</strong></p>\n<ul>\n<li>intro: rainbow SSD (R-SSD)</li>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1705.09587\">https://arxiv.org/abs/1705.09587</a></li>\n</ul>\n<p><strong>Context-aware Single-Shot Detector</strong></p>\n<ul>\n<li>keywords: CSSD, DiCSSD, DeCSSD, effective receptive fields (ERFs), theoretical receptive fields (TRFs)</li>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1707.08682\">https://arxiv.org/abs/1707.08682</a></li>\n</ul>\n<p><strong>Feature-Fused SSD: Fast Detection for Small Objects</strong></p>\n<p><a href=\"https://arxiv.org/abs/1709.05054\">https://arxiv.org/abs/1709.05054</a></p>\n<h2 id=\"FSSD\"><a href=\"#FSSD\" class=\"headerlink\" title=\"FSSD\"></a>FSSD</h2><p><strong>FSSD: Feature Fusion Single Shot Multibox Detector</strong></p>\n<p><a href=\"https://arxiv.org/abs/1712.00960\">https://arxiv.org/abs/1712.00960</a></p>\n<p><strong>Weaving Multi-scale Context for Single Shot Detector</strong></p>\n<ul>\n<li>intro: WeaveNet</li>\n<li>keywords: fuse multi-scale information</li>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1712.03149\">https://arxiv.org/abs/1712.03149</a></li>\n</ul>\n<h2 id=\"ESSD\"><a href=\"#ESSD\" class=\"headerlink\" title=\"ESSD\"></a>ESSD</h2><p><strong>Extend the shallow part of Single Shot MultiBox Detector via Convolutional Neural Network</strong></p>\n<p><a href=\"https://arxiv.org/abs/1801.05918\">https://arxiv.org/abs/1801.05918</a></p>\n<p><strong>Tiny SSD: A Tiny Single-shot Detection Deep Convolutional Neural Network for Real-time Embedded Object Detection</strong></p>\n<p><a href=\"https://arxiv.org/abs/1802.06488\">https://arxiv.org/abs/1802.06488</a></p>\n<h2 id=\"MDSSD\"><a href=\"#MDSSD\" class=\"headerlink\" title=\"MDSSD\"></a>MDSSD</h2><p><strong>MDSSD: Multi-scale Deconvolutional Single Shot Detector for small objects</strong></p>\n<ul>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1805.07009\">https://arxiv.org/abs/1805.07009</a></li>\n</ul>\n<h2 id=\"Pelee\"><a href=\"#Pelee\" class=\"headerlink\" title=\"Pelee\"></a>Pelee</h2><p><strong>Pelee: A Real-Time Object Detection System on Mobile Devices</strong></p>\n<p><a href=\"https://github.com/Robert-JunWang/Pelee\">https://github.com/Robert-JunWang/Pelee</a></p>\n<ul>\n<li><p>intro: (ICLR 2018 workshop track)</p>\n</li>\n<li><p>arxiv: <a href=\"https://arxiv.org/abs/1804.06882\">https://arxiv.org/abs/1804.06882</a></p>\n</li>\n<li><p>github: <a href=\"https://github.com/Robert-JunWang/Pelee\">https://github.com/Robert-JunWang/Pelee</a></p>\n</li>\n</ul>\n<h2 id=\"Fire-SSD\"><a href=\"#Fire-SSD\" class=\"headerlink\" title=\"Fire SSD\"></a>Fire SSD</h2><p><strong>Fire SSD: Wide Fire Modules based Single Shot Detector on Edge Device</strong></p>\n<ul>\n<li><p>intro:low cost, fast speed and high mAP on  factor edge computing devices</p>\n</li>\n<li><p>arxiv:<a href=\"https://arxiv.org/abs/1806.05363\">https://arxiv.org/abs/1806.05363</a></p>\n</li>\n</ul>\n<h2 id=\"R-FCN\"><a href=\"#R-FCN\" class=\"headerlink\" title=\"R-FCN\"></a>R-FCN</h2><p><strong>R-FCN: Object Detection via Region-based Fully Convolutional Networks</strong></p>\n<ul>\n<li>arxiv: <a href=\"http://arxiv.org/abs/1605.06409\">http://arxiv.org/abs/1605.06409</a></li>\n<li>github: <a href=\"https://github.com/daijifeng001/R-FCN\">https://github.com/daijifeng001/R-FCN</a></li>\n<li>github(MXNet): <a href=\"https://github.com/msracver/Deformable-ConvNets/tree/master/rfcn\">https://github.com/msracver/Deformable-ConvNets/tree/master/rfcn</a></li>\n<li>github: <a href=\"https://github.com/Orpine/py-R-FCN\">https://github.com/Orpine/py-R-FCN</a></li>\n<li>github: <a href=\"https://github.com/PureDiors/pytorch_RFCN\">https://github.com/PureDiors/pytorch_RFCN</a></li>\n<li>github: <a href=\"https://github.com/bharatsingh430/py-R-FCN-multiGPU\">https://github.com/bharatsingh430/py-R-FCN-multiGPU</a></li>\n<li>github: <a href=\"https://github.com/xdever/RFCN-tensorflow\">https://github.com/xdever/RFCN-tensorflow</a></li>\n</ul>\n<p><strong>R-FCN-3000 at 30fps: Decoupling Detection and Classification</strong></p>\n<p><a href=\"https://arxiv.org/abs/1712.01802\">https://arxiv.org/abs/1712.01802</a></p>\n<p><strong>Recycle deep features for better object detection</strong></p>\n<ul>\n<li>arxiv: <a href=\"http://arxiv.org/abs/1607.05066\">http://arxiv.org/abs/1607.05066</a></li>\n</ul>\n<h2 id=\"FPN\"><a href=\"#FPN\" class=\"headerlink\" title=\"FPN\"></a>FPN</h2><p><strong>Feature Pyramid Networks for Object Detection</strong></p>\n<ul>\n<li>intro: Facebook AI Research</li>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1612.03144\">https://arxiv.org/abs/1612.03144</a></li>\n</ul>\n<p><strong>Action-Driven Object Detection with Top-Down Visual Attentions</strong></p>\n<ul>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1612.06704\">https://arxiv.org/abs/1612.06704</a></li>\n</ul>\n<p><strong>Beyond Skip Connections: Top-Down Modulation for Object Detection</strong></p>\n<ul>\n<li>intro: CMU &amp; UC Berkeley &amp; Google Research</li>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1612.06851\">https://arxiv.org/abs/1612.06851</a></li>\n</ul>\n<p><strong>Wide-Residual-Inception Networks for Real-time Object Detection</strong></p>\n<ul>\n<li>intro: Inha University</li>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1702.01243\">https://arxiv.org/abs/1702.01243</a></li>\n</ul>\n<p><strong>Attentional Network for Visual Object Detection</strong></p>\n<ul>\n<li>intro: University of Maryland &amp; Mitsubishi Electric Research Laboratories</li>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1702.01478\">https://arxiv.org/abs/1702.01478</a></li>\n</ul>\n<p><strong>Learning Chained Deep Features and Classifiers for Cascade in Object Detection</strong></p>\n<ul>\n<li>keykwords: CC-Net</li>\n<li>intro: chained cascade network (CC-Net). 81.1% mAP on PASCAL VOC 2007</li>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1702.07054\">https://arxiv.org/abs/1702.07054</a></li>\n</ul>\n<p><strong>DeNet: Scalable Real-time Object Detection with Directed Sparse Sampling</strong></p>\n<ul>\n<li>intro: ICCV 2017 (poster)</li>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1703.10295\">https://arxiv.org/abs/1703.10295</a></li>\n</ul>\n<p><strong>Discriminative Bimodal Networks for Visual Localization and Detection with Natural Language Queries</strong></p>\n<ul>\n<li>intro: CVPR 2017</li>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1704.03944\">https://arxiv.org/abs/1704.03944</a></li>\n</ul>\n<p><strong>Spatial Memory for Context Reasoning in Object Detection</strong></p>\n<ul>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1704.04224\">https://arxiv.org/abs/1704.04224</a></li>\n</ul>\n<p><strong>Accurate Single Stage Detector Using Recurrent Rolling Convolution</strong></p>\n<ul>\n<li>intro: CVPR 2017. SenseTime</li>\n<li>keywords: Recurrent Rolling Convolution (RRC)</li>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1704.05776\">https://arxiv.org/abs/1704.05776</a></li>\n<li>github: <a href=\"https://github.com/xiaohaoChen/rrc_detection\">https://github.com/xiaohaoChen/rrc_detection</a></li>\n</ul>\n<p><strong>Deep Occlusion Reasoning for Multi-Camera Multi-Target Detection</strong></p>\n<p><a href=\"https://arxiv.org/abs/1704.05775\">https://arxiv.org/abs/1704.05775</a></p>\n<p><strong>LCDet: Low-Complexity Fully-Convolutional Neural Networks for Object Detection in Embedded Systems</strong></p>\n<ul>\n<li>intro: Embedded Vision Workshop in CVPR. UC San Diego &amp; Qualcomm Inc</li>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1705.05922\">https://arxiv.org/abs/1705.05922</a></li>\n</ul>\n<p><strong>Point Linking Network for Object Detection</strong></p>\n<ul>\n<li>intro: Point Linking Network (PLN)</li>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1706.03646\">https://arxiv.org/abs/1706.03646</a></li>\n</ul>\n<p><strong>Perceptual Generative Adversarial Networks for Small Object Detection</strong></p>\n<p><a href=\"https://arxiv.org/abs/1706.05274\">https://arxiv.org/abs/1706.05274</a></p>\n<p><strong>Few-shot Object Detection</strong></p>\n<p><a href=\"https://arxiv.org/abs/1706.08249\">https://arxiv.org/abs/1706.08249</a></p>\n<p><strong>Yes-Net: An effective Detector Based on Global Information</strong></p>\n<p><a href=\"https://arxiv.org/abs/1706.09180\">https://arxiv.org/abs/1706.09180</a></p>\n<p><strong>SMC Faster R-CNN: Toward a scene-specialized multi-object detector</strong></p>\n<p><a href=\"https://arxiv.org/abs/1706.10217\">https://arxiv.org/abs/1706.10217</a></p>\n<p><strong>Towards lightweight convolutional neural networks for object detection</strong></p>\n<p><a href=\"https://arxiv.org/abs/1707.01395\">https://arxiv.org/abs/1707.01395</a></p>\n<p><strong>RON: Reverse Connection with Objectness Prior Networks for Object Detection</strong></p>\n<ul>\n<li>intro: CVPR 2017</li>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1707.01691\">https://arxiv.org/abs/1707.01691</a></li>\n<li>github: <a href=\"https://github.com/taokong/RON\">https://github.com/taokong/RON</a></li>\n</ul>\n<p><strong>Mimicking Very Efficient Network for Object Detection</strong></p>\n<ul>\n<li>intro: CVPR 2017. SenseTime &amp; Beihang University</li>\n<li>paper: <a href=\"http://openaccess.thecvf.com/content_cvpr_2017/papers/Li_Mimicking_Very_Efficient_CVPR_2017_paper.pdf\">http://openaccess.thecvf.com/content_cvpr_2017/papers/Li_Mimicking_Very_Efficient_CVPR_2017_paper.pdf</a></li>\n</ul>\n<p><strong>Residual Features and Unified Prediction Network for Single Stage Detection</strong></p>\n<p><a href=\"https://arxiv.org/abs/1707.05031\">https://arxiv.org/abs/1707.05031</a></p>\n<p><strong>Deformable Part-based Fully Convolutional Network for Object Detection</strong></p>\n<ul>\n<li>intro: BMVC 2017 (oral). Sorbonne Universités &amp; CEDRIC</li>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1707.06175\">https://arxiv.org/abs/1707.06175</a></li>\n</ul>\n<p><strong>Adaptive Feeding: Achieving Fast and Accurate Detections by Adaptively Combining Object Detectors</strong></p>\n<ul>\n<li>intro: ICCV 2017</li>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1707.06399\">https://arxiv.org/abs/1707.06399</a></li>\n</ul>\n<p><strong>Recurrent Scale Approximation for Object Detection in CNN</strong></p>\n<ul>\n<li>intro: ICCV 2017</li>\n<li>keywords: Recurrent Scale Approximation (RSA)</li>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1707.09531\">https://arxiv.org/abs/1707.09531</a></li>\n<li>github: <a href=\"https://github.com/sciencefans/RSA-for-object-detection\">https://github.com/sciencefans/RSA-for-object-detection</a></li>\n</ul>\n<h2 id=\"DSOD\"><a href=\"#DSOD\" class=\"headerlink\" title=\"DSOD\"></a>DSOD</h2><p><strong>DSOD: Learning Deeply Supervised Object Detectors from Scratch</strong></p>\n<p><img src=\"https://user-images.githubusercontent.com/3794909/28934967-718c9302-78b5-11e7-89ee-8b514e53e23c.png\" alt=\"img\"></p>\n<ul>\n<li>intro: ICCV 2017. Fudan University &amp; Tsinghua University &amp; Intel Labs China</li>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1708.01241\">https://arxiv.org/abs/1708.01241</a></li>\n<li>github: <a href=\"https://github.com/szq0214/DSOD\">https://github.com/szq0214/DSOD</a></li>\n<li>github:<a href=\"https://github.com/Windaway/DSOD-Tensorflow\">https://github.com/Windaway/DSOD-Tensorflow</a></li>\n<li>github:<a href=\"https://github.com/chenyuntc/dsod.pytorch\">https://github.com/chenyuntc/dsod.pytorch</a></li>\n</ul>\n<p><strong>Learning Object Detectors from Scratch with Gated Recurrent Feature Pyramids</strong></p>\n<ul>\n<li>arxiv:<a href=\"https://arxiv.org/abs/1712.00886\">https://arxiv.org/abs/1712.00886</a></li>\n<li>github:<a href=\"https://github.com/szq0214/GRP-DSOD\">https://github.com/szq0214/GRP-DSOD</a></li>\n</ul>\n<p><strong>Tiny-DSOD: Lightweight Object Detection for Resource-Restricted Usages</strong></p>\n<ul>\n<li>intro: BMVC 2018</li>\n<li>arXiv: <a href=\"https://arxiv.org/abs/1807.11013\">https://arxiv.org/abs/1807.11013</a></li>\n</ul>\n<p><strong>Object Detection from Scratch with Deep Supervision</strong></p>\n<ul>\n<li>intro: This is an extended version of DSOD</li>\n<li>arXiv: <a href=\"https://arxiv.org/abs/1809.09294\">https://arxiv.org/abs/1809.09294</a></li>\n</ul>\n<h2 id=\"RetinaNet\"><a href=\"#RetinaNet\" class=\"headerlink\" title=\"RetinaNet\"></a>RetinaNet</h2><p><strong>Focal Loss for Dense Object Detection</strong></p>\n<ul>\n<li>intro: ICCV 2017 Best student paper award. Facebook AI Research</li>\n<li>keywords: RetinaNet</li>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1708.02002\">https://arxiv.org/abs/1708.02002</a></li>\n</ul>\n<p><strong>CoupleNet: Coupling Global Structure with Local Parts for Object Detection</strong></p>\n<ul>\n<li>intro: ICCV 2017</li>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1708.02863\">https://arxiv.org/abs/1708.02863</a></li>\n</ul>\n<p><strong>Incremental Learning of Object Detectors without Catastrophic Forgetting</strong></p>\n<ul>\n<li>intro: ICCV 2017. Inria</li>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1708.06977\">https://arxiv.org/abs/1708.06977</a></li>\n</ul>\n<p><strong>Zoom Out-and-In Network with Map Attention Decision for Region Proposal and Object Detection</strong></p>\n<p><a href=\"https://arxiv.org/abs/1709.04347\">https://arxiv.org/abs/1709.04347</a></p>\n<p><strong>StairNet: Top-Down Semantic Aggregation for Accurate One Shot Detection</strong></p>\n<p><a href=\"https://arxiv.org/abs/1709.05788\">https://arxiv.org/abs/1709.05788</a></p>\n<p><strong>Dynamic Zoom-in Network for Fast Object Detection in Large Images</strong></p>\n<p><a href=\"https://arxiv.org/abs/1711.05187\">https://arxiv.org/abs/1711.05187</a></p>\n<p><strong>Zero-Annotation Object Detection with Web Knowledge Transfer</strong></p>\n<ul>\n<li>intro: NTU, Singapore &amp; Amazon</li>\n<li>keywords: multi-instance multi-label domain adaption learning framework</li>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1711.05954\">https://arxiv.org/abs/1711.05954</a></li>\n</ul>\n<h2 id=\"MegDet\"><a href=\"#MegDet\" class=\"headerlink\" title=\"MegDet\"></a>MegDet</h2><p><strong>MegDet: A Large Mini-Batch Object Detector</strong></p>\n<ul>\n<li>intro: Peking University &amp; Tsinghua University &amp; Megvii Inc</li>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1711.07240\">https://arxiv.org/abs/1711.07240</a></li>\n</ul>\n<p><strong>Receptive Field Block Net for Accurate and Fast Object Detection</strong></p>\n<ul>\n<li>intro: RFBNet</li>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1711.07767\">https://arxiv.org/abs/1711.07767</a></li>\n<li>github: <a href=\"https://github.com//ruinmessi/RFBNet\">https://github.com//ruinmessi/RFBNet</a></li>\n</ul>\n<p><strong>An Analysis of Scale Invariance in Object Detection - SNIP</strong></p>\n<ul>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1711.08189\">https://arxiv.org/abs/1711.08189</a></li>\n<li>github: <a href=\"https://github.com/bharatsingh430/snip\">https://github.com/bharatsingh430/snip</a></li>\n</ul>\n<p><strong>Feature Selective Networks for Object Detection</strong></p>\n<p><a href=\"https://arxiv.org/abs/1711.08879\">https://arxiv.org/abs/1711.08879</a></p>\n<p><strong>Learning a Rotation Invariant Detector with Rotatable Bounding Box</strong></p>\n<ul>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1711.09405\">https://arxiv.org/abs/1711.09405</a></li>\n<li>github: <a href=\"https://github.com/liulei01/DRBox\">https://github.com/liulei01/DRBox</a></li>\n</ul>\n<p><strong>Scalable Object Detection for Stylized Objects</strong></p>\n<ul>\n<li>intro: Microsoft AI &amp; Research Munich</li>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1711.09822\">https://arxiv.org/abs/1711.09822</a></li>\n</ul>\n<p><strong>Learning Object Detectors from Scratch with Gated Recurrent Feature Pyramids</strong></p>\n<ul>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1712.00886\">https://arxiv.org/abs/1712.00886</a></li>\n<li>github: <a href=\"https://github.com/szq0214/GRP-DSOD\">https://github.com/szq0214/GRP-DSOD</a></li>\n</ul>\n<p><strong>Deep Regionlets for Object Detection</strong></p>\n<ul>\n<li>keywords: region selection network, gating network</li>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1712.02408\">https://arxiv.org/abs/1712.02408</a></li>\n</ul>\n<p><strong>Training and Testing Object Detectors with Virtual Images</strong></p>\n<ul>\n<li>intro: IEEE&#x2F;CAA Journal of Automatica Sinica</li>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1712.08470\">https://arxiv.org/abs/1712.08470</a></li>\n</ul>\n<p><strong>Large-Scale Object Discovery and Detector Adaptation from Unlabeled Video</strong></p>\n<ul>\n<li>keywords: object mining, object tracking, unsupervised object discovery by appearance-based clustering, self-supervised detector adaptation</li>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1712.08832\">https://arxiv.org/abs/1712.08832</a></li>\n</ul>\n<p><strong>Spot the Difference by Object Detection</strong></p>\n<ul>\n<li>intro: Tsinghua University &amp; JD Group</li>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1801.01051\">https://arxiv.org/abs/1801.01051</a></li>\n</ul>\n<p><strong>Localization-Aware Active Learning for Object Detection</strong></p>\n<ul>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1801.05124\">https://arxiv.org/abs/1801.05124</a></li>\n</ul>\n<p><strong>Object Detection with Mask-based Feature Encoding</strong></p>\n<ul>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1802.03934\">https://arxiv.org/abs/1802.03934</a></li>\n</ul>\n<p><strong>LSTD: A Low-Shot Transfer Detector for Object Detection</strong></p>\n<ul>\n<li>intro: AAAI 2018</li>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1803.01529\">https://arxiv.org/abs/1803.01529</a></li>\n</ul>\n<p><strong>Pseudo Mask Augmented Object Detection</strong></p>\n<p><a href=\"https://arxiv.org/abs/1803.05858\">https://arxiv.org/abs/1803.05858</a></p>\n<p><strong>Revisiting RCNN: On Awakening the Classification Power of Faster RCNN</strong></p>\n<p><a href=\"https://arxiv.org/abs/1803.06799\">https://arxiv.org/abs/1803.06799</a></p>\n<p><strong>Learning Region Features for Object Detection</strong></p>\n<ul>\n<li>intro: Peking University &amp; MSRA</li>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1803.07066\">https://arxiv.org/abs/1803.07066</a></li>\n</ul>\n<p><strong>Single-Shot Bidirectional Pyramid Networks for High-Quality Object Detection</strong></p>\n<ul>\n<li>intro: Singapore Management University &amp; Zhejiang University</li>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1803.08208\">https://arxiv.org/abs/1803.08208</a></li>\n</ul>\n<p><strong>Object Detection for Comics using Manga109 Annotations</strong></p>\n<ul>\n<li>intro: University of Tokyo &amp; National Institute of Informatics, Japan</li>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1803.08670\">https://arxiv.org/abs/1803.08670</a></li>\n</ul>\n<p><strong>Task-Driven Super Resolution: Object Detection in Low-resolution Images</strong></p>\n<ul>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1803.11316\">https://arxiv.org/abs/1803.11316</a></li>\n</ul>\n<p><strong>Transferring Common-Sense Knowledge for Object Detection</strong></p>\n<ul>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1804.01077\">https://arxiv.org/abs/1804.01077</a></li>\n</ul>\n<p><strong>Multi-scale Location-aware Kernel Representation for Object Detection</strong></p>\n<ul>\n<li>intro: CVPR 2018</li>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1804.00428\">https://arxiv.org/abs/1804.00428</a></li>\n<li>github: <a href=\"https://github.com/Hwang64/MLKP\">https://github.com/Hwang64/MLKP</a></li>\n</ul>\n<p><strong>Loss Rank Mining: A General Hard Example Mining Method for Real-time Detectors</strong></p>\n<ul>\n<li>intro: National University of Defense Technology</li>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1804.04606\">https://arxiv.org/abs/1804.04606</a></li>\n</ul>\n<p><strong>Robust Physical Adversarial Attack on Faster R-CNN Object Detector</strong></p>\n<ul>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1804.05810\">https://arxiv.org/abs/1804.05810</a></li>\n</ul>\n<h2 id=\"RefineNet\"><a href=\"#RefineNet\" class=\"headerlink\" title=\"RefineNet\"></a>RefineNet</h2><p><strong>Single-Shot Refinement Neural Network for Object Detection</strong></p>\n<ul>\n<li><p>intro: CVPR 2018</p>\n</li>\n<li><p>arxiv: <a href=\"https://arxiv.org/abs/1711.06897\">https://arxiv.org/abs/1711.06897</a></p>\n</li>\n<li><p>github: <a href=\"https://github.com/sfzhang15/RefineDet\">https://github.com/sfzhang15/RefineDet</a></p>\n</li>\n<li><p>github: <a href=\"https://github.com/lzx1413/PytorchSSD\">https://github.com/lzx1413/PytorchSSD</a></p>\n</li>\n<li><p>github: <a href=\"https://github.com/ddlee96/RefineDet_mxnet\">https://github.com/ddlee96/RefineDet_mxnet</a></p>\n</li>\n<li><p>github: <a href=\"https://github.com/MTCloudVision/RefineDet-Mxnet\">https://github.com/MTCloudVision/RefineDet-Mxnet</a></p>\n</li>\n</ul>\n<h2 id=\"DetNet\"><a href=\"#DetNet\" class=\"headerlink\" title=\"DetNet\"></a>DetNet</h2><p><strong>DetNet: A Backbone network for Object Detection</strong></p>\n<ul>\n<li>intro: Tsinghua University &amp; Face++</li>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1804.06215\">https://arxiv.org/abs/1804.06215</a></li>\n</ul>\n<h2 id=\"SSOD\"><a href=\"#SSOD\" class=\"headerlink\" title=\"SSOD\"></a>SSOD</h2><p><strong>Self-supervisory Signals for Object Discovery and Detection</strong></p>\n<ul>\n<li>Google Brain</li>\n<li>arxiv:<a href=\"https://arxiv.org/abs/1806.03370\">https://arxiv.org/abs/1806.03370</a></li>\n</ul>\n<h2 id=\"CornerNet\"><a href=\"#CornerNet\" class=\"headerlink\" title=\"CornerNet\"></a>CornerNet</h2><p><strong>CornerNet: Detecting Objects as Paired Keypoints</strong></p>\n<ul>\n<li>intro: ECCV 2018</li>\n<li>arXiv: <a href=\"https://arxiv.org/abs/1808.01244\">https://arxiv.org/abs/1808.01244</a></li>\n<li>github: <a href=\"https://github.com/umich-vl/CornerNet\">https://github.com/umich-vl/CornerNet</a></li>\n</ul>\n<h2 id=\"M2Det\"><a href=\"#M2Det\" class=\"headerlink\" title=\"M2Det\"></a>M2Det</h2><p><strong>M2Det: A Single-Shot Object Detector based on Multi-Level Feature Pyramid Network</strong></p>\n<ul>\n<li>intro: AAAI 2019</li>\n<li>arXiv: <a href=\"https://arxiv.org/abs/1811.04533\">https://arxiv.org/abs/1811.04533</a></li>\n<li>github: <a href=\"https://github.com/qijiezhao/M2Det\">https://github.com/qijiezhao/M2Det</a></li>\n</ul>\n<h2 id=\"3D-Object-Detection\"><a href=\"#3D-Object-Detection\" class=\"headerlink\" title=\"3D Object Detection\"></a>3D Object Detection</h2><p><strong>3D Backbone Network for 3D Object Detection</strong></p>\n<ul>\n<li>arXiv: <a href=\"https://arxiv.org/abs/1901.08373\">https://arxiv.org/abs/1901.08373</a></li>\n</ul>\n<p><strong>LMNet: Real-time Multiclass Object Detection on CPU using 3D LiDARs</strong></p>\n<ul>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1805.04902\">https://arxiv.org/abs/1805.04902</a></li>\n<li>github: <a href=\"https://github.com/CPFL/Autoware/tree/feature/cnn_lidar_detection\">https://github.com/CPFL/Autoware/tree/feature/cnn_lidar_detection</a></li>\n</ul>\n<h2 id=\"ZSD（Zero-Shot-Object-Detection）\"><a href=\"#ZSD（Zero-Shot-Object-Detection）\" class=\"headerlink\" title=\"ZSD（Zero-Shot Object Detection）\"></a>ZSD（Zero-Shot Object Detection）</h2><p><strong>Zero-Shot Detection</strong></p>\n<ul>\n<li>intro: Australian National University</li>\n<li>keywords: YOLO</li>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1803.07113\">https://arxiv.org/abs/1803.07113</a></li>\n</ul>\n<p><strong>Zero-Shot Object Detection</strong></p>\n<ul>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1804.04340\">https://arxiv.org/abs/1804.04340</a></li>\n</ul>\n<p><strong>Zero-Shot Object Detection: Learning to Simultaneously Recognize and Localize Novel Concepts</strong></p>\n<ul>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1803.06049\">https://arxiv.org/abs/1803.06049</a></li>\n</ul>\n<p><strong>Zero-Shot Object Detection by Hybrid Region Embedding</strong></p>\n<ul>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1805.06157\">https://arxiv.org/abs/1805.06157</a></li>\n</ul>\n<h2 id=\"OSD（One-Shot-Object-Detection）\"><a href=\"#OSD（One-Shot-Object-Detection）\" class=\"headerlink\" title=\"OSD（One-Shot Object Detection）\"></a>OSD（One-Shot Object Detection）</h2><p><strong>Comparison Network for One-Shot Conditional Object Detection</strong></p>\n<ul>\n<li>arXiv: <a href=\"https://arxiv.org/abs/1904.02317\">https://arxiv.org/abs/1904.02317</a></li>\n</ul>\n<p><strong>One-Shot Object Detection</strong></p>\n<p>RepMet: Representative-based metric learning for classification and one-shot object detection</p>\n<ul>\n<li>intro: IBM Research AI</li>\n<li>arxiv:<a href=\"https://arxiv.org/abs/1806.04728\">https://arxiv.org/abs/1806.04728</a></li>\n<li>github: TODO</li>\n</ul>\n<h2 id=\"Weakly-Supervised-Object-Detection\"><a href=\"#Weakly-Supervised-Object-Detection\" class=\"headerlink\" title=\"Weakly Supervised Object Detection\"></a>Weakly Supervised Object Detection</h2><p><strong>Weakly Supervised Object Detection in Artworks</strong></p>\n<ul>\n<li>intro: ECCV 2018 Workshop Computer Vision for Art Analysis</li>\n<li>arXiv: <a href=\"https://arxiv.org/abs/1810.02569\">https://arxiv.org/abs/1810.02569</a></li>\n<li>Datasets: <a href=\"https://wsoda.telecom-paristech.fr/downloads/dataset/IconArt_v1.zip\">https://wsoda.telecom-paristech.fr/downloads/dataset/IconArt_v1.zip</a></li>\n</ul>\n<p><strong>Cross-Domain Weakly-Supervised Object Detection through Progressive Domain Adaptation</strong></p>\n<ul>\n<li>intro: CVPR 2018</li>\n<li>arXiv: <a href=\"https://arxiv.org/abs/1803.11365\">https://arxiv.org/abs/1803.11365</a></li>\n<li>homepage: <a href=\"https://naoto0804.github.io/cross_domain_detection/\">https://naoto0804.github.io/cross_domain_detection/</a></li>\n<li>paper: <a href=\"http://openaccess.thecvf.com/content_cvpr_2018/html/Inoue_Cross-Domain_Weakly-Supervised_Object_CVPR_2018_paper.html\">http://openaccess.thecvf.com/content_cvpr_2018/html/Inoue_Cross-Domain_Weakly-Supervised_Object_CVPR_2018_paper.html</a></li>\n<li>github: <a href=\"https://github.com/naoto0804/cross-domain-detection\">https://github.com/naoto0804/cross-domain-detection</a></li>\n</ul>\n<h2 id=\"Softer-NMS\"><a href=\"#Softer-NMS\" class=\"headerlink\" title=\"Softer-NMS\"></a>Softer-NMS</h2><p><strong>《Softer-NMS: Rethinking Bounding Box Regression for Accurate Object Detection》</strong></p>\n<ul>\n<li>intro: CMU &amp; Face++</li>\n<li>arXiv: <a href=\"https://arxiv.org/abs/1809.08545\">https://arxiv.org/abs/1809.08545</a></li>\n<li>github: <a href=\"https://github.com/yihui-he/softer-NMS\">https://github.com/yihui-he/softer-NMS</a></li>\n</ul>\n<h2 id=\"2019\"><a href=\"#2019\" class=\"headerlink\" title=\"2019\"></a>2019</h2><p><strong>Feature Selective Anchor-Free Module for Single-Shot Object Detection</strong></p>\n<ul>\n<li><p>intro: CVPR 2019</p>\n</li>\n<li><p>arXiv: <a href=\"https://arxiv.org/abs/1903.00621\">https://arxiv.org/abs/1903.00621</a></p>\n</li>\n</ul>\n<p><strong>Object Detection based on Region Decomposition and Assembly</strong></p>\n<ul>\n<li><p>intro: AAAI 2019</p>\n</li>\n<li><p>arXiv: <a href=\"https://arxiv.org/abs/1901.08225\">https://arxiv.org/abs/1901.08225</a></p>\n</li>\n</ul>\n<p><strong>Bottom-up Object Detection by Grouping Extreme and Center Points</strong></p>\n<ul>\n<li>intro: one stage 43.2% on COCO test-dev</li>\n<li>arXiv: <a href=\"https://arxiv.org/abs/1901.08043\">https://arxiv.org/abs/1901.08043</a></li>\n<li>github: <a href=\"https://github.com/xingyizhou/ExtremeNet\">https://github.com/xingyizhou/ExtremeNet</a></li>\n</ul>\n<p><strong>ORSIm Detector: A Novel Object Detection Framework in Optical Remote Sensing Imagery Using Spatial-Frequency Channel Features</strong></p>\n<ul>\n<li><p>intro: IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING</p>\n</li>\n<li><p>arXiv: <a href=\"https://arxiv.org/abs/1901.07925\">https://arxiv.org/abs/1901.07925</a></p>\n</li>\n</ul>\n<p><strong>Consistent Optimization for Single-Shot Object Detection</strong></p>\n<ul>\n<li><p>intro: improves RetinaNet from 39.1 AP to 40.1 AP on COCO datase</p>\n</li>\n<li><p>arXiv: <a href=\"https://arxiv.org/abs/1901.06563\">https://arxiv.org/abs/1901.06563</a></p>\n</li>\n</ul>\n<p><strong>Learning Pairwise Relationship for Multi-object Detection in Crowded Scenes</strong></p>\n<ul>\n<li>arXiv: <a href=\"https://arxiv.org/abs/1901.03796\">https://arxiv.org/abs/1901.03796</a></li>\n</ul>\n<p><strong>RetinaMask: Learning to predict masks improves state-of-the-art single-shot detection for free</strong></p>\n<ul>\n<li>arXiv: <a href=\"https://arxiv.org/abs/1901.03353\">https://arxiv.org/abs/1901.03353</a></li>\n<li>github: <a href=\"https://github.com/chengyangfu/retinamask\">https://github.com/chengyangfu/retinamask</a></li>\n</ul>\n<p><strong>Region Proposal by Guided Anchoring</strong></p>\n<ul>\n<li>intro: CUHK - SenseTime Joint Lab</li>\n<li>arXiv: <a href=\"https://arxiv.org/abs/1901.03278\">https://arxiv.org/abs/1901.03278</a></li>\n</ul>\n<p><strong>Scale-Aware Trident Networks for Object Detection</strong></p>\n<ul>\n<li>intro: mAP of <strong>48.4</strong> on the COCO dataset</li>\n<li>arXiv: <a href=\"https://arxiv.org/abs/1901.01892\">https://arxiv.org/abs/1901.01892</a></li>\n</ul>\n<h2 id=\"2018\"><a href=\"#2018\" class=\"headerlink\" title=\"2018\"></a>2018</h2><p><strong>Large-Scale Object Detection of Images from Network Cameras in Variable Ambient Lighting Conditions</strong></p>\n<ul>\n<li>arXiv: <a href=\"https://arxiv.org/abs/1812.11901\">https://arxiv.org/abs/1812.11901</a></li>\n</ul>\n<p><strong>Strong-Weak Distribution Alignment for Adaptive Object Detection</strong></p>\n<ul>\n<li>arXiv: <a href=\"https://arxiv.org/abs/1812.04798\">https://arxiv.org/abs/1812.04798</a></li>\n</ul>\n<p><strong>AutoFocus: Efficient Multi-Scale Inference</strong></p>\n<ul>\n<li>intro: AutoFocus obtains an <strong>mAP of 47.9%</strong> (68.3% at 50% overlap) on the <strong>COCO test-dev</strong> set while processing <strong>6.4 images per second on a Titan X (Pascal) GPU</strong> </li>\n<li>arXiv: <a href=\"https://arxiv.org/abs/1812.01600\">https://arxiv.org/abs/1812.01600</a></li>\n</ul>\n<p><strong>NOTE-RCNN: NOise Tolerant Ensemble RCNN for Semi-Supervised Object Detection</strong></p>\n<ul>\n<li>intro: Google Could</li>\n<li>arXiv: <a href=\"https://arxiv.org/abs/1812.00124\">https://arxiv.org/abs/1812.00124</a></li>\n</ul>\n<p><strong>SPLAT: Semantic Pixel-Level Adaptation Transforms for Detection</strong></p>\n<ul>\n<li>intro: UC Berkeley</li>\n<li>arXiv: <a href=\"https://arxiv.org/abs/1812.00929\">https://arxiv.org/abs/1812.00929</a></li>\n</ul>\n<p><strong>Grid R-CNN</strong></p>\n<ul>\n<li>intro: SenseTime</li>\n<li>arXiv: <a href=\"https://arxiv.org/abs/1811.12030\">https://arxiv.org/abs/1811.12030</a></li>\n</ul>\n<p><strong>Deformable ConvNets v2: More Deformable, Better Results</strong></p>\n<ul>\n<li><p>intro: Microsoft Research Asia</p>\n</li>\n<li><p>arXiv: <a href=\"https://arxiv.org/abs/1811.11168\">https://arxiv.org/abs/1811.11168</a></p>\n</li>\n</ul>\n<p><strong>Anchor Box Optimization for Object Detection</strong></p>\n<ul>\n<li>intro: Microsoft Research</li>\n<li>arXiv: <a href=\"https://arxiv.org/abs/1812.00469\">https://arxiv.org/abs/1812.00469</a></li>\n</ul>\n<p><strong>Efficient Coarse-to-Fine Non-Local Module for the Detection of Small Objects</strong></p>\n<ul>\n<li>intro: <a href=\"https://arxiv.org/abs/1811.12152\">https://arxiv.org/abs/1811.12152</a></li>\n</ul>\n<p><strong>NOTE-RCNN: NOise Tolerant Ensemble RCNN for Semi-Supervised Object Detection</strong></p>\n<ul>\n<li>arXiv: <a href=\"https://arxiv.org/abs/1812.00124\">https://arxiv.org/abs/1812.00124</a></li>\n</ul>\n<p><strong>Learning RoI Transformer for Detecting Oriented Objects in Aerial Images</strong></p>\n<ul>\n<li>arXiv: <a href=\"https://arxiv.org/abs/1812.00155\">https://arxiv.org/abs/1812.00155</a></li>\n</ul>\n<p><strong>Integrated Object Detection and Tracking with Tracklet-Conditioned Detection</strong></p>\n<ul>\n<li>intro: Microsoft Research Asia</li>\n<li>arXiv: <a href=\"https://arxiv.org/abs/1811.11167\">https://arxiv.org/abs/1811.11167</a></li>\n</ul>\n<p><strong>Deep Regionlets: Blended Representation and Deep Learning for Generic Object Detection</strong></p>\n<ul>\n<li>arXiv: <a href=\"https://arxiv.org/abs/1811.11318\">https://arxiv.org/abs/1811.11318</a></li>\n</ul>\n<p> <strong>Gradient Harmonized Single-stage Detector</strong></p>\n<ul>\n<li>intro: AAAI 2019</li>\n<li>arXiv: <a href=\"https://arxiv.org/abs/1811.05181\">https://arxiv.org/abs/1811.05181</a></li>\n</ul>\n<p><strong>CFENet: Object Detection with Comprehensive Feature Enhancement Module</strong></p>\n<ul>\n<li>intro: ACCV 2018</li>\n<li>github: <a href=\"https://github.com/qijiezhao/CFENet\">https://github.com/qijiezhao/CFENet</a></li>\n</ul>\n<p><strong>DeRPN: Taking a further step toward more general object detection</strong></p>\n<ul>\n<li>intro: AAAI 2019</li>\n<li>arXiv: <a href=\"https://arxiv.org/abs/1811.06700\">https://arxiv.org/abs/1811.06700</a></li>\n<li>github: <a href=\"https://github.com/HCIILAB/DeRPN\">https://github.com/HCIILAB/DeRPN</a></li>\n</ul>\n<p><strong>Hybrid Knowledge Routed Modules for Large-scale Object Detection</strong></p>\n<ul>\n<li>intro: Sun Yat-Sen University &amp; Huawei Noah’s Ark Lab</li>\n<li>arXiv: <a href=\"https://arxiv.org/abs/1810.12681\">https://arxiv.org/abs/1810.12681</a></li>\n<li>github: <a href=\"https://github.com/chanyn/HKRM\">https://github.com/chanyn/HKRM</a></li>\n</ul>\n<p><strong>《Receptive Field Block Net for Accurate and Fast Object Detection》</strong></p>\n<ul>\n<li>intro: ECCV 2018</li>\n<li>arXiv: <a href=\"https://arxiv.org/abs/1711.07767\">https://arxiv.org/abs/1711.07767</a></li>\n<li>github: <a href=\"https://github.com/ruinmessi/RFBNet\">https://github.com/ruinmessi/RFBNet</a></li>\n</ul>\n<p><strong>Deep Feature Pyramid Reconfiguration for Object Detection</strong></p>\n<ul>\n<li>intro: ECCV 2018</li>\n<li>arXiv: <a href=\"https://arxiv.org/abs/1808.07993\">https://arxiv.org/abs/1808.07993</a></li>\n</ul>\n<p><strong>Unsupervised Hard Example Mining from Videos for Improved Object Detection</strong></p>\n<ul>\n<li>intro: ECCV 2018</li>\n<li>arXiv: <a href=\"https://arxiv.org/abs/1808.04285\">https://arxiv.org/abs/1808.04285</a></li>\n</ul>\n<p><strong>Acquisition of Localization Confidence for Accurate Object Detection</strong></p>\n<ul>\n<li>intro: ECCV 2018</li>\n<li>arXiv: <a href=\"https://arxiv.org/abs/1807.11590\">https://arxiv.org/abs/1807.11590</a></li>\n<li>github: <a href=\"https://github.com/vacancy/PreciseRoIPooling\">https://github.com/vacancy/PreciseRoIPooling</a></li>\n</ul>\n<p><strong>Toward Scale-Invariance and Position-Sensitive Region Proposal Networks</strong></p>\n<ul>\n<li>intro: ECCV 2018</li>\n<li>arXiv: <a href=\"https://arxiv.org/abs/1807.09528\">https://arxiv.org/abs/1807.09528</a></li>\n</ul>\n<p><strong>MetaAnchor: Learning to Detect Objects with Customized Anchors</strong></p>\n<ul>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1807.00980\">https://arxiv.org/abs/1807.00980</a></li>\n</ul>\n<p><strong>Relation Network for Object Detection</strong></p>\n<ul>\n<li>intro: CVPR 2018</li>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1711.11575\">https://arxiv.org/abs/1711.11575</a></li>\n<li>github:<a href=\"https://github.com/msracver/Relation-Networks-for-Object-Detection\">https://github.com/msracver/Relation-Networks-for-Object-Detection</a></li>\n</ul>\n<p><strong>Quantization Mimic: Towards Very Tiny CNN for Object Detection</strong></p>\n<ul>\n<li>Tsinghua University1 &amp; The Chinese University of Hong Kong2 &amp;SenseTime3</li>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1805.02152\">https://arxiv.org/abs/1805.02152</a></li>\n</ul>\n<p><strong>Learning Rich Features for Image Manipulation Detection</strong></p>\n<ul>\n<li>intro: CVPR 2018 Camera Ready</li>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1805.04953\">https://arxiv.org/abs/1805.04953</a></li>\n</ul>\n<p><strong>SNIPER: Efficient Multi-Scale Training</strong></p>\n<ul>\n<li>arxiv:<a href=\"https://arxiv.org/abs/1805.09300\">https://arxiv.org/abs/1805.09300</a></li>\n<li>github:<a href=\"https://github.com/mahyarnajibi/SNIPER\">https://github.com/mahyarnajibi/SNIPER</a></li>\n</ul>\n<p><strong>Soft Sampling for Robust Object Detection</strong></p>\n<ul>\n<li>intro: the robustness of object detection under the presence of missing annotations</li>\n<li>arxiv:<a href=\"https://arxiv.org/abs/1806.06986\">https://arxiv.org/abs/1806.06986</a></li>\n</ul>\n<p><strong>Cost-effective Object Detection: Active Sample Mining with Switchable Selection Criteria</strong></p>\n<ul>\n<li>intro: TNNLS 2018</li>\n<li>arxiv:<a href=\"https://arxiv.org/abs/1807.00147\">https://arxiv.org/abs/1807.00147</a></li>\n<li>code: <a href=\"http://kezewang.com/codes/ASM_ver1.zip\">http://kezewang.com/codes/ASM_ver1.zip</a></li>\n</ul>\n<h2 id=\"Other\"><a href=\"#Other\" class=\"headerlink\" title=\"Other\"></a>Other</h2><p><strong>R3-Net: A Deep Network for Multi-oriented Vehicle Detection in Aerial Images and Videos</strong></p>\n<ul>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1808.05560\">https://arxiv.org/abs/1808.05560</a></li>\n<li>youtube: <a href=\"https://youtu.be/xCYD-tYudN0\">https://youtu.be/xCYD-tYudN0</a></li>\n</ul>\n<h1 id=\"Detection-Toolbox\"><a href=\"#Detection-Toolbox\" class=\"headerlink\" title=\"Detection Toolbox\"></a>Detection Toolbox</h1><ul>\n<li><a href=\"https://github.com/facebookresearch/Detectron\">Detectron(FAIR)</a>: Detectron is Facebook AI Research’s software system that implements state-of-the-art object detection algorithms, including <a href=\"https://arxiv.org/abs/1703.06870\">Mask R-CNN</a>. It is written in Python and powered by the <a href=\"https://github.com/caffe2/caffe2\">Caffe2</a> deep learning framework.</li>\n<li><a href=\"https://github.com/facebookresearch/detectron2\">Detectron2</a>: Detectron2 is FAIR’s next-generation research platform for object detection and segmentation.</li>\n<li><a href=\"https://github.com/facebookresearch/maskrcnn-benchmark\">maskrcnn-benchmark(FAIR)</a>: Fast, modular reference implementation of Instance Segmentation and Object Detection algorithms in PyTorch.</li>\n<li><a href=\"https://github.com/open-mmlab/mmdetection\">mmdetection(SenseTime&amp;CUHK)</a>: mmdetection is an open source object detection toolbox based on PyTorch. It is a part of the open-mmlab project developed by <a href=\"http://mmlab.ie.cuhk.edu.hk/\">Multimedia Laboratory, CUHK</a>.</li>\n</ul>","related_posts":["to-desk.html","how-I-build-this-web.html","jupyter-notebook-extensions.html","code-and-project2.html","passwd-free-for-deployment.html"],"length":30529,"excerpt":"<p>down来的机器学习图像识别资料。</p>","more":"<ul>\n<li>R-CNN</li>\n<li>Fast R-CNN</li>\n<li>Faster R-CNN</li>\n<li>Mask R-CNN</li>\n<li>Light-Head R-CNN</li>\n<li>Cascade R-CNN</li>\n<li>SPP-Net</li>\n<li>YOLO</li>\n<li>YOLOv2</li>\n<li>YOLOv3</li>\n<li>YOLT</li>\n<li>SSD</li>\n<li>DSSD</li>\n<li>FSSD</li>\n<li>ESSD</li>\n<li>MDSSD</li>\n<li>Pelee</li>\n<li>Fire SSD</li>\n<li>R-FCN</li>\n<li>FPN</li>\n<li>DSOD</li>\n<li>RetinaNet</li>\n<li>MegDet</li>\n<li>RefineNet</li>\n<li>DetNet</li>\n<li>SSOD</li>\n<li>CornerNet</li>\n<li>M2Det</li>\n<li>3D Object Detection</li>\n<li>ZSD（Zero-Shot Object Detection）</li>\n<li>OSD（One-Shot object Detection）</li>\n<li>Weakly Supervised Object Detection</li>\n<li>Softer-NMS</li>\n<li>2018</li>\n<li>2019</li>\n<li>Other</li>\n</ul>\n<p>Based on handong1587’s github: <a href=\"https://handong1587.github.io/deep_learning/2015/10/09/object-detection.html\">https://handong1587.github.io/deep_learning/2015/10/09/object-detection.html</a></p>\n<h1 id=\"Survey\"><a href=\"#Survey\" class=\"headerlink\" title=\"Survey\"></a>Survey</h1><p><strong>Imbalance Problems in Object Detection: A Review</strong></p>\n<ul>\n<li>intro: under review at TPAMI</li>\n<li>arXiv: <a href=\"https://arxiv.org/abs/1909.00169\">https://arxiv.org/abs/1909.00169</a></li>\n</ul>\n<p><strong>Recent Advances in Deep Learning for Object Detection</strong></p>\n<ul>\n<li>intro: From 2013 (OverFeat) to 2019 (DetNAS)</li>\n<li>arXiv: <a href=\"https://arxiv.org/abs/1908.03673\">https://arxiv.org/abs/1908.03673</a></li>\n</ul>\n<p><strong>A Survey of Deep Learning-based Object Detection</strong></p>\n<ul>\n<li><p>intro：From Fast R-CNN to NAS-FPN</p>\n</li>\n<li><p>arXiv：<a href=\"https://arxiv.org/abs/1907.09408\">https://arxiv.org/abs/1907.09408</a></p>\n</li>\n</ul>\n<p><strong>Object Detection in 20 Years: A Survey</strong></p>\n<ul>\n<li>intro：This work has been submitted to the IEEE TPAMI for possible publication</li>\n<li>arXiv：<a href=\"https://arxiv.org/abs/1905.05055\">https://arxiv.org/abs/1905.05055</a></li>\n</ul>\n<p><strong>《Recent Advances in Object Detection in the Age of Deep Convolutional Neural Networks》</strong></p>\n<ul>\n<li><p>intro: awesome</p>\n</li>\n<li><p>arXiv: <a href=\"https://arxiv.org/abs/1809.03193\">https://arxiv.org/abs/1809.03193</a></p>\n</li>\n</ul>\n<p><strong>《Deep Learning for Generic Object Detection: A Survey》</strong></p>\n<ul>\n<li>intro: Submitted to IJCV 2018</li>\n<li>arXiv: <a href=\"https://arxiv.org/abs/1809.02165\">https://arxiv.org/abs/1809.02165</a></li>\n</ul>\n<h1 id=\"Papers-Codes\"><a href=\"#Papers-Codes\" class=\"headerlink\" title=\"Papers&amp;Codes\"></a>Papers&amp;Codes</h1><h2 id=\"R-CNN\"><a href=\"#R-CNN\" class=\"headerlink\" title=\"R-CNN\"></a>R-CNN</h2><p><strong>Rich feature hierarchies for accurate object detection and semantic segmentation</strong></p>\n<ul>\n<li>intro: R-CNN</li>\n<li>arxiv: <a href=\"http://arxiv.org/abs/1311.2524\">http://arxiv.org/abs/1311.2524</a></li>\n<li>supp: <a href=\"http://people.eecs.berkeley.edu/~rbg/papers/r-cnn-cvpr-supp.pdf\">http://people.eecs.berkeley.edu/~rbg/papers/r-cnn-cvpr-supp.pdf</a></li>\n<li>slides: <a href=\"http://www.image-net.org/challenges/LSVRC/2013/slides/r-cnn-ilsvrc2013-workshop.pdf\">http://www.image-net.org/challenges/LSVRC/2013/slides/r-cnn-ilsvrc2013-workshop.pdf</a></li>\n<li>slides: <a href=\"http://www.cs.berkeley.edu/~rbg/slides/rcnn-cvpr14-slides.pdf\">http://www.cs.berkeley.edu/~rbg/slides/rcnn-cvpr14-slides.pdf</a></li>\n<li>github: <a href=\"https://github.com/rbgirshick/rcnn\">https://github.com/rbgirshick/rcnn</a></li>\n<li>notes: <a href=\"http://zhangliliang.com/2014/07/23/paper-note-rcnn/\">http://zhangliliang.com/2014/07/23/paper-note-rcnn/</a></li>\n<li>caffe-pr(“Make R-CNN the Caffe detection example”): <a href=\"https://github.com/BVLC/caffe/pull/482\">https://github.com/BVLC/caffe/pull/482</a></li>\n</ul>\n<h2 id=\"Fast-R-CNN\"><a href=\"#Fast-R-CNN\" class=\"headerlink\" title=\"Fast R-CNN\"></a>Fast R-CNN</h2><p><strong>Fast R-CNN</strong></p>\n<ul>\n<li>arxiv: <a href=\"http://arxiv.org/abs/1504.08083\">http://arxiv.org/abs/1504.08083</a></li>\n<li>slides: <a href=\"http://tutorial.caffe.berkeleyvision.org/caffe-cvpr15-detection.pdf\">http://tutorial.caffe.berkeleyvision.org/caffe-cvpr15-detection.pdf</a></li>\n<li>github: <a href=\"https://github.com/rbgirshick/fast-rcnn\">https://github.com/rbgirshick/fast-rcnn</a></li>\n<li>github(COCO-branch): <a href=\"https://github.com/rbgirshick/fast-rcnn/tree/coco\">https://github.com/rbgirshick/fast-rcnn/tree/coco</a></li>\n<li>webcam demo: <a href=\"https://github.com/rbgirshick/fast-rcnn/pull/29\">https://github.com/rbgirshick/fast-rcnn/pull/29</a></li>\n<li>notes: <a href=\"http://zhangliliang.com/2015/05/17/paper-note-fast-rcnn/\">http://zhangliliang.com/2015/05/17/paper-note-fast-rcnn/</a></li>\n<li>notes: <a href=\"http://blog.csdn.net/linj_m/article/details/48930179\">http://blog.csdn.net/linj_m/article/details/48930179</a></li>\n<li>github(“Fast R-CNN in MXNet”): <a href=\"https://github.com/precedenceguo/mx-rcnn\">https://github.com/precedenceguo/mx-rcnn</a></li>\n<li>github: <a href=\"https://github.com/mahyarnajibi/fast-rcnn-torch\">https://github.com/mahyarnajibi/fast-rcnn-torch</a></li>\n<li>github: <a href=\"https://github.com/apple2373/chainer-simple-fast-rnn\">https://github.com/apple2373/chainer-simple-fast-rnn</a></li>\n<li>github: <a href=\"https://github.com/zplizzi/tensorflow-fast-rcnn\">https://github.com/zplizzi/tensorflow-fast-rcnn</a></li>\n</ul>\n<p><strong>A-Fast-RCNN: Hard Positive Generation via Adversary for Object Detection</strong></p>\n<ul>\n<li>intro: CVPR 2017</li>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1704.03414\">https://arxiv.org/abs/1704.03414</a></li>\n<li>paper: <a href=\"http://abhinavsh.info/papers/pdfs/adversarial_object_detection.pdf\">http://abhinavsh.info/papers/pdfs/adversarial_object_detection.pdf</a></li>\n<li>github(Caffe): <a href=\"https://github.com/xiaolonw/adversarial-frcnn\">https://github.com/xiaolonw/adversarial-frcnn</a></li>\n</ul>\n<h2 id=\"Faster-R-CNN\"><a href=\"#Faster-R-CNN\" class=\"headerlink\" title=\"Faster R-CNN\"></a>Faster R-CNN</h2><p><strong>Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks</strong></p>\n<ul>\n<li>intro: NIPS 2015</li>\n<li>arxiv: <a href=\"http://arxiv.org/abs/1506.01497\">http://arxiv.org/abs/1506.01497</a></li>\n<li>gitxiv: <a href=\"http://www.gitxiv.com/posts/8pfpcvefDYn2gSgXk/faster-r-cnn-towards-real-time-object-detection-with-region\">http://www.gitxiv.com/posts/8pfpcvefDYn2gSgXk/faster-r-cnn-towards-real-time-object-detection-with-region</a></li>\n<li>slides: <a href=\"http://web.cs.hacettepe.edu.tr/~aykut/classes/spring2016/bil722/slides/w05-FasterR-CNN.pdf\">http://web.cs.hacettepe.edu.tr/~aykut/classes/spring2016/bil722/slides/w05-FasterR-CNN.pdf</a></li>\n<li>github(official, Matlab): <a href=\"https://github.com/ShaoqingRen/faster_rcnn\">https://github.com/ShaoqingRen/faster_rcnn</a></li>\n<li>github(Caffe): <a href=\"https://github.com/rbgirshick/py-faster-rcnn\">https://github.com/rbgirshick/py-faster-rcnn</a></li>\n<li>github(MXNet): <a href=\"https://github.com/msracver/Deformable-ConvNets/tree/master/faster_rcnn\">https://github.com/msracver/Deformable-ConvNets/tree/master/faster_rcnn</a></li>\n<li>github(PyTorch–recommend): <a href=\"https://github.com//jwyang/faster-rcnn.pytorch\">https://github.com//jwyang/faster-rcnn.pytorch</a></li>\n<li>github: <a href=\"https://github.com/mitmul/chainer-faster-rcnn\">https://github.com/mitmul/chainer-faster-rcnn</a></li>\n<li>github(Torch):: <a href=\"https://github.com/andreaskoepf/faster-rcnn.torch\">https://github.com/andreaskoepf/faster-rcnn.torch</a></li>\n<li>github(Torch):: <a href=\"https://github.com/ruotianluo/Faster-RCNN-Densecap-torch\">https://github.com/ruotianluo/Faster-RCNN-Densecap-torch</a></li>\n<li>github(TensorFlow): <a href=\"https://github.com/smallcorgi/Faster-RCNN_TF\">https://github.com/smallcorgi/Faster-RCNN_TF</a></li>\n<li>github(TensorFlow): <a href=\"https://github.com/CharlesShang/TFFRCNN\">https://github.com/CharlesShang/TFFRCNN</a></li>\n<li>github(C++ demo): <a href=\"https://github.com/YihangLou/FasterRCNN-Encapsulation-Cplusplus\">https://github.com/YihangLou/FasterRCNN-Encapsulation-Cplusplus</a></li>\n<li>github(Keras): <a href=\"https://github.com/yhenon/keras-frcnn\">https://github.com/yhenon/keras-frcnn</a></li>\n<li>github: <a href=\"https://github.com/Eniac-Xie/faster-rcnn-resnet\">https://github.com/Eniac-Xie/faster-rcnn-resnet</a></li>\n<li>github(C++): <a href=\"https://github.com/D-X-Y/caffe-faster-rcnn/tree/dev\">https://github.com/D-X-Y/caffe-faster-rcnn/tree/dev</a></li>\n</ul>\n<p><strong>R-CNN minus R</strong></p>\n<ul>\n<li>intro: BMVC 2015</li>\n<li>arxiv: <a href=\"http://arxiv.org/abs/1506.06981\">http://arxiv.org/abs/1506.06981</a></li>\n</ul>\n<p><strong>Faster R-CNN in MXNet with distributed implementation and data parallelization</strong></p>\n<ul>\n<li>github: <a href=\"https://github.com/dmlc/mxnet/tree/master/example/rcnn\">https://github.com/dmlc/mxnet/tree/master/example/rcnn</a></li>\n</ul>\n<p><strong>Contextual Priming and Feedback for Faster R-CNN</strong></p>\n<ul>\n<li>intro: ECCV 2016. Carnegie Mellon University</li>\n<li>paper: <a href=\"http://abhinavsh.info/context_priming_feedback.pdf\">http://abhinavsh.info/context_priming_feedback.pdf</a></li>\n<li>poster: <a href=\"http://www.eccv2016.org/files/posters/P-1A-20.pdf\">http://www.eccv2016.org/files/posters/P-1A-20.pdf</a></li>\n</ul>\n<p><strong>An Implementation of Faster RCNN with Study for Region Sampling</strong></p>\n<ul>\n<li>intro: Technical Report, 3 pages. CMU</li>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1702.02138\">https://arxiv.org/abs/1702.02138</a></li>\n<li>github: <a href=\"https://github.com/endernewton/tf-faster-rcnn\">https://github.com/endernewton/tf-faster-rcnn</a></li>\n<li>github: <a href=\"https://github.com/ruotianluo/pytorch-faster-rcnn\">https://github.com/ruotianluo/pytorch-faster-rcnn</a></li>\n</ul>\n<p><strong>Interpretable R-CNN</strong></p>\n<ul>\n<li>intro: North Carolina State University &amp; Alibaba</li>\n<li>keywords: AND-OR Graph (AOG)</li>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1711.05226\">https://arxiv.org/abs/1711.05226</a></li>\n</ul>\n<p><strong>Domain Adaptive Faster R-CNN for Object Detection in the Wild</strong></p>\n<ul>\n<li>intro: CVPR 2018. ETH Zurich &amp; ESAT&#x2F;PSI</li>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1803.03243\">https://arxiv.org/abs/1803.03243</a></li>\n</ul>\n<h2 id=\"Mask-R-CNN\"><a href=\"#Mask-R-CNN\" class=\"headerlink\" title=\"Mask R-CNN\"></a>Mask R-CNN</h2><ul>\n<li>arxiv: <a href=\"http://arxiv.org/abs/1703.06870\">http://arxiv.org/abs/1703.06870</a></li>\n<li>github(Keras): <a href=\"https://github.com/matterport/Mask_RCNN\">https://github.com/matterport/Mask_RCNN</a></li>\n<li>github(Caffe2): <a href=\"https://github.com/facebookresearch/Detectron\">https://github.com/facebookresearch/Detectron</a></li>\n<li>github(Pytorch): <a href=\"https://github.com/wannabeOG/Mask-RCNN\">https://github.com/wannabeOG/Mask-RCNN</a></li>\n<li>github(MXNet): <a href=\"https://github.com/TuSimple/mx-maskrcnn\">https://github.com/TuSimple/mx-maskrcnn</a></li>\n<li>github(Chainer): <a href=\"https://github.com/DeNA/Chainer_Mask_R-CNN\">https://github.com/DeNA/Chainer_Mask_R-CNN</a></li>\n</ul>\n<h2 id=\"Light-Head-R-CNN\"><a href=\"#Light-Head-R-CNN\" class=\"headerlink\" title=\"Light-Head R-CNN\"></a>Light-Head R-CNN</h2><p><strong>Light-Head R-CNN: In Defense of Two-Stage Object Detector</strong></p>\n<ul>\n<li>intro: Tsinghua University &amp; Megvii Inc</li>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1711.07264\">https://arxiv.org/abs/1711.07264</a></li>\n<li>github(offical): <a href=\"https://github.com/zengarden/light_head_rcnn\">https://github.com/zengarden/light_head_rcnn</a></li>\n<li>github: <a href=\"https://github.com/terrychenism/Deformable-ConvNets/blob/master/rfcn/symbols/resnet_v1_101_rfcn_light.py#L784\">https://github.com/terrychenism/Deformable-ConvNets/blob/master/rfcn/symbols/resnet_v1_101_rfcn_light.py#L784</a></li>\n</ul>\n<h2 id=\"Cascade-R-CNN\"><a href=\"#Cascade-R-CNN\" class=\"headerlink\" title=\"Cascade R-CNN\"></a>Cascade R-CNN</h2><p><strong>Cascade R-CNN: Delving into High Quality Object Detection</strong></p>\n<ul>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1712.00726\">https://arxiv.org/abs/1712.00726</a></li>\n<li>github: <a href=\"https://github.com/zhaoweicai/cascade-rcnn\">https://github.com/zhaoweicai/cascade-rcnn</a></li>\n</ul>\n<h2 id=\"SPP-Net\"><a href=\"#SPP-Net\" class=\"headerlink\" title=\"SPP-Net\"></a>SPP-Net</h2><p><strong>Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition</strong></p>\n<ul>\n<li>intro: ECCV 2014 &#x2F; TPAMI 2015</li>\n<li>arxiv: <a href=\"http://arxiv.org/abs/1406.4729\">http://arxiv.org/abs/1406.4729</a></li>\n<li>github: <a href=\"https://github.com/ShaoqingRen/SPP_net\">https://github.com/ShaoqingRen/SPP_net</a></li>\n<li>notes: <a href=\"http://zhangliliang.com/2014/09/13/paper-note-sppnet/\">http://zhangliliang.com/2014/09/13/paper-note-sppnet/</a></li>\n</ul>\n<p><strong>DeepID-Net: Deformable Deep Convolutional Neural Networks for Object Detection</strong></p>\n<ul>\n<li>intro: PAMI 2016</li>\n<li>intro: an extension of R-CNN. box pre-training, cascade on region proposals, deformation layers and context representations</li>\n<li>project page: <a href=\"http://www.ee.cuhk.edu.hk/%CB%9Cwlouyang/projects/imagenetDeepId/index.html\">http://www.ee.cuhk.edu.hk/%CB%9Cwlouyang/projects/imagenetDeepId/index.html</a></li>\n<li>arxiv: <a href=\"http://arxiv.org/abs/1412.5661\">http://arxiv.org/abs/1412.5661</a></li>\n</ul>\n<p><strong>Object Detectors Emerge in Deep Scene CNNs</strong></p>\n<ul>\n<li>intro: ICLR 2015</li>\n<li>arxiv: <a href=\"http://arxiv.org/abs/1412.6856\">http://arxiv.org/abs/1412.6856</a></li>\n<li>paper: <a href=\"https://www.robots.ox.ac.uk/~vgg/rg/papers/zhou_iclr15.pdf\">https://www.robots.ox.ac.uk/~vgg/rg/papers/zhou_iclr15.pdf</a></li>\n<li>paper: <a href=\"https://people.csail.mit.edu/khosla/papers/iclr2015_zhou.pdf\">https://people.csail.mit.edu/khosla/papers/iclr2015_zhou.pdf</a></li>\n<li>slides: <a href=\"http://places.csail.mit.edu/slide_iclr2015.pdf\">http://places.csail.mit.edu/slide_iclr2015.pdf</a></li>\n</ul>\n<p><strong>segDeepM: Exploiting Segmentation and Context in Deep Neural Networks for Object Detection</strong></p>\n<ul>\n<li>intro: CVPR 2015</li>\n<li>project(code+data): <a href=\"https://www.cs.toronto.edu/~yukun/segdeepm.html\">https://www.cs.toronto.edu/~yukun/segdeepm.html</a></li>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1502.04275\">https://arxiv.org/abs/1502.04275</a></li>\n<li>github: <a href=\"https://github.com/YknZhu/segDeepM\">https://github.com/YknZhu/segDeepM</a></li>\n</ul>\n<p><strong>Object Detection Networks on Convolutional Feature Maps</strong></p>\n<ul>\n<li>intro: TPAMI 2015</li>\n<li>keywords: NoC</li>\n<li>arxiv: <a href=\"http://arxiv.org/abs/1504.06066\">http://arxiv.org/abs/1504.06066</a></li>\n</ul>\n<p><strong>Improving Object Detection with Deep Convolutional Networks via Bayesian Optimization and Structured Prediction</strong></p>\n<ul>\n<li>arxiv: <a href=\"http://arxiv.org/abs/1504.03293\">http://arxiv.org/abs/1504.03293</a></li>\n<li>slides: <a href=\"http://www.ytzhang.net/files/publications/2015-cvpr-det-slides.pdf\">http://www.ytzhang.net/files/publications/2015-cvpr-det-slides.pdf</a></li>\n<li>github: <a href=\"https://github.com/YutingZhang/fgs-obj\">https://github.com/YutingZhang/fgs-obj</a></li>\n</ul>\n<p><strong>DeepBox: Learning Objectness with Convolutional Networks</strong></p>\n<ul>\n<li>keywords: DeepBox</li>\n<li>arxiv: <a href=\"http://arxiv.org/abs/1505.02146\">http://arxiv.org/abs/1505.02146</a></li>\n<li>github: <a href=\"https://github.com/weichengkuo/DeepBox\">https://github.com/weichengkuo/DeepBox</a></li>\n</ul>\n<h2 id=\"YOLO\"><a href=\"#YOLO\" class=\"headerlink\" title=\"YOLO\"></a>YOLO</h2><p><strong>You Only Look Once: Unified, Real-Time Object Detection</strong></p>\n<p><a href=\"https://camo.githubusercontent.com/e69d4118b20a42de4e23b9549f9a6ec6dbbb0814/687474703a2f2f706a7265646469652e636f6d2f6d656469612f66696c65732f6461726b6e65742d626c61636b2d736d616c6c2e706e67\"><img src=\"https://camo.githubusercontent.com/e69d4118b20a42de4e23b9549f9a6ec6dbbb0814/687474703a2f2f706a7265646469652e636f6d2f6d656469612f66696c65732f6461726b6e65742d626c61636b2d736d616c6c2e706e67\" alt=\"img\"></a></p>\n<ul>\n<li>arxiv: <a href=\"http://arxiv.org/abs/1506.02640\">http://arxiv.org/abs/1506.02640</a></li>\n<li>code: <a href=\"https://pjreddie.com/darknet/yolov1/\">https://pjreddie.com/darknet/yolov1/</a></li>\n<li>github: <a href=\"https://github.com/pjreddie/darknet\">https://github.com/pjreddie/darknet</a></li>\n<li>blog: <a href=\"https://pjreddie.com/darknet/yolov1/\">https://pjreddie.com/darknet/yolov1/</a></li>\n<li>slides: <a href=\"https://docs.google.com/presentation/d/1aeRvtKG21KHdD5lg6Hgyhx5rPq_ZOsGjG5rJ1HP7BbA/pub?start=false&amp;loop=false&amp;delayms=3000&amp;slide=id.p\">https://docs.google.com/presentation/d/1aeRvtKG21KHdD5lg6Hgyhx5rPq_ZOsGjG5rJ1HP7BbA/pub?start=false&amp;loop=false&amp;delayms=3000&amp;slide=id.p</a></li>\n<li>reddit: <a href=\"https://www.reddit.com/r/MachineLearning/comments/3a3m0o/realtime_object_detection_with_yolo/\">https://www.reddit.com/r/MachineLearning/comments/3a3m0o/realtime_object_detection_with_yolo/</a></li>\n<li>github: <a href=\"https://github.com/gliese581gg/YOLO_tensorflow\">https://github.com/gliese581gg/YOLO_tensorflow</a></li>\n<li>github: <a href=\"https://github.com/xingwangsfu/caffe-yolo\">https://github.com/xingwangsfu/caffe-yolo</a></li>\n<li>github: <a href=\"https://github.com/frankzhangrui/Darknet-Yolo\">https://github.com/frankzhangrui/Darknet-Yolo</a></li>\n<li>github: <a href=\"https://github.com/BriSkyHekun/py-darknet-yolo\">https://github.com/BriSkyHekun/py-darknet-yolo</a></li>\n<li>github: <a href=\"https://github.com/tommy-qichang/yolo.torch\">https://github.com/tommy-qichang/yolo.torch</a></li>\n<li>github: <a href=\"https://github.com/frischzenger/yolo-windows\">https://github.com/frischzenger/yolo-windows</a></li>\n<li>github: <a href=\"https://github.com/AlexeyAB/yolo-windows\">https://github.com/AlexeyAB/yolo-windows</a></li>\n<li>github: <a href=\"https://github.com/nilboy/tensorflow-yolo\">https://github.com/nilboy/tensorflow-yolo</a></li>\n</ul>\n<p><strong>darkflow - translate darknet to tensorflow. Load trained weights, retrain&#x2F;fine-tune them using tensorflow, export constant graph def to C++</strong></p>\n<ul>\n<li>blog: <a href=\"https://thtrieu.github.io/notes/yolo-tensorflow-graph-buffer-cpp\">https://thtrieu.github.io/notes/yolo-tensorflow-graph-buffer-cpp</a></li>\n<li>github: <a href=\"https://github.com/thtrieu/darkflow\">https://github.com/thtrieu/darkflow</a></li>\n</ul>\n<p><strong>Start Training YOLO with Our Own Data</strong></p>\n<p><a href=\"https://camo.githubusercontent.com/2f99b692dd7ce47d7832385f3e8a6654e680d92a/687474703a2f2f6775616e6768616e2e696e666f2f626c6f672f656e2f77702d636f6e74656e742f75706c6f6164732f323031352f31322f696d616765732d34302e6a7067\"><img src=\"https://camo.githubusercontent.com/2f99b692dd7ce47d7832385f3e8a6654e680d92a/687474703a2f2f6775616e6768616e2e696e666f2f626c6f672f656e2f77702d636f6e74656e742f75706c6f6164732f323031352f31322f696d616765732d34302e6a7067\" alt=\"img\"></a></p>\n<ul>\n<li>intro: train with customized data and class numbers&#x2F;labels. Linux &#x2F; Windows version for darknet.</li>\n<li>blog: <a href=\"http://guanghan.info/blog/en/my-works/train-yolo/\">http://guanghan.info/blog/en/my-works/train-yolo/</a></li>\n<li>github: <a href=\"https://github.com/Guanghan/darknet\">https://github.com/Guanghan/darknet</a></li>\n</ul>\n<p><strong>YOLO: Core ML versus MPSNNGraph</strong></p>\n<ul>\n<li>intro: Tiny YOLO for iOS implemented using CoreML but also using the new MPS graph API.</li>\n<li>blog: <a href=\"http://machinethink.net/blog/yolo-coreml-versus-mps-graph/\">http://machinethink.net/blog/yolo-coreml-versus-mps-graph/</a></li>\n<li>github: <a href=\"https://github.com/hollance/YOLO-CoreML-MPSNNGraph\">https://github.com/hollance/YOLO-CoreML-MPSNNGraph</a></li>\n</ul>\n<p><strong>TensorFlow YOLO object detection on Android</strong></p>\n<ul>\n<li>intro: Real-time object detection on Android using the YOLO network with TensorFlow</li>\n<li>github: <a href=\"https://github.com/natanielruiz/android-yolo\">https://github.com/natanielruiz/android-yolo</a></li>\n</ul>\n<p><strong>Computer Vision in iOS – Object Detection</strong></p>\n<ul>\n<li>blog: <a href=\"https://sriraghu.com/2017/07/12/computer-vision-in-ios-object-detection/\">https://sriraghu.com/2017/07/12/computer-vision-in-ios-object-detection/</a></li>\n<li>github:<a href=\"https://github.com/r4ghu/iOS-CoreML-Yolo\">https://github.com/r4ghu/iOS-CoreML-Yolo</a></li>\n</ul>\n<h2 id=\"YOLOv2\"><a href=\"#YOLOv2\" class=\"headerlink\" title=\"YOLOv2\"></a>YOLOv2</h2><p><strong>YOLO9000: Better, Faster, Stronger</strong></p>\n<ul>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1612.08242\">https://arxiv.org/abs/1612.08242</a></li>\n<li>code: <a href=\"http://pjreddie.com/yolo9000/\">http://pjreddie.com/yolo9000/</a>    <a href=\"https://pjreddie.com/darknet/yolov2/\">https://pjreddie.com/darknet/yolov2/</a></li>\n<li>github(Chainer): <a href=\"https://github.com/leetenki/YOLOv2\">https://github.com/leetenki/YOLOv2</a></li>\n<li>github(Keras): <a href=\"https://github.com/allanzelener/YAD2K\">https://github.com/allanzelener/YAD2K</a></li>\n<li>github(PyTorch): <a href=\"https://github.com/longcw/yolo2-pytorch\">https://github.com/longcw/yolo2-pytorch</a></li>\n<li>github(Tensorflow): <a href=\"https://github.com/hizhangp/yolo_tensorflow\">https://github.com/hizhangp/yolo_tensorflow</a></li>\n<li>github(Windows): <a href=\"https://github.com/AlexeyAB/darknet\">https://github.com/AlexeyAB/darknet</a></li>\n<li>github: <a href=\"https://github.com/choasUp/caffe-yolo9000\">https://github.com/choasUp/caffe-yolo9000</a></li>\n<li>github: <a href=\"https://github.com/philipperemy/yolo-9000\">https://github.com/philipperemy/yolo-9000</a></li>\n<li>github(TensorFlow): <a href=\"https://github.com/KOD-Chen/YOLOv2-Tensorflow\">https://github.com/KOD-Chen/YOLOv2-Tensorflow</a></li>\n<li>github(Keras): <a href=\"https://github.com/yhcc/yolo2\">https://github.com/yhcc/yolo2</a></li>\n<li>github(Keras): <a href=\"https://github.com/experiencor/keras-yolo2\">https://github.com/experiencor/keras-yolo2</a></li>\n<li>github(TensorFlow): <a href=\"https://github.com/WojciechMormul/yolo2\">https://github.com/WojciechMormul/yolo2</a></li>\n</ul>\n<p><strong>darknet_scripts</strong></p>\n<ul>\n<li>intro: Auxilary scripts to work with (YOLO) darknet deep learning famework. AKA -&gt; How to generate YOLO anchors?</li>\n<li>github: <a href=\"https://github.com/Jumabek/darknet_scripts\">https://github.com/Jumabek/darknet_scripts</a></li>\n</ul>\n<p><strong>Yolo_mark: GUI for marking bounded boxes of objects in images for training Yolo v2</strong></p>\n<ul>\n<li>github: <a href=\"https://github.com/AlexeyAB/Yolo_mark\">https://github.com/AlexeyAB/Yolo_mark</a></li>\n</ul>\n<p><strong>LightNet: Bringing pjreddie’s DarkNet out of the shadows</strong></p>\n<p><a href=\"https://github.com//explosion/lightnet\">https://github.com//explosion/lightnet</a></p>\n<p><strong>YOLO v2 Bounding Box Tool</strong></p>\n<ul>\n<li>intro: Bounding box labeler tool to generate the training data in the format YOLO v2 requires.</li>\n<li>github: <a href=\"https://github.com/Cartucho/yolo-boundingbox-labeler-GUI\">https://github.com/Cartucho/yolo-boundingbox-labeler-GUI</a></li>\n</ul>\n<p><strong>Loss Rank Mining: A General Hard Example Mining Method for Real-time Detectors</strong></p>\n<ul>\n<li>intro: <strong>LRM</strong> is the first hard example mining strategy which could fit YOLOv2 perfectly and make it better applied in series of real scenarios where both real-time rates and accurate detection are strongly demanded.</li>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1804.04606\">https://arxiv.org/abs/1804.04606</a></li>\n</ul>\n<p><strong>Object detection at 200 Frames Per Second</strong></p>\n<ul>\n<li>intro: faster than Tiny-Yolo-v2</li>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1805.06361\">https://arxiv.org/abs/1805.06361</a></li>\n</ul>\n<p><strong>Event-based Convolutional Networks for Object Detection in Neuromorphic Cameras</strong></p>\n<ul>\n<li>intro: YOLE–Object Detection in Neuromorphic Cameras</li>\n<li>arxiv:<a href=\"https://arxiv.org/abs/1805.07931\">https://arxiv.org/abs/1805.07931</a></li>\n</ul>\n<p><strong>OmniDetector: With Neural Networks to Bounding Boxes</strong></p>\n<ul>\n<li>intro: a person detector on n fish-eye images of indoor scenes（NIPS 2018）</li>\n<li>arxiv:<a href=\"https://arxiv.org/abs/1805.08503\">https://arxiv.org/abs/1805.08503</a></li>\n<li>datasets:<a href=\"https://gitlab.com/omnidetector/omnidetector\">https://gitlab.com/omnidetector/omnidetector</a></li>\n</ul>\n<h2 id=\"YOLOv3\"><a href=\"#YOLOv3\" class=\"headerlink\" title=\"YOLOv3\"></a>YOLOv3</h2><p><strong>YOLOv3: An Incremental Improvement</strong></p>\n<ul>\n<li>arxiv:<a href=\"https://arxiv.org/abs/1804.02767\">https://arxiv.org/abs/1804.02767</a></li>\n<li>paper:<a href=\"https://pjreddie.com/media/files/papers/YOLOv3.pdf\">https://pjreddie.com/media/files/papers/YOLOv3.pdf</a></li>\n<li>code: <a href=\"https://pjreddie.com/darknet/yolo/\">https://pjreddie.com/darknet/yolo/</a></li>\n<li>github(Official):<a href=\"https://github.com/pjreddie/darknet\">https://github.com/pjreddie/darknet</a></li>\n<li>github:<a href=\"https://github.com/mystic123/tensorflow-yolo-v3\">https://github.com/mystic123/tensorflow-yolo-v3</a></li>\n<li>github:<a href=\"https://github.com/experiencor/keras-yolo3\">https://github.com/experiencor/keras-yolo3</a></li>\n<li>github:<a href=\"https://github.com/qqwweee/keras-yolo3\">https://github.com/qqwweee/keras-yolo3</a></li>\n<li>github:<a href=\"https://github.com/marvis/pytorch-yolo3\">https://github.com/marvis/pytorch-yolo3</a></li>\n<li>github:<a href=\"https://github.com/ayooshkathuria/pytorch-yolo-v3\">https://github.com/ayooshkathuria/pytorch-yolo-v3</a></li>\n<li>github:<a href=\"https://github.com/ayooshkathuria/YOLO_v3_tutorial_from_scratch\">https://github.com/ayooshkathuria/YOLO_v3_tutorial_from_scratch</a></li>\n<li>github:<a href=\"https://github.com/eriklindernoren/PyTorch-YOLOv3\">https://github.com/eriklindernoren/PyTorch-YOLOv3</a></li>\n<li>github:<a href=\"https://github.com/ultralytics/yolov3\">https://github.com/ultralytics/yolov3</a></li>\n<li>github:<a href=\"https://github.com/BobLiu20/YOLOv3_PyTorch\">https://github.com/BobLiu20/YOLOv3_PyTorch</a></li>\n<li>github:<a href=\"https://github.com/andy-yun/pytorch-0.4-yolov3\">https://github.com/andy-yun/pytorch-0.4-yolov3</a></li>\n<li>github:<a href=\"https://github.com/DeNA/PyTorch_YOLOv3\">https://github.com/DeNA/PyTorch_YOLOv3</a></li>\n</ul>\n<h2 id=\"YOLT\"><a href=\"#YOLT\" class=\"headerlink\" title=\"YOLT\"></a>YOLT</h2><p><strong>You Only Look Twice: Rapid Multi-Scale Object Detection In Satellite Imagery</strong></p>\n<ul>\n<li><p>intro: Small Object Detection</p>\n</li>\n<li><p>arxiv:<a href=\"https://arxiv.org/abs/1805.09512\">https://arxiv.org/abs/1805.09512</a></p>\n</li>\n<li><p>github:<a href=\"https://github.com/avanetten/yolt\">https://github.com/avanetten/yolt</a></p>\n</li>\n</ul>\n<h2 id=\"SSD\"><a href=\"#SSD\" class=\"headerlink\" title=\"SSD\"></a>SSD</h2><p><strong>SSD: Single Shot MultiBox Detector</strong></p>\n<p><a href=\"https://camo.githubusercontent.com/ad9b147ed3a5f48ffb7c3540711c15aa04ce49c6/687474703a2f2f7777772e63732e756e632e6564752f7e776c69752f7061706572732f7373642e706e67\"><img src=\"https://camo.githubusercontent.com/ad9b147ed3a5f48ffb7c3540711c15aa04ce49c6/687474703a2f2f7777772e63732e756e632e6564752f7e776c69752f7061706572732f7373642e706e67\" alt=\"img\"></a></p>\n<ul>\n<li>intro: ECCV 2016 Oral</li>\n<li>arxiv: <a href=\"http://arxiv.org/abs/1512.02325\">http://arxiv.org/abs/1512.02325</a></li>\n<li>paper: <a href=\"http://www.cs.unc.edu/~wliu/papers/ssd.pdf\">http://www.cs.unc.edu/~wliu/papers/ssd.pdf</a></li>\n<li>slides: <a href=\"http://www.cs.unc.edu/~wliu/papers/ssd_eccv2016_slide.pdf\">http://www.cs.unc.edu/%7Ewliu/papers/ssd_eccv2016_slide.pdf</a></li>\n<li>github(Official): <a href=\"https://github.com/weiliu89/caffe/tree/ssd\">https://github.com/weiliu89/caffe/tree/ssd</a></li>\n<li>video: <a href=\"http://weibo.com/p/2304447a2326da963254c963c97fb05dd3a973\">http://weibo.com/p/2304447a2326da963254c963c97fb05dd3a973</a></li>\n<li>github: <a href=\"https://github.com/zhreshold/mxnet-ssd\">https://github.com/zhreshold/mxnet-ssd</a></li>\n<li>github: <a href=\"https://github.com/zhreshold/mxnet-ssd.cpp\">https://github.com/zhreshold/mxnet-ssd.cpp</a></li>\n<li>github: <a href=\"https://github.com/rykov8/ssd_keras\">https://github.com/rykov8/ssd_keras</a></li>\n<li>github: <a href=\"https://github.com/balancap/SSD-Tensorflow\">https://github.com/balancap/SSD-Tensorflow</a></li>\n<li>github: <a href=\"https://github.com/amdegroot/ssd.pytorch\">https://github.com/amdegroot/ssd.pytorch</a></li>\n<li>github(Caffe): <a href=\"https://github.com/chuanqi305/MobileNet-SSD\">https://github.com/chuanqi305/MobileNet-SSD</a></li>\n</ul>\n<p><strong>What’s the diffience in performance between this new code you pushed and the previous code? #327</strong></p>\n<p><a href=\"https://github.com/weiliu89/caffe/issues/327\">https://github.com/weiliu89/caffe/issues/327</a></p>\n<h2 id=\"DSSD\"><a href=\"#DSSD\" class=\"headerlink\" title=\"DSSD\"></a>DSSD</h2><p><strong>DSSD : Deconvolutional Single Shot Detector</strong></p>\n<ul>\n<li>intro: UNC Chapel Hill &amp; Amazon Inc</li>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1701.06659\">https://arxiv.org/abs/1701.06659</a></li>\n<li>github: <a href=\"https://github.com/chengyangfu/caffe/tree/dssd\">https://github.com/chengyangfu/caffe/tree/dssd</a></li>\n<li>github: <a href=\"https://github.com/MTCloudVision/mxnet-dssd\">https://github.com/MTCloudVision/mxnet-dssd</a></li>\n<li>demo: <a href=\"http://120.52.72.53/www.cs.unc.edu/c3pr90ntc0td/~cyfu/dssd_lalaland.mp4\">http://120.52.72.53/www.cs.unc.edu/c3pr90ntc0td/~cyfu/dssd_lalaland.mp4</a></li>\n</ul>\n<p><strong>Enhancement of SSD by concatenating feature maps for object detection</strong></p>\n<ul>\n<li>intro: rainbow SSD (R-SSD)</li>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1705.09587\">https://arxiv.org/abs/1705.09587</a></li>\n</ul>\n<p><strong>Context-aware Single-Shot Detector</strong></p>\n<ul>\n<li>keywords: CSSD, DiCSSD, DeCSSD, effective receptive fields (ERFs), theoretical receptive fields (TRFs)</li>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1707.08682\">https://arxiv.org/abs/1707.08682</a></li>\n</ul>\n<p><strong>Feature-Fused SSD: Fast Detection for Small Objects</strong></p>\n<p><a href=\"https://arxiv.org/abs/1709.05054\">https://arxiv.org/abs/1709.05054</a></p>\n<h2 id=\"FSSD\"><a href=\"#FSSD\" class=\"headerlink\" title=\"FSSD\"></a>FSSD</h2><p><strong>FSSD: Feature Fusion Single Shot Multibox Detector</strong></p>\n<p><a href=\"https://arxiv.org/abs/1712.00960\">https://arxiv.org/abs/1712.00960</a></p>\n<p><strong>Weaving Multi-scale Context for Single Shot Detector</strong></p>\n<ul>\n<li>intro: WeaveNet</li>\n<li>keywords: fuse multi-scale information</li>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1712.03149\">https://arxiv.org/abs/1712.03149</a></li>\n</ul>\n<h2 id=\"ESSD\"><a href=\"#ESSD\" class=\"headerlink\" title=\"ESSD\"></a>ESSD</h2><p><strong>Extend the shallow part of Single Shot MultiBox Detector via Convolutional Neural Network</strong></p>\n<p><a href=\"https://arxiv.org/abs/1801.05918\">https://arxiv.org/abs/1801.05918</a></p>\n<p><strong>Tiny SSD: A Tiny Single-shot Detection Deep Convolutional Neural Network for Real-time Embedded Object Detection</strong></p>\n<p><a href=\"https://arxiv.org/abs/1802.06488\">https://arxiv.org/abs/1802.06488</a></p>\n<h2 id=\"MDSSD\"><a href=\"#MDSSD\" class=\"headerlink\" title=\"MDSSD\"></a>MDSSD</h2><p><strong>MDSSD: Multi-scale Deconvolutional Single Shot Detector for small objects</strong></p>\n<ul>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1805.07009\">https://arxiv.org/abs/1805.07009</a></li>\n</ul>\n<h2 id=\"Pelee\"><a href=\"#Pelee\" class=\"headerlink\" title=\"Pelee\"></a>Pelee</h2><p><strong>Pelee: A Real-Time Object Detection System on Mobile Devices</strong></p>\n<p><a href=\"https://github.com/Robert-JunWang/Pelee\">https://github.com/Robert-JunWang/Pelee</a></p>\n<ul>\n<li><p>intro: (ICLR 2018 workshop track)</p>\n</li>\n<li><p>arxiv: <a href=\"https://arxiv.org/abs/1804.06882\">https://arxiv.org/abs/1804.06882</a></p>\n</li>\n<li><p>github: <a href=\"https://github.com/Robert-JunWang/Pelee\">https://github.com/Robert-JunWang/Pelee</a></p>\n</li>\n</ul>\n<h2 id=\"Fire-SSD\"><a href=\"#Fire-SSD\" class=\"headerlink\" title=\"Fire SSD\"></a>Fire SSD</h2><p><strong>Fire SSD: Wide Fire Modules based Single Shot Detector on Edge Device</strong></p>\n<ul>\n<li><p>intro:low cost, fast speed and high mAP on  factor edge computing devices</p>\n</li>\n<li><p>arxiv:<a href=\"https://arxiv.org/abs/1806.05363\">https://arxiv.org/abs/1806.05363</a></p>\n</li>\n</ul>\n<h2 id=\"R-FCN\"><a href=\"#R-FCN\" class=\"headerlink\" title=\"R-FCN\"></a>R-FCN</h2><p><strong>R-FCN: Object Detection via Region-based Fully Convolutional Networks</strong></p>\n<ul>\n<li>arxiv: <a href=\"http://arxiv.org/abs/1605.06409\">http://arxiv.org/abs/1605.06409</a></li>\n<li>github: <a href=\"https://github.com/daijifeng001/R-FCN\">https://github.com/daijifeng001/R-FCN</a></li>\n<li>github(MXNet): <a href=\"https://github.com/msracver/Deformable-ConvNets/tree/master/rfcn\">https://github.com/msracver/Deformable-ConvNets/tree/master/rfcn</a></li>\n<li>github: <a href=\"https://github.com/Orpine/py-R-FCN\">https://github.com/Orpine/py-R-FCN</a></li>\n<li>github: <a href=\"https://github.com/PureDiors/pytorch_RFCN\">https://github.com/PureDiors/pytorch_RFCN</a></li>\n<li>github: <a href=\"https://github.com/bharatsingh430/py-R-FCN-multiGPU\">https://github.com/bharatsingh430/py-R-FCN-multiGPU</a></li>\n<li>github: <a href=\"https://github.com/xdever/RFCN-tensorflow\">https://github.com/xdever/RFCN-tensorflow</a></li>\n</ul>\n<p><strong>R-FCN-3000 at 30fps: Decoupling Detection and Classification</strong></p>\n<p><a href=\"https://arxiv.org/abs/1712.01802\">https://arxiv.org/abs/1712.01802</a></p>\n<p><strong>Recycle deep features for better object detection</strong></p>\n<ul>\n<li>arxiv: <a href=\"http://arxiv.org/abs/1607.05066\">http://arxiv.org/abs/1607.05066</a></li>\n</ul>\n<h2 id=\"FPN\"><a href=\"#FPN\" class=\"headerlink\" title=\"FPN\"></a>FPN</h2><p><strong>Feature Pyramid Networks for Object Detection</strong></p>\n<ul>\n<li>intro: Facebook AI Research</li>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1612.03144\">https://arxiv.org/abs/1612.03144</a></li>\n</ul>\n<p><strong>Action-Driven Object Detection with Top-Down Visual Attentions</strong></p>\n<ul>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1612.06704\">https://arxiv.org/abs/1612.06704</a></li>\n</ul>\n<p><strong>Beyond Skip Connections: Top-Down Modulation for Object Detection</strong></p>\n<ul>\n<li>intro: CMU &amp; UC Berkeley &amp; Google Research</li>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1612.06851\">https://arxiv.org/abs/1612.06851</a></li>\n</ul>\n<p><strong>Wide-Residual-Inception Networks for Real-time Object Detection</strong></p>\n<ul>\n<li>intro: Inha University</li>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1702.01243\">https://arxiv.org/abs/1702.01243</a></li>\n</ul>\n<p><strong>Attentional Network for Visual Object Detection</strong></p>\n<ul>\n<li>intro: University of Maryland &amp; Mitsubishi Electric Research Laboratories</li>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1702.01478\">https://arxiv.org/abs/1702.01478</a></li>\n</ul>\n<p><strong>Learning Chained Deep Features and Classifiers for Cascade in Object Detection</strong></p>\n<ul>\n<li>keykwords: CC-Net</li>\n<li>intro: chained cascade network (CC-Net). 81.1% mAP on PASCAL VOC 2007</li>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1702.07054\">https://arxiv.org/abs/1702.07054</a></li>\n</ul>\n<p><strong>DeNet: Scalable Real-time Object Detection with Directed Sparse Sampling</strong></p>\n<ul>\n<li>intro: ICCV 2017 (poster)</li>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1703.10295\">https://arxiv.org/abs/1703.10295</a></li>\n</ul>\n<p><strong>Discriminative Bimodal Networks for Visual Localization and Detection with Natural Language Queries</strong></p>\n<ul>\n<li>intro: CVPR 2017</li>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1704.03944\">https://arxiv.org/abs/1704.03944</a></li>\n</ul>\n<p><strong>Spatial Memory for Context Reasoning in Object Detection</strong></p>\n<ul>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1704.04224\">https://arxiv.org/abs/1704.04224</a></li>\n</ul>\n<p><strong>Accurate Single Stage Detector Using Recurrent Rolling Convolution</strong></p>\n<ul>\n<li>intro: CVPR 2017. SenseTime</li>\n<li>keywords: Recurrent Rolling Convolution (RRC)</li>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1704.05776\">https://arxiv.org/abs/1704.05776</a></li>\n<li>github: <a href=\"https://github.com/xiaohaoChen/rrc_detection\">https://github.com/xiaohaoChen/rrc_detection</a></li>\n</ul>\n<p><strong>Deep Occlusion Reasoning for Multi-Camera Multi-Target Detection</strong></p>\n<p><a href=\"https://arxiv.org/abs/1704.05775\">https://arxiv.org/abs/1704.05775</a></p>\n<p><strong>LCDet: Low-Complexity Fully-Convolutional Neural Networks for Object Detection in Embedded Systems</strong></p>\n<ul>\n<li>intro: Embedded Vision Workshop in CVPR. UC San Diego &amp; Qualcomm Inc</li>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1705.05922\">https://arxiv.org/abs/1705.05922</a></li>\n</ul>\n<p><strong>Point Linking Network for Object Detection</strong></p>\n<ul>\n<li>intro: Point Linking Network (PLN)</li>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1706.03646\">https://arxiv.org/abs/1706.03646</a></li>\n</ul>\n<p><strong>Perceptual Generative Adversarial Networks for Small Object Detection</strong></p>\n<p><a href=\"https://arxiv.org/abs/1706.05274\">https://arxiv.org/abs/1706.05274</a></p>\n<p><strong>Few-shot Object Detection</strong></p>\n<p><a href=\"https://arxiv.org/abs/1706.08249\">https://arxiv.org/abs/1706.08249</a></p>\n<p><strong>Yes-Net: An effective Detector Based on Global Information</strong></p>\n<p><a href=\"https://arxiv.org/abs/1706.09180\">https://arxiv.org/abs/1706.09180</a></p>\n<p><strong>SMC Faster R-CNN: Toward a scene-specialized multi-object detector</strong></p>\n<p><a href=\"https://arxiv.org/abs/1706.10217\">https://arxiv.org/abs/1706.10217</a></p>\n<p><strong>Towards lightweight convolutional neural networks for object detection</strong></p>\n<p><a href=\"https://arxiv.org/abs/1707.01395\">https://arxiv.org/abs/1707.01395</a></p>\n<p><strong>RON: Reverse Connection with Objectness Prior Networks for Object Detection</strong></p>\n<ul>\n<li>intro: CVPR 2017</li>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1707.01691\">https://arxiv.org/abs/1707.01691</a></li>\n<li>github: <a href=\"https://github.com/taokong/RON\">https://github.com/taokong/RON</a></li>\n</ul>\n<p><strong>Mimicking Very Efficient Network for Object Detection</strong></p>\n<ul>\n<li>intro: CVPR 2017. SenseTime &amp; Beihang University</li>\n<li>paper: <a href=\"http://openaccess.thecvf.com/content_cvpr_2017/papers/Li_Mimicking_Very_Efficient_CVPR_2017_paper.pdf\">http://openaccess.thecvf.com/content_cvpr_2017/papers/Li_Mimicking_Very_Efficient_CVPR_2017_paper.pdf</a></li>\n</ul>\n<p><strong>Residual Features and Unified Prediction Network for Single Stage Detection</strong></p>\n<p><a href=\"https://arxiv.org/abs/1707.05031\">https://arxiv.org/abs/1707.05031</a></p>\n<p><strong>Deformable Part-based Fully Convolutional Network for Object Detection</strong></p>\n<ul>\n<li>intro: BMVC 2017 (oral). Sorbonne Universités &amp; CEDRIC</li>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1707.06175\">https://arxiv.org/abs/1707.06175</a></li>\n</ul>\n<p><strong>Adaptive Feeding: Achieving Fast and Accurate Detections by Adaptively Combining Object Detectors</strong></p>\n<ul>\n<li>intro: ICCV 2017</li>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1707.06399\">https://arxiv.org/abs/1707.06399</a></li>\n</ul>\n<p><strong>Recurrent Scale Approximation for Object Detection in CNN</strong></p>\n<ul>\n<li>intro: ICCV 2017</li>\n<li>keywords: Recurrent Scale Approximation (RSA)</li>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1707.09531\">https://arxiv.org/abs/1707.09531</a></li>\n<li>github: <a href=\"https://github.com/sciencefans/RSA-for-object-detection\">https://github.com/sciencefans/RSA-for-object-detection</a></li>\n</ul>\n<h2 id=\"DSOD\"><a href=\"#DSOD\" class=\"headerlink\" title=\"DSOD\"></a>DSOD</h2><p><strong>DSOD: Learning Deeply Supervised Object Detectors from Scratch</strong></p>\n<p><img src=\"https://user-images.githubusercontent.com/3794909/28934967-718c9302-78b5-11e7-89ee-8b514e53e23c.png\" alt=\"img\"></p>\n<ul>\n<li>intro: ICCV 2017. Fudan University &amp; Tsinghua University &amp; Intel Labs China</li>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1708.01241\">https://arxiv.org/abs/1708.01241</a></li>\n<li>github: <a href=\"https://github.com/szq0214/DSOD\">https://github.com/szq0214/DSOD</a></li>\n<li>github:<a href=\"https://github.com/Windaway/DSOD-Tensorflow\">https://github.com/Windaway/DSOD-Tensorflow</a></li>\n<li>github:<a href=\"https://github.com/chenyuntc/dsod.pytorch\">https://github.com/chenyuntc/dsod.pytorch</a></li>\n</ul>\n<p><strong>Learning Object Detectors from Scratch with Gated Recurrent Feature Pyramids</strong></p>\n<ul>\n<li>arxiv:<a href=\"https://arxiv.org/abs/1712.00886\">https://arxiv.org/abs/1712.00886</a></li>\n<li>github:<a href=\"https://github.com/szq0214/GRP-DSOD\">https://github.com/szq0214/GRP-DSOD</a></li>\n</ul>\n<p><strong>Tiny-DSOD: Lightweight Object Detection for Resource-Restricted Usages</strong></p>\n<ul>\n<li>intro: BMVC 2018</li>\n<li>arXiv: <a href=\"https://arxiv.org/abs/1807.11013\">https://arxiv.org/abs/1807.11013</a></li>\n</ul>\n<p><strong>Object Detection from Scratch with Deep Supervision</strong></p>\n<ul>\n<li>intro: This is an extended version of DSOD</li>\n<li>arXiv: <a href=\"https://arxiv.org/abs/1809.09294\">https://arxiv.org/abs/1809.09294</a></li>\n</ul>\n<h2 id=\"RetinaNet\"><a href=\"#RetinaNet\" class=\"headerlink\" title=\"RetinaNet\"></a>RetinaNet</h2><p><strong>Focal Loss for Dense Object Detection</strong></p>\n<ul>\n<li>intro: ICCV 2017 Best student paper award. Facebook AI Research</li>\n<li>keywords: RetinaNet</li>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1708.02002\">https://arxiv.org/abs/1708.02002</a></li>\n</ul>\n<p><strong>CoupleNet: Coupling Global Structure with Local Parts for Object Detection</strong></p>\n<ul>\n<li>intro: ICCV 2017</li>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1708.02863\">https://arxiv.org/abs/1708.02863</a></li>\n</ul>\n<p><strong>Incremental Learning of Object Detectors without Catastrophic Forgetting</strong></p>\n<ul>\n<li>intro: ICCV 2017. Inria</li>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1708.06977\">https://arxiv.org/abs/1708.06977</a></li>\n</ul>\n<p><strong>Zoom Out-and-In Network with Map Attention Decision for Region Proposal and Object Detection</strong></p>\n<p><a href=\"https://arxiv.org/abs/1709.04347\">https://arxiv.org/abs/1709.04347</a></p>\n<p><strong>StairNet: Top-Down Semantic Aggregation for Accurate One Shot Detection</strong></p>\n<p><a href=\"https://arxiv.org/abs/1709.05788\">https://arxiv.org/abs/1709.05788</a></p>\n<p><strong>Dynamic Zoom-in Network for Fast Object Detection in Large Images</strong></p>\n<p><a href=\"https://arxiv.org/abs/1711.05187\">https://arxiv.org/abs/1711.05187</a></p>\n<p><strong>Zero-Annotation Object Detection with Web Knowledge Transfer</strong></p>\n<ul>\n<li>intro: NTU, Singapore &amp; Amazon</li>\n<li>keywords: multi-instance multi-label domain adaption learning framework</li>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1711.05954\">https://arxiv.org/abs/1711.05954</a></li>\n</ul>\n<h2 id=\"MegDet\"><a href=\"#MegDet\" class=\"headerlink\" title=\"MegDet\"></a>MegDet</h2><p><strong>MegDet: A Large Mini-Batch Object Detector</strong></p>\n<ul>\n<li>intro: Peking University &amp; Tsinghua University &amp; Megvii Inc</li>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1711.07240\">https://arxiv.org/abs/1711.07240</a></li>\n</ul>\n<p><strong>Receptive Field Block Net for Accurate and Fast Object Detection</strong></p>\n<ul>\n<li>intro: RFBNet</li>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1711.07767\">https://arxiv.org/abs/1711.07767</a></li>\n<li>github: <a href=\"https://github.com//ruinmessi/RFBNet\">https://github.com//ruinmessi/RFBNet</a></li>\n</ul>\n<p><strong>An Analysis of Scale Invariance in Object Detection - SNIP</strong></p>\n<ul>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1711.08189\">https://arxiv.org/abs/1711.08189</a></li>\n<li>github: <a href=\"https://github.com/bharatsingh430/snip\">https://github.com/bharatsingh430/snip</a></li>\n</ul>\n<p><strong>Feature Selective Networks for Object Detection</strong></p>\n<p><a href=\"https://arxiv.org/abs/1711.08879\">https://arxiv.org/abs/1711.08879</a></p>\n<p><strong>Learning a Rotation Invariant Detector with Rotatable Bounding Box</strong></p>\n<ul>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1711.09405\">https://arxiv.org/abs/1711.09405</a></li>\n<li>github: <a href=\"https://github.com/liulei01/DRBox\">https://github.com/liulei01/DRBox</a></li>\n</ul>\n<p><strong>Scalable Object Detection for Stylized Objects</strong></p>\n<ul>\n<li>intro: Microsoft AI &amp; Research Munich</li>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1711.09822\">https://arxiv.org/abs/1711.09822</a></li>\n</ul>\n<p><strong>Learning Object Detectors from Scratch with Gated Recurrent Feature Pyramids</strong></p>\n<ul>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1712.00886\">https://arxiv.org/abs/1712.00886</a></li>\n<li>github: <a href=\"https://github.com/szq0214/GRP-DSOD\">https://github.com/szq0214/GRP-DSOD</a></li>\n</ul>\n<p><strong>Deep Regionlets for Object Detection</strong></p>\n<ul>\n<li>keywords: region selection network, gating network</li>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1712.02408\">https://arxiv.org/abs/1712.02408</a></li>\n</ul>\n<p><strong>Training and Testing Object Detectors with Virtual Images</strong></p>\n<ul>\n<li>intro: IEEE&#x2F;CAA Journal of Automatica Sinica</li>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1712.08470\">https://arxiv.org/abs/1712.08470</a></li>\n</ul>\n<p><strong>Large-Scale Object Discovery and Detector Adaptation from Unlabeled Video</strong></p>\n<ul>\n<li>keywords: object mining, object tracking, unsupervised object discovery by appearance-based clustering, self-supervised detector adaptation</li>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1712.08832\">https://arxiv.org/abs/1712.08832</a></li>\n</ul>\n<p><strong>Spot the Difference by Object Detection</strong></p>\n<ul>\n<li>intro: Tsinghua University &amp; JD Group</li>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1801.01051\">https://arxiv.org/abs/1801.01051</a></li>\n</ul>\n<p><strong>Localization-Aware Active Learning for Object Detection</strong></p>\n<ul>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1801.05124\">https://arxiv.org/abs/1801.05124</a></li>\n</ul>\n<p><strong>Object Detection with Mask-based Feature Encoding</strong></p>\n<ul>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1802.03934\">https://arxiv.org/abs/1802.03934</a></li>\n</ul>\n<p><strong>LSTD: A Low-Shot Transfer Detector for Object Detection</strong></p>\n<ul>\n<li>intro: AAAI 2018</li>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1803.01529\">https://arxiv.org/abs/1803.01529</a></li>\n</ul>\n<p><strong>Pseudo Mask Augmented Object Detection</strong></p>\n<p><a href=\"https://arxiv.org/abs/1803.05858\">https://arxiv.org/abs/1803.05858</a></p>\n<p><strong>Revisiting RCNN: On Awakening the Classification Power of Faster RCNN</strong></p>\n<p><a href=\"https://arxiv.org/abs/1803.06799\">https://arxiv.org/abs/1803.06799</a></p>\n<p><strong>Learning Region Features for Object Detection</strong></p>\n<ul>\n<li>intro: Peking University &amp; MSRA</li>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1803.07066\">https://arxiv.org/abs/1803.07066</a></li>\n</ul>\n<p><strong>Single-Shot Bidirectional Pyramid Networks for High-Quality Object Detection</strong></p>\n<ul>\n<li>intro: Singapore Management University &amp; Zhejiang University</li>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1803.08208\">https://arxiv.org/abs/1803.08208</a></li>\n</ul>\n<p><strong>Object Detection for Comics using Manga109 Annotations</strong></p>\n<ul>\n<li>intro: University of Tokyo &amp; National Institute of Informatics, Japan</li>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1803.08670\">https://arxiv.org/abs/1803.08670</a></li>\n</ul>\n<p><strong>Task-Driven Super Resolution: Object Detection in Low-resolution Images</strong></p>\n<ul>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1803.11316\">https://arxiv.org/abs/1803.11316</a></li>\n</ul>\n<p><strong>Transferring Common-Sense Knowledge for Object Detection</strong></p>\n<ul>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1804.01077\">https://arxiv.org/abs/1804.01077</a></li>\n</ul>\n<p><strong>Multi-scale Location-aware Kernel Representation for Object Detection</strong></p>\n<ul>\n<li>intro: CVPR 2018</li>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1804.00428\">https://arxiv.org/abs/1804.00428</a></li>\n<li>github: <a href=\"https://github.com/Hwang64/MLKP\">https://github.com/Hwang64/MLKP</a></li>\n</ul>\n<p><strong>Loss Rank Mining: A General Hard Example Mining Method for Real-time Detectors</strong></p>\n<ul>\n<li>intro: National University of Defense Technology</li>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1804.04606\">https://arxiv.org/abs/1804.04606</a></li>\n</ul>\n<p><strong>Robust Physical Adversarial Attack on Faster R-CNN Object Detector</strong></p>\n<ul>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1804.05810\">https://arxiv.org/abs/1804.05810</a></li>\n</ul>\n<h2 id=\"RefineNet\"><a href=\"#RefineNet\" class=\"headerlink\" title=\"RefineNet\"></a>RefineNet</h2><p><strong>Single-Shot Refinement Neural Network for Object Detection</strong></p>\n<ul>\n<li><p>intro: CVPR 2018</p>\n</li>\n<li><p>arxiv: <a href=\"https://arxiv.org/abs/1711.06897\">https://arxiv.org/abs/1711.06897</a></p>\n</li>\n<li><p>github: <a href=\"https://github.com/sfzhang15/RefineDet\">https://github.com/sfzhang15/RefineDet</a></p>\n</li>\n<li><p>github: <a href=\"https://github.com/lzx1413/PytorchSSD\">https://github.com/lzx1413/PytorchSSD</a></p>\n</li>\n<li><p>github: <a href=\"https://github.com/ddlee96/RefineDet_mxnet\">https://github.com/ddlee96/RefineDet_mxnet</a></p>\n</li>\n<li><p>github: <a href=\"https://github.com/MTCloudVision/RefineDet-Mxnet\">https://github.com/MTCloudVision/RefineDet-Mxnet</a></p>\n</li>\n</ul>\n<h2 id=\"DetNet\"><a href=\"#DetNet\" class=\"headerlink\" title=\"DetNet\"></a>DetNet</h2><p><strong>DetNet: A Backbone network for Object Detection</strong></p>\n<ul>\n<li>intro: Tsinghua University &amp; Face++</li>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1804.06215\">https://arxiv.org/abs/1804.06215</a></li>\n</ul>\n<h2 id=\"SSOD\"><a href=\"#SSOD\" class=\"headerlink\" title=\"SSOD\"></a>SSOD</h2><p><strong>Self-supervisory Signals for Object Discovery and Detection</strong></p>\n<ul>\n<li>Google Brain</li>\n<li>arxiv:<a href=\"https://arxiv.org/abs/1806.03370\">https://arxiv.org/abs/1806.03370</a></li>\n</ul>\n<h2 id=\"CornerNet\"><a href=\"#CornerNet\" class=\"headerlink\" title=\"CornerNet\"></a>CornerNet</h2><p><strong>CornerNet: Detecting Objects as Paired Keypoints</strong></p>\n<ul>\n<li>intro: ECCV 2018</li>\n<li>arXiv: <a href=\"https://arxiv.org/abs/1808.01244\">https://arxiv.org/abs/1808.01244</a></li>\n<li>github: <a href=\"https://github.com/umich-vl/CornerNet\">https://github.com/umich-vl/CornerNet</a></li>\n</ul>\n<h2 id=\"M2Det\"><a href=\"#M2Det\" class=\"headerlink\" title=\"M2Det\"></a>M2Det</h2><p><strong>M2Det: A Single-Shot Object Detector based on Multi-Level Feature Pyramid Network</strong></p>\n<ul>\n<li>intro: AAAI 2019</li>\n<li>arXiv: <a href=\"https://arxiv.org/abs/1811.04533\">https://arxiv.org/abs/1811.04533</a></li>\n<li>github: <a href=\"https://github.com/qijiezhao/M2Det\">https://github.com/qijiezhao/M2Det</a></li>\n</ul>\n<h2 id=\"3D-Object-Detection\"><a href=\"#3D-Object-Detection\" class=\"headerlink\" title=\"3D Object Detection\"></a>3D Object Detection</h2><p><strong>3D Backbone Network for 3D Object Detection</strong></p>\n<ul>\n<li>arXiv: <a href=\"https://arxiv.org/abs/1901.08373\">https://arxiv.org/abs/1901.08373</a></li>\n</ul>\n<p><strong>LMNet: Real-time Multiclass Object Detection on CPU using 3D LiDARs</strong></p>\n<ul>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1805.04902\">https://arxiv.org/abs/1805.04902</a></li>\n<li>github: <a href=\"https://github.com/CPFL/Autoware/tree/feature/cnn_lidar_detection\">https://github.com/CPFL/Autoware/tree/feature/cnn_lidar_detection</a></li>\n</ul>\n<h2 id=\"ZSD（Zero-Shot-Object-Detection）\"><a href=\"#ZSD（Zero-Shot-Object-Detection）\" class=\"headerlink\" title=\"ZSD（Zero-Shot Object Detection）\"></a>ZSD（Zero-Shot Object Detection）</h2><p><strong>Zero-Shot Detection</strong></p>\n<ul>\n<li>intro: Australian National University</li>\n<li>keywords: YOLO</li>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1803.07113\">https://arxiv.org/abs/1803.07113</a></li>\n</ul>\n<p><strong>Zero-Shot Object Detection</strong></p>\n<ul>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1804.04340\">https://arxiv.org/abs/1804.04340</a></li>\n</ul>\n<p><strong>Zero-Shot Object Detection: Learning to Simultaneously Recognize and Localize Novel Concepts</strong></p>\n<ul>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1803.06049\">https://arxiv.org/abs/1803.06049</a></li>\n</ul>\n<p><strong>Zero-Shot Object Detection by Hybrid Region Embedding</strong></p>\n<ul>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1805.06157\">https://arxiv.org/abs/1805.06157</a></li>\n</ul>\n<h2 id=\"OSD（One-Shot-Object-Detection）\"><a href=\"#OSD（One-Shot-Object-Detection）\" class=\"headerlink\" title=\"OSD（One-Shot Object Detection）\"></a>OSD（One-Shot Object Detection）</h2><p><strong>Comparison Network for One-Shot Conditional Object Detection</strong></p>\n<ul>\n<li>arXiv: <a href=\"https://arxiv.org/abs/1904.02317\">https://arxiv.org/abs/1904.02317</a></li>\n</ul>\n<p><strong>One-Shot Object Detection</strong></p>\n<p>RepMet: Representative-based metric learning for classification and one-shot object detection</p>\n<ul>\n<li>intro: IBM Research AI</li>\n<li>arxiv:<a href=\"https://arxiv.org/abs/1806.04728\">https://arxiv.org/abs/1806.04728</a></li>\n<li>github: TODO</li>\n</ul>\n<h2 id=\"Weakly-Supervised-Object-Detection\"><a href=\"#Weakly-Supervised-Object-Detection\" class=\"headerlink\" title=\"Weakly Supervised Object Detection\"></a>Weakly Supervised Object Detection</h2><p><strong>Weakly Supervised Object Detection in Artworks</strong></p>\n<ul>\n<li>intro: ECCV 2018 Workshop Computer Vision for Art Analysis</li>\n<li>arXiv: <a href=\"https://arxiv.org/abs/1810.02569\">https://arxiv.org/abs/1810.02569</a></li>\n<li>Datasets: <a href=\"https://wsoda.telecom-paristech.fr/downloads/dataset/IconArt_v1.zip\">https://wsoda.telecom-paristech.fr/downloads/dataset/IconArt_v1.zip</a></li>\n</ul>\n<p><strong>Cross-Domain Weakly-Supervised Object Detection through Progressive Domain Adaptation</strong></p>\n<ul>\n<li>intro: CVPR 2018</li>\n<li>arXiv: <a href=\"https://arxiv.org/abs/1803.11365\">https://arxiv.org/abs/1803.11365</a></li>\n<li>homepage: <a href=\"https://naoto0804.github.io/cross_domain_detection/\">https://naoto0804.github.io/cross_domain_detection/</a></li>\n<li>paper: <a href=\"http://openaccess.thecvf.com/content_cvpr_2018/html/Inoue_Cross-Domain_Weakly-Supervised_Object_CVPR_2018_paper.html\">http://openaccess.thecvf.com/content_cvpr_2018/html/Inoue_Cross-Domain_Weakly-Supervised_Object_CVPR_2018_paper.html</a></li>\n<li>github: <a href=\"https://github.com/naoto0804/cross-domain-detection\">https://github.com/naoto0804/cross-domain-detection</a></li>\n</ul>\n<h2 id=\"Softer-NMS\"><a href=\"#Softer-NMS\" class=\"headerlink\" title=\"Softer-NMS\"></a>Softer-NMS</h2><p><strong>《Softer-NMS: Rethinking Bounding Box Regression for Accurate Object Detection》</strong></p>\n<ul>\n<li>intro: CMU &amp; Face++</li>\n<li>arXiv: <a href=\"https://arxiv.org/abs/1809.08545\">https://arxiv.org/abs/1809.08545</a></li>\n<li>github: <a href=\"https://github.com/yihui-he/softer-NMS\">https://github.com/yihui-he/softer-NMS</a></li>\n</ul>\n<h2 id=\"2019\"><a href=\"#2019\" class=\"headerlink\" title=\"2019\"></a>2019</h2><p><strong>Feature Selective Anchor-Free Module for Single-Shot Object Detection</strong></p>\n<ul>\n<li><p>intro: CVPR 2019</p>\n</li>\n<li><p>arXiv: <a href=\"https://arxiv.org/abs/1903.00621\">https://arxiv.org/abs/1903.00621</a></p>\n</li>\n</ul>\n<p><strong>Object Detection based on Region Decomposition and Assembly</strong></p>\n<ul>\n<li><p>intro: AAAI 2019</p>\n</li>\n<li><p>arXiv: <a href=\"https://arxiv.org/abs/1901.08225\">https://arxiv.org/abs/1901.08225</a></p>\n</li>\n</ul>\n<p><strong>Bottom-up Object Detection by Grouping Extreme and Center Points</strong></p>\n<ul>\n<li>intro: one stage 43.2% on COCO test-dev</li>\n<li>arXiv: <a href=\"https://arxiv.org/abs/1901.08043\">https://arxiv.org/abs/1901.08043</a></li>\n<li>github: <a href=\"https://github.com/xingyizhou/ExtremeNet\">https://github.com/xingyizhou/ExtremeNet</a></li>\n</ul>\n<p><strong>ORSIm Detector: A Novel Object Detection Framework in Optical Remote Sensing Imagery Using Spatial-Frequency Channel Features</strong></p>\n<ul>\n<li><p>intro: IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING</p>\n</li>\n<li><p>arXiv: <a href=\"https://arxiv.org/abs/1901.07925\">https://arxiv.org/abs/1901.07925</a></p>\n</li>\n</ul>\n<p><strong>Consistent Optimization for Single-Shot Object Detection</strong></p>\n<ul>\n<li><p>intro: improves RetinaNet from 39.1 AP to 40.1 AP on COCO datase</p>\n</li>\n<li><p>arXiv: <a href=\"https://arxiv.org/abs/1901.06563\">https://arxiv.org/abs/1901.06563</a></p>\n</li>\n</ul>\n<p><strong>Learning Pairwise Relationship for Multi-object Detection in Crowded Scenes</strong></p>\n<ul>\n<li>arXiv: <a href=\"https://arxiv.org/abs/1901.03796\">https://arxiv.org/abs/1901.03796</a></li>\n</ul>\n<p><strong>RetinaMask: Learning to predict masks improves state-of-the-art single-shot detection for free</strong></p>\n<ul>\n<li>arXiv: <a href=\"https://arxiv.org/abs/1901.03353\">https://arxiv.org/abs/1901.03353</a></li>\n<li>github: <a href=\"https://github.com/chengyangfu/retinamask\">https://github.com/chengyangfu/retinamask</a></li>\n</ul>\n<p><strong>Region Proposal by Guided Anchoring</strong></p>\n<ul>\n<li>intro: CUHK - SenseTime Joint Lab</li>\n<li>arXiv: <a href=\"https://arxiv.org/abs/1901.03278\">https://arxiv.org/abs/1901.03278</a></li>\n</ul>\n<p><strong>Scale-Aware Trident Networks for Object Detection</strong></p>\n<ul>\n<li>intro: mAP of <strong>48.4</strong> on the COCO dataset</li>\n<li>arXiv: <a href=\"https://arxiv.org/abs/1901.01892\">https://arxiv.org/abs/1901.01892</a></li>\n</ul>\n<h2 id=\"2018\"><a href=\"#2018\" class=\"headerlink\" title=\"2018\"></a>2018</h2><p><strong>Large-Scale Object Detection of Images from Network Cameras in Variable Ambient Lighting Conditions</strong></p>\n<ul>\n<li>arXiv: <a href=\"https://arxiv.org/abs/1812.11901\">https://arxiv.org/abs/1812.11901</a></li>\n</ul>\n<p><strong>Strong-Weak Distribution Alignment for Adaptive Object Detection</strong></p>\n<ul>\n<li>arXiv: <a href=\"https://arxiv.org/abs/1812.04798\">https://arxiv.org/abs/1812.04798</a></li>\n</ul>\n<p><strong>AutoFocus: Efficient Multi-Scale Inference</strong></p>\n<ul>\n<li>intro: AutoFocus obtains an <strong>mAP of 47.9%</strong> (68.3% at 50% overlap) on the <strong>COCO test-dev</strong> set while processing <strong>6.4 images per second on a Titan X (Pascal) GPU</strong> </li>\n<li>arXiv: <a href=\"https://arxiv.org/abs/1812.01600\">https://arxiv.org/abs/1812.01600</a></li>\n</ul>\n<p><strong>NOTE-RCNN: NOise Tolerant Ensemble RCNN for Semi-Supervised Object Detection</strong></p>\n<ul>\n<li>intro: Google Could</li>\n<li>arXiv: <a href=\"https://arxiv.org/abs/1812.00124\">https://arxiv.org/abs/1812.00124</a></li>\n</ul>\n<p><strong>SPLAT: Semantic Pixel-Level Adaptation Transforms for Detection</strong></p>\n<ul>\n<li>intro: UC Berkeley</li>\n<li>arXiv: <a href=\"https://arxiv.org/abs/1812.00929\">https://arxiv.org/abs/1812.00929</a></li>\n</ul>\n<p><strong>Grid R-CNN</strong></p>\n<ul>\n<li>intro: SenseTime</li>\n<li>arXiv: <a href=\"https://arxiv.org/abs/1811.12030\">https://arxiv.org/abs/1811.12030</a></li>\n</ul>\n<p><strong>Deformable ConvNets v2: More Deformable, Better Results</strong></p>\n<ul>\n<li><p>intro: Microsoft Research Asia</p>\n</li>\n<li><p>arXiv: <a href=\"https://arxiv.org/abs/1811.11168\">https://arxiv.org/abs/1811.11168</a></p>\n</li>\n</ul>\n<p><strong>Anchor Box Optimization for Object Detection</strong></p>\n<ul>\n<li>intro: Microsoft Research</li>\n<li>arXiv: <a href=\"https://arxiv.org/abs/1812.00469\">https://arxiv.org/abs/1812.00469</a></li>\n</ul>\n<p><strong>Efficient Coarse-to-Fine Non-Local Module for the Detection of Small Objects</strong></p>\n<ul>\n<li>intro: <a href=\"https://arxiv.org/abs/1811.12152\">https://arxiv.org/abs/1811.12152</a></li>\n</ul>\n<p><strong>NOTE-RCNN: NOise Tolerant Ensemble RCNN for Semi-Supervised Object Detection</strong></p>\n<ul>\n<li>arXiv: <a href=\"https://arxiv.org/abs/1812.00124\">https://arxiv.org/abs/1812.00124</a></li>\n</ul>\n<p><strong>Learning RoI Transformer for Detecting Oriented Objects in Aerial Images</strong></p>\n<ul>\n<li>arXiv: <a href=\"https://arxiv.org/abs/1812.00155\">https://arxiv.org/abs/1812.00155</a></li>\n</ul>\n<p><strong>Integrated Object Detection and Tracking with Tracklet-Conditioned Detection</strong></p>\n<ul>\n<li>intro: Microsoft Research Asia</li>\n<li>arXiv: <a href=\"https://arxiv.org/abs/1811.11167\">https://arxiv.org/abs/1811.11167</a></li>\n</ul>\n<p><strong>Deep Regionlets: Blended Representation and Deep Learning for Generic Object Detection</strong></p>\n<ul>\n<li>arXiv: <a href=\"https://arxiv.org/abs/1811.11318\">https://arxiv.org/abs/1811.11318</a></li>\n</ul>\n<p> <strong>Gradient Harmonized Single-stage Detector</strong></p>\n<ul>\n<li>intro: AAAI 2019</li>\n<li>arXiv: <a href=\"https://arxiv.org/abs/1811.05181\">https://arxiv.org/abs/1811.05181</a></li>\n</ul>\n<p><strong>CFENet: Object Detection with Comprehensive Feature Enhancement Module</strong></p>\n<ul>\n<li>intro: ACCV 2018</li>\n<li>github: <a href=\"https://github.com/qijiezhao/CFENet\">https://github.com/qijiezhao/CFENet</a></li>\n</ul>\n<p><strong>DeRPN: Taking a further step toward more general object detection</strong></p>\n<ul>\n<li>intro: AAAI 2019</li>\n<li>arXiv: <a href=\"https://arxiv.org/abs/1811.06700\">https://arxiv.org/abs/1811.06700</a></li>\n<li>github: <a href=\"https://github.com/HCIILAB/DeRPN\">https://github.com/HCIILAB/DeRPN</a></li>\n</ul>\n<p><strong>Hybrid Knowledge Routed Modules for Large-scale Object Detection</strong></p>\n<ul>\n<li>intro: Sun Yat-Sen University &amp; Huawei Noah’s Ark Lab</li>\n<li>arXiv: <a href=\"https://arxiv.org/abs/1810.12681\">https://arxiv.org/abs/1810.12681</a></li>\n<li>github: <a href=\"https://github.com/chanyn/HKRM\">https://github.com/chanyn/HKRM</a></li>\n</ul>\n<p><strong>《Receptive Field Block Net for Accurate and Fast Object Detection》</strong></p>\n<ul>\n<li>intro: ECCV 2018</li>\n<li>arXiv: <a href=\"https://arxiv.org/abs/1711.07767\">https://arxiv.org/abs/1711.07767</a></li>\n<li>github: <a href=\"https://github.com/ruinmessi/RFBNet\">https://github.com/ruinmessi/RFBNet</a></li>\n</ul>\n<p><strong>Deep Feature Pyramid Reconfiguration for Object Detection</strong></p>\n<ul>\n<li>intro: ECCV 2018</li>\n<li>arXiv: <a href=\"https://arxiv.org/abs/1808.07993\">https://arxiv.org/abs/1808.07993</a></li>\n</ul>\n<p><strong>Unsupervised Hard Example Mining from Videos for Improved Object Detection</strong></p>\n<ul>\n<li>intro: ECCV 2018</li>\n<li>arXiv: <a href=\"https://arxiv.org/abs/1808.04285\">https://arxiv.org/abs/1808.04285</a></li>\n</ul>\n<p><strong>Acquisition of Localization Confidence for Accurate Object Detection</strong></p>\n<ul>\n<li>intro: ECCV 2018</li>\n<li>arXiv: <a href=\"https://arxiv.org/abs/1807.11590\">https://arxiv.org/abs/1807.11590</a></li>\n<li>github: <a href=\"https://github.com/vacancy/PreciseRoIPooling\">https://github.com/vacancy/PreciseRoIPooling</a></li>\n</ul>\n<p><strong>Toward Scale-Invariance and Position-Sensitive Region Proposal Networks</strong></p>\n<ul>\n<li>intro: ECCV 2018</li>\n<li>arXiv: <a href=\"https://arxiv.org/abs/1807.09528\">https://arxiv.org/abs/1807.09528</a></li>\n</ul>\n<p><strong>MetaAnchor: Learning to Detect Objects with Customized Anchors</strong></p>\n<ul>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1807.00980\">https://arxiv.org/abs/1807.00980</a></li>\n</ul>\n<p><strong>Relation Network for Object Detection</strong></p>\n<ul>\n<li>intro: CVPR 2018</li>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1711.11575\">https://arxiv.org/abs/1711.11575</a></li>\n<li>github:<a href=\"https://github.com/msracver/Relation-Networks-for-Object-Detection\">https://github.com/msracver/Relation-Networks-for-Object-Detection</a></li>\n</ul>\n<p><strong>Quantization Mimic: Towards Very Tiny CNN for Object Detection</strong></p>\n<ul>\n<li>Tsinghua University1 &amp; The Chinese University of Hong Kong2 &amp;SenseTime3</li>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1805.02152\">https://arxiv.org/abs/1805.02152</a></li>\n</ul>\n<p><strong>Learning Rich Features for Image Manipulation Detection</strong></p>\n<ul>\n<li>intro: CVPR 2018 Camera Ready</li>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1805.04953\">https://arxiv.org/abs/1805.04953</a></li>\n</ul>\n<p><strong>SNIPER: Efficient Multi-Scale Training</strong></p>\n<ul>\n<li>arxiv:<a href=\"https://arxiv.org/abs/1805.09300\">https://arxiv.org/abs/1805.09300</a></li>\n<li>github:<a href=\"https://github.com/mahyarnajibi/SNIPER\">https://github.com/mahyarnajibi/SNIPER</a></li>\n</ul>\n<p><strong>Soft Sampling for Robust Object Detection</strong></p>\n<ul>\n<li>intro: the robustness of object detection under the presence of missing annotations</li>\n<li>arxiv:<a href=\"https://arxiv.org/abs/1806.06986\">https://arxiv.org/abs/1806.06986</a></li>\n</ul>\n<p><strong>Cost-effective Object Detection: Active Sample Mining with Switchable Selection Criteria</strong></p>\n<ul>\n<li>intro: TNNLS 2018</li>\n<li>arxiv:<a href=\"https://arxiv.org/abs/1807.00147\">https://arxiv.org/abs/1807.00147</a></li>\n<li>code: <a href=\"http://kezewang.com/codes/ASM_ver1.zip\">http://kezewang.com/codes/ASM_ver1.zip</a></li>\n</ul>\n<h2 id=\"Other\"><a href=\"#Other\" class=\"headerlink\" title=\"Other\"></a>Other</h2><p><strong>R3-Net: A Deep Network for Multi-oriented Vehicle Detection in Aerial Images and Videos</strong></p>\n<ul>\n<li>arxiv: <a href=\"https://arxiv.org/abs/1808.05560\">https://arxiv.org/abs/1808.05560</a></li>\n<li>youtube: <a href=\"https://youtu.be/xCYD-tYudN0\">https://youtu.be/xCYD-tYudN0</a></li>\n</ul>\n<h1 id=\"Detection-Toolbox\"><a href=\"#Detection-Toolbox\" class=\"headerlink\" title=\"Detection Toolbox\"></a>Detection Toolbox</h1><ul>\n<li><a href=\"https://github.com/facebookresearch/Detectron\">Detectron(FAIR)</a>: Detectron is Facebook AI Research’s software system that implements state-of-the-art object detection algorithms, including <a href=\"https://arxiv.org/abs/1703.06870\">Mask R-CNN</a>. It is written in Python and powered by the <a href=\"https://github.com/caffe2/caffe2\">Caffe2</a> deep learning framework.</li>\n<li><a href=\"https://github.com/facebookresearch/detectron2\">Detectron2</a>: Detectron2 is FAIR’s next-generation research platform for object detection and segmentation.</li>\n<li><a href=\"https://github.com/facebookresearch/maskrcnn-benchmark\">maskrcnn-benchmark(FAIR)</a>: Fast, modular reference implementation of Instance Segmentation and Object Detection algorithms in PyTorch.</li>\n<li><a href=\"https://github.com/open-mmlab/mmdetection\">mmdetection(SenseTime&amp;CUHK)</a>: mmdetection is an open source object detection toolbox based on PyTorch. It is a part of the open-mmlab project developed by <a href=\"http://mmlab.ie.cuhk.edu.hk/\">Multimedia Laboratory, CUHK</a>.</li>\n</ul>"},{"title":"如何让大脑保持敏锐？","abbrlink":"858f56c0","date":"2024-06-14T11:55:58.000Z","_content":"&emsp;&emsp;如何让你的大脑保持年轻敏锐。\n<!--less-->\n&emsp;&emsp;答案是学习新技能和改变生活方式。研究人员对约650万65岁及以上的患有阿尔茨海默病的美国人进行研究发现，学习演奏乐器或从事园艺可能会有帮助。耶鲁大学医学院的神经学家卡罗琳·弗雷德里克斯说：“超过30%的痴呆风险是可以逆转的。” 患有高血压、抑郁症、糖尿病或有吸烟和久坐生活方式的人，大脑认知能力下降的风会险增大。研究表明，尽管存在这些不利的遗传因素或生活习惯，对大脑的刺激和挑战可以延缓认知能力下降并降低痴呆的风险。\n\n&emsp;&emsp;阿尔茨海默病如何导致死亡？做填字游戏或玩国际象棋和桥牌等战略游戏无疑对大脑有好处。此外学习任何新的有趣的技能同样有益——无论是学习新语言、爱好还是运动。因此，选择一些吸引你的、能刺激大脑的活动，这些终身学习过程都能保持你的大脑突触的活跃。以下是她分享的一些入门想法：\n\n1. 社交。人类是社交动物，我们需要社交互动以获得最佳健康状态。在新冠大流行期间，弗雷德里克斯说，一些无法适应虚拟会议的老年患者感到非常孤独。多项研究发现，孤立可能影响认知以及情绪。她建议人们参与能让他们与其他人互动的活动。如果这些活动能刺激你的大脑或让你的身体动起来，那就更好了。例如，与伴侣跳舞。阅读也很好，如果能成为一个读书俱乐部的一员，与其他会员交流并讨论书籍内容会更好。\n\n2. 出汗。这对心脏和大脑都有好处。阿尔茨海默病协会研究称，当人们有损害心脏和血管的活动习惯时，发展成阿尔茨海默病或血管性痴呆、心脏病、高血压、中风、糖尿病的风险都会增高。为了心脏和大脑健康，协会的指南建议人每周至少进行5次、每次30分钟的“中等强度”运动，或者每周3次、每次1小时的“高等强度”运动。“如果你和我正在徒步旅行，我们正爬山，我们喘不过气来，但还没有到不能互相交谈的程度，”她说，“这就是推荐的中等强度。”\n\n3. 戒烟。研究人员发现，那些每天吸一包烟超过10年的人在40多岁时就会出现认知障碍。另一方面，那些戒烟或被定义为轻度吸烟者的人并没有同样的认知能力下降。研究表明，烟民在戒烟后也会对身体造成伤害，但越早戒烟越好。\n\n4. 吃大脑“喜欢”的食物。关于饮食和认知功能的关系，最近发表在《营养学进展》上的一项研究认为三种饮食------地中海饮食、DASH（阻止高血压的饮食方法）和MIND（地中海-DASH神经退行性延迟干预）可能会降低你认知能力下降的风险。“如果你在意大利海岸度假时会吃什么，”弗雷德里克斯说。“鱼类、精益蛋白、豆类、其他蔬菜来源的蛋白，以及一系列水果和蔬菜——特别是深色、绿叶蔬菜，这些似乎对保持认知功能有特定的好处。”此外，选择橄榄油而不是黄油，并选择全谷物，她继续说：“这真的不是一种限制性饮食，而是一种似乎对大脑非常有益的饮食习惯。”\n\n5. 限制饮酒。为了降低痴呆风险，遵循CDC的指南，女性饮酒每天不应超过一杯，男性每天不超过两杯。当然，一周内戒酒并不意味着你可以在周末安全地多喝。已经有认知能力下降症状的人应该避免所有酒精摄入——因为任何剂量的酒精都会对认知能力有影响，对大脑是毒物。\n\n6. 应对压力。尽管无法避免所有压力，但你可以采取措施减少其伤害。RAND公司高级行为和社会科学家、睡眠基金会科学顾问温迪·特罗克斯建议每天做这些压力管理技巧：太极、瑜伽、冥想、正念练习、运动。\n\n7. 充足的睡眠。我们的大脑每晚至少需要七小时的休息睡眠来休息和充电。为睡眠做准备（比如：至少在睡前30分钟远离屏幕）还有额外的好处，可以保持我们的思维敏锐。如果你感到压力，特罗克斯说，“重要的是在晚上放松，并在睡前尽量降低压力水平。”为了促进心态平稳以及幸福感的获得以提高睡眠质量，她提出了这些建议：洗个热水澡、和伴侣拥抱、在日记中写下至少三件你感激的事情。\n\n8. 保护你的大脑。失去意识的脑损伤，可能会增加你认知能力下降和痴呆的风险。因此，坐车要系安全带，骑自行车或机动车辆、滑雪、滑冰、滑板或玩美式足球等接触性运动时要佩戴头盔。你还可以采取措施预防跌倒。\n\n9. 注意心理健康问题。一些研究将抑郁史与认知能力下降的风险联系起来，包括2013年发表在《心理医学》上的一篇文章。另一项最近发表在《神经精神药物治疗》上的研究，发现一种名为沃替西汀的抗抑郁药物有助于治疗认知功能和抑郁症。在我们国家遇到抑郁症还是去看医生吧，别乱吃药。\n\n10. 花时间与年轻人相处。另一种社交和学习新技能的方式是与不同代际的人互动。2019年发表在《衰老研究评论》上的一篇综述中，研究人员发现，与年轻人有交流的老年人比那些只与同龄人交往的人表现出更缓慢的认知能力下降趋势。研究人员发现这种交往会缓解焦虑，孤独和抑郁，这些都是促进大脑健康的因素。也就是说与孙子们共度时光对你有好处！\n\n\n","source":"_posts/2024-06-14-how-to-make-the-brain-sharp.md","raw":"---\ntitle: 如何让大脑保持敏锐？\nabbrlink: 858f56c0\ndate: 2024-06-14 19:55:58\ncategories:\n  - 学习\ntags:\n  - 大脑\n---\n&emsp;&emsp;如何让你的大脑保持年轻敏锐。\n<!--less-->\n&emsp;&emsp;答案是学习新技能和改变生活方式。研究人员对约650万65岁及以上的患有阿尔茨海默病的美国人进行研究发现，学习演奏乐器或从事园艺可能会有帮助。耶鲁大学医学院的神经学家卡罗琳·弗雷德里克斯说：“超过30%的痴呆风险是可以逆转的。” 患有高血压、抑郁症、糖尿病或有吸烟和久坐生活方式的人，大脑认知能力下降的风会险增大。研究表明，尽管存在这些不利的遗传因素或生活习惯，对大脑的刺激和挑战可以延缓认知能力下降并降低痴呆的风险。\n\n&emsp;&emsp;阿尔茨海默病如何导致死亡？做填字游戏或玩国际象棋和桥牌等战略游戏无疑对大脑有好处。此外学习任何新的有趣的技能同样有益——无论是学习新语言、爱好还是运动。因此，选择一些吸引你的、能刺激大脑的活动，这些终身学习过程都能保持你的大脑突触的活跃。以下是她分享的一些入门想法：\n\n1. 社交。人类是社交动物，我们需要社交互动以获得最佳健康状态。在新冠大流行期间，弗雷德里克斯说，一些无法适应虚拟会议的老年患者感到非常孤独。多项研究发现，孤立可能影响认知以及情绪。她建议人们参与能让他们与其他人互动的活动。如果这些活动能刺激你的大脑或让你的身体动起来，那就更好了。例如，与伴侣跳舞。阅读也很好，如果能成为一个读书俱乐部的一员，与其他会员交流并讨论书籍内容会更好。\n\n2. 出汗。这对心脏和大脑都有好处。阿尔茨海默病协会研究称，当人们有损害心脏和血管的活动习惯时，发展成阿尔茨海默病或血管性痴呆、心脏病、高血压、中风、糖尿病的风险都会增高。为了心脏和大脑健康，协会的指南建议人每周至少进行5次、每次30分钟的“中等强度”运动，或者每周3次、每次1小时的“高等强度”运动。“如果你和我正在徒步旅行，我们正爬山，我们喘不过气来，但还没有到不能互相交谈的程度，”她说，“这就是推荐的中等强度。”\n\n3. 戒烟。研究人员发现，那些每天吸一包烟超过10年的人在40多岁时就会出现认知障碍。另一方面，那些戒烟或被定义为轻度吸烟者的人并没有同样的认知能力下降。研究表明，烟民在戒烟后也会对身体造成伤害，但越早戒烟越好。\n\n4. 吃大脑“喜欢”的食物。关于饮食和认知功能的关系，最近发表在《营养学进展》上的一项研究认为三种饮食------地中海饮食、DASH（阻止高血压的饮食方法）和MIND（地中海-DASH神经退行性延迟干预）可能会降低你认知能力下降的风险。“如果你在意大利海岸度假时会吃什么，”弗雷德里克斯说。“鱼类、精益蛋白、豆类、其他蔬菜来源的蛋白，以及一系列水果和蔬菜——特别是深色、绿叶蔬菜，这些似乎对保持认知功能有特定的好处。”此外，选择橄榄油而不是黄油，并选择全谷物，她继续说：“这真的不是一种限制性饮食，而是一种似乎对大脑非常有益的饮食习惯。”\n\n5. 限制饮酒。为了降低痴呆风险，遵循CDC的指南，女性饮酒每天不应超过一杯，男性每天不超过两杯。当然，一周内戒酒并不意味着你可以在周末安全地多喝。已经有认知能力下降症状的人应该避免所有酒精摄入——因为任何剂量的酒精都会对认知能力有影响，对大脑是毒物。\n\n6. 应对压力。尽管无法避免所有压力，但你可以采取措施减少其伤害。RAND公司高级行为和社会科学家、睡眠基金会科学顾问温迪·特罗克斯建议每天做这些压力管理技巧：太极、瑜伽、冥想、正念练习、运动。\n\n7. 充足的睡眠。我们的大脑每晚至少需要七小时的休息睡眠来休息和充电。为睡眠做准备（比如：至少在睡前30分钟远离屏幕）还有额外的好处，可以保持我们的思维敏锐。如果你感到压力，特罗克斯说，“重要的是在晚上放松，并在睡前尽量降低压力水平。”为了促进心态平稳以及幸福感的获得以提高睡眠质量，她提出了这些建议：洗个热水澡、和伴侣拥抱、在日记中写下至少三件你感激的事情。\n\n8. 保护你的大脑。失去意识的脑损伤，可能会增加你认知能力下降和痴呆的风险。因此，坐车要系安全带，骑自行车或机动车辆、滑雪、滑冰、滑板或玩美式足球等接触性运动时要佩戴头盔。你还可以采取措施预防跌倒。\n\n9. 注意心理健康问题。一些研究将抑郁史与认知能力下降的风险联系起来，包括2013年发表在《心理医学》上的一篇文章。另一项最近发表在《神经精神药物治疗》上的研究，发现一种名为沃替西汀的抗抑郁药物有助于治疗认知功能和抑郁症。在我们国家遇到抑郁症还是去看医生吧，别乱吃药。\n\n10. 花时间与年轻人相处。另一种社交和学习新技能的方式是与不同代际的人互动。2019年发表在《衰老研究评论》上的一篇综述中，研究人员发现，与年轻人有交流的老年人比那些只与同龄人交往的人表现出更缓慢的认知能力下降趋势。研究人员发现这种交往会缓解焦虑，孤独和抑郁，这些都是促进大脑健康的因素。也就是说与孙子们共度时光对你有好处！\n\n\n","slug":"how-to-make-the-brain-sharp","published":1,"updated":"2024-06-15T10:47:39.949Z","comments":1,"layout":"post","photos":[],"_id":"cmh498ipo007lwvou9ex12wpm","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>&emsp;&emsp;答案是学习新技能和改变生活方式。研究人员对约650万65岁及以上的患有阿尔茨海默病的美国人进行研究发现，学习演奏乐器或从事园艺可能会有帮助。耶鲁大学医学院的神经学家卡罗琳·弗雷德里克斯说：“超过30%的痴呆风险是可以逆转的。” 患有高血压、抑郁症、糖尿病或有吸烟和久坐生活方式的人，大脑认知能力下降的风会险增大。研究表明，尽管存在这些不利的遗传因素或生活习惯，对大脑的刺激和挑战可以延缓认知能力下降并降低痴呆的风险。</p>\n<p>&emsp;&emsp;阿尔茨海默病如何导致死亡？做填字游戏或玩国际象棋和桥牌等战略游戏无疑对大脑有好处。此外学习任何新的有趣的技能同样有益——无论是学习新语言、爱好还是运动。因此，选择一些吸引你的、能刺激大脑的活动，这些终身学习过程都能保持你的大脑突触的活跃。以下是她分享的一些入门想法：</p>\n<ol>\n<li><p>社交。人类是社交动物，我们需要社交互动以获得最佳健康状态。在新冠大流行期间，弗雷德里克斯说，一些无法适应虚拟会议的老年患者感到非常孤独。多项研究发现，孤立可能影响认知以及情绪。她建议人们参与能让他们与其他人互动的活动。如果这些活动能刺激你的大脑或让你的身体动起来，那就更好了。例如，与伴侣跳舞。阅读也很好，如果能成为一个读书俱乐部的一员，与其他会员交流并讨论书籍内容会更好。</p>\n</li>\n<li><p>出汗。这对心脏和大脑都有好处。阿尔茨海默病协会研究称，当人们有损害心脏和血管的活动习惯时，发展成阿尔茨海默病或血管性痴呆、心脏病、高血压、中风、糖尿病的风险都会增高。为了心脏和大脑健康，协会的指南建议人每周至少进行5次、每次30分钟的“中等强度”运动，或者每周3次、每次1小时的“高等强度”运动。“如果你和我正在徒步旅行，我们正爬山，我们喘不过气来，但还没有到不能互相交谈的程度，”她说，“这就是推荐的中等强度。”</p>\n</li>\n<li><p>戒烟。研究人员发现，那些每天吸一包烟超过10年的人在40多岁时就会出现认知障碍。另一方面，那些戒烟或被定义为轻度吸烟者的人并没有同样的认知能力下降。研究表明，烟民在戒烟后也会对身体造成伤害，但越早戒烟越好。</p>\n</li>\n<li><p>吃大脑“喜欢”的食物。关于饮食和认知功能的关系，最近发表在《营养学进展》上的一项研究认为三种饮食——地中海饮食、DASH（阻止高血压的饮食方法）和MIND（地中海-DASH神经退行性延迟干预）可能会降低你认知能力下降的风险。“如果你在意大利海岸度假时会吃什么，”弗雷德里克斯说。“鱼类、精益蛋白、豆类、其他蔬菜来源的蛋白，以及一系列水果和蔬菜——特别是深色、绿叶蔬菜，这些似乎对保持认知功能有特定的好处。”此外，选择橄榄油而不是黄油，并选择全谷物，她继续说：“这真的不是一种限制性饮食，而是一种似乎对大脑非常有益的饮食习惯。”</p>\n</li>\n<li><p>限制饮酒。为了降低痴呆风险，遵循CDC的指南，女性饮酒每天不应超过一杯，男性每天不超过两杯。当然，一周内戒酒并不意味着你可以在周末安全地多喝。已经有认知能力下降症状的人应该避免所有酒精摄入——因为任何剂量的酒精都会对认知能力有影响，对大脑是毒物。</p>\n</li>\n<li><p>应对压力。尽管无法避免所有压力，但你可以采取措施减少其伤害。RAND公司高级行为和社会科学家、睡眠基金会科学顾问温迪·特罗克斯建议每天做这些压力管理技巧：太极、瑜伽、冥想、正念练习、运动。</p>\n</li>\n<li><p>充足的睡眠。我们的大脑每晚至少需要七小时的休息睡眠来休息和充电。为睡眠做准备（比如：至少在睡前30分钟远离屏幕）还有额外的好处，可以保持我们的思维敏锐。如果你感到压力，特罗克斯说，“重要的是在晚上放松，并在睡前尽量降低压力水平。”为了促进心态平稳以及幸福感的获得以提高睡眠质量，她提出了这些建议：洗个热水澡、和伴侣拥抱、在日记中写下至少三件你感激的事情。</p>\n</li>\n<li><p>保护你的大脑。失去意识的脑损伤，可能会增加你认知能力下降和痴呆的风险。因此，坐车要系安全带，骑自行车或机动车辆、滑雪、滑冰、滑板或玩美式足球等接触性运动时要佩戴头盔。你还可以采取措施预防跌倒。</p>\n</li>\n<li><p>注意心理健康问题。一些研究将抑郁史与认知能力下降的风险联系起来，包括2013年发表在《心理医学》上的一篇文章。另一项最近发表在《神经精神药物治疗》上的研究，发现一种名为沃替西汀的抗抑郁药物有助于治疗认知功能和抑郁症。在我们国家遇到抑郁症还是去看医生吧，别乱吃药。</p>\n</li>\n<li><p>花时间与年轻人相处。另一种社交和学习新技能的方式是与不同代际的人互动。2019年发表在《衰老研究评论》上的一篇综述中，研究人员发现，与年轻人有交流的老年人比那些只与同龄人交往的人表现出更缓慢的认知能力下降趋势。研究人员发现这种交往会缓解焦虑，孤独和抑郁，这些都是促进大脑健康的因素。也就是说与孙子们共度时光对你有好处！</p>\n</li>\n</ol>","related_posts":[],"length":1930,"excerpt":"<p>&emsp;&emsp;如何让你的大脑保持年轻敏锐。</p>","more":"<p>&emsp;&emsp;答案是学习新技能和改变生活方式。研究人员对约650万65岁及以上的患有阿尔茨海默病的美国人进行研究发现，学习演奏乐器或从事园艺可能会有帮助。耶鲁大学医学院的神经学家卡罗琳·弗雷德里克斯说：“超过30%的痴呆风险是可以逆转的。” 患有高血压、抑郁症、糖尿病或有吸烟和久坐生活方式的人，大脑认知能力下降的风会险增大。研究表明，尽管存在这些不利的遗传因素或生活习惯，对大脑的刺激和挑战可以延缓认知能力下降并降低痴呆的风险。</p>\n<p>&emsp;&emsp;阿尔茨海默病如何导致死亡？做填字游戏或玩国际象棋和桥牌等战略游戏无疑对大脑有好处。此外学习任何新的有趣的技能同样有益——无论是学习新语言、爱好还是运动。因此，选择一些吸引你的、能刺激大脑的活动，这些终身学习过程都能保持你的大脑突触的活跃。以下是她分享的一些入门想法：</p>\n<ol>\n<li><p>社交。人类是社交动物，我们需要社交互动以获得最佳健康状态。在新冠大流行期间，弗雷德里克斯说，一些无法适应虚拟会议的老年患者感到非常孤独。多项研究发现，孤立可能影响认知以及情绪。她建议人们参与能让他们与其他人互动的活动。如果这些活动能刺激你的大脑或让你的身体动起来，那就更好了。例如，与伴侣跳舞。阅读也很好，如果能成为一个读书俱乐部的一员，与其他会员交流并讨论书籍内容会更好。</p>\n</li>\n<li><p>出汗。这对心脏和大脑都有好处。阿尔茨海默病协会研究称，当人们有损害心脏和血管的活动习惯时，发展成阿尔茨海默病或血管性痴呆、心脏病、高血压、中风、糖尿病的风险都会增高。为了心脏和大脑健康，协会的指南建议人每周至少进行5次、每次30分钟的“中等强度”运动，或者每周3次、每次1小时的“高等强度”运动。“如果你和我正在徒步旅行，我们正爬山，我们喘不过气来，但还没有到不能互相交谈的程度，”她说，“这就是推荐的中等强度。”</p>\n</li>\n<li><p>戒烟。研究人员发现，那些每天吸一包烟超过10年的人在40多岁时就会出现认知障碍。另一方面，那些戒烟或被定义为轻度吸烟者的人并没有同样的认知能力下降。研究表明，烟民在戒烟后也会对身体造成伤害，但越早戒烟越好。</p>\n</li>\n<li><p>吃大脑“喜欢”的食物。关于饮食和认知功能的关系，最近发表在《营养学进展》上的一项研究认为三种饮食——地中海饮食、DASH（阻止高血压的饮食方法）和MIND（地中海-DASH神经退行性延迟干预）可能会降低你认知能力下降的风险。“如果你在意大利海岸度假时会吃什么，”弗雷德里克斯说。“鱼类、精益蛋白、豆类、其他蔬菜来源的蛋白，以及一系列水果和蔬菜——特别是深色、绿叶蔬菜，这些似乎对保持认知功能有特定的好处。”此外，选择橄榄油而不是黄油，并选择全谷物，她继续说：“这真的不是一种限制性饮食，而是一种似乎对大脑非常有益的饮食习惯。”</p>\n</li>\n<li><p>限制饮酒。为了降低痴呆风险，遵循CDC的指南，女性饮酒每天不应超过一杯，男性每天不超过两杯。当然，一周内戒酒并不意味着你可以在周末安全地多喝。已经有认知能力下降症状的人应该避免所有酒精摄入——因为任何剂量的酒精都会对认知能力有影响，对大脑是毒物。</p>\n</li>\n<li><p>应对压力。尽管无法避免所有压力，但你可以采取措施减少其伤害。RAND公司高级行为和社会科学家、睡眠基金会科学顾问温迪·特罗克斯建议每天做这些压力管理技巧：太极、瑜伽、冥想、正念练习、运动。</p>\n</li>\n<li><p>充足的睡眠。我们的大脑每晚至少需要七小时的休息睡眠来休息和充电。为睡眠做准备（比如：至少在睡前30分钟远离屏幕）还有额外的好处，可以保持我们的思维敏锐。如果你感到压力，特罗克斯说，“重要的是在晚上放松，并在睡前尽量降低压力水平。”为了促进心态平稳以及幸福感的获得以提高睡眠质量，她提出了这些建议：洗个热水澡、和伴侣拥抱、在日记中写下至少三件你感激的事情。</p>\n</li>\n<li><p>保护你的大脑。失去意识的脑损伤，可能会增加你认知能力下降和痴呆的风险。因此，坐车要系安全带，骑自行车或机动车辆、滑雪、滑冰、滑板或玩美式足球等接触性运动时要佩戴头盔。你还可以采取措施预防跌倒。</p>\n</li>\n<li><p>注意心理健康问题。一些研究将抑郁史与认知能力下降的风险联系起来，包括2013年发表在《心理医学》上的一篇文章。另一项最近发表在《神经精神药物治疗》上的研究，发现一种名为沃替西汀的抗抑郁药物有助于治疗认知功能和抑郁症。在我们国家遇到抑郁症还是去看医生吧，别乱吃药。</p>\n</li>\n<li><p>花时间与年轻人相处。另一种社交和学习新技能的方式是与不同代际的人互动。2019年发表在《衰老研究评论》上的一篇综述中，研究人员发现，与年轻人有交流的老年人比那些只与同龄人交往的人表现出更缓慢的认知能力下降趋势。研究人员发现这种交往会缓解焦虑，孤独和抑郁，这些都是促进大脑健康的因素。也就是说与孙子们共度时光对你有好处！</p>\n</li>\n</ol>"},{"title":"文献阅读（一）","abbrlink":"7f608d63","date":"2024-06-14T14:55:04.000Z","_content":"[Tidally Modulated Glacial Slip and Tremor at HelheimGlacier, Greenland](https://agupubs.onlinelibrary.wiley.com/doi/10.1029/2023GL105342?af=R)\n<!--less-->\n### 摘要\n数值模拟冰盖运动及其对全球海平面上升的预测需要了解不断演变的冰下环境信息，但遗憾的是，由于难以接近，这些信息在很大程度上仍然未知。本文通过多年的地震震颤数据来推进这类冰下观测，这些震颤很可能与Helheim冰川的冰川滑动有关。这种关联通过震颤功率与不同时间尺度上的多种环境驱动因素之间的相关性分析得到了证实。观测到的震颤功率的变化表明，不同的因素在不同的时间尺度上影响冰川滑动。有效压力可能在长期（季节性/年度）时间尺度上控制冰川滑动，而潮汐力在短（小时/日）时间尺度上调节滑动速率和震颤功率。极化结果表明，震颤源可能来自上游的冰下山脊。这一观测为如何在冰盖建模中包含不同因素以及它们变化的时间尺度如何发挥重要作用提供了见解。\n### 重要性\n\n这篇文章研究了格陵兰冰盖的冰流变化，这对于理解全球海平面上升的预测至关重要。冰盖的动态变化对全球气候系统有着深远的影响，特别是对海洋的热盐循环和全球气候模式。\n\n### 总结的前人研究\n\n- 引用了Choi et al., 2021; Howat et al., 2007; Mankoff, Solgaard, et al., 2020; Van den Broeke et al., 2016等研究，这些研究涉及了格陵兰冰盖物质流失的量度和影响。\n- 提到了Weertman (1957)关于冰川滑动的早期理论，以及Lliboutry (1968)和Schoof (2005)关于空化过程的研究。\n- 引用了Alley et al., 2023; Clarke, 2005; Tsai et al., 2015, 2022; Zoet & Iverson, 2020等研究，这些研究涉及了冰川滑动的软床变形和空间异质滑动场景。\n\n### 不足之处\n\n- 由于难以接近，特别是快速流动的峡湾冰川，对冰下环境的了解仍然非常有限。\n- 冰下环境的演变对冰盖模型的准确性至关重要，但目前对其了解不足。\n\n### 使用的数据\n\n- 多年份的地震观测数据，这些数据可能与Helheim冰川的冰川滑动有关。\n- 通过地震记录计算的功率谱密度（PSD）。\n- 利用地面雷达干涉仪（TRI）和自动天气站（AWS）收集的数据。\n\n### 采用的方法\n\n- 应用了频率依赖的极化分析（FDPA）来确定地震信号的来源方向。\n- 利用了B样条插值方法来估算长期（季节性和年际）的冰面速度。\n- 进行了交叉相关性分析，以研究地震功率与多种环境因素之间的关系。\n\n### 获得的结果\n\n- 观察到的地震震颤功率与潮汐力在短时尺度（小时/日）上有强相关性，而在长时尺度（季节性/年）上则由有效压力控制。\n- 通过极化分析指出，震颤源可能来自上游的冰下山脊。\n\n### 创新之处\n\n- 首次报道了与Helheim冰川冰下滑动可能相关的多年连续观测的震颤信号。\n- 揭示了不同因素在不同时间尺度上对冰川滑动的影响，这对冰盖模型的构建具有重要意义。\n\n### 贡献\n\n- 为理解冰盖物质流失的动态提供了新的见解，有助于改进全球海平面上升的预测模型。\n- 通过被动地震学方法，以成本效益高的方式远程感知冰下过程。\n\n### 不足\n\n- 文章没有详细讨论冰下环境变化的具体机制，以及这些变化如何影响长期冰流速度。\n- 对于地震震颤源的确切位置和机制还需要进一步的研究和验证。\n","source":"_posts/2024-06-14-paper-reading-1.md","raw":"---\ntitle: 文献阅读（一）\ncategories:\n  - work\ntags:\n  - paper\nabbrlink: 7f608d63\ndate: 2024-06-14 22:55:04\n---\n[Tidally Modulated Glacial Slip and Tremor at HelheimGlacier, Greenland](https://agupubs.onlinelibrary.wiley.com/doi/10.1029/2023GL105342?af=R)\n<!--less-->\n### 摘要\n数值模拟冰盖运动及其对全球海平面上升的预测需要了解不断演变的冰下环境信息，但遗憾的是，由于难以接近，这些信息在很大程度上仍然未知。本文通过多年的地震震颤数据来推进这类冰下观测，这些震颤很可能与Helheim冰川的冰川滑动有关。这种关联通过震颤功率与不同时间尺度上的多种环境驱动因素之间的相关性分析得到了证实。观测到的震颤功率的变化表明，不同的因素在不同的时间尺度上影响冰川滑动。有效压力可能在长期（季节性/年度）时间尺度上控制冰川滑动，而潮汐力在短（小时/日）时间尺度上调节滑动速率和震颤功率。极化结果表明，震颤源可能来自上游的冰下山脊。这一观测为如何在冰盖建模中包含不同因素以及它们变化的时间尺度如何发挥重要作用提供了见解。\n### 重要性\n\n这篇文章研究了格陵兰冰盖的冰流变化，这对于理解全球海平面上升的预测至关重要。冰盖的动态变化对全球气候系统有着深远的影响，特别是对海洋的热盐循环和全球气候模式。\n\n### 总结的前人研究\n\n- 引用了Choi et al., 2021; Howat et al., 2007; Mankoff, Solgaard, et al., 2020; Van den Broeke et al., 2016等研究，这些研究涉及了格陵兰冰盖物质流失的量度和影响。\n- 提到了Weertman (1957)关于冰川滑动的早期理论，以及Lliboutry (1968)和Schoof (2005)关于空化过程的研究。\n- 引用了Alley et al., 2023; Clarke, 2005; Tsai et al., 2015, 2022; Zoet & Iverson, 2020等研究，这些研究涉及了冰川滑动的软床变形和空间异质滑动场景。\n\n### 不足之处\n\n- 由于难以接近，特别是快速流动的峡湾冰川，对冰下环境的了解仍然非常有限。\n- 冰下环境的演变对冰盖模型的准确性至关重要，但目前对其了解不足。\n\n### 使用的数据\n\n- 多年份的地震观测数据，这些数据可能与Helheim冰川的冰川滑动有关。\n- 通过地震记录计算的功率谱密度（PSD）。\n- 利用地面雷达干涉仪（TRI）和自动天气站（AWS）收集的数据。\n\n### 采用的方法\n\n- 应用了频率依赖的极化分析（FDPA）来确定地震信号的来源方向。\n- 利用了B样条插值方法来估算长期（季节性和年际）的冰面速度。\n- 进行了交叉相关性分析，以研究地震功率与多种环境因素之间的关系。\n\n### 获得的结果\n\n- 观察到的地震震颤功率与潮汐力在短时尺度（小时/日）上有强相关性，而在长时尺度（季节性/年）上则由有效压力控制。\n- 通过极化分析指出，震颤源可能来自上游的冰下山脊。\n\n### 创新之处\n\n- 首次报道了与Helheim冰川冰下滑动可能相关的多年连续观测的震颤信号。\n- 揭示了不同因素在不同时间尺度上对冰川滑动的影响，这对冰盖模型的构建具有重要意义。\n\n### 贡献\n\n- 为理解冰盖物质流失的动态提供了新的见解，有助于改进全球海平面上升的预测模型。\n- 通过被动地震学方法，以成本效益高的方式远程感知冰下过程。\n\n### 不足\n\n- 文章没有详细讨论冰下环境变化的具体机制，以及这些变化如何影响长期冰流速度。\n- 对于地震震颤源的确切位置和机制还需要进一步的研究和验证。\n","slug":"paper-reading-1","published":1,"updated":"2024-06-14T15:00:07.802Z","comments":1,"layout":"post","photos":[],"_id":"cmh498ipp007owvou4zja66fs","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><h3 id=\"摘要\"><a href=\"#摘要\" class=\"headerlink\" title=\"摘要\"></a>摘要</h3><p>数值模拟冰盖运动及其对全球海平面上升的预测需要了解不断演变的冰下环境信息，但遗憾的是，由于难以接近，这些信息在很大程度上仍然未知。本文通过多年的地震震颤数据来推进这类冰下观测，这些震颤很可能与Helheim冰川的冰川滑动有关。这种关联通过震颤功率与不同时间尺度上的多种环境驱动因素之间的相关性分析得到了证实。观测到的震颤功率的变化表明，不同的因素在不同的时间尺度上影响冰川滑动。有效压力可能在长期（季节性&#x2F;年度）时间尺度上控制冰川滑动，而潮汐力在短（小时&#x2F;日）时间尺度上调节滑动速率和震颤功率。极化结果表明，震颤源可能来自上游的冰下山脊。这一观测为如何在冰盖建模中包含不同因素以及它们变化的时间尺度如何发挥重要作用提供了见解。</p>\n<h3 id=\"重要性\"><a href=\"#重要性\" class=\"headerlink\" title=\"重要性\"></a>重要性</h3><p>这篇文章研究了格陵兰冰盖的冰流变化，这对于理解全球海平面上升的预测至关重要。冰盖的动态变化对全球气候系统有着深远的影响，特别是对海洋的热盐循环和全球气候模式。</p>\n<h3 id=\"总结的前人研究\"><a href=\"#总结的前人研究\" class=\"headerlink\" title=\"总结的前人研究\"></a>总结的前人研究</h3><ul>\n<li>引用了Choi et al., 2021; Howat et al., 2007; Mankoff, Solgaard, et al., 2020; Van den Broeke et al., 2016等研究，这些研究涉及了格陵兰冰盖物质流失的量度和影响。</li>\n<li>提到了Weertman (1957)关于冰川滑动的早期理论，以及Lliboutry (1968)和Schoof (2005)关于空化过程的研究。</li>\n<li>引用了Alley et al., 2023; Clarke, 2005; Tsai et al., 2015, 2022; Zoet &amp; Iverson, 2020等研究，这些研究涉及了冰川滑动的软床变形和空间异质滑动场景。</li>\n</ul>\n<h3 id=\"不足之处\"><a href=\"#不足之处\" class=\"headerlink\" title=\"不足之处\"></a>不足之处</h3><ul>\n<li>由于难以接近，特别是快速流动的峡湾冰川，对冰下环境的了解仍然非常有限。</li>\n<li>冰下环境的演变对冰盖模型的准确性至关重要，但目前对其了解不足。</li>\n</ul>\n<h3 id=\"使用的数据\"><a href=\"#使用的数据\" class=\"headerlink\" title=\"使用的数据\"></a>使用的数据</h3><ul>\n<li>多年份的地震观测数据，这些数据可能与Helheim冰川的冰川滑动有关。</li>\n<li>通过地震记录计算的功率谱密度（PSD）。</li>\n<li>利用地面雷达干涉仪（TRI）和自动天气站（AWS）收集的数据。</li>\n</ul>\n<h3 id=\"采用的方法\"><a href=\"#采用的方法\" class=\"headerlink\" title=\"采用的方法\"></a>采用的方法</h3><ul>\n<li>应用了频率依赖的极化分析（FDPA）来确定地震信号的来源方向。</li>\n<li>利用了B样条插值方法来估算长期（季节性和年际）的冰面速度。</li>\n<li>进行了交叉相关性分析，以研究地震功率与多种环境因素之间的关系。</li>\n</ul>\n<h3 id=\"获得的结果\"><a href=\"#获得的结果\" class=\"headerlink\" title=\"获得的结果\"></a>获得的结果</h3><ul>\n<li>观察到的地震震颤功率与潮汐力在短时尺度（小时&#x2F;日）上有强相关性，而在长时尺度（季节性&#x2F;年）上则由有效压力控制。</li>\n<li>通过极化分析指出，震颤源可能来自上游的冰下山脊。</li>\n</ul>\n<h3 id=\"创新之处\"><a href=\"#创新之处\" class=\"headerlink\" title=\"创新之处\"></a>创新之处</h3><ul>\n<li>首次报道了与Helheim冰川冰下滑动可能相关的多年连续观测的震颤信号。</li>\n<li>揭示了不同因素在不同时间尺度上对冰川滑动的影响，这对冰盖模型的构建具有重要意义。</li>\n</ul>\n<h3 id=\"贡献\"><a href=\"#贡献\" class=\"headerlink\" title=\"贡献\"></a>贡献</h3><ul>\n<li>为理解冰盖物质流失的动态提供了新的见解，有助于改进全球海平面上升的预测模型。</li>\n<li>通过被动地震学方法，以成本效益高的方式远程感知冰下过程。</li>\n</ul>\n<h3 id=\"不足\"><a href=\"#不足\" class=\"headerlink\" title=\"不足\"></a>不足</h3><ul>\n<li>文章没有详细讨论冰下环境变化的具体机制，以及这些变化如何影响长期冰流速度。</li>\n<li>对于地震震颤源的确切位置和机制还需要进一步的研究和验证。</li>\n</ul>","related_posts":["paper-reading-2.html","paper-reading-5.html"],"length":1324,"excerpt":"<p><a href=\"https://agupubs.onlinelibrary.wiley.com/doi/10.1029/2023GL105342?af=R\">Tidally Modulated Glacial Slip and Tremor at HelheimGlacier, Greenland</a></p>","more":"<h3 id=\"摘要\"><a href=\"#摘要\" class=\"headerlink\" title=\"摘要\"></a>摘要</h3><p>数值模拟冰盖运动及其对全球海平面上升的预测需要了解不断演变的冰下环境信息，但遗憾的是，由于难以接近，这些信息在很大程度上仍然未知。本文通过多年的地震震颤数据来推进这类冰下观测，这些震颤很可能与Helheim冰川的冰川滑动有关。这种关联通过震颤功率与不同时间尺度上的多种环境驱动因素之间的相关性分析得到了证实。观测到的震颤功率的变化表明，不同的因素在不同的时间尺度上影响冰川滑动。有效压力可能在长期（季节性&#x2F;年度）时间尺度上控制冰川滑动，而潮汐力在短（小时&#x2F;日）时间尺度上调节滑动速率和震颤功率。极化结果表明，震颤源可能来自上游的冰下山脊。这一观测为如何在冰盖建模中包含不同因素以及它们变化的时间尺度如何发挥重要作用提供了见解。</p>\n<h3 id=\"重要性\"><a href=\"#重要性\" class=\"headerlink\" title=\"重要性\"></a>重要性</h3><p>这篇文章研究了格陵兰冰盖的冰流变化，这对于理解全球海平面上升的预测至关重要。冰盖的动态变化对全球气候系统有着深远的影响，特别是对海洋的热盐循环和全球气候模式。</p>\n<h3 id=\"总结的前人研究\"><a href=\"#总结的前人研究\" class=\"headerlink\" title=\"总结的前人研究\"></a>总结的前人研究</h3><ul>\n<li>引用了Choi et al., 2021; Howat et al., 2007; Mankoff, Solgaard, et al., 2020; Van den Broeke et al., 2016等研究，这些研究涉及了格陵兰冰盖物质流失的量度和影响。</li>\n<li>提到了Weertman (1957)关于冰川滑动的早期理论，以及Lliboutry (1968)和Schoof (2005)关于空化过程的研究。</li>\n<li>引用了Alley et al., 2023; Clarke, 2005; Tsai et al., 2015, 2022; Zoet &amp; Iverson, 2020等研究，这些研究涉及了冰川滑动的软床变形和空间异质滑动场景。</li>\n</ul>\n<h3 id=\"不足之处\"><a href=\"#不足之处\" class=\"headerlink\" title=\"不足之处\"></a>不足之处</h3><ul>\n<li>由于难以接近，特别是快速流动的峡湾冰川，对冰下环境的了解仍然非常有限。</li>\n<li>冰下环境的演变对冰盖模型的准确性至关重要，但目前对其了解不足。</li>\n</ul>\n<h3 id=\"使用的数据\"><a href=\"#使用的数据\" class=\"headerlink\" title=\"使用的数据\"></a>使用的数据</h3><ul>\n<li>多年份的地震观测数据，这些数据可能与Helheim冰川的冰川滑动有关。</li>\n<li>通过地震记录计算的功率谱密度（PSD）。</li>\n<li>利用地面雷达干涉仪（TRI）和自动天气站（AWS）收集的数据。</li>\n</ul>\n<h3 id=\"采用的方法\"><a href=\"#采用的方法\" class=\"headerlink\" title=\"采用的方法\"></a>采用的方法</h3><ul>\n<li>应用了频率依赖的极化分析（FDPA）来确定地震信号的来源方向。</li>\n<li>利用了B样条插值方法来估算长期（季节性和年际）的冰面速度。</li>\n<li>进行了交叉相关性分析，以研究地震功率与多种环境因素之间的关系。</li>\n</ul>\n<h3 id=\"获得的结果\"><a href=\"#获得的结果\" class=\"headerlink\" title=\"获得的结果\"></a>获得的结果</h3><ul>\n<li>观察到的地震震颤功率与潮汐力在短时尺度（小时&#x2F;日）上有强相关性，而在长时尺度（季节性&#x2F;年）上则由有效压力控制。</li>\n<li>通过极化分析指出，震颤源可能来自上游的冰下山脊。</li>\n</ul>\n<h3 id=\"创新之处\"><a href=\"#创新之处\" class=\"headerlink\" title=\"创新之处\"></a>创新之处</h3><ul>\n<li>首次报道了与Helheim冰川冰下滑动可能相关的多年连续观测的震颤信号。</li>\n<li>揭示了不同因素在不同时间尺度上对冰川滑动的影响，这对冰盖模型的构建具有重要意义。</li>\n</ul>\n<h3 id=\"贡献\"><a href=\"#贡献\" class=\"headerlink\" title=\"贡献\"></a>贡献</h3><ul>\n<li>为理解冰盖物质流失的动态提供了新的见解，有助于改进全球海平面上升的预测模型。</li>\n<li>通过被动地震学方法，以成本效益高的方式远程感知冰下过程。</li>\n</ul>\n<h3 id=\"不足\"><a href=\"#不足\" class=\"headerlink\" title=\"不足\"></a>不足</h3><ul>\n<li>文章没有详细讨论冰下环境变化的具体机制，以及这些变化如何影响长期冰流速度。</li>\n<li>对于地震震颤源的确切位置和机制还需要进一步的研究和验证。</li>\n</ul>"},{"title":"写作能力提升技巧","abbrlink":"dd0f1f93","date":"2024-06-14T23:50:16.000Z","_content":"&emsp;&emsp;如何写好博文？DailyBlogTips有话说。\n<!--less-->\n&emsp;&emsp;要想成为一个成功的博主，你必须要擅长写作。写好文章并不意味着你需要拥有文学博士学位，或者出版过一堆作品。当你读了很多他人文章并刻意练习，写了更多文章之后，你的写作能力自然能得到提升。有很多技巧也可以快速帮你提高写作能力，这些技巧适用于各种文本写作:\n\n### 在开始写作前做好计划\n&emsp;&emsp;提前计划对你的写作质量有很大的影响。它为你带来了更好的写作体验，也为你的读者带来了更好的阅读体验。\n\n&emsp;&emsp;提前花五分钟进行计划意味着：\n\n1. 你能提前发现很多大的问题（例如，你的主题是不是调子定得太高了）。\n2. 你能构想文章的结构，并进行必要的修改。\n3. 当你开始写的时候，你会有一个路线图来指导写作方向。创建思维导图就是一个不错的方式。\n\n### 想象你是写给某一个特定的人\n&emsp;&emsp;你是否因为不知道如何表达而苦恼？克服这一点的最简单方法是想象你只是在给一个特定的人写作。\n\n&emsp;&emsp;你可以将他想象成那个给你点赞的人，那个留下评论的人。\n\n### 写短的句子和段落\n&emsp;&emsp;这通常是加强你写作的一个好方法。短小精悍的句子和段落，不仅能够吸引读者的注意力，也让你的生活变得更容易。通常，拥有两个短句子比一个单一的长而复杂的句子要简单得多。\n\n### 使用“你”和“你的”与读者对话\n&emsp;&emsp;要直接与你的读者对话。这有助于使你的帖子、电子书或电子邮件感觉像是对话的一部分。\n\n&emsp;&emsp;通常，最好写得就像你在与一个读者交谈（见技巧 #2）。所以，不要写“你们中的一些人可能知道……”，而是写“你可能知道……”\n\n### 删减10%的词汇\n&emsp;&emsp;大多数人写东西会冗长繁复。在编辑你的作品时，看看你能否删减掉10%的内容。400个字的摘要得变成360个，当然还是写到390个字为妙。\n\n&emsp;&emsp;你可能会惊讶，在不改变原意的情况下很多文字都可以被删减。不必要的词会浪费读者的时间，也会分散他们的注意力。\n\n### 大声朗读你的文章，或者把它打印出来\n&emsp;&emsp;发现自己的别字和错误表达很难，因为你脑子知道你要写啥且你认为你写出来的就是你脑子里的东西。大声朗读可以强迫你慢下来，并能使这些错误显现出来。\n\n&emsp;&emsp;你也可以把你的文章打印出来看。这有助于获得看自己文章的割离感，并让你更容易专注，从而找到问题。\n","source":"_posts/2024-06-15-how-to-write-blog.md","raw":"---\ntitle: 写作能力提升技巧\ncategories:\n  - 学习\ntags:\n  - 博客\nabbrlink: dd0f1f93\ndate: 2024-06-15 07:50:16\n---\n&emsp;&emsp;如何写好博文？DailyBlogTips有话说。\n<!--less-->\n&emsp;&emsp;要想成为一个成功的博主，你必须要擅长写作。写好文章并不意味着你需要拥有文学博士学位，或者出版过一堆作品。当你读了很多他人文章并刻意练习，写了更多文章之后，你的写作能力自然能得到提升。有很多技巧也可以快速帮你提高写作能力，这些技巧适用于各种文本写作:\n\n### 在开始写作前做好计划\n&emsp;&emsp;提前计划对你的写作质量有很大的影响。它为你带来了更好的写作体验，也为你的读者带来了更好的阅读体验。\n\n&emsp;&emsp;提前花五分钟进行计划意味着：\n\n1. 你能提前发现很多大的问题（例如，你的主题是不是调子定得太高了）。\n2. 你能构想文章的结构，并进行必要的修改。\n3. 当你开始写的时候，你会有一个路线图来指导写作方向。创建思维导图就是一个不错的方式。\n\n### 想象你是写给某一个特定的人\n&emsp;&emsp;你是否因为不知道如何表达而苦恼？克服这一点的最简单方法是想象你只是在给一个特定的人写作。\n\n&emsp;&emsp;你可以将他想象成那个给你点赞的人，那个留下评论的人。\n\n### 写短的句子和段落\n&emsp;&emsp;这通常是加强你写作的一个好方法。短小精悍的句子和段落，不仅能够吸引读者的注意力，也让你的生活变得更容易。通常，拥有两个短句子比一个单一的长而复杂的句子要简单得多。\n\n### 使用“你”和“你的”与读者对话\n&emsp;&emsp;要直接与你的读者对话。这有助于使你的帖子、电子书或电子邮件感觉像是对话的一部分。\n\n&emsp;&emsp;通常，最好写得就像你在与一个读者交谈（见技巧 #2）。所以，不要写“你们中的一些人可能知道……”，而是写“你可能知道……”\n\n### 删减10%的词汇\n&emsp;&emsp;大多数人写东西会冗长繁复。在编辑你的作品时，看看你能否删减掉10%的内容。400个字的摘要得变成360个，当然还是写到390个字为妙。\n\n&emsp;&emsp;你可能会惊讶，在不改变原意的情况下很多文字都可以被删减。不必要的词会浪费读者的时间，也会分散他们的注意力。\n\n### 大声朗读你的文章，或者把它打印出来\n&emsp;&emsp;发现自己的别字和错误表达很难，因为你脑子知道你要写啥且你认为你写出来的就是你脑子里的东西。大声朗读可以强迫你慢下来，并能使这些错误显现出来。\n\n&emsp;&emsp;你也可以把你的文章打印出来看。这有助于获得看自己文章的割离感，并让你更容易专注，从而找到问题。\n","slug":"how-to-write-blog","published":1,"updated":"2024-06-15T00:24:09.458Z","comments":1,"layout":"post","photos":[],"_id":"cmh498ipp007qwvou77mb03js","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>&emsp;&emsp;要想成为一个成功的博主，你必须要擅长写作。写好文章并不意味着你需要拥有文学博士学位，或者出版过一堆作品。当你读了很多他人文章并刻意练习，写了更多文章之后，你的写作能力自然能得到提升。有很多技巧也可以快速帮你提高写作能力，这些技巧适用于各种文本写作:</p>\n<h3 id=\"在开始写作前做好计划\"><a href=\"#在开始写作前做好计划\" class=\"headerlink\" title=\"在开始写作前做好计划\"></a>在开始写作前做好计划</h3><p>&emsp;&emsp;提前计划对你的写作质量有很大的影响。它为你带来了更好的写作体验，也为你的读者带来了更好的阅读体验。</p>\n<p>&emsp;&emsp;提前花五分钟进行计划意味着：</p>\n<ol>\n<li>你能提前发现很多大的问题（例如，你的主题是不是调子定得太高了）。</li>\n<li>你能构想文章的结构，并进行必要的修改。</li>\n<li>当你开始写的时候，你会有一个路线图来指导写作方向。创建思维导图就是一个不错的方式。</li>\n</ol>\n<h3 id=\"想象你是写给某一个特定的人\"><a href=\"#想象你是写给某一个特定的人\" class=\"headerlink\" title=\"想象你是写给某一个特定的人\"></a>想象你是写给某一个特定的人</h3><p>&emsp;&emsp;你是否因为不知道如何表达而苦恼？克服这一点的最简单方法是想象你只是在给一个特定的人写作。</p>\n<p>&emsp;&emsp;你可以将他想象成那个给你点赞的人，那个留下评论的人。</p>\n<h3 id=\"写短的句子和段落\"><a href=\"#写短的句子和段落\" class=\"headerlink\" title=\"写短的句子和段落\"></a>写短的句子和段落</h3><p>&emsp;&emsp;这通常是加强你写作的一个好方法。短小精悍的句子和段落，不仅能够吸引读者的注意力，也让你的生活变得更容易。通常，拥有两个短句子比一个单一的长而复杂的句子要简单得多。</p>\n<h3 id=\"使用“你”和“你的”与读者对话\"><a href=\"#使用“你”和“你的”与读者对话\" class=\"headerlink\" title=\"使用“你”和“你的”与读者对话\"></a>使用“你”和“你的”与读者对话</h3><p>&emsp;&emsp;要直接与你的读者对话。这有助于使你的帖子、电子书或电子邮件感觉像是对话的一部分。</p>\n<p>&emsp;&emsp;通常，最好写得就像你在与一个读者交谈（见技巧 #2）。所以，不要写“你们中的一些人可能知道……”，而是写“你可能知道……”</p>\n<h3 id=\"删减10-的词汇\"><a href=\"#删减10-的词汇\" class=\"headerlink\" title=\"删减10%的词汇\"></a>删减10%的词汇</h3><p>&emsp;&emsp;大多数人写东西会冗长繁复。在编辑你的作品时，看看你能否删减掉10%的内容。400个字的摘要得变成360个，当然还是写到390个字为妙。</p>\n<p>&emsp;&emsp;你可能会惊讶，在不改变原意的情况下很多文字都可以被删减。不必要的词会浪费读者的时间，也会分散他们的注意力。</p>\n<h3 id=\"大声朗读你的文章，或者把它打印出来\"><a href=\"#大声朗读你的文章，或者把它打印出来\" class=\"headerlink\" title=\"大声朗读你的文章，或者把它打印出来\"></a>大声朗读你的文章，或者把它打印出来</h3><p>&emsp;&emsp;发现自己的别字和错误表达很难，因为你脑子知道你要写啥且你认为你写出来的就是你脑子里的东西。大声朗读可以强迫你慢下来，并能使这些错误显现出来。</p>\n<p>&emsp;&emsp;你也可以把你的文章打印出来看。这有助于获得看自己文章的割离感，并让你更容易专注，从而找到问题。</p>","related_posts":[],"length":1018,"excerpt":"<p>&emsp;&emsp;如何写好博文？DailyBlogTips有话说。</p>","more":"<p>&emsp;&emsp;要想成为一个成功的博主，你必须要擅长写作。写好文章并不意味着你需要拥有文学博士学位，或者出版过一堆作品。当你读了很多他人文章并刻意练习，写了更多文章之后，你的写作能力自然能得到提升。有很多技巧也可以快速帮你提高写作能力，这些技巧适用于各种文本写作:</p>\n<h3 id=\"在开始写作前做好计划\"><a href=\"#在开始写作前做好计划\" class=\"headerlink\" title=\"在开始写作前做好计划\"></a>在开始写作前做好计划</h3><p>&emsp;&emsp;提前计划对你的写作质量有很大的影响。它为你带来了更好的写作体验，也为你的读者带来了更好的阅读体验。</p>\n<p>&emsp;&emsp;提前花五分钟进行计划意味着：</p>\n<ol>\n<li>你能提前发现很多大的问题（例如，你的主题是不是调子定得太高了）。</li>\n<li>你能构想文章的结构，并进行必要的修改。</li>\n<li>当你开始写的时候，你会有一个路线图来指导写作方向。创建思维导图就是一个不错的方式。</li>\n</ol>\n<h3 id=\"想象你是写给某一个特定的人\"><a href=\"#想象你是写给某一个特定的人\" class=\"headerlink\" title=\"想象你是写给某一个特定的人\"></a>想象你是写给某一个特定的人</h3><p>&emsp;&emsp;你是否因为不知道如何表达而苦恼？克服这一点的最简单方法是想象你只是在给一个特定的人写作。</p>\n<p>&emsp;&emsp;你可以将他想象成那个给你点赞的人，那个留下评论的人。</p>\n<h3 id=\"写短的句子和段落\"><a href=\"#写短的句子和段落\" class=\"headerlink\" title=\"写短的句子和段落\"></a>写短的句子和段落</h3><p>&emsp;&emsp;这通常是加强你写作的一个好方法。短小精悍的句子和段落，不仅能够吸引读者的注意力，也让你的生活变得更容易。通常，拥有两个短句子比一个单一的长而复杂的句子要简单得多。</p>\n<h3 id=\"使用“你”和“你的”与读者对话\"><a href=\"#使用“你”和“你的”与读者对话\" class=\"headerlink\" title=\"使用“你”和“你的”与读者对话\"></a>使用“你”和“你的”与读者对话</h3><p>&emsp;&emsp;要直接与你的读者对话。这有助于使你的帖子、电子书或电子邮件感觉像是对话的一部分。</p>\n<p>&emsp;&emsp;通常，最好写得就像你在与一个读者交谈（见技巧 #2）。所以，不要写“你们中的一些人可能知道……”，而是写“你可能知道……”</p>\n<h3 id=\"删减10-的词汇\"><a href=\"#删减10-的词汇\" class=\"headerlink\" title=\"删减10%的词汇\"></a>删减10%的词汇</h3><p>&emsp;&emsp;大多数人写东西会冗长繁复。在编辑你的作品时，看看你能否删减掉10%的内容。400个字的摘要得变成360个，当然还是写到390个字为妙。</p>\n<p>&emsp;&emsp;你可能会惊讶，在不改变原意的情况下很多文字都可以被删减。不必要的词会浪费读者的时间，也会分散他们的注意力。</p>\n<h3 id=\"大声朗读你的文章，或者把它打印出来\"><a href=\"#大声朗读你的文章，或者把它打印出来\" class=\"headerlink\" title=\"大声朗读你的文章，或者把它打印出来\"></a>大声朗读你的文章，或者把它打印出来</h3><p>&emsp;&emsp;发现自己的别字和错误表达很难，因为你脑子知道你要写啥且你认为你写出来的就是你脑子里的东西。大声朗读可以强迫你慢下来，并能使这些错误显现出来。</p>\n<p>&emsp;&emsp;你也可以把你的文章打印出来看。这有助于获得看自己文章的割离感，并让你更容易专注，从而找到问题。</p>"},{"title":"冰川地震研究方向(一)","abbrlink":"511e47a","date":"2024-06-03T09:00:01.000Z","_content":"冰川地震研究方向。\n<!--less-->\n1. 冰川内部水流与冰震活动的作用关系。冰下湖水位变化、接地线附近的冰下水流、冰流底部空枪的打开和闭合、冰川侵蚀作用、冰架底部裂缝扩张与冰震关系。\n2. 冰川物理、冰川动力学建模与冰川地震学的进一步交叉与融合、冰川结构变化机制及冰震和冰川物性参数关系，如冰川底部冰zi的剪切模量主要受到冰zi密度、含水量以及孔隙度的影响是研究冰川滑移定律及冰川动力学建模的重要参数。\n3. 冰川结构变化的前兆特征研究，例如冰川地震发生前的前段冰震密集活动。\n4. 外部环境与冰川的相互作用，例如海浪、潮汐、次重力波以及温度、风场变化对冰川活动的变化。\n","source":"_posts/2024-06-03-gls1.md","raw":"---\ntitle: 冰川地震研究方向(一)\ncategories:\n  - work\ntags:\n  - glacial seismology\nabbrlink: 511e47a\ndate: 2024-06-03 17:00:01\n---\n冰川地震研究方向。\n<!--less-->\n1. 冰川内部水流与冰震活动的作用关系。冰下湖水位变化、接地线附近的冰下水流、冰流底部空枪的打开和闭合、冰川侵蚀作用、冰架底部裂缝扩张与冰震关系。\n2. 冰川物理、冰川动力学建模与冰川地震学的进一步交叉与融合、冰川结构变化机制及冰震和冰川物性参数关系，如冰川底部冰zi的剪切模量主要受到冰zi密度、含水量以及孔隙度的影响是研究冰川滑移定律及冰川动力学建模的重要参数。\n3. 冰川结构变化的前兆特征研究，例如冰川地震发生前的前段冰震密集活动。\n4. 外部环境与冰川的相互作用，例如海浪、潮汐、次重力波以及温度、风场变化对冰川活动的变化。\n","slug":"gls1","published":1,"updated":"2024-06-05T02:19:40.666Z","comments":1,"layout":"post","photos":[],"_id":"cmh498ipq007uwvouc4si70gu","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><ol>\n<li>冰川内部水流与冰震活动的作用关系。冰下湖水位变化、接地线附近的冰下水流、冰流底部空枪的打开和闭合、冰川侵蚀作用、冰架底部裂缝扩张与冰震关系。</li>\n<li>冰川物理、冰川动力学建模与冰川地震学的进一步交叉与融合、冰川结构变化机制及冰震和冰川物性参数关系，如冰川底部冰zi的剪切模量主要受到冰zi密度、含水量以及孔隙度的影响是研究冰川滑移定律及冰川动力学建模的重要参数。</li>\n<li>冰川结构变化的前兆特征研究，例如冰川地震发生前的前段冰震密集活动。</li>\n<li>外部环境与冰川的相互作用，例如海浪、潮汐、次重力波以及温度、风场变化对冰川活动的变化。</li>\n</ol>","related_posts":[],"length":261,"excerpt":"<p>冰川地震研究方向。</p>","more":"<ol>\n<li>冰川内部水流与冰震活动的作用关系。冰下湖水位变化、接地线附近的冰下水流、冰流底部空枪的打开和闭合、冰川侵蚀作用、冰架底部裂缝扩张与冰震关系。</li>\n<li>冰川物理、冰川动力学建模与冰川地震学的进一步交叉与融合、冰川结构变化机制及冰震和冰川物性参数关系，如冰川底部冰zi的剪切模量主要受到冰zi密度、含水量以及孔隙度的影响是研究冰川滑移定律及冰川动力学建模的重要参数。</li>\n<li>冰川结构变化的前兆特征研究，例如冰川地震发生前的前段冰震密集活动。</li>\n<li>外部环境与冰川的相互作用，例如海浪、潮汐、次重力波以及温度、风场变化对冰川活动的变化。</li>\n</ol>"},{"title":"文献阅读（二）","abbrlink":"4f7661bb","date":"2024-06-15T00:51:55.000Z","_content":"&emsp;&emsp;[Repeated Tidally Induced Hydrofracture of a Supraglacial Lake at the Amery Ice Shelf Grounding Zone](https://agupubs.onlinelibrary.wiley.com/doi/10.1029/2021GL095661?af=R)\n<!--less-->\n### 摘要\n南极冰架上的表面融化和湖泊是常见的现象，它们的存在和排水被认为是冰架崩塌的前兆。在这里，我们展示了2014年至2020年间，东南极Amery冰架接地区一个表冰湖反复快速排水的卫星观测结果。2018年排水后的图像显示了湖底特征，这些特征是快速垂直湖排水的特征。观测到的湖体积表明，排水与一个阈值的融水体积无关。相反，排水通常与日潮汐幅度高的时期一致，这表明水力断裂是由冰架接地区固有的潮汐力引起的冰的弯曲所协助的。结合在Amery冰架接地区广泛观测到的湖泊排水，这些发现表明，尽管这些地区普遍存在增强的融化，但接地区的排水事件可能抑制了冰架融水的积累，从而代表了一种潜在的稳定机制。\n### 重要性\n\n这篇文章研究了南极冰盖表面湖泊的演变及其对冰盖稳定性的影响，这对于理解全球海平面上升的潜在贡献至关重要。特别是，研究集中在Amery冰架接地区的表面湖泊，这些湖泊的排水可能通过潮汐力引起的冰架弯曲来促进，这为冰盖稳定性提供了一个可能的稳定机制。\n\n### 总结的前人研究\n\n- 文章引用了关于南极冰盖质量损失加速的研究，如Smith等人(2020)、Bell等人(2018)和Turner等人(2005)。\n- 引用了关于冰架表面湖泊和融水生产的研究，例如Arthur等人(2020)、Dell等人(2020)和Dirscherl等人(2020)。\n- 提到了Larsen B冰架在2002年的崩塌，这是由表面融水增加和表面湖泊网络的快速排水触发的，可能通过融水驱动的水力断裂(Scambos等人，2000)。\n\n### 不足之处\n\n- 尽管对湖泊排水过程的观测已有一些报道，但缺乏高空间和时间分辨率的冰架湖泊排水过程的报告。\n- 大多数预测未来南极海平面贡献的冰盖模型仅初步参数化了湖泊和水力断裂的影响，尽管它们有可能引发大规模的冰盖不稳定性。\n\n### 使用的数据\n\n- 利用了多种卫星平台的观测数据，包括Landsat 8和Sentinel-1合成孔径雷达(SAR)图像。\n- 使用了区域气候模型RACMO2.3p2和ERA-5再分析数据来评估融水生产。\n- 利用了CATS2008(Circum-Antarctic Tidal Simulation)模型来计算每日潮汐幅度。\n\n### 采用的方法\n\n- 通过分析Landsat 8数据，使用归一化水体指数(NDWI)来分类包含湖水的像素。\n- 采用了基于物理的方法来计算湖水体积，基于水中光的衰减率、湖底反照率和光学深水的反射率。\n- 使用了数字高程模型(DEM)来提取湖岸线，并计算湖体积。\n\n### 获得的结果\n\n- 观察到一个位于Amery冰架接地区的表面湖泊在2014年至2020年间多次迅速排水。\n- 湖泊排水与高潮汐幅度周期相关，表明水力断裂可能由潮汐力引起的冰架弯曲协助。\n- 湖泊排水事件通常不与融水体积的阈值相关，而是与日潮汐幅度高的时期一致。\n\n### 创新之处\n\n- 这项研究首次利用SAR影像捕捉了南极未覆盖表面湖泊的快速排水，强调了结合雷达和光学观测湖泊动态的效用。\n- 提出了潮汐力引起的冰架弯曲可能是湖泊排水的触发因素，这为理解冰架稳定性提供了新的视角。\n\n### 贡献\n\n- 增进了我们对南极冰盖表面湖泊动态及其对冰盖稳定性影响的理解。\n- 为预测未来南极冰质量损失和海平面贡献提供了重要的观测数据和理论基础。\n\n### 不足\n\n- 文章并未详细讨论其他可能影响湖泊排水的因素，例如冰下条件和冰架底部的水力条件。\n- 对于湖泊排水对冰盖底部压力和冰-海洋相互作用的长期影响，还需要进一步的研究。\n","source":"_posts/2024-06-15-paper-reading-2.md","raw":"---\ntitle: 文献阅读（二）\ncategories:\n  - work\ntags:\n  - paper\nabbrlink: 4f7661bb\ndate: 2024-06-15 08:51:55\n---\n&emsp;&emsp;[Repeated Tidally Induced Hydrofracture of a Supraglacial Lake at the Amery Ice Shelf Grounding Zone](https://agupubs.onlinelibrary.wiley.com/doi/10.1029/2021GL095661?af=R)\n<!--less-->\n### 摘要\n南极冰架上的表面融化和湖泊是常见的现象，它们的存在和排水被认为是冰架崩塌的前兆。在这里，我们展示了2014年至2020年间，东南极Amery冰架接地区一个表冰湖反复快速排水的卫星观测结果。2018年排水后的图像显示了湖底特征，这些特征是快速垂直湖排水的特征。观测到的湖体积表明，排水与一个阈值的融水体积无关。相反，排水通常与日潮汐幅度高的时期一致，这表明水力断裂是由冰架接地区固有的潮汐力引起的冰的弯曲所协助的。结合在Amery冰架接地区广泛观测到的湖泊排水，这些发现表明，尽管这些地区普遍存在增强的融化，但接地区的排水事件可能抑制了冰架融水的积累，从而代表了一种潜在的稳定机制。\n### 重要性\n\n这篇文章研究了南极冰盖表面湖泊的演变及其对冰盖稳定性的影响，这对于理解全球海平面上升的潜在贡献至关重要。特别是，研究集中在Amery冰架接地区的表面湖泊，这些湖泊的排水可能通过潮汐力引起的冰架弯曲来促进，这为冰盖稳定性提供了一个可能的稳定机制。\n\n### 总结的前人研究\n\n- 文章引用了关于南极冰盖质量损失加速的研究，如Smith等人(2020)、Bell等人(2018)和Turner等人(2005)。\n- 引用了关于冰架表面湖泊和融水生产的研究，例如Arthur等人(2020)、Dell等人(2020)和Dirscherl等人(2020)。\n- 提到了Larsen B冰架在2002年的崩塌，这是由表面融水增加和表面湖泊网络的快速排水触发的，可能通过融水驱动的水力断裂(Scambos等人，2000)。\n\n### 不足之处\n\n- 尽管对湖泊排水过程的观测已有一些报道，但缺乏高空间和时间分辨率的冰架湖泊排水过程的报告。\n- 大多数预测未来南极海平面贡献的冰盖模型仅初步参数化了湖泊和水力断裂的影响，尽管它们有可能引发大规模的冰盖不稳定性。\n\n### 使用的数据\n\n- 利用了多种卫星平台的观测数据，包括Landsat 8和Sentinel-1合成孔径雷达(SAR)图像。\n- 使用了区域气候模型RACMO2.3p2和ERA-5再分析数据来评估融水生产。\n- 利用了CATS2008(Circum-Antarctic Tidal Simulation)模型来计算每日潮汐幅度。\n\n### 采用的方法\n\n- 通过分析Landsat 8数据，使用归一化水体指数(NDWI)来分类包含湖水的像素。\n- 采用了基于物理的方法来计算湖水体积，基于水中光的衰减率、湖底反照率和光学深水的反射率。\n- 使用了数字高程模型(DEM)来提取湖岸线，并计算湖体积。\n\n### 获得的结果\n\n- 观察到一个位于Amery冰架接地区的表面湖泊在2014年至2020年间多次迅速排水。\n- 湖泊排水与高潮汐幅度周期相关，表明水力断裂可能由潮汐力引起的冰架弯曲协助。\n- 湖泊排水事件通常不与融水体积的阈值相关，而是与日潮汐幅度高的时期一致。\n\n### 创新之处\n\n- 这项研究首次利用SAR影像捕捉了南极未覆盖表面湖泊的快速排水，强调了结合雷达和光学观测湖泊动态的效用。\n- 提出了潮汐力引起的冰架弯曲可能是湖泊排水的触发因素，这为理解冰架稳定性提供了新的视角。\n\n### 贡献\n\n- 增进了我们对南极冰盖表面湖泊动态及其对冰盖稳定性影响的理解。\n- 为预测未来南极冰质量损失和海平面贡献提供了重要的观测数据和理论基础。\n\n### 不足\n\n- 文章并未详细讨论其他可能影响湖泊排水的因素，例如冰下条件和冰架底部的水力条件。\n- 对于湖泊排水对冰盖底部压力和冰-海洋相互作用的长期影响，还需要进一步的研究。\n","slug":"paper-reading-2","published":1,"updated":"2024-06-17T07:31:38.406Z","comments":1,"layout":"post","photos":[],"_id":"cmh498ipq007xwvoucuvxgv8u","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><h3 id=\"摘要\"><a href=\"#摘要\" class=\"headerlink\" title=\"摘要\"></a>摘要</h3><p>南极冰架上的表面融化和湖泊是常见的现象，它们的存在和排水被认为是冰架崩塌的前兆。在这里，我们展示了2014年至2020年间，东南极Amery冰架接地区一个表冰湖反复快速排水的卫星观测结果。2018年排水后的图像显示了湖底特征，这些特征是快速垂直湖排水的特征。观测到的湖体积表明，排水与一个阈值的融水体积无关。相反，排水通常与日潮汐幅度高的时期一致，这表明水力断裂是由冰架接地区固有的潮汐力引起的冰的弯曲所协助的。结合在Amery冰架接地区广泛观测到的湖泊排水，这些发现表明，尽管这些地区普遍存在增强的融化，但接地区的排水事件可能抑制了冰架融水的积累，从而代表了一种潜在的稳定机制。</p>\n<h3 id=\"重要性\"><a href=\"#重要性\" class=\"headerlink\" title=\"重要性\"></a>重要性</h3><p>这篇文章研究了南极冰盖表面湖泊的演变及其对冰盖稳定性的影响，这对于理解全球海平面上升的潜在贡献至关重要。特别是，研究集中在Amery冰架接地区的表面湖泊，这些湖泊的排水可能通过潮汐力引起的冰架弯曲来促进，这为冰盖稳定性提供了一个可能的稳定机制。</p>\n<h3 id=\"总结的前人研究\"><a href=\"#总结的前人研究\" class=\"headerlink\" title=\"总结的前人研究\"></a>总结的前人研究</h3><ul>\n<li>文章引用了关于南极冰盖质量损失加速的研究，如Smith等人(2020)、Bell等人(2018)和Turner等人(2005)。</li>\n<li>引用了关于冰架表面湖泊和融水生产的研究，例如Arthur等人(2020)、Dell等人(2020)和Dirscherl等人(2020)。</li>\n<li>提到了Larsen B冰架在2002年的崩塌，这是由表面融水增加和表面湖泊网络的快速排水触发的，可能通过融水驱动的水力断裂(Scambos等人，2000)。</li>\n</ul>\n<h3 id=\"不足之处\"><a href=\"#不足之处\" class=\"headerlink\" title=\"不足之处\"></a>不足之处</h3><ul>\n<li>尽管对湖泊排水过程的观测已有一些报道，但缺乏高空间和时间分辨率的冰架湖泊排水过程的报告。</li>\n<li>大多数预测未来南极海平面贡献的冰盖模型仅初步参数化了湖泊和水力断裂的影响，尽管它们有可能引发大规模的冰盖不稳定性。</li>\n</ul>\n<h3 id=\"使用的数据\"><a href=\"#使用的数据\" class=\"headerlink\" title=\"使用的数据\"></a>使用的数据</h3><ul>\n<li>利用了多种卫星平台的观测数据，包括Landsat 8和Sentinel-1合成孔径雷达(SAR)图像。</li>\n<li>使用了区域气候模型RACMO2.3p2和ERA-5再分析数据来评估融水生产。</li>\n<li>利用了CATS2008(Circum-Antarctic Tidal Simulation)模型来计算每日潮汐幅度。</li>\n</ul>\n<h3 id=\"采用的方法\"><a href=\"#采用的方法\" class=\"headerlink\" title=\"采用的方法\"></a>采用的方法</h3><ul>\n<li>通过分析Landsat 8数据，使用归一化水体指数(NDWI)来分类包含湖水的像素。</li>\n<li>采用了基于物理的方法来计算湖水体积，基于水中光的衰减率、湖底反照率和光学深水的反射率。</li>\n<li>使用了数字高程模型(DEM)来提取湖岸线，并计算湖体积。</li>\n</ul>\n<h3 id=\"获得的结果\"><a href=\"#获得的结果\" class=\"headerlink\" title=\"获得的结果\"></a>获得的结果</h3><ul>\n<li>观察到一个位于Amery冰架接地区的表面湖泊在2014年至2020年间多次迅速排水。</li>\n<li>湖泊排水与高潮汐幅度周期相关，表明水力断裂可能由潮汐力引起的冰架弯曲协助。</li>\n<li>湖泊排水事件通常不与融水体积的阈值相关，而是与日潮汐幅度高的时期一致。</li>\n</ul>\n<h3 id=\"创新之处\"><a href=\"#创新之处\" class=\"headerlink\" title=\"创新之处\"></a>创新之处</h3><ul>\n<li>这项研究首次利用SAR影像捕捉了南极未覆盖表面湖泊的快速排水，强调了结合雷达和光学观测湖泊动态的效用。</li>\n<li>提出了潮汐力引起的冰架弯曲可能是湖泊排水的触发因素，这为理解冰架稳定性提供了新的视角。</li>\n</ul>\n<h3 id=\"贡献\"><a href=\"#贡献\" class=\"headerlink\" title=\"贡献\"></a>贡献</h3><ul>\n<li>增进了我们对南极冰盖表面湖泊动态及其对冰盖稳定性影响的理解。</li>\n<li>为预测未来南极冰质量损失和海平面贡献提供了重要的观测数据和理论基础。</li>\n</ul>\n<h3 id=\"不足\"><a href=\"#不足\" class=\"headerlink\" title=\"不足\"></a>不足</h3><ul>\n<li>文章并未详细讨论其他可能影响湖泊排水的因素，例如冰下条件和冰架底部的水力条件。</li>\n<li>对于湖泊排水对冰盖底部压力和冰-海洋相互作用的长期影响，还需要进一步的研究。</li>\n</ul>","related_posts":["paper-reading-1.html"],"length":1463,"excerpt":"<p>&emsp;&emsp;<a href=\"https://agupubs.onlinelibrary.wiley.com/doi/10.1029/2021GL095661?af=R\">Repeated Tidally Induced Hydrofracture of a Supraglacial Lake at the Amery Ice Shelf Grounding Zone</a></p>","more":"<h3 id=\"摘要\"><a href=\"#摘要\" class=\"headerlink\" title=\"摘要\"></a>摘要</h3><p>南极冰架上的表面融化和湖泊是常见的现象，它们的存在和排水被认为是冰架崩塌的前兆。在这里，我们展示了2014年至2020年间，东南极Amery冰架接地区一个表冰湖反复快速排水的卫星观测结果。2018年排水后的图像显示了湖底特征，这些特征是快速垂直湖排水的特征。观测到的湖体积表明，排水与一个阈值的融水体积无关。相反，排水通常与日潮汐幅度高的时期一致，这表明水力断裂是由冰架接地区固有的潮汐力引起的冰的弯曲所协助的。结合在Amery冰架接地区广泛观测到的湖泊排水，这些发现表明，尽管这些地区普遍存在增强的融化，但接地区的排水事件可能抑制了冰架融水的积累，从而代表了一种潜在的稳定机制。</p>\n<h3 id=\"重要性\"><a href=\"#重要性\" class=\"headerlink\" title=\"重要性\"></a>重要性</h3><p>这篇文章研究了南极冰盖表面湖泊的演变及其对冰盖稳定性的影响，这对于理解全球海平面上升的潜在贡献至关重要。特别是，研究集中在Amery冰架接地区的表面湖泊，这些湖泊的排水可能通过潮汐力引起的冰架弯曲来促进，这为冰盖稳定性提供了一个可能的稳定机制。</p>\n<h3 id=\"总结的前人研究\"><a href=\"#总结的前人研究\" class=\"headerlink\" title=\"总结的前人研究\"></a>总结的前人研究</h3><ul>\n<li>文章引用了关于南极冰盖质量损失加速的研究，如Smith等人(2020)、Bell等人(2018)和Turner等人(2005)。</li>\n<li>引用了关于冰架表面湖泊和融水生产的研究，例如Arthur等人(2020)、Dell等人(2020)和Dirscherl等人(2020)。</li>\n<li>提到了Larsen B冰架在2002年的崩塌，这是由表面融水增加和表面湖泊网络的快速排水触发的，可能通过融水驱动的水力断裂(Scambos等人，2000)。</li>\n</ul>\n<h3 id=\"不足之处\"><a href=\"#不足之处\" class=\"headerlink\" title=\"不足之处\"></a>不足之处</h3><ul>\n<li>尽管对湖泊排水过程的观测已有一些报道，但缺乏高空间和时间分辨率的冰架湖泊排水过程的报告。</li>\n<li>大多数预测未来南极海平面贡献的冰盖模型仅初步参数化了湖泊和水力断裂的影响，尽管它们有可能引发大规模的冰盖不稳定性。</li>\n</ul>\n<h3 id=\"使用的数据\"><a href=\"#使用的数据\" class=\"headerlink\" title=\"使用的数据\"></a>使用的数据</h3><ul>\n<li>利用了多种卫星平台的观测数据，包括Landsat 8和Sentinel-1合成孔径雷达(SAR)图像。</li>\n<li>使用了区域气候模型RACMO2.3p2和ERA-5再分析数据来评估融水生产。</li>\n<li>利用了CATS2008(Circum-Antarctic Tidal Simulation)模型来计算每日潮汐幅度。</li>\n</ul>\n<h3 id=\"采用的方法\"><a href=\"#采用的方法\" class=\"headerlink\" title=\"采用的方法\"></a>采用的方法</h3><ul>\n<li>通过分析Landsat 8数据，使用归一化水体指数(NDWI)来分类包含湖水的像素。</li>\n<li>采用了基于物理的方法来计算湖水体积，基于水中光的衰减率、湖底反照率和光学深水的反射率。</li>\n<li>使用了数字高程模型(DEM)来提取湖岸线，并计算湖体积。</li>\n</ul>\n<h3 id=\"获得的结果\"><a href=\"#获得的结果\" class=\"headerlink\" title=\"获得的结果\"></a>获得的结果</h3><ul>\n<li>观察到一个位于Amery冰架接地区的表面湖泊在2014年至2020年间多次迅速排水。</li>\n<li>湖泊排水与高潮汐幅度周期相关，表明水力断裂可能由潮汐力引起的冰架弯曲协助。</li>\n<li>湖泊排水事件通常不与融水体积的阈值相关，而是与日潮汐幅度高的时期一致。</li>\n</ul>\n<h3 id=\"创新之处\"><a href=\"#创新之处\" class=\"headerlink\" title=\"创新之处\"></a>创新之处</h3><ul>\n<li>这项研究首次利用SAR影像捕捉了南极未覆盖表面湖泊的快速排水，强调了结合雷达和光学观测湖泊动态的效用。</li>\n<li>提出了潮汐力引起的冰架弯曲可能是湖泊排水的触发因素，这为理解冰架稳定性提供了新的视角。</li>\n</ul>\n<h3 id=\"贡献\"><a href=\"#贡献\" class=\"headerlink\" title=\"贡献\"></a>贡献</h3><ul>\n<li>增进了我们对南极冰盖表面湖泊动态及其对冰盖稳定性影响的理解。</li>\n<li>为预测未来南极冰质量损失和海平面贡献提供了重要的观测数据和理论基础。</li>\n</ul>\n<h3 id=\"不足\"><a href=\"#不足\" class=\"headerlink\" title=\"不足\"></a>不足</h3><ul>\n<li>文章并未详细讨论其他可能影响湖泊排水的因素，例如冰下条件和冰架底部的水力条件。</li>\n<li>对于湖泊排水对冰盖底部压力和冰-海洋相互作用的长期影响，还需要进一步的研究。</li>\n</ul>"},{"title":"文献阅读（三）","abbrlink":"b3f68f1b","date":"2024-06-15T10:37:59.000Z","_content":"&emsp;&emsp;[Topographic and Ground-Ice Controls on Shallow Landsliding in Thawing Arctic Permafrost](https://agupubs.onlinelibrary.wiley.com/doi/10.1029/2020GL092264?af=R)\n<!--less-->\n### 摘要\n北极浅层滑坡的增加是气候变暖的一个潜在后果。更温暖的夏季气温和更大的降雨事件将热量输送到活动层，融化冰层并降低土壤的剪切应力。地形通过控制地下冰的分布和地表下水的运动，有可能加剧滑坡。我们展示了北极浅层滑坡是在零级排水盆地中启动的，这与非冻土环境中浅层滑坡的模型一致。然而，北极山坡的平均坡度低和凹度低，无法产生足够的孔隙水压力来引发滑坡。相反，二维坡面稳定性模型表明，地下冰的垂直分布控制了滑坡的易发性。靠近潜在破坏面的高地下冰浓度比高平均冰体积或快速融化有更强的控制作用。我们的结果表明，滑坡易发性强烈受到地形对地下冰和水文的控制影响。\n### 重要性\n\n这篇文章研究了北极地区由于气候变暖导致的冰土融化和浅层滑坡的潜在后果。随着极端天气事件的增加，北极的永久冻土正在迅速融化，这可能导致土壤稳定性下降，引发滑坡等地质灾害。这些滑坡不仅对基础设施和公共安全构成威胁，还可能加剧温室气体排放，因为冻土中储存的碳被释放到大气中。\n\n### 总结的前人研究\n\n- 文章引用了Dobricic等人(2020)、Lewkowicz和Way(2019)等研究，这些研究讨论了北极极端天气事件的增加以及冻土的迅速融化。\n- 引用了Balser等人(2014)、Harris等人(2011)等研究，这些研究探讨了冰土融化如何导致土壤不稳定和滑坡。\n- 引用了Lamoureux和Lafrenière(2009)的研究，该研究讨论了冻土退化过程中碳的释放。\n\n### 不足之处\n\n- 尽管已有研究探讨了冻土退化和滑坡的关系，但对控制斜坡不稳定性的过程的理解仍然有限。\n- 现有模型和方法可能未能充分考虑地形、水文和冻土中冰的分布对滑坡触发的影响。\n\n### 使用的数据\n\n- 使用了Maxar Technologies 2008年的图像数据，通过Google Earth获取，空间分辨率为50cm。\n- 利用了5米间隔的合成孔径雷达(InSAR)衍生的数字高程模型(DEM)。\n- 使用了SHALSTAB模型来评估滑坡易发性。\n\n### 采用的方法\n\n- 开发了基于地形的滑坡分析模型，比较了滑坡分布与地形衍生的水系网络。\n- 使用了2D极限平衡方法(Morgenstern-Price方法)进行坡面稳定性模拟。\n- 通过GeoStudio软件进行地质技术模拟，以测试不同地下冰分布对滑坡触发的影响。\n\n### 获得的结果\n\n- 发现北极浅层滑坡主要在零级排水盆地的汇聚地形中启动。\n- 坡面稳定性模型表明，地下冰的垂直分布对滑坡敏感性有重要影响，尤其是在潜在的滑坡破坏面附近的高地下冰浓度。\n- 研究结果表明，滑坡敏感性受到地形对地下冰和水文控制的强烈影响。\n\n### 创新之处\n\n- 提供了一种新的视角，将地形、地下冰分布和水文因素结合起来，以评估北极地区滑坡的易发性。\n- 通过2D坡面稳定性模型，展示了地下冰分布对滑坡触发的控制作用，这在以往的研究中并不常见。\n\n### 贡献\n\n- 增进了对北极地区气候变化、冻土退化和滑坡活动之间关系的理解。\n- 为评估气候变化对北极地区基础设施和公共安全的影响提供了科学依据。\n\n### 不足\n\n- 模型可能未能完全考虑所有影响滑坡的因素，例如季节性气候变化和随机天气事件的影响。\n- 需要更多的实地数据和长期监测来验证模型的预测和评估滑坡易发性的准确性。\n","source":"_posts/2024-06-15-paper-reading-3.md","raw":"---\ntitle: 文献阅读（三）\ncategories:\n  - work\ntags:\n  - paper\nabbrlink: b3f68f1b\ndate: 2024-06-15 18:37:59\n---\n&emsp;&emsp;[Topographic and Ground-Ice Controls on Shallow Landsliding in Thawing Arctic Permafrost](https://agupubs.onlinelibrary.wiley.com/doi/10.1029/2020GL092264?af=R)\n<!--less-->\n### 摘要\n北极浅层滑坡的增加是气候变暖的一个潜在后果。更温暖的夏季气温和更大的降雨事件将热量输送到活动层，融化冰层并降低土壤的剪切应力。地形通过控制地下冰的分布和地表下水的运动，有可能加剧滑坡。我们展示了北极浅层滑坡是在零级排水盆地中启动的，这与非冻土环境中浅层滑坡的模型一致。然而，北极山坡的平均坡度低和凹度低，无法产生足够的孔隙水压力来引发滑坡。相反，二维坡面稳定性模型表明，地下冰的垂直分布控制了滑坡的易发性。靠近潜在破坏面的高地下冰浓度比高平均冰体积或快速融化有更强的控制作用。我们的结果表明，滑坡易发性强烈受到地形对地下冰和水文的控制影响。\n### 重要性\n\n这篇文章研究了北极地区由于气候变暖导致的冰土融化和浅层滑坡的潜在后果。随着极端天气事件的增加，北极的永久冻土正在迅速融化，这可能导致土壤稳定性下降，引发滑坡等地质灾害。这些滑坡不仅对基础设施和公共安全构成威胁，还可能加剧温室气体排放，因为冻土中储存的碳被释放到大气中。\n\n### 总结的前人研究\n\n- 文章引用了Dobricic等人(2020)、Lewkowicz和Way(2019)等研究，这些研究讨论了北极极端天气事件的增加以及冻土的迅速融化。\n- 引用了Balser等人(2014)、Harris等人(2011)等研究，这些研究探讨了冰土融化如何导致土壤不稳定和滑坡。\n- 引用了Lamoureux和Lafrenière(2009)的研究，该研究讨论了冻土退化过程中碳的释放。\n\n### 不足之处\n\n- 尽管已有研究探讨了冻土退化和滑坡的关系，但对控制斜坡不稳定性的过程的理解仍然有限。\n- 现有模型和方法可能未能充分考虑地形、水文和冻土中冰的分布对滑坡触发的影响。\n\n### 使用的数据\n\n- 使用了Maxar Technologies 2008年的图像数据，通过Google Earth获取，空间分辨率为50cm。\n- 利用了5米间隔的合成孔径雷达(InSAR)衍生的数字高程模型(DEM)。\n- 使用了SHALSTAB模型来评估滑坡易发性。\n\n### 采用的方法\n\n- 开发了基于地形的滑坡分析模型，比较了滑坡分布与地形衍生的水系网络。\n- 使用了2D极限平衡方法(Morgenstern-Price方法)进行坡面稳定性模拟。\n- 通过GeoStudio软件进行地质技术模拟，以测试不同地下冰分布对滑坡触发的影响。\n\n### 获得的结果\n\n- 发现北极浅层滑坡主要在零级排水盆地的汇聚地形中启动。\n- 坡面稳定性模型表明，地下冰的垂直分布对滑坡敏感性有重要影响，尤其是在潜在的滑坡破坏面附近的高地下冰浓度。\n- 研究结果表明，滑坡敏感性受到地形对地下冰和水文控制的强烈影响。\n\n### 创新之处\n\n- 提供了一种新的视角，将地形、地下冰分布和水文因素结合起来，以评估北极地区滑坡的易发性。\n- 通过2D坡面稳定性模型，展示了地下冰分布对滑坡触发的控制作用，这在以往的研究中并不常见。\n\n### 贡献\n\n- 增进了对北极地区气候变化、冻土退化和滑坡活动之间关系的理解。\n- 为评估气候变化对北极地区基础设施和公共安全的影响提供了科学依据。\n\n### 不足\n\n- 模型可能未能完全考虑所有影响滑坡的因素，例如季节性气候变化和随机天气事件的影响。\n- 需要更多的实地数据和长期监测来验证模型的预测和评估滑坡易发性的准确性。\n","slug":"paper-reading-3","published":1,"updated":"2024-06-15T10:46:53.209Z","comments":1,"layout":"post","photos":[],"_id":"cmh498ipr0081wvou5le0dqas","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><h3 id=\"摘要\"><a href=\"#摘要\" class=\"headerlink\" title=\"摘要\"></a>摘要</h3><p>北极浅层滑坡的增加是气候变暖的一个潜在后果。更温暖的夏季气温和更大的降雨事件将热量输送到活动层，融化冰层并降低土壤的剪切应力。地形通过控制地下冰的分布和地表下水的运动，有可能加剧滑坡。我们展示了北极浅层滑坡是在零级排水盆地中启动的，这与非冻土环境中浅层滑坡的模型一致。然而，北极山坡的平均坡度低和凹度低，无法产生足够的孔隙水压力来引发滑坡。相反，二维坡面稳定性模型表明，地下冰的垂直分布控制了滑坡的易发性。靠近潜在破坏面的高地下冰浓度比高平均冰体积或快速融化有更强的控制作用。我们的结果表明，滑坡易发性强烈受到地形对地下冰和水文的控制影响。</p>\n<h3 id=\"重要性\"><a href=\"#重要性\" class=\"headerlink\" title=\"重要性\"></a>重要性</h3><p>这篇文章研究了北极地区由于气候变暖导致的冰土融化和浅层滑坡的潜在后果。随着极端天气事件的增加，北极的永久冻土正在迅速融化，这可能导致土壤稳定性下降，引发滑坡等地质灾害。这些滑坡不仅对基础设施和公共安全构成威胁，还可能加剧温室气体排放，因为冻土中储存的碳被释放到大气中。</p>\n<h3 id=\"总结的前人研究\"><a href=\"#总结的前人研究\" class=\"headerlink\" title=\"总结的前人研究\"></a>总结的前人研究</h3><ul>\n<li>文章引用了Dobricic等人(2020)、Lewkowicz和Way(2019)等研究，这些研究讨论了北极极端天气事件的增加以及冻土的迅速融化。</li>\n<li>引用了Balser等人(2014)、Harris等人(2011)等研究，这些研究探讨了冰土融化如何导致土壤不稳定和滑坡。</li>\n<li>引用了Lamoureux和Lafrenière(2009)的研究，该研究讨论了冻土退化过程中碳的释放。</li>\n</ul>\n<h3 id=\"不足之处\"><a href=\"#不足之处\" class=\"headerlink\" title=\"不足之处\"></a>不足之处</h3><ul>\n<li>尽管已有研究探讨了冻土退化和滑坡的关系，但对控制斜坡不稳定性的过程的理解仍然有限。</li>\n<li>现有模型和方法可能未能充分考虑地形、水文和冻土中冰的分布对滑坡触发的影响。</li>\n</ul>\n<h3 id=\"使用的数据\"><a href=\"#使用的数据\" class=\"headerlink\" title=\"使用的数据\"></a>使用的数据</h3><ul>\n<li>使用了Maxar Technologies 2008年的图像数据，通过Google Earth获取，空间分辨率为50cm。</li>\n<li>利用了5米间隔的合成孔径雷达(InSAR)衍生的数字高程模型(DEM)。</li>\n<li>使用了SHALSTAB模型来评估滑坡易发性。</li>\n</ul>\n<h3 id=\"采用的方法\"><a href=\"#采用的方法\" class=\"headerlink\" title=\"采用的方法\"></a>采用的方法</h3><ul>\n<li>开发了基于地形的滑坡分析模型，比较了滑坡分布与地形衍生的水系网络。</li>\n<li>使用了2D极限平衡方法(Morgenstern-Price方法)进行坡面稳定性模拟。</li>\n<li>通过GeoStudio软件进行地质技术模拟，以测试不同地下冰分布对滑坡触发的影响。</li>\n</ul>\n<h3 id=\"获得的结果\"><a href=\"#获得的结果\" class=\"headerlink\" title=\"获得的结果\"></a>获得的结果</h3><ul>\n<li>发现北极浅层滑坡主要在零级排水盆地的汇聚地形中启动。</li>\n<li>坡面稳定性模型表明，地下冰的垂直分布对滑坡敏感性有重要影响，尤其是在潜在的滑坡破坏面附近的高地下冰浓度。</li>\n<li>研究结果表明，滑坡敏感性受到地形对地下冰和水文控制的强烈影响。</li>\n</ul>\n<h3 id=\"创新之处\"><a href=\"#创新之处\" class=\"headerlink\" title=\"创新之处\"></a>创新之处</h3><ul>\n<li>提供了一种新的视角，将地形、地下冰分布和水文因素结合起来，以评估北极地区滑坡的易发性。</li>\n<li>通过2D坡面稳定性模型，展示了地下冰分布对滑坡触发的控制作用，这在以往的研究中并不常见。</li>\n</ul>\n<h3 id=\"贡献\"><a href=\"#贡献\" class=\"headerlink\" title=\"贡献\"></a>贡献</h3><ul>\n<li>增进了对北极地区气候变化、冻土退化和滑坡活动之间关系的理解。</li>\n<li>为评估气候变化对北极地区基础设施和公共安全的影响提供了科学依据。</li>\n</ul>\n<h3 id=\"不足\"><a href=\"#不足\" class=\"headerlink\" title=\"不足\"></a>不足</h3><ul>\n<li>模型可能未能完全考虑所有影响滑坡的因素，例如季节性气候变化和随机天气事件的影响。</li>\n<li>需要更多的实地数据和长期监测来验证模型的预测和评估滑坡易发性的准确性。</li>\n</ul>","related_posts":["paper-reading-5.html"],"length":1359,"excerpt":"<p>&emsp;&emsp;<a href=\"https://agupubs.onlinelibrary.wiley.com/doi/10.1029/2020GL092264?af=R\">Topographic and Ground-Ice Controls on Shallow Landsliding in Thawing Arctic Permafrost</a></p>","more":"<h3 id=\"摘要\"><a href=\"#摘要\" class=\"headerlink\" title=\"摘要\"></a>摘要</h3><p>北极浅层滑坡的增加是气候变暖的一个潜在后果。更温暖的夏季气温和更大的降雨事件将热量输送到活动层，融化冰层并降低土壤的剪切应力。地形通过控制地下冰的分布和地表下水的运动，有可能加剧滑坡。我们展示了北极浅层滑坡是在零级排水盆地中启动的，这与非冻土环境中浅层滑坡的模型一致。然而，北极山坡的平均坡度低和凹度低，无法产生足够的孔隙水压力来引发滑坡。相反，二维坡面稳定性模型表明，地下冰的垂直分布控制了滑坡的易发性。靠近潜在破坏面的高地下冰浓度比高平均冰体积或快速融化有更强的控制作用。我们的结果表明，滑坡易发性强烈受到地形对地下冰和水文的控制影响。</p>\n<h3 id=\"重要性\"><a href=\"#重要性\" class=\"headerlink\" title=\"重要性\"></a>重要性</h3><p>这篇文章研究了北极地区由于气候变暖导致的冰土融化和浅层滑坡的潜在后果。随着极端天气事件的增加，北极的永久冻土正在迅速融化，这可能导致土壤稳定性下降，引发滑坡等地质灾害。这些滑坡不仅对基础设施和公共安全构成威胁，还可能加剧温室气体排放，因为冻土中储存的碳被释放到大气中。</p>\n<h3 id=\"总结的前人研究\"><a href=\"#总结的前人研究\" class=\"headerlink\" title=\"总结的前人研究\"></a>总结的前人研究</h3><ul>\n<li>文章引用了Dobricic等人(2020)、Lewkowicz和Way(2019)等研究，这些研究讨论了北极极端天气事件的增加以及冻土的迅速融化。</li>\n<li>引用了Balser等人(2014)、Harris等人(2011)等研究，这些研究探讨了冰土融化如何导致土壤不稳定和滑坡。</li>\n<li>引用了Lamoureux和Lafrenière(2009)的研究，该研究讨论了冻土退化过程中碳的释放。</li>\n</ul>\n<h3 id=\"不足之处\"><a href=\"#不足之处\" class=\"headerlink\" title=\"不足之处\"></a>不足之处</h3><ul>\n<li>尽管已有研究探讨了冻土退化和滑坡的关系，但对控制斜坡不稳定性的过程的理解仍然有限。</li>\n<li>现有模型和方法可能未能充分考虑地形、水文和冻土中冰的分布对滑坡触发的影响。</li>\n</ul>\n<h3 id=\"使用的数据\"><a href=\"#使用的数据\" class=\"headerlink\" title=\"使用的数据\"></a>使用的数据</h3><ul>\n<li>使用了Maxar Technologies 2008年的图像数据，通过Google Earth获取，空间分辨率为50cm。</li>\n<li>利用了5米间隔的合成孔径雷达(InSAR)衍生的数字高程模型(DEM)。</li>\n<li>使用了SHALSTAB模型来评估滑坡易发性。</li>\n</ul>\n<h3 id=\"采用的方法\"><a href=\"#采用的方法\" class=\"headerlink\" title=\"采用的方法\"></a>采用的方法</h3><ul>\n<li>开发了基于地形的滑坡分析模型，比较了滑坡分布与地形衍生的水系网络。</li>\n<li>使用了2D极限平衡方法(Morgenstern-Price方法)进行坡面稳定性模拟。</li>\n<li>通过GeoStudio软件进行地质技术模拟，以测试不同地下冰分布对滑坡触发的影响。</li>\n</ul>\n<h3 id=\"获得的结果\"><a href=\"#获得的结果\" class=\"headerlink\" title=\"获得的结果\"></a>获得的结果</h3><ul>\n<li>发现北极浅层滑坡主要在零级排水盆地的汇聚地形中启动。</li>\n<li>坡面稳定性模型表明，地下冰的垂直分布对滑坡敏感性有重要影响，尤其是在潜在的滑坡破坏面附近的高地下冰浓度。</li>\n<li>研究结果表明，滑坡敏感性受到地形对地下冰和水文控制的强烈影响。</li>\n</ul>\n<h3 id=\"创新之处\"><a href=\"#创新之处\" class=\"headerlink\" title=\"创新之处\"></a>创新之处</h3><ul>\n<li>提供了一种新的视角，将地形、地下冰分布和水文因素结合起来，以评估北极地区滑坡的易发性。</li>\n<li>通过2D坡面稳定性模型，展示了地下冰分布对滑坡触发的控制作用，这在以往的研究中并不常见。</li>\n</ul>\n<h3 id=\"贡献\"><a href=\"#贡献\" class=\"headerlink\" title=\"贡献\"></a>贡献</h3><ul>\n<li>增进了对北极地区气候变化、冻土退化和滑坡活动之间关系的理解。</li>\n<li>为评估气候变化对北极地区基础设施和公共安全的影响提供了科学依据。</li>\n</ul>\n<h3 id=\"不足\"><a href=\"#不足\" class=\"headerlink\" title=\"不足\"></a>不足</h3><ul>\n<li>模型可能未能完全考虑所有影响滑坡的因素，例如季节性气候变化和随机天气事件的影响。</li>\n<li>需要更多的实地数据和长期监测来验证模型的预测和评估滑坡易发性的准确性。</li>\n</ul>"},{"title":"文献阅读","abbrlink":"7c36b624","date":"2024-06-15T00:59:11.000Z","_content":"&emsp;&emsp;阅读文献对于了解研究趋势是十分重要的。\n<!--less-->\n&emsp;&emsp;少数文章需要精读，例如研究方向的经典文章，相关方向的好文章。仔细阅读，你可以学习到他们的写作模式，逻辑结构，文字表达，模仿他们的工作和写作，你也可以干科研。\n\n&emsp;&emsp;也有很多文章不太需要精读，毕竟你的”时间“那么有限。这个时候可以用到很多AI工具帮你快速的阅读文献，获得该文献的大致内容。然后你再判断这篇文章有没有必要精读。\n\n&emsp;&emsp;以后会在博客记录下看到的一些文章的内容，当然都是通过AI帮我读的。我用的是[kimi](https://kimi.moonshot.cn/)还挺好用。先上传文章，然后给提示词：\n```\n请先翻译摘要。相关研究的重要性有哪些？请具体列举并阐述前人具体有哪些相关研究，这些研究有哪些不足？本文使用了什么数据，采用了什么方法，获得了什么结果？本文创新之处是什么，有什么贡献，有什么不足？请用markdown的格式一条一条详细回答以上问题。\n```\n","source":"_posts/2024-06-15-paper-reading.md","raw":"---\ntitle: 文献阅读\ncategories:\n  - work\ntags:\n  - paper\nabbrlink: 7c36b624\ndate: 2024-06-15 08:59:11\n---\n&emsp;&emsp;阅读文献对于了解研究趋势是十分重要的。\n<!--less-->\n&emsp;&emsp;少数文章需要精读，例如研究方向的经典文章，相关方向的好文章。仔细阅读，你可以学习到他们的写作模式，逻辑结构，文字表达，模仿他们的工作和写作，你也可以干科研。\n\n&emsp;&emsp;也有很多文章不太需要精读，毕竟你的”时间“那么有限。这个时候可以用到很多AI工具帮你快速的阅读文献，获得该文献的大致内容。然后你再判断这篇文章有没有必要精读。\n\n&emsp;&emsp;以后会在博客记录下看到的一些文章的内容，当然都是通过AI帮我读的。我用的是[kimi](https://kimi.moonshot.cn/)还挺好用。先上传文章，然后给提示词：\n```\n请先翻译摘要。相关研究的重要性有哪些？请具体列举并阐述前人具体有哪些相关研究，这些研究有哪些不足？本文使用了什么数据，采用了什么方法，获得了什么结果？本文创新之处是什么，有什么贡献，有什么不足？请用markdown的格式一条一条详细回答以上问题。\n```\n","slug":"paper-reading","published":1,"updated":"2024-06-18T05:18:14.409Z","comments":1,"layout":"post","photos":[],"_id":"cmh498ipr0084wvou73wi1qzs","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>&emsp;&emsp;少数文章需要精读，例如研究方向的经典文章，相关方向的好文章。仔细阅读，你可以学习到他们的写作模式，逻辑结构，文字表达，模仿他们的工作和写作，你也可以干科研。</p>\n<p>&emsp;&emsp;也有很多文章不太需要精读，毕竟你的”时间“那么有限。这个时候可以用到很多AI工具帮你快速的阅读文献，获得该文献的大致内容。然后你再判断这篇文章有没有必要精读。</p>\n<p>&emsp;&emsp;以后会在博客记录下看到的一些文章的内容，当然都是通过AI帮我读的。我用的是<a href=\"https://kimi.moonshot.cn/\">kimi</a>还挺好用。先上传文章，然后给提示词：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">请先翻译摘要。相关研究的重要性有哪些？请具体列举并阐述前人具体有哪些相关研究，这些研究有哪些不足？本文使用了什么数据，采用了什么方法，获得了什么结果？本文创新之处是什么，有什么贡献，有什么不足？请用markdown的格式一条一条详细回答以上问题。</span><br></pre></td></tr></table></figure>","related_posts":[],"length":407,"excerpt":"<p>&emsp;&emsp;阅读文献对于了解研究趋势是十分重要的。</p>","more":"<p>&emsp;&emsp;少数文章需要精读，例如研究方向的经典文章，相关方向的好文章。仔细阅读，你可以学习到他们的写作模式，逻辑结构，文字表达，模仿他们的工作和写作，你也可以干科研。</p>\n<p>&emsp;&emsp;也有很多文章不太需要精读，毕竟你的”时间“那么有限。这个时候可以用到很多AI工具帮你快速的阅读文献，获得该文献的大致内容。然后你再判断这篇文章有没有必要精读。</p>\n<p>&emsp;&emsp;以后会在博客记录下看到的一些文章的内容，当然都是通过AI帮我读的。我用的是<a href=\"https://kimi.moonshot.cn/\">kimi</a>还挺好用。先上传文章，然后给提示词：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">请先翻译摘要。相关研究的重要性有哪些？请具体列举并阐述前人具体有哪些相关研究，这些研究有哪些不足？本文使用了什么数据，采用了什么方法，获得了什么结果？本文创新之处是什么，有什么贡献，有什么不足？请用markdown的格式一条一条详细回答以上问题。</span><br></pre></td></tr></table></figure>"},{"title":"文献阅读（四）","abbrlink":"b545db8c","date":"2024-06-16T15:41:11.000Z","_content":"&emsp;&emsp;[Model Mean State Sea Ice Thickness Reflects Dynamic EffectBiases: A Process Based Evaluation](https://agupubs.onlinelibrary.wiley.com/doi/10.1029/2023GL106963?af=R)\n<!--less-->\n### 摘要\n全球气候模型通过累加影响厚度的热力学过程（通过相变影响厚度）和动力学过程（通过相对运动影响厚度）来计算海冰厚度。将这些单独的过程与观测结果进行比较对于模型的解释和发展至关重要。我们利用基底热力学生长、整体厚度变化及其残差差异（包括动力学）的观测估计来评估这些过程，在国家大气研究中心（NCAR）社区地球系统模型2（CESM2）提交给世界气候研究计划（WCRP）海洋模型比较项目第二阶段（OMIP2）和泛北极冰-洋建模与同化系统（PIOMAS）中的表现。两种模型都表现出与2010年至2018年观测估计相比，在中央北极有更高的基底热力学生长和更低的残差效应以及冬季厚度，而在边缘海域则相反。纠正残差效应的偏差将改善平均厚度和基底热力学生长的偏差。\n### 重要性\n\n这篇文章研究了全球气候模型中海冰厚度的模拟，这对于理解北极海冰对气候变化的响应至关重要。海冰厚度的准确模拟有助于预测未来北极海冰条件，进而对全球气候和海平面变化进行更准确的预测。\n\n### 总结的前人研究\n\n- 文章中提到了之前对海冰模型输出与观测数据进行比较的研究，例如Boe et al. (2009), Massonnet et al. (2012), Notz et al. (2020), Shu et al. (2015, 2020), Stroeve et al. (2007)。\n- 引用了关于海冰厚度和自由板高度之间关系的Alexanderrov et al. (2010)。\n- 讨论了Hibler (1980), Thorndike et al. (1975), Zhang & Rothrock (2001)等人关于海冰动力学和热力学过程的早期研究。\n\n### 不足之处\n\n- 之前的研究缺乏对模型中热力学和动力学海冰厚度效应独立与观测数据的比较。\n- 文章指出，现有模型在模拟海冰厚度方面存在偏差，特别是在中央北极和周边海域的基底热力学生长和剩余效应方面。\n\n### 使用的数据\n\n- 使用了AWI CS2SMOS海冰厚度观测数据集，该数据集结合了CryoSat-2和SMOS卫星的数据。\n- 使用了SLICE（Stefan’s Law Integrated Conducted Energy）方法来检索基底热力学生长并计算剩余过程效应。\n- 比较了NCAR社区地球系统模型2（CESM2）提交给OMIP2和PIOMAS的数据。\n\n### 采用的方法\n\n- 文章采用了一种基于过程的评估方法，通过比较观测估计和模型预测来评估海冰模型中的热力学和动力学过程。\n- 使用了差分插值将PIOMAS和CESM2-OMIP2数据集转换为25公里分辨率的EASE-Grid 2.0。\n\n### 获得的结果\n\n- 发现CESM2-OMIP2和PIOMAS在中央北极的基底热力学生长和剩余效应方面与观测估计相比存在相似的模式偏差。\n- 通过调整动态效应使其更接近观测估计，可以纠正平均厚度和基底热力学生长的偏差。\n\n### 创新之处\n\n- 本研究是首次尝试将观测到的热力学海冰厚度生长和动态海冰厚度效应与全球气候模型和海冰模型再分析进行比较。\n- 引入SLICE方法，这是一种新的基于卫星数据的海冰厚度变化观测估计方法。\n\n### 贡献\n\n- 为改进海冰模型提供了观测数据支持，有助于提高模型预测的准确性。\n- 通过比较观测数据和模型输出，为理解影响海冰厚度的过程提供了新的见解。\n\n### 不足\n\n- 文章指出，需要进一步调整模型中的动态组分参数化，以更准确地反映观测估计。\n- 对于模型中的热力学过程的表示可能需要进一步的改进，以更好地匹配观测数据。\n","source":"_posts/2024-06-16-paper-reading-4.md","raw":"---\ntitle: 文献阅读（四）\ncategories:\n  - work\ntags:\n  - paper\nabbrlink: b545db8c\ndate: 2024-06-16 23:41:11\n---\n&emsp;&emsp;[Model Mean State Sea Ice Thickness Reflects Dynamic EffectBiases: A Process Based Evaluation](https://agupubs.onlinelibrary.wiley.com/doi/10.1029/2023GL106963?af=R)\n<!--less-->\n### 摘要\n全球气候模型通过累加影响厚度的热力学过程（通过相变影响厚度）和动力学过程（通过相对运动影响厚度）来计算海冰厚度。将这些单独的过程与观测结果进行比较对于模型的解释和发展至关重要。我们利用基底热力学生长、整体厚度变化及其残差差异（包括动力学）的观测估计来评估这些过程，在国家大气研究中心（NCAR）社区地球系统模型2（CESM2）提交给世界气候研究计划（WCRP）海洋模型比较项目第二阶段（OMIP2）和泛北极冰-洋建模与同化系统（PIOMAS）中的表现。两种模型都表现出与2010年至2018年观测估计相比，在中央北极有更高的基底热力学生长和更低的残差效应以及冬季厚度，而在边缘海域则相反。纠正残差效应的偏差将改善平均厚度和基底热力学生长的偏差。\n### 重要性\n\n这篇文章研究了全球气候模型中海冰厚度的模拟，这对于理解北极海冰对气候变化的响应至关重要。海冰厚度的准确模拟有助于预测未来北极海冰条件，进而对全球气候和海平面变化进行更准确的预测。\n\n### 总结的前人研究\n\n- 文章中提到了之前对海冰模型输出与观测数据进行比较的研究，例如Boe et al. (2009), Massonnet et al. (2012), Notz et al. (2020), Shu et al. (2015, 2020), Stroeve et al. (2007)。\n- 引用了关于海冰厚度和自由板高度之间关系的Alexanderrov et al. (2010)。\n- 讨论了Hibler (1980), Thorndike et al. (1975), Zhang & Rothrock (2001)等人关于海冰动力学和热力学过程的早期研究。\n\n### 不足之处\n\n- 之前的研究缺乏对模型中热力学和动力学海冰厚度效应独立与观测数据的比较。\n- 文章指出，现有模型在模拟海冰厚度方面存在偏差，特别是在中央北极和周边海域的基底热力学生长和剩余效应方面。\n\n### 使用的数据\n\n- 使用了AWI CS2SMOS海冰厚度观测数据集，该数据集结合了CryoSat-2和SMOS卫星的数据。\n- 使用了SLICE（Stefan’s Law Integrated Conducted Energy）方法来检索基底热力学生长并计算剩余过程效应。\n- 比较了NCAR社区地球系统模型2（CESM2）提交给OMIP2和PIOMAS的数据。\n\n### 采用的方法\n\n- 文章采用了一种基于过程的评估方法，通过比较观测估计和模型预测来评估海冰模型中的热力学和动力学过程。\n- 使用了差分插值将PIOMAS和CESM2-OMIP2数据集转换为25公里分辨率的EASE-Grid 2.0。\n\n### 获得的结果\n\n- 发现CESM2-OMIP2和PIOMAS在中央北极的基底热力学生长和剩余效应方面与观测估计相比存在相似的模式偏差。\n- 通过调整动态效应使其更接近观测估计，可以纠正平均厚度和基底热力学生长的偏差。\n\n### 创新之处\n\n- 本研究是首次尝试将观测到的热力学海冰厚度生长和动态海冰厚度效应与全球气候模型和海冰模型再分析进行比较。\n- 引入SLICE方法，这是一种新的基于卫星数据的海冰厚度变化观测估计方法。\n\n### 贡献\n\n- 为改进海冰模型提供了观测数据支持，有助于提高模型预测的准确性。\n- 通过比较观测数据和模型输出，为理解影响海冰厚度的过程提供了新的见解。\n\n### 不足\n\n- 文章指出，需要进一步调整模型中的动态组分参数化，以更准确地反映观测估计。\n- 对于模型中的热力学过程的表示可能需要进一步的改进，以更好地匹配观测数据。\n","slug":"paper-reading-4","published":1,"updated":"2024-06-16T15:45:56.985Z","comments":1,"layout":"post","photos":[],"_id":"cmh498ips0088wvou7caj7rhk","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><h3 id=\"摘要\"><a href=\"#摘要\" class=\"headerlink\" title=\"摘要\"></a>摘要</h3><p>全球气候模型通过累加影响厚度的热力学过程（通过相变影响厚度）和动力学过程（通过相对运动影响厚度）来计算海冰厚度。将这些单独的过程与观测结果进行比较对于模型的解释和发展至关重要。我们利用基底热力学生长、整体厚度变化及其残差差异（包括动力学）的观测估计来评估这些过程，在国家大气研究中心（NCAR）社区地球系统模型2（CESM2）提交给世界气候研究计划（WCRP）海洋模型比较项目第二阶段（OMIP2）和泛北极冰-洋建模与同化系统（PIOMAS）中的表现。两种模型都表现出与2010年至2018年观测估计相比，在中央北极有更高的基底热力学生长和更低的残差效应以及冬季厚度，而在边缘海域则相反。纠正残差效应的偏差将改善平均厚度和基底热力学生长的偏差。</p>\n<h3 id=\"重要性\"><a href=\"#重要性\" class=\"headerlink\" title=\"重要性\"></a>重要性</h3><p>这篇文章研究了全球气候模型中海冰厚度的模拟，这对于理解北极海冰对气候变化的响应至关重要。海冰厚度的准确模拟有助于预测未来北极海冰条件，进而对全球气候和海平面变化进行更准确的预测。</p>\n<h3 id=\"总结的前人研究\"><a href=\"#总结的前人研究\" class=\"headerlink\" title=\"总结的前人研究\"></a>总结的前人研究</h3><ul>\n<li>文章中提到了之前对海冰模型输出与观测数据进行比较的研究，例如Boe et al. (2009), Massonnet et al. (2012), Notz et al. (2020), Shu et al. (2015, 2020), Stroeve et al. (2007)。</li>\n<li>引用了关于海冰厚度和自由板高度之间关系的Alexanderrov et al. (2010)。</li>\n<li>讨论了Hibler (1980), Thorndike et al. (1975), Zhang &amp; Rothrock (2001)等人关于海冰动力学和热力学过程的早期研究。</li>\n</ul>\n<h3 id=\"不足之处\"><a href=\"#不足之处\" class=\"headerlink\" title=\"不足之处\"></a>不足之处</h3><ul>\n<li>之前的研究缺乏对模型中热力学和动力学海冰厚度效应独立与观测数据的比较。</li>\n<li>文章指出，现有模型在模拟海冰厚度方面存在偏差，特别是在中央北极和周边海域的基底热力学生长和剩余效应方面。</li>\n</ul>\n<h3 id=\"使用的数据\"><a href=\"#使用的数据\" class=\"headerlink\" title=\"使用的数据\"></a>使用的数据</h3><ul>\n<li>使用了AWI CS2SMOS海冰厚度观测数据集，该数据集结合了CryoSat-2和SMOS卫星的数据。</li>\n<li>使用了SLICE（Stefan’s Law Integrated Conducted Energy）方法来检索基底热力学生长并计算剩余过程效应。</li>\n<li>比较了NCAR社区地球系统模型2（CESM2）提交给OMIP2和PIOMAS的数据。</li>\n</ul>\n<h3 id=\"采用的方法\"><a href=\"#采用的方法\" class=\"headerlink\" title=\"采用的方法\"></a>采用的方法</h3><ul>\n<li>文章采用了一种基于过程的评估方法，通过比较观测估计和模型预测来评估海冰模型中的热力学和动力学过程。</li>\n<li>使用了差分插值将PIOMAS和CESM2-OMIP2数据集转换为25公里分辨率的EASE-Grid 2.0。</li>\n</ul>\n<h3 id=\"获得的结果\"><a href=\"#获得的结果\" class=\"headerlink\" title=\"获得的结果\"></a>获得的结果</h3><ul>\n<li>发现CESM2-OMIP2和PIOMAS在中央北极的基底热力学生长和剩余效应方面与观测估计相比存在相似的模式偏差。</li>\n<li>通过调整动态效应使其更接近观测估计，可以纠正平均厚度和基底热力学生长的偏差。</li>\n</ul>\n<h3 id=\"创新之处\"><a href=\"#创新之处\" class=\"headerlink\" title=\"创新之处\"></a>创新之处</h3><ul>\n<li>本研究是首次尝试将观测到的热力学海冰厚度生长和动态海冰厚度效应与全球气候模型和海冰模型再分析进行比较。</li>\n<li>引入SLICE方法，这是一种新的基于卫星数据的海冰厚度变化观测估计方法。</li>\n</ul>\n<h3 id=\"贡献\"><a href=\"#贡献\" class=\"headerlink\" title=\"贡献\"></a>贡献</h3><ul>\n<li>为改进海冰模型提供了观测数据支持，有助于提高模型预测的准确性。</li>\n<li>通过比较观测数据和模型输出，为理解影响海冰厚度的过程提供了新的见解。</li>\n</ul>\n<h3 id=\"不足\"><a href=\"#不足\" class=\"headerlink\" title=\"不足\"></a>不足</h3><ul>\n<li>文章指出，需要进一步调整模型中的动态组分参数化，以更准确地反映观测估计。</li>\n<li>对于模型中的热力学过程的表示可能需要进一步的改进，以更好地匹配观测数据。</li>\n</ul>","related_posts":[],"length":1457,"excerpt":"<p>&emsp;&emsp;<a href=\"https://agupubs.onlinelibrary.wiley.com/doi/10.1029/2023GL106963?af=R\">Model Mean State Sea Ice Thickness Reflects Dynamic EffectBiases: A Process Based Evaluation</a></p>","more":"<h3 id=\"摘要\"><a href=\"#摘要\" class=\"headerlink\" title=\"摘要\"></a>摘要</h3><p>全球气候模型通过累加影响厚度的热力学过程（通过相变影响厚度）和动力学过程（通过相对运动影响厚度）来计算海冰厚度。将这些单独的过程与观测结果进行比较对于模型的解释和发展至关重要。我们利用基底热力学生长、整体厚度变化及其残差差异（包括动力学）的观测估计来评估这些过程，在国家大气研究中心（NCAR）社区地球系统模型2（CESM2）提交给世界气候研究计划（WCRP）海洋模型比较项目第二阶段（OMIP2）和泛北极冰-洋建模与同化系统（PIOMAS）中的表现。两种模型都表现出与2010年至2018年观测估计相比，在中央北极有更高的基底热力学生长和更低的残差效应以及冬季厚度，而在边缘海域则相反。纠正残差效应的偏差将改善平均厚度和基底热力学生长的偏差。</p>\n<h3 id=\"重要性\"><a href=\"#重要性\" class=\"headerlink\" title=\"重要性\"></a>重要性</h3><p>这篇文章研究了全球气候模型中海冰厚度的模拟，这对于理解北极海冰对气候变化的响应至关重要。海冰厚度的准确模拟有助于预测未来北极海冰条件，进而对全球气候和海平面变化进行更准确的预测。</p>\n<h3 id=\"总结的前人研究\"><a href=\"#总结的前人研究\" class=\"headerlink\" title=\"总结的前人研究\"></a>总结的前人研究</h3><ul>\n<li>文章中提到了之前对海冰模型输出与观测数据进行比较的研究，例如Boe et al. (2009), Massonnet et al. (2012), Notz et al. (2020), Shu et al. (2015, 2020), Stroeve et al. (2007)。</li>\n<li>引用了关于海冰厚度和自由板高度之间关系的Alexanderrov et al. (2010)。</li>\n<li>讨论了Hibler (1980), Thorndike et al. (1975), Zhang &amp; Rothrock (2001)等人关于海冰动力学和热力学过程的早期研究。</li>\n</ul>\n<h3 id=\"不足之处\"><a href=\"#不足之处\" class=\"headerlink\" title=\"不足之处\"></a>不足之处</h3><ul>\n<li>之前的研究缺乏对模型中热力学和动力学海冰厚度效应独立与观测数据的比较。</li>\n<li>文章指出，现有模型在模拟海冰厚度方面存在偏差，特别是在中央北极和周边海域的基底热力学生长和剩余效应方面。</li>\n</ul>\n<h3 id=\"使用的数据\"><a href=\"#使用的数据\" class=\"headerlink\" title=\"使用的数据\"></a>使用的数据</h3><ul>\n<li>使用了AWI CS2SMOS海冰厚度观测数据集，该数据集结合了CryoSat-2和SMOS卫星的数据。</li>\n<li>使用了SLICE（Stefan’s Law Integrated Conducted Energy）方法来检索基底热力学生长并计算剩余过程效应。</li>\n<li>比较了NCAR社区地球系统模型2（CESM2）提交给OMIP2和PIOMAS的数据。</li>\n</ul>\n<h3 id=\"采用的方法\"><a href=\"#采用的方法\" class=\"headerlink\" title=\"采用的方法\"></a>采用的方法</h3><ul>\n<li>文章采用了一种基于过程的评估方法，通过比较观测估计和模型预测来评估海冰模型中的热力学和动力学过程。</li>\n<li>使用了差分插值将PIOMAS和CESM2-OMIP2数据集转换为25公里分辨率的EASE-Grid 2.0。</li>\n</ul>\n<h3 id=\"获得的结果\"><a href=\"#获得的结果\" class=\"headerlink\" title=\"获得的结果\"></a>获得的结果</h3><ul>\n<li>发现CESM2-OMIP2和PIOMAS在中央北极的基底热力学生长和剩余效应方面与观测估计相比存在相似的模式偏差。</li>\n<li>通过调整动态效应使其更接近观测估计，可以纠正平均厚度和基底热力学生长的偏差。</li>\n</ul>\n<h3 id=\"创新之处\"><a href=\"#创新之处\" class=\"headerlink\" title=\"创新之处\"></a>创新之处</h3><ul>\n<li>本研究是首次尝试将观测到的热力学海冰厚度生长和动态海冰厚度效应与全球气候模型和海冰模型再分析进行比较。</li>\n<li>引入SLICE方法，这是一种新的基于卫星数据的海冰厚度变化观测估计方法。</li>\n</ul>\n<h3 id=\"贡献\"><a href=\"#贡献\" class=\"headerlink\" title=\"贡献\"></a>贡献</h3><ul>\n<li>为改进海冰模型提供了观测数据支持，有助于提高模型预测的准确性。</li>\n<li>通过比较观测数据和模型输出，为理解影响海冰厚度的过程提供了新的见解。</li>\n</ul>\n<h3 id=\"不足\"><a href=\"#不足\" class=\"headerlink\" title=\"不足\"></a>不足</h3><ul>\n<li>文章指出，需要进一步调整模型中的动态组分参数化，以更准确地反映观测估计。</li>\n<li>对于模型中的热力学过程的表示可能需要进一步的改进，以更好地匹配观测数据。</li>\n</ul>"},{"title":"文献阅读（五）","abbrlink":"dadb1ecb","date":"2024-06-16T15:56:32.000Z","_content":"&emsp;&emsp;[A “Floatilla” of Airborne Seismometers for Venus](https://agupubs.onlinelibrary.wiley.com/doi/10.1029/2022GL100978?af=R)\n<!--less-->\n### 摘要\n\n在金星相对温和的云层中飘浮的高空气球上的气压计能够探测和表征由地震活动产生的声波，避免了进行地表地震学所需的高温电子设备的需求。Garcia等人（2022年，https://doi.org/10.1029/2022GL098844）最近展示了从距震中近3000公里的平流层气球探测到由7.3级和7.5级地震引起的低频声音（次声波）。他们仅使用其声学特征，初步展示了地震大小和位置的反演，以及S波和瑞利波速度的确定。大型地震产生的低频地震波能够穿透行星的内部；从高空优势点探测到的大陆尺度距离证明了基于气球的金星内部研究的可行性。我们将这些结果置于从气球上对金星进行地震学研究的努力中，讨论其局限性，并分享这一领域未解决研究问题的观点。\n\n### 重要性\n\n这篇文章探讨了金星内部结构研究的重要性，强调了通过研究行星内部结构来了解太阳系形成的过程。由于金星表面极端的高温和高压，传统的地震测量方法难以实施，因此探索新的地震监测手段对于理解金星的地质活动和内部结构至关重要。\n\n### 总结的前人研究\n\n- 文章提到了利用地震波研究地球、月球和火星内部结构的成功案例。\n- 引用了Lognonné和Johnson (2007) 对金星地震活动的估计。\n- 提到了Garcia等人 (2022) 在地球上通过平流层气球检测到远距离地震产生的次声波的研究。\n\n### 不足之处\n\n- 金星表面的极端条件使得长期地震记录难以实现，限制了对金星内部结构的了解。\n- 目前对金星地震活动的了解非常有限，缺乏直接的地震观测数据。\n\n### 使用的数据\n\n- 文章中使用了Garcia等人 (2022) 通过平流层气球收集的次声波数据，这些数据来自地球上的地震事件。\n\n### 采用的方法\n\n- 提出了在金星的相对温和的云层中使用高空气球进行地震监测的新方法。\n- 使用了数值模拟和数据分析技术来检测和表征由地震活动产生的次声波。\n\n### 获得的结果\n\n- 证明了通过气球平台在地球上检测到远距离地震产生的次声波是可行的，这为在金星上实施类似监测提供了概念验证。\n\n### 创新之处\n\n- 提出了一种新颖的金星地震监测方法，即使用高空气球来检测次声波，从而避免了在金星表面部署高温电子设备的需求。\n\n### 贡献\n\n- 为金星内部结构的研究提供了新的视角和可能的解决方案。\n- 对于未来金星探测任务的规划和设计具有指导意义。\n\n### 不足\n\n- 文章中提出的监测方法需要在金星上实际部署气球网络进行验证。\n- 对于如何在金星多变的大气环境中稳定运行气球网络，以及如何处理和解释收集到的数据，仍存在技术和科学上的挑战。\n","source":"_posts/2024-06-16-paper-reading-5.md","raw":"---\ntitle: 文献阅读（五）\ncategories:\n  - work\ntags:\n  - paper\nabbrlink: dadb1ecb\ndate: 2024-06-16 23:56:32\n---\n&emsp;&emsp;[A “Floatilla” of Airborne Seismometers for Venus](https://agupubs.onlinelibrary.wiley.com/doi/10.1029/2022GL100978?af=R)\n<!--less-->\n### 摘要\n\n在金星相对温和的云层中飘浮的高空气球上的气压计能够探测和表征由地震活动产生的声波，避免了进行地表地震学所需的高温电子设备的需求。Garcia等人（2022年，https://doi.org/10.1029/2022GL098844）最近展示了从距震中近3000公里的平流层气球探测到由7.3级和7.5级地震引起的低频声音（次声波）。他们仅使用其声学特征，初步展示了地震大小和位置的反演，以及S波和瑞利波速度的确定。大型地震产生的低频地震波能够穿透行星的内部；从高空优势点探测到的大陆尺度距离证明了基于气球的金星内部研究的可行性。我们将这些结果置于从气球上对金星进行地震学研究的努力中，讨论其局限性，并分享这一领域未解决研究问题的观点。\n\n### 重要性\n\n这篇文章探讨了金星内部结构研究的重要性，强调了通过研究行星内部结构来了解太阳系形成的过程。由于金星表面极端的高温和高压，传统的地震测量方法难以实施，因此探索新的地震监测手段对于理解金星的地质活动和内部结构至关重要。\n\n### 总结的前人研究\n\n- 文章提到了利用地震波研究地球、月球和火星内部结构的成功案例。\n- 引用了Lognonné和Johnson (2007) 对金星地震活动的估计。\n- 提到了Garcia等人 (2022) 在地球上通过平流层气球检测到远距离地震产生的次声波的研究。\n\n### 不足之处\n\n- 金星表面的极端条件使得长期地震记录难以实现，限制了对金星内部结构的了解。\n- 目前对金星地震活动的了解非常有限，缺乏直接的地震观测数据。\n\n### 使用的数据\n\n- 文章中使用了Garcia等人 (2022) 通过平流层气球收集的次声波数据，这些数据来自地球上的地震事件。\n\n### 采用的方法\n\n- 提出了在金星的相对温和的云层中使用高空气球进行地震监测的新方法。\n- 使用了数值模拟和数据分析技术来检测和表征由地震活动产生的次声波。\n\n### 获得的结果\n\n- 证明了通过气球平台在地球上检测到远距离地震产生的次声波是可行的，这为在金星上实施类似监测提供了概念验证。\n\n### 创新之处\n\n- 提出了一种新颖的金星地震监测方法，即使用高空气球来检测次声波，从而避免了在金星表面部署高温电子设备的需求。\n\n### 贡献\n\n- 为金星内部结构的研究提供了新的视角和可能的解决方案。\n- 对于未来金星探测任务的规划和设计具有指导意义。\n\n### 不足\n\n- 文章中提出的监测方法需要在金星上实际部署气球网络进行验证。\n- 对于如何在金星多变的大气环境中稳定运行气球网络，以及如何处理和解释收集到的数据，仍存在技术和科学上的挑战。\n","slug":"paper-reading-5","published":1,"updated":"2024-06-16T15:59:08.007Z","comments":1,"layout":"post","photos":[],"_id":"cmh498ips008bwvouel0uhxer","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><h3 id=\"摘要\"><a href=\"#摘要\" class=\"headerlink\" title=\"摘要\"></a>摘要</h3><p>在金星相对温和的云层中飘浮的高空气球上的气压计能够探测和表征由地震活动产生的声波，避免了进行地表地震学所需的高温电子设备的需求。Garcia等人（2022年，<a href=\"https://doi.org/10.1029/2022GL098844%EF%BC%89%E6%9C%80%E8%BF%91%E5%B1%95%E7%A4%BA%E4%BA%86%E4%BB%8E%E8%B7%9D%E9%9C%87%E4%B8%AD%E8%BF%913000%E5%85%AC%E9%87%8C%E7%9A%84%E5%B9%B3%E6%B5%81%E5%B1%82%E6%B0%94%E7%90%83%E6%8E%A2%E6%B5%8B%E5%88%B0%E7%94%B17.3%E7%BA%A7%E5%92%8C7.5%E7%BA%A7%E5%9C%B0%E9%9C%87%E5%BC%95%E8%B5%B7%E7%9A%84%E4%BD%8E%E9%A2%91%E5%A3%B0%E9%9F%B3%EF%BC%88%E6%AC%A1%E5%A3%B0%E6%B3%A2%EF%BC%89%E3%80%82%E4%BB%96%E4%BB%AC%E4%BB%85%E4%BD%BF%E7%94%A8%E5%85%B6%E5%A3%B0%E5%AD%A6%E7%89%B9%E5%BE%81%EF%BC%8C%E5%88%9D%E6%AD%A5%E5%B1%95%E7%A4%BA%E4%BA%86%E5%9C%B0%E9%9C%87%E5%A4%A7%E5%B0%8F%E5%92%8C%E4%BD%8D%E7%BD%AE%E7%9A%84%E5%8F%8D%E6%BC%94%EF%BC%8C%E4%BB%A5%E5%8F%8AS%E6%B3%A2%E5%92%8C%E7%91%9E%E5%88%A9%E6%B3%A2%E9%80%9F%E5%BA%A6%E7%9A%84%E7%A1%AE%E5%AE%9A%E3%80%82%E5%A4%A7%E5%9E%8B%E5%9C%B0%E9%9C%87%E4%BA%A7%E7%94%9F%E7%9A%84%E4%BD%8E%E9%A2%91%E5%9C%B0%E9%9C%87%E6%B3%A2%E8%83%BD%E5%A4%9F%E7%A9%BF%E9%80%8F%E8%A1%8C%E6%98%9F%E7%9A%84%E5%86%85%E9%83%A8%EF%BC%9B%E4%BB%8E%E9%AB%98%E7%A9%BA%E4%BC%98%E5%8A%BF%E7%82%B9%E6%8E%A2%E6%B5%8B%E5%88%B0%E7%9A%84%E5%A4%A7%E9%99%86%E5%B0%BA%E5%BA%A6%E8%B7%9D%E7%A6%BB%E8%AF%81%E6%98%8E%E4%BA%86%E5%9F%BA%E4%BA%8E%E6%B0%94%E7%90%83%E7%9A%84%E9%87%91%E6%98%9F%E5%86%85%E9%83%A8%E7%A0%94%E7%A9%B6%E7%9A%84%E5%8F%AF%E8%A1%8C%E6%80%A7%E3%80%82%E6%88%91%E4%BB%AC%E5%B0%86%E8%BF%99%E4%BA%9B%E7%BB%93%E6%9E%9C%E7%BD%AE%E4%BA%8E%E4%BB%8E%E6%B0%94%E7%90%83%E4%B8%8A%E5%AF%B9%E9%87%91%E6%98%9F%E8%BF%9B%E8%A1%8C%E5%9C%B0%E9%9C%87%E5%AD%A6%E7%A0%94%E7%A9%B6%E7%9A%84%E5%8A%AA%E5%8A%9B%E4%B8%AD%EF%BC%8C%E8%AE%A8%E8%AE%BA%E5%85%B6%E5%B1%80%E9%99%90%E6%80%A7%EF%BC%8C%E5%B9%B6%E5%88%86%E4%BA%AB%E8%BF%99%E4%B8%80%E9%A2%86%E5%9F%9F%E6%9C%AA%E8%A7%A3%E5%86%B3%E7%A0%94%E7%A9%B6%E9%97%AE%E9%A2%98%E7%9A%84%E8%A7%82%E7%82%B9%E3%80%82\">https://doi.org/10.1029/2022GL098844）最近展示了从距震中近3000公里的平流层气球探测到由7.3级和7.5级地震引起的低频声音（次声波）。他们仅使用其声学特征，初步展示了地震大小和位置的反演，以及S波和瑞利波速度的确定。大型地震产生的低频地震波能够穿透行星的内部；从高空优势点探测到的大陆尺度距离证明了基于气球的金星内部研究的可行性。我们将这些结果置于从气球上对金星进行地震学研究的努力中，讨论其局限性，并分享这一领域未解决研究问题的观点。</a></p>\n<h3 id=\"重要性\"><a href=\"#重要性\" class=\"headerlink\" title=\"重要性\"></a>重要性</h3><p>这篇文章探讨了金星内部结构研究的重要性，强调了通过研究行星内部结构来了解太阳系形成的过程。由于金星表面极端的高温和高压，传统的地震测量方法难以实施，因此探索新的地震监测手段对于理解金星的地质活动和内部结构至关重要。</p>\n<h3 id=\"总结的前人研究\"><a href=\"#总结的前人研究\" class=\"headerlink\" title=\"总结的前人研究\"></a>总结的前人研究</h3><ul>\n<li>文章提到了利用地震波研究地球、月球和火星内部结构的成功案例。</li>\n<li>引用了Lognonné和Johnson (2007) 对金星地震活动的估计。</li>\n<li>提到了Garcia等人 (2022) 在地球上通过平流层气球检测到远距离地震产生的次声波的研究。</li>\n</ul>\n<h3 id=\"不足之处\"><a href=\"#不足之处\" class=\"headerlink\" title=\"不足之处\"></a>不足之处</h3><ul>\n<li>金星表面的极端条件使得长期地震记录难以实现，限制了对金星内部结构的了解。</li>\n<li>目前对金星地震活动的了解非常有限，缺乏直接的地震观测数据。</li>\n</ul>\n<h3 id=\"使用的数据\"><a href=\"#使用的数据\" class=\"headerlink\" title=\"使用的数据\"></a>使用的数据</h3><ul>\n<li>文章中使用了Garcia等人 (2022) 通过平流层气球收集的次声波数据，这些数据来自地球上的地震事件。</li>\n</ul>\n<h3 id=\"采用的方法\"><a href=\"#采用的方法\" class=\"headerlink\" title=\"采用的方法\"></a>采用的方法</h3><ul>\n<li>提出了在金星的相对温和的云层中使用高空气球进行地震监测的新方法。</li>\n<li>使用了数值模拟和数据分析技术来检测和表征由地震活动产生的次声波。</li>\n</ul>\n<h3 id=\"获得的结果\"><a href=\"#获得的结果\" class=\"headerlink\" title=\"获得的结果\"></a>获得的结果</h3><ul>\n<li>证明了通过气球平台在地球上检测到远距离地震产生的次声波是可行的，这为在金星上实施类似监测提供了概念验证。</li>\n</ul>\n<h3 id=\"创新之处\"><a href=\"#创新之处\" class=\"headerlink\" title=\"创新之处\"></a>创新之处</h3><ul>\n<li>提出了一种新颖的金星地震监测方法，即使用高空气球来检测次声波，从而避免了在金星表面部署高温电子设备的需求。</li>\n</ul>\n<h3 id=\"贡献\"><a href=\"#贡献\" class=\"headerlink\" title=\"贡献\"></a>贡献</h3><ul>\n<li>为金星内部结构的研究提供了新的视角和可能的解决方案。</li>\n<li>对于未来金星探测任务的规划和设计具有指导意义。</li>\n</ul>\n<h3 id=\"不足\"><a href=\"#不足\" class=\"headerlink\" title=\"不足\"></a>不足</h3><ul>\n<li>文章中提出的监测方法需要在金星上实际部署气球网络进行验证。</li>\n<li>对于如何在金星多变的大气环境中稳定运行气球网络，以及如何处理和解释收集到的数据，仍存在技术和科学上的挑战。</li>\n</ul>","related_posts":["paper-reading-1.html","paper-reading-3.html"],"length":1045,"excerpt":"<p>&emsp;&emsp;<a href=\"https://agupubs.onlinelibrary.wiley.com/doi/10.1029/2022GL100978?af=R\">A “Floatilla” of Airborne Seismometers for Venus</a></p>","more":"<h3 id=\"摘要\"><a href=\"#摘要\" class=\"headerlink\" title=\"摘要\"></a>摘要</h3><p>在金星相对温和的云层中飘浮的高空气球上的气压计能够探测和表征由地震活动产生的声波，避免了进行地表地震学所需的高温电子设备的需求。Garcia等人（2022年，<a href=\"https://doi.org/10.1029/2022GL098844%EF%BC%89%E6%9C%80%E8%BF%91%E5%B1%95%E7%A4%BA%E4%BA%86%E4%BB%8E%E8%B7%9D%E9%9C%87%E4%B8%AD%E8%BF%913000%E5%85%AC%E9%87%8C%E7%9A%84%E5%B9%B3%E6%B5%81%E5%B1%82%E6%B0%94%E7%90%83%E6%8E%A2%E6%B5%8B%E5%88%B0%E7%94%B17.3%E7%BA%A7%E5%92%8C7.5%E7%BA%A7%E5%9C%B0%E9%9C%87%E5%BC%95%E8%B5%B7%E7%9A%84%E4%BD%8E%E9%A2%91%E5%A3%B0%E9%9F%B3%EF%BC%88%E6%AC%A1%E5%A3%B0%E6%B3%A2%EF%BC%89%E3%80%82%E4%BB%96%E4%BB%AC%E4%BB%85%E4%BD%BF%E7%94%A8%E5%85%B6%E5%A3%B0%E5%AD%A6%E7%89%B9%E5%BE%81%EF%BC%8C%E5%88%9D%E6%AD%A5%E5%B1%95%E7%A4%BA%E4%BA%86%E5%9C%B0%E9%9C%87%E5%A4%A7%E5%B0%8F%E5%92%8C%E4%BD%8D%E7%BD%AE%E7%9A%84%E5%8F%8D%E6%BC%94%EF%BC%8C%E4%BB%A5%E5%8F%8AS%E6%B3%A2%E5%92%8C%E7%91%9E%E5%88%A9%E6%B3%A2%E9%80%9F%E5%BA%A6%E7%9A%84%E7%A1%AE%E5%AE%9A%E3%80%82%E5%A4%A7%E5%9E%8B%E5%9C%B0%E9%9C%87%E4%BA%A7%E7%94%9F%E7%9A%84%E4%BD%8E%E9%A2%91%E5%9C%B0%E9%9C%87%E6%B3%A2%E8%83%BD%E5%A4%9F%E7%A9%BF%E9%80%8F%E8%A1%8C%E6%98%9F%E7%9A%84%E5%86%85%E9%83%A8%EF%BC%9B%E4%BB%8E%E9%AB%98%E7%A9%BA%E4%BC%98%E5%8A%BF%E7%82%B9%E6%8E%A2%E6%B5%8B%E5%88%B0%E7%9A%84%E5%A4%A7%E9%99%86%E5%B0%BA%E5%BA%A6%E8%B7%9D%E7%A6%BB%E8%AF%81%E6%98%8E%E4%BA%86%E5%9F%BA%E4%BA%8E%E6%B0%94%E7%90%83%E7%9A%84%E9%87%91%E6%98%9F%E5%86%85%E9%83%A8%E7%A0%94%E7%A9%B6%E7%9A%84%E5%8F%AF%E8%A1%8C%E6%80%A7%E3%80%82%E6%88%91%E4%BB%AC%E5%B0%86%E8%BF%99%E4%BA%9B%E7%BB%93%E6%9E%9C%E7%BD%AE%E4%BA%8E%E4%BB%8E%E6%B0%94%E7%90%83%E4%B8%8A%E5%AF%B9%E9%87%91%E6%98%9F%E8%BF%9B%E8%A1%8C%E5%9C%B0%E9%9C%87%E5%AD%A6%E7%A0%94%E7%A9%B6%E7%9A%84%E5%8A%AA%E5%8A%9B%E4%B8%AD%EF%BC%8C%E8%AE%A8%E8%AE%BA%E5%85%B6%E5%B1%80%E9%99%90%E6%80%A7%EF%BC%8C%E5%B9%B6%E5%88%86%E4%BA%AB%E8%BF%99%E4%B8%80%E9%A2%86%E5%9F%9F%E6%9C%AA%E8%A7%A3%E5%86%B3%E7%A0%94%E7%A9%B6%E9%97%AE%E9%A2%98%E7%9A%84%E8%A7%82%E7%82%B9%E3%80%82\">https://doi.org/10.1029/2022GL098844）最近展示了从距震中近3000公里的平流层气球探测到由7.3级和7.5级地震引起的低频声音（次声波）。他们仅使用其声学特征，初步展示了地震大小和位置的反演，以及S波和瑞利波速度的确定。大型地震产生的低频地震波能够穿透行星的内部；从高空优势点探测到的大陆尺度距离证明了基于气球的金星内部研究的可行性。我们将这些结果置于从气球上对金星进行地震学研究的努力中，讨论其局限性，并分享这一领域未解决研究问题的观点。</a></p>\n<h3 id=\"重要性\"><a href=\"#重要性\" class=\"headerlink\" title=\"重要性\"></a>重要性</h3><p>这篇文章探讨了金星内部结构研究的重要性，强调了通过研究行星内部结构来了解太阳系形成的过程。由于金星表面极端的高温和高压，传统的地震测量方法难以实施，因此探索新的地震监测手段对于理解金星的地质活动和内部结构至关重要。</p>\n<h3 id=\"总结的前人研究\"><a href=\"#总结的前人研究\" class=\"headerlink\" title=\"总结的前人研究\"></a>总结的前人研究</h3><ul>\n<li>文章提到了利用地震波研究地球、月球和火星内部结构的成功案例。</li>\n<li>引用了Lognonné和Johnson (2007) 对金星地震活动的估计。</li>\n<li>提到了Garcia等人 (2022) 在地球上通过平流层气球检测到远距离地震产生的次声波的研究。</li>\n</ul>\n<h3 id=\"不足之处\"><a href=\"#不足之处\" class=\"headerlink\" title=\"不足之处\"></a>不足之处</h3><ul>\n<li>金星表面的极端条件使得长期地震记录难以实现，限制了对金星内部结构的了解。</li>\n<li>目前对金星地震活动的了解非常有限，缺乏直接的地震观测数据。</li>\n</ul>\n<h3 id=\"使用的数据\"><a href=\"#使用的数据\" class=\"headerlink\" title=\"使用的数据\"></a>使用的数据</h3><ul>\n<li>文章中使用了Garcia等人 (2022) 通过平流层气球收集的次声波数据，这些数据来自地球上的地震事件。</li>\n</ul>\n<h3 id=\"采用的方法\"><a href=\"#采用的方法\" class=\"headerlink\" title=\"采用的方法\"></a>采用的方法</h3><ul>\n<li>提出了在金星的相对温和的云层中使用高空气球进行地震监测的新方法。</li>\n<li>使用了数值模拟和数据分析技术来检测和表征由地震活动产生的次声波。</li>\n</ul>\n<h3 id=\"获得的结果\"><a href=\"#获得的结果\" class=\"headerlink\" title=\"获得的结果\"></a>获得的结果</h3><ul>\n<li>证明了通过气球平台在地球上检测到远距离地震产生的次声波是可行的，这为在金星上实施类似监测提供了概念验证。</li>\n</ul>\n<h3 id=\"创新之处\"><a href=\"#创新之处\" class=\"headerlink\" title=\"创新之处\"></a>创新之处</h3><ul>\n<li>提出了一种新颖的金星地震监测方法，即使用高空气球来检测次声波，从而避免了在金星表面部署高温电子设备的需求。</li>\n</ul>\n<h3 id=\"贡献\"><a href=\"#贡献\" class=\"headerlink\" title=\"贡献\"></a>贡献</h3><ul>\n<li>为金星内部结构的研究提供了新的视角和可能的解决方案。</li>\n<li>对于未来金星探测任务的规划和设计具有指导意义。</li>\n</ul>\n<h3 id=\"不足\"><a href=\"#不足\" class=\"headerlink\" title=\"不足\"></a>不足</h3><ul>\n<li>文章中提出的监测方法需要在金星上实际部署气球网络进行验证。</li>\n<li>对于如何在金星多变的大气环境中稳定运行气球网络，以及如何处理和解释收集到的数据，仍存在技术和科学上的挑战。</li>\n</ul>"},{"title":"文献阅读（六）","abbrlink":"bfd55512","date":"2024-06-17T02:46:13.000Z","_content":"\n&emsp;&emsp;[Estimating the 3D structure of the Enceladus ice shell from Flexural and Crary waves using seismic simulations](https://www.sciencedirect.com/science/article/pii/S0012821X22006203?dgcid=rss_sd_all)\n<!--less-->\n### 摘要\n通过恢复相位和群速度以及表面波的频率内容，对土星的卫星土卫二进行地震调查可以确定冰壳的厚度以及与平均厚度的偏差。在这里，我们模拟了土卫二冰壳的均匀厚度分别为5公里、20公里和40公里，以及冰面地形变化在5-40公里范围内的情况。我们研究了几种恢复平均冰壳厚度的方法。我们展示了表面波色散可以用来确定平均冰壳厚度。只有在冰壳比临界值薄（小于20公里）时，才会出现冰中的挠曲波。只有在更厚的冰壳中，瑞利波才会占主导地位。Crary波的频率内容取决于冰壳的厚度。\n\n### 文章重要性\n\n这篇文章的重要性在于它提供了一种新的方法来估计土卫二冰壳的厚度，这对于了解其潜在的地下海洋环境和评估其宜居性至关重要。\n\n### 总结前人研究\n\n文章提到了之前的研究，例如：\n- Lee et al., 2003; Stähler et al., 2017; Maguire et al., 2021 等，这些研究集中于使用简单的一维模型。\n\n### 存在的不足\n\n文章并没有明确指出前人研究的不足，但指出了本研究的潜在局限性，例如：\n- 没有模拟背景噪声。\n- 假设冰壳没有孔隙性，这限制了散射效应的考量。\n\n### 使用的数据\n\n- 使用Cassini任务提供的数据来建立土卫二冰壳厚度的空间变化性。\n- 使用PlanetProfile软件生成土卫二内部结构模型。\n\n### 采用的方法\n\n- 构建了一维模型，模拟了不同均匀厚度的冰壳。\n- 使用Salvus软件创建合成波形。\n- 进行了时间序列分析和表面波色散分析。\n\n### 获得的结果\n\n- 表面波色散可以用来确定土卫二冰壳的平均厚度。\n- 挠曲波和瑞利波的存在与否可以指示冰壳的相对厚度。\n- Crary波的频率内容和群速度可以用来限制冰壳的厚度。\n\n### 创新之处\n\n- 采用三维模型和地震模拟来估计土卫二冰壳的厚度，这在以往的研究中较少见。\n- 考虑了冰壳厚度的变化性和冰壳地形的影响。\n\n### 贡献\n\n- 为土卫二等冰冷海洋世界的地质结构研究提供了新的视角和方法。\n- 为未来的土卫二着陆任务和地震探测提供了理论基础。\n\n### 存在的不足\n\n- 研究没有考虑背景噪声和其他可能影响地震信号的复杂因素。\n- 对于地震事件的定位和定时存在一定的假设，可能影响实际应用中的准确性。\n","source":"_posts/2024-06-17-paper-reading-6.md","raw":"---\ntitle: 文献阅读（六）\ncategories:\n  - work\ntags:\n  - paper\nabbrlink: bfd55512\ndate: 2024-06-17 10:46:13\n---\n\n&emsp;&emsp;[Estimating the 3D structure of the Enceladus ice shell from Flexural and Crary waves using seismic simulations](https://www.sciencedirect.com/science/article/pii/S0012821X22006203?dgcid=rss_sd_all)\n<!--less-->\n### 摘要\n通过恢复相位和群速度以及表面波的频率内容，对土星的卫星土卫二进行地震调查可以确定冰壳的厚度以及与平均厚度的偏差。在这里，我们模拟了土卫二冰壳的均匀厚度分别为5公里、20公里和40公里，以及冰面地形变化在5-40公里范围内的情况。我们研究了几种恢复平均冰壳厚度的方法。我们展示了表面波色散可以用来确定平均冰壳厚度。只有在冰壳比临界值薄（小于20公里）时，才会出现冰中的挠曲波。只有在更厚的冰壳中，瑞利波才会占主导地位。Crary波的频率内容取决于冰壳的厚度。\n\n### 文章重要性\n\n这篇文章的重要性在于它提供了一种新的方法来估计土卫二冰壳的厚度，这对于了解其潜在的地下海洋环境和评估其宜居性至关重要。\n\n### 总结前人研究\n\n文章提到了之前的研究，例如：\n- Lee et al., 2003; Stähler et al., 2017; Maguire et al., 2021 等，这些研究集中于使用简单的一维模型。\n\n### 存在的不足\n\n文章并没有明确指出前人研究的不足，但指出了本研究的潜在局限性，例如：\n- 没有模拟背景噪声。\n- 假设冰壳没有孔隙性，这限制了散射效应的考量。\n\n### 使用的数据\n\n- 使用Cassini任务提供的数据来建立土卫二冰壳厚度的空间变化性。\n- 使用PlanetProfile软件生成土卫二内部结构模型。\n\n### 采用的方法\n\n- 构建了一维模型，模拟了不同均匀厚度的冰壳。\n- 使用Salvus软件创建合成波形。\n- 进行了时间序列分析和表面波色散分析。\n\n### 获得的结果\n\n- 表面波色散可以用来确定土卫二冰壳的平均厚度。\n- 挠曲波和瑞利波的存在与否可以指示冰壳的相对厚度。\n- Crary波的频率内容和群速度可以用来限制冰壳的厚度。\n\n### 创新之处\n\n- 采用三维模型和地震模拟来估计土卫二冰壳的厚度，这在以往的研究中较少见。\n- 考虑了冰壳厚度的变化性和冰壳地形的影响。\n\n### 贡献\n\n- 为土卫二等冰冷海洋世界的地质结构研究提供了新的视角和方法。\n- 为未来的土卫二着陆任务和地震探测提供了理论基础。\n\n### 存在的不足\n\n- 研究没有考虑背景噪声和其他可能影响地震信号的复杂因素。\n- 对于地震事件的定位和定时存在一定的假设，可能影响实际应用中的准确性。\n","slug":"paper-reading-6","published":1,"updated":"2024-06-17T02:48:29.364Z","comments":1,"layout":"post","photos":[],"_id":"cmh498ipt008fwvou1bvg9k2b","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><h3 id=\"摘要\"><a href=\"#摘要\" class=\"headerlink\" title=\"摘要\"></a>摘要</h3><p>通过恢复相位和群速度以及表面波的频率内容，对土星的卫星土卫二进行地震调查可以确定冰壳的厚度以及与平均厚度的偏差。在这里，我们模拟了土卫二冰壳的均匀厚度分别为5公里、20公里和40公里，以及冰面地形变化在5-40公里范围内的情况。我们研究了几种恢复平均冰壳厚度的方法。我们展示了表面波色散可以用来确定平均冰壳厚度。只有在冰壳比临界值薄（小于20公里）时，才会出现冰中的挠曲波。只有在更厚的冰壳中，瑞利波才会占主导地位。Crary波的频率内容取决于冰壳的厚度。</p>\n<h3 id=\"文章重要性\"><a href=\"#文章重要性\" class=\"headerlink\" title=\"文章重要性\"></a>文章重要性</h3><p>这篇文章的重要性在于它提供了一种新的方法来估计土卫二冰壳的厚度，这对于了解其潜在的地下海洋环境和评估其宜居性至关重要。</p>\n<h3 id=\"总结前人研究\"><a href=\"#总结前人研究\" class=\"headerlink\" title=\"总结前人研究\"></a>总结前人研究</h3><p>文章提到了之前的研究，例如：</p>\n<ul>\n<li>Lee et al., 2003; Stähler et al., 2017; Maguire et al., 2021 等，这些研究集中于使用简单的一维模型。</li>\n</ul>\n<h3 id=\"存在的不足\"><a href=\"#存在的不足\" class=\"headerlink\" title=\"存在的不足\"></a>存在的不足</h3><p>文章并没有明确指出前人研究的不足，但指出了本研究的潜在局限性，例如：</p>\n<ul>\n<li>没有模拟背景噪声。</li>\n<li>假设冰壳没有孔隙性，这限制了散射效应的考量。</li>\n</ul>\n<h3 id=\"使用的数据\"><a href=\"#使用的数据\" class=\"headerlink\" title=\"使用的数据\"></a>使用的数据</h3><ul>\n<li>使用Cassini任务提供的数据来建立土卫二冰壳厚度的空间变化性。</li>\n<li>使用PlanetProfile软件生成土卫二内部结构模型。</li>\n</ul>\n<h3 id=\"采用的方法\"><a href=\"#采用的方法\" class=\"headerlink\" title=\"采用的方法\"></a>采用的方法</h3><ul>\n<li>构建了一维模型，模拟了不同均匀厚度的冰壳。</li>\n<li>使用Salvus软件创建合成波形。</li>\n<li>进行了时间序列分析和表面波色散分析。</li>\n</ul>\n<h3 id=\"获得的结果\"><a href=\"#获得的结果\" class=\"headerlink\" title=\"获得的结果\"></a>获得的结果</h3><ul>\n<li>表面波色散可以用来确定土卫二冰壳的平均厚度。</li>\n<li>挠曲波和瑞利波的存在与否可以指示冰壳的相对厚度。</li>\n<li>Crary波的频率内容和群速度可以用来限制冰壳的厚度。</li>\n</ul>\n<h3 id=\"创新之处\"><a href=\"#创新之处\" class=\"headerlink\" title=\"创新之处\"></a>创新之处</h3><ul>\n<li>采用三维模型和地震模拟来估计土卫二冰壳的厚度，这在以往的研究中较少见。</li>\n<li>考虑了冰壳厚度的变化性和冰壳地形的影响。</li>\n</ul>\n<h3 id=\"贡献\"><a href=\"#贡献\" class=\"headerlink\" title=\"贡献\"></a>贡献</h3><ul>\n<li>为土卫二等冰冷海洋世界的地质结构研究提供了新的视角和方法。</li>\n<li>为未来的土卫二着陆任务和地震探测提供了理论基础。</li>\n</ul>\n<h3 id=\"存在的不足-1\"><a href=\"#存在的不足-1\" class=\"headerlink\" title=\"存在的不足\"></a>存在的不足</h3><ul>\n<li>研究没有考虑背景噪声和其他可能影响地震信号的复杂因素。</li>\n<li>对于地震事件的定位和定时存在一定的假设，可能影响实际应用中的准确性。</li>\n</ul>","related_posts":["paper-reading-7.html"],"length":944,"excerpt":"<p>&emsp;&emsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0012821X22006203?dgcid=rss_sd_all\">Estimating the 3D structure of the Enceladus ice shell from Flexural and Crary waves using seismic simulations</a></p>","more":"<h3 id=\"摘要\"><a href=\"#摘要\" class=\"headerlink\" title=\"摘要\"></a>摘要</h3><p>通过恢复相位和群速度以及表面波的频率内容，对土星的卫星土卫二进行地震调查可以确定冰壳的厚度以及与平均厚度的偏差。在这里，我们模拟了土卫二冰壳的均匀厚度分别为5公里、20公里和40公里，以及冰面地形变化在5-40公里范围内的情况。我们研究了几种恢复平均冰壳厚度的方法。我们展示了表面波色散可以用来确定平均冰壳厚度。只有在冰壳比临界值薄（小于20公里）时，才会出现冰中的挠曲波。只有在更厚的冰壳中，瑞利波才会占主导地位。Crary波的频率内容取决于冰壳的厚度。</p>\n<h3 id=\"文章重要性\"><a href=\"#文章重要性\" class=\"headerlink\" title=\"文章重要性\"></a>文章重要性</h3><p>这篇文章的重要性在于它提供了一种新的方法来估计土卫二冰壳的厚度，这对于了解其潜在的地下海洋环境和评估其宜居性至关重要。</p>\n<h3 id=\"总结前人研究\"><a href=\"#总结前人研究\" class=\"headerlink\" title=\"总结前人研究\"></a>总结前人研究</h3><p>文章提到了之前的研究，例如：</p>\n<ul>\n<li>Lee et al., 2003; Stähler et al., 2017; Maguire et al., 2021 等，这些研究集中于使用简单的一维模型。</li>\n</ul>\n<h3 id=\"存在的不足\"><a href=\"#存在的不足\" class=\"headerlink\" title=\"存在的不足\"></a>存在的不足</h3><p>文章并没有明确指出前人研究的不足，但指出了本研究的潜在局限性，例如：</p>\n<ul>\n<li>没有模拟背景噪声。</li>\n<li>假设冰壳没有孔隙性，这限制了散射效应的考量。</li>\n</ul>\n<h3 id=\"使用的数据\"><a href=\"#使用的数据\" class=\"headerlink\" title=\"使用的数据\"></a>使用的数据</h3><ul>\n<li>使用Cassini任务提供的数据来建立土卫二冰壳厚度的空间变化性。</li>\n<li>使用PlanetProfile软件生成土卫二内部结构模型。</li>\n</ul>\n<h3 id=\"采用的方法\"><a href=\"#采用的方法\" class=\"headerlink\" title=\"采用的方法\"></a>采用的方法</h3><ul>\n<li>构建了一维模型，模拟了不同均匀厚度的冰壳。</li>\n<li>使用Salvus软件创建合成波形。</li>\n<li>进行了时间序列分析和表面波色散分析。</li>\n</ul>\n<h3 id=\"获得的结果\"><a href=\"#获得的结果\" class=\"headerlink\" title=\"获得的结果\"></a>获得的结果</h3><ul>\n<li>表面波色散可以用来确定土卫二冰壳的平均厚度。</li>\n<li>挠曲波和瑞利波的存在与否可以指示冰壳的相对厚度。</li>\n<li>Crary波的频率内容和群速度可以用来限制冰壳的厚度。</li>\n</ul>\n<h3 id=\"创新之处\"><a href=\"#创新之处\" class=\"headerlink\" title=\"创新之处\"></a>创新之处</h3><ul>\n<li>采用三维模型和地震模拟来估计土卫二冰壳的厚度，这在以往的研究中较少见。</li>\n<li>考虑了冰壳厚度的变化性和冰壳地形的影响。</li>\n</ul>\n<h3 id=\"贡献\"><a href=\"#贡献\" class=\"headerlink\" title=\"贡献\"></a>贡献</h3><ul>\n<li>为土卫二等冰冷海洋世界的地质结构研究提供了新的视角和方法。</li>\n<li>为未来的土卫二着陆任务和地震探测提供了理论基础。</li>\n</ul>\n<h3 id=\"存在的不足-1\"><a href=\"#存在的不足-1\" class=\"headerlink\" title=\"存在的不足\"></a>存在的不足</h3><ul>\n<li>研究没有考虑背景噪声和其他可能影响地震信号的复杂因素。</li>\n<li>对于地震事件的定位和定时存在一定的假设，可能影响实际应用中的准确性。</li>\n</ul>"},{"title":"如何审稿","abbrlink":"2ae6dad5","date":"2024-06-17T06:37:51.000Z","_content":"&emsp;&emsp;如何审稿。转自[jtleek](https://github.com/jtleek/reviews)。\n<!--less-->\n\n### 审阅学术论文\n\n如果你在学术圈混，你就得审论文。你的第一次审稿几乎可以肯定是你老板要你审的。随着你的职业生涯的发展，你会成为一个（或多个）领域的专家，你会审更多的论文。审论文是你应该严肃对待的，是你的职责。\n\n没有人给我写过正式的审稿指南，这可能对你来说可能也差不多。\n\n这篇文档目标是让你避免成为那个令人讨厌的审稿人，同时帮助你提高你的效率，免得你审稿时无从下手。\n\n### 同行评审中的关键角色\n\n在同行评审过程中有几个重要角色。\n\n首先是期刊的编辑，他会在最开始对论文进行一些审查——主要是筛选出提交的非常疯狂的东西（你会惊讶于看到了什么鬼东西）。通常，编辑是一位对学科领域有广泛了解的高级科学家，他们有很好的直觉，知道什么研究可能引起期刊读者群兴趣以及什么研究才是真正的科学。通常他们不感兴趣的论文或明显错误的论文会直接pass掉。\n\n编辑通常会将论文分配给一个对该论文相关主题有更多专业知识的副编辑。副编辑通常是中级教职员工（高级助理教授或副教授）。同样，明显有缺陷或提出荒谬观点的论文通常无法逃过副编辑的法眼。\n\n如果你的论文通过了这层关卡，并不意味着它是对的或是合理的。这只意味着编辑在快速过一遍时，论文看起来有趣且不离谱。然后副编辑会努力找到在论文相关特定领域工作且与论文作者没有强烈的冲突或有过合作过的审稿人。在某些领域，很难找到既没有冲突又有时间的审稿人。所以有时他们可能找到专业知识接近但与论文主题不完全一致的人。\n\n### 你在同行评审中的工作是什么？\n\n科学论文可以提炼为四个部分：\n\n1. 一套方法\n2. 数据描述\n3. 一系列结果\n4. 一系列观点\n\n当你写一篇论文时，目标是要清晰地传达以上的1-3项内容。在当前的同行评审系统中，作为同行评审者，你有三件事情要负责：\n\n1. 评估方法、数据和结果的质量和准确性。\n2. 确定方法、数据和结果是否支撑结论。\n3. 确定结论的重要性以及它们是否适合期刊。\n\n理想情况下，你能够验证论文中的每一个主张并测试每一个结果。考虑到审阅过程的时间限制，这几乎是不可能的。相反，你的目标是尽你所能获得对三个部分的合理估计。\n\n你关于1-3的初步认识得从假设开始，即你得认为作者是个正直（正常人）的人。他会努力做到正确、全面、透明，并且不会夸大其词。如果是个你从未听说过的期刊；或者如果你被要求审阅远远超出你专业知识范围的论文；又或者论文观点非常极端以至于它们可能会颠覆整个学科领域，那你就得调整你的先入为主的认识了。\n\n### 审稿的结构\n\n你的审稿需包含三个部分。对作者的评论、对编辑的意见以及建议。\n\n**对作者的评论**\n\n审稿意见第一部分包括对作者的评论，它包括以下部分：\n\n1. 用你自己的一段话总结论文（动机、方法、结果）。\n2. 主要问题列表\n3. 次要问题列表\n4. 一些别字列表\n\n总结至关重要，因为如果你不能将观点提炼出来，那么你就真的没有读懂该论文。总结绝对不应该是论文摘要的重述，你应该将你认为最相关的内容写总结中。\n\n主要问题应该整一个列表。根据论文的质量，这个列表可长可短。主要问题必须是以下情形之一：（1）数据不支持的结论，（2）看起来完全错误的方法或结果，（3）关键信息缺失，或者（4）论文可读性很差。你需要指出每一个问题对应的图表、段落或结果，并具体说明问题，批评需要有建设性要具体。如果可能，可以用文献来支持你的观点。\n\n没有提供所有数据和代码以及具体链接和说明，也是一个主要问题。\n\n次要问题也要给出一个列表。次要问题范围可能更广，例如模拟遗漏了一些案例，图表缺少轴标签，或者论文有一些与结论无关的多余结果。\n\n文字错误不是次要问题或主要问题，你没有义务去一一找出它们。如果你发现了文字错误，就以列表的形式提供给作者，格式为：“在第x页，第z行，将...改为...”。\n\n论文如果有很多文字错误，那么可以作为一个次要问题提出。如果论文完全无法阅读，那就是一个主要问题。完全无法阅读的意思是即使你忽略了所有的打字错误，你也无法理解论文。\n\n以下是你的评论中不应该包含的内容：\n\n- 推荐接受或拒绝论文\n- 要求引用你的很多论文\n- 要求进行不必要的实验/模拟以证明论文的主要观点\n- 侮辱性的批评或讽刺\n\n记住这是一个专业文件。它通常是匿名的（你不需要签名），但副编辑和编辑会看到你的审稿意见，你的声誉会受到你评审意见质量的影响。\n\n**对编辑的评论**\n\n如果你认为你在对作者的评论中已经涵盖了一切，你可以留白。如果你确实想写点啥，尽量不超过一段文字。不要写你没有在对作者的评论中提出的任何方法/结果的批评。你可以写你认为论文有多有趣以及它对期刊读者群有多合适。总之，该内容应该与对作者的评论一致。\n\n**建议**\n\n你通常有以下四种决定选项：\n\n1. 拒绝\n2. 大修\n3. 小修\n4. 接收\n\n如果你认为方法、结果或观点明显是错误的，请拒绝。如果你认为论文有重大缺陷无法纠正，请拒绝。如果论文显然不是对当前技术状态的改进，请拒绝。如果你没有该领域足够多经验，你最好咨询你的导师。\n\n如果你认为论文有严重问题但可以纠正，那就给大修意见。如果你要求进行大修，你就默认如果他们能够/确实纠正了你指出的所有主要问题，就接收。有时，在进行更正的过程中，你发现他们的方法/结果/结论是错的，那就拒绝。\n\n如果你认为论文很无趣，不要给反修意见；否则作者针对你的意见进行了仔细的修改，最后你还是拒掉。这样干就是jerk reviwer，混蛋审稿人。\n\n如果论文只有次要问题，你相信作者可以纠正，改正后你就准备接受，那么你就给个小修。\n\n直接接收论文是很少见的。有时候你会收到一篇只有次要问题的论文，这些问题只是你认为的小问题，而不是需要修正以证明观点或方法/结果/数据清晰的问题。在这种情况下，列出次要问题并建议接收是完全可以的。\n\n### 审稿的长度\n\n最好的审稿是要点突出、简洁、只指出关键问题。你绝对没有责任重写论文，改变论文的框架，或者让作者做一些原始工作范围之外的事情。如果你认为论文在当前形式下不适合该期刊，你应该解释/证明为什么，并选择拒绝。\n\n你完全没有必要通过写很长的意见来表明你仔细阅读了该论文，以凸显你是多么的专业。不要这样干，你不会因为挑剔、啰嗦或冗长而得到什么收益。\n\n反而你会因为以下事情而得到很大的好处：\n\n- 简洁 - 没有多余的东西\n- 精确 - 指出稿件的具体问题\n- 建设性 - 说明作者如何解决你发现的问题\n- 礼貌 - 这有助于关注真正的问题，而不是小问题\n\n好的审稿意见通常以要点格式控制在1-2页的长度。\n\n### 重新审阅\n\n除非论文被直接拒绝或接收，否则作者将有机会对你的评审做出回应。如果你遵循了上述建议，重新审阅过程会很简单：\n\n- 如果你选的是小修，作者解决了你的次要问题 - 接收。\n- 如果你选的是大修，作者解决了你指出的所有主要/次要问题 - 接收。\n- 如果你选的是大修，作者没有按照你的要求做 - 以未解决的问题为由给个大修。\n- 如果你选的是大修，作者的修订显示他们的方法不正确/无趣 - 拒绝。\n\n### 审阅应该花多长时间？\n\n如果你接受审稿，你应该在一个月内完成它。一般两周你就能搞定。如果预计无法在截止日期前完成，那就礼貌地拒绝，并推荐一些评审人。\n\n有时因为情况特殊，你在截止日期前可能无法完成审稿，那就申请延期。审稿是学术专业生活中的一个重要组成部分，但它不是你自己工作的优先事项，不要\"太当回事\"。\n\n不过，请记住，有人为了这篇论文付出了巨大的努力，他的饭碗就靠着这篇论文。如果你认为论文应该被拒绝那赶紧，如果你认为论文该被接收，那赶紧。\n","source":"_posts/2024-06-17-how-to-review.md","raw":"---\ntitle: 如何审稿\ncategories:\n  - work\ntags:\n  - review\nabbrlink: 2ae6dad5\ndate: 2024-06-17 14:37:51\n---\n&emsp;&emsp;如何审稿。转自[jtleek](https://github.com/jtleek/reviews)。\n<!--less-->\n\n### 审阅学术论文\n\n如果你在学术圈混，你就得审论文。你的第一次审稿几乎可以肯定是你老板要你审的。随着你的职业生涯的发展，你会成为一个（或多个）领域的专家，你会审更多的论文。审论文是你应该严肃对待的，是你的职责。\n\n没有人给我写过正式的审稿指南，这可能对你来说可能也差不多。\n\n这篇文档目标是让你避免成为那个令人讨厌的审稿人，同时帮助你提高你的效率，免得你审稿时无从下手。\n\n### 同行评审中的关键角色\n\n在同行评审过程中有几个重要角色。\n\n首先是期刊的编辑，他会在最开始对论文进行一些审查——主要是筛选出提交的非常疯狂的东西（你会惊讶于看到了什么鬼东西）。通常，编辑是一位对学科领域有广泛了解的高级科学家，他们有很好的直觉，知道什么研究可能引起期刊读者群兴趣以及什么研究才是真正的科学。通常他们不感兴趣的论文或明显错误的论文会直接pass掉。\n\n编辑通常会将论文分配给一个对该论文相关主题有更多专业知识的副编辑。副编辑通常是中级教职员工（高级助理教授或副教授）。同样，明显有缺陷或提出荒谬观点的论文通常无法逃过副编辑的法眼。\n\n如果你的论文通过了这层关卡，并不意味着它是对的或是合理的。这只意味着编辑在快速过一遍时，论文看起来有趣且不离谱。然后副编辑会努力找到在论文相关特定领域工作且与论文作者没有强烈的冲突或有过合作过的审稿人。在某些领域，很难找到既没有冲突又有时间的审稿人。所以有时他们可能找到专业知识接近但与论文主题不完全一致的人。\n\n### 你在同行评审中的工作是什么？\n\n科学论文可以提炼为四个部分：\n\n1. 一套方法\n2. 数据描述\n3. 一系列结果\n4. 一系列观点\n\n当你写一篇论文时，目标是要清晰地传达以上的1-3项内容。在当前的同行评审系统中，作为同行评审者，你有三件事情要负责：\n\n1. 评估方法、数据和结果的质量和准确性。\n2. 确定方法、数据和结果是否支撑结论。\n3. 确定结论的重要性以及它们是否适合期刊。\n\n理想情况下，你能够验证论文中的每一个主张并测试每一个结果。考虑到审阅过程的时间限制，这几乎是不可能的。相反，你的目标是尽你所能获得对三个部分的合理估计。\n\n你关于1-3的初步认识得从假设开始，即你得认为作者是个正直（正常人）的人。他会努力做到正确、全面、透明，并且不会夸大其词。如果是个你从未听说过的期刊；或者如果你被要求审阅远远超出你专业知识范围的论文；又或者论文观点非常极端以至于它们可能会颠覆整个学科领域，那你就得调整你的先入为主的认识了。\n\n### 审稿的结构\n\n你的审稿需包含三个部分。对作者的评论、对编辑的意见以及建议。\n\n**对作者的评论**\n\n审稿意见第一部分包括对作者的评论，它包括以下部分：\n\n1. 用你自己的一段话总结论文（动机、方法、结果）。\n2. 主要问题列表\n3. 次要问题列表\n4. 一些别字列表\n\n总结至关重要，因为如果你不能将观点提炼出来，那么你就真的没有读懂该论文。总结绝对不应该是论文摘要的重述，你应该将你认为最相关的内容写总结中。\n\n主要问题应该整一个列表。根据论文的质量，这个列表可长可短。主要问题必须是以下情形之一：（1）数据不支持的结论，（2）看起来完全错误的方法或结果，（3）关键信息缺失，或者（4）论文可读性很差。你需要指出每一个问题对应的图表、段落或结果，并具体说明问题，批评需要有建设性要具体。如果可能，可以用文献来支持你的观点。\n\n没有提供所有数据和代码以及具体链接和说明，也是一个主要问题。\n\n次要问题也要给出一个列表。次要问题范围可能更广，例如模拟遗漏了一些案例，图表缺少轴标签，或者论文有一些与结论无关的多余结果。\n\n文字错误不是次要问题或主要问题，你没有义务去一一找出它们。如果你发现了文字错误，就以列表的形式提供给作者，格式为：“在第x页，第z行，将...改为...”。\n\n论文如果有很多文字错误，那么可以作为一个次要问题提出。如果论文完全无法阅读，那就是一个主要问题。完全无法阅读的意思是即使你忽略了所有的打字错误，你也无法理解论文。\n\n以下是你的评论中不应该包含的内容：\n\n- 推荐接受或拒绝论文\n- 要求引用你的很多论文\n- 要求进行不必要的实验/模拟以证明论文的主要观点\n- 侮辱性的批评或讽刺\n\n记住这是一个专业文件。它通常是匿名的（你不需要签名），但副编辑和编辑会看到你的审稿意见，你的声誉会受到你评审意见质量的影响。\n\n**对编辑的评论**\n\n如果你认为你在对作者的评论中已经涵盖了一切，你可以留白。如果你确实想写点啥，尽量不超过一段文字。不要写你没有在对作者的评论中提出的任何方法/结果的批评。你可以写你认为论文有多有趣以及它对期刊读者群有多合适。总之，该内容应该与对作者的评论一致。\n\n**建议**\n\n你通常有以下四种决定选项：\n\n1. 拒绝\n2. 大修\n3. 小修\n4. 接收\n\n如果你认为方法、结果或观点明显是错误的，请拒绝。如果你认为论文有重大缺陷无法纠正，请拒绝。如果论文显然不是对当前技术状态的改进，请拒绝。如果你没有该领域足够多经验，你最好咨询你的导师。\n\n如果你认为论文有严重问题但可以纠正，那就给大修意见。如果你要求进行大修，你就默认如果他们能够/确实纠正了你指出的所有主要问题，就接收。有时，在进行更正的过程中，你发现他们的方法/结果/结论是错的，那就拒绝。\n\n如果你认为论文很无趣，不要给反修意见；否则作者针对你的意见进行了仔细的修改，最后你还是拒掉。这样干就是jerk reviwer，混蛋审稿人。\n\n如果论文只有次要问题，你相信作者可以纠正，改正后你就准备接受，那么你就给个小修。\n\n直接接收论文是很少见的。有时候你会收到一篇只有次要问题的论文，这些问题只是你认为的小问题，而不是需要修正以证明观点或方法/结果/数据清晰的问题。在这种情况下，列出次要问题并建议接收是完全可以的。\n\n### 审稿的长度\n\n最好的审稿是要点突出、简洁、只指出关键问题。你绝对没有责任重写论文，改变论文的框架，或者让作者做一些原始工作范围之外的事情。如果你认为论文在当前形式下不适合该期刊，你应该解释/证明为什么，并选择拒绝。\n\n你完全没有必要通过写很长的意见来表明你仔细阅读了该论文，以凸显你是多么的专业。不要这样干，你不会因为挑剔、啰嗦或冗长而得到什么收益。\n\n反而你会因为以下事情而得到很大的好处：\n\n- 简洁 - 没有多余的东西\n- 精确 - 指出稿件的具体问题\n- 建设性 - 说明作者如何解决你发现的问题\n- 礼貌 - 这有助于关注真正的问题，而不是小问题\n\n好的审稿意见通常以要点格式控制在1-2页的长度。\n\n### 重新审阅\n\n除非论文被直接拒绝或接收，否则作者将有机会对你的评审做出回应。如果你遵循了上述建议，重新审阅过程会很简单：\n\n- 如果你选的是小修，作者解决了你的次要问题 - 接收。\n- 如果你选的是大修，作者解决了你指出的所有主要/次要问题 - 接收。\n- 如果你选的是大修，作者没有按照你的要求做 - 以未解决的问题为由给个大修。\n- 如果你选的是大修，作者的修订显示他们的方法不正确/无趣 - 拒绝。\n\n### 审阅应该花多长时间？\n\n如果你接受审稿，你应该在一个月内完成它。一般两周你就能搞定。如果预计无法在截止日期前完成，那就礼貌地拒绝，并推荐一些评审人。\n\n有时因为情况特殊，你在截止日期前可能无法完成审稿，那就申请延期。审稿是学术专业生活中的一个重要组成部分，但它不是你自己工作的优先事项，不要\"太当回事\"。\n\n不过，请记住，有人为了这篇论文付出了巨大的努力，他的饭碗就靠着这篇论文。如果你认为论文应该被拒绝那赶紧，如果你认为论文该被接收，那赶紧。\n","slug":"how-to-review","published":1,"updated":"2024-06-18T02:19:44.538Z","comments":1,"layout":"post","photos":[],"_id":"cmh498ipt008iwvoub8hh2vwz","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><h3 id=\"审阅学术论文\"><a href=\"#审阅学术论文\" class=\"headerlink\" title=\"审阅学术论文\"></a>审阅学术论文</h3><p>如果你在学术圈混，你就得审论文。你的第一次审稿几乎可以肯定是你老板要你审的。随着你的职业生涯的发展，你会成为一个（或多个）领域的专家，你会审更多的论文。审论文是你应该严肃对待的，是你的职责。</p>\n<p>没有人给我写过正式的审稿指南，这可能对你来说可能也差不多。</p>\n<p>这篇文档目标是让你避免成为那个令人讨厌的审稿人，同时帮助你提高你的效率，免得你审稿时无从下手。</p>\n<h3 id=\"同行评审中的关键角色\"><a href=\"#同行评审中的关键角色\" class=\"headerlink\" title=\"同行评审中的关键角色\"></a>同行评审中的关键角色</h3><p>在同行评审过程中有几个重要角色。</p>\n<p>首先是期刊的编辑，他会在最开始对论文进行一些审查——主要是筛选出提交的非常疯狂的东西（你会惊讶于看到了什么鬼东西）。通常，编辑是一位对学科领域有广泛了解的高级科学家，他们有很好的直觉，知道什么研究可能引起期刊读者群兴趣以及什么研究才是真正的科学。通常他们不感兴趣的论文或明显错误的论文会直接pass掉。</p>\n<p>编辑通常会将论文分配给一个对该论文相关主题有更多专业知识的副编辑。副编辑通常是中级教职员工（高级助理教授或副教授）。同样，明显有缺陷或提出荒谬观点的论文通常无法逃过副编辑的法眼。</p>\n<p>如果你的论文通过了这层关卡，并不意味着它是对的或是合理的。这只意味着编辑在快速过一遍时，论文看起来有趣且不离谱。然后副编辑会努力找到在论文相关特定领域工作且与论文作者没有强烈的冲突或有过合作过的审稿人。在某些领域，很难找到既没有冲突又有时间的审稿人。所以有时他们可能找到专业知识接近但与论文主题不完全一致的人。</p>\n<h3 id=\"你在同行评审中的工作是什么？\"><a href=\"#你在同行评审中的工作是什么？\" class=\"headerlink\" title=\"你在同行评审中的工作是什么？\"></a>你在同行评审中的工作是什么？</h3><p>科学论文可以提炼为四个部分：</p>\n<ol>\n<li>一套方法</li>\n<li>数据描述</li>\n<li>一系列结果</li>\n<li>一系列观点</li>\n</ol>\n<p>当你写一篇论文时，目标是要清晰地传达以上的1-3项内容。在当前的同行评审系统中，作为同行评审者，你有三件事情要负责：</p>\n<ol>\n<li>评估方法、数据和结果的质量和准确性。</li>\n<li>确定方法、数据和结果是否支撑结论。</li>\n<li>确定结论的重要性以及它们是否适合期刊。</li>\n</ol>\n<p>理想情况下，你能够验证论文中的每一个主张并测试每一个结果。考虑到审阅过程的时间限制，这几乎是不可能的。相反，你的目标是尽你所能获得对三个部分的合理估计。</p>\n<p>你关于1-3的初步认识得从假设开始，即你得认为作者是个正直（正常人）的人。他会努力做到正确、全面、透明，并且不会夸大其词。如果是个你从未听说过的期刊；或者如果你被要求审阅远远超出你专业知识范围的论文；又或者论文观点非常极端以至于它们可能会颠覆整个学科领域，那你就得调整你的先入为主的认识了。</p>\n<h3 id=\"审稿的结构\"><a href=\"#审稿的结构\" class=\"headerlink\" title=\"审稿的结构\"></a>审稿的结构</h3><p>你的审稿需包含三个部分。对作者的评论、对编辑的意见以及建议。</p>\n<p><strong>对作者的评论</strong></p>\n<p>审稿意见第一部分包括对作者的评论，它包括以下部分：</p>\n<ol>\n<li>用你自己的一段话总结论文（动机、方法、结果）。</li>\n<li>主要问题列表</li>\n<li>次要问题列表</li>\n<li>一些别字列表</li>\n</ol>\n<p>总结至关重要，因为如果你不能将观点提炼出来，那么你就真的没有读懂该论文。总结绝对不应该是论文摘要的重述，你应该将你认为最相关的内容写总结中。</p>\n<p>主要问题应该整一个列表。根据论文的质量，这个列表可长可短。主要问题必须是以下情形之一：（1）数据不支持的结论，（2）看起来完全错误的方法或结果，（3）关键信息缺失，或者（4）论文可读性很差。你需要指出每一个问题对应的图表、段落或结果，并具体说明问题，批评需要有建设性要具体。如果可能，可以用文献来支持你的观点。</p>\n<p>没有提供所有数据和代码以及具体链接和说明，也是一个主要问题。</p>\n<p>次要问题也要给出一个列表。次要问题范围可能更广，例如模拟遗漏了一些案例，图表缺少轴标签，或者论文有一些与结论无关的多余结果。</p>\n<p>文字错误不是次要问题或主要问题，你没有义务去一一找出它们。如果你发现了文字错误，就以列表的形式提供给作者，格式为：“在第x页，第z行，将…改为…”。</p>\n<p>论文如果有很多文字错误，那么可以作为一个次要问题提出。如果论文完全无法阅读，那就是一个主要问题。完全无法阅读的意思是即使你忽略了所有的打字错误，你也无法理解论文。</p>\n<p>以下是你的评论中不应该包含的内容：</p>\n<ul>\n<li>推荐接受或拒绝论文</li>\n<li>要求引用你的很多论文</li>\n<li>要求进行不必要的实验&#x2F;模拟以证明论文的主要观点</li>\n<li>侮辱性的批评或讽刺</li>\n</ul>\n<p>记住这是一个专业文件。它通常是匿名的（你不需要签名），但副编辑和编辑会看到你的审稿意见，你的声誉会受到你评审意见质量的影响。</p>\n<p><strong>对编辑的评论</strong></p>\n<p>如果你认为你在对作者的评论中已经涵盖了一切，你可以留白。如果你确实想写点啥，尽量不超过一段文字。不要写你没有在对作者的评论中提出的任何方法&#x2F;结果的批评。你可以写你认为论文有多有趣以及它对期刊读者群有多合适。总之，该内容应该与对作者的评论一致。</p>\n<p><strong>建议</strong></p>\n<p>你通常有以下四种决定选项：</p>\n<ol>\n<li>拒绝</li>\n<li>大修</li>\n<li>小修</li>\n<li>接收</li>\n</ol>\n<p>如果你认为方法、结果或观点明显是错误的，请拒绝。如果你认为论文有重大缺陷无法纠正，请拒绝。如果论文显然不是对当前技术状态的改进，请拒绝。如果你没有该领域足够多经验，你最好咨询你的导师。</p>\n<p>如果你认为论文有严重问题但可以纠正，那就给大修意见。如果你要求进行大修，你就默认如果他们能够&#x2F;确实纠正了你指出的所有主要问题，就接收。有时，在进行更正的过程中，你发现他们的方法&#x2F;结果&#x2F;结论是错的，那就拒绝。</p>\n<p>如果你认为论文很无趣，不要给反修意见；否则作者针对你的意见进行了仔细的修改，最后你还是拒掉。这样干就是jerk reviwer，混蛋审稿人。</p>\n<p>如果论文只有次要问题，你相信作者可以纠正，改正后你就准备接受，那么你就给个小修。</p>\n<p>直接接收论文是很少见的。有时候你会收到一篇只有次要问题的论文，这些问题只是你认为的小问题，而不是需要修正以证明观点或方法&#x2F;结果&#x2F;数据清晰的问题。在这种情况下，列出次要问题并建议接收是完全可以的。</p>\n<h3 id=\"审稿的长度\"><a href=\"#审稿的长度\" class=\"headerlink\" title=\"审稿的长度\"></a>审稿的长度</h3><p>最好的审稿是要点突出、简洁、只指出关键问题。你绝对没有责任重写论文，改变论文的框架，或者让作者做一些原始工作范围之外的事情。如果你认为论文在当前形式下不适合该期刊，你应该解释&#x2F;证明为什么，并选择拒绝。</p>\n<p>你完全没有必要通过写很长的意见来表明你仔细阅读了该论文，以凸显你是多么的专业。不要这样干，你不会因为挑剔、啰嗦或冗长而得到什么收益。</p>\n<p>反而你会因为以下事情而得到很大的好处：</p>\n<ul>\n<li>简洁 - 没有多余的东西</li>\n<li>精确 - 指出稿件的具体问题</li>\n<li>建设性 - 说明作者如何解决你发现的问题</li>\n<li>礼貌 - 这有助于关注真正的问题，而不是小问题</li>\n</ul>\n<p>好的审稿意见通常以要点格式控制在1-2页的长度。</p>\n<h3 id=\"重新审阅\"><a href=\"#重新审阅\" class=\"headerlink\" title=\"重新审阅\"></a>重新审阅</h3><p>除非论文被直接拒绝或接收，否则作者将有机会对你的评审做出回应。如果你遵循了上述建议，重新审阅过程会很简单：</p>\n<ul>\n<li>如果你选的是小修，作者解决了你的次要问题 - 接收。</li>\n<li>如果你选的是大修，作者解决了你指出的所有主要&#x2F;次要问题 - 接收。</li>\n<li>如果你选的是大修，作者没有按照你的要求做 - 以未解决的问题为由给个大修。</li>\n<li>如果你选的是大修，作者的修订显示他们的方法不正确&#x2F;无趣 - 拒绝。</li>\n</ul>\n<h3 id=\"审阅应该花多长时间？\"><a href=\"#审阅应该花多长时间？\" class=\"headerlink\" title=\"审阅应该花多长时间？\"></a>审阅应该花多长时间？</h3><p>如果你接受审稿，你应该在一个月内完成它。一般两周你就能搞定。如果预计无法在截止日期前完成，那就礼貌地拒绝，并推荐一些评审人。</p>\n<p>有时因为情况特殊，你在截止日期前可能无法完成审稿，那就申请延期。审稿是学术专业生活中的一个重要组成部分，但它不是你自己工作的优先事项，不要”太当回事”。</p>\n<p>不过，请记住，有人为了这篇论文付出了巨大的努力，他的饭碗就靠着这篇论文。如果你认为论文应该被拒绝那赶紧，如果你认为论文该被接收，那赶紧。</p>","related_posts":[],"length":2982,"excerpt":"<p>&emsp;&emsp;如何审稿。转自<a href=\"https://github.com/jtleek/reviews\">jtleek</a>。</p>","more":"<h3 id=\"审阅学术论文\"><a href=\"#审阅学术论文\" class=\"headerlink\" title=\"审阅学术论文\"></a>审阅学术论文</h3><p>如果你在学术圈混，你就得审论文。你的第一次审稿几乎可以肯定是你老板要你审的。随着你的职业生涯的发展，你会成为一个（或多个）领域的专家，你会审更多的论文。审论文是你应该严肃对待的，是你的职责。</p>\n<p>没有人给我写过正式的审稿指南，这可能对你来说可能也差不多。</p>\n<p>这篇文档目标是让你避免成为那个令人讨厌的审稿人，同时帮助你提高你的效率，免得你审稿时无从下手。</p>\n<h3 id=\"同行评审中的关键角色\"><a href=\"#同行评审中的关键角色\" class=\"headerlink\" title=\"同行评审中的关键角色\"></a>同行评审中的关键角色</h3><p>在同行评审过程中有几个重要角色。</p>\n<p>首先是期刊的编辑，他会在最开始对论文进行一些审查——主要是筛选出提交的非常疯狂的东西（你会惊讶于看到了什么鬼东西）。通常，编辑是一位对学科领域有广泛了解的高级科学家，他们有很好的直觉，知道什么研究可能引起期刊读者群兴趣以及什么研究才是真正的科学。通常他们不感兴趣的论文或明显错误的论文会直接pass掉。</p>\n<p>编辑通常会将论文分配给一个对该论文相关主题有更多专业知识的副编辑。副编辑通常是中级教职员工（高级助理教授或副教授）。同样，明显有缺陷或提出荒谬观点的论文通常无法逃过副编辑的法眼。</p>\n<p>如果你的论文通过了这层关卡，并不意味着它是对的或是合理的。这只意味着编辑在快速过一遍时，论文看起来有趣且不离谱。然后副编辑会努力找到在论文相关特定领域工作且与论文作者没有强烈的冲突或有过合作过的审稿人。在某些领域，很难找到既没有冲突又有时间的审稿人。所以有时他们可能找到专业知识接近但与论文主题不完全一致的人。</p>\n<h3 id=\"你在同行评审中的工作是什么？\"><a href=\"#你在同行评审中的工作是什么？\" class=\"headerlink\" title=\"你在同行评审中的工作是什么？\"></a>你在同行评审中的工作是什么？</h3><p>科学论文可以提炼为四个部分：</p>\n<ol>\n<li>一套方法</li>\n<li>数据描述</li>\n<li>一系列结果</li>\n<li>一系列观点</li>\n</ol>\n<p>当你写一篇论文时，目标是要清晰地传达以上的1-3项内容。在当前的同行评审系统中，作为同行评审者，你有三件事情要负责：</p>\n<ol>\n<li>评估方法、数据和结果的质量和准确性。</li>\n<li>确定方法、数据和结果是否支撑结论。</li>\n<li>确定结论的重要性以及它们是否适合期刊。</li>\n</ol>\n<p>理想情况下，你能够验证论文中的每一个主张并测试每一个结果。考虑到审阅过程的时间限制，这几乎是不可能的。相反，你的目标是尽你所能获得对三个部分的合理估计。</p>\n<p>你关于1-3的初步认识得从假设开始，即你得认为作者是个正直（正常人）的人。他会努力做到正确、全面、透明，并且不会夸大其词。如果是个你从未听说过的期刊；或者如果你被要求审阅远远超出你专业知识范围的论文；又或者论文观点非常极端以至于它们可能会颠覆整个学科领域，那你就得调整你的先入为主的认识了。</p>\n<h3 id=\"审稿的结构\"><a href=\"#审稿的结构\" class=\"headerlink\" title=\"审稿的结构\"></a>审稿的结构</h3><p>你的审稿需包含三个部分。对作者的评论、对编辑的意见以及建议。</p>\n<p><strong>对作者的评论</strong></p>\n<p>审稿意见第一部分包括对作者的评论，它包括以下部分：</p>\n<ol>\n<li>用你自己的一段话总结论文（动机、方法、结果）。</li>\n<li>主要问题列表</li>\n<li>次要问题列表</li>\n<li>一些别字列表</li>\n</ol>\n<p>总结至关重要，因为如果你不能将观点提炼出来，那么你就真的没有读懂该论文。总结绝对不应该是论文摘要的重述，你应该将你认为最相关的内容写总结中。</p>\n<p>主要问题应该整一个列表。根据论文的质量，这个列表可长可短。主要问题必须是以下情形之一：（1）数据不支持的结论，（2）看起来完全错误的方法或结果，（3）关键信息缺失，或者（4）论文可读性很差。你需要指出每一个问题对应的图表、段落或结果，并具体说明问题，批评需要有建设性要具体。如果可能，可以用文献来支持你的观点。</p>\n<p>没有提供所有数据和代码以及具体链接和说明，也是一个主要问题。</p>\n<p>次要问题也要给出一个列表。次要问题范围可能更广，例如模拟遗漏了一些案例，图表缺少轴标签，或者论文有一些与结论无关的多余结果。</p>\n<p>文字错误不是次要问题或主要问题，你没有义务去一一找出它们。如果你发现了文字错误，就以列表的形式提供给作者，格式为：“在第x页，第z行，将…改为…”。</p>\n<p>论文如果有很多文字错误，那么可以作为一个次要问题提出。如果论文完全无法阅读，那就是一个主要问题。完全无法阅读的意思是即使你忽略了所有的打字错误，你也无法理解论文。</p>\n<p>以下是你的评论中不应该包含的内容：</p>\n<ul>\n<li>推荐接受或拒绝论文</li>\n<li>要求引用你的很多论文</li>\n<li>要求进行不必要的实验&#x2F;模拟以证明论文的主要观点</li>\n<li>侮辱性的批评或讽刺</li>\n</ul>\n<p>记住这是一个专业文件。它通常是匿名的（你不需要签名），但副编辑和编辑会看到你的审稿意见，你的声誉会受到你评审意见质量的影响。</p>\n<p><strong>对编辑的评论</strong></p>\n<p>如果你认为你在对作者的评论中已经涵盖了一切，你可以留白。如果你确实想写点啥，尽量不超过一段文字。不要写你没有在对作者的评论中提出的任何方法&#x2F;结果的批评。你可以写你认为论文有多有趣以及它对期刊读者群有多合适。总之，该内容应该与对作者的评论一致。</p>\n<p><strong>建议</strong></p>\n<p>你通常有以下四种决定选项：</p>\n<ol>\n<li>拒绝</li>\n<li>大修</li>\n<li>小修</li>\n<li>接收</li>\n</ol>\n<p>如果你认为方法、结果或观点明显是错误的，请拒绝。如果你认为论文有重大缺陷无法纠正，请拒绝。如果论文显然不是对当前技术状态的改进，请拒绝。如果你没有该领域足够多经验，你最好咨询你的导师。</p>\n<p>如果你认为论文有严重问题但可以纠正，那就给大修意见。如果你要求进行大修，你就默认如果他们能够&#x2F;确实纠正了你指出的所有主要问题，就接收。有时，在进行更正的过程中，你发现他们的方法&#x2F;结果&#x2F;结论是错的，那就拒绝。</p>\n<p>如果你认为论文很无趣，不要给反修意见；否则作者针对你的意见进行了仔细的修改，最后你还是拒掉。这样干就是jerk reviwer，混蛋审稿人。</p>\n<p>如果论文只有次要问题，你相信作者可以纠正，改正后你就准备接受，那么你就给个小修。</p>\n<p>直接接收论文是很少见的。有时候你会收到一篇只有次要问题的论文，这些问题只是你认为的小问题，而不是需要修正以证明观点或方法&#x2F;结果&#x2F;数据清晰的问题。在这种情况下，列出次要问题并建议接收是完全可以的。</p>\n<h3 id=\"审稿的长度\"><a href=\"#审稿的长度\" class=\"headerlink\" title=\"审稿的长度\"></a>审稿的长度</h3><p>最好的审稿是要点突出、简洁、只指出关键问题。你绝对没有责任重写论文，改变论文的框架，或者让作者做一些原始工作范围之外的事情。如果你认为论文在当前形式下不适合该期刊，你应该解释&#x2F;证明为什么，并选择拒绝。</p>\n<p>你完全没有必要通过写很长的意见来表明你仔细阅读了该论文，以凸显你是多么的专业。不要这样干，你不会因为挑剔、啰嗦或冗长而得到什么收益。</p>\n<p>反而你会因为以下事情而得到很大的好处：</p>\n<ul>\n<li>简洁 - 没有多余的东西</li>\n<li>精确 - 指出稿件的具体问题</li>\n<li>建设性 - 说明作者如何解决你发现的问题</li>\n<li>礼貌 - 这有助于关注真正的问题，而不是小问题</li>\n</ul>\n<p>好的审稿意见通常以要点格式控制在1-2页的长度。</p>\n<h3 id=\"重新审阅\"><a href=\"#重新审阅\" class=\"headerlink\" title=\"重新审阅\"></a>重新审阅</h3><p>除非论文被直接拒绝或接收，否则作者将有机会对你的评审做出回应。如果你遵循了上述建议，重新审阅过程会很简单：</p>\n<ul>\n<li>如果你选的是小修，作者解决了你的次要问题 - 接收。</li>\n<li>如果你选的是大修，作者解决了你指出的所有主要&#x2F;次要问题 - 接收。</li>\n<li>如果你选的是大修，作者没有按照你的要求做 - 以未解决的问题为由给个大修。</li>\n<li>如果你选的是大修，作者的修订显示他们的方法不正确&#x2F;无趣 - 拒绝。</li>\n</ul>\n<h3 id=\"审阅应该花多长时间？\"><a href=\"#审阅应该花多长时间？\" class=\"headerlink\" title=\"审阅应该花多长时间？\"></a>审阅应该花多长时间？</h3><p>如果你接受审稿，你应该在一个月内完成它。一般两周你就能搞定。如果预计无法在截止日期前完成，那就礼貌地拒绝，并推荐一些评审人。</p>\n<p>有时因为情况特殊，你在截止日期前可能无法完成审稿，那就申请延期。审稿是学术专业生活中的一个重要组成部分，但它不是你自己工作的优先事项，不要”太当回事”。</p>\n<p>不过，请记住，有人为了这篇论文付出了巨大的努力，他的饭碗就靠着这篇论文。如果你认为论文应该被拒绝那赶紧，如果你认为论文该被接收，那赶紧。</p>"},{"title":"文献阅读（七）","abbrlink":"6dd5228d","date":"2024-06-17T08:24:45.000Z","_content":"&emsp;&emsp;[Mapping Glacier Structure in Inaccessible Areas From Turning Seismic Sources Into a Dense Seismic Array](https://agupubs.onlinelibrary.wiley.com/doi/10.1029/2023GL108058?af=R)\n<!--less-->\n### 摘要\n\n&emsp;&emsp;了解冰川结构的异质性对于评估其命运至关重要。然而，结构变化强烈的地方，如裂缝场，通常无法直接进行仪器观测。为了克服这一限制，我们引入了一种创新技术，利用源-接收器空间互易原理，将由裂缝产生的地震源转化为虚拟接收器。我们展示了利用Seismic Michelson Interferometry（地震干涉测量学）技术，通过局部化良好的地震源之间的相位干涉模式来获取相位速度图。得到的相位速度对冰川结构的变化表现出敏感性，提供了对机械属性变化起源的洞见，并且空间分辨率比传统方法提高了五倍。特别是，我们观察到与严重受损的地下区域相关的相位速度的急剧变化，表明了一个复杂的三维介质。更系统地应用这种方法并在其他情境中使用将提高我们对冰川和其他地震发生环境结构的理解。\n\n### 文章重要性\n\n这篇文章的重要性在于提出了一种新的技术手段，可以在人迹罕至的地区，如冰川裂缝区域，通过地震干涉测量学来获取高分辨率的冰川结构图。\n\n### 总结前人研究\n\n文章总结了以下前人研究：\n- 被动地震方法在监测冰量变化、冰床界面变化和冰厚空间变化方面的应用。\n- 利用已知位置的脉冲源，通过Rayleigh表面波旅行时间延迟层析成像来揭示裂缝发生与地震相速度之间的非唯一关系。\n\n### 存在的不足\n\n文章指出的不足包括：\n- 使用噪声源进行地震成像时，确保方位等分性（azimuthal equipartitioning）的挑战。\n- 在采样波场方面的限制，尤其是在仪器部署区域之外。\n\n### 使用的数据\n\n- 法国阿尔卑斯山Argentière冰川消融区的地震事件目录，由98个三分量地震仪组成的阵列收集。\n\n### 采用的方法\n\n- 利用源-接收器空间互易原理将地震源转化为虚拟接收器。\n- 使用波形同步化和表面波衍射核（Diffraction Kernels, DKs）构建。\n- 采用地震干涉测量学（Seismic Michelson Interferometry, SMI）进行迭代反演。\n\n### 获得的结果\n\n- 获得了在空间分辨率上比传统方法高五倍的相位速度图。\n- 观察到与冰川厚度和裂缝存在相关的相位速度变化。\n\n### 创新之处\n\n- 利用地震源作为虚拟接收器，通过干涉模式来获取高分辨率的相位速度图。\n- 这种方法允许在没有直接测量设备的地区进行地震成像。\n\n### 贡献\n\n- 提供了一种新的技术手段，可以在传统方法难以到达的地区进行高分辨率的地震成像。\n- 为理解冰川结构和动态提供了新的视角。\n\n### 存在的不足\n\n文章中并未明确指出研究的不足之处，但可以推测可能的不足包括：\n- 技术的应用范围可能受限于地震源的分布和定位精度。\n- 对于非脉冲源或非冰川环境的适用性尚未得到验证。\n","source":"_posts/2024-06-17-paper-reading-7.md","raw":"---\ntitle: 文献阅读（七）\ncategories:\n  - work\ntags:\n  - paper\nabbrlink: 6dd5228d\ndate: 2024-06-17 16:24:45\n---\n&emsp;&emsp;[Mapping Glacier Structure in Inaccessible Areas From Turning Seismic Sources Into a Dense Seismic Array](https://agupubs.onlinelibrary.wiley.com/doi/10.1029/2023GL108058?af=R)\n<!--less-->\n### 摘要\n\n&emsp;&emsp;了解冰川结构的异质性对于评估其命运至关重要。然而，结构变化强烈的地方，如裂缝场，通常无法直接进行仪器观测。为了克服这一限制，我们引入了一种创新技术，利用源-接收器空间互易原理，将由裂缝产生的地震源转化为虚拟接收器。我们展示了利用Seismic Michelson Interferometry（地震干涉测量学）技术，通过局部化良好的地震源之间的相位干涉模式来获取相位速度图。得到的相位速度对冰川结构的变化表现出敏感性，提供了对机械属性变化起源的洞见，并且空间分辨率比传统方法提高了五倍。特别是，我们观察到与严重受损的地下区域相关的相位速度的急剧变化，表明了一个复杂的三维介质。更系统地应用这种方法并在其他情境中使用将提高我们对冰川和其他地震发生环境结构的理解。\n\n### 文章重要性\n\n这篇文章的重要性在于提出了一种新的技术手段，可以在人迹罕至的地区，如冰川裂缝区域，通过地震干涉测量学来获取高分辨率的冰川结构图。\n\n### 总结前人研究\n\n文章总结了以下前人研究：\n- 被动地震方法在监测冰量变化、冰床界面变化和冰厚空间变化方面的应用。\n- 利用已知位置的脉冲源，通过Rayleigh表面波旅行时间延迟层析成像来揭示裂缝发生与地震相速度之间的非唯一关系。\n\n### 存在的不足\n\n文章指出的不足包括：\n- 使用噪声源进行地震成像时，确保方位等分性（azimuthal equipartitioning）的挑战。\n- 在采样波场方面的限制，尤其是在仪器部署区域之外。\n\n### 使用的数据\n\n- 法国阿尔卑斯山Argentière冰川消融区的地震事件目录，由98个三分量地震仪组成的阵列收集。\n\n### 采用的方法\n\n- 利用源-接收器空间互易原理将地震源转化为虚拟接收器。\n- 使用波形同步化和表面波衍射核（Diffraction Kernels, DKs）构建。\n- 采用地震干涉测量学（Seismic Michelson Interferometry, SMI）进行迭代反演。\n\n### 获得的结果\n\n- 获得了在空间分辨率上比传统方法高五倍的相位速度图。\n- 观察到与冰川厚度和裂缝存在相关的相位速度变化。\n\n### 创新之处\n\n- 利用地震源作为虚拟接收器，通过干涉模式来获取高分辨率的相位速度图。\n- 这种方法允许在没有直接测量设备的地区进行地震成像。\n\n### 贡献\n\n- 提供了一种新的技术手段，可以在传统方法难以到达的地区进行高分辨率的地震成像。\n- 为理解冰川结构和动态提供了新的视角。\n\n### 存在的不足\n\n文章中并未明确指出研究的不足之处，但可以推测可能的不足包括：\n- 技术的应用范围可能受限于地震源的分布和定位精度。\n- 对于非脉冲源或非冰川环境的适用性尚未得到验证。\n","slug":"paper-reading-7","published":1,"updated":"2024-06-18T05:13:33.591Z","comments":1,"layout":"post","photos":[],"_id":"cmh498ipu008mwvoubh8w0a1l","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><h3 id=\"摘要\"><a href=\"#摘要\" class=\"headerlink\" title=\"摘要\"></a>摘要</h3><p>&emsp;&emsp;了解冰川结构的异质性对于评估其命运至关重要。然而，结构变化强烈的地方，如裂缝场，通常无法直接进行仪器观测。为了克服这一限制，我们引入了一种创新技术，利用源-接收器空间互易原理，将由裂缝产生的地震源转化为虚拟接收器。我们展示了利用Seismic Michelson Interferometry（地震干涉测量学）技术，通过局部化良好的地震源之间的相位干涉模式来获取相位速度图。得到的相位速度对冰川结构的变化表现出敏感性，提供了对机械属性变化起源的洞见，并且空间分辨率比传统方法提高了五倍。特别是，我们观察到与严重受损的地下区域相关的相位速度的急剧变化，表明了一个复杂的三维介质。更系统地应用这种方法并在其他情境中使用将提高我们对冰川和其他地震发生环境结构的理解。</p>\n<h3 id=\"文章重要性\"><a href=\"#文章重要性\" class=\"headerlink\" title=\"文章重要性\"></a>文章重要性</h3><p>这篇文章的重要性在于提出了一种新的技术手段，可以在人迹罕至的地区，如冰川裂缝区域，通过地震干涉测量学来获取高分辨率的冰川结构图。</p>\n<h3 id=\"总结前人研究\"><a href=\"#总结前人研究\" class=\"headerlink\" title=\"总结前人研究\"></a>总结前人研究</h3><p>文章总结了以下前人研究：</p>\n<ul>\n<li>被动地震方法在监测冰量变化、冰床界面变化和冰厚空间变化方面的应用。</li>\n<li>利用已知位置的脉冲源，通过Rayleigh表面波旅行时间延迟层析成像来揭示裂缝发生与地震相速度之间的非唯一关系。</li>\n</ul>\n<h3 id=\"存在的不足\"><a href=\"#存在的不足\" class=\"headerlink\" title=\"存在的不足\"></a>存在的不足</h3><p>文章指出的不足包括：</p>\n<ul>\n<li>使用噪声源进行地震成像时，确保方位等分性（azimuthal equipartitioning）的挑战。</li>\n<li>在采样波场方面的限制，尤其是在仪器部署区域之外。</li>\n</ul>\n<h3 id=\"使用的数据\"><a href=\"#使用的数据\" class=\"headerlink\" title=\"使用的数据\"></a>使用的数据</h3><ul>\n<li>法国阿尔卑斯山Argentière冰川消融区的地震事件目录，由98个三分量地震仪组成的阵列收集。</li>\n</ul>\n<h3 id=\"采用的方法\"><a href=\"#采用的方法\" class=\"headerlink\" title=\"采用的方法\"></a>采用的方法</h3><ul>\n<li>利用源-接收器空间互易原理将地震源转化为虚拟接收器。</li>\n<li>使用波形同步化和表面波衍射核（Diffraction Kernels, DKs）构建。</li>\n<li>采用地震干涉测量学（Seismic Michelson Interferometry, SMI）进行迭代反演。</li>\n</ul>\n<h3 id=\"获得的结果\"><a href=\"#获得的结果\" class=\"headerlink\" title=\"获得的结果\"></a>获得的结果</h3><ul>\n<li>获得了在空间分辨率上比传统方法高五倍的相位速度图。</li>\n<li>观察到与冰川厚度和裂缝存在相关的相位速度变化。</li>\n</ul>\n<h3 id=\"创新之处\"><a href=\"#创新之处\" class=\"headerlink\" title=\"创新之处\"></a>创新之处</h3><ul>\n<li>利用地震源作为虚拟接收器，通过干涉模式来获取高分辨率的相位速度图。</li>\n<li>这种方法允许在没有直接测量设备的地区进行地震成像。</li>\n</ul>\n<h3 id=\"贡献\"><a href=\"#贡献\" class=\"headerlink\" title=\"贡献\"></a>贡献</h3><ul>\n<li>提供了一种新的技术手段，可以在传统方法难以到达的地区进行高分辨率的地震成像。</li>\n<li>为理解冰川结构和动态提供了新的视角。</li>\n</ul>\n<h3 id=\"存在的不足-1\"><a href=\"#存在的不足-1\" class=\"headerlink\" title=\"存在的不足\"></a>存在的不足</h3><p>文章中并未明确指出研究的不足之处，但可以推测可能的不足包括：</p>\n<ul>\n<li>技术的应用范围可能受限于地震源的分布和定位精度。</li>\n<li>对于非脉冲源或非冰川环境的适用性尚未得到验证。</li>\n</ul>","related_posts":["paper-reading-6.html","code-and-project2.html","paper-reading-26.html"],"length":1141,"excerpt":"<p>&emsp;&emsp;<a href=\"https://agupubs.onlinelibrary.wiley.com/doi/10.1029/2023GL108058?af=R\">Mapping Glacier Structure in Inaccessible Areas From Turning Seismic Sources Into a Dense Seismic Array</a></p>","more":"<h3 id=\"摘要\"><a href=\"#摘要\" class=\"headerlink\" title=\"摘要\"></a>摘要</h3><p>&emsp;&emsp;了解冰川结构的异质性对于评估其命运至关重要。然而，结构变化强烈的地方，如裂缝场，通常无法直接进行仪器观测。为了克服这一限制，我们引入了一种创新技术，利用源-接收器空间互易原理，将由裂缝产生的地震源转化为虚拟接收器。我们展示了利用Seismic Michelson Interferometry（地震干涉测量学）技术，通过局部化良好的地震源之间的相位干涉模式来获取相位速度图。得到的相位速度对冰川结构的变化表现出敏感性，提供了对机械属性变化起源的洞见，并且空间分辨率比传统方法提高了五倍。特别是，我们观察到与严重受损的地下区域相关的相位速度的急剧变化，表明了一个复杂的三维介质。更系统地应用这种方法并在其他情境中使用将提高我们对冰川和其他地震发生环境结构的理解。</p>\n<h3 id=\"文章重要性\"><a href=\"#文章重要性\" class=\"headerlink\" title=\"文章重要性\"></a>文章重要性</h3><p>这篇文章的重要性在于提出了一种新的技术手段，可以在人迹罕至的地区，如冰川裂缝区域，通过地震干涉测量学来获取高分辨率的冰川结构图。</p>\n<h3 id=\"总结前人研究\"><a href=\"#总结前人研究\" class=\"headerlink\" title=\"总结前人研究\"></a>总结前人研究</h3><p>文章总结了以下前人研究：</p>\n<ul>\n<li>被动地震方法在监测冰量变化、冰床界面变化和冰厚空间变化方面的应用。</li>\n<li>利用已知位置的脉冲源，通过Rayleigh表面波旅行时间延迟层析成像来揭示裂缝发生与地震相速度之间的非唯一关系。</li>\n</ul>\n<h3 id=\"存在的不足\"><a href=\"#存在的不足\" class=\"headerlink\" title=\"存在的不足\"></a>存在的不足</h3><p>文章指出的不足包括：</p>\n<ul>\n<li>使用噪声源进行地震成像时，确保方位等分性（azimuthal equipartitioning）的挑战。</li>\n<li>在采样波场方面的限制，尤其是在仪器部署区域之外。</li>\n</ul>\n<h3 id=\"使用的数据\"><a href=\"#使用的数据\" class=\"headerlink\" title=\"使用的数据\"></a>使用的数据</h3><ul>\n<li>法国阿尔卑斯山Argentière冰川消融区的地震事件目录，由98个三分量地震仪组成的阵列收集。</li>\n</ul>\n<h3 id=\"采用的方法\"><a href=\"#采用的方法\" class=\"headerlink\" title=\"采用的方法\"></a>采用的方法</h3><ul>\n<li>利用源-接收器空间互易原理将地震源转化为虚拟接收器。</li>\n<li>使用波形同步化和表面波衍射核（Diffraction Kernels, DKs）构建。</li>\n<li>采用地震干涉测量学（Seismic Michelson Interferometry, SMI）进行迭代反演。</li>\n</ul>\n<h3 id=\"获得的结果\"><a href=\"#获得的结果\" class=\"headerlink\" title=\"获得的结果\"></a>获得的结果</h3><ul>\n<li>获得了在空间分辨率上比传统方法高五倍的相位速度图。</li>\n<li>观察到与冰川厚度和裂缝存在相关的相位速度变化。</li>\n</ul>\n<h3 id=\"创新之处\"><a href=\"#创新之处\" class=\"headerlink\" title=\"创新之处\"></a>创新之处</h3><ul>\n<li>利用地震源作为虚拟接收器，通过干涉模式来获取高分辨率的相位速度图。</li>\n<li>这种方法允许在没有直接测量设备的地区进行地震成像。</li>\n</ul>\n<h3 id=\"贡献\"><a href=\"#贡献\" class=\"headerlink\" title=\"贡献\"></a>贡献</h3><ul>\n<li>提供了一种新的技术手段，可以在传统方法难以到达的地区进行高分辨率的地震成像。</li>\n<li>为理解冰川结构和动态提供了新的视角。</li>\n</ul>\n<h3 id=\"存在的不足-1\"><a href=\"#存在的不足-1\" class=\"headerlink\" title=\"存在的不足\"></a>存在的不足</h3><p>文章中并未明确指出研究的不足之处，但可以推测可能的不足包括：</p>\n<ul>\n<li>技术的应用范围可能受限于地震源的分布和定位精度。</li>\n<li>对于非脉冲源或非冰川环境的适用性尚未得到验证。</li>\n</ul>"},{"title":"如何在HEXO中加入网络视频（以bilibili视频为例）","abbrlink":"c174d0ed","date":"2024-06-18T11:56:47.000Z","_content":"hexo里面怎么添加视频？\n<!--less-->\n只需要在日志里面加入这句话就可以了：\n```\n<div style=\"position: relative; width: 100%; height: 0; padding-bottom: 75%;\"> <iframe src=\"//player.bilibili.com/player.html?isOutside=true&aid=1754790640&bvid=BV1Kt421u7oB&cid=1553481822&p=1\" scrolling=\"no\" border=\"0\" frameborder=\"no\" framespacing=\"0\" allowfullscreen=\"true\"></iframe> </div>\n```\n其中\n```\n<iframe src=\"//player.bilibili.com/player.html?isOutside=true&aid=1754790640&bvid=BV1Kt421u7oB&cid=1553481822&p=1\" scrolling=\"no\" border=\"0\" frameborder=\"no\" framespacing=\"0\" allowfullscreen=\"true\"></iframe>\n```\n是从bilibili中点击复制链接->嵌入代码获得。\n\n这个视频是播主“愤怒的唐小虎”的关于大脑可塑性研究的讲述。侵删。大脑的可塑性是很强的，就像练肌肉一样。所以不要借口说我老了，学不来。只要你想，你去做，你都可以。\n<div style=\"position: relative; width: 100%; height: 0; padding-bottom: 75%;\"> <iframe src=\"//player.bilibili.com/player.html?isOutside=true&aid=1754790640&bvid=BV1Kt421u7oB&cid=1553481822&p=1\" scrolling=\"no\" border=\"0\" frameborder=\"no\" framespacing=\"0\" allowfullscreen=\"true\"></iframe> </div>\n","source":"_posts/2024-06-18-add-video.md","raw":"---\ntitle: 如何在HEXO中加入网络视频（以bilibili视频为例）\nabbrlink: c174d0ed\ndate: 2024-06-18 19:56:47\ncategories:\n  - web\ntags:\n  - hexo\n---\nhexo里面怎么添加视频？\n<!--less-->\n只需要在日志里面加入这句话就可以了：\n```\n<div style=\"position: relative; width: 100%; height: 0; padding-bottom: 75%;\"> <iframe src=\"//player.bilibili.com/player.html?isOutside=true&aid=1754790640&bvid=BV1Kt421u7oB&cid=1553481822&p=1\" scrolling=\"no\" border=\"0\" frameborder=\"no\" framespacing=\"0\" allowfullscreen=\"true\"></iframe> </div>\n```\n其中\n```\n<iframe src=\"//player.bilibili.com/player.html?isOutside=true&aid=1754790640&bvid=BV1Kt421u7oB&cid=1553481822&p=1\" scrolling=\"no\" border=\"0\" frameborder=\"no\" framespacing=\"0\" allowfullscreen=\"true\"></iframe>\n```\n是从bilibili中点击复制链接->嵌入代码获得。\n\n这个视频是播主“愤怒的唐小虎”的关于大脑可塑性研究的讲述。侵删。大脑的可塑性是很强的，就像练肌肉一样。所以不要借口说我老了，学不来。只要你想，你去做，你都可以。\n<div style=\"position: relative; width: 100%; height: 0; padding-bottom: 75%;\"> <iframe src=\"//player.bilibili.com/player.html?isOutside=true&aid=1754790640&bvid=BV1Kt421u7oB&cid=1553481822&p=1\" scrolling=\"no\" border=\"0\" frameborder=\"no\" framespacing=\"0\" allowfullscreen=\"true\"></iframe> </div>\n","slug":"add-video","published":1,"updated":"2024-06-18T12:42:09.317Z","comments":1,"layout":"post","photos":[],"_id":"cmh498ipu008pwvouhs8qbscr","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>只需要在日志里面加入这句话就可以了：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;div style=&quot;position: relative; width: 100%; height: 0; padding-bottom: 75%;&quot;&gt; &lt;iframe src=&quot;//player.bilibili.com/player.html?isOutside=true&amp;aid=1754790640&amp;bvid=BV1Kt421u7oB&amp;cid=1553481822&amp;p=1&quot; scrolling=&quot;no&quot; border=&quot;0&quot; frameborder=&quot;no&quot; framespacing=&quot;0&quot; allowfullscreen=&quot;true&quot;&gt;&lt;/iframe&gt; &lt;/div&gt;</span><br></pre></td></tr></table></figure>\n<p>其中</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;iframe src=&quot;//player.bilibili.com/player.html?isOutside=true&amp;aid=1754790640&amp;bvid=BV1Kt421u7oB&amp;cid=1553481822&amp;p=1&quot; scrolling=&quot;no&quot; border=&quot;0&quot; frameborder=&quot;no&quot; framespacing=&quot;0&quot; allowfullscreen=&quot;true&quot;&gt;&lt;/iframe&gt;</span><br></pre></td></tr></table></figure>\n<p>是从bilibili中点击复制链接-&gt;嵌入代码获得。</p>\n<p>这个视频是播主“愤怒的唐小虎”的关于大脑可塑性研究的讲述。侵删。大脑的可塑性是很强的，就像练肌肉一样。所以不要借口说我老了，学不来。只要你想，你去做，你都可以。</p>\n<div style=\"position: relative; width: 100%; height: 0; padding-bottom: 75%;\"> <iframe src=\"//player.bilibili.com/player.html?isOutside=true&aid=1754790640&bvid=BV1Kt421u7oB&cid=1553481822&p=1\" scrolling=\"no\" border=\"0\" frameborder=\"no\" framespacing=\"0\" allowfullscreen=\"true\"></iframe> </div>","related_posts":[],"length":820,"excerpt":"<p>hexo里面怎么添加视频？</p>","more":"<p>只需要在日志里面加入这句话就可以了：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;div style=&quot;position: relative; width: 100%; height: 0; padding-bottom: 75%;&quot;&gt; &lt;iframe src=&quot;//player.bilibili.com/player.html?isOutside=true&amp;aid=1754790640&amp;bvid=BV1Kt421u7oB&amp;cid=1553481822&amp;p=1&quot; scrolling=&quot;no&quot; border=&quot;0&quot; frameborder=&quot;no&quot; framespacing=&quot;0&quot; allowfullscreen=&quot;true&quot;&gt;&lt;/iframe&gt; &lt;/div&gt;</span><br></pre></td></tr></table></figure>\n<p>其中</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;iframe src=&quot;//player.bilibili.com/player.html?isOutside=true&amp;aid=1754790640&amp;bvid=BV1Kt421u7oB&amp;cid=1553481822&amp;p=1&quot; scrolling=&quot;no&quot; border=&quot;0&quot; frameborder=&quot;no&quot; framespacing=&quot;0&quot; allowfullscreen=&quot;true&quot;&gt;&lt;/iframe&gt;</span><br></pre></td></tr></table></figure>\n<p>是从bilibili中点击复制链接-&gt;嵌入代码获得。</p>\n<p>这个视频是播主“愤怒的唐小虎”的关于大脑可塑性研究的讲述。侵删。大脑的可塑性是很强的，就像练肌肉一样。所以不要借口说我老了，学不来。只要你想，你去做，你都可以。</p>\n<div style=\"position: relative; width: 100%; height: 0; padding-bottom: 75%;\"> <iframe src=\"//player.bilibili.com/player.html?isOutside=true&aid=1754790640&bvid=BV1Kt421u7oB&cid=1553481822&p=1\" scrolling=\"no\" border=\"0\" frameborder=\"no\" framespacing=\"0\" allowfullscreen=\"true\"></iframe> </div>"},{"title":"文献阅读（十）","abbrlink":"65410e55","date":"2024-06-18T12:52:37.000Z","_content":"\n&emsp;&emsp;[Nature of Low‐Frequency, Atmosphere‐Generated Seismic Noise](https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2020JB019423?af=R)\n<!--less-->\n\n### 摘要\n&emsp;&emsp;本文研究了当表面压力较大时，低于 0.05 Hz 的大气生成地震噪声的特征。在本文中，大气压力大意味着在 0.01 Hz 时压力功率谱密度超过 100 Pa²/Hz。本文讨论了三个要点：\n\n1. 存在两个频率范围，它们在共址的压力和垂直地震数据之间显示出高一致性。低频(LF)范围较宽，其上限约为 0.002 Hz。高频(HF)范围限制在大约 0.01 到 0.05 Hz 之间。压力和垂直位移之间的相位差在两个范围内是不同的。LF 范围显示出零的相位差，而 HF 范围显示出 180° 的相位差。\n\n2. 第二点是关于 HF 范围内的激励机制。利用理论和数据，我们展示了 HF 范围内的地震噪声主要是由风相关的压力激发的。当压力高时，风速变高，风向变得单一。在这种情况下，Sorrells (1971) 提出的确定性、移动的压力源模型比随机源模型更好地捕捉了数据的特征。\n\n3. 第三点是关于 LF 范围和 HF 范围之间相位差异的原因。即使在去除了仪器响应之后，垂直地震数据中也包含了重力和地球自转的影响。对于低于 0.005 Hz 的频率，重力效应变得显著，并在去卷积垂直位移和真实垂直地面位移之间造成了差异。相位差异的结果自然由它解释。\n\n### 相关研究的重要性\n\n- 地震噪声的低频特性对于理解地球内部结构和动力学过程至关重要。\n- 大气压力变化对地震信号的影响是地震监测和数据分析中不可忽视的因素。\n\n### 前人研究及不足\n\n- **Beauduin et al., 1996; De Angelis & Bodin, 2012; Herrin et al., 1969; Hutt et al., 2017; McDonald et al., 1971; Müller & Zürn, 1983; Savino et al., 1972; Sorrells, 1971; Sorrells et al., 1971; Sorrells & Goforth, 1973; Tsai et al., 2004; Warburton & Goodkind, 1977; Ziolkowski, 1973; Zürn & Widmer, 1995; Zürn et al., 2007** 等研究识别了一些重要特性，并提出了具体机制，如地球表面的压力加载效应和大气密度变化的引力吸引效应。\n  \n- 这些研究的不足包括对不同频率地震噪声的物理机制理解不足，以及对地震噪声与大气压力之间关系的复杂性认识有限。\n\n### 本文使用的数据和方法\n\n- **数据**: 使用了共址的压力和地震数据，以及风速和风向数据。\n- **方法**: 采用了频谱分析，理论推导和数据拟合，以及确定性和随机压力源模型的比较。\n\n### 本文结果\n\n- 发现了两个频率范围内压力和垂直地震数据之间的高一致性。\n- 确定了 HF 范围内地震噪声主要由风相关压力激发。\n- 揭示了 LF 和 HF 范围之间相位差异的原因是垂直地震数据包含了重力和地球自转的效应。\n\n### 本文创新之处和贡献\n\n- 明确区分了低频和高频地震噪声的不同物理机制。\n- 提供了一种新的理解大气压力如何影响地震数据的视角。\n- 通过理论分析和实际数据验证，改进了对地震噪声特性的理解。\n\n### 本文不足\n\n- 文章未明确指出其研究的局限性，但通常可能包括数据的代表性问题，模型的简化假设，以及对更广泛地区地震噪声特性的普适性考量。\n","source":"_posts/2024-06-18-paper-reading-10.md","raw":"---\ntitle: 文献阅读（十）\ncategories:\n  - work\ntags:\n  - paper\nabbrlink: '65410e55'\ndate: 2024-06-18 20:52:37\n---\n\n&emsp;&emsp;[Nature of Low‐Frequency, Atmosphere‐Generated Seismic Noise](https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2020JB019423?af=R)\n<!--less-->\n\n### 摘要\n&emsp;&emsp;本文研究了当表面压力较大时，低于 0.05 Hz 的大气生成地震噪声的特征。在本文中，大气压力大意味着在 0.01 Hz 时压力功率谱密度超过 100 Pa²/Hz。本文讨论了三个要点：\n\n1. 存在两个频率范围，它们在共址的压力和垂直地震数据之间显示出高一致性。低频(LF)范围较宽，其上限约为 0.002 Hz。高频(HF)范围限制在大约 0.01 到 0.05 Hz 之间。压力和垂直位移之间的相位差在两个范围内是不同的。LF 范围显示出零的相位差，而 HF 范围显示出 180° 的相位差。\n\n2. 第二点是关于 HF 范围内的激励机制。利用理论和数据，我们展示了 HF 范围内的地震噪声主要是由风相关的压力激发的。当压力高时，风速变高，风向变得单一。在这种情况下，Sorrells (1971) 提出的确定性、移动的压力源模型比随机源模型更好地捕捉了数据的特征。\n\n3. 第三点是关于 LF 范围和 HF 范围之间相位差异的原因。即使在去除了仪器响应之后，垂直地震数据中也包含了重力和地球自转的影响。对于低于 0.005 Hz 的频率，重力效应变得显著，并在去卷积垂直位移和真实垂直地面位移之间造成了差异。相位差异的结果自然由它解释。\n\n### 相关研究的重要性\n\n- 地震噪声的低频特性对于理解地球内部结构和动力学过程至关重要。\n- 大气压力变化对地震信号的影响是地震监测和数据分析中不可忽视的因素。\n\n### 前人研究及不足\n\n- **Beauduin et al., 1996; De Angelis & Bodin, 2012; Herrin et al., 1969; Hutt et al., 2017; McDonald et al., 1971; Müller & Zürn, 1983; Savino et al., 1972; Sorrells, 1971; Sorrells et al., 1971; Sorrells & Goforth, 1973; Tsai et al., 2004; Warburton & Goodkind, 1977; Ziolkowski, 1973; Zürn & Widmer, 1995; Zürn et al., 2007** 等研究识别了一些重要特性，并提出了具体机制，如地球表面的压力加载效应和大气密度变化的引力吸引效应。\n  \n- 这些研究的不足包括对不同频率地震噪声的物理机制理解不足，以及对地震噪声与大气压力之间关系的复杂性认识有限。\n\n### 本文使用的数据和方法\n\n- **数据**: 使用了共址的压力和地震数据，以及风速和风向数据。\n- **方法**: 采用了频谱分析，理论推导和数据拟合，以及确定性和随机压力源模型的比较。\n\n### 本文结果\n\n- 发现了两个频率范围内压力和垂直地震数据之间的高一致性。\n- 确定了 HF 范围内地震噪声主要由风相关压力激发。\n- 揭示了 LF 和 HF 范围之间相位差异的原因是垂直地震数据包含了重力和地球自转的效应。\n\n### 本文创新之处和贡献\n\n- 明确区分了低频和高频地震噪声的不同物理机制。\n- 提供了一种新的理解大气压力如何影响地震数据的视角。\n- 通过理论分析和实际数据验证，改进了对地震噪声特性的理解。\n\n### 本文不足\n\n- 文章未明确指出其研究的局限性，但通常可能包括数据的代表性问题，模型的简化假设，以及对更广泛地区地震噪声特性的普适性考量。\n","slug":"paper-reading-10","published":1,"updated":"2024-06-18T13:13:19.143Z","comments":1,"layout":"post","photos":[],"_id":"cmh498ipu008twvougtpyb6o6","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><h3 id=\"摘要\"><a href=\"#摘要\" class=\"headerlink\" title=\"摘要\"></a>摘要</h3><p>&emsp;&emsp;本文研究了当表面压力较大时，低于 0.05 Hz 的大气生成地震噪声的特征。在本文中，大气压力大意味着在 0.01 Hz 时压力功率谱密度超过 100 Pa²&#x2F;Hz。本文讨论了三个要点：</p>\n<ol>\n<li><p>存在两个频率范围，它们在共址的压力和垂直地震数据之间显示出高一致性。低频(LF)范围较宽，其上限约为 0.002 Hz。高频(HF)范围限制在大约 0.01 到 0.05 Hz 之间。压力和垂直位移之间的相位差在两个范围内是不同的。LF 范围显示出零的相位差，而 HF 范围显示出 180° 的相位差。</p>\n</li>\n<li><p>第二点是关于 HF 范围内的激励机制。利用理论和数据，我们展示了 HF 范围内的地震噪声主要是由风相关的压力激发的。当压力高时，风速变高，风向变得单一。在这种情况下，Sorrells (1971) 提出的确定性、移动的压力源模型比随机源模型更好地捕捉了数据的特征。</p>\n</li>\n<li><p>第三点是关于 LF 范围和 HF 范围之间相位差异的原因。即使在去除了仪器响应之后，垂直地震数据中也包含了重力和地球自转的影响。对于低于 0.005 Hz 的频率，重力效应变得显著，并在去卷积垂直位移和真实垂直地面位移之间造成了差异。相位差异的结果自然由它解释。</p>\n</li>\n</ol>\n<h3 id=\"相关研究的重要性\"><a href=\"#相关研究的重要性\" class=\"headerlink\" title=\"相关研究的重要性\"></a>相关研究的重要性</h3><ul>\n<li>地震噪声的低频特性对于理解地球内部结构和动力学过程至关重要。</li>\n<li>大气压力变化对地震信号的影响是地震监测和数据分析中不可忽视的因素。</li>\n</ul>\n<h3 id=\"前人研究及不足\"><a href=\"#前人研究及不足\" class=\"headerlink\" title=\"前人研究及不足\"></a>前人研究及不足</h3><ul>\n<li><p><strong>Beauduin et al., 1996; De Angelis &amp; Bodin, 2012; Herrin et al., 1969; Hutt et al., 2017; McDonald et al., 1971; Müller &amp; Zürn, 1983; Savino et al., 1972; Sorrells, 1971; Sorrells et al., 1971; Sorrells &amp; Goforth, 1973; Tsai et al., 2004; Warburton &amp; Goodkind, 1977; Ziolkowski, 1973; Zürn &amp; Widmer, 1995; Zürn et al., 2007</strong> 等研究识别了一些重要特性，并提出了具体机制，如地球表面的压力加载效应和大气密度变化的引力吸引效应。</p>\n</li>\n<li><p>这些研究的不足包括对不同频率地震噪声的物理机制理解不足，以及对地震噪声与大气压力之间关系的复杂性认识有限。</p>\n</li>\n</ul>\n<h3 id=\"本文使用的数据和方法\"><a href=\"#本文使用的数据和方法\" class=\"headerlink\" title=\"本文使用的数据和方法\"></a>本文使用的数据和方法</h3><ul>\n<li><strong>数据</strong>: 使用了共址的压力和地震数据，以及风速和风向数据。</li>\n<li><strong>方法</strong>: 采用了频谱分析，理论推导和数据拟合，以及确定性和随机压力源模型的比较。</li>\n</ul>\n<h3 id=\"本文结果\"><a href=\"#本文结果\" class=\"headerlink\" title=\"本文结果\"></a>本文结果</h3><ul>\n<li>发现了两个频率范围内压力和垂直地震数据之间的高一致性。</li>\n<li>确定了 HF 范围内地震噪声主要由风相关压力激发。</li>\n<li>揭示了 LF 和 HF 范围之间相位差异的原因是垂直地震数据包含了重力和地球自转的效应。</li>\n</ul>\n<h3 id=\"本文创新之处和贡献\"><a href=\"#本文创新之处和贡献\" class=\"headerlink\" title=\"本文创新之处和贡献\"></a>本文创新之处和贡献</h3><ul>\n<li>明确区分了低频和高频地震噪声的不同物理机制。</li>\n<li>提供了一种新的理解大气压力如何影响地震数据的视角。</li>\n<li>通过理论分析和实际数据验证，改进了对地震噪声特性的理解。</li>\n</ul>\n<h3 id=\"本文不足\"><a href=\"#本文不足\" class=\"headerlink\" title=\"本文不足\"></a>本文不足</h3><ul>\n<li>文章未明确指出其研究的局限性，但通常可能包括数据的代表性问题，模型的简化假设，以及对更广泛地区地震噪声特性的普适性考量。</li>\n</ul>","related_posts":[],"length":1342,"excerpt":"<p>&emsp;&emsp;<a href=\"https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2020JB019423?af=R\">Nature of Low‐Frequency, Atmosphere‐Generated Seismic Noise</a></p>","more":"<h3 id=\"摘要\"><a href=\"#摘要\" class=\"headerlink\" title=\"摘要\"></a>摘要</h3><p>&emsp;&emsp;本文研究了当表面压力较大时，低于 0.05 Hz 的大气生成地震噪声的特征。在本文中，大气压力大意味着在 0.01 Hz 时压力功率谱密度超过 100 Pa²&#x2F;Hz。本文讨论了三个要点：</p>\n<ol>\n<li><p>存在两个频率范围，它们在共址的压力和垂直地震数据之间显示出高一致性。低频(LF)范围较宽，其上限约为 0.002 Hz。高频(HF)范围限制在大约 0.01 到 0.05 Hz 之间。压力和垂直位移之间的相位差在两个范围内是不同的。LF 范围显示出零的相位差，而 HF 范围显示出 180° 的相位差。</p>\n</li>\n<li><p>第二点是关于 HF 范围内的激励机制。利用理论和数据，我们展示了 HF 范围内的地震噪声主要是由风相关的压力激发的。当压力高时，风速变高，风向变得单一。在这种情况下，Sorrells (1971) 提出的确定性、移动的压力源模型比随机源模型更好地捕捉了数据的特征。</p>\n</li>\n<li><p>第三点是关于 LF 范围和 HF 范围之间相位差异的原因。即使在去除了仪器响应之后，垂直地震数据中也包含了重力和地球自转的影响。对于低于 0.005 Hz 的频率，重力效应变得显著，并在去卷积垂直位移和真实垂直地面位移之间造成了差异。相位差异的结果自然由它解释。</p>\n</li>\n</ol>\n<h3 id=\"相关研究的重要性\"><a href=\"#相关研究的重要性\" class=\"headerlink\" title=\"相关研究的重要性\"></a>相关研究的重要性</h3><ul>\n<li>地震噪声的低频特性对于理解地球内部结构和动力学过程至关重要。</li>\n<li>大气压力变化对地震信号的影响是地震监测和数据分析中不可忽视的因素。</li>\n</ul>\n<h3 id=\"前人研究及不足\"><a href=\"#前人研究及不足\" class=\"headerlink\" title=\"前人研究及不足\"></a>前人研究及不足</h3><ul>\n<li><p><strong>Beauduin et al., 1996; De Angelis &amp; Bodin, 2012; Herrin et al., 1969; Hutt et al., 2017; McDonald et al., 1971; Müller &amp; Zürn, 1983; Savino et al., 1972; Sorrells, 1971; Sorrells et al., 1971; Sorrells &amp; Goforth, 1973; Tsai et al., 2004; Warburton &amp; Goodkind, 1977; Ziolkowski, 1973; Zürn &amp; Widmer, 1995; Zürn et al., 2007</strong> 等研究识别了一些重要特性，并提出了具体机制，如地球表面的压力加载效应和大气密度变化的引力吸引效应。</p>\n</li>\n<li><p>这些研究的不足包括对不同频率地震噪声的物理机制理解不足，以及对地震噪声与大气压力之间关系的复杂性认识有限。</p>\n</li>\n</ul>\n<h3 id=\"本文使用的数据和方法\"><a href=\"#本文使用的数据和方法\" class=\"headerlink\" title=\"本文使用的数据和方法\"></a>本文使用的数据和方法</h3><ul>\n<li><strong>数据</strong>: 使用了共址的压力和地震数据，以及风速和风向数据。</li>\n<li><strong>方法</strong>: 采用了频谱分析，理论推导和数据拟合，以及确定性和随机压力源模型的比较。</li>\n</ul>\n<h3 id=\"本文结果\"><a href=\"#本文结果\" class=\"headerlink\" title=\"本文结果\"></a>本文结果</h3><ul>\n<li>发现了两个频率范围内压力和垂直地震数据之间的高一致性。</li>\n<li>确定了 HF 范围内地震噪声主要由风相关压力激发。</li>\n<li>揭示了 LF 和 HF 范围之间相位差异的原因是垂直地震数据包含了重力和地球自转的效应。</li>\n</ul>\n<h3 id=\"本文创新之处和贡献\"><a href=\"#本文创新之处和贡献\" class=\"headerlink\" title=\"本文创新之处和贡献\"></a>本文创新之处和贡献</h3><ul>\n<li>明确区分了低频和高频地震噪声的不同物理机制。</li>\n<li>提供了一种新的理解大气压力如何影响地震数据的视角。</li>\n<li>通过理论分析和实际数据验证，改进了对地震噪声特性的理解。</li>\n</ul>\n<h3 id=\"本文不足\"><a href=\"#本文不足\" class=\"headerlink\" title=\"本文不足\"></a>本文不足</h3><ul>\n<li>文章未明确指出其研究的局限性，但通常可能包括数据的代表性问题，模型的简化假设，以及对更广泛地区地震噪声特性的普适性考量。</li>\n</ul>"},{"title":"文献阅读（八）","abbrlink":"9abe0ace","date":"2024-06-18T05:10:10.000Z","_content":"&emsp;&emsp;[Far-Field Groundwater Response to the Lamb Waves From the 2022 Hunga-Tonga Volcano Eruption](https://agupubs.onlinelibrary.wiley.com/doi/10.1029/2023GL107442?af=R)\n<!--less-->\n\n### 摘要\n&emsp;&emsp;2022年1月15日，汤加火山发生了史上最大的喷发事件，产生了被全球多参数仪器记录的羽流。然而，这次喷发产生的Lamb波对远场水文地质的响应尚未被充分研究。我们研究了远场超过8700公里范围内的地下水对火山喷发的响应，包括274个井。结果表明，速度为316米/秒的Lamb波影响了地下水系统，导致井水位（WL）出现类似波动，钻孔应变出现相反相位的波动。不同井在WL幅度上表现出不同的响应，可能由于当地含水层系统的异质性。同时测量大气压力、钻孔空气压力、钻孔应变和WL的5个井的增益值与通过交叉功率谱估计得到的结果一致。这项工作展示了Lamb波在远场地下水系统中诱导的一种新响应，并期望应用于含水层参数估计。\n### 研究的重要性\n- 水文地质响应的探索：了解Lamb波如何影响远场地下水系统对于评估火山活动对地下水资源的潜在影响至关重要。\n- 灾害预警和管理：通过监测地下水位的变化，可以为火山喷发等自然灾害提供预警和管理策略。\n\n### 前人研究及不足\n\n- **Briggs et al., 2022; D’Arcangelo et al., 2022; Poli & Shapiro, 2022**：研究了洪阿汤加火山喷发对大气、海啸等的影响。\n- **Jia & Minnett, 2023; Lynett et al., 2022; Ravanelli et al., 2023; Tonegawa & Fukao, 2023**：研究了Lamb波对海洋的影响。\n- **不足**：现有研究主要集中在直接的地质和大气效应上，对远场地下水系统的响应研究不足。\n\n### 使用的数据\n\n- 中国大陆274个井下观测数据，包括气象站的大气压力、钻孔内的空气压力、水位和钻孔应变。\n\n### 采用的方法\n\n- **小波功率谱方法**：展示水位响应特征。\n- **交叉功率谱方法**：估计增益值。\n\n### 获得的结果\n\n- Lamb波以约316米/秒的速度影响地下水系统。\n- 井水位和钻孔应变出现类似波动和相反相位波动。\n- 观测到可能的时间滞后，可能由不同水力特性的井所致。\n\n### 本文创新之处\n\n- **新的响应类型**：首次研究了Lamb波对远场地下水系统的新影响。\n- **增益值的一致性**：发现同时测量的大气压力、钻孔空气压力、钻孔应变和WL的增益值与通过交叉功率谱估计得到的结果一致。\n\n### 本文贡献\n\n- 为理解火山活动对远场地下水系统的影响提供了新的视角。\n- 为含水层参数估计提供了一种可能的新方法。\n\n### 本文不足\n\n文章未明确指出研究的不足之处，但可能包括：\n- 数据可能受限于井的分布和观测条件。\n- 对Lamb波影响地下水系统的详细机制需要进一步研究。\n","source":"_posts/2024-06-18-paper-reading-8.md","raw":"---\ntitle: 文献阅读（八）\ncategories:\n  - work\ntags:\n  - paper\nabbrlink: 9abe0ace\ndate: 2024-06-18 13:10:10\n---\n&emsp;&emsp;[Far-Field Groundwater Response to the Lamb Waves From the 2022 Hunga-Tonga Volcano Eruption](https://agupubs.onlinelibrary.wiley.com/doi/10.1029/2023GL107442?af=R)\n<!--less-->\n\n### 摘要\n&emsp;&emsp;2022年1月15日，汤加火山发生了史上最大的喷发事件，产生了被全球多参数仪器记录的羽流。然而，这次喷发产生的Lamb波对远场水文地质的响应尚未被充分研究。我们研究了远场超过8700公里范围内的地下水对火山喷发的响应，包括274个井。结果表明，速度为316米/秒的Lamb波影响了地下水系统，导致井水位（WL）出现类似波动，钻孔应变出现相反相位的波动。不同井在WL幅度上表现出不同的响应，可能由于当地含水层系统的异质性。同时测量大气压力、钻孔空气压力、钻孔应变和WL的5个井的增益值与通过交叉功率谱估计得到的结果一致。这项工作展示了Lamb波在远场地下水系统中诱导的一种新响应，并期望应用于含水层参数估计。\n### 研究的重要性\n- 水文地质响应的探索：了解Lamb波如何影响远场地下水系统对于评估火山活动对地下水资源的潜在影响至关重要。\n- 灾害预警和管理：通过监测地下水位的变化，可以为火山喷发等自然灾害提供预警和管理策略。\n\n### 前人研究及不足\n\n- **Briggs et al., 2022; D’Arcangelo et al., 2022; Poli & Shapiro, 2022**：研究了洪阿汤加火山喷发对大气、海啸等的影响。\n- **Jia & Minnett, 2023; Lynett et al., 2022; Ravanelli et al., 2023; Tonegawa & Fukao, 2023**：研究了Lamb波对海洋的影响。\n- **不足**：现有研究主要集中在直接的地质和大气效应上，对远场地下水系统的响应研究不足。\n\n### 使用的数据\n\n- 中国大陆274个井下观测数据，包括气象站的大气压力、钻孔内的空气压力、水位和钻孔应变。\n\n### 采用的方法\n\n- **小波功率谱方法**：展示水位响应特征。\n- **交叉功率谱方法**：估计增益值。\n\n### 获得的结果\n\n- Lamb波以约316米/秒的速度影响地下水系统。\n- 井水位和钻孔应变出现类似波动和相反相位波动。\n- 观测到可能的时间滞后，可能由不同水力特性的井所致。\n\n### 本文创新之处\n\n- **新的响应类型**：首次研究了Lamb波对远场地下水系统的新影响。\n- **增益值的一致性**：发现同时测量的大气压力、钻孔空气压力、钻孔应变和WL的增益值与通过交叉功率谱估计得到的结果一致。\n\n### 本文贡献\n\n- 为理解火山活动对远场地下水系统的影响提供了新的视角。\n- 为含水层参数估计提供了一种可能的新方法。\n\n### 本文不足\n\n文章未明确指出研究的不足之处，但可能包括：\n- 数据可能受限于井的分布和观测条件。\n- 对Lamb波影响地下水系统的详细机制需要进一步研究。\n","slug":"paper-reading-8","published":1,"updated":"2024-06-18T05:15:49.799Z","comments":1,"layout":"post","photos":[],"_id":"cmh498ipv008wwvoubrk97maz","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><h3 id=\"摘要\"><a href=\"#摘要\" class=\"headerlink\" title=\"摘要\"></a>摘要</h3><p>&emsp;&emsp;2022年1月15日，汤加火山发生了史上最大的喷发事件，产生了被全球多参数仪器记录的羽流。然而，这次喷发产生的Lamb波对远场水文地质的响应尚未被充分研究。我们研究了远场超过8700公里范围内的地下水对火山喷发的响应，包括274个井。结果表明，速度为316米&#x2F;秒的Lamb波影响了地下水系统，导致井水位（WL）出现类似波动，钻孔应变出现相反相位的波动。不同井在WL幅度上表现出不同的响应，可能由于当地含水层系统的异质性。同时测量大气压力、钻孔空气压力、钻孔应变和WL的5个井的增益值与通过交叉功率谱估计得到的结果一致。这项工作展示了Lamb波在远场地下水系统中诱导的一种新响应，并期望应用于含水层参数估计。</p>\n<h3 id=\"研究的重要性\"><a href=\"#研究的重要性\" class=\"headerlink\" title=\"研究的重要性\"></a>研究的重要性</h3><ul>\n<li>水文地质响应的探索：了解Lamb波如何影响远场地下水系统对于评估火山活动对地下水资源的潜在影响至关重要。</li>\n<li>灾害预警和管理：通过监测地下水位的变化，可以为火山喷发等自然灾害提供预警和管理策略。</li>\n</ul>\n<h3 id=\"前人研究及不足\"><a href=\"#前人研究及不足\" class=\"headerlink\" title=\"前人研究及不足\"></a>前人研究及不足</h3><ul>\n<li><strong>Briggs et al., 2022; D’Arcangelo et al., 2022; Poli &amp; Shapiro, 2022</strong>：研究了洪阿汤加火山喷发对大气、海啸等的影响。</li>\n<li><strong>Jia &amp; Minnett, 2023; Lynett et al., 2022; Ravanelli et al., 2023; Tonegawa &amp; Fukao, 2023</strong>：研究了Lamb波对海洋的影响。</li>\n<li><strong>不足</strong>：现有研究主要集中在直接的地质和大气效应上，对远场地下水系统的响应研究不足。</li>\n</ul>\n<h3 id=\"使用的数据\"><a href=\"#使用的数据\" class=\"headerlink\" title=\"使用的数据\"></a>使用的数据</h3><ul>\n<li>中国大陆274个井下观测数据，包括气象站的大气压力、钻孔内的空气压力、水位和钻孔应变。</li>\n</ul>\n<h3 id=\"采用的方法\"><a href=\"#采用的方法\" class=\"headerlink\" title=\"采用的方法\"></a>采用的方法</h3><ul>\n<li><strong>小波功率谱方法</strong>：展示水位响应特征。</li>\n<li><strong>交叉功率谱方法</strong>：估计增益值。</li>\n</ul>\n<h3 id=\"获得的结果\"><a href=\"#获得的结果\" class=\"headerlink\" title=\"获得的结果\"></a>获得的结果</h3><ul>\n<li>Lamb波以约316米&#x2F;秒的速度影响地下水系统。</li>\n<li>井水位和钻孔应变出现类似波动和相反相位波动。</li>\n<li>观测到可能的时间滞后，可能由不同水力特性的井所致。</li>\n</ul>\n<h3 id=\"本文创新之处\"><a href=\"#本文创新之处\" class=\"headerlink\" title=\"本文创新之处\"></a>本文创新之处</h3><ul>\n<li><strong>新的响应类型</strong>：首次研究了Lamb波对远场地下水系统的新影响。</li>\n<li><strong>增益值的一致性</strong>：发现同时测量的大气压力、钻孔空气压力、钻孔应变和WL的增益值与通过交叉功率谱估计得到的结果一致。</li>\n</ul>\n<h3 id=\"本文贡献\"><a href=\"#本文贡献\" class=\"headerlink\" title=\"本文贡献\"></a>本文贡献</h3><ul>\n<li>为理解火山活动对远场地下水系统的影响提供了新的视角。</li>\n<li>为含水层参数估计提供了一种可能的新方法。</li>\n</ul>\n<h3 id=\"本文不足\"><a href=\"#本文不足\" class=\"headerlink\" title=\"本文不足\"></a>本文不足</h3><p>文章未明确指出研究的不足之处，但可能包括：</p>\n<ul>\n<li>数据可能受限于井的分布和观测条件。</li>\n<li>对Lamb波影响地下水系统的详细机制需要进一步研究。</li>\n</ul>","related_posts":["paper-reading-9.html"],"length":1115,"excerpt":"<p>&emsp;&emsp;<a href=\"https://agupubs.onlinelibrary.wiley.com/doi/10.1029/2023GL107442?af=R\">Far-Field Groundwater Response to the Lamb Waves From the 2022 Hunga-Tonga Volcano Eruption</a></p>","more":"<h3 id=\"摘要\"><a href=\"#摘要\" class=\"headerlink\" title=\"摘要\"></a>摘要</h3><p>&emsp;&emsp;2022年1月15日，汤加火山发生了史上最大的喷发事件，产生了被全球多参数仪器记录的羽流。然而，这次喷发产生的Lamb波对远场水文地质的响应尚未被充分研究。我们研究了远场超过8700公里范围内的地下水对火山喷发的响应，包括274个井。结果表明，速度为316米&#x2F;秒的Lamb波影响了地下水系统，导致井水位（WL）出现类似波动，钻孔应变出现相反相位的波动。不同井在WL幅度上表现出不同的响应，可能由于当地含水层系统的异质性。同时测量大气压力、钻孔空气压力、钻孔应变和WL的5个井的增益值与通过交叉功率谱估计得到的结果一致。这项工作展示了Lamb波在远场地下水系统中诱导的一种新响应，并期望应用于含水层参数估计。</p>\n<h3 id=\"研究的重要性\"><a href=\"#研究的重要性\" class=\"headerlink\" title=\"研究的重要性\"></a>研究的重要性</h3><ul>\n<li>水文地质响应的探索：了解Lamb波如何影响远场地下水系统对于评估火山活动对地下水资源的潜在影响至关重要。</li>\n<li>灾害预警和管理：通过监测地下水位的变化，可以为火山喷发等自然灾害提供预警和管理策略。</li>\n</ul>\n<h3 id=\"前人研究及不足\"><a href=\"#前人研究及不足\" class=\"headerlink\" title=\"前人研究及不足\"></a>前人研究及不足</h3><ul>\n<li><strong>Briggs et al., 2022; D’Arcangelo et al., 2022; Poli &amp; Shapiro, 2022</strong>：研究了洪阿汤加火山喷发对大气、海啸等的影响。</li>\n<li><strong>Jia &amp; Minnett, 2023; Lynett et al., 2022; Ravanelli et al., 2023; Tonegawa &amp; Fukao, 2023</strong>：研究了Lamb波对海洋的影响。</li>\n<li><strong>不足</strong>：现有研究主要集中在直接的地质和大气效应上，对远场地下水系统的响应研究不足。</li>\n</ul>\n<h3 id=\"使用的数据\"><a href=\"#使用的数据\" class=\"headerlink\" title=\"使用的数据\"></a>使用的数据</h3><ul>\n<li>中国大陆274个井下观测数据，包括气象站的大气压力、钻孔内的空气压力、水位和钻孔应变。</li>\n</ul>\n<h3 id=\"采用的方法\"><a href=\"#采用的方法\" class=\"headerlink\" title=\"采用的方法\"></a>采用的方法</h3><ul>\n<li><strong>小波功率谱方法</strong>：展示水位响应特征。</li>\n<li><strong>交叉功率谱方法</strong>：估计增益值。</li>\n</ul>\n<h3 id=\"获得的结果\"><a href=\"#获得的结果\" class=\"headerlink\" title=\"获得的结果\"></a>获得的结果</h3><ul>\n<li>Lamb波以约316米&#x2F;秒的速度影响地下水系统。</li>\n<li>井水位和钻孔应变出现类似波动和相反相位波动。</li>\n<li>观测到可能的时间滞后，可能由不同水力特性的井所致。</li>\n</ul>\n<h3 id=\"本文创新之处\"><a href=\"#本文创新之处\" class=\"headerlink\" title=\"本文创新之处\"></a>本文创新之处</h3><ul>\n<li><strong>新的响应类型</strong>：首次研究了Lamb波对远场地下水系统的新影响。</li>\n<li><strong>增益值的一致性</strong>：发现同时测量的大气压力、钻孔空气压力、钻孔应变和WL的增益值与通过交叉功率谱估计得到的结果一致。</li>\n</ul>\n<h3 id=\"本文贡献\"><a href=\"#本文贡献\" class=\"headerlink\" title=\"本文贡献\"></a>本文贡献</h3><ul>\n<li>为理解火山活动对远场地下水系统的影响提供了新的视角。</li>\n<li>为含水层参数估计提供了一种可能的新方法。</li>\n</ul>\n<h3 id=\"本文不足\"><a href=\"#本文不足\" class=\"headerlink\" title=\"本文不足\"></a>本文不足</h3><p>文章未明确指出研究的不足之处，但可能包括：</p>\n<ul>\n<li>数据可能受限于井的分布和观测条件。</li>\n<li>对Lamb波影响地下水系统的详细机制需要进一步研究。</li>\n</ul>"},{"title":"文献阅读（九）","abbrlink":"e0732b91","date":"2024-06-18T06:21:16.000Z","_content":"\n&emsp;&emsp;[Abundant Spontaneous and Dynamically Triggered Submarine Landslides in the Gulf of Mexico](https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2020GL087213?af=R)\n<!--less-->\n\n### 摘要\n\n&emsp;&emsp;墨西哥湾近海发生的海底滑坡在美国大陆边缘很常见。这些大规模的土体流失事件可能引发海啸，因此可能对沿海社区和海上基础设施造成严重破坏。然而，海底滑坡的启动和失效过程了解甚少。在这里，我们通过2008年至2015年的数据，识别并定位了墨西哥湾85个以前未知的海底滑坡。其中10个滑坡自发发生，其余75个由远处地震产生的地震面波动态触发，这些地震的震级低至约5级。我们的观察表明，在墨西哥湾存在持续的海底滑坡活动，那里有密集的能源行业基础设施，并且该地区容易受到次生地震灾害的威胁，尽管当地的地震活动率很低。我们的结果应该有助于未来的调查，以识别不稳定的海上斜坡，阐明滑坡的动态过程，也许可以在海啸预警系统中应用远程检测技术。\n\n### 相关研究的重要性\n\n1. **海底滑坡对沿海社区和海上基础设施的潜在破坏性**：可能引发海啸，破坏石油平台和海底通信线路。\n2. **了解海底滑坡的启动和失效过程**：对于预测和减轻这些灾害至关重要。\n\n### 前人研究及不足\n\n- **Hampton et al., 1996; McAdoo et al., 2000**：研究了海底滑坡对海啸的潜在影响。\n- **Caplan-Auerbach et al., 2001; Dewey & Dellinger, 2008**：发现较小的海底滑坡也能产生可检测的地震信号。\n- **不足**：对海底滑坡的动态触发机制和远程地震面波的触发过程了解不足。\n\n### 使用的数据\n\n- 使用了2008年至2015年连续8年的地震数据。\n\n### 采用的方法\n\n- **表面波检测器**：基于Automated Event Location Using a Mesh of Arrays (AELUMA)方法。\n- **Rayleigh波**：用于检测和定位墨西哥湾的海底滑坡。\n\n### 获得的结果\n\n- 识别了85个以前未知的海底滑坡事件。\n- 10个滑坡自发发生，75个由远处地震触发。\n\n### 本文创新之处\n\n- **远程检测技术的应用**：提出将远程检测技术应用于海啸预警系统。\n- **海底滑坡的动态触发研究**：提供了海底滑坡动态触发的新见解。\n\n### 本文贡献\n\n- 增进了对海底滑坡启动和失效过程的理解。\n- 为海底滑坡的远程检测和海啸预警提供了新的方法。\n\n### 本文不足\n\n  - 数据覆盖的时间范围有限，仅为8年。\n  - 对于海底滑坡的动态触发机制需要进一步的现场观测和研究。\n","source":"_posts/2024-06-18-paper-reading-9.md","raw":"---\ntitle: 文献阅读（九）\ncategories:\n  - work\ntags:\n  - paper\nabbrlink: e0732b91\ndate: 2024-06-18 14:21:16\n---\n\n&emsp;&emsp;[Abundant Spontaneous and Dynamically Triggered Submarine Landslides in the Gulf of Mexico](https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2020GL087213?af=R)\n<!--less-->\n\n### 摘要\n\n&emsp;&emsp;墨西哥湾近海发生的海底滑坡在美国大陆边缘很常见。这些大规模的土体流失事件可能引发海啸，因此可能对沿海社区和海上基础设施造成严重破坏。然而，海底滑坡的启动和失效过程了解甚少。在这里，我们通过2008年至2015年的数据，识别并定位了墨西哥湾85个以前未知的海底滑坡。其中10个滑坡自发发生，其余75个由远处地震产生的地震面波动态触发，这些地震的震级低至约5级。我们的观察表明，在墨西哥湾存在持续的海底滑坡活动，那里有密集的能源行业基础设施，并且该地区容易受到次生地震灾害的威胁，尽管当地的地震活动率很低。我们的结果应该有助于未来的调查，以识别不稳定的海上斜坡，阐明滑坡的动态过程，也许可以在海啸预警系统中应用远程检测技术。\n\n### 相关研究的重要性\n\n1. **海底滑坡对沿海社区和海上基础设施的潜在破坏性**：可能引发海啸，破坏石油平台和海底通信线路。\n2. **了解海底滑坡的启动和失效过程**：对于预测和减轻这些灾害至关重要。\n\n### 前人研究及不足\n\n- **Hampton et al., 1996; McAdoo et al., 2000**：研究了海底滑坡对海啸的潜在影响。\n- **Caplan-Auerbach et al., 2001; Dewey & Dellinger, 2008**：发现较小的海底滑坡也能产生可检测的地震信号。\n- **不足**：对海底滑坡的动态触发机制和远程地震面波的触发过程了解不足。\n\n### 使用的数据\n\n- 使用了2008年至2015年连续8年的地震数据。\n\n### 采用的方法\n\n- **表面波检测器**：基于Automated Event Location Using a Mesh of Arrays (AELUMA)方法。\n- **Rayleigh波**：用于检测和定位墨西哥湾的海底滑坡。\n\n### 获得的结果\n\n- 识别了85个以前未知的海底滑坡事件。\n- 10个滑坡自发发生，75个由远处地震触发。\n\n### 本文创新之处\n\n- **远程检测技术的应用**：提出将远程检测技术应用于海啸预警系统。\n- **海底滑坡的动态触发研究**：提供了海底滑坡动态触发的新见解。\n\n### 本文贡献\n\n- 增进了对海底滑坡启动和失效过程的理解。\n- 为海底滑坡的远程检测和海啸预警提供了新的方法。\n\n### 本文不足\n\n  - 数据覆盖的时间范围有限，仅为8年。\n  - 对于海底滑坡的动态触发机制需要进一步的现场观测和研究。\n","slug":"paper-reading-9","published":1,"updated":"2024-06-18T06:33:19.514Z","comments":1,"layout":"post","photos":[],"_id":"cmh498ipv0090wvou31ctgdik","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><h3 id=\"摘要\"><a href=\"#摘要\" class=\"headerlink\" title=\"摘要\"></a>摘要</h3><p>&emsp;&emsp;墨西哥湾近海发生的海底滑坡在美国大陆边缘很常见。这些大规模的土体流失事件可能引发海啸，因此可能对沿海社区和海上基础设施造成严重破坏。然而，海底滑坡的启动和失效过程了解甚少。在这里，我们通过2008年至2015年的数据，识别并定位了墨西哥湾85个以前未知的海底滑坡。其中10个滑坡自发发生，其余75个由远处地震产生的地震面波动态触发，这些地震的震级低至约5级。我们的观察表明，在墨西哥湾存在持续的海底滑坡活动，那里有密集的能源行业基础设施，并且该地区容易受到次生地震灾害的威胁，尽管当地的地震活动率很低。我们的结果应该有助于未来的调查，以识别不稳定的海上斜坡，阐明滑坡的动态过程，也许可以在海啸预警系统中应用远程检测技术。</p>\n<h3 id=\"相关研究的重要性\"><a href=\"#相关研究的重要性\" class=\"headerlink\" title=\"相关研究的重要性\"></a>相关研究的重要性</h3><ol>\n<li><strong>海底滑坡对沿海社区和海上基础设施的潜在破坏性</strong>：可能引发海啸，破坏石油平台和海底通信线路。</li>\n<li><strong>了解海底滑坡的启动和失效过程</strong>：对于预测和减轻这些灾害至关重要。</li>\n</ol>\n<h3 id=\"前人研究及不足\"><a href=\"#前人研究及不足\" class=\"headerlink\" title=\"前人研究及不足\"></a>前人研究及不足</h3><ul>\n<li><strong>Hampton et al., 1996; McAdoo et al., 2000</strong>：研究了海底滑坡对海啸的潜在影响。</li>\n<li><strong>Caplan-Auerbach et al., 2001; Dewey &amp; Dellinger, 2008</strong>：发现较小的海底滑坡也能产生可检测的地震信号。</li>\n<li><strong>不足</strong>：对海底滑坡的动态触发机制和远程地震面波的触发过程了解不足。</li>\n</ul>\n<h3 id=\"使用的数据\"><a href=\"#使用的数据\" class=\"headerlink\" title=\"使用的数据\"></a>使用的数据</h3><ul>\n<li>使用了2008年至2015年连续8年的地震数据。</li>\n</ul>\n<h3 id=\"采用的方法\"><a href=\"#采用的方法\" class=\"headerlink\" title=\"采用的方法\"></a>采用的方法</h3><ul>\n<li><strong>表面波检测器</strong>：基于Automated Event Location Using a Mesh of Arrays (AELUMA)方法。</li>\n<li><strong>Rayleigh波</strong>：用于检测和定位墨西哥湾的海底滑坡。</li>\n</ul>\n<h3 id=\"获得的结果\"><a href=\"#获得的结果\" class=\"headerlink\" title=\"获得的结果\"></a>获得的结果</h3><ul>\n<li>识别了85个以前未知的海底滑坡事件。</li>\n<li>10个滑坡自发发生，75个由远处地震触发。</li>\n</ul>\n<h3 id=\"本文创新之处\"><a href=\"#本文创新之处\" class=\"headerlink\" title=\"本文创新之处\"></a>本文创新之处</h3><ul>\n<li><strong>远程检测技术的应用</strong>：提出将远程检测技术应用于海啸预警系统。</li>\n<li><strong>海底滑坡的动态触发研究</strong>：提供了海底滑坡动态触发的新见解。</li>\n</ul>\n<h3 id=\"本文贡献\"><a href=\"#本文贡献\" class=\"headerlink\" title=\"本文贡献\"></a>本文贡献</h3><ul>\n<li>增进了对海底滑坡启动和失效过程的理解。</li>\n<li>为海底滑坡的远程检测和海啸预警提供了新的方法。</li>\n</ul>\n<h3 id=\"本文不足\"><a href=\"#本文不足\" class=\"headerlink\" title=\"本文不足\"></a>本文不足</h3><ul>\n<li>数据覆盖的时间范围有限，仅为8年。</li>\n<li>对于海底滑坡的动态触发机制需要进一步的现场观测和研究。</li>\n</ul>","related_posts":["paper-reading-15.html","paper-reading-8.html"],"length":982,"excerpt":"<p>&emsp;&emsp;<a href=\"https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2020GL087213?af=R\">Abundant Spontaneous and Dynamically Triggered Submarine Landslides in the Gulf of Mexico</a></p>","more":"<h3 id=\"摘要\"><a href=\"#摘要\" class=\"headerlink\" title=\"摘要\"></a>摘要</h3><p>&emsp;&emsp;墨西哥湾近海发生的海底滑坡在美国大陆边缘很常见。这些大规模的土体流失事件可能引发海啸，因此可能对沿海社区和海上基础设施造成严重破坏。然而，海底滑坡的启动和失效过程了解甚少。在这里，我们通过2008年至2015年的数据，识别并定位了墨西哥湾85个以前未知的海底滑坡。其中10个滑坡自发发生，其余75个由远处地震产生的地震面波动态触发，这些地震的震级低至约5级。我们的观察表明，在墨西哥湾存在持续的海底滑坡活动，那里有密集的能源行业基础设施，并且该地区容易受到次生地震灾害的威胁，尽管当地的地震活动率很低。我们的结果应该有助于未来的调查，以识别不稳定的海上斜坡，阐明滑坡的动态过程，也许可以在海啸预警系统中应用远程检测技术。</p>\n<h3 id=\"相关研究的重要性\"><a href=\"#相关研究的重要性\" class=\"headerlink\" title=\"相关研究的重要性\"></a>相关研究的重要性</h3><ol>\n<li><strong>海底滑坡对沿海社区和海上基础设施的潜在破坏性</strong>：可能引发海啸，破坏石油平台和海底通信线路。</li>\n<li><strong>了解海底滑坡的启动和失效过程</strong>：对于预测和减轻这些灾害至关重要。</li>\n</ol>\n<h3 id=\"前人研究及不足\"><a href=\"#前人研究及不足\" class=\"headerlink\" title=\"前人研究及不足\"></a>前人研究及不足</h3><ul>\n<li><strong>Hampton et al., 1996; McAdoo et al., 2000</strong>：研究了海底滑坡对海啸的潜在影响。</li>\n<li><strong>Caplan-Auerbach et al., 2001; Dewey &amp; Dellinger, 2008</strong>：发现较小的海底滑坡也能产生可检测的地震信号。</li>\n<li><strong>不足</strong>：对海底滑坡的动态触发机制和远程地震面波的触发过程了解不足。</li>\n</ul>\n<h3 id=\"使用的数据\"><a href=\"#使用的数据\" class=\"headerlink\" title=\"使用的数据\"></a>使用的数据</h3><ul>\n<li>使用了2008年至2015年连续8年的地震数据。</li>\n</ul>\n<h3 id=\"采用的方法\"><a href=\"#采用的方法\" class=\"headerlink\" title=\"采用的方法\"></a>采用的方法</h3><ul>\n<li><strong>表面波检测器</strong>：基于Automated Event Location Using a Mesh of Arrays (AELUMA)方法。</li>\n<li><strong>Rayleigh波</strong>：用于检测和定位墨西哥湾的海底滑坡。</li>\n</ul>\n<h3 id=\"获得的结果\"><a href=\"#获得的结果\" class=\"headerlink\" title=\"获得的结果\"></a>获得的结果</h3><ul>\n<li>识别了85个以前未知的海底滑坡事件。</li>\n<li>10个滑坡自发发生，75个由远处地震触发。</li>\n</ul>\n<h3 id=\"本文创新之处\"><a href=\"#本文创新之处\" class=\"headerlink\" title=\"本文创新之处\"></a>本文创新之处</h3><ul>\n<li><strong>远程检测技术的应用</strong>：提出将远程检测技术应用于海啸预警系统。</li>\n<li><strong>海底滑坡的动态触发研究</strong>：提供了海底滑坡动态触发的新见解。</li>\n</ul>\n<h3 id=\"本文贡献\"><a href=\"#本文贡献\" class=\"headerlink\" title=\"本文贡献\"></a>本文贡献</h3><ul>\n<li>增进了对海底滑坡启动和失效过程的理解。</li>\n<li>为海底滑坡的远程检测和海啸预警提供了新的方法。</li>\n</ul>\n<h3 id=\"本文不足\"><a href=\"#本文不足\" class=\"headerlink\" title=\"本文不足\"></a>本文不足</h3><ul>\n<li>数据覆盖的时间范围有限，仅为8年。</li>\n<li>对于海底滑坡的动态触发机制需要进一步的现场观测和研究。</li>\n</ul>"},{"title":"文献阅读（十一）","abbrlink":"968b3d80","date":"2024-06-19T14:04:08.000Z","_content":"\n&emsp;&emsp;[High-Resolution Characterization of the Firn Layer Near the West Antarctic Ice Sheet Divide Camp With Active and Passive Seismic Data](https://agupubs.onlinelibrary.wiley.com/doi/10.1029/2024GL108933?af=R)\n<!--less-->\n\n### 摘要\n\n&emsp;&emsp;本文利用西南极附近冰盖分界营地的背景噪声层析成像技术，构建了上覆100米范围内的高分辨率剪切波速度（VS）模型。这是通过联合反演瑞利波相速度和H/V比率实现的，其信噪比分别通过三站干涉测量法和相位匹配滤波器得到增强。VS显示在顶部5米内急剧增加（0.04-0.9 km/s），在大约8-12米处有明显界面，随后在10到45米深度之间逐渐增加（1.2-1.8 km/s），并在约65米处达到2 km/s。压缩波速度和经验得到的密度剖面与主动源射击实验中潜水波的Herglotz-Wiechert反演结果以及冰芯分析的结果相吻合。我们的方法提供了一种工具，用于表征雪层和浅层冰柱的高分辨率属性，这有助于推断更深层冰盖的物理属性，从而有助于提高对地球冰冻圈的理解。\n\n### 相关研究的重要性\n\n1. **气候变化影响**：南极冰盖保存了关于过去环境条件、气候变化影响的重要信息，对于预测未来海平面上升至关重要。\n2. **海平面上升预测**：西南极冰盖（WAIS）对海洋温度的变化非常敏感，其融化可能导致高达3米的海平面上升。\n\n### 前人研究及不足\n\n- **Zhang et al., 2022**：通过环境噪声层析成像技术构建了上层300米的剪切波速度（VS）模型，但在上层雪层的分辨率有限，且预测的瑞利波相速度在频率超过25 Hz时持续超过观测值。\n\n### 本文使用的数据和方法\n\n- **数据**：使用了Thwaites跨学科边缘演化（TIME）项目期间收集的一周长的环境噪声数据。\n- **方法**：\n  - **三站干涉测量法**：增强基模瑞利波。\n  - **相位匹配滤波器**：提高H/V比率测量的质量。\n  - **联合反演**：Vph和H/V比率，以获得高分辨率的VS模型。\n  - **Herglotz-Wiechert反演（HWI）**：独立验证模型，使用主动源射击实验中潜水波的数据。\n\n### 本文结果\n\n- 获得了高分辨率的VS模型，揭示了雪层的显著垂直变化和微妙的水平不均匀性。\n- 经验转换得到的密度剖面为雪层压实过程提供了宝贵见解，并与冰芯分析的测量结果一致。\n\n### 本文创新之处和贡献\n\n- 利用环境噪声数据，通过先进的去噪技术和联合反演方法，显著提高了雪层特别是最上层约20米分辨率的刻画。\n- 该方法可以扩展到长期监测更大区域，为冰盖动力学的预测模型提供数据支持。\n\n### 本文不足\n\n- 文章中并未明确指出研究的局限性，但可能包括信噪比提升技术的局限性、模型对P波速度（VP）的敏感度有限，以及对环境噪声的假设可能带来的影响。\n\n### 数据可用性声明\n\n- 本研究中使用的数据波形可在EarthScope Consortium PH5 Web Services下获取。\n","source":"_posts/2024-06-19-paper-reading-11.md","raw":"---\ntitle: 文献阅读（十一）\ncategories:\n  - work\ntags:\n  - paper\nabbrlink: 968b3d80\ndate: 2024-06-19 22:04:08\n---\n\n&emsp;&emsp;[High-Resolution Characterization of the Firn Layer Near the West Antarctic Ice Sheet Divide Camp With Active and Passive Seismic Data](https://agupubs.onlinelibrary.wiley.com/doi/10.1029/2024GL108933?af=R)\n<!--less-->\n\n### 摘要\n\n&emsp;&emsp;本文利用西南极附近冰盖分界营地的背景噪声层析成像技术，构建了上覆100米范围内的高分辨率剪切波速度（VS）模型。这是通过联合反演瑞利波相速度和H/V比率实现的，其信噪比分别通过三站干涉测量法和相位匹配滤波器得到增强。VS显示在顶部5米内急剧增加（0.04-0.9 km/s），在大约8-12米处有明显界面，随后在10到45米深度之间逐渐增加（1.2-1.8 km/s），并在约65米处达到2 km/s。压缩波速度和经验得到的密度剖面与主动源射击实验中潜水波的Herglotz-Wiechert反演结果以及冰芯分析的结果相吻合。我们的方法提供了一种工具，用于表征雪层和浅层冰柱的高分辨率属性，这有助于推断更深层冰盖的物理属性，从而有助于提高对地球冰冻圈的理解。\n\n### 相关研究的重要性\n\n1. **气候变化影响**：南极冰盖保存了关于过去环境条件、气候变化影响的重要信息，对于预测未来海平面上升至关重要。\n2. **海平面上升预测**：西南极冰盖（WAIS）对海洋温度的变化非常敏感，其融化可能导致高达3米的海平面上升。\n\n### 前人研究及不足\n\n- **Zhang et al., 2022**：通过环境噪声层析成像技术构建了上层300米的剪切波速度（VS）模型，但在上层雪层的分辨率有限，且预测的瑞利波相速度在频率超过25 Hz时持续超过观测值。\n\n### 本文使用的数据和方法\n\n- **数据**：使用了Thwaites跨学科边缘演化（TIME）项目期间收集的一周长的环境噪声数据。\n- **方法**：\n  - **三站干涉测量法**：增强基模瑞利波。\n  - **相位匹配滤波器**：提高H/V比率测量的质量。\n  - **联合反演**：Vph和H/V比率，以获得高分辨率的VS模型。\n  - **Herglotz-Wiechert反演（HWI）**：独立验证模型，使用主动源射击实验中潜水波的数据。\n\n### 本文结果\n\n- 获得了高分辨率的VS模型，揭示了雪层的显著垂直变化和微妙的水平不均匀性。\n- 经验转换得到的密度剖面为雪层压实过程提供了宝贵见解，并与冰芯分析的测量结果一致。\n\n### 本文创新之处和贡献\n\n- 利用环境噪声数据，通过先进的去噪技术和联合反演方法，显著提高了雪层特别是最上层约20米分辨率的刻画。\n- 该方法可以扩展到长期监测更大区域，为冰盖动力学的预测模型提供数据支持。\n\n### 本文不足\n\n- 文章中并未明确指出研究的局限性，但可能包括信噪比提升技术的局限性、模型对P波速度（VP）的敏感度有限，以及对环境噪声的假设可能带来的影响。\n\n### 数据可用性声明\n\n- 本研究中使用的数据波形可在EarthScope Consortium PH5 Web Services下获取。\n","slug":"paper-reading-11","published":1,"updated":"2024-06-20T00:14:47.694Z","comments":1,"layout":"post","photos":[],"_id":"cmh498ipw0093wvou11pb8bv0","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><h3 id=\"摘要\"><a href=\"#摘要\" class=\"headerlink\" title=\"摘要\"></a>摘要</h3><p>&emsp;&emsp;本文利用西南极附近冰盖分界营地的背景噪声层析成像技术，构建了上覆100米范围内的高分辨率剪切波速度（VS）模型。这是通过联合反演瑞利波相速度和H&#x2F;V比率实现的，其信噪比分别通过三站干涉测量法和相位匹配滤波器得到增强。VS显示在顶部5米内急剧增加（0.04-0.9 km&#x2F;s），在大约8-12米处有明显界面，随后在10到45米深度之间逐渐增加（1.2-1.8 km&#x2F;s），并在约65米处达到2 km&#x2F;s。压缩波速度和经验得到的密度剖面与主动源射击实验中潜水波的Herglotz-Wiechert反演结果以及冰芯分析的结果相吻合。我们的方法提供了一种工具，用于表征雪层和浅层冰柱的高分辨率属性，这有助于推断更深层冰盖的物理属性，从而有助于提高对地球冰冻圈的理解。</p>\n<h3 id=\"相关研究的重要性\"><a href=\"#相关研究的重要性\" class=\"headerlink\" title=\"相关研究的重要性\"></a>相关研究的重要性</h3><ol>\n<li><strong>气候变化影响</strong>：南极冰盖保存了关于过去环境条件、气候变化影响的重要信息，对于预测未来海平面上升至关重要。</li>\n<li><strong>海平面上升预测</strong>：西南极冰盖（WAIS）对海洋温度的变化非常敏感，其融化可能导致高达3米的海平面上升。</li>\n</ol>\n<h3 id=\"前人研究及不足\"><a href=\"#前人研究及不足\" class=\"headerlink\" title=\"前人研究及不足\"></a>前人研究及不足</h3><ul>\n<li><strong>Zhang et al., 2022</strong>：通过环境噪声层析成像技术构建了上层300米的剪切波速度（VS）模型，但在上层雪层的分辨率有限，且预测的瑞利波相速度在频率超过25 Hz时持续超过观测值。</li>\n</ul>\n<h3 id=\"本文使用的数据和方法\"><a href=\"#本文使用的数据和方法\" class=\"headerlink\" title=\"本文使用的数据和方法\"></a>本文使用的数据和方法</h3><ul>\n<li><strong>数据</strong>：使用了Thwaites跨学科边缘演化（TIME）项目期间收集的一周长的环境噪声数据。</li>\n<li><strong>方法</strong>：<ul>\n<li><strong>三站干涉测量法</strong>：增强基模瑞利波。</li>\n<li><strong>相位匹配滤波器</strong>：提高H&#x2F;V比率测量的质量。</li>\n<li><strong>联合反演</strong>：Vph和H&#x2F;V比率，以获得高分辨率的VS模型。</li>\n<li><strong>Herglotz-Wiechert反演（HWI）</strong>：独立验证模型，使用主动源射击实验中潜水波的数据。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"本文结果\"><a href=\"#本文结果\" class=\"headerlink\" title=\"本文结果\"></a>本文结果</h3><ul>\n<li>获得了高分辨率的VS模型，揭示了雪层的显著垂直变化和微妙的水平不均匀性。</li>\n<li>经验转换得到的密度剖面为雪层压实过程提供了宝贵见解，并与冰芯分析的测量结果一致。</li>\n</ul>\n<h3 id=\"本文创新之处和贡献\"><a href=\"#本文创新之处和贡献\" class=\"headerlink\" title=\"本文创新之处和贡献\"></a>本文创新之处和贡献</h3><ul>\n<li>利用环境噪声数据，通过先进的去噪技术和联合反演方法，显著提高了雪层特别是最上层约20米分辨率的刻画。</li>\n<li>该方法可以扩展到长期监测更大区域，为冰盖动力学的预测模型提供数据支持。</li>\n</ul>\n<h3 id=\"本文不足\"><a href=\"#本文不足\" class=\"headerlink\" title=\"本文不足\"></a>本文不足</h3><ul>\n<li>文章中并未明确指出研究的局限性，但可能包括信噪比提升技术的局限性、模型对P波速度（VP）的敏感度有限，以及对环境噪声的假设可能带来的影响。</li>\n</ul>\n<h3 id=\"数据可用性声明\"><a href=\"#数据可用性声明\" class=\"headerlink\" title=\"数据可用性声明\"></a>数据可用性声明</h3><ul>\n<li>本研究中使用的数据波形可在EarthScope Consortium PH5 Web Services下获取。</li>\n</ul>","related_posts":["paper-reading-13.html"],"length":1180,"excerpt":"<p>&emsp;&emsp;<a href=\"https://agupubs.onlinelibrary.wiley.com/doi/10.1029/2024GL108933?af=R\">High-Resolution Characterization of the Firn Layer Near the West Antarctic Ice Sheet Divide Camp With Active and Passive Seismic Data</a></p>","more":"<h3 id=\"摘要\"><a href=\"#摘要\" class=\"headerlink\" title=\"摘要\"></a>摘要</h3><p>&emsp;&emsp;本文利用西南极附近冰盖分界营地的背景噪声层析成像技术，构建了上覆100米范围内的高分辨率剪切波速度（VS）模型。这是通过联合反演瑞利波相速度和H&#x2F;V比率实现的，其信噪比分别通过三站干涉测量法和相位匹配滤波器得到增强。VS显示在顶部5米内急剧增加（0.04-0.9 km&#x2F;s），在大约8-12米处有明显界面，随后在10到45米深度之间逐渐增加（1.2-1.8 km&#x2F;s），并在约65米处达到2 km&#x2F;s。压缩波速度和经验得到的密度剖面与主动源射击实验中潜水波的Herglotz-Wiechert反演结果以及冰芯分析的结果相吻合。我们的方法提供了一种工具，用于表征雪层和浅层冰柱的高分辨率属性，这有助于推断更深层冰盖的物理属性，从而有助于提高对地球冰冻圈的理解。</p>\n<h3 id=\"相关研究的重要性\"><a href=\"#相关研究的重要性\" class=\"headerlink\" title=\"相关研究的重要性\"></a>相关研究的重要性</h3><ol>\n<li><strong>气候变化影响</strong>：南极冰盖保存了关于过去环境条件、气候变化影响的重要信息，对于预测未来海平面上升至关重要。</li>\n<li><strong>海平面上升预测</strong>：西南极冰盖（WAIS）对海洋温度的变化非常敏感，其融化可能导致高达3米的海平面上升。</li>\n</ol>\n<h3 id=\"前人研究及不足\"><a href=\"#前人研究及不足\" class=\"headerlink\" title=\"前人研究及不足\"></a>前人研究及不足</h3><ul>\n<li><strong>Zhang et al., 2022</strong>：通过环境噪声层析成像技术构建了上层300米的剪切波速度（VS）模型，但在上层雪层的分辨率有限，且预测的瑞利波相速度在频率超过25 Hz时持续超过观测值。</li>\n</ul>\n<h3 id=\"本文使用的数据和方法\"><a href=\"#本文使用的数据和方法\" class=\"headerlink\" title=\"本文使用的数据和方法\"></a>本文使用的数据和方法</h3><ul>\n<li><strong>数据</strong>：使用了Thwaites跨学科边缘演化（TIME）项目期间收集的一周长的环境噪声数据。</li>\n<li><strong>方法</strong>：<ul>\n<li><strong>三站干涉测量法</strong>：增强基模瑞利波。</li>\n<li><strong>相位匹配滤波器</strong>：提高H&#x2F;V比率测量的质量。</li>\n<li><strong>联合反演</strong>：Vph和H&#x2F;V比率，以获得高分辨率的VS模型。</li>\n<li><strong>Herglotz-Wiechert反演（HWI）</strong>：独立验证模型，使用主动源射击实验中潜水波的数据。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"本文结果\"><a href=\"#本文结果\" class=\"headerlink\" title=\"本文结果\"></a>本文结果</h3><ul>\n<li>获得了高分辨率的VS模型，揭示了雪层的显著垂直变化和微妙的水平不均匀性。</li>\n<li>经验转换得到的密度剖面为雪层压实过程提供了宝贵见解，并与冰芯分析的测量结果一致。</li>\n</ul>\n<h3 id=\"本文创新之处和贡献\"><a href=\"#本文创新之处和贡献\" class=\"headerlink\" title=\"本文创新之处和贡献\"></a>本文创新之处和贡献</h3><ul>\n<li>利用环境噪声数据，通过先进的去噪技术和联合反演方法，显著提高了雪层特别是最上层约20米分辨率的刻画。</li>\n<li>该方法可以扩展到长期监测更大区域，为冰盖动力学的预测模型提供数据支持。</li>\n</ul>\n<h3 id=\"本文不足\"><a href=\"#本文不足\" class=\"headerlink\" title=\"本文不足\"></a>本文不足</h3><ul>\n<li>文章中并未明确指出研究的局限性，但可能包括信噪比提升技术的局限性、模型对P波速度（VP）的敏感度有限，以及对环境噪声的假设可能带来的影响。</li>\n</ul>\n<h3 id=\"数据可用性声明\"><a href=\"#数据可用性声明\" class=\"headerlink\" title=\"数据可用性声明\"></a>数据可用性声明</h3><ul>\n<li>本研究中使用的数据波形可在EarthScope Consortium PH5 Web Services下获取。</li>\n</ul>"},{"title":"有趣的程序和项目（一）","abbrlink":"169823f1","date":"2024-06-20T02:53:09.000Z","_content":"\n1. [Global lake level database](https://github.com/ESIPFed/Global-Lake-Level-Database) The Global Lake Level Database (GLLD) is the back-end architecture for the Python package LakePy. \n2. [Road building extraction](https://github.com/jeffwen/road_building_extraction) This repository contains the code used for this [project](https://jeffwen.com/2018/02/23/road_extraction).\n3. [geopy](https://github.com/geopy/geopy) geopy is a Python client for several popular geocoding web services.\n4. [geocoder](https://github.com/DenisCarriere/geocoder) Simple and consistent geocoding library written in Python.\n5. [Awesome datascience](https://github.com/academic/awesome-datascience) \n6. [Machine learning workshop](https://github.com/amueller/ml-workshop-1-of-4) This repository contains the teaching material and other info associated with the \"Introduction to Machine Learning with scikit-learn\" course.\n7. [Machine learning interactive visualization](https://github.com/dhaitz/machine-learning-interactive-visualization) An interactive dashboard made with Jupyter and Voila. Users can play around with parameter like class imbalance, model strength or cutoff value and observe the effects on metris like ROC/AUC or accuracy/precision/recall.\n8. [Awesome deep learning](https://github.com/ChristosChristofidis/awesome-deep-learning) An open-source Data Science repository to learn and apply towards solving real world problems.\n9. [Unet pytorch](https://github.com/bubbliiiing/unet-pytorch) Unet：U-Net: Convolutional Networks for Biomedical Image Segmentation.\n10. [Open Sora](https://github.com/hpcaitech/Open-Sora/) Democratizing Efficient Video Production for All.\n11. [Hacker news daily](https://github.com/headllines/hackernews-daily) 通过GitHub订阅Hacker News每日top10.\n","source":"_posts/2024-06-20-code-and-project1.md","raw":"---\ntitle: 有趣的程序和项目（一）\ncategories:\n  - work\ntags:\n  - code\n  - project\nabbrlink: 169823f1\ndate: 2024-06-20 10:53:09\n---\n\n1. [Global lake level database](https://github.com/ESIPFed/Global-Lake-Level-Database) The Global Lake Level Database (GLLD) is the back-end architecture for the Python package LakePy. \n2. [Road building extraction](https://github.com/jeffwen/road_building_extraction) This repository contains the code used for this [project](https://jeffwen.com/2018/02/23/road_extraction).\n3. [geopy](https://github.com/geopy/geopy) geopy is a Python client for several popular geocoding web services.\n4. [geocoder](https://github.com/DenisCarriere/geocoder) Simple and consistent geocoding library written in Python.\n5. [Awesome datascience](https://github.com/academic/awesome-datascience) \n6. [Machine learning workshop](https://github.com/amueller/ml-workshop-1-of-4) This repository contains the teaching material and other info associated with the \"Introduction to Machine Learning with scikit-learn\" course.\n7. [Machine learning interactive visualization](https://github.com/dhaitz/machine-learning-interactive-visualization) An interactive dashboard made with Jupyter and Voila. Users can play around with parameter like class imbalance, model strength or cutoff value and observe the effects on metris like ROC/AUC or accuracy/precision/recall.\n8. [Awesome deep learning](https://github.com/ChristosChristofidis/awesome-deep-learning) An open-source Data Science repository to learn and apply towards solving real world problems.\n9. [Unet pytorch](https://github.com/bubbliiiing/unet-pytorch) Unet：U-Net: Convolutional Networks for Biomedical Image Segmentation.\n10. [Open Sora](https://github.com/hpcaitech/Open-Sora/) Democratizing Efficient Video Production for All.\n11. [Hacker news daily](https://github.com/headllines/hackernews-daily) 通过GitHub订阅Hacker News每日top10.\n","slug":"code-and-project1","published":1,"updated":"2025-04-17T08:28:47.248Z","comments":1,"layout":"post","photos":[],"_id":"cmh498ipw0097wvou33mx8431","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><ol>\n<li><a href=\"https://github.com/ESIPFed/Global-Lake-Level-Database\">Global lake level database</a> The Global Lake Level Database (GLLD) is the back-end architecture for the Python package LakePy. </li>\n<li><a href=\"https://github.com/jeffwen/road_building_extraction\">Road building extraction</a> This repository contains the code used for this <a href=\"https://jeffwen.com/2018/02/23/road_extraction\">project</a>.</li>\n<li><a href=\"https://github.com/geopy/geopy\">geopy</a> geopy is a Python client for several popular geocoding web services.</li>\n<li><a href=\"https://github.com/DenisCarriere/geocoder\">geocoder</a> Simple and consistent geocoding library written in Python.</li>\n<li><a href=\"https://github.com/academic/awesome-datascience\">Awesome datascience</a> </li>\n<li><a href=\"https://github.com/amueller/ml-workshop-1-of-4\">Machine learning workshop</a> This repository contains the teaching material and other info associated with the “Introduction to Machine Learning with scikit-learn” course.</li>\n<li><a href=\"https://github.com/dhaitz/machine-learning-interactive-visualization\">Machine learning interactive visualization</a> An interactive dashboard made with Jupyter and Voila. Users can play around with parameter like class imbalance, model strength or cutoff value and observe the effects on metris like ROC&#x2F;AUC or accuracy&#x2F;precision&#x2F;recall.</li>\n<li><a href=\"https://github.com/ChristosChristofidis/awesome-deep-learning\">Awesome deep learning</a> An open-source Data Science repository to learn and apply towards solving real world problems.</li>\n<li><a href=\"https://github.com/bubbliiiing/unet-pytorch\">Unet pytorch</a> Unet：U-Net: Convolutional Networks for Biomedical Image Segmentation.</li>\n<li><a href=\"https://github.com/hpcaitech/Open-Sora/\">Open Sora</a> Democratizing Efficient Video Production for All.</li>\n<li><a href=\"https://github.com/headllines/hackernews-daily\">Hacker news daily</a> 通过GitHub订阅Hacker News每日top10.</li>\n</ol>\n","related_posts":["code-and-project2.html","install-and-backup-mediawiki.html","object-detection.html","science-blogs.html","paper-reading-13.html"],"length":975,"excerpt":"","more":"<ol>\n<li><a href=\"https://github.com/ESIPFed/Global-Lake-Level-Database\">Global lake level database</a> The Global Lake Level Database (GLLD) is the back-end architecture for the Python package LakePy. </li>\n<li><a href=\"https://github.com/jeffwen/road_building_extraction\">Road building extraction</a> This repository contains the code used for this <a href=\"https://jeffwen.com/2018/02/23/road_extraction\">project</a>.</li>\n<li><a href=\"https://github.com/geopy/geopy\">geopy</a> geopy is a Python client for several popular geocoding web services.</li>\n<li><a href=\"https://github.com/DenisCarriere/geocoder\">geocoder</a> Simple and consistent geocoding library written in Python.</li>\n<li><a href=\"https://github.com/academic/awesome-datascience\">Awesome datascience</a> </li>\n<li><a href=\"https://github.com/amueller/ml-workshop-1-of-4\">Machine learning workshop</a> This repository contains the teaching material and other info associated with the “Introduction to Machine Learning with scikit-learn” course.</li>\n<li><a href=\"https://github.com/dhaitz/machine-learning-interactive-visualization\">Machine learning interactive visualization</a> An interactive dashboard made with Jupyter and Voila. Users can play around with parameter like class imbalance, model strength or cutoff value and observe the effects on metris like ROC&#x2F;AUC or accuracy&#x2F;precision&#x2F;recall.</li>\n<li><a href=\"https://github.com/ChristosChristofidis/awesome-deep-learning\">Awesome deep learning</a> An open-source Data Science repository to learn and apply towards solving real world problems.</li>\n<li><a href=\"https://github.com/bubbliiiing/unet-pytorch\">Unet pytorch</a> Unet：U-Net: Convolutional Networks for Biomedical Image Segmentation.</li>\n<li><a href=\"https://github.com/hpcaitech/Open-Sora/\">Open Sora</a> Democratizing Efficient Video Production for All.</li>\n<li><a href=\"https://github.com/headllines/hackernews-daily\">Hacker news daily</a> 通过GitHub订阅Hacker News每日top10.</li>\n</ol>\n"},{"title":"如何读文献","abbrlink":"52d1faf3","date":"2024-06-20T03:13:28.000Z","_content":"&emsp;&emsp;如何阅读文献？Keshav S. How to Read a Paper.\n<!--less-->\n\n### 引言\n&emsp;&emsp;高效地阅读论文是一项很关键但多半没有人教你的技能。这里讲述了\"三遍阅读法\"及其在进行文献调查中的使用。\n\n### 三遍阅读法\n&emsp;&emsp;读第一遍你对论文会有一个大致的了解。读第二遍你能基本掌握论文的基本内容。读第三遍你将深入理解论文。\n\n#### 第一遍\n快速浏览，获得论文的大致内容，大约需要五到十分钟：\n\n- 仔细阅读标题、摘要和引言\n- 阅读各个章节和小节的标题，忽略其他所有内容\n- 阅读结论\n- 浏览参考文献，心里记下你已经读过的那些\n\n\n在第一遍结束时，你应该能够回答5C问题：\n\n1. Category：这是哪种类型的论文？\n2. Context：它与哪些其他论文相关？使用了哪些理论基础？\n3. Correctness：结论看起来合理吗？\n4. Contributions：论文的主要贡献是什么？\n5. Clarity：这篇论文写得好吗?\n\n\n像审稿人一样思考：一般审稿人在一遍阅读后不能理解你的论文要点，这篇论文可能会被拒绝。\n\n#### 第二遍\n仔细地阅读论文，但忽略证明等细节，最多需要一个小时。\n\n- 仔细看图表和其他插图\n- 标记需要进一步阅读的相关未读参考文献\n\n#### 第三遍\n对于初学者大约需要四到五个小时，对于有经验的读者大约需要一个小时。\n\n- 能够基本复现这篇论文的工作\n\n### 进行文献调研\n使用学术搜索引擎找到该领域最近的三到五篇论文\n\n- 阅读它们的相关工作\n- 阅读最近的综述论文\n- 在参考文献中找到共享的引用和重复出现的作者名字\n- 下载关键论文（1）\n- 找出最优秀的研究者最近在哪里发表了论文\n- 访问这些顶级会议或期刊的网站，浏览他们最近的论文集\n- 确定最近的高质量相关工作（2）\n- 由（1）和（2）构成调查的第一版\n- 获取你在这些论文中没有找到的关键论文，获取并阅读它\n- 你最好写一个文献调研综述。\n","source":"_posts/2024-06-20-how-to-read-paper.md","raw":"---\ntitle: 如何读文献\ncategories:\n  - work\ntags:\n  - paper\nabbrlink: 52d1faf3\ndate: 2024-06-20 11:13:28\n---\n&emsp;&emsp;如何阅读文献？Keshav S. How to Read a Paper.\n<!--less-->\n\n### 引言\n&emsp;&emsp;高效地阅读论文是一项很关键但多半没有人教你的技能。这里讲述了\"三遍阅读法\"及其在进行文献调查中的使用。\n\n### 三遍阅读法\n&emsp;&emsp;读第一遍你对论文会有一个大致的了解。读第二遍你能基本掌握论文的基本内容。读第三遍你将深入理解论文。\n\n#### 第一遍\n快速浏览，获得论文的大致内容，大约需要五到十分钟：\n\n- 仔细阅读标题、摘要和引言\n- 阅读各个章节和小节的标题，忽略其他所有内容\n- 阅读结论\n- 浏览参考文献，心里记下你已经读过的那些\n\n\n在第一遍结束时，你应该能够回答5C问题：\n\n1. Category：这是哪种类型的论文？\n2. Context：它与哪些其他论文相关？使用了哪些理论基础？\n3. Correctness：结论看起来合理吗？\n4. Contributions：论文的主要贡献是什么？\n5. Clarity：这篇论文写得好吗?\n\n\n像审稿人一样思考：一般审稿人在一遍阅读后不能理解你的论文要点，这篇论文可能会被拒绝。\n\n#### 第二遍\n仔细地阅读论文，但忽略证明等细节，最多需要一个小时。\n\n- 仔细看图表和其他插图\n- 标记需要进一步阅读的相关未读参考文献\n\n#### 第三遍\n对于初学者大约需要四到五个小时，对于有经验的读者大约需要一个小时。\n\n- 能够基本复现这篇论文的工作\n\n### 进行文献调研\n使用学术搜索引擎找到该领域最近的三到五篇论文\n\n- 阅读它们的相关工作\n- 阅读最近的综述论文\n- 在参考文献中找到共享的引用和重复出现的作者名字\n- 下载关键论文（1）\n- 找出最优秀的研究者最近在哪里发表了论文\n- 访问这些顶级会议或期刊的网站，浏览他们最近的论文集\n- 确定最近的高质量相关工作（2）\n- 由（1）和（2）构成调查的第一版\n- 获取你在这些论文中没有找到的关键论文，获取并阅读它\n- 你最好写一个文献调研综述。\n","slug":"how-to-read-paper","published":1,"updated":"2024-06-20T07:59:18.685Z","comments":1,"layout":"post","photos":[],"_id":"cmh498ipx009awvougsvaadgt","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><h3 id=\"引言\"><a href=\"#引言\" class=\"headerlink\" title=\"引言\"></a>引言</h3><p>&emsp;&emsp;高效地阅读论文是一项很关键但多半没有人教你的技能。这里讲述了”三遍阅读法”及其在进行文献调查中的使用。</p>\n<h3 id=\"三遍阅读法\"><a href=\"#三遍阅读法\" class=\"headerlink\" title=\"三遍阅读法\"></a>三遍阅读法</h3><p>&emsp;&emsp;读第一遍你对论文会有一个大致的了解。读第二遍你能基本掌握论文的基本内容。读第三遍你将深入理解论文。</p>\n<h4 id=\"第一遍\"><a href=\"#第一遍\" class=\"headerlink\" title=\"第一遍\"></a>第一遍</h4><p>快速浏览，获得论文的大致内容，大约需要五到十分钟：</p>\n<ul>\n<li>仔细阅读标题、摘要和引言</li>\n<li>阅读各个章节和小节的标题，忽略其他所有内容</li>\n<li>阅读结论</li>\n<li>浏览参考文献，心里记下你已经读过的那些</li>\n</ul>\n<p>在第一遍结束时，你应该能够回答5C问题：</p>\n<ol>\n<li>Category：这是哪种类型的论文？</li>\n<li>Context：它与哪些其他论文相关？使用了哪些理论基础？</li>\n<li>Correctness：结论看起来合理吗？</li>\n<li>Contributions：论文的主要贡献是什么？</li>\n<li>Clarity：这篇论文写得好吗?</li>\n</ol>\n<p>像审稿人一样思考：一般审稿人在一遍阅读后不能理解你的论文要点，这篇论文可能会被拒绝。</p>\n<h4 id=\"第二遍\"><a href=\"#第二遍\" class=\"headerlink\" title=\"第二遍\"></a>第二遍</h4><p>仔细地阅读论文，但忽略证明等细节，最多需要一个小时。</p>\n<ul>\n<li>仔细看图表和其他插图</li>\n<li>标记需要进一步阅读的相关未读参考文献</li>\n</ul>\n<h4 id=\"第三遍\"><a href=\"#第三遍\" class=\"headerlink\" title=\"第三遍\"></a>第三遍</h4><p>对于初学者大约需要四到五个小时，对于有经验的读者大约需要一个小时。</p>\n<ul>\n<li>能够基本复现这篇论文的工作</li>\n</ul>\n<h3 id=\"进行文献调研\"><a href=\"#进行文献调研\" class=\"headerlink\" title=\"进行文献调研\"></a>进行文献调研</h3><p>使用学术搜索引擎找到该领域最近的三到五篇论文</p>\n<ul>\n<li>阅读它们的相关工作</li>\n<li>阅读最近的综述论文</li>\n<li>在参考文献中找到共享的引用和重复出现的作者名字</li>\n<li>下载关键论文（1）</li>\n<li>找出最优秀的研究者最近在哪里发表了论文</li>\n<li>访问这些顶级会议或期刊的网站，浏览他们最近的论文集</li>\n<li>确定最近的高质量相关工作（2）</li>\n<li>由（1）和（2）构成调查的第一版</li>\n<li>获取你在这些论文中没有找到的关键论文，获取并阅读它</li>\n<li>你最好写一个文献调研综述。</li>\n</ul>","related_posts":[],"length":728,"excerpt":"<p>&emsp;&emsp;如何阅读文献？Keshav S. How to Read a Paper.</p>","more":"<h3 id=\"引言\"><a href=\"#引言\" class=\"headerlink\" title=\"引言\"></a>引言</h3><p>&emsp;&emsp;高效地阅读论文是一项很关键但多半没有人教你的技能。这里讲述了”三遍阅读法”及其在进行文献调查中的使用。</p>\n<h3 id=\"三遍阅读法\"><a href=\"#三遍阅读法\" class=\"headerlink\" title=\"三遍阅读法\"></a>三遍阅读法</h3><p>&emsp;&emsp;读第一遍你对论文会有一个大致的了解。读第二遍你能基本掌握论文的基本内容。读第三遍你将深入理解论文。</p>\n<h4 id=\"第一遍\"><a href=\"#第一遍\" class=\"headerlink\" title=\"第一遍\"></a>第一遍</h4><p>快速浏览，获得论文的大致内容，大约需要五到十分钟：</p>\n<ul>\n<li>仔细阅读标题、摘要和引言</li>\n<li>阅读各个章节和小节的标题，忽略其他所有内容</li>\n<li>阅读结论</li>\n<li>浏览参考文献，心里记下你已经读过的那些</li>\n</ul>\n<p>在第一遍结束时，你应该能够回答5C问题：</p>\n<ol>\n<li>Category：这是哪种类型的论文？</li>\n<li>Context：它与哪些其他论文相关？使用了哪些理论基础？</li>\n<li>Correctness：结论看起来合理吗？</li>\n<li>Contributions：论文的主要贡献是什么？</li>\n<li>Clarity：这篇论文写得好吗?</li>\n</ol>\n<p>像审稿人一样思考：一般审稿人在一遍阅读后不能理解你的论文要点，这篇论文可能会被拒绝。</p>\n<h4 id=\"第二遍\"><a href=\"#第二遍\" class=\"headerlink\" title=\"第二遍\"></a>第二遍</h4><p>仔细地阅读论文，但忽略证明等细节，最多需要一个小时。</p>\n<ul>\n<li>仔细看图表和其他插图</li>\n<li>标记需要进一步阅读的相关未读参考文献</li>\n</ul>\n<h4 id=\"第三遍\"><a href=\"#第三遍\" class=\"headerlink\" title=\"第三遍\"></a>第三遍</h4><p>对于初学者大约需要四到五个小时，对于有经验的读者大约需要一个小时。</p>\n<ul>\n<li>能够基本复现这篇论文的工作</li>\n</ul>\n<h3 id=\"进行文献调研\"><a href=\"#进行文献调研\" class=\"headerlink\" title=\"进行文献调研\"></a>进行文献调研</h3><p>使用学术搜索引擎找到该领域最近的三到五篇论文</p>\n<ul>\n<li>阅读它们的相关工作</li>\n<li>阅读最近的综述论文</li>\n<li>在参考文献中找到共享的引用和重复出现的作者名字</li>\n<li>下载关键论文（1）</li>\n<li>找出最优秀的研究者最近在哪里发表了论文</li>\n<li>访问这些顶级会议或期刊的网站，浏览他们最近的论文集</li>\n<li>确定最近的高质量相关工作（2）</li>\n<li>由（1）和（2）构成调查的第一版</li>\n<li>获取你在这些论文中没有找到的关键论文，获取并阅读它</li>\n<li>你最好写一个文献调研综述。</li>\n</ul>"},{"title":"文献阅读（十二）","abbrlink":"a235e3ec","date":"2024-06-20T00:09:35.000Z","_content":"&emsp;&emsp;[Early Holocene Greenland-ice mass loss likely triggered earthquakes and tsunami](https://www.sciencedirect.com/science/article/pii/S0012821X20303873?dgcid=rss_sd_all)\n<!--less-->\n\n### 摘要\n\n&emsp;&emsp;由于冰盖质量巨大，会在地球地壳中引起显著的应力。研究表明，在北欧的某些地区，冰川消融过程中的应力释放可以触发大地震。尽管已经在北欧分析了冰川引起的应力，但尚未对格陵兰进行分析。我们知道格陵兰冰盖在早期全新世经历了一个大规模的融化期，我们首次分析了格陵兰在冰川消融期间的冰川诱发应力变化。结合历史海平面指标和冰川诱发断层重新激活模型的综合分析表明，大约10,600年前，格陵兰冰盖的消融可能导致了一次大地震或一系列较小震级地震。地震可能使相对海平面观测值发生了数米的偏移。地震引发的应力释放是在单一事件中产生的，它可能在北大西洋产生了高达7.2米的英国群岛上岸高度和高达7.8米的加拿大沿岸海啸。\n\n### 相关研究的重要性\n\n1. **冰盖融化与地壳应力**：冰盖的融化可以导致地壳应力的释放，进而可能触发地震活动，这对理解地球内部动力学和表面过程具有重要意义。\n2. **海平面变化与地震活动**：相对海平面的变化是研究古气候变化的重要指标，而地震活动与海平面变化之间可能存在联系。\n\n### 前人研究及不足\n\n- **北欧地区研究**：已有研究分析了北欧地区冰川消融引起的地壳应力和地震活动，例如Arvidsson (1996) 研究了Fennoscandian地区的地震活动与冰川消融的关系。\n- **格陵兰冰盖研究**：尽管格陵兰冰盖的融化速度在过去几十年有所加快，但目前尚无证据表明这与地震活动的增加有关 (Voss et al., 2007; Olivieri and Spada, 2015)。\n- **不足**：对格陵兰地区冰川消融引起的应力释放及其可能触发的地震活动的研究相对较少。\n\n### 本文使用的数据和方法\n\n- **数据**：\n  - 过去的海平面指标\n  - 格陵兰冰盖模型 (Huy3)\n  - 地球粘滞模型\n  - 海洋负荷模型\n- **方法**：\n  - 结合历史海平面数据和冰川诱导断层重新激活模型\n  - 使用有限元软件ABAQUS进行三维模型计算\n  - 应用GeoClaw软件模拟海啸动力学\n\n### 本文结果\n\n- **应力模型**：表明南格陵兰是冰川触发断层活动的最可能区域。\n- **海啸模拟**：如果地震是由单一事件引起的，可能在北大西洋产生了高达数米的海啸。\n\n### 本文创新之处和贡献\n\n- **首次分析**：首次对格陵兰地区冰川消融期间的冰川诱导应力进行了分析。\n- **综合方法**：结合了多种方法来评估冰川触发地震的可能性，并模拟了可能产生的海啸。\n\n### 本文不足\n\n- 文章中并未明确指出研究的局限性，但可能包括模型的简化假设、对冰盖融化历史和地震活动的不确定性，以及缺乏直接的地质证据来支持模型预测。\n","source":"_posts/2024-06-20-paper-reading-12.md","raw":"---\ntitle: 文献阅读（十二）\nabbrlink: a235e3ec\ndate: 2024-06-20 08:09:35\ncategories:\n  - work\ntags:\n  - paper\n---\n&emsp;&emsp;[Early Holocene Greenland-ice mass loss likely triggered earthquakes and tsunami](https://www.sciencedirect.com/science/article/pii/S0012821X20303873?dgcid=rss_sd_all)\n<!--less-->\n\n### 摘要\n\n&emsp;&emsp;由于冰盖质量巨大，会在地球地壳中引起显著的应力。研究表明，在北欧的某些地区，冰川消融过程中的应力释放可以触发大地震。尽管已经在北欧分析了冰川引起的应力，但尚未对格陵兰进行分析。我们知道格陵兰冰盖在早期全新世经历了一个大规模的融化期，我们首次分析了格陵兰在冰川消融期间的冰川诱发应力变化。结合历史海平面指标和冰川诱发断层重新激活模型的综合分析表明，大约10,600年前，格陵兰冰盖的消融可能导致了一次大地震或一系列较小震级地震。地震可能使相对海平面观测值发生了数米的偏移。地震引发的应力释放是在单一事件中产生的，它可能在北大西洋产生了高达7.2米的英国群岛上岸高度和高达7.8米的加拿大沿岸海啸。\n\n### 相关研究的重要性\n\n1. **冰盖融化与地壳应力**：冰盖的融化可以导致地壳应力的释放，进而可能触发地震活动，这对理解地球内部动力学和表面过程具有重要意义。\n2. **海平面变化与地震活动**：相对海平面的变化是研究古气候变化的重要指标，而地震活动与海平面变化之间可能存在联系。\n\n### 前人研究及不足\n\n- **北欧地区研究**：已有研究分析了北欧地区冰川消融引起的地壳应力和地震活动，例如Arvidsson (1996) 研究了Fennoscandian地区的地震活动与冰川消融的关系。\n- **格陵兰冰盖研究**：尽管格陵兰冰盖的融化速度在过去几十年有所加快，但目前尚无证据表明这与地震活动的增加有关 (Voss et al., 2007; Olivieri and Spada, 2015)。\n- **不足**：对格陵兰地区冰川消融引起的应力释放及其可能触发的地震活动的研究相对较少。\n\n### 本文使用的数据和方法\n\n- **数据**：\n  - 过去的海平面指标\n  - 格陵兰冰盖模型 (Huy3)\n  - 地球粘滞模型\n  - 海洋负荷模型\n- **方法**：\n  - 结合历史海平面数据和冰川诱导断层重新激活模型\n  - 使用有限元软件ABAQUS进行三维模型计算\n  - 应用GeoClaw软件模拟海啸动力学\n\n### 本文结果\n\n- **应力模型**：表明南格陵兰是冰川触发断层活动的最可能区域。\n- **海啸模拟**：如果地震是由单一事件引起的，可能在北大西洋产生了高达数米的海啸。\n\n### 本文创新之处和贡献\n\n- **首次分析**：首次对格陵兰地区冰川消融期间的冰川诱导应力进行了分析。\n- **综合方法**：结合了多种方法来评估冰川触发地震的可能性，并模拟了可能产生的海啸。\n\n### 本文不足\n\n- 文章中并未明确指出研究的局限性，但可能包括模型的简化假设、对冰盖融化历史和地震活动的不确定性，以及缺乏直接的地质证据来支持模型预测。\n","slug":"paper-reading-12","published":1,"updated":"2024-06-20T02:54:03.477Z","comments":1,"layout":"post","photos":[],"_id":"cmh498ipx009dwvou8dd16i3i","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><h3 id=\"摘要\"><a href=\"#摘要\" class=\"headerlink\" title=\"摘要\"></a>摘要</h3><p>&emsp;&emsp;由于冰盖质量巨大，会在地球地壳中引起显著的应力。研究表明，在北欧的某些地区，冰川消融过程中的应力释放可以触发大地震。尽管已经在北欧分析了冰川引起的应力，但尚未对格陵兰进行分析。我们知道格陵兰冰盖在早期全新世经历了一个大规模的融化期，我们首次分析了格陵兰在冰川消融期间的冰川诱发应力变化。结合历史海平面指标和冰川诱发断层重新激活模型的综合分析表明，大约10,600年前，格陵兰冰盖的消融可能导致了一次大地震或一系列较小震级地震。地震可能使相对海平面观测值发生了数米的偏移。地震引发的应力释放是在单一事件中产生的，它可能在北大西洋产生了高达7.2米的英国群岛上岸高度和高达7.8米的加拿大沿岸海啸。</p>\n<h3 id=\"相关研究的重要性\"><a href=\"#相关研究的重要性\" class=\"headerlink\" title=\"相关研究的重要性\"></a>相关研究的重要性</h3><ol>\n<li><strong>冰盖融化与地壳应力</strong>：冰盖的融化可以导致地壳应力的释放，进而可能触发地震活动，这对理解地球内部动力学和表面过程具有重要意义。</li>\n<li><strong>海平面变化与地震活动</strong>：相对海平面的变化是研究古气候变化的重要指标，而地震活动与海平面变化之间可能存在联系。</li>\n</ol>\n<h3 id=\"前人研究及不足\"><a href=\"#前人研究及不足\" class=\"headerlink\" title=\"前人研究及不足\"></a>前人研究及不足</h3><ul>\n<li><strong>北欧地区研究</strong>：已有研究分析了北欧地区冰川消融引起的地壳应力和地震活动，例如Arvidsson (1996) 研究了Fennoscandian地区的地震活动与冰川消融的关系。</li>\n<li><strong>格陵兰冰盖研究</strong>：尽管格陵兰冰盖的融化速度在过去几十年有所加快，但目前尚无证据表明这与地震活动的增加有关 (Voss et al., 2007; Olivieri and Spada, 2015)。</li>\n<li><strong>不足</strong>：对格陵兰地区冰川消融引起的应力释放及其可能触发的地震活动的研究相对较少。</li>\n</ul>\n<h3 id=\"本文使用的数据和方法\"><a href=\"#本文使用的数据和方法\" class=\"headerlink\" title=\"本文使用的数据和方法\"></a>本文使用的数据和方法</h3><ul>\n<li><strong>数据</strong>：<ul>\n<li>过去的海平面指标</li>\n<li>格陵兰冰盖模型 (Huy3)</li>\n<li>地球粘滞模型</li>\n<li>海洋负荷模型</li>\n</ul>\n</li>\n<li><strong>方法</strong>：<ul>\n<li>结合历史海平面数据和冰川诱导断层重新激活模型</li>\n<li>使用有限元软件ABAQUS进行三维模型计算</li>\n<li>应用GeoClaw软件模拟海啸动力学</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"本文结果\"><a href=\"#本文结果\" class=\"headerlink\" title=\"本文结果\"></a>本文结果</h3><ul>\n<li><strong>应力模型</strong>：表明南格陵兰是冰川触发断层活动的最可能区域。</li>\n<li><strong>海啸模拟</strong>：如果地震是由单一事件引起的，可能在北大西洋产生了高达数米的海啸。</li>\n</ul>\n<h3 id=\"本文创新之处和贡献\"><a href=\"#本文创新之处和贡献\" class=\"headerlink\" title=\"本文创新之处和贡献\"></a>本文创新之处和贡献</h3><ul>\n<li><strong>首次分析</strong>：首次对格陵兰地区冰川消融期间的冰川诱导应力进行了分析。</li>\n<li><strong>综合方法</strong>：结合了多种方法来评估冰川触发地震的可能性，并模拟了可能产生的海啸。</li>\n</ul>\n<h3 id=\"本文不足\"><a href=\"#本文不足\" class=\"headerlink\" title=\"本文不足\"></a>本文不足</h3><ul>\n<li>文章中并未明确指出研究的局限性，但可能包括模型的简化假设、对冰盖融化历史和地震活动的不确定性，以及缺乏直接的地质证据来支持模型预测。</li>\n</ul>","related_posts":["code-and-project2.html","paper-reading-15.html","paper-reading-13.html"],"length":1062,"excerpt":"<p>&emsp;&emsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0012821X20303873?dgcid=rss_sd_all\">Early Holocene Greenland-ice mass loss likely triggered earthquakes and tsunami</a></p>","more":"<h3 id=\"摘要\"><a href=\"#摘要\" class=\"headerlink\" title=\"摘要\"></a>摘要</h3><p>&emsp;&emsp;由于冰盖质量巨大，会在地球地壳中引起显著的应力。研究表明，在北欧的某些地区，冰川消融过程中的应力释放可以触发大地震。尽管已经在北欧分析了冰川引起的应力，但尚未对格陵兰进行分析。我们知道格陵兰冰盖在早期全新世经历了一个大规模的融化期，我们首次分析了格陵兰在冰川消融期间的冰川诱发应力变化。结合历史海平面指标和冰川诱发断层重新激活模型的综合分析表明，大约10,600年前，格陵兰冰盖的消融可能导致了一次大地震或一系列较小震级地震。地震可能使相对海平面观测值发生了数米的偏移。地震引发的应力释放是在单一事件中产生的，它可能在北大西洋产生了高达7.2米的英国群岛上岸高度和高达7.8米的加拿大沿岸海啸。</p>\n<h3 id=\"相关研究的重要性\"><a href=\"#相关研究的重要性\" class=\"headerlink\" title=\"相关研究的重要性\"></a>相关研究的重要性</h3><ol>\n<li><strong>冰盖融化与地壳应力</strong>：冰盖的融化可以导致地壳应力的释放，进而可能触发地震活动，这对理解地球内部动力学和表面过程具有重要意义。</li>\n<li><strong>海平面变化与地震活动</strong>：相对海平面的变化是研究古气候变化的重要指标，而地震活动与海平面变化之间可能存在联系。</li>\n</ol>\n<h3 id=\"前人研究及不足\"><a href=\"#前人研究及不足\" class=\"headerlink\" title=\"前人研究及不足\"></a>前人研究及不足</h3><ul>\n<li><strong>北欧地区研究</strong>：已有研究分析了北欧地区冰川消融引起的地壳应力和地震活动，例如Arvidsson (1996) 研究了Fennoscandian地区的地震活动与冰川消融的关系。</li>\n<li><strong>格陵兰冰盖研究</strong>：尽管格陵兰冰盖的融化速度在过去几十年有所加快，但目前尚无证据表明这与地震活动的增加有关 (Voss et al., 2007; Olivieri and Spada, 2015)。</li>\n<li><strong>不足</strong>：对格陵兰地区冰川消融引起的应力释放及其可能触发的地震活动的研究相对较少。</li>\n</ul>\n<h3 id=\"本文使用的数据和方法\"><a href=\"#本文使用的数据和方法\" class=\"headerlink\" title=\"本文使用的数据和方法\"></a>本文使用的数据和方法</h3><ul>\n<li><strong>数据</strong>：<ul>\n<li>过去的海平面指标</li>\n<li>格陵兰冰盖模型 (Huy3)</li>\n<li>地球粘滞模型</li>\n<li>海洋负荷模型</li>\n</ul>\n</li>\n<li><strong>方法</strong>：<ul>\n<li>结合历史海平面数据和冰川诱导断层重新激活模型</li>\n<li>使用有限元软件ABAQUS进行三维模型计算</li>\n<li>应用GeoClaw软件模拟海啸动力学</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"本文结果\"><a href=\"#本文结果\" class=\"headerlink\" title=\"本文结果\"></a>本文结果</h3><ul>\n<li><strong>应力模型</strong>：表明南格陵兰是冰川触发断层活动的最可能区域。</li>\n<li><strong>海啸模拟</strong>：如果地震是由单一事件引起的，可能在北大西洋产生了高达数米的海啸。</li>\n</ul>\n<h3 id=\"本文创新之处和贡献\"><a href=\"#本文创新之处和贡献\" class=\"headerlink\" title=\"本文创新之处和贡献\"></a>本文创新之处和贡献</h3><ul>\n<li><strong>首次分析</strong>：首次对格陵兰地区冰川消融期间的冰川诱导应力进行了分析。</li>\n<li><strong>综合方法</strong>：结合了多种方法来评估冰川触发地震的可能性，并模拟了可能产生的海啸。</li>\n</ul>\n<h3 id=\"本文不足\"><a href=\"#本文不足\" class=\"headerlink\" title=\"本文不足\"></a>本文不足</h3><ul>\n<li>文章中并未明确指出研究的局限性，但可能包括模型的简化假设、对冰盖融化历史和地震活动的不确定性，以及缺乏直接的地质证据来支持模型预测。</li>\n</ul>"},{"title":"文献阅读（十三）","abbrlink":"eb83720a","date":"2024-06-20T04:48:48.000Z","_content":"\n&emsp;&emsp;[Identifying Different Classes of Seismic Noise Signals Using Unsupervised Learning](https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2020GL088353?af=R)\n<!--less-->\n\n### 摘要\n\n&emsp;&emsp;适当的非构造性地震信号分类对于检测微地震和提高对持续弱地面运动的理解至关重要。我们利用无监督机器学习来标记连续波形中常见的五种非平稳地震噪声类别。描述数据的时间和频谱特征被聚类以识别可分离的紧急和脉冲波形类型。训练好的聚类模型被用来分类来自密集地震阵列的每1秒连续地震记录，站点间隔为10-30米。研究表明，主导噪声信号可以高度局部化，尺度在数百米。该方法展示了弱地面运动的复杂性，并提高了在低信噪比下分析地震波形的标准。应用这种技术将提高在嘈杂环境中检测真实微小地震事件的能力，其中地震传感器记录了来自非构造性源的类似地震信号。\n\n### 相关研究的重要性\n\n- **微地震检测**：提高微地震的检测能力有助于更好地理解断层上的故障过程。\n- **地震信号与噪声的区分**：正确区分地震信号和噪声对于地震监测和预测至关重要。\n\n### 前人研究及不足\n\n- **Aguiar & Beroza, 2014; Hammer et al., 2013; Linville et al., 2019; Mousavi et al., 2016; Perol et al., 2018; Ross, Meier, & Hauksson, 2018; Ross, Meier, Hauksson, & Heaton, 2018; Rouet-Leduc et al., 2019**：这些研究使用有监督的机器学习来识别地震、颤动、山体滑坡、雪崩和矿震等。\n- **不足**：现有研究多集中在使用有监督学习，需要大量正确标记的数据，对于新出现的或未知的信号类型识别能力有限。\n\n### 本文使用的数据和方法\n\n- **数据**：来自加利福尼亚大学圣地亚哥分校斯克里普斯海洋学研究所的密集地震阵列的连续波形数据。\n- **方法**：\n  - 使用无监督机器学习对数据进行聚类分析。\n  - 利用主成分分析（PCA）对标准化的特征向量进行降维。\n  - 应用k-means聚类算法对特征向量进行分类。\n\n### 本文结果\n\n- **识别了五种不同的噪声类别**：具有不同的频谱和时间波形属性。\n- **噪声信号的空间分布**：在密集阵列中表现出高度的局部化和变化。\n\n### 本文创新之处和贡献\n\n- **无监督学习的应用**：首次尝试在密集地震阵列中对连续波形的每一秒进行标记和评估。\n- **聚类模型**：训练的模型能够快速分类大量连续地震波形数据。\n\n### 本文不足\n\n- 文章中并未明确指出研究的局限性，但可能包括对噪声源的物理特性缺乏直接的实验验证，以及模型在不同地区或不同类型噪声的泛化能力尚未得到验证。\n\n### 数据可用性声明\n\n- 原始数据通过地震学研究机构的联合研究机构公开获取。训练数据可通过国际数字地震图网络获取。\n","source":"_posts/2024-06-20-paper-reading-13.md","raw":"---\ntitle: 文献阅读（十三）\ncategories:\n  - work\ntags:\n  - paper\nabbrlink: eb83720a\ndate: 2024-06-20 12:48:48\n---\n\n&emsp;&emsp;[Identifying Different Classes of Seismic Noise Signals Using Unsupervised Learning](https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2020GL088353?af=R)\n<!--less-->\n\n### 摘要\n\n&emsp;&emsp;适当的非构造性地震信号分类对于检测微地震和提高对持续弱地面运动的理解至关重要。我们利用无监督机器学习来标记连续波形中常见的五种非平稳地震噪声类别。描述数据的时间和频谱特征被聚类以识别可分离的紧急和脉冲波形类型。训练好的聚类模型被用来分类来自密集地震阵列的每1秒连续地震记录，站点间隔为10-30米。研究表明，主导噪声信号可以高度局部化，尺度在数百米。该方法展示了弱地面运动的复杂性，并提高了在低信噪比下分析地震波形的标准。应用这种技术将提高在嘈杂环境中检测真实微小地震事件的能力，其中地震传感器记录了来自非构造性源的类似地震信号。\n\n### 相关研究的重要性\n\n- **微地震检测**：提高微地震的检测能力有助于更好地理解断层上的故障过程。\n- **地震信号与噪声的区分**：正确区分地震信号和噪声对于地震监测和预测至关重要。\n\n### 前人研究及不足\n\n- **Aguiar & Beroza, 2014; Hammer et al., 2013; Linville et al., 2019; Mousavi et al., 2016; Perol et al., 2018; Ross, Meier, & Hauksson, 2018; Ross, Meier, Hauksson, & Heaton, 2018; Rouet-Leduc et al., 2019**：这些研究使用有监督的机器学习来识别地震、颤动、山体滑坡、雪崩和矿震等。\n- **不足**：现有研究多集中在使用有监督学习，需要大量正确标记的数据，对于新出现的或未知的信号类型识别能力有限。\n\n### 本文使用的数据和方法\n\n- **数据**：来自加利福尼亚大学圣地亚哥分校斯克里普斯海洋学研究所的密集地震阵列的连续波形数据。\n- **方法**：\n  - 使用无监督机器学习对数据进行聚类分析。\n  - 利用主成分分析（PCA）对标准化的特征向量进行降维。\n  - 应用k-means聚类算法对特征向量进行分类。\n\n### 本文结果\n\n- **识别了五种不同的噪声类别**：具有不同的频谱和时间波形属性。\n- **噪声信号的空间分布**：在密集阵列中表现出高度的局部化和变化。\n\n### 本文创新之处和贡献\n\n- **无监督学习的应用**：首次尝试在密集地震阵列中对连续波形的每一秒进行标记和评估。\n- **聚类模型**：训练的模型能够快速分类大量连续地震波形数据。\n\n### 本文不足\n\n- 文章中并未明确指出研究的局限性，但可能包括对噪声源的物理特性缺乏直接的实验验证，以及模型在不同地区或不同类型噪声的泛化能力尚未得到验证。\n\n### 数据可用性声明\n\n- 原始数据通过地震学研究机构的联合研究机构公开获取。训练数据可通过国际数字地震图网络获取。\n","slug":"paper-reading-13","published":1,"updated":"2024-06-20T06:57:26.048Z","comments":1,"layout":"post","photos":[],"_id":"cmh498ipy009hwvou4abq4acv","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><h3 id=\"摘要\"><a href=\"#摘要\" class=\"headerlink\" title=\"摘要\"></a>摘要</h3><p>&emsp;&emsp;适当的非构造性地震信号分类对于检测微地震和提高对持续弱地面运动的理解至关重要。我们利用无监督机器学习来标记连续波形中常见的五种非平稳地震噪声类别。描述数据的时间和频谱特征被聚类以识别可分离的紧急和脉冲波形类型。训练好的聚类模型被用来分类来自密集地震阵列的每1秒连续地震记录，站点间隔为10-30米。研究表明，主导噪声信号可以高度局部化，尺度在数百米。该方法展示了弱地面运动的复杂性，并提高了在低信噪比下分析地震波形的标准。应用这种技术将提高在嘈杂环境中检测真实微小地震事件的能力，其中地震传感器记录了来自非构造性源的类似地震信号。</p>\n<h3 id=\"相关研究的重要性\"><a href=\"#相关研究的重要性\" class=\"headerlink\" title=\"相关研究的重要性\"></a>相关研究的重要性</h3><ul>\n<li><strong>微地震检测</strong>：提高微地震的检测能力有助于更好地理解断层上的故障过程。</li>\n<li><strong>地震信号与噪声的区分</strong>：正确区分地震信号和噪声对于地震监测和预测至关重要。</li>\n</ul>\n<h3 id=\"前人研究及不足\"><a href=\"#前人研究及不足\" class=\"headerlink\" title=\"前人研究及不足\"></a>前人研究及不足</h3><ul>\n<li><strong>Aguiar &amp; Beroza, 2014; Hammer et al., 2013; Linville et al., 2019; Mousavi et al., 2016; Perol et al., 2018; Ross, Meier, &amp; Hauksson, 2018; Ross, Meier, Hauksson, &amp; Heaton, 2018; Rouet-Leduc et al., 2019</strong>：这些研究使用有监督的机器学习来识别地震、颤动、山体滑坡、雪崩和矿震等。</li>\n<li><strong>不足</strong>：现有研究多集中在使用有监督学习，需要大量正确标记的数据，对于新出现的或未知的信号类型识别能力有限。</li>\n</ul>\n<h3 id=\"本文使用的数据和方法\"><a href=\"#本文使用的数据和方法\" class=\"headerlink\" title=\"本文使用的数据和方法\"></a>本文使用的数据和方法</h3><ul>\n<li><strong>数据</strong>：来自加利福尼亚大学圣地亚哥分校斯克里普斯海洋学研究所的密集地震阵列的连续波形数据。</li>\n<li><strong>方法</strong>：<ul>\n<li>使用无监督机器学习对数据进行聚类分析。</li>\n<li>利用主成分分析（PCA）对标准化的特征向量进行降维。</li>\n<li>应用k-means聚类算法对特征向量进行分类。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"本文结果\"><a href=\"#本文结果\" class=\"headerlink\" title=\"本文结果\"></a>本文结果</h3><ul>\n<li><strong>识别了五种不同的噪声类别</strong>：具有不同的频谱和时间波形属性。</li>\n<li><strong>噪声信号的空间分布</strong>：在密集阵列中表现出高度的局部化和变化。</li>\n</ul>\n<h3 id=\"本文创新之处和贡献\"><a href=\"#本文创新之处和贡献\" class=\"headerlink\" title=\"本文创新之处和贡献\"></a>本文创新之处和贡献</h3><ul>\n<li><strong>无监督学习的应用</strong>：首次尝试在密集地震阵列中对连续波形的每一秒进行标记和评估。</li>\n<li><strong>聚类模型</strong>：训练的模型能够快速分类大量连续地震波形数据。</li>\n</ul>\n<h3 id=\"本文不足\"><a href=\"#本文不足\" class=\"headerlink\" title=\"本文不足\"></a>本文不足</h3><ul>\n<li>文章中并未明确指出研究的局限性，但可能包括对噪声源的物理特性缺乏直接的实验验证，以及模型在不同地区或不同类型噪声的泛化能力尚未得到验证。</li>\n</ul>\n<h3 id=\"数据可用性声明\"><a href=\"#数据可用性声明\" class=\"headerlink\" title=\"数据可用性声明\"></a>数据可用性声明</h3><ul>\n<li>原始数据通过地震学研究机构的联合研究机构公开获取。训练数据可通过国际数字地震图网络获取。</li>\n</ul>","related_posts":["paper-reading-11.html","code-and-project1.html","paper-reading-12.html"],"length":1100,"excerpt":"<p>&emsp;&emsp;<a href=\"https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2020GL088353?af=R\">Identifying Different Classes of Seismic Noise Signals Using Unsupervised Learning</a></p>","more":"<h3 id=\"摘要\"><a href=\"#摘要\" class=\"headerlink\" title=\"摘要\"></a>摘要</h3><p>&emsp;&emsp;适当的非构造性地震信号分类对于检测微地震和提高对持续弱地面运动的理解至关重要。我们利用无监督机器学习来标记连续波形中常见的五种非平稳地震噪声类别。描述数据的时间和频谱特征被聚类以识别可分离的紧急和脉冲波形类型。训练好的聚类模型被用来分类来自密集地震阵列的每1秒连续地震记录，站点间隔为10-30米。研究表明，主导噪声信号可以高度局部化，尺度在数百米。该方法展示了弱地面运动的复杂性，并提高了在低信噪比下分析地震波形的标准。应用这种技术将提高在嘈杂环境中检测真实微小地震事件的能力，其中地震传感器记录了来自非构造性源的类似地震信号。</p>\n<h3 id=\"相关研究的重要性\"><a href=\"#相关研究的重要性\" class=\"headerlink\" title=\"相关研究的重要性\"></a>相关研究的重要性</h3><ul>\n<li><strong>微地震检测</strong>：提高微地震的检测能力有助于更好地理解断层上的故障过程。</li>\n<li><strong>地震信号与噪声的区分</strong>：正确区分地震信号和噪声对于地震监测和预测至关重要。</li>\n</ul>\n<h3 id=\"前人研究及不足\"><a href=\"#前人研究及不足\" class=\"headerlink\" title=\"前人研究及不足\"></a>前人研究及不足</h3><ul>\n<li><strong>Aguiar &amp; Beroza, 2014; Hammer et al., 2013; Linville et al., 2019; Mousavi et al., 2016; Perol et al., 2018; Ross, Meier, &amp; Hauksson, 2018; Ross, Meier, Hauksson, &amp; Heaton, 2018; Rouet-Leduc et al., 2019</strong>：这些研究使用有监督的机器学习来识别地震、颤动、山体滑坡、雪崩和矿震等。</li>\n<li><strong>不足</strong>：现有研究多集中在使用有监督学习，需要大量正确标记的数据，对于新出现的或未知的信号类型识别能力有限。</li>\n</ul>\n<h3 id=\"本文使用的数据和方法\"><a href=\"#本文使用的数据和方法\" class=\"headerlink\" title=\"本文使用的数据和方法\"></a>本文使用的数据和方法</h3><ul>\n<li><strong>数据</strong>：来自加利福尼亚大学圣地亚哥分校斯克里普斯海洋学研究所的密集地震阵列的连续波形数据。</li>\n<li><strong>方法</strong>：<ul>\n<li>使用无监督机器学习对数据进行聚类分析。</li>\n<li>利用主成分分析（PCA）对标准化的特征向量进行降维。</li>\n<li>应用k-means聚类算法对特征向量进行分类。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"本文结果\"><a href=\"#本文结果\" class=\"headerlink\" title=\"本文结果\"></a>本文结果</h3><ul>\n<li><strong>识别了五种不同的噪声类别</strong>：具有不同的频谱和时间波形属性。</li>\n<li><strong>噪声信号的空间分布</strong>：在密集阵列中表现出高度的局部化和变化。</li>\n</ul>\n<h3 id=\"本文创新之处和贡献\"><a href=\"#本文创新之处和贡献\" class=\"headerlink\" title=\"本文创新之处和贡献\"></a>本文创新之处和贡献</h3><ul>\n<li><strong>无监督学习的应用</strong>：首次尝试在密集地震阵列中对连续波形的每一秒进行标记和评估。</li>\n<li><strong>聚类模型</strong>：训练的模型能够快速分类大量连续地震波形数据。</li>\n</ul>\n<h3 id=\"本文不足\"><a href=\"#本文不足\" class=\"headerlink\" title=\"本文不足\"></a>本文不足</h3><ul>\n<li>文章中并未明确指出研究的局限性，但可能包括对噪声源的物理特性缺乏直接的实验验证，以及模型在不同地区或不同类型噪声的泛化能力尚未得到验证。</li>\n</ul>\n<h3 id=\"数据可用性声明\"><a href=\"#数据可用性声明\" class=\"headerlink\" title=\"数据可用性声明\"></a>数据可用性声明</h3><ul>\n<li>原始数据通过地震学研究机构的联合研究机构公开获取。训练数据可通过国际数字地震图网络获取。</li>\n</ul>"},{"title":"哪里去了解科学研究趋势","abbrlink":"b51aee94","date":"2024-06-20T06:25:21.000Z","_content":"&emsp;&emsp;做科研肯定不能闭门造车。那怎么了解研究趋势，热点问题呢？\n<!--less-->\n&emsp;&emsp;自然是要发挥你的主观能动性了。事在人为，干就完了。如果你实在不知道怎么开始干的话，那就看看下面的建议：\n1. 首先肯定是关注你的相关研究的期刊了。例如：[EPSL](https://www.sciencedirect.com/journal/earth-and-planetary-science-letters)，[GRL](https://agupubs.onlinelibrary.wiley.com/journal/19448007)，[JRG: Solid Earth](https://agupubs.onlinelibrary.wiley.com/journal/21699356)，[SRL](https://www.seismosoc.org/publications/srl/)，[GJI](https://academic.oup.com/gji/)等。每次都跑去点开人家主页显然是比较麻烦的。\n那有没有简单的方法呢？自然是有的。你需要RSS(Really Simple Syndication)，他是一种描述和同步网站内容的格式。找一个你喜欢的RSS工具。然后在里面订阅不同网站的RSS源，然后她会定时推送新的内容给你。RSS源一般在每个期刊主页都可以找到。你可以在一个地方坐拥万千稿件和信息。每天点开打卡，审批奏折。\n以前我用的是google reader，后来不对咱开放了，然后换到feedly。结果后来又封了。试了很多rss工具，都不太喜欢。最后用的是[FreshRSS](https://rss.othing.xyz/)，好像是一个小朋友整的个人网站。界面很简洁，是我的风格。\n2. 除了自己去读期刊发表的相关研究，自然可以请别人帮你读。哪里去找呢？我找到了这个几个：\n - [Science blogs1](https://www.science.org/blogs)，[Science blogs2](https://scienceblogs.com/)\n - [Nature blogs](https://blogs.nature.com/) Nature的博客。但感觉不怎更新了。\n - [phys.org](https://phys.org/)这里更多的是物理学领域的内容。\n - [NASA blogs](https://blogs.nasa.gov/)\n - [Science Buddies](https://www.sciencebuddies.org/)\n - [Popular Science](https://www.popsci.com/)\n - [The planetary socity](https://www.planetary.org/articles)\n - [Science Friday](https://www.sciencefriday.com/series/educator-collaborative/)\n - [科学网](https://blog.sciencenet.cn/blog.php)这里有好多熟人，名人，新论文，博客等。\n - [Berkeley Seismology Lab](https://www.seismo.berkeley.edu/blog/index.html)\n - [PNSN](https://www.pnsn.org/blog)\n - [Landslide blog](https://eos.org/landslide-blog)\n - [Geospace](https://blogs.agu.org/geospace)\n - [EarthObservatory](https://earthobservatory.nasa.gov/blogs/)\n - [Volcanodiscovery](https://www.volcanodiscovery.com/earthquakes/news.html)\n3. 开会。多开会，你会看到一手的研究，见到你读到的文章的作者，你的idol，你的网友，审你稿件的大小牛，甚至你的未来老板，好友等等。多开会，你会有非常多的视角，兼听则明。\n4. 多和课题组，实验室的同学，学长，学姐，老师交流。你以为的问题，有时可能就不是问题。\n","source":"_posts/2024-06-20-science-blogs.md","raw":"---\ntitle: 哪里去了解科学研究趋势\ncategories:\n  - work\ntags:\n  - blogs\n  - science\nabbrlink: b51aee94\ndate: 2024-06-20 14:25:21\n---\n&emsp;&emsp;做科研肯定不能闭门造车。那怎么了解研究趋势，热点问题呢？\n<!--less-->\n&emsp;&emsp;自然是要发挥你的主观能动性了。事在人为，干就完了。如果你实在不知道怎么开始干的话，那就看看下面的建议：\n1. 首先肯定是关注你的相关研究的期刊了。例如：[EPSL](https://www.sciencedirect.com/journal/earth-and-planetary-science-letters)，[GRL](https://agupubs.onlinelibrary.wiley.com/journal/19448007)，[JRG: Solid Earth](https://agupubs.onlinelibrary.wiley.com/journal/21699356)，[SRL](https://www.seismosoc.org/publications/srl/)，[GJI](https://academic.oup.com/gji/)等。每次都跑去点开人家主页显然是比较麻烦的。\n那有没有简单的方法呢？自然是有的。你需要RSS(Really Simple Syndication)，他是一种描述和同步网站内容的格式。找一个你喜欢的RSS工具。然后在里面订阅不同网站的RSS源，然后她会定时推送新的内容给你。RSS源一般在每个期刊主页都可以找到。你可以在一个地方坐拥万千稿件和信息。每天点开打卡，审批奏折。\n以前我用的是google reader，后来不对咱开放了，然后换到feedly。结果后来又封了。试了很多rss工具，都不太喜欢。最后用的是[FreshRSS](https://rss.othing.xyz/)，好像是一个小朋友整的个人网站。界面很简洁，是我的风格。\n2. 除了自己去读期刊发表的相关研究，自然可以请别人帮你读。哪里去找呢？我找到了这个几个：\n - [Science blogs1](https://www.science.org/blogs)，[Science blogs2](https://scienceblogs.com/)\n - [Nature blogs](https://blogs.nature.com/) Nature的博客。但感觉不怎更新了。\n - [phys.org](https://phys.org/)这里更多的是物理学领域的内容。\n - [NASA blogs](https://blogs.nasa.gov/)\n - [Science Buddies](https://www.sciencebuddies.org/)\n - [Popular Science](https://www.popsci.com/)\n - [The planetary socity](https://www.planetary.org/articles)\n - [Science Friday](https://www.sciencefriday.com/series/educator-collaborative/)\n - [科学网](https://blog.sciencenet.cn/blog.php)这里有好多熟人，名人，新论文，博客等。\n - [Berkeley Seismology Lab](https://www.seismo.berkeley.edu/blog/index.html)\n - [PNSN](https://www.pnsn.org/blog)\n - [Landslide blog](https://eos.org/landslide-blog)\n - [Geospace](https://blogs.agu.org/geospace)\n - [EarthObservatory](https://earthobservatory.nasa.gov/blogs/)\n - [Volcanodiscovery](https://www.volcanodiscovery.com/earthquakes/news.html)\n3. 开会。多开会，你会看到一手的研究，见到你读到的文章的作者，你的idol，你的网友，审你稿件的大小牛，甚至你的未来老板，好友等等。多开会，你会有非常多的视角，兼听则明。\n4. 多和课题组，实验室的同学，学长，学姐，老师交流。你以为的问题，有时可能就不是问题。\n","slug":"science-blogs","published":1,"updated":"2024-08-06T01:00:22.636Z","comments":1,"layout":"post","photos":[],"_id":"cmh498ipy009kwvoud8jffz90","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>&emsp;&emsp;自然是要发挥你的主观能动性了。事在人为，干就完了。如果你实在不知道怎么开始干的话，那就看看下面的建议：</p>\n<ol>\n<li>首先肯定是关注你的相关研究的期刊了。例如：<a href=\"https://www.sciencedirect.com/journal/earth-and-planetary-science-letters\">EPSL</a>，<a href=\"https://agupubs.onlinelibrary.wiley.com/journal/19448007\">GRL</a>，<a href=\"https://agupubs.onlinelibrary.wiley.com/journal/21699356\">JRG: Solid Earth</a>，<a href=\"https://www.seismosoc.org/publications/srl/\">SRL</a>，<a href=\"https://academic.oup.com/gji/\">GJI</a>等。每次都跑去点开人家主页显然是比较麻烦的。<br>那有没有简单的方法呢？自然是有的。你需要RSS(Really Simple Syndication)，他是一种描述和同步网站内容的格式。找一个你喜欢的RSS工具。然后在里面订阅不同网站的RSS源，然后她会定时推送新的内容给你。RSS源一般在每个期刊主页都可以找到。你可以在一个地方坐拥万千稿件和信息。每天点开打卡，审批奏折。<br>以前我用的是google reader，后来不对咱开放了，然后换到feedly。结果后来又封了。试了很多rss工具，都不太喜欢。最后用的是<a href=\"https://rss.othing.xyz/\">FreshRSS</a>，好像是一个小朋友整的个人网站。界面很简洁，是我的风格。</li>\n<li>除了自己去读期刊发表的相关研究，自然可以请别人帮你读。哪里去找呢？我找到了这个几个：</li>\n</ol>\n<ul>\n<li><a href=\"https://www.science.org/blogs\">Science blogs1</a>，<a href=\"https://scienceblogs.com/\">Science blogs2</a></li>\n<li><a href=\"https://blogs.nature.com/\">Nature blogs</a> Nature的博客。但感觉不怎更新了。</li>\n<li><a href=\"https://phys.org/\">phys.org</a>这里更多的是物理学领域的内容。</li>\n<li><a href=\"https://blogs.nasa.gov/\">NASA blogs</a></li>\n<li><a href=\"https://www.sciencebuddies.org/\">Science Buddies</a></li>\n<li><a href=\"https://www.popsci.com/\">Popular Science</a></li>\n<li><a href=\"https://www.planetary.org/articles\">The planetary socity</a></li>\n<li><a href=\"https://www.sciencefriday.com/series/educator-collaborative/\">Science Friday</a></li>\n<li><a href=\"https://blog.sciencenet.cn/blog.php\">科学网</a>这里有好多熟人，名人，新论文，博客等。</li>\n<li><a href=\"https://www.seismo.berkeley.edu/blog/index.html\">Berkeley Seismology Lab</a></li>\n<li><a href=\"https://www.pnsn.org/blog\">PNSN</a></li>\n<li><a href=\"https://eos.org/landslide-blog\">Landslide blog</a></li>\n<li><a href=\"https://blogs.agu.org/geospace\">Geospace</a></li>\n<li><a href=\"https://earthobservatory.nasa.gov/blogs/\">EarthObservatory</a></li>\n<li><a href=\"https://www.volcanodiscovery.com/earthquakes/news.html\">Volcanodiscovery</a></li>\n</ul>\n<ol start=\"3\">\n<li>开会。多开会，你会看到一手的研究，见到你读到的文章的作者，你的idol，你的网友，审你稿件的大小牛，甚至你的未来老板，好友等等。多开会，你会有非常多的视角，兼听则明。</li>\n<li>多和课题组，实验室的同学，学长，学姐，老师交流。你以为的问题，有时可能就不是问题。</li>\n</ol>","related_posts":["code-and-project1.html","fedora-install-freshress.html"],"length":855,"excerpt":"<p>&emsp;&emsp;做科研肯定不能闭门造车。那怎么了解研究趋势，热点问题呢？</p>","more":"<p>&emsp;&emsp;自然是要发挥你的主观能动性了。事在人为，干就完了。如果你实在不知道怎么开始干的话，那就看看下面的建议：</p>\n<ol>\n<li>首先肯定是关注你的相关研究的期刊了。例如：<a href=\"https://www.sciencedirect.com/journal/earth-and-planetary-science-letters\">EPSL</a>，<a href=\"https://agupubs.onlinelibrary.wiley.com/journal/19448007\">GRL</a>，<a href=\"https://agupubs.onlinelibrary.wiley.com/journal/21699356\">JRG: Solid Earth</a>，<a href=\"https://www.seismosoc.org/publications/srl/\">SRL</a>，<a href=\"https://academic.oup.com/gji/\">GJI</a>等。每次都跑去点开人家主页显然是比较麻烦的。<br>那有没有简单的方法呢？自然是有的。你需要RSS(Really Simple Syndication)，他是一种描述和同步网站内容的格式。找一个你喜欢的RSS工具。然后在里面订阅不同网站的RSS源，然后她会定时推送新的内容给你。RSS源一般在每个期刊主页都可以找到。你可以在一个地方坐拥万千稿件和信息。每天点开打卡，审批奏折。<br>以前我用的是google reader，后来不对咱开放了，然后换到feedly。结果后来又封了。试了很多rss工具，都不太喜欢。最后用的是<a href=\"https://rss.othing.xyz/\">FreshRSS</a>，好像是一个小朋友整的个人网站。界面很简洁，是我的风格。</li>\n<li>除了自己去读期刊发表的相关研究，自然可以请别人帮你读。哪里去找呢？我找到了这个几个：</li>\n</ol>\n<ul>\n<li><a href=\"https://www.science.org/blogs\">Science blogs1</a>，<a href=\"https://scienceblogs.com/\">Science blogs2</a></li>\n<li><a href=\"https://blogs.nature.com/\">Nature blogs</a> Nature的博客。但感觉不怎更新了。</li>\n<li><a href=\"https://phys.org/\">phys.org</a>这里更多的是物理学领域的内容。</li>\n<li><a href=\"https://blogs.nasa.gov/\">NASA blogs</a></li>\n<li><a href=\"https://www.sciencebuddies.org/\">Science Buddies</a></li>\n<li><a href=\"https://www.popsci.com/\">Popular Science</a></li>\n<li><a href=\"https://www.planetary.org/articles\">The planetary socity</a></li>\n<li><a href=\"https://www.sciencefriday.com/series/educator-collaborative/\">Science Friday</a></li>\n<li><a href=\"https://blog.sciencenet.cn/blog.php\">科学网</a>这里有好多熟人，名人，新论文，博客等。</li>\n<li><a href=\"https://www.seismo.berkeley.edu/blog/index.html\">Berkeley Seismology Lab</a></li>\n<li><a href=\"https://www.pnsn.org/blog\">PNSN</a></li>\n<li><a href=\"https://eos.org/landslide-blog\">Landslide blog</a></li>\n<li><a href=\"https://blogs.agu.org/geospace\">Geospace</a></li>\n<li><a href=\"https://earthobservatory.nasa.gov/blogs/\">EarthObservatory</a></li>\n<li><a href=\"https://www.volcanodiscovery.com/earthquakes/news.html\">Volcanodiscovery</a></li>\n</ul>\n<ol start=\"3\">\n<li>开会。多开会，你会看到一手的研究，见到你读到的文章的作者，你的idol，你的网友，审你稿件的大小牛，甚至你的未来老板，好友等等。多开会，你会有非常多的视角，兼听则明。</li>\n<li>多和课题组，实验室的同学，学长，学姐，老师交流。你以为的问题，有时可能就不是问题。</li>\n</ol>"},{"title":"文献阅读（十四）","abbrlink":"5cae6b6f","date":"2024-06-22T02:41:33.000Z","_content":"&emsp;&emsp;[Glacier Retreat in Eastern Himalaya Drives Catastrophic Glacier Hazard Chain](https://agupubs.onlinelibrary.wiley.com/doi/10.1029/2024GL108202?af=R)\n<!--less-->\n### 摘要\n\n&emsp;&emsp;气候变暖导致的冰冻圈响应包括冰川退缩、海拔依赖的热不稳定性以及丰富的融水，这些增加了灾难性冰川灾害链（CGHC）事件的频率。本研究调查了2018年发生在中国喜马拉雅山东部的色东普冰川的一种特殊CGHC事件的形成机制。基于多源遥感、地震信号分析和数值模拟，我们进行了长期的回顾性分析和事件过程重建。结果表明，该事件可分为两个阶段。首先，一个体积为8.5×10^6立方米的悬挂冰川坍塌到下游的主冰川上。接下来，约1.17×10^8立方米的侵蚀物质从受冲击的冰川转变成为泥石流，并沿下游流动了8公里。在级联过程中，冰-岩崩落动量和冰川速度是决定CGHC形成和最终体积的关键因素。我们的研究有助于更好地理解CGHC灾害的多米诺效应。\n\n### 相关研究的重要性\n\n- **气候变化对冰冻圈的影响**：冰川退缩和相关的灾害链事件对下游社区可能产生灾难性后果。\n- **冰川灾害链（CGHC）**：对CGHC事件的理解有助于改进灾害风险评估和减灾措施。\n\n### 前人研究及不足\n\n- **Chiarle et al., 2007; Evans & Delaney, 2015; Lutz et al., 2014**：研究了冰川化环境中的大规模流动，包括由融水引起的摩擦减弱、高速度和长距离运动。\n- **Scherler et al., 2011**：研究了全球变暖如何重塑和动员冰川系统，导致冰川相关大规模流动的频率增加。\n- **不足**：现有研究对CGHC事件的物理过程和对气候变化的响应理解不足。\n\n### 本文使用的数据和方法\n\n- **数据**：\n  - 多源遥感数据，包括光学和合成孔径雷达（SAR）图像。\n  - 气象站数据和全球降水测量任务（GPM IMERG v6）降水数据。\n  - 地震记录数据，来自围绕色东普的11个宽频带地震站的网络。\n- **方法**：\n  - 应用相关匹配算法追踪Landsat/Sentinel-2图像中的亚像素偏移。\n  - 使用数值方法基于热力学耦合解决冰川运动。\n  - 利用地形重建和质量运动解释来揭示2018年CGHC事件的动态过程。\n\n### 本文结果\n\n- **气候变化和冰川退缩**：自1970年代以来，青藏高原的年平均气温每十年上升0.32°C，是全球平均水平的两倍。\n- **动态过程和地貌特征**：CGHC事件包括冰-岩崩落和随后的泥石流过程，具有超流动性和体积显著增加。\n\n### 本文创新之处和贡献\n\n- **CGHC事件的详细重建**：提供了2018年CGHC事件形成、演变和运动过程的详细重建。\n- **气候变化对CGHC的影响**：分析了气候变化如何通过增加冰川融化和降水来促进CGHC事件。\n\n### 本文不足\n\n- 文章中并未明确指出研究的局限性，但可能包括对冰川动态和CGHC事件复杂性的进一步理解需要更多的实地观测和数据。\n","source":"_posts/2024-06-22-paper-reading-14.md","raw":"---\ntitle: 文献阅读（十四）\ncategories:\n  - work\ntags:\n  - paper\nabbrlink: 5cae6b6f\ndate: 2024-06-22 10:41:33\n---\n&emsp;&emsp;[Glacier Retreat in Eastern Himalaya Drives Catastrophic Glacier Hazard Chain](https://agupubs.onlinelibrary.wiley.com/doi/10.1029/2024GL108202?af=R)\n<!--less-->\n### 摘要\n\n&emsp;&emsp;气候变暖导致的冰冻圈响应包括冰川退缩、海拔依赖的热不稳定性以及丰富的融水，这些增加了灾难性冰川灾害链（CGHC）事件的频率。本研究调查了2018年发生在中国喜马拉雅山东部的色东普冰川的一种特殊CGHC事件的形成机制。基于多源遥感、地震信号分析和数值模拟，我们进行了长期的回顾性分析和事件过程重建。结果表明，该事件可分为两个阶段。首先，一个体积为8.5×10^6立方米的悬挂冰川坍塌到下游的主冰川上。接下来，约1.17×10^8立方米的侵蚀物质从受冲击的冰川转变成为泥石流，并沿下游流动了8公里。在级联过程中，冰-岩崩落动量和冰川速度是决定CGHC形成和最终体积的关键因素。我们的研究有助于更好地理解CGHC灾害的多米诺效应。\n\n### 相关研究的重要性\n\n- **气候变化对冰冻圈的影响**：冰川退缩和相关的灾害链事件对下游社区可能产生灾难性后果。\n- **冰川灾害链（CGHC）**：对CGHC事件的理解有助于改进灾害风险评估和减灾措施。\n\n### 前人研究及不足\n\n- **Chiarle et al., 2007; Evans & Delaney, 2015; Lutz et al., 2014**：研究了冰川化环境中的大规模流动，包括由融水引起的摩擦减弱、高速度和长距离运动。\n- **Scherler et al., 2011**：研究了全球变暖如何重塑和动员冰川系统，导致冰川相关大规模流动的频率增加。\n- **不足**：现有研究对CGHC事件的物理过程和对气候变化的响应理解不足。\n\n### 本文使用的数据和方法\n\n- **数据**：\n  - 多源遥感数据，包括光学和合成孔径雷达（SAR）图像。\n  - 气象站数据和全球降水测量任务（GPM IMERG v6）降水数据。\n  - 地震记录数据，来自围绕色东普的11个宽频带地震站的网络。\n- **方法**：\n  - 应用相关匹配算法追踪Landsat/Sentinel-2图像中的亚像素偏移。\n  - 使用数值方法基于热力学耦合解决冰川运动。\n  - 利用地形重建和质量运动解释来揭示2018年CGHC事件的动态过程。\n\n### 本文结果\n\n- **气候变化和冰川退缩**：自1970年代以来，青藏高原的年平均气温每十年上升0.32°C，是全球平均水平的两倍。\n- **动态过程和地貌特征**：CGHC事件包括冰-岩崩落和随后的泥石流过程，具有超流动性和体积显著增加。\n\n### 本文创新之处和贡献\n\n- **CGHC事件的详细重建**：提供了2018年CGHC事件形成、演变和运动过程的详细重建。\n- **气候变化对CGHC的影响**：分析了气候变化如何通过增加冰川融化和降水来促进CGHC事件。\n\n### 本文不足\n\n- 文章中并未明确指出研究的局限性，但可能包括对冰川动态和CGHC事件复杂性的进一步理解需要更多的实地观测和数据。\n","slug":"paper-reading-14","published":1,"updated":"2024-06-22T02:56:39.302Z","comments":1,"layout":"post","photos":[],"_id":"cmh498ipy009owvoua09v1k7i","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><h3 id=\"摘要\"><a href=\"#摘要\" class=\"headerlink\" title=\"摘要\"></a>摘要</h3><p>&emsp;&emsp;气候变暖导致的冰冻圈响应包括冰川退缩、海拔依赖的热不稳定性以及丰富的融水，这些增加了灾难性冰川灾害链（CGHC）事件的频率。本研究调查了2018年发生在中国喜马拉雅山东部的色东普冰川的一种特殊CGHC事件的形成机制。基于多源遥感、地震信号分析和数值模拟，我们进行了长期的回顾性分析和事件过程重建。结果表明，该事件可分为两个阶段。首先，一个体积为8.5×10^6立方米的悬挂冰川坍塌到下游的主冰川上。接下来，约1.17×10^8立方米的侵蚀物质从受冲击的冰川转变成为泥石流，并沿下游流动了8公里。在级联过程中，冰-岩崩落动量和冰川速度是决定CGHC形成和最终体积的关键因素。我们的研究有助于更好地理解CGHC灾害的多米诺效应。</p>\n<h3 id=\"相关研究的重要性\"><a href=\"#相关研究的重要性\" class=\"headerlink\" title=\"相关研究的重要性\"></a>相关研究的重要性</h3><ul>\n<li><strong>气候变化对冰冻圈的影响</strong>：冰川退缩和相关的灾害链事件对下游社区可能产生灾难性后果。</li>\n<li><strong>冰川灾害链（CGHC）</strong>：对CGHC事件的理解有助于改进灾害风险评估和减灾措施。</li>\n</ul>\n<h3 id=\"前人研究及不足\"><a href=\"#前人研究及不足\" class=\"headerlink\" title=\"前人研究及不足\"></a>前人研究及不足</h3><ul>\n<li><strong>Chiarle et al., 2007; Evans &amp; Delaney, 2015; Lutz et al., 2014</strong>：研究了冰川化环境中的大规模流动，包括由融水引起的摩擦减弱、高速度和长距离运动。</li>\n<li><strong>Scherler et al., 2011</strong>：研究了全球变暖如何重塑和动员冰川系统，导致冰川相关大规模流动的频率增加。</li>\n<li><strong>不足</strong>：现有研究对CGHC事件的物理过程和对气候变化的响应理解不足。</li>\n</ul>\n<h3 id=\"本文使用的数据和方法\"><a href=\"#本文使用的数据和方法\" class=\"headerlink\" title=\"本文使用的数据和方法\"></a>本文使用的数据和方法</h3><ul>\n<li><strong>数据</strong>：<ul>\n<li>多源遥感数据，包括光学和合成孔径雷达（SAR）图像。</li>\n<li>气象站数据和全球降水测量任务（GPM IMERG v6）降水数据。</li>\n<li>地震记录数据，来自围绕色东普的11个宽频带地震站的网络。</li>\n</ul>\n</li>\n<li><strong>方法</strong>：<ul>\n<li>应用相关匹配算法追踪Landsat&#x2F;Sentinel-2图像中的亚像素偏移。</li>\n<li>使用数值方法基于热力学耦合解决冰川运动。</li>\n<li>利用地形重建和质量运动解释来揭示2018年CGHC事件的动态过程。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"本文结果\"><a href=\"#本文结果\" class=\"headerlink\" title=\"本文结果\"></a>本文结果</h3><ul>\n<li><strong>气候变化和冰川退缩</strong>：自1970年代以来，青藏高原的年平均气温每十年上升0.32°C，是全球平均水平的两倍。</li>\n<li><strong>动态过程和地貌特征</strong>：CGHC事件包括冰-岩崩落和随后的泥石流过程，具有超流动性和体积显著增加。</li>\n</ul>\n<h3 id=\"本文创新之处和贡献\"><a href=\"#本文创新之处和贡献\" class=\"headerlink\" title=\"本文创新之处和贡献\"></a>本文创新之处和贡献</h3><ul>\n<li><strong>CGHC事件的详细重建</strong>：提供了2018年CGHC事件形成、演变和运动过程的详细重建。</li>\n<li><strong>气候变化对CGHC的影响</strong>：分析了气候变化如何通过增加冰川融化和降水来促进CGHC事件。</li>\n</ul>\n<h3 id=\"本文不足\"><a href=\"#本文不足\" class=\"headerlink\" title=\"本文不足\"></a>本文不足</h3><ul>\n<li>文章中并未明确指出研究的局限性，但可能包括对冰川动态和CGHC事件复杂性的进一步理解需要更多的实地观测和数据。</li>\n</ul>","related_posts":[],"length":1136,"excerpt":"<p>&emsp;&emsp;<a href=\"https://agupubs.onlinelibrary.wiley.com/doi/10.1029/2024GL108202?af=R\">Glacier Retreat in Eastern Himalaya Drives Catastrophic Glacier Hazard Chain</a></p>","more":"<h3 id=\"摘要\"><a href=\"#摘要\" class=\"headerlink\" title=\"摘要\"></a>摘要</h3><p>&emsp;&emsp;气候变暖导致的冰冻圈响应包括冰川退缩、海拔依赖的热不稳定性以及丰富的融水，这些增加了灾难性冰川灾害链（CGHC）事件的频率。本研究调查了2018年发生在中国喜马拉雅山东部的色东普冰川的一种特殊CGHC事件的形成机制。基于多源遥感、地震信号分析和数值模拟，我们进行了长期的回顾性分析和事件过程重建。结果表明，该事件可分为两个阶段。首先，一个体积为8.5×10^6立方米的悬挂冰川坍塌到下游的主冰川上。接下来，约1.17×10^8立方米的侵蚀物质从受冲击的冰川转变成为泥石流，并沿下游流动了8公里。在级联过程中，冰-岩崩落动量和冰川速度是决定CGHC形成和最终体积的关键因素。我们的研究有助于更好地理解CGHC灾害的多米诺效应。</p>\n<h3 id=\"相关研究的重要性\"><a href=\"#相关研究的重要性\" class=\"headerlink\" title=\"相关研究的重要性\"></a>相关研究的重要性</h3><ul>\n<li><strong>气候变化对冰冻圈的影响</strong>：冰川退缩和相关的灾害链事件对下游社区可能产生灾难性后果。</li>\n<li><strong>冰川灾害链（CGHC）</strong>：对CGHC事件的理解有助于改进灾害风险评估和减灾措施。</li>\n</ul>\n<h3 id=\"前人研究及不足\"><a href=\"#前人研究及不足\" class=\"headerlink\" title=\"前人研究及不足\"></a>前人研究及不足</h3><ul>\n<li><strong>Chiarle et al., 2007; Evans &amp; Delaney, 2015; Lutz et al., 2014</strong>：研究了冰川化环境中的大规模流动，包括由融水引起的摩擦减弱、高速度和长距离运动。</li>\n<li><strong>Scherler et al., 2011</strong>：研究了全球变暖如何重塑和动员冰川系统，导致冰川相关大规模流动的频率增加。</li>\n<li><strong>不足</strong>：现有研究对CGHC事件的物理过程和对气候变化的响应理解不足。</li>\n</ul>\n<h3 id=\"本文使用的数据和方法\"><a href=\"#本文使用的数据和方法\" class=\"headerlink\" title=\"本文使用的数据和方法\"></a>本文使用的数据和方法</h3><ul>\n<li><strong>数据</strong>：<ul>\n<li>多源遥感数据，包括光学和合成孔径雷达（SAR）图像。</li>\n<li>气象站数据和全球降水测量任务（GPM IMERG v6）降水数据。</li>\n<li>地震记录数据，来自围绕色东普的11个宽频带地震站的网络。</li>\n</ul>\n</li>\n<li><strong>方法</strong>：<ul>\n<li>应用相关匹配算法追踪Landsat&#x2F;Sentinel-2图像中的亚像素偏移。</li>\n<li>使用数值方法基于热力学耦合解决冰川运动。</li>\n<li>利用地形重建和质量运动解释来揭示2018年CGHC事件的动态过程。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"本文结果\"><a href=\"#本文结果\" class=\"headerlink\" title=\"本文结果\"></a>本文结果</h3><ul>\n<li><strong>气候变化和冰川退缩</strong>：自1970年代以来，青藏高原的年平均气温每十年上升0.32°C，是全球平均水平的两倍。</li>\n<li><strong>动态过程和地貌特征</strong>：CGHC事件包括冰-岩崩落和随后的泥石流过程，具有超流动性和体积显著增加。</li>\n</ul>\n<h3 id=\"本文创新之处和贡献\"><a href=\"#本文创新之处和贡献\" class=\"headerlink\" title=\"本文创新之处和贡献\"></a>本文创新之处和贡献</h3><ul>\n<li><strong>CGHC事件的详细重建</strong>：提供了2018年CGHC事件形成、演变和运动过程的详细重建。</li>\n<li><strong>气候变化对CGHC的影响</strong>：分析了气候变化如何通过增加冰川融化和降水来促进CGHC事件。</li>\n</ul>\n<h3 id=\"本文不足\"><a href=\"#本文不足\" class=\"headerlink\" title=\"本文不足\"></a>本文不足</h3><ul>\n<li>文章中并未明确指出研究的局限性，但可能包括对冰川动态和CGHC事件复杂性的进一步理解需要更多的实地观测和数据。</li>\n</ul>"},{"title":"文献阅读（十五）","abbrlink":"3330ae28","date":"2024-06-26T14:19:17.000Z","_content":"&emsp;&emsp;[Submarine landslides triggered by iceberg collision with the seafloor](https://www.nature.com/articles/s41561-021-00767-4)\n<!--less-->\n### 摘要\n\n极地地区冰川崩解通常与大气-海洋变化相关，因此预计在气候变暖的情况下会增加。冰山排放对海洋环流、气候和全球海平面都有影响。冰山还因海床刮擦影响底栖生物群落，对航运业和海洋基础设施构成威胁，并通过产生冰山倾覆海啸危及沿海居民。人们认为冰山对海床的影响限于大陆架和上坡，水深不超过冰山龙骨深度（通常小于500米）。在本文中，我们提供了证据表明，冰山通过引发海底滑坡影响了其龙骨深度以外的海床。海底滑坡通常比陆地上的滑坡大得多。它们是主要的地质灾害，尤其是因为它们可能触发对沿海居民造成毁灭性后果的海啸。此外，它们可能破坏海上基础设施，例如承载超过95%全球数据的海底互联网电缆。目前，世界上很少有海底滑坡有已知的触发因素，尽管这些沉积物已在各种水体和环境中被绘制出来。少数被实时记录的海底滑坡通常意味着地震是它们的触发机制。更常见的是，海底不稳定性的原因是基于推测的，这在识别海底滑坡的触发因素时产生了很大的不确定性，并负面影响了适当的风险评估的发展。由于海底滑坡极难在海底观测和监测，关于它们的触发机制仍有重要问题需要解答。在这项研究中，我们结合了重复的海底地形数据、卫星图像和海底沉积物的地质技术属性，以提供证据表明，在巴芬岛南风峡湾，冰山与海床的碰撞触发了海底滑坡。这些结果表明，冰山搁浅和倾覆可能是在许多峡湾和极地至亚极地环境中的大陆坡触发海底滑坡的原因，这是一个以前被低估的隐患。\n\n### 相关研究的重要性\n\n1. **气候变化对冰川和冰山的影响**：研究冰山崩解对理解全球气候变化的影响至关重要。\n2. **海底滑坡的地质灾害**：海底滑坡可能引发海啸，对沿海社区构成严重威胁。\n3. **海洋基础设施的保护**：了解冰山对海底的影响有助于保护海底电缆等基础设施。\n\n### 前人研究及不足\n\n- **Dowdeswell & Bamber, 2007; Barrie et al., 1992**：研究了冰山在浅于龙骨深度的水域刮擦海床的现象。\n- **Hill & Condron, 2014**：探讨了在冰期后退时，冰山在亚热带佛罗里达的分布。\n- **不足**：现有研究对冰山在超过龙骨深度的水域引发海底滑坡的认识有限，缺乏对此类事件触发机制的直接观测和数据。\n\n### 本文使用的数据和方法\n\n- **数据**：\n  - 重复的海底地形数据（多波束回声探测数据）。\n  - 卫星图像。\n  - 海底沉积物的地质技术属性。\n- **方法**：\n  - 对比分析不同时间点的海底地形数据，以识别海底滑坡的发生。\n  - 使用卫星图像确认冰山的位置和行为。\n  - 进行简单的极限平衡边坡稳定性分析，以评估冰山撞击对海底沉积物稳定性的影响。\n\n### 本文结果\n\n- 确定了在巴芬岛南风峡湾，冰山与海床的碰撞触发了海底滑坡。\n- 通过卫星图像和多波束回声探测数据，观察到冰山在滑坡发生地的搁浅和倾覆。\n- 地质技术数据显示，冰山撞击产生的垂直载荷足以触发海底滑坡。\n\n### 本文创新之处和贡献\n\n- **冰山撞击深度的扩展认识**：提供了冰山可以在超过其龙骨深度的水域影响海底的证据。\n- **海底滑坡触发机制的新见解**：揭示了冰山搁浅和倾覆可能是在极地至亚极地环境中触发海底滑坡的一个重要因素。\n\n### 本文不足\n\n- 文章中并未明确指出研究的局限性，但可能包括对冰山撞击和海底滑坡之间关系的更深入理解需要更多案例研究和数据支持。\n","source":"_posts/2024-06-26-paper-reading-15.md","raw":"---\ntitle: 文献阅读（十五）\ncategories:\n  - work\ntags:\n  - paper\nabbrlink: 3330ae28\ndate: 2024-06-26 22:19:17\n---\n&emsp;&emsp;[Submarine landslides triggered by iceberg collision with the seafloor](https://www.nature.com/articles/s41561-021-00767-4)\n<!--less-->\n### 摘要\n\n极地地区冰川崩解通常与大气-海洋变化相关，因此预计在气候变暖的情况下会增加。冰山排放对海洋环流、气候和全球海平面都有影响。冰山还因海床刮擦影响底栖生物群落，对航运业和海洋基础设施构成威胁，并通过产生冰山倾覆海啸危及沿海居民。人们认为冰山对海床的影响限于大陆架和上坡，水深不超过冰山龙骨深度（通常小于500米）。在本文中，我们提供了证据表明，冰山通过引发海底滑坡影响了其龙骨深度以外的海床。海底滑坡通常比陆地上的滑坡大得多。它们是主要的地质灾害，尤其是因为它们可能触发对沿海居民造成毁灭性后果的海啸。此外，它们可能破坏海上基础设施，例如承载超过95%全球数据的海底互联网电缆。目前，世界上很少有海底滑坡有已知的触发因素，尽管这些沉积物已在各种水体和环境中被绘制出来。少数被实时记录的海底滑坡通常意味着地震是它们的触发机制。更常见的是，海底不稳定性的原因是基于推测的，这在识别海底滑坡的触发因素时产生了很大的不确定性，并负面影响了适当的风险评估的发展。由于海底滑坡极难在海底观测和监测，关于它们的触发机制仍有重要问题需要解答。在这项研究中，我们结合了重复的海底地形数据、卫星图像和海底沉积物的地质技术属性，以提供证据表明，在巴芬岛南风峡湾，冰山与海床的碰撞触发了海底滑坡。这些结果表明，冰山搁浅和倾覆可能是在许多峡湾和极地至亚极地环境中的大陆坡触发海底滑坡的原因，这是一个以前被低估的隐患。\n\n### 相关研究的重要性\n\n1. **气候变化对冰川和冰山的影响**：研究冰山崩解对理解全球气候变化的影响至关重要。\n2. **海底滑坡的地质灾害**：海底滑坡可能引发海啸，对沿海社区构成严重威胁。\n3. **海洋基础设施的保护**：了解冰山对海底的影响有助于保护海底电缆等基础设施。\n\n### 前人研究及不足\n\n- **Dowdeswell & Bamber, 2007; Barrie et al., 1992**：研究了冰山在浅于龙骨深度的水域刮擦海床的现象。\n- **Hill & Condron, 2014**：探讨了在冰期后退时，冰山在亚热带佛罗里达的分布。\n- **不足**：现有研究对冰山在超过龙骨深度的水域引发海底滑坡的认识有限，缺乏对此类事件触发机制的直接观测和数据。\n\n### 本文使用的数据和方法\n\n- **数据**：\n  - 重复的海底地形数据（多波束回声探测数据）。\n  - 卫星图像。\n  - 海底沉积物的地质技术属性。\n- **方法**：\n  - 对比分析不同时间点的海底地形数据，以识别海底滑坡的发生。\n  - 使用卫星图像确认冰山的位置和行为。\n  - 进行简单的极限平衡边坡稳定性分析，以评估冰山撞击对海底沉积物稳定性的影响。\n\n### 本文结果\n\n- 确定了在巴芬岛南风峡湾，冰山与海床的碰撞触发了海底滑坡。\n- 通过卫星图像和多波束回声探测数据，观察到冰山在滑坡发生地的搁浅和倾覆。\n- 地质技术数据显示，冰山撞击产生的垂直载荷足以触发海底滑坡。\n\n### 本文创新之处和贡献\n\n- **冰山撞击深度的扩展认识**：提供了冰山可以在超过其龙骨深度的水域影响海底的证据。\n- **海底滑坡触发机制的新见解**：揭示了冰山搁浅和倾覆可能是在极地至亚极地环境中触发海底滑坡的一个重要因素。\n\n### 本文不足\n\n- 文章中并未明确指出研究的局限性，但可能包括对冰山撞击和海底滑坡之间关系的更深入理解需要更多案例研究和数据支持。\n","slug":"paper-reading-15","published":1,"updated":"2024-06-26T14:21:51.301Z","comments":1,"layout":"post","photos":[],"_id":"cmh498ipz009rwvoud9at681t","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><h3 id=\"摘要\"><a href=\"#摘要\" class=\"headerlink\" title=\"摘要\"></a>摘要</h3><p>极地地区冰川崩解通常与大气-海洋变化相关，因此预计在气候变暖的情况下会增加。冰山排放对海洋环流、气候和全球海平面都有影响。冰山还因海床刮擦影响底栖生物群落，对航运业和海洋基础设施构成威胁，并通过产生冰山倾覆海啸危及沿海居民。人们认为冰山对海床的影响限于大陆架和上坡，水深不超过冰山龙骨深度（通常小于500米）。在本文中，我们提供了证据表明，冰山通过引发海底滑坡影响了其龙骨深度以外的海床。海底滑坡通常比陆地上的滑坡大得多。它们是主要的地质灾害，尤其是因为它们可能触发对沿海居民造成毁灭性后果的海啸。此外，它们可能破坏海上基础设施，例如承载超过95%全球数据的海底互联网电缆。目前，世界上很少有海底滑坡有已知的触发因素，尽管这些沉积物已在各种水体和环境中被绘制出来。少数被实时记录的海底滑坡通常意味着地震是它们的触发机制。更常见的是，海底不稳定性的原因是基于推测的，这在识别海底滑坡的触发因素时产生了很大的不确定性，并负面影响了适当的风险评估的发展。由于海底滑坡极难在海底观测和监测，关于它们的触发机制仍有重要问题需要解答。在这项研究中，我们结合了重复的海底地形数据、卫星图像和海底沉积物的地质技术属性，以提供证据表明，在巴芬岛南风峡湾，冰山与海床的碰撞触发了海底滑坡。这些结果表明，冰山搁浅和倾覆可能是在许多峡湾和极地至亚极地环境中的大陆坡触发海底滑坡的原因，这是一个以前被低估的隐患。</p>\n<h3 id=\"相关研究的重要性\"><a href=\"#相关研究的重要性\" class=\"headerlink\" title=\"相关研究的重要性\"></a>相关研究的重要性</h3><ol>\n<li><strong>气候变化对冰川和冰山的影响</strong>：研究冰山崩解对理解全球气候变化的影响至关重要。</li>\n<li><strong>海底滑坡的地质灾害</strong>：海底滑坡可能引发海啸，对沿海社区构成严重威胁。</li>\n<li><strong>海洋基础设施的保护</strong>：了解冰山对海底的影响有助于保护海底电缆等基础设施。</li>\n</ol>\n<h3 id=\"前人研究及不足\"><a href=\"#前人研究及不足\" class=\"headerlink\" title=\"前人研究及不足\"></a>前人研究及不足</h3><ul>\n<li><strong>Dowdeswell &amp; Bamber, 2007; Barrie et al., 1992</strong>：研究了冰山在浅于龙骨深度的水域刮擦海床的现象。</li>\n<li><strong>Hill &amp; Condron, 2014</strong>：探讨了在冰期后退时，冰山在亚热带佛罗里达的分布。</li>\n<li><strong>不足</strong>：现有研究对冰山在超过龙骨深度的水域引发海底滑坡的认识有限，缺乏对此类事件触发机制的直接观测和数据。</li>\n</ul>\n<h3 id=\"本文使用的数据和方法\"><a href=\"#本文使用的数据和方法\" class=\"headerlink\" title=\"本文使用的数据和方法\"></a>本文使用的数据和方法</h3><ul>\n<li><strong>数据</strong>：<ul>\n<li>重复的海底地形数据（多波束回声探测数据）。</li>\n<li>卫星图像。</li>\n<li>海底沉积物的地质技术属性。</li>\n</ul>\n</li>\n<li><strong>方法</strong>：<ul>\n<li>对比分析不同时间点的海底地形数据，以识别海底滑坡的发生。</li>\n<li>使用卫星图像确认冰山的位置和行为。</li>\n<li>进行简单的极限平衡边坡稳定性分析，以评估冰山撞击对海底沉积物稳定性的影响。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"本文结果\"><a href=\"#本文结果\" class=\"headerlink\" title=\"本文结果\"></a>本文结果</h3><ul>\n<li>确定了在巴芬岛南风峡湾，冰山与海床的碰撞触发了海底滑坡。</li>\n<li>通过卫星图像和多波束回声探测数据，观察到冰山在滑坡发生地的搁浅和倾覆。</li>\n<li>地质技术数据显示，冰山撞击产生的垂直载荷足以触发海底滑坡。</li>\n</ul>\n<h3 id=\"本文创新之处和贡献\"><a href=\"#本文创新之处和贡献\" class=\"headerlink\" title=\"本文创新之处和贡献\"></a>本文创新之处和贡献</h3><ul>\n<li><strong>冰山撞击深度的扩展认识</strong>：提供了冰山可以在超过其龙骨深度的水域影响海底的证据。</li>\n<li><strong>海底滑坡触发机制的新见解</strong>：揭示了冰山搁浅和倾覆可能是在极地至亚极地环境中触发海底滑坡的一个重要因素。</li>\n</ul>\n<h3 id=\"本文不足\"><a href=\"#本文不足\" class=\"headerlink\" title=\"本文不足\"></a>本文不足</h3><ul>\n<li>文章中并未明确指出研究的局限性，但可能包括对冰山撞击和海底滑坡之间关系的更深入理解需要更多案例研究和数据支持。</li>\n</ul>","related_posts":["paper-reading-9.html","paper-reading-12.html"],"length":1342,"excerpt":"<p>&emsp;&emsp;<a href=\"https://www.nature.com/articles/s41561-021-00767-4\">Submarine landslides triggered by iceberg collision with the seafloor</a></p>","more":"<h3 id=\"摘要\"><a href=\"#摘要\" class=\"headerlink\" title=\"摘要\"></a>摘要</h3><p>极地地区冰川崩解通常与大气-海洋变化相关，因此预计在气候变暖的情况下会增加。冰山排放对海洋环流、气候和全球海平面都有影响。冰山还因海床刮擦影响底栖生物群落，对航运业和海洋基础设施构成威胁，并通过产生冰山倾覆海啸危及沿海居民。人们认为冰山对海床的影响限于大陆架和上坡，水深不超过冰山龙骨深度（通常小于500米）。在本文中，我们提供了证据表明，冰山通过引发海底滑坡影响了其龙骨深度以外的海床。海底滑坡通常比陆地上的滑坡大得多。它们是主要的地质灾害，尤其是因为它们可能触发对沿海居民造成毁灭性后果的海啸。此外，它们可能破坏海上基础设施，例如承载超过95%全球数据的海底互联网电缆。目前，世界上很少有海底滑坡有已知的触发因素，尽管这些沉积物已在各种水体和环境中被绘制出来。少数被实时记录的海底滑坡通常意味着地震是它们的触发机制。更常见的是，海底不稳定性的原因是基于推测的，这在识别海底滑坡的触发因素时产生了很大的不确定性，并负面影响了适当的风险评估的发展。由于海底滑坡极难在海底观测和监测，关于它们的触发机制仍有重要问题需要解答。在这项研究中，我们结合了重复的海底地形数据、卫星图像和海底沉积物的地质技术属性，以提供证据表明，在巴芬岛南风峡湾，冰山与海床的碰撞触发了海底滑坡。这些结果表明，冰山搁浅和倾覆可能是在许多峡湾和极地至亚极地环境中的大陆坡触发海底滑坡的原因，这是一个以前被低估的隐患。</p>\n<h3 id=\"相关研究的重要性\"><a href=\"#相关研究的重要性\" class=\"headerlink\" title=\"相关研究的重要性\"></a>相关研究的重要性</h3><ol>\n<li><strong>气候变化对冰川和冰山的影响</strong>：研究冰山崩解对理解全球气候变化的影响至关重要。</li>\n<li><strong>海底滑坡的地质灾害</strong>：海底滑坡可能引发海啸，对沿海社区构成严重威胁。</li>\n<li><strong>海洋基础设施的保护</strong>：了解冰山对海底的影响有助于保护海底电缆等基础设施。</li>\n</ol>\n<h3 id=\"前人研究及不足\"><a href=\"#前人研究及不足\" class=\"headerlink\" title=\"前人研究及不足\"></a>前人研究及不足</h3><ul>\n<li><strong>Dowdeswell &amp; Bamber, 2007; Barrie et al., 1992</strong>：研究了冰山在浅于龙骨深度的水域刮擦海床的现象。</li>\n<li><strong>Hill &amp; Condron, 2014</strong>：探讨了在冰期后退时，冰山在亚热带佛罗里达的分布。</li>\n<li><strong>不足</strong>：现有研究对冰山在超过龙骨深度的水域引发海底滑坡的认识有限，缺乏对此类事件触发机制的直接观测和数据。</li>\n</ul>\n<h3 id=\"本文使用的数据和方法\"><a href=\"#本文使用的数据和方法\" class=\"headerlink\" title=\"本文使用的数据和方法\"></a>本文使用的数据和方法</h3><ul>\n<li><strong>数据</strong>：<ul>\n<li>重复的海底地形数据（多波束回声探测数据）。</li>\n<li>卫星图像。</li>\n<li>海底沉积物的地质技术属性。</li>\n</ul>\n</li>\n<li><strong>方法</strong>：<ul>\n<li>对比分析不同时间点的海底地形数据，以识别海底滑坡的发生。</li>\n<li>使用卫星图像确认冰山的位置和行为。</li>\n<li>进行简单的极限平衡边坡稳定性分析，以评估冰山撞击对海底沉积物稳定性的影响。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"本文结果\"><a href=\"#本文结果\" class=\"headerlink\" title=\"本文结果\"></a>本文结果</h3><ul>\n<li>确定了在巴芬岛南风峡湾，冰山与海床的碰撞触发了海底滑坡。</li>\n<li>通过卫星图像和多波束回声探测数据，观察到冰山在滑坡发生地的搁浅和倾覆。</li>\n<li>地质技术数据显示，冰山撞击产生的垂直载荷足以触发海底滑坡。</li>\n</ul>\n<h3 id=\"本文创新之处和贡献\"><a href=\"#本文创新之处和贡献\" class=\"headerlink\" title=\"本文创新之处和贡献\"></a>本文创新之处和贡献</h3><ul>\n<li><strong>冰山撞击深度的扩展认识</strong>：提供了冰山可以在超过其龙骨深度的水域影响海底的证据。</li>\n<li><strong>海底滑坡触发机制的新见解</strong>：揭示了冰山搁浅和倾覆可能是在极地至亚极地环境中触发海底滑坡的一个重要因素。</li>\n</ul>\n<h3 id=\"本文不足\"><a href=\"#本文不足\" class=\"headerlink\" title=\"本文不足\"></a>本文不足</h3><ul>\n<li>文章中并未明确指出研究的局限性，但可能包括对冰山撞击和海底滑坡之间关系的更深入理解需要更多案例研究和数据支持。</li>\n</ul>"},{"title":"文献阅读（十六）","abbrlink":"563ee5f1","date":"2024-06-27T00:47:07.000Z","_content":"&emsp;&emsp;[Locating the Largest Event Observed on Mars With Multi-Orbit Surface Waves](https://agupubs.onlinelibrary.wiley.com/doi/10.1029/2022GL101270?af=R)\n<!--less-->\n\n### 摘要\n\n在2018年InSight任务着陆之前，InSight科学团队提出了一种独立于地震速度模型的方法，使用多圈面波来定位火星震，适用于大于MW4.6的事件。2022年5月4日的S1222a MW4.7是记录到的最大的火星震，也是第一个足够大，可以使用这种方法的地震。通过确定前三圈Rayleigh波的群到达时间，我们计算出了群速度、震中距和起始时间。平均距离为36.9±0.3°，与基于体波测量的火星地震服务(MQS)的距离37.0±1.6°一致。表面波的起始时间比MQS的起始时间系统性地晚了20秒。背方位角估计与MQS基于体波的估计相似，尽管表明向南有所偏移。R2和R3的背方位角估计更加分散，但显示出明显的椭圆形运动。\n\n### 相关研究的重要性及前人研究\n\n- **重要性：**\n  - 火星震学对于理解火星内部结构和地质活动至关重要。\n  - 独立于地震速度模型的定位方法可以提供一种在地震速度结构未知的情况下估计地震位置的手段。\n\n- **前人研究：**\n  - Khan et al., 2016; Panning et al., 2015 提出了使用圈面波进行火星地震定位的方法。\n  - 其他研究如 Bagheri et al., 2019; Khan et al., 2018; Smrekar et al., 2019 提供了火星内部速度结构的先验模型。\n\n- **不足之处：**\n  - 之前的研究依赖于对火星震速度结构的假设，而这些结构在InSight任务之前并不完全清楚。\n  - 火星震事件较小，无法测试多圈面波方法的有效性。\n\n### 本文使用的数据和方法\n\n- **数据：**\n  - 使用InSight任务的SEIS仪器记录的S1222a火星地震事件数据。\n\n- **方法：**\n  - 应用了多圈面波定位方法，通过测量R1、R2和R3 Rayleigh波的群到达时间来确定震中距、群速度和起始时间。\n\n### 获得的结果\n\n- 震中距估计为36.9±0.3°，与MQS基于体波测量的距离一致。\n- 面波的起始时间比MQS的起始时间晚了20秒。\n- 后方位角估计与MQS的估计相似，但表明可能向南有所偏移。\n\n### 本文创新之处及贡献\n\n- **创新之处：**\n  - 首次应用了不依赖于先验地震速度模型的火星地震定位方法。\n  - 利用了足够大的火星震事件来测试和验证这种方法。\n\n- **贡献：**\n  - 验证了MQS方法的有效性，并为火星地震学提供了一种新的独立工具。\n  - 通过实际地震数据的应用，增强了对火星地震定位方法的信心。\n\n### 本文不足\n\n- 文章中并未明确指出研究的不足之处，但可能的不足可能包括：\n  - 由于火星震事件的稀有性和噪声问题，可能影响数据质量和分析结果的准确性。\n  - 背方位角的估计可能受到火星表面风等非地震因素的影响，导致估计存在偏差。\n","source":"_posts/2024-06-27-paper-reading-16.md","raw":"---\ntitle: 文献阅读（十六）\ncategories:\n  - work\ntags:\n  - paper\nabbrlink: 563ee5f1\ndate: 2024-06-27 08:47:07\n---\n&emsp;&emsp;[Locating the Largest Event Observed on Mars With Multi-Orbit Surface Waves](https://agupubs.onlinelibrary.wiley.com/doi/10.1029/2022GL101270?af=R)\n<!--less-->\n\n### 摘要\n\n在2018年InSight任务着陆之前，InSight科学团队提出了一种独立于地震速度模型的方法，使用多圈面波来定位火星震，适用于大于MW4.6的事件。2022年5月4日的S1222a MW4.7是记录到的最大的火星震，也是第一个足够大，可以使用这种方法的地震。通过确定前三圈Rayleigh波的群到达时间，我们计算出了群速度、震中距和起始时间。平均距离为36.9±0.3°，与基于体波测量的火星地震服务(MQS)的距离37.0±1.6°一致。表面波的起始时间比MQS的起始时间系统性地晚了20秒。背方位角估计与MQS基于体波的估计相似，尽管表明向南有所偏移。R2和R3的背方位角估计更加分散，但显示出明显的椭圆形运动。\n\n### 相关研究的重要性及前人研究\n\n- **重要性：**\n  - 火星震学对于理解火星内部结构和地质活动至关重要。\n  - 独立于地震速度模型的定位方法可以提供一种在地震速度结构未知的情况下估计地震位置的手段。\n\n- **前人研究：**\n  - Khan et al., 2016; Panning et al., 2015 提出了使用圈面波进行火星地震定位的方法。\n  - 其他研究如 Bagheri et al., 2019; Khan et al., 2018; Smrekar et al., 2019 提供了火星内部速度结构的先验模型。\n\n- **不足之处：**\n  - 之前的研究依赖于对火星震速度结构的假设，而这些结构在InSight任务之前并不完全清楚。\n  - 火星震事件较小，无法测试多圈面波方法的有效性。\n\n### 本文使用的数据和方法\n\n- **数据：**\n  - 使用InSight任务的SEIS仪器记录的S1222a火星地震事件数据。\n\n- **方法：**\n  - 应用了多圈面波定位方法，通过测量R1、R2和R3 Rayleigh波的群到达时间来确定震中距、群速度和起始时间。\n\n### 获得的结果\n\n- 震中距估计为36.9±0.3°，与MQS基于体波测量的距离一致。\n- 面波的起始时间比MQS的起始时间晚了20秒。\n- 后方位角估计与MQS的估计相似，但表明可能向南有所偏移。\n\n### 本文创新之处及贡献\n\n- **创新之处：**\n  - 首次应用了不依赖于先验地震速度模型的火星地震定位方法。\n  - 利用了足够大的火星震事件来测试和验证这种方法。\n\n- **贡献：**\n  - 验证了MQS方法的有效性，并为火星地震学提供了一种新的独立工具。\n  - 通过实际地震数据的应用，增强了对火星地震定位方法的信心。\n\n### 本文不足\n\n- 文章中并未明确指出研究的不足之处，但可能的不足可能包括：\n  - 由于火星震事件的稀有性和噪声问题，可能影响数据质量和分析结果的准确性。\n  - 背方位角的估计可能受到火星表面风等非地震因素的影响，导致估计存在偏差。\n","slug":"paper-reading-16","published":1,"updated":"2024-06-27T00:52:11.587Z","comments":1,"layout":"post","photos":[],"_id":"cmh498ipz009vwvou3zyhdw81","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><h3 id=\"摘要\"><a href=\"#摘要\" class=\"headerlink\" title=\"摘要\"></a>摘要</h3><p>在2018年InSight任务着陆之前，InSight科学团队提出了一种独立于地震速度模型的方法，使用多圈面波来定位火星震，适用于大于MW4.6的事件。2022年5月4日的S1222a MW4.7是记录到的最大的火星震，也是第一个足够大，可以使用这种方法的地震。通过确定前三圈Rayleigh波的群到达时间，我们计算出了群速度、震中距和起始时间。平均距离为36.9±0.3°，与基于体波测量的火星地震服务(MQS)的距离37.0±1.6°一致。表面波的起始时间比MQS的起始时间系统性地晚了20秒。背方位角估计与MQS基于体波的估计相似，尽管表明向南有所偏移。R2和R3的背方位角估计更加分散，但显示出明显的椭圆形运动。</p>\n<h3 id=\"相关研究的重要性及前人研究\"><a href=\"#相关研究的重要性及前人研究\" class=\"headerlink\" title=\"相关研究的重要性及前人研究\"></a>相关研究的重要性及前人研究</h3><ul>\n<li><p><strong>重要性：</strong></p>\n<ul>\n<li>火星震学对于理解火星内部结构和地质活动至关重要。</li>\n<li>独立于地震速度模型的定位方法可以提供一种在地震速度结构未知的情况下估计地震位置的手段。</li>\n</ul>\n</li>\n<li><p><strong>前人研究：</strong></p>\n<ul>\n<li>Khan et al., 2016; Panning et al., 2015 提出了使用圈面波进行火星地震定位的方法。</li>\n<li>其他研究如 Bagheri et al., 2019; Khan et al., 2018; Smrekar et al., 2019 提供了火星内部速度结构的先验模型。</li>\n</ul>\n</li>\n<li><p><strong>不足之处：</strong></p>\n<ul>\n<li>之前的研究依赖于对火星震速度结构的假设，而这些结构在InSight任务之前并不完全清楚。</li>\n<li>火星震事件较小，无法测试多圈面波方法的有效性。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"本文使用的数据和方法\"><a href=\"#本文使用的数据和方法\" class=\"headerlink\" title=\"本文使用的数据和方法\"></a>本文使用的数据和方法</h3><ul>\n<li><p><strong>数据：</strong></p>\n<ul>\n<li>使用InSight任务的SEIS仪器记录的S1222a火星地震事件数据。</li>\n</ul>\n</li>\n<li><p><strong>方法：</strong></p>\n<ul>\n<li>应用了多圈面波定位方法，通过测量R1、R2和R3 Rayleigh波的群到达时间来确定震中距、群速度和起始时间。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"获得的结果\"><a href=\"#获得的结果\" class=\"headerlink\" title=\"获得的结果\"></a>获得的结果</h3><ul>\n<li>震中距估计为36.9±0.3°，与MQS基于体波测量的距离一致。</li>\n<li>面波的起始时间比MQS的起始时间晚了20秒。</li>\n<li>后方位角估计与MQS的估计相似，但表明可能向南有所偏移。</li>\n</ul>\n<h3 id=\"本文创新之处及贡献\"><a href=\"#本文创新之处及贡献\" class=\"headerlink\" title=\"本文创新之处及贡献\"></a>本文创新之处及贡献</h3><ul>\n<li><p><strong>创新之处：</strong></p>\n<ul>\n<li>首次应用了不依赖于先验地震速度模型的火星地震定位方法。</li>\n<li>利用了足够大的火星震事件来测试和验证这种方法。</li>\n</ul>\n</li>\n<li><p><strong>贡献：</strong></p>\n<ul>\n<li>验证了MQS方法的有效性，并为火星地震学提供了一种新的独立工具。</li>\n<li>通过实际地震数据的应用，增强了对火星地震定位方法的信心。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"本文不足\"><a href=\"#本文不足\" class=\"headerlink\" title=\"本文不足\"></a>本文不足</h3><ul>\n<li>文章中并未明确指出研究的不足之处，但可能的不足可能包括：<ul>\n<li>由于火星震事件的稀有性和噪声问题，可能影响数据质量和分析结果的准确性。</li>\n<li>背方位角的估计可能受到火星表面风等非地震因素的影响，导致估计存在偏差。</li>\n</ul>\n</li>\n</ul>","related_posts":[],"length":1095,"excerpt":"<p>&emsp;&emsp;<a href=\"https://agupubs.onlinelibrary.wiley.com/doi/10.1029/2022GL101270?af=R\">Locating the Largest Event Observed on Mars With Multi-Orbit Surface Waves</a></p>","more":"<h3 id=\"摘要\"><a href=\"#摘要\" class=\"headerlink\" title=\"摘要\"></a>摘要</h3><p>在2018年InSight任务着陆之前，InSight科学团队提出了一种独立于地震速度模型的方法，使用多圈面波来定位火星震，适用于大于MW4.6的事件。2022年5月4日的S1222a MW4.7是记录到的最大的火星震，也是第一个足够大，可以使用这种方法的地震。通过确定前三圈Rayleigh波的群到达时间，我们计算出了群速度、震中距和起始时间。平均距离为36.9±0.3°，与基于体波测量的火星地震服务(MQS)的距离37.0±1.6°一致。表面波的起始时间比MQS的起始时间系统性地晚了20秒。背方位角估计与MQS基于体波的估计相似，尽管表明向南有所偏移。R2和R3的背方位角估计更加分散，但显示出明显的椭圆形运动。</p>\n<h3 id=\"相关研究的重要性及前人研究\"><a href=\"#相关研究的重要性及前人研究\" class=\"headerlink\" title=\"相关研究的重要性及前人研究\"></a>相关研究的重要性及前人研究</h3><ul>\n<li><p><strong>重要性：</strong></p>\n<ul>\n<li>火星震学对于理解火星内部结构和地质活动至关重要。</li>\n<li>独立于地震速度模型的定位方法可以提供一种在地震速度结构未知的情况下估计地震位置的手段。</li>\n</ul>\n</li>\n<li><p><strong>前人研究：</strong></p>\n<ul>\n<li>Khan et al., 2016; Panning et al., 2015 提出了使用圈面波进行火星地震定位的方法。</li>\n<li>其他研究如 Bagheri et al., 2019; Khan et al., 2018; Smrekar et al., 2019 提供了火星内部速度结构的先验模型。</li>\n</ul>\n</li>\n<li><p><strong>不足之处：</strong></p>\n<ul>\n<li>之前的研究依赖于对火星震速度结构的假设，而这些结构在InSight任务之前并不完全清楚。</li>\n<li>火星震事件较小，无法测试多圈面波方法的有效性。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"本文使用的数据和方法\"><a href=\"#本文使用的数据和方法\" class=\"headerlink\" title=\"本文使用的数据和方法\"></a>本文使用的数据和方法</h3><ul>\n<li><p><strong>数据：</strong></p>\n<ul>\n<li>使用InSight任务的SEIS仪器记录的S1222a火星地震事件数据。</li>\n</ul>\n</li>\n<li><p><strong>方法：</strong></p>\n<ul>\n<li>应用了多圈面波定位方法，通过测量R1、R2和R3 Rayleigh波的群到达时间来确定震中距、群速度和起始时间。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"获得的结果\"><a href=\"#获得的结果\" class=\"headerlink\" title=\"获得的结果\"></a>获得的结果</h3><ul>\n<li>震中距估计为36.9±0.3°，与MQS基于体波测量的距离一致。</li>\n<li>面波的起始时间比MQS的起始时间晚了20秒。</li>\n<li>后方位角估计与MQS的估计相似，但表明可能向南有所偏移。</li>\n</ul>\n<h3 id=\"本文创新之处及贡献\"><a href=\"#本文创新之处及贡献\" class=\"headerlink\" title=\"本文创新之处及贡献\"></a>本文创新之处及贡献</h3><ul>\n<li><p><strong>创新之处：</strong></p>\n<ul>\n<li>首次应用了不依赖于先验地震速度模型的火星地震定位方法。</li>\n<li>利用了足够大的火星震事件来测试和验证这种方法。</li>\n</ul>\n</li>\n<li><p><strong>贡献：</strong></p>\n<ul>\n<li>验证了MQS方法的有效性，并为火星地震学提供了一种新的独立工具。</li>\n<li>通过实际地震数据的应用，增强了对火星地震定位方法的信心。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"本文不足\"><a href=\"#本文不足\" class=\"headerlink\" title=\"本文不足\"></a>本文不足</h3><ul>\n<li>文章中并未明确指出研究的不足之处，但可能的不足可能包括：<ul>\n<li>由于火星震事件的稀有性和噪声问题，可能影响数据质量和分析结果的准确性。</li>\n<li>背方位角的估计可能受到火星表面风等非地震因素的影响，导致估计存在偏差。</li>\n</ul>\n</li>\n</ul>"},{"title":"文献阅读（十七）","abbrlink":"843e926e","date":"2024-06-27T00:57:24.000Z","_content":"&emsp;&emsp;[Development of ice-shelf estuaries promotes fractures and calving](https://www.nature.com/articles/s41561-021-00837-7)\n<!--less-->\n\n### 摘要\n\n随着全球气候变暖，冰架表面的融水增加可能会触发冰架崩塌，加速全球海平面上升。表面河流的形成如果能有效排走融水，也可能有助于防止冰架崩塌。在这里，我们展示了格陵兰西北部彼得曼冰架表面河流演变成冰架河口的演变观测，并在附近的雷德冰架上发现了第二个河口。这种表面水文过程可以促进断裂并增强冰架崩解。在彼得曼河口，观察到海冰在上游河口处汇聚，表明了流动方向的逆转。在周围的冰景冻结后，海水仍持续存在于河口中。沿着彼得曼河口的底部，从崩解前沿开始的线性裂缝沿着通道向上游传播。类似的沿着河口通道的裂缝塑造了彼得曼和雷德冰架上过去的大型直线崩解事件。在一个变暖的世界中，表面融化的增加将增强河流侵蚀，促进河口发展，沿冰架前沿的纵向断裂正交于冰架前沿，并增加直线崩解。河口可能在接下来的半个世纪内出现在南极洲，导致冰架崩解增加，加速冰层损失和全球海平面上升。\n\n### 研究的重要性\n\n1. **冰架稳定性与全球海平面上升**：冰架的稳定性直接关系到全球海平面的变化，是气候变化研究的重要组成部分。\n2. **表面水文学对冰架稳定性的影响**：了解表面河流和河口如何影响冰架的稳定性，对预测冰架未来的变化至关重要。\n\n### 前人研究与不足\n\n- **相关研究**：\n  - Kingslake et al. (2017) 观察到南极冰架上的融水广泛流动。\n  - Bell et al. (2017) 发现南极冰架可能通过表面河流的融水排出而稳定。\n  - Dow et al. (2018) 发现冰架底部的通道驱动活跃的表面水文学和冰架的横向断裂。\n\n- **不足之处**：\n  - 之前的研究没有明确识别出冰架上的河口，对河口形成和其对冰架稳定性的影响理解有限。\n  - 缺乏对冰架表面河流如何演变成河口的直接观测。\n\n### 本文使用的数据和方法\n\n- **数据**：\n  - DigitalGlobe卫星图像、Landsat数据、NASA Operation IceBridge (OIB)数据、气候模型Modèle Atmosphérique Régionale (MAR)输出、南极洲的DEM (REMA)。\n\n- **方法**：\n  - 高分辨率卫星和航空图像分析。\n  - 利用气候模型定性分析表面过程的趋势。\n  - 通过测量图像中河流和河口的宽度，追踪其演变。\n\n### 获得的结果\n\n- 观测到彼得曼冰架上的表面河流演变成河口，并且在雷德冰架上发现了第二个河口。\n- 河口的形成与冰架前沿的裂缝发展和直线崩解事件有关。\n- 预测在接下来的30年内，南极洲的冰架上可能会形成更多的河口。\n\n### 本文创新之处及贡献\n\n- **创新之处**：\n  - 首次识别出冰架上的河口，并研究了其对冰架稳定性的潜在影响。\n  - 提出了“河口弱化”这一新概念，解释了河口如何促进冰架的直线崩解。\n\n- **贡献**：\n  - 为理解冰架表面水文学对冰架稳定性的影响提供了新的视角。\n  - 对未来南极冰架河口的发展及其对全球海平面上升的潜在影响进行了预测。\n\n### 本文不足\n\n- 文章中并未明确指出研究的不足之处，但潜在的不足可能包括：\n  - 预测模型可能过于简化，未考虑日内河流水文变化对侵蚀率的影响。\n  - 对河口形成所需时间的估计存在不确定性，依赖于多个假设和参数。\n","source":"_posts/2024-06-27-paper-reading-17.md","raw":"---\ntitle: 文献阅读（十七）\ncategories:\n  - work\ntags:\n  - paper\nabbrlink: 843e926e\ndate: 2024-06-27 08:57:24\n---\n&emsp;&emsp;[Development of ice-shelf estuaries promotes fractures and calving](https://www.nature.com/articles/s41561-021-00837-7)\n<!--less-->\n\n### 摘要\n\n随着全球气候变暖，冰架表面的融水增加可能会触发冰架崩塌，加速全球海平面上升。表面河流的形成如果能有效排走融水，也可能有助于防止冰架崩塌。在这里，我们展示了格陵兰西北部彼得曼冰架表面河流演变成冰架河口的演变观测，并在附近的雷德冰架上发现了第二个河口。这种表面水文过程可以促进断裂并增强冰架崩解。在彼得曼河口，观察到海冰在上游河口处汇聚，表明了流动方向的逆转。在周围的冰景冻结后，海水仍持续存在于河口中。沿着彼得曼河口的底部，从崩解前沿开始的线性裂缝沿着通道向上游传播。类似的沿着河口通道的裂缝塑造了彼得曼和雷德冰架上过去的大型直线崩解事件。在一个变暖的世界中，表面融化的增加将增强河流侵蚀，促进河口发展，沿冰架前沿的纵向断裂正交于冰架前沿，并增加直线崩解。河口可能在接下来的半个世纪内出现在南极洲，导致冰架崩解增加，加速冰层损失和全球海平面上升。\n\n### 研究的重要性\n\n1. **冰架稳定性与全球海平面上升**：冰架的稳定性直接关系到全球海平面的变化，是气候变化研究的重要组成部分。\n2. **表面水文学对冰架稳定性的影响**：了解表面河流和河口如何影响冰架的稳定性，对预测冰架未来的变化至关重要。\n\n### 前人研究与不足\n\n- **相关研究**：\n  - Kingslake et al. (2017) 观察到南极冰架上的融水广泛流动。\n  - Bell et al. (2017) 发现南极冰架可能通过表面河流的融水排出而稳定。\n  - Dow et al. (2018) 发现冰架底部的通道驱动活跃的表面水文学和冰架的横向断裂。\n\n- **不足之处**：\n  - 之前的研究没有明确识别出冰架上的河口，对河口形成和其对冰架稳定性的影响理解有限。\n  - 缺乏对冰架表面河流如何演变成河口的直接观测。\n\n### 本文使用的数据和方法\n\n- **数据**：\n  - DigitalGlobe卫星图像、Landsat数据、NASA Operation IceBridge (OIB)数据、气候模型Modèle Atmosphérique Régionale (MAR)输出、南极洲的DEM (REMA)。\n\n- **方法**：\n  - 高分辨率卫星和航空图像分析。\n  - 利用气候模型定性分析表面过程的趋势。\n  - 通过测量图像中河流和河口的宽度，追踪其演变。\n\n### 获得的结果\n\n- 观测到彼得曼冰架上的表面河流演变成河口，并且在雷德冰架上发现了第二个河口。\n- 河口的形成与冰架前沿的裂缝发展和直线崩解事件有关。\n- 预测在接下来的30年内，南极洲的冰架上可能会形成更多的河口。\n\n### 本文创新之处及贡献\n\n- **创新之处**：\n  - 首次识别出冰架上的河口，并研究了其对冰架稳定性的潜在影响。\n  - 提出了“河口弱化”这一新概念，解释了河口如何促进冰架的直线崩解。\n\n- **贡献**：\n  - 为理解冰架表面水文学对冰架稳定性的影响提供了新的视角。\n  - 对未来南极冰架河口的发展及其对全球海平面上升的潜在影响进行了预测。\n\n### 本文不足\n\n- 文章中并未明确指出研究的不足之处，但潜在的不足可能包括：\n  - 预测模型可能过于简化，未考虑日内河流水文变化对侵蚀率的影响。\n  - 对河口形成所需时间的估计存在不确定性，依赖于多个假设和参数。\n","slug":"paper-reading-17","published":1,"updated":"2024-06-27T01:03:38.428Z","comments":1,"layout":"post","photos":[],"_id":"cmh498iq0009ywvou7w3xg94z","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><h3 id=\"摘要\"><a href=\"#摘要\" class=\"headerlink\" title=\"摘要\"></a>摘要</h3><p>随着全球气候变暖，冰架表面的融水增加可能会触发冰架崩塌，加速全球海平面上升。表面河流的形成如果能有效排走融水，也可能有助于防止冰架崩塌。在这里，我们展示了格陵兰西北部彼得曼冰架表面河流演变成冰架河口的演变观测，并在附近的雷德冰架上发现了第二个河口。这种表面水文过程可以促进断裂并增强冰架崩解。在彼得曼河口，观察到海冰在上游河口处汇聚，表明了流动方向的逆转。在周围的冰景冻结后，海水仍持续存在于河口中。沿着彼得曼河口的底部，从崩解前沿开始的线性裂缝沿着通道向上游传播。类似的沿着河口通道的裂缝塑造了彼得曼和雷德冰架上过去的大型直线崩解事件。在一个变暖的世界中，表面融化的增加将增强河流侵蚀，促进河口发展，沿冰架前沿的纵向断裂正交于冰架前沿，并增加直线崩解。河口可能在接下来的半个世纪内出现在南极洲，导致冰架崩解增加，加速冰层损失和全球海平面上升。</p>\n<h3 id=\"研究的重要性\"><a href=\"#研究的重要性\" class=\"headerlink\" title=\"研究的重要性\"></a>研究的重要性</h3><ol>\n<li><strong>冰架稳定性与全球海平面上升</strong>：冰架的稳定性直接关系到全球海平面的变化，是气候变化研究的重要组成部分。</li>\n<li><strong>表面水文学对冰架稳定性的影响</strong>：了解表面河流和河口如何影响冰架的稳定性，对预测冰架未来的变化至关重要。</li>\n</ol>\n<h3 id=\"前人研究与不足\"><a href=\"#前人研究与不足\" class=\"headerlink\" title=\"前人研究与不足\"></a>前人研究与不足</h3><ul>\n<li><p><strong>相关研究</strong>：</p>\n<ul>\n<li>Kingslake et al. (2017) 观察到南极冰架上的融水广泛流动。</li>\n<li>Bell et al. (2017) 发现南极冰架可能通过表面河流的融水排出而稳定。</li>\n<li>Dow et al. (2018) 发现冰架底部的通道驱动活跃的表面水文学和冰架的横向断裂。</li>\n</ul>\n</li>\n<li><p><strong>不足之处</strong>：</p>\n<ul>\n<li>之前的研究没有明确识别出冰架上的河口，对河口形成和其对冰架稳定性的影响理解有限。</li>\n<li>缺乏对冰架表面河流如何演变成河口的直接观测。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"本文使用的数据和方法\"><a href=\"#本文使用的数据和方法\" class=\"headerlink\" title=\"本文使用的数据和方法\"></a>本文使用的数据和方法</h3><ul>\n<li><p><strong>数据</strong>：</p>\n<ul>\n<li>DigitalGlobe卫星图像、Landsat数据、NASA Operation IceBridge (OIB)数据、气候模型Modèle Atmosphérique Régionale (MAR)输出、南极洲的DEM (REMA)。</li>\n</ul>\n</li>\n<li><p><strong>方法</strong>：</p>\n<ul>\n<li>高分辨率卫星和航空图像分析。</li>\n<li>利用气候模型定性分析表面过程的趋势。</li>\n<li>通过测量图像中河流和河口的宽度，追踪其演变。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"获得的结果\"><a href=\"#获得的结果\" class=\"headerlink\" title=\"获得的结果\"></a>获得的结果</h3><ul>\n<li>观测到彼得曼冰架上的表面河流演变成河口，并且在雷德冰架上发现了第二个河口。</li>\n<li>河口的形成与冰架前沿的裂缝发展和直线崩解事件有关。</li>\n<li>预测在接下来的30年内，南极洲的冰架上可能会形成更多的河口。</li>\n</ul>\n<h3 id=\"本文创新之处及贡献\"><a href=\"#本文创新之处及贡献\" class=\"headerlink\" title=\"本文创新之处及贡献\"></a>本文创新之处及贡献</h3><ul>\n<li><p><strong>创新之处</strong>：</p>\n<ul>\n<li>首次识别出冰架上的河口，并研究了其对冰架稳定性的潜在影响。</li>\n<li>提出了“河口弱化”这一新概念，解释了河口如何促进冰架的直线崩解。</li>\n</ul>\n</li>\n<li><p><strong>贡献</strong>：</p>\n<ul>\n<li>为理解冰架表面水文学对冰架稳定性的影响提供了新的视角。</li>\n<li>对未来南极冰架河口的发展及其对全球海平面上升的潜在影响进行了预测。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"本文不足\"><a href=\"#本文不足\" class=\"headerlink\" title=\"本文不足\"></a>本文不足</h3><ul>\n<li>文章中并未明确指出研究的不足之处，但潜在的不足可能包括：<ul>\n<li>预测模型可能过于简化，未考虑日内河流水文变化对侵蚀率的影响。</li>\n<li>对河口形成所需时间的估计存在不确定性，依赖于多个假设和参数。</li>\n</ul>\n</li>\n</ul>","related_posts":["paper-reading-18.html"],"length":1252,"excerpt":"<p>&emsp;&emsp;<a href=\"https://www.nature.com/articles/s41561-021-00837-7\">Development of ice-shelf estuaries promotes fractures and calving</a></p>","more":"<h3 id=\"摘要\"><a href=\"#摘要\" class=\"headerlink\" title=\"摘要\"></a>摘要</h3><p>随着全球气候变暖，冰架表面的融水增加可能会触发冰架崩塌，加速全球海平面上升。表面河流的形成如果能有效排走融水，也可能有助于防止冰架崩塌。在这里，我们展示了格陵兰西北部彼得曼冰架表面河流演变成冰架河口的演变观测，并在附近的雷德冰架上发现了第二个河口。这种表面水文过程可以促进断裂并增强冰架崩解。在彼得曼河口，观察到海冰在上游河口处汇聚，表明了流动方向的逆转。在周围的冰景冻结后，海水仍持续存在于河口中。沿着彼得曼河口的底部，从崩解前沿开始的线性裂缝沿着通道向上游传播。类似的沿着河口通道的裂缝塑造了彼得曼和雷德冰架上过去的大型直线崩解事件。在一个变暖的世界中，表面融化的增加将增强河流侵蚀，促进河口发展，沿冰架前沿的纵向断裂正交于冰架前沿，并增加直线崩解。河口可能在接下来的半个世纪内出现在南极洲，导致冰架崩解增加，加速冰层损失和全球海平面上升。</p>\n<h3 id=\"研究的重要性\"><a href=\"#研究的重要性\" class=\"headerlink\" title=\"研究的重要性\"></a>研究的重要性</h3><ol>\n<li><strong>冰架稳定性与全球海平面上升</strong>：冰架的稳定性直接关系到全球海平面的变化，是气候变化研究的重要组成部分。</li>\n<li><strong>表面水文学对冰架稳定性的影响</strong>：了解表面河流和河口如何影响冰架的稳定性，对预测冰架未来的变化至关重要。</li>\n</ol>\n<h3 id=\"前人研究与不足\"><a href=\"#前人研究与不足\" class=\"headerlink\" title=\"前人研究与不足\"></a>前人研究与不足</h3><ul>\n<li><p><strong>相关研究</strong>：</p>\n<ul>\n<li>Kingslake et al. (2017) 观察到南极冰架上的融水广泛流动。</li>\n<li>Bell et al. (2017) 发现南极冰架可能通过表面河流的融水排出而稳定。</li>\n<li>Dow et al. (2018) 发现冰架底部的通道驱动活跃的表面水文学和冰架的横向断裂。</li>\n</ul>\n</li>\n<li><p><strong>不足之处</strong>：</p>\n<ul>\n<li>之前的研究没有明确识别出冰架上的河口，对河口形成和其对冰架稳定性的影响理解有限。</li>\n<li>缺乏对冰架表面河流如何演变成河口的直接观测。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"本文使用的数据和方法\"><a href=\"#本文使用的数据和方法\" class=\"headerlink\" title=\"本文使用的数据和方法\"></a>本文使用的数据和方法</h3><ul>\n<li><p><strong>数据</strong>：</p>\n<ul>\n<li>DigitalGlobe卫星图像、Landsat数据、NASA Operation IceBridge (OIB)数据、气候模型Modèle Atmosphérique Régionale (MAR)输出、南极洲的DEM (REMA)。</li>\n</ul>\n</li>\n<li><p><strong>方法</strong>：</p>\n<ul>\n<li>高分辨率卫星和航空图像分析。</li>\n<li>利用气候模型定性分析表面过程的趋势。</li>\n<li>通过测量图像中河流和河口的宽度，追踪其演变。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"获得的结果\"><a href=\"#获得的结果\" class=\"headerlink\" title=\"获得的结果\"></a>获得的结果</h3><ul>\n<li>观测到彼得曼冰架上的表面河流演变成河口，并且在雷德冰架上发现了第二个河口。</li>\n<li>河口的形成与冰架前沿的裂缝发展和直线崩解事件有关。</li>\n<li>预测在接下来的30年内，南极洲的冰架上可能会形成更多的河口。</li>\n</ul>\n<h3 id=\"本文创新之处及贡献\"><a href=\"#本文创新之处及贡献\" class=\"headerlink\" title=\"本文创新之处及贡献\"></a>本文创新之处及贡献</h3><ul>\n<li><p><strong>创新之处</strong>：</p>\n<ul>\n<li>首次识别出冰架上的河口，并研究了其对冰架稳定性的潜在影响。</li>\n<li>提出了“河口弱化”这一新概念，解释了河口如何促进冰架的直线崩解。</li>\n</ul>\n</li>\n<li><p><strong>贡献</strong>：</p>\n<ul>\n<li>为理解冰架表面水文学对冰架稳定性的影响提供了新的视角。</li>\n<li>对未来南极冰架河口的发展及其对全球海平面上升的潜在影响进行了预测。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"本文不足\"><a href=\"#本文不足\" class=\"headerlink\" title=\"本文不足\"></a>本文不足</h3><ul>\n<li>文章中并未明确指出研究的不足之处，但潜在的不足可能包括：<ul>\n<li>预测模型可能过于简化，未考虑日内河流水文变化对侵蚀率的影响。</li>\n<li>对河口形成所需时间的估计存在不确定性，依赖于多个假设和参数。</li>\n</ul>\n</li>\n</ul>"},{"title":"文献阅读（十八）","abbrlink":"7355ba2d","date":"2024-06-29T02:52:56.000Z","_content":"&emsp;&emsp;[Ross Ice Shelf Icequakes Associated With Ocean Gravity Wave Activity](https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2019GL084123)\n<!--less-->\n### 摘要\n\n&emsp;&emsp;罗斯冰架上的冰震活动与海洋重力波活动的振幅有关。在罗斯冰架上部署的宽带地震仪，辅以近冰前海底水听器，确立了强烈的冰震活动与低于0.04赫兹的海洋重力波幅度（AG）之间的关联。罗斯冰架前沿的地震垂直位移幅度（ASV）与AG有很好的相关性，从而可以估计从重力波幅度到冰前垂直位移幅度（TGSV(f)）的频率依赖传递函数。TGSV(f)在0.001–0.01赫兹时为0.6–0.7，但在更高频率时迅速减小。强烈的冰震活动在空间上和季节上与不同的重力波频段有关，最强的冰震主要在南半球夏季观测到，那时海冰最少，涌浪的冲击最强。\n\n### 研究的重要性\n\n1. **冰架稳定性**：冰架对于抑制陆地冰流向海中的流动起着重要作用，其完整性对调节海平面上升至关重要。\n2. **海洋动力影响**：海洋动力可以通过热和动力学两种方式影响冰架的完整性，从而影响全球海平面上升。\n\n### 前人研究与不足\n\n- **相关研究**：\n  - 早期研究将冰架对重力波的响应建模为均匀厚度的漂浮板。\n  - 近期研究包括二维和三维有限元模拟，以及从现场地震数据估算由弯曲和伸展波引起的伸展应力。\n\n- **不足之处**：\n  - 这些模拟表明，引起的动态应力强烈依赖于系统几何形状，包括冰架厚度、物理属性、冰下腔室厚度和海底地形，这些因素具有显著的不确定性和空间变异性，尚未得到充分考虑。\n\n### 本文使用的数据和方法\n\n- **数据**：\n  - 利用在罗斯冰架上部署的34站宽带地震阵列收集的数据，以及海底压力观测数据。\n\n- **方法**：\n  - 使用地震仪和水听器记录的地震数据来估计海洋重力波幅度和冰架前沿的垂直位移幅度。\n  - 通过这些数据来确定一个经验的频率依赖的海洋波-冰架位移幅度传递函数。\n\n### 获得的结果\n\n- 确定了罗斯冰架前沿的地震垂直位移幅度与海洋重力波幅度有很好的相关性。\n- 发现冰震活动在南半球夏季最为频繁，这与海冰的最小化和涌浪冲击的最强有关。\n- 获得了一个从海洋重力波幅度到冰架前沿垂直位移幅度的经验传递函数。\n\n### 本文创新之处及贡献\n\n- **创新之处**：\n  - 首次提供了一个基于观测的海洋到冰架位移传递函数，为理解海洋强迫与冰架响应之间的机械联系提供了新的视角。\n\n- **贡献**：\n  - 为冰架建模工作提供了验证观测，有助于改进现有的冰架响应模型。\n  - 增进了我们对冰架如何响应海洋重力波影响的理解，这对于预测冰架动态和海平面上升具有重要意义。\n\n### 本文不足\n\n- 文章中并未明确指出研究的不足之处，但潜在的不足可能包括：\n  - 研究可能需要进一步验证传递函数在不同条件下的适用性和准确性。\n  - 对于冰架完整性变化的长期影响和更广泛海洋环境因素的综合评估可能需要更多的研究。\n","source":"_posts/2024-06-29-paper-reading-18.md","raw":"---\ntitle: 文献阅读（十八）\ncategories:\n  - work\ntags:\n  - paper\nabbrlink: 7355ba2d\ndate: 2024-06-29 10:52:56\n---\n&emsp;&emsp;[Ross Ice Shelf Icequakes Associated With Ocean Gravity Wave Activity](https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2019GL084123)\n<!--less-->\n### 摘要\n\n&emsp;&emsp;罗斯冰架上的冰震活动与海洋重力波活动的振幅有关。在罗斯冰架上部署的宽带地震仪，辅以近冰前海底水听器，确立了强烈的冰震活动与低于0.04赫兹的海洋重力波幅度（AG）之间的关联。罗斯冰架前沿的地震垂直位移幅度（ASV）与AG有很好的相关性，从而可以估计从重力波幅度到冰前垂直位移幅度（TGSV(f)）的频率依赖传递函数。TGSV(f)在0.001–0.01赫兹时为0.6–0.7，但在更高频率时迅速减小。强烈的冰震活动在空间上和季节上与不同的重力波频段有关，最强的冰震主要在南半球夏季观测到，那时海冰最少，涌浪的冲击最强。\n\n### 研究的重要性\n\n1. **冰架稳定性**：冰架对于抑制陆地冰流向海中的流动起着重要作用，其完整性对调节海平面上升至关重要。\n2. **海洋动力影响**：海洋动力可以通过热和动力学两种方式影响冰架的完整性，从而影响全球海平面上升。\n\n### 前人研究与不足\n\n- **相关研究**：\n  - 早期研究将冰架对重力波的响应建模为均匀厚度的漂浮板。\n  - 近期研究包括二维和三维有限元模拟，以及从现场地震数据估算由弯曲和伸展波引起的伸展应力。\n\n- **不足之处**：\n  - 这些模拟表明，引起的动态应力强烈依赖于系统几何形状，包括冰架厚度、物理属性、冰下腔室厚度和海底地形，这些因素具有显著的不确定性和空间变异性，尚未得到充分考虑。\n\n### 本文使用的数据和方法\n\n- **数据**：\n  - 利用在罗斯冰架上部署的34站宽带地震阵列收集的数据，以及海底压力观测数据。\n\n- **方法**：\n  - 使用地震仪和水听器记录的地震数据来估计海洋重力波幅度和冰架前沿的垂直位移幅度。\n  - 通过这些数据来确定一个经验的频率依赖的海洋波-冰架位移幅度传递函数。\n\n### 获得的结果\n\n- 确定了罗斯冰架前沿的地震垂直位移幅度与海洋重力波幅度有很好的相关性。\n- 发现冰震活动在南半球夏季最为频繁，这与海冰的最小化和涌浪冲击的最强有关。\n- 获得了一个从海洋重力波幅度到冰架前沿垂直位移幅度的经验传递函数。\n\n### 本文创新之处及贡献\n\n- **创新之处**：\n  - 首次提供了一个基于观测的海洋到冰架位移传递函数，为理解海洋强迫与冰架响应之间的机械联系提供了新的视角。\n\n- **贡献**：\n  - 为冰架建模工作提供了验证观测，有助于改进现有的冰架响应模型。\n  - 增进了我们对冰架如何响应海洋重力波影响的理解，这对于预测冰架动态和海平面上升具有重要意义。\n\n### 本文不足\n\n- 文章中并未明确指出研究的不足之处，但潜在的不足可能包括：\n  - 研究可能需要进一步验证传递函数在不同条件下的适用性和准确性。\n  - 对于冰架完整性变化的长期影响和更广泛海洋环境因素的综合评估可能需要更多的研究。\n","slug":"paper-reading-18","published":1,"updated":"2024-06-29T03:10:53.503Z","comments":1,"layout":"post","photos":[],"_id":"cmh498iq000a2wvou9webh8do","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><h3 id=\"摘要\"><a href=\"#摘要\" class=\"headerlink\" title=\"摘要\"></a>摘要</h3><p>&emsp;&emsp;罗斯冰架上的冰震活动与海洋重力波活动的振幅有关。在罗斯冰架上部署的宽带地震仪，辅以近冰前海底水听器，确立了强烈的冰震活动与低于0.04赫兹的海洋重力波幅度（AG）之间的关联。罗斯冰架前沿的地震垂直位移幅度（ASV）与AG有很好的相关性，从而可以估计从重力波幅度到冰前垂直位移幅度（TGSV(f)）的频率依赖传递函数。TGSV(f)在0.001–0.01赫兹时为0.6–0.7，但在更高频率时迅速减小。强烈的冰震活动在空间上和季节上与不同的重力波频段有关，最强的冰震主要在南半球夏季观测到，那时海冰最少，涌浪的冲击最强。</p>\n<h3 id=\"研究的重要性\"><a href=\"#研究的重要性\" class=\"headerlink\" title=\"研究的重要性\"></a>研究的重要性</h3><ol>\n<li><strong>冰架稳定性</strong>：冰架对于抑制陆地冰流向海中的流动起着重要作用，其完整性对调节海平面上升至关重要。</li>\n<li><strong>海洋动力影响</strong>：海洋动力可以通过热和动力学两种方式影响冰架的完整性，从而影响全球海平面上升。</li>\n</ol>\n<h3 id=\"前人研究与不足\"><a href=\"#前人研究与不足\" class=\"headerlink\" title=\"前人研究与不足\"></a>前人研究与不足</h3><ul>\n<li><p><strong>相关研究</strong>：</p>\n<ul>\n<li>早期研究将冰架对重力波的响应建模为均匀厚度的漂浮板。</li>\n<li>近期研究包括二维和三维有限元模拟，以及从现场地震数据估算由弯曲和伸展波引起的伸展应力。</li>\n</ul>\n</li>\n<li><p><strong>不足之处</strong>：</p>\n<ul>\n<li>这些模拟表明，引起的动态应力强烈依赖于系统几何形状，包括冰架厚度、物理属性、冰下腔室厚度和海底地形，这些因素具有显著的不确定性和空间变异性，尚未得到充分考虑。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"本文使用的数据和方法\"><a href=\"#本文使用的数据和方法\" class=\"headerlink\" title=\"本文使用的数据和方法\"></a>本文使用的数据和方法</h3><ul>\n<li><p><strong>数据</strong>：</p>\n<ul>\n<li>利用在罗斯冰架上部署的34站宽带地震阵列收集的数据，以及海底压力观测数据。</li>\n</ul>\n</li>\n<li><p><strong>方法</strong>：</p>\n<ul>\n<li>使用地震仪和水听器记录的地震数据来估计海洋重力波幅度和冰架前沿的垂直位移幅度。</li>\n<li>通过这些数据来确定一个经验的频率依赖的海洋波-冰架位移幅度传递函数。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"获得的结果\"><a href=\"#获得的结果\" class=\"headerlink\" title=\"获得的结果\"></a>获得的结果</h3><ul>\n<li>确定了罗斯冰架前沿的地震垂直位移幅度与海洋重力波幅度有很好的相关性。</li>\n<li>发现冰震活动在南半球夏季最为频繁，这与海冰的最小化和涌浪冲击的最强有关。</li>\n<li>获得了一个从海洋重力波幅度到冰架前沿垂直位移幅度的经验传递函数。</li>\n</ul>\n<h3 id=\"本文创新之处及贡献\"><a href=\"#本文创新之处及贡献\" class=\"headerlink\" title=\"本文创新之处及贡献\"></a>本文创新之处及贡献</h3><ul>\n<li><p><strong>创新之处</strong>：</p>\n<ul>\n<li>首次提供了一个基于观测的海洋到冰架位移传递函数，为理解海洋强迫与冰架响应之间的机械联系提供了新的视角。</li>\n</ul>\n</li>\n<li><p><strong>贡献</strong>：</p>\n<ul>\n<li>为冰架建模工作提供了验证观测，有助于改进现有的冰架响应模型。</li>\n<li>增进了我们对冰架如何响应海洋重力波影响的理解，这对于预测冰架动态和海平面上升具有重要意义。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"本文不足\"><a href=\"#本文不足\" class=\"headerlink\" title=\"本文不足\"></a>本文不足</h3><ul>\n<li>文章中并未明确指出研究的不足之处，但潜在的不足可能包括：<ul>\n<li>研究可能需要进一步验证传递函数在不同条件下的适用性和准确性。</li>\n<li>对于冰架完整性变化的长期影响和更广泛海洋环境因素的综合评估可能需要更多的研究。</li>\n</ul>\n</li>\n</ul>","related_posts":["paper-reading-17.html","paper-reading-20.html"],"length":1083,"excerpt":"<p>&emsp;&emsp;<a href=\"https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2019GL084123\">Ross Ice Shelf Icequakes Associated With Ocean Gravity Wave Activity</a></p>","more":"<h3 id=\"摘要\"><a href=\"#摘要\" class=\"headerlink\" title=\"摘要\"></a>摘要</h3><p>&emsp;&emsp;罗斯冰架上的冰震活动与海洋重力波活动的振幅有关。在罗斯冰架上部署的宽带地震仪，辅以近冰前海底水听器，确立了强烈的冰震活动与低于0.04赫兹的海洋重力波幅度（AG）之间的关联。罗斯冰架前沿的地震垂直位移幅度（ASV）与AG有很好的相关性，从而可以估计从重力波幅度到冰前垂直位移幅度（TGSV(f)）的频率依赖传递函数。TGSV(f)在0.001–0.01赫兹时为0.6–0.7，但在更高频率时迅速减小。强烈的冰震活动在空间上和季节上与不同的重力波频段有关，最强的冰震主要在南半球夏季观测到，那时海冰最少，涌浪的冲击最强。</p>\n<h3 id=\"研究的重要性\"><a href=\"#研究的重要性\" class=\"headerlink\" title=\"研究的重要性\"></a>研究的重要性</h3><ol>\n<li><strong>冰架稳定性</strong>：冰架对于抑制陆地冰流向海中的流动起着重要作用，其完整性对调节海平面上升至关重要。</li>\n<li><strong>海洋动力影响</strong>：海洋动力可以通过热和动力学两种方式影响冰架的完整性，从而影响全球海平面上升。</li>\n</ol>\n<h3 id=\"前人研究与不足\"><a href=\"#前人研究与不足\" class=\"headerlink\" title=\"前人研究与不足\"></a>前人研究与不足</h3><ul>\n<li><p><strong>相关研究</strong>：</p>\n<ul>\n<li>早期研究将冰架对重力波的响应建模为均匀厚度的漂浮板。</li>\n<li>近期研究包括二维和三维有限元模拟，以及从现场地震数据估算由弯曲和伸展波引起的伸展应力。</li>\n</ul>\n</li>\n<li><p><strong>不足之处</strong>：</p>\n<ul>\n<li>这些模拟表明，引起的动态应力强烈依赖于系统几何形状，包括冰架厚度、物理属性、冰下腔室厚度和海底地形，这些因素具有显著的不确定性和空间变异性，尚未得到充分考虑。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"本文使用的数据和方法\"><a href=\"#本文使用的数据和方法\" class=\"headerlink\" title=\"本文使用的数据和方法\"></a>本文使用的数据和方法</h3><ul>\n<li><p><strong>数据</strong>：</p>\n<ul>\n<li>利用在罗斯冰架上部署的34站宽带地震阵列收集的数据，以及海底压力观测数据。</li>\n</ul>\n</li>\n<li><p><strong>方法</strong>：</p>\n<ul>\n<li>使用地震仪和水听器记录的地震数据来估计海洋重力波幅度和冰架前沿的垂直位移幅度。</li>\n<li>通过这些数据来确定一个经验的频率依赖的海洋波-冰架位移幅度传递函数。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"获得的结果\"><a href=\"#获得的结果\" class=\"headerlink\" title=\"获得的结果\"></a>获得的结果</h3><ul>\n<li>确定了罗斯冰架前沿的地震垂直位移幅度与海洋重力波幅度有很好的相关性。</li>\n<li>发现冰震活动在南半球夏季最为频繁，这与海冰的最小化和涌浪冲击的最强有关。</li>\n<li>获得了一个从海洋重力波幅度到冰架前沿垂直位移幅度的经验传递函数。</li>\n</ul>\n<h3 id=\"本文创新之处及贡献\"><a href=\"#本文创新之处及贡献\" class=\"headerlink\" title=\"本文创新之处及贡献\"></a>本文创新之处及贡献</h3><ul>\n<li><p><strong>创新之处</strong>：</p>\n<ul>\n<li>首次提供了一个基于观测的海洋到冰架位移传递函数，为理解海洋强迫与冰架响应之间的机械联系提供了新的视角。</li>\n</ul>\n</li>\n<li><p><strong>贡献</strong>：</p>\n<ul>\n<li>为冰架建模工作提供了验证观测，有助于改进现有的冰架响应模型。</li>\n<li>增进了我们对冰架如何响应海洋重力波影响的理解，这对于预测冰架动态和海平面上升具有重要意义。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"本文不足\"><a href=\"#本文不足\" class=\"headerlink\" title=\"本文不足\"></a>本文不足</h3><ul>\n<li>文章中并未明确指出研究的不足之处，但潜在的不足可能包括：<ul>\n<li>研究可能需要进一步验证传递函数在不同条件下的适用性和准确性。</li>\n<li>对于冰架完整性变化的长期影响和更广泛海洋环境因素的综合评估可能需要更多的研究。</li>\n</ul>\n</li>\n</ul>"},{"title":"如何下载S-net数据","abbrlink":"2bac6571","date":"2024-07-09T07:16:25.000Z","_content":"&emsp;&emsp;如何下载S-net数据呢？\n<!--less-->\n&emsp;&emsp;S-net是NIED（日本国立防灾科学技术研究所）布设的海底地震动观测网络，由150台三分量地震仪组成。观测区域覆盖了2011年东日本大地震及其邻近地区的震源区域。自2017年4月以来，S-net已全面开始运作，实时地将数据传回NIED。\n&emsp;&emsp;如何下载S-net的数据呢？参见Seisman的[HinetPy](https://seisman.github.io/HinetPy/)。\n### 安装\n1. 用命令安装HinetPy，用python3.8以上版本，命令为。\n```\npython -m pip install HinetPy\n```\n2. 安装win32tools\n在[hinet](https://hinetwww11.bosai.go.jp/auth/manual/?LANG=en)网站下载安装包[win32tools.tar.gz](https://hinetwww11.bosai.go.jp/auth/manual/dlDialogue.php?r=win32tools)，运行:\n```bash\ntar -xvf win32tools.tar.gz\ncd win32tools/\nmake\n```\n把catwin32.src/catwin32和win2sac.src/win2sac_32拷贝到环境变量认识的位置。\n### 运行\n&emsp;&emsp;具体怎么下载数据自己去看说明就好了。我想要下载连续数据，所以写了个循环脚本，如下：\n```\nimport os\nfrom HinetPy import Client\nfrom HinetPy import win32\nfrom datetime import datetime,timedelta\n\nclient = Client (\"xxxx\",\"xxxx\")\n# 这里输入你自己的账号和密码。自己申请就好了。\nendtime=datetime(2016,8,16,2,0) # 截至时间\ntime=datetime(2016,8,16,1,40)   # 开始时间\ndt=timedelta(minutes=20)        # 时间增量（分钟记）\ndir=\"data\"                      # 数据存在dir下面\nwhile (time<endtime):\n    print(time,endtime)\n    y=\"%04d\"%time.year\n    m=\"%02d\"%time.month\n    d=\"%02d\"%time.day\n    h=\"%02d\"%time.hour\n    mm=\"%02d\"%time.minute\n    name=y+\"_\"+m+\"_\"+d+\"_\"+h+\"_\"+mm+\".cnt\"\n    cname=y+\"_\"+m+\"_\"+d+\"_\"+h+\"_\"+mm+\".ch\"\n    outd=dir+\"/\"+y+\"_\"+m+\"_\"+d+\"_\"+h+\"_\"+mm #每20分钟一个文件夹\n    data=dir+\"/\"+y+\"_\"+m+\"_\"+d+\"_\"+h+\"_\"+mm+\".cnt\"\n    ctable=dir+\"/\"+y+\"_\"+m+\"_\"+d+\"_\"+h+\"_\"+mm+\".ch\"\n    if not os.path.exists(ctable):\n        # 如果仪器信息文件没有则创建一个空的，这样做可以多跑几个进程，同时下载，并保证不重复。\n        with open(ctable, 'w') as file:\n            pass\n        dat,ctabl = client.get_continuous_waveform(\"0120\",time,20,data=name,ctable=cname,outdir=dir) # 下载数据，这里0120就是指代S-net。client.info()可以查看所有台网。 outdir指定保存数据的文件夹。\n        if os.access(data, os.F_OK):\n        # 如果下载成功则进行解压。如果没有数据，强行进行解压，程序就出错跳出来。\n        #if os.path.getsize(data) != 0:\n            win32.extract_sac(data,ctable,outdir=outd) #解压sac。\n            win32.extract_sacpz(ctable, outdir=outd) #解压仪器响应。\n    time=time+dt\n```\n&emsp;&emsp;NEID下载数据有个限制就是道数X时间（按分钟记）<12000。S-net有150个台，三分量就是450道，因此12000/450=26.666分钟，即每次最长可下载不超过26分钟数据。为了方便我搞的是20分钟。\n&emsp;&emsp;其他没有什么问题，就是下载数据好慢。\n","source":"_posts/2024-07-09-how-to-download-Snet-data.md","raw":"---\ntitle: 如何下载S-net数据\ncategories:\n  - work\ntags:\n  - seismic\nabbrlink: 2bac6571\ndate: 2024-07-09 15:16:25\n---\n&emsp;&emsp;如何下载S-net数据呢？\n<!--less-->\n&emsp;&emsp;S-net是NIED（日本国立防灾科学技术研究所）布设的海底地震动观测网络，由150台三分量地震仪组成。观测区域覆盖了2011年东日本大地震及其邻近地区的震源区域。自2017年4月以来，S-net已全面开始运作，实时地将数据传回NIED。\n&emsp;&emsp;如何下载S-net的数据呢？参见Seisman的[HinetPy](https://seisman.github.io/HinetPy/)。\n### 安装\n1. 用命令安装HinetPy，用python3.8以上版本，命令为。\n```\npython -m pip install HinetPy\n```\n2. 安装win32tools\n在[hinet](https://hinetwww11.bosai.go.jp/auth/manual/?LANG=en)网站下载安装包[win32tools.tar.gz](https://hinetwww11.bosai.go.jp/auth/manual/dlDialogue.php?r=win32tools)，运行:\n```bash\ntar -xvf win32tools.tar.gz\ncd win32tools/\nmake\n```\n把catwin32.src/catwin32和win2sac.src/win2sac_32拷贝到环境变量认识的位置。\n### 运行\n&emsp;&emsp;具体怎么下载数据自己去看说明就好了。我想要下载连续数据，所以写了个循环脚本，如下：\n```\nimport os\nfrom HinetPy import Client\nfrom HinetPy import win32\nfrom datetime import datetime,timedelta\n\nclient = Client (\"xxxx\",\"xxxx\")\n# 这里输入你自己的账号和密码。自己申请就好了。\nendtime=datetime(2016,8,16,2,0) # 截至时间\ntime=datetime(2016,8,16,1,40)   # 开始时间\ndt=timedelta(minutes=20)        # 时间增量（分钟记）\ndir=\"data\"                      # 数据存在dir下面\nwhile (time<endtime):\n    print(time,endtime)\n    y=\"%04d\"%time.year\n    m=\"%02d\"%time.month\n    d=\"%02d\"%time.day\n    h=\"%02d\"%time.hour\n    mm=\"%02d\"%time.minute\n    name=y+\"_\"+m+\"_\"+d+\"_\"+h+\"_\"+mm+\".cnt\"\n    cname=y+\"_\"+m+\"_\"+d+\"_\"+h+\"_\"+mm+\".ch\"\n    outd=dir+\"/\"+y+\"_\"+m+\"_\"+d+\"_\"+h+\"_\"+mm #每20分钟一个文件夹\n    data=dir+\"/\"+y+\"_\"+m+\"_\"+d+\"_\"+h+\"_\"+mm+\".cnt\"\n    ctable=dir+\"/\"+y+\"_\"+m+\"_\"+d+\"_\"+h+\"_\"+mm+\".ch\"\n    if not os.path.exists(ctable):\n        # 如果仪器信息文件没有则创建一个空的，这样做可以多跑几个进程，同时下载，并保证不重复。\n        with open(ctable, 'w') as file:\n            pass\n        dat,ctabl = client.get_continuous_waveform(\"0120\",time,20,data=name,ctable=cname,outdir=dir) # 下载数据，这里0120就是指代S-net。client.info()可以查看所有台网。 outdir指定保存数据的文件夹。\n        if os.access(data, os.F_OK):\n        # 如果下载成功则进行解压。如果没有数据，强行进行解压，程序就出错跳出来。\n        #if os.path.getsize(data) != 0:\n            win32.extract_sac(data,ctable,outdir=outd) #解压sac。\n            win32.extract_sacpz(ctable, outdir=outd) #解压仪器响应。\n    time=time+dt\n```\n&emsp;&emsp;NEID下载数据有个限制就是道数X时间（按分钟记）<12000。S-net有150个台，三分量就是450道，因此12000/450=26.666分钟，即每次最长可下载不超过26分钟数据。为了方便我搞的是20分钟。\n&emsp;&emsp;其他没有什么问题，就是下载数据好慢。\n","slug":"how-to-download-Snet-data","published":1,"updated":"2024-07-09T09:11:16.289Z","comments":1,"layout":"post","photos":[],"_id":"cmh498iq100a5wvoudgl9begy","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>&emsp;&emsp;S-net是NIED（日本国立防灾科学技术研究所）布设的海底地震动观测网络，由150台三分量地震仪组成。观测区域覆盖了2011年东日本大地震及其邻近地区的震源区域。自2017年4月以来，S-net已全面开始运作，实时地将数据传回NIED。<br>&emsp;&emsp;如何下载S-net的数据呢？参见Seisman的<a href=\"https://seisman.github.io/HinetPy/\">HinetPy</a>。</p>\n<h3 id=\"安装\"><a href=\"#安装\" class=\"headerlink\" title=\"安装\"></a>安装</h3><ol>\n<li>用命令安装HinetPy，用python3.8以上版本，命令为。<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">python -m pip install HinetPy</span><br></pre></td></tr></table></figure></li>\n<li>安装win32tools<br>在<a href=\"https://hinetwww11.bosai.go.jp/auth/manual/?LANG=en\">hinet</a>网站下载安装包<a href=\"https://hinetwww11.bosai.go.jp/auth/manual/dlDialogue.php?r=win32tools\">win32tools.tar.gz</a>，运行:<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">tar -xvf win32tools.tar.gz</span><br><span class=\"line\"><span class=\"built_in\">cd</span> win32tools/</span><br><span class=\"line\">make</span><br></pre></td></tr></table></figure>\n把catwin32.src&#x2F;catwin32和win2sac.src&#x2F;win2sac_32拷贝到环境变量认识的位置。</li>\n</ol>\n<h3 id=\"运行\"><a href=\"#运行\" class=\"headerlink\" title=\"运行\"></a>运行</h3><p>&emsp;&emsp;具体怎么下载数据自己去看说明就好了。我想要下载连续数据，所以写了个循环脚本，如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">import os</span><br><span class=\"line\">from HinetPy import Client</span><br><span class=\"line\">from HinetPy import win32</span><br><span class=\"line\">from datetime import datetime,timedelta</span><br><span class=\"line\"></span><br><span class=\"line\">client = Client (&quot;xxxx&quot;,&quot;xxxx&quot;)</span><br><span class=\"line\"># 这里输入你自己的账号和密码。自己申请就好了。</span><br><span class=\"line\">endtime=datetime(2016,8,16,2,0) # 截至时间</span><br><span class=\"line\">time=datetime(2016,8,16,1,40)   # 开始时间</span><br><span class=\"line\">dt=timedelta(minutes=20)        # 时间增量（分钟记）</span><br><span class=\"line\">dir=&quot;data&quot;                      # 数据存在dir下面</span><br><span class=\"line\">while (time&lt;endtime):</span><br><span class=\"line\">    print(time,endtime)</span><br><span class=\"line\">    y=&quot;%04d&quot;%time.year</span><br><span class=\"line\">    m=&quot;%02d&quot;%time.month</span><br><span class=\"line\">    d=&quot;%02d&quot;%time.day</span><br><span class=\"line\">    h=&quot;%02d&quot;%time.hour</span><br><span class=\"line\">    mm=&quot;%02d&quot;%time.minute</span><br><span class=\"line\">    name=y+&quot;_&quot;+m+&quot;_&quot;+d+&quot;_&quot;+h+&quot;_&quot;+mm+&quot;.cnt&quot;</span><br><span class=\"line\">    cname=y+&quot;_&quot;+m+&quot;_&quot;+d+&quot;_&quot;+h+&quot;_&quot;+mm+&quot;.ch&quot;</span><br><span class=\"line\">    outd=dir+&quot;/&quot;+y+&quot;_&quot;+m+&quot;_&quot;+d+&quot;_&quot;+h+&quot;_&quot;+mm #每20分钟一个文件夹</span><br><span class=\"line\">    data=dir+&quot;/&quot;+y+&quot;_&quot;+m+&quot;_&quot;+d+&quot;_&quot;+h+&quot;_&quot;+mm+&quot;.cnt&quot;</span><br><span class=\"line\">    ctable=dir+&quot;/&quot;+y+&quot;_&quot;+m+&quot;_&quot;+d+&quot;_&quot;+h+&quot;_&quot;+mm+&quot;.ch&quot;</span><br><span class=\"line\">    if not os.path.exists(ctable):</span><br><span class=\"line\">        # 如果仪器信息文件没有则创建一个空的，这样做可以多跑几个进程，同时下载，并保证不重复。</span><br><span class=\"line\">        with open(ctable, &#x27;w&#x27;) as file:</span><br><span class=\"line\">            pass</span><br><span class=\"line\">        dat,ctabl = client.get_continuous_waveform(&quot;0120&quot;,time,20,data=name,ctable=cname,outdir=dir) # 下载数据，这里0120就是指代S-net。client.info()可以查看所有台网。 outdir指定保存数据的文件夹。</span><br><span class=\"line\">        if os.access(data, os.F_OK):</span><br><span class=\"line\">        # 如果下载成功则进行解压。如果没有数据，强行进行解压，程序就出错跳出来。</span><br><span class=\"line\">        #if os.path.getsize(data) != 0:</span><br><span class=\"line\">            win32.extract_sac(data,ctable,outdir=outd) #解压sac。</span><br><span class=\"line\">            win32.extract_sacpz(ctable, outdir=outd) #解压仪器响应。</span><br><span class=\"line\">    time=time+dt</span><br></pre></td></tr></table></figure>\n<p>&emsp;&emsp;NEID下载数据有个限制就是道数X时间（按分钟记）&lt;12000。S-net有150个台，三分量就是450道，因此12000&#x2F;450&#x3D;26.666分钟，即每次最长可下载不超过26分钟数据。为了方便我搞的是20分钟。<br>&emsp;&emsp;其他没有什么问题，就是下载数据好慢。</p>","related_posts":["problem-of-urllib3.html"],"length":2132,"excerpt":"<p>&emsp;&emsp;如何下载S-net数据呢？</p>","more":"<p>&emsp;&emsp;S-net是NIED（日本国立防灾科学技术研究所）布设的海底地震动观测网络，由150台三分量地震仪组成。观测区域覆盖了2011年东日本大地震及其邻近地区的震源区域。自2017年4月以来，S-net已全面开始运作，实时地将数据传回NIED。<br>&emsp;&emsp;如何下载S-net的数据呢？参见Seisman的<a href=\"https://seisman.github.io/HinetPy/\">HinetPy</a>。</p>\n<h3 id=\"安装\"><a href=\"#安装\" class=\"headerlink\" title=\"安装\"></a>安装</h3><ol>\n<li>用命令安装HinetPy，用python3.8以上版本，命令为。<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">python -m pip install HinetPy</span><br></pre></td></tr></table></figure></li>\n<li>安装win32tools<br>在<a href=\"https://hinetwww11.bosai.go.jp/auth/manual/?LANG=en\">hinet</a>网站下载安装包<a href=\"https://hinetwww11.bosai.go.jp/auth/manual/dlDialogue.php?r=win32tools\">win32tools.tar.gz</a>，运行:<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">tar -xvf win32tools.tar.gz</span><br><span class=\"line\"><span class=\"built_in\">cd</span> win32tools/</span><br><span class=\"line\">make</span><br></pre></td></tr></table></figure>\n把catwin32.src&#x2F;catwin32和win2sac.src&#x2F;win2sac_32拷贝到环境变量认识的位置。</li>\n</ol>\n<h3 id=\"运行\"><a href=\"#运行\" class=\"headerlink\" title=\"运行\"></a>运行</h3><p>&emsp;&emsp;具体怎么下载数据自己去看说明就好了。我想要下载连续数据，所以写了个循环脚本，如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">import os</span><br><span class=\"line\">from HinetPy import Client</span><br><span class=\"line\">from HinetPy import win32</span><br><span class=\"line\">from datetime import datetime,timedelta</span><br><span class=\"line\"></span><br><span class=\"line\">client = Client (&quot;xxxx&quot;,&quot;xxxx&quot;)</span><br><span class=\"line\"># 这里输入你自己的账号和密码。自己申请就好了。</span><br><span class=\"line\">endtime=datetime(2016,8,16,2,0) # 截至时间</span><br><span class=\"line\">time=datetime(2016,8,16,1,40)   # 开始时间</span><br><span class=\"line\">dt=timedelta(minutes=20)        # 时间增量（分钟记）</span><br><span class=\"line\">dir=&quot;data&quot;                      # 数据存在dir下面</span><br><span class=\"line\">while (time&lt;endtime):</span><br><span class=\"line\">    print(time,endtime)</span><br><span class=\"line\">    y=&quot;%04d&quot;%time.year</span><br><span class=\"line\">    m=&quot;%02d&quot;%time.month</span><br><span class=\"line\">    d=&quot;%02d&quot;%time.day</span><br><span class=\"line\">    h=&quot;%02d&quot;%time.hour</span><br><span class=\"line\">    mm=&quot;%02d&quot;%time.minute</span><br><span class=\"line\">    name=y+&quot;_&quot;+m+&quot;_&quot;+d+&quot;_&quot;+h+&quot;_&quot;+mm+&quot;.cnt&quot;</span><br><span class=\"line\">    cname=y+&quot;_&quot;+m+&quot;_&quot;+d+&quot;_&quot;+h+&quot;_&quot;+mm+&quot;.ch&quot;</span><br><span class=\"line\">    outd=dir+&quot;/&quot;+y+&quot;_&quot;+m+&quot;_&quot;+d+&quot;_&quot;+h+&quot;_&quot;+mm #每20分钟一个文件夹</span><br><span class=\"line\">    data=dir+&quot;/&quot;+y+&quot;_&quot;+m+&quot;_&quot;+d+&quot;_&quot;+h+&quot;_&quot;+mm+&quot;.cnt&quot;</span><br><span class=\"line\">    ctable=dir+&quot;/&quot;+y+&quot;_&quot;+m+&quot;_&quot;+d+&quot;_&quot;+h+&quot;_&quot;+mm+&quot;.ch&quot;</span><br><span class=\"line\">    if not os.path.exists(ctable):</span><br><span class=\"line\">        # 如果仪器信息文件没有则创建一个空的，这样做可以多跑几个进程，同时下载，并保证不重复。</span><br><span class=\"line\">        with open(ctable, &#x27;w&#x27;) as file:</span><br><span class=\"line\">            pass</span><br><span class=\"line\">        dat,ctabl = client.get_continuous_waveform(&quot;0120&quot;,time,20,data=name,ctable=cname,outdir=dir) # 下载数据，这里0120就是指代S-net。client.info()可以查看所有台网。 outdir指定保存数据的文件夹。</span><br><span class=\"line\">        if os.access(data, os.F_OK):</span><br><span class=\"line\">        # 如果下载成功则进行解压。如果没有数据，强行进行解压，程序就出错跳出来。</span><br><span class=\"line\">        #if os.path.getsize(data) != 0:</span><br><span class=\"line\">            win32.extract_sac(data,ctable,outdir=outd) #解压sac。</span><br><span class=\"line\">            win32.extract_sacpz(ctable, outdir=outd) #解压仪器响应。</span><br><span class=\"line\">    time=time+dt</span><br></pre></td></tr></table></figure>\n<p>&emsp;&emsp;NEID下载数据有个限制就是道数X时间（按分钟记）&lt;12000。S-net有150个台，三分量就是450道，因此12000&#x2F;450&#x3D;26.666分钟，即每次最长可下载不超过26分钟数据。为了方便我搞的是20分钟。<br>&emsp;&emsp;其他没有什么问题，就是下载数据好慢。</p>"},{"title":"学习聚束分析(一)","abbrlink":"cd52224a","date":"2024-07-19T13:27:44.000Z","mathjax":true,"_content":"\n&emsp;&emsp;这是聚束分析学习一，参见[这里](https://geophydog.cool/post/music_array_process/)。\n\n<!--less-->\n\n&emsp;&emsp;聚束分析技术（Bartlett 聚束成形器）虽然稳定性和稳健性很好，但分辨率较差。Schmidt 提出了一种称为多信号分类 （MUSIC） 的新聚束分析算法，用于在保持波束形成器稳定性的同时解决分辨率问题 （Schmidt, 1986）。这里我们学习 MUSIC 算法，并给出一些Python代码来展示该技术的工作原理。\n\n\n&emsp;&emsp;假设一个信号为$u(t)$则傅里叶频谱为$U(\\omega)$, $N$ 个接收器的向量为, \n$$ \\vec{u}(\\omega) = [U_{1}(\\omega), U_{2}(\\omega), \\cdots, U_{N}(\\omega)]^T \\tag{1} $$ \n互相关矩阵由下式给出,\n$$ \\bar{C}(\\omega) = \\frac{1}{N}\\vec{u}(\\omega) \\vec{u}^H(\\omega) \\tag{2} $$ \n式中$H$表示Hermitian转置算符。互相关矩阵$\\bar{C}(\\omega)$通常受到非相干信号及仪器产生的噪声干扰。因此该矩阵包括相干信号和噪声。对$\\bar{C}(\\omega)$进行特征值分解获得，\n\n$$ \\bar{C}(\\omega) = \\bar{E}(\\omega) \\bar{\\Lambda}(\\omega) \\bar{E}^{-1}(\\omega) \\tag{3} $$\n\n式中$\\bar{E}(\\omega)$由$N$个特征向量$\\vec{e}_{i} $ 组成，\n\n$$ \\bar{E}(\\omega) = [\\vec{e}_1, \\vec{e}_2, \\cdots, \\vec{e}_N] \\tag{4} $$\n\n$\\bar{\\Lambda}(\\omega)$ 是对角矩阵，对角元素$\\lambda_{i}$是$\\bar{C}(\\omega)$的特征值，\n\n$$ \\bar{\\Lambda}(\\omega) = diag \\{ \\lambda_{1}, \\lambda_{2}, \\cdots, \\lambda_{N} \\} \\tag{5} $$\n\n&emsp;&emsp;最大的特征值表示相干信号（可能有多个相干信号），左边的特征值及其特征向量被噪声占据，这意味着这些噪声是正交的。在这里，我们使用噪声的特征向量构造一个新矩阵\n\n$$ \\bar{N}_e(\\omega) = [\\vec{e}_1, \\vec{e}_2, \\cdots, \\vec{e}_{ne}] [\\vec{e}_1, \\vec{e}_2, \\cdots, \\vec{e}_{ne}]^H \\tag{6} $$\n\n&emsp;&emsp;Barlett聚束器从 \n\n$$ P(\\omega) = \\vec{a}(\\omega) \\bar{C}(\\omega) \\vec{a}^H(\\omega) \\tag{7} $$\n\n变为，\n\n$$ P(\\omega) =\\frac{1}{ \\vec{a}(\\omega) \\bar{N}_e(\\omega) \\vec{a}^H(\\omega) } \\tag{8} $$ \n式中 $\\vec{a}(\\omega)$ 表示转向向量 $\\vec{a}_n=e^{-i\\omega \\Delta t_n}$。 当我们将转向向量投影到噪声特征向量跨越的噪声矩阵子空间时, 公式$(8)$的分母项将为零。在这种情况下 $P(\\omega)$ 将取极大值。$\\Delta t_n$ 是时间延迟，其形式为，\n\n$$ \\Delta t_{n} = \\vec{s} \\cdot \\vec{r}_n \\tag{9} $$\n\n式中$\\vec{s}=s[-sin\\theta, -cos\\theta]^T$ 和 $\\vec{r}_{n}$ 是慢度和位置矢量，其中接收器的反方位角为$\\theta$。$\\vec{r}_s$ 和 $v$ 是源位置向量和传播速度。\n\n&emsp;&emsp;MUSIC 算法在分辨率上优于 Bartlett 波束成形器。然而，与 MUSIC 相比，Bartlett 波束成形器具有更好的稳定性。以下是两种算法的python脚本示例。\n```\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# ARF of the Bartlett beamformer.\ndef arf_beam_barlett(c0, xy, f0=10, b0=90, s0=3.5e-3, b1=0, b2=360, nb=181, s1=1e-3, s2=5e-3, ns=81):\n    n = xy.shape[0]\n    a = np.zeros((n, 1), dtype=complex)\n    b = np.linspace(b1, b2, nb)\n    bb = np.radians(b)\n    s = np.linspace(s1, s2, ns)\n    p = np.zeros((ns, nb), dtype=complex)\n    for i in range(ns):\n        for j in range(nb):\n            shift = -s[i] * (np.sin(bb[j])*xy[:, 0]+np.cos(bb[j])*xy[:, 1])\n            a[:, 0] = np.exp(-2j*np.pi*f0*shift)\n            p[i, j] = np.conjugate(a.T) @ c0 @ a\n    return b, s, p/n**2\n\n# ARF of the MUSIC beamformer.\ndef arf_beam_music(c0, xy, f0=10, b0=90, s0=3.5e-3, b1=0, b2=360, nb=181, s1=1e-3, s2=5e-3, ns=81, ne=10):\n    n = xy.shape[0]\n    a = np.zeros((n, 1), dtype=complex)\n    b = np.linspace(b1, b2, nb)\n    bb = np.radians(b)\n    s = np.linspace(s1, s2, ns)\n    p = np.zeros((ns, nb), dtype=complex)\n    w, v = np.linalg.eigh(c0)\n    ve = v[:, :ne]\n    ne = ve @ np.conjugate(ve.T)\n\n    for i in range(ns):\n        for j in range(nb):\n            shift = -s[i] * (np.sin(bb[j])*xy[:, 0]+np.cos(bb[j])*xy[:, 1])\n            a[:, 0] = np.exp(-2j*np.pi*f0*shift)\n            p[i, j] = 1 / (np.conjugate(a.T) @ ne @ a)\n    return b, s, p / np.abs(p).max()\n```\n```\n# Number of receivers\nnr = 15\n# Aperture of the array\nr = 1e2\n# Randomly generating the Cartician coordinates\nxy = np.random.random((nr, 2)) * r\n# Frequency, back-azimuth and slowness of signal\nf0 = 5; b0 = 90; s0 = 3.5e-3\n# From degree to radian\nbb0 = np.radians(b0)\n# Fourier vector if signal\nu = np.zeros((nr, 1), dtype=complex)\nu[:, 0] = np.exp(-2j*np.pi*f0*s0*(-np.sin(bb0)*xy[:, 0]-np.cos(bb0)*xy[:, 1]))\n# Generating correlation matrix using u\nc0 = u @ np.conjugate(u.T)\nc0 /= np.abs(c0); c0[np.isnan(c0)] = 0.\n# Back-azimuth and slowness ranges of computing\nb1 = 0; b2 = 360; nb = 361\ns1 = 1e-3; s2 = 5e-3; ns = 81\n# Adding noise to the correlation matrix\nnoiser = np.random.randn(nr, nr)\nnoisei = np.random.randn(nr, nr)\nratio = 1.25\nc0 = c0 + noiser * ratio + 1j * noisei * ratio\n# Computing the Bartlett beamformer\nb, s, p1 = arf_beam_barlett(c0, xy, f0=f0, b0=b0, s0=s0, b1=b1, b2=b2, nb=nb, s1=s1, s2=s2, ns=ns)\n# Computing the MUSIC beamformer.\n_, _, p2 = arf_beam_music(c0, xy, f0=f0, b0=b0, s0=s0, b1=b1, b2=b2, nb=nb, s1=s1, s2=s2, ns=ns, ne=nr-1)\n# Normalizing beam power\np1 = np.abs(p1); p1 /= p1.max()\np2 = np.abs(p2); p2 /= p2.max()\n\n\n## Visualizing the beam power results.\n# Array configuration\nplt.figure(figsize=(12, 8))\nplt.subplot(221)\nplt.scatter(xy[:, 0], xy[:, 1], marker='v', s=100, edgecolor='k', alpha=0.5)\nplt.xlabel('Easting (m)', fontsize=14)\nplt.ylabel('Northing (m)', fontsize=14)\nplt.gca().tick_params(labelsize=12)\nplt.axis('equal')\nplt.grid(ls='--')\n\n# Comparing the accuracy\nsn = int((s0-s.min())/(s[1]-s[0])); dsn = 2\npp1 = np.mean(p1[sn-dsn:sn+dsn], axis=0)\npp2 = np.mean(p2[sn-dsn:sn+dsn], axis=0)\npp1 /= pp1.max(); pp2 /= pp2.max()\nax = plt.subplot(222, projection='polar')\nax.plot(np.radians(b), pp1, 'r', label='Bartlett')\nax.plot(np.radians(b), pp2, 'b', label='MUSIC')\nax.plot([np.radians(b0), np.radians(b0)], [0, 1], 'k--', label='True')\nax.legend(fontsize=11)\nax.set_theta_zero_location('N')\nax.set_theta_direction(-1)\nplt.gca().tick_params(labelsize=13)\n\n# Barlett beam power\nax = plt.subplot(223, projection='polar')\nplt.pcolormesh(np.radians(b), s*1e3, p1, cmap='gnuplot2_r')\ncbar = plt.colorbar(shrink=0.8, pad=0.075)\ncbar.set_label(r'Barlett beam power', fontsize=13)\ncbar.ax.tick_params(labelsize=11)\nax.grid(color='#333333', ls=(10, (6, 5)), lw=0.5)\nax.tick_params(axis='y', colors='k', labelsize=13)\nax.set_theta_zero_location('N')\nax.set_theta_direction(-1)\nax.set_xlabel('Slowness (s/km)', fontsize=14)\nax.tick_params(labelsize=13)\nax.scatter(bb0, s0*1e3, marker='o', s=100, facecolor='none', edgecolor='c', lw=2)\n\n# MUSIC beam power\nax = plt.subplot(224, projection='polar')\nplt.pcolormesh(np.radians(b), s*1e3, p2, cmap='gnuplot2_r')\ncbar = plt.colorbar(shrink=0.8, pad=0.075)\ncbar.set_label(r'MUSIC beam power', fontsize=13)\ncbar.ax.tick_params(labelsize=11)\nax.grid(color='#333333', ls=(10, (6, 5)), lw=0.5)\nax.tick_params(axis='y', colors='k', labelsize=13)\nax.set_theta_zero_location('N')\nax.set_theta_direction(-1)\nax.set_xlabel('Slowness (s/km)', fontsize=14)\nax.tick_params(labelsize=13)\nax.scatter(bb0, s0*1e3, marker='o', s=100, facecolor='none', edgecolor='c', lw=2)\nplt.show()\n```\n参考文献：\nSchmidt, R.O, “Multiple Emitter Location and Signal Parameter Estimation,” IEEE Trans. Antennas Propagation, Vol. AP-34 (March 1986), pp. 276–280.\n","source":"_posts/2024-07-19-music.md","raw":"---\ntitle: 学习聚束分析(一)\ntags:\n  - Seismology\ncategories:\n  - work\nabbrlink: cd52224a\ndate: 2024-07-19 21:27:44\nmathjax: true\n---\n\n&emsp;&emsp;这是聚束分析学习一，参见[这里](https://geophydog.cool/post/music_array_process/)。\n\n<!--less-->\n\n&emsp;&emsp;聚束分析技术（Bartlett 聚束成形器）虽然稳定性和稳健性很好，但分辨率较差。Schmidt 提出了一种称为多信号分类 （MUSIC） 的新聚束分析算法，用于在保持波束形成器稳定性的同时解决分辨率问题 （Schmidt, 1986）。这里我们学习 MUSIC 算法，并给出一些Python代码来展示该技术的工作原理。\n\n\n&emsp;&emsp;假设一个信号为$u(t)$则傅里叶频谱为$U(\\omega)$, $N$ 个接收器的向量为, \n$$ \\vec{u}(\\omega) = [U_{1}(\\omega), U_{2}(\\omega), \\cdots, U_{N}(\\omega)]^T \\tag{1} $$ \n互相关矩阵由下式给出,\n$$ \\bar{C}(\\omega) = \\frac{1}{N}\\vec{u}(\\omega) \\vec{u}^H(\\omega) \\tag{2} $$ \n式中$H$表示Hermitian转置算符。互相关矩阵$\\bar{C}(\\omega)$通常受到非相干信号及仪器产生的噪声干扰。因此该矩阵包括相干信号和噪声。对$\\bar{C}(\\omega)$进行特征值分解获得，\n\n$$ \\bar{C}(\\omega) = \\bar{E}(\\omega) \\bar{\\Lambda}(\\omega) \\bar{E}^{-1}(\\omega) \\tag{3} $$\n\n式中$\\bar{E}(\\omega)$由$N$个特征向量$\\vec{e}_{i} $ 组成，\n\n$$ \\bar{E}(\\omega) = [\\vec{e}_1, \\vec{e}_2, \\cdots, \\vec{e}_N] \\tag{4} $$\n\n$\\bar{\\Lambda}(\\omega)$ 是对角矩阵，对角元素$\\lambda_{i}$是$\\bar{C}(\\omega)$的特征值，\n\n$$ \\bar{\\Lambda}(\\omega) = diag \\{ \\lambda_{1}, \\lambda_{2}, \\cdots, \\lambda_{N} \\} \\tag{5} $$\n\n&emsp;&emsp;最大的特征值表示相干信号（可能有多个相干信号），左边的特征值及其特征向量被噪声占据，这意味着这些噪声是正交的。在这里，我们使用噪声的特征向量构造一个新矩阵\n\n$$ \\bar{N}_e(\\omega) = [\\vec{e}_1, \\vec{e}_2, \\cdots, \\vec{e}_{ne}] [\\vec{e}_1, \\vec{e}_2, \\cdots, \\vec{e}_{ne}]^H \\tag{6} $$\n\n&emsp;&emsp;Barlett聚束器从 \n\n$$ P(\\omega) = \\vec{a}(\\omega) \\bar{C}(\\omega) \\vec{a}^H(\\omega) \\tag{7} $$\n\n变为，\n\n$$ P(\\omega) =\\frac{1}{ \\vec{a}(\\omega) \\bar{N}_e(\\omega) \\vec{a}^H(\\omega) } \\tag{8} $$ \n式中 $\\vec{a}(\\omega)$ 表示转向向量 $\\vec{a}_n=e^{-i\\omega \\Delta t_n}$。 当我们将转向向量投影到噪声特征向量跨越的噪声矩阵子空间时, 公式$(8)$的分母项将为零。在这种情况下 $P(\\omega)$ 将取极大值。$\\Delta t_n$ 是时间延迟，其形式为，\n\n$$ \\Delta t_{n} = \\vec{s} \\cdot \\vec{r}_n \\tag{9} $$\n\n式中$\\vec{s}=s[-sin\\theta, -cos\\theta]^T$ 和 $\\vec{r}_{n}$ 是慢度和位置矢量，其中接收器的反方位角为$\\theta$。$\\vec{r}_s$ 和 $v$ 是源位置向量和传播速度。\n\n&emsp;&emsp;MUSIC 算法在分辨率上优于 Bartlett 波束成形器。然而，与 MUSIC 相比，Bartlett 波束成形器具有更好的稳定性。以下是两种算法的python脚本示例。\n```\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# ARF of the Bartlett beamformer.\ndef arf_beam_barlett(c0, xy, f0=10, b0=90, s0=3.5e-3, b1=0, b2=360, nb=181, s1=1e-3, s2=5e-3, ns=81):\n    n = xy.shape[0]\n    a = np.zeros((n, 1), dtype=complex)\n    b = np.linspace(b1, b2, nb)\n    bb = np.radians(b)\n    s = np.linspace(s1, s2, ns)\n    p = np.zeros((ns, nb), dtype=complex)\n    for i in range(ns):\n        for j in range(nb):\n            shift = -s[i] * (np.sin(bb[j])*xy[:, 0]+np.cos(bb[j])*xy[:, 1])\n            a[:, 0] = np.exp(-2j*np.pi*f0*shift)\n            p[i, j] = np.conjugate(a.T) @ c0 @ a\n    return b, s, p/n**2\n\n# ARF of the MUSIC beamformer.\ndef arf_beam_music(c0, xy, f0=10, b0=90, s0=3.5e-3, b1=0, b2=360, nb=181, s1=1e-3, s2=5e-3, ns=81, ne=10):\n    n = xy.shape[0]\n    a = np.zeros((n, 1), dtype=complex)\n    b = np.linspace(b1, b2, nb)\n    bb = np.radians(b)\n    s = np.linspace(s1, s2, ns)\n    p = np.zeros((ns, nb), dtype=complex)\n    w, v = np.linalg.eigh(c0)\n    ve = v[:, :ne]\n    ne = ve @ np.conjugate(ve.T)\n\n    for i in range(ns):\n        for j in range(nb):\n            shift = -s[i] * (np.sin(bb[j])*xy[:, 0]+np.cos(bb[j])*xy[:, 1])\n            a[:, 0] = np.exp(-2j*np.pi*f0*shift)\n            p[i, j] = 1 / (np.conjugate(a.T) @ ne @ a)\n    return b, s, p / np.abs(p).max()\n```\n```\n# Number of receivers\nnr = 15\n# Aperture of the array\nr = 1e2\n# Randomly generating the Cartician coordinates\nxy = np.random.random((nr, 2)) * r\n# Frequency, back-azimuth and slowness of signal\nf0 = 5; b0 = 90; s0 = 3.5e-3\n# From degree to radian\nbb0 = np.radians(b0)\n# Fourier vector if signal\nu = np.zeros((nr, 1), dtype=complex)\nu[:, 0] = np.exp(-2j*np.pi*f0*s0*(-np.sin(bb0)*xy[:, 0]-np.cos(bb0)*xy[:, 1]))\n# Generating correlation matrix using u\nc0 = u @ np.conjugate(u.T)\nc0 /= np.abs(c0); c0[np.isnan(c0)] = 0.\n# Back-azimuth and slowness ranges of computing\nb1 = 0; b2 = 360; nb = 361\ns1 = 1e-3; s2 = 5e-3; ns = 81\n# Adding noise to the correlation matrix\nnoiser = np.random.randn(nr, nr)\nnoisei = np.random.randn(nr, nr)\nratio = 1.25\nc0 = c0 + noiser * ratio + 1j * noisei * ratio\n# Computing the Bartlett beamformer\nb, s, p1 = arf_beam_barlett(c0, xy, f0=f0, b0=b0, s0=s0, b1=b1, b2=b2, nb=nb, s1=s1, s2=s2, ns=ns)\n# Computing the MUSIC beamformer.\n_, _, p2 = arf_beam_music(c0, xy, f0=f0, b0=b0, s0=s0, b1=b1, b2=b2, nb=nb, s1=s1, s2=s2, ns=ns, ne=nr-1)\n# Normalizing beam power\np1 = np.abs(p1); p1 /= p1.max()\np2 = np.abs(p2); p2 /= p2.max()\n\n\n## Visualizing the beam power results.\n# Array configuration\nplt.figure(figsize=(12, 8))\nplt.subplot(221)\nplt.scatter(xy[:, 0], xy[:, 1], marker='v', s=100, edgecolor='k', alpha=0.5)\nplt.xlabel('Easting (m)', fontsize=14)\nplt.ylabel('Northing (m)', fontsize=14)\nplt.gca().tick_params(labelsize=12)\nplt.axis('equal')\nplt.grid(ls='--')\n\n# Comparing the accuracy\nsn = int((s0-s.min())/(s[1]-s[0])); dsn = 2\npp1 = np.mean(p1[sn-dsn:sn+dsn], axis=0)\npp2 = np.mean(p2[sn-dsn:sn+dsn], axis=0)\npp1 /= pp1.max(); pp2 /= pp2.max()\nax = plt.subplot(222, projection='polar')\nax.plot(np.radians(b), pp1, 'r', label='Bartlett')\nax.plot(np.radians(b), pp2, 'b', label='MUSIC')\nax.plot([np.radians(b0), np.radians(b0)], [0, 1], 'k--', label='True')\nax.legend(fontsize=11)\nax.set_theta_zero_location('N')\nax.set_theta_direction(-1)\nplt.gca().tick_params(labelsize=13)\n\n# Barlett beam power\nax = plt.subplot(223, projection='polar')\nplt.pcolormesh(np.radians(b), s*1e3, p1, cmap='gnuplot2_r')\ncbar = plt.colorbar(shrink=0.8, pad=0.075)\ncbar.set_label(r'Barlett beam power', fontsize=13)\ncbar.ax.tick_params(labelsize=11)\nax.grid(color='#333333', ls=(10, (6, 5)), lw=0.5)\nax.tick_params(axis='y', colors='k', labelsize=13)\nax.set_theta_zero_location('N')\nax.set_theta_direction(-1)\nax.set_xlabel('Slowness (s/km)', fontsize=14)\nax.tick_params(labelsize=13)\nax.scatter(bb0, s0*1e3, marker='o', s=100, facecolor='none', edgecolor='c', lw=2)\n\n# MUSIC beam power\nax = plt.subplot(224, projection='polar')\nplt.pcolormesh(np.radians(b), s*1e3, p2, cmap='gnuplot2_r')\ncbar = plt.colorbar(shrink=0.8, pad=0.075)\ncbar.set_label(r'MUSIC beam power', fontsize=13)\ncbar.ax.tick_params(labelsize=11)\nax.grid(color='#333333', ls=(10, (6, 5)), lw=0.5)\nax.tick_params(axis='y', colors='k', labelsize=13)\nax.set_theta_zero_location('N')\nax.set_theta_direction(-1)\nax.set_xlabel('Slowness (s/km)', fontsize=14)\nax.tick_params(labelsize=13)\nax.scatter(bb0, s0*1e3, marker='o', s=100, facecolor='none', edgecolor='c', lw=2)\nplt.show()\n```\n参考文献：\nSchmidt, R.O, “Multiple Emitter Location and Signal Parameter Estimation,” IEEE Trans. Antennas Propagation, Vol. AP-34 (March 1986), pp. 276–280.\n","slug":"music","published":1,"updated":"2025-06-18T02:55:23.140Z","comments":1,"layout":"post","photos":[],"_id":"cmh498iq100a9wvou8dzb0u0h","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>&emsp;&emsp;聚束分析技术（Bartlett 聚束成形器）虽然稳定性和稳健性很好，但分辨率较差。Schmidt 提出了一种称为多信号分类 （MUSIC） 的新聚束分析算法，用于在保持波束形成器稳定性的同时解决分辨率问题 （Schmidt, 1986）。这里我们学习 MUSIC 算法，并给出一些Python代码来展示该技术的工作原理。</p>\n<p>&emsp;&emsp;假设一个信号为$u(t)$则傅里叶频谱为$U(\\omega)$, $N$ 个接收器的向量为,<br>$$ \\vec{u}(\\omega) &#x3D; [U_{1}(\\omega), U_{2}(\\omega), \\cdots, U_{N}(\\omega)]^T \\tag{1} $$<br>互相关矩阵由下式给出,<br>$$ \\bar{C}(\\omega) &#x3D; \\frac{1}{N}\\vec{u}(\\omega) \\vec{u}^H(\\omega) \\tag{2} $$<br>式中$H$表示Hermitian转置算符。互相关矩阵$\\bar{C}(\\omega)$通常受到非相干信号及仪器产生的噪声干扰。因此该矩阵包括相干信号和噪声。对$\\bar{C}(\\omega)$进行特征值分解获得，</p>\n<p>$$ \\bar{C}(\\omega) &#x3D; \\bar{E}(\\omega) \\bar{\\Lambda}(\\omega) \\bar{E}^{-1}(\\omega) \\tag{3} $$</p>\n<p>式中$\\bar{E}(\\omega)$由$N$个特征向量$\\vec{e}_{i} $ 组成，</p>\n<p>$$ \\bar{E}(\\omega) &#x3D; [\\vec{e}_1, \\vec{e}_2, \\cdots, \\vec{e}_N] \\tag{4} $$</p>\n<p>$\\bar{\\Lambda}(\\omega)$ 是对角矩阵，对角元素$\\lambda_{i}$是$\\bar{C}(\\omega)$的特征值，</p>\n<p>$$ \\bar{\\Lambda}(\\omega) &#x3D; diag { \\lambda_{1}, \\lambda_{2}, \\cdots, \\lambda_{N} } \\tag{5} $$</p>\n<p>&emsp;&emsp;最大的特征值表示相干信号（可能有多个相干信号），左边的特征值及其特征向量被噪声占据，这意味着这些噪声是正交的。在这里，我们使用噪声的特征向量构造一个新矩阵</p>\n<p>$$ \\bar{N}_e(\\omega) &#x3D; [\\vec{e}_1, \\vec{e}<em>2, \\cdots, \\vec{e}</em>{ne}] [\\vec{e}_1, \\vec{e}<em>2, \\cdots, \\vec{e}</em>{ne}]^H \\tag{6} $$</p>\n<p>&emsp;&emsp;Barlett聚束器从 </p>\n<p>$$ P(\\omega) &#x3D; \\vec{a}(\\omega) \\bar{C}(\\omega) \\vec{a}^H(\\omega) \\tag{7} $$</p>\n<p>变为，</p>\n<p>$$ P(\\omega) &#x3D;\\frac{1}{ \\vec{a}(\\omega) \\bar{N}_e(\\omega) \\vec{a}^H(\\omega) } \\tag{8} $$<br>式中 $\\vec{a}(\\omega)$ 表示转向向量 $\\vec{a}_n&#x3D;e^{-i\\omega \\Delta t_n}$。 当我们将转向向量投影到噪声特征向量跨越的噪声矩阵子空间时, 公式$(8)$的分母项将为零。在这种情况下 $P(\\omega)$ 将取极大值。$\\Delta t_n$ 是时间延迟，其形式为，</p>\n<p>$$ \\Delta t_{n} &#x3D; \\vec{s} \\cdot \\vec{r}_n \\tag{9} $$</p>\n<p>式中$\\vec{s}&#x3D;s[-sin\\theta, -cos\\theta]^T$ 和 $\\vec{r}_{n}$ 是慢度和位置矢量，其中接收器的反方位角为$\\theta$。$\\vec{r}_s$ 和 $v$ 是源位置向量和传播速度。</p>\n<p>&emsp;&emsp;MUSIC 算法在分辨率上优于 Bartlett 波束成形器。然而，与 MUSIC 相比，Bartlett 波束成形器具有更好的稳定性。以下是两种算法的python脚本示例。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">import numpy as np</span><br><span class=\"line\">import matplotlib.pyplot as plt</span><br><span class=\"line\"></span><br><span class=\"line\"># ARF of the Bartlett beamformer.</span><br><span class=\"line\">def arf_beam_barlett(c0, xy, f0=10, b0=90, s0=3.5e-3, b1=0, b2=360, nb=181, s1=1e-3, s2=5e-3, ns=81):</span><br><span class=\"line\">    n = xy.shape[0]</span><br><span class=\"line\">    a = np.zeros((n, 1), dtype=complex)</span><br><span class=\"line\">    b = np.linspace(b1, b2, nb)</span><br><span class=\"line\">    bb = np.radians(b)</span><br><span class=\"line\">    s = np.linspace(s1, s2, ns)</span><br><span class=\"line\">    p = np.zeros((ns, nb), dtype=complex)</span><br><span class=\"line\">    for i in range(ns):</span><br><span class=\"line\">        for j in range(nb):</span><br><span class=\"line\">            shift = -s[i] * (np.sin(bb[j])*xy[:, 0]+np.cos(bb[j])*xy[:, 1])</span><br><span class=\"line\">            a[:, 0] = np.exp(-2j*np.pi*f0*shift)</span><br><span class=\"line\">            p[i, j] = np.conjugate(a.T) @ c0 @ a</span><br><span class=\"line\">    return b, s, p/n**2</span><br><span class=\"line\"></span><br><span class=\"line\"># ARF of the MUSIC beamformer.</span><br><span class=\"line\">def arf_beam_music(c0, xy, f0=10, b0=90, s0=3.5e-3, b1=0, b2=360, nb=181, s1=1e-3, s2=5e-3, ns=81, ne=10):</span><br><span class=\"line\">    n = xy.shape[0]</span><br><span class=\"line\">    a = np.zeros((n, 1), dtype=complex)</span><br><span class=\"line\">    b = np.linspace(b1, b2, nb)</span><br><span class=\"line\">    bb = np.radians(b)</span><br><span class=\"line\">    s = np.linspace(s1, s2, ns)</span><br><span class=\"line\">    p = np.zeros((ns, nb), dtype=complex)</span><br><span class=\"line\">    w, v = np.linalg.eigh(c0)</span><br><span class=\"line\">    ve = v[:, :ne]</span><br><span class=\"line\">    ne = ve @ np.conjugate(ve.T)</span><br><span class=\"line\"></span><br><span class=\"line\">    for i in range(ns):</span><br><span class=\"line\">        for j in range(nb):</span><br><span class=\"line\">            shift = -s[i] * (np.sin(bb[j])*xy[:, 0]+np.cos(bb[j])*xy[:, 1])</span><br><span class=\"line\">            a[:, 0] = np.exp(-2j*np.pi*f0*shift)</span><br><span class=\"line\">            p[i, j] = 1 / (np.conjugate(a.T) @ ne @ a)</span><br><span class=\"line\">    return b, s, p / np.abs(p).max()</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># Number of receivers</span><br><span class=\"line\">nr = 15</span><br><span class=\"line\"># Aperture of the array</span><br><span class=\"line\">r = 1e2</span><br><span class=\"line\"># Randomly generating the Cartician coordinates</span><br><span class=\"line\">xy = np.random.random((nr, 2)) * r</span><br><span class=\"line\"># Frequency, back-azimuth and slowness of signal</span><br><span class=\"line\">f0 = 5; b0 = 90; s0 = 3.5e-3</span><br><span class=\"line\"># From degree to radian</span><br><span class=\"line\">bb0 = np.radians(b0)</span><br><span class=\"line\"># Fourier vector if signal</span><br><span class=\"line\">u = np.zeros((nr, 1), dtype=complex)</span><br><span class=\"line\">u[:, 0] = np.exp(-2j*np.pi*f0*s0*(-np.sin(bb0)*xy[:, 0]-np.cos(bb0)*xy[:, 1]))</span><br><span class=\"line\"># Generating correlation matrix using u</span><br><span class=\"line\">c0 = u @ np.conjugate(u.T)</span><br><span class=\"line\">c0 /= np.abs(c0); c0[np.isnan(c0)] = 0.</span><br><span class=\"line\"># Back-azimuth and slowness ranges of computing</span><br><span class=\"line\">b1 = 0; b2 = 360; nb = 361</span><br><span class=\"line\">s1 = 1e-3; s2 = 5e-3; ns = 81</span><br><span class=\"line\"># Adding noise to the correlation matrix</span><br><span class=\"line\">noiser = np.random.randn(nr, nr)</span><br><span class=\"line\">noisei = np.random.randn(nr, nr)</span><br><span class=\"line\">ratio = 1.25</span><br><span class=\"line\">c0 = c0 + noiser * ratio + 1j * noisei * ratio</span><br><span class=\"line\"># Computing the Bartlett beamformer</span><br><span class=\"line\">b, s, p1 = arf_beam_barlett(c0, xy, f0=f0, b0=b0, s0=s0, b1=b1, b2=b2, nb=nb, s1=s1, s2=s2, ns=ns)</span><br><span class=\"line\"># Computing the MUSIC beamformer.</span><br><span class=\"line\">_, _, p2 = arf_beam_music(c0, xy, f0=f0, b0=b0, s0=s0, b1=b1, b2=b2, nb=nb, s1=s1, s2=s2, ns=ns, ne=nr-1)</span><br><span class=\"line\"># Normalizing beam power</span><br><span class=\"line\">p1 = np.abs(p1); p1 /= p1.max()</span><br><span class=\"line\">p2 = np.abs(p2); p2 /= p2.max()</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">## Visualizing the beam power results.</span><br><span class=\"line\"># Array configuration</span><br><span class=\"line\">plt.figure(figsize=(12, 8))</span><br><span class=\"line\">plt.subplot(221)</span><br><span class=\"line\">plt.scatter(xy[:, 0], xy[:, 1], marker=&#x27;v&#x27;, s=100, edgecolor=&#x27;k&#x27;, alpha=0.5)</span><br><span class=\"line\">plt.xlabel(&#x27;Easting (m)&#x27;, fontsize=14)</span><br><span class=\"line\">plt.ylabel(&#x27;Northing (m)&#x27;, fontsize=14)</span><br><span class=\"line\">plt.gca().tick_params(labelsize=12)</span><br><span class=\"line\">plt.axis(&#x27;equal&#x27;)</span><br><span class=\"line\">plt.grid(ls=&#x27;--&#x27;)</span><br><span class=\"line\"></span><br><span class=\"line\"># Comparing the accuracy</span><br><span class=\"line\">sn = int((s0-s.min())/(s[1]-s[0])); dsn = 2</span><br><span class=\"line\">pp1 = np.mean(p1[sn-dsn:sn+dsn], axis=0)</span><br><span class=\"line\">pp2 = np.mean(p2[sn-dsn:sn+dsn], axis=0)</span><br><span class=\"line\">pp1 /= pp1.max(); pp2 /= pp2.max()</span><br><span class=\"line\">ax = plt.subplot(222, projection=&#x27;polar&#x27;)</span><br><span class=\"line\">ax.plot(np.radians(b), pp1, &#x27;r&#x27;, label=&#x27;Bartlett&#x27;)</span><br><span class=\"line\">ax.plot(np.radians(b), pp2, &#x27;b&#x27;, label=&#x27;MUSIC&#x27;)</span><br><span class=\"line\">ax.plot([np.radians(b0), np.radians(b0)], [0, 1], &#x27;k--&#x27;, label=&#x27;True&#x27;)</span><br><span class=\"line\">ax.legend(fontsize=11)</span><br><span class=\"line\">ax.set_theta_zero_location(&#x27;N&#x27;)</span><br><span class=\"line\">ax.set_theta_direction(-1)</span><br><span class=\"line\">plt.gca().tick_params(labelsize=13)</span><br><span class=\"line\"></span><br><span class=\"line\"># Barlett beam power</span><br><span class=\"line\">ax = plt.subplot(223, projection=&#x27;polar&#x27;)</span><br><span class=\"line\">plt.pcolormesh(np.radians(b), s*1e3, p1, cmap=&#x27;gnuplot2_r&#x27;)</span><br><span class=\"line\">cbar = plt.colorbar(shrink=0.8, pad=0.075)</span><br><span class=\"line\">cbar.set_label(r&#x27;Barlett beam power&#x27;, fontsize=13)</span><br><span class=\"line\">cbar.ax.tick_params(labelsize=11)</span><br><span class=\"line\">ax.grid(color=&#x27;#333333&#x27;, ls=(10, (6, 5)), lw=0.5)</span><br><span class=\"line\">ax.tick_params(axis=&#x27;y&#x27;, colors=&#x27;k&#x27;, labelsize=13)</span><br><span class=\"line\">ax.set_theta_zero_location(&#x27;N&#x27;)</span><br><span class=\"line\">ax.set_theta_direction(-1)</span><br><span class=\"line\">ax.set_xlabel(&#x27;Slowness (s/km)&#x27;, fontsize=14)</span><br><span class=\"line\">ax.tick_params(labelsize=13)</span><br><span class=\"line\">ax.scatter(bb0, s0*1e3, marker=&#x27;o&#x27;, s=100, facecolor=&#x27;none&#x27;, edgecolor=&#x27;c&#x27;, lw=2)</span><br><span class=\"line\"></span><br><span class=\"line\"># MUSIC beam power</span><br><span class=\"line\">ax = plt.subplot(224, projection=&#x27;polar&#x27;)</span><br><span class=\"line\">plt.pcolormesh(np.radians(b), s*1e3, p2, cmap=&#x27;gnuplot2_r&#x27;)</span><br><span class=\"line\">cbar = plt.colorbar(shrink=0.8, pad=0.075)</span><br><span class=\"line\">cbar.set_label(r&#x27;MUSIC beam power&#x27;, fontsize=13)</span><br><span class=\"line\">cbar.ax.tick_params(labelsize=11)</span><br><span class=\"line\">ax.grid(color=&#x27;#333333&#x27;, ls=(10, (6, 5)), lw=0.5)</span><br><span class=\"line\">ax.tick_params(axis=&#x27;y&#x27;, colors=&#x27;k&#x27;, labelsize=13)</span><br><span class=\"line\">ax.set_theta_zero_location(&#x27;N&#x27;)</span><br><span class=\"line\">ax.set_theta_direction(-1)</span><br><span class=\"line\">ax.set_xlabel(&#x27;Slowness (s/km)&#x27;, fontsize=14)</span><br><span class=\"line\">ax.tick_params(labelsize=13)</span><br><span class=\"line\">ax.scatter(bb0, s0*1e3, marker=&#x27;o&#x27;, s=100, facecolor=&#x27;none&#x27;, edgecolor=&#x27;c&#x27;, lw=2)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p>参考文献：<br>Schmidt, R.O, “Multiple Emitter Location and Signal Parameter Estimation,” IEEE Trans. Antennas Propagation, Vol. AP-34 (March 1986), pp. 276–280.</p>","related_posts":["mfp.html","noise-source-back-azimuth.html","latex-math-express.html"],"length":6148,"excerpt":"<p>&emsp;&emsp;这是聚束分析学习一，参见<a href=\"https://geophydog.cool/post/music_array_process/\">这里</a>。</p>","more":"<p>&emsp;&emsp;聚束分析技术（Bartlett 聚束成形器）虽然稳定性和稳健性很好，但分辨率较差。Schmidt 提出了一种称为多信号分类 （MUSIC） 的新聚束分析算法，用于在保持波束形成器稳定性的同时解决分辨率问题 （Schmidt, 1986）。这里我们学习 MUSIC 算法，并给出一些Python代码来展示该技术的工作原理。</p>\n<p>&emsp;&emsp;假设一个信号为$u(t)$则傅里叶频谱为$U(\\omega)$, $N$ 个接收器的向量为,<br>$$ \\vec{u}(\\omega) &#x3D; [U_{1}(\\omega), U_{2}(\\omega), \\cdots, U_{N}(\\omega)]^T \\tag{1} $$<br>互相关矩阵由下式给出,<br>$$ \\bar{C}(\\omega) &#x3D; \\frac{1}{N}\\vec{u}(\\omega) \\vec{u}^H(\\omega) \\tag{2} $$<br>式中$H$表示Hermitian转置算符。互相关矩阵$\\bar{C}(\\omega)$通常受到非相干信号及仪器产生的噪声干扰。因此该矩阵包括相干信号和噪声。对$\\bar{C}(\\omega)$进行特征值分解获得，</p>\n<p>$$ \\bar{C}(\\omega) &#x3D; \\bar{E}(\\omega) \\bar{\\Lambda}(\\omega) \\bar{E}^{-1}(\\omega) \\tag{3} $$</p>\n<p>式中$\\bar{E}(\\omega)$由$N$个特征向量$\\vec{e}_{i} $ 组成，</p>\n<p>$$ \\bar{E}(\\omega) &#x3D; [\\vec{e}_1, \\vec{e}_2, \\cdots, \\vec{e}_N] \\tag{4} $$</p>\n<p>$\\bar{\\Lambda}(\\omega)$ 是对角矩阵，对角元素$\\lambda_{i}$是$\\bar{C}(\\omega)$的特征值，</p>\n<p>$$ \\bar{\\Lambda}(\\omega) &#x3D; diag { \\lambda_{1}, \\lambda_{2}, \\cdots, \\lambda_{N} } \\tag{5} $$</p>\n<p>&emsp;&emsp;最大的特征值表示相干信号（可能有多个相干信号），左边的特征值及其特征向量被噪声占据，这意味着这些噪声是正交的。在这里，我们使用噪声的特征向量构造一个新矩阵</p>\n<p>$$ \\bar{N}_e(\\omega) &#x3D; [\\vec{e}_1, \\vec{e}<em>2, \\cdots, \\vec{e}</em>{ne}] [\\vec{e}_1, \\vec{e}<em>2, \\cdots, \\vec{e}</em>{ne}]^H \\tag{6} $$</p>\n<p>&emsp;&emsp;Barlett聚束器从 </p>\n<p>$$ P(\\omega) &#x3D; \\vec{a}(\\omega) \\bar{C}(\\omega) \\vec{a}^H(\\omega) \\tag{7} $$</p>\n<p>变为，</p>\n<p>$$ P(\\omega) &#x3D;\\frac{1}{ \\vec{a}(\\omega) \\bar{N}_e(\\omega) \\vec{a}^H(\\omega) } \\tag{8} $$<br>式中 $\\vec{a}(\\omega)$ 表示转向向量 $\\vec{a}_n&#x3D;e^{-i\\omega \\Delta t_n}$。 当我们将转向向量投影到噪声特征向量跨越的噪声矩阵子空间时, 公式$(8)$的分母项将为零。在这种情况下 $P(\\omega)$ 将取极大值。$\\Delta t_n$ 是时间延迟，其形式为，</p>\n<p>$$ \\Delta t_{n} &#x3D; \\vec{s} \\cdot \\vec{r}_n \\tag{9} $$</p>\n<p>式中$\\vec{s}&#x3D;s[-sin\\theta, -cos\\theta]^T$ 和 $\\vec{r}_{n}$ 是慢度和位置矢量，其中接收器的反方位角为$\\theta$。$\\vec{r}_s$ 和 $v$ 是源位置向量和传播速度。</p>\n<p>&emsp;&emsp;MUSIC 算法在分辨率上优于 Bartlett 波束成形器。然而，与 MUSIC 相比，Bartlett 波束成形器具有更好的稳定性。以下是两种算法的python脚本示例。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">import numpy as np</span><br><span class=\"line\">import matplotlib.pyplot as plt</span><br><span class=\"line\"></span><br><span class=\"line\"># ARF of the Bartlett beamformer.</span><br><span class=\"line\">def arf_beam_barlett(c0, xy, f0=10, b0=90, s0=3.5e-3, b1=0, b2=360, nb=181, s1=1e-3, s2=5e-3, ns=81):</span><br><span class=\"line\">    n = xy.shape[0]</span><br><span class=\"line\">    a = np.zeros((n, 1), dtype=complex)</span><br><span class=\"line\">    b = np.linspace(b1, b2, nb)</span><br><span class=\"line\">    bb = np.radians(b)</span><br><span class=\"line\">    s = np.linspace(s1, s2, ns)</span><br><span class=\"line\">    p = np.zeros((ns, nb), dtype=complex)</span><br><span class=\"line\">    for i in range(ns):</span><br><span class=\"line\">        for j in range(nb):</span><br><span class=\"line\">            shift = -s[i] * (np.sin(bb[j])*xy[:, 0]+np.cos(bb[j])*xy[:, 1])</span><br><span class=\"line\">            a[:, 0] = np.exp(-2j*np.pi*f0*shift)</span><br><span class=\"line\">            p[i, j] = np.conjugate(a.T) @ c0 @ a</span><br><span class=\"line\">    return b, s, p/n**2</span><br><span class=\"line\"></span><br><span class=\"line\"># ARF of the MUSIC beamformer.</span><br><span class=\"line\">def arf_beam_music(c0, xy, f0=10, b0=90, s0=3.5e-3, b1=0, b2=360, nb=181, s1=1e-3, s2=5e-3, ns=81, ne=10):</span><br><span class=\"line\">    n = xy.shape[0]</span><br><span class=\"line\">    a = np.zeros((n, 1), dtype=complex)</span><br><span class=\"line\">    b = np.linspace(b1, b2, nb)</span><br><span class=\"line\">    bb = np.radians(b)</span><br><span class=\"line\">    s = np.linspace(s1, s2, ns)</span><br><span class=\"line\">    p = np.zeros((ns, nb), dtype=complex)</span><br><span class=\"line\">    w, v = np.linalg.eigh(c0)</span><br><span class=\"line\">    ve = v[:, :ne]</span><br><span class=\"line\">    ne = ve @ np.conjugate(ve.T)</span><br><span class=\"line\"></span><br><span class=\"line\">    for i in range(ns):</span><br><span class=\"line\">        for j in range(nb):</span><br><span class=\"line\">            shift = -s[i] * (np.sin(bb[j])*xy[:, 0]+np.cos(bb[j])*xy[:, 1])</span><br><span class=\"line\">            a[:, 0] = np.exp(-2j*np.pi*f0*shift)</span><br><span class=\"line\">            p[i, j] = 1 / (np.conjugate(a.T) @ ne @ a)</span><br><span class=\"line\">    return b, s, p / np.abs(p).max()</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># Number of receivers</span><br><span class=\"line\">nr = 15</span><br><span class=\"line\"># Aperture of the array</span><br><span class=\"line\">r = 1e2</span><br><span class=\"line\"># Randomly generating the Cartician coordinates</span><br><span class=\"line\">xy = np.random.random((nr, 2)) * r</span><br><span class=\"line\"># Frequency, back-azimuth and slowness of signal</span><br><span class=\"line\">f0 = 5; b0 = 90; s0 = 3.5e-3</span><br><span class=\"line\"># From degree to radian</span><br><span class=\"line\">bb0 = np.radians(b0)</span><br><span class=\"line\"># Fourier vector if signal</span><br><span class=\"line\">u = np.zeros((nr, 1), dtype=complex)</span><br><span class=\"line\">u[:, 0] = np.exp(-2j*np.pi*f0*s0*(-np.sin(bb0)*xy[:, 0]-np.cos(bb0)*xy[:, 1]))</span><br><span class=\"line\"># Generating correlation matrix using u</span><br><span class=\"line\">c0 = u @ np.conjugate(u.T)</span><br><span class=\"line\">c0 /= np.abs(c0); c0[np.isnan(c0)] = 0.</span><br><span class=\"line\"># Back-azimuth and slowness ranges of computing</span><br><span class=\"line\">b1 = 0; b2 = 360; nb = 361</span><br><span class=\"line\">s1 = 1e-3; s2 = 5e-3; ns = 81</span><br><span class=\"line\"># Adding noise to the correlation matrix</span><br><span class=\"line\">noiser = np.random.randn(nr, nr)</span><br><span class=\"line\">noisei = np.random.randn(nr, nr)</span><br><span class=\"line\">ratio = 1.25</span><br><span class=\"line\">c0 = c0 + noiser * ratio + 1j * noisei * ratio</span><br><span class=\"line\"># Computing the Bartlett beamformer</span><br><span class=\"line\">b, s, p1 = arf_beam_barlett(c0, xy, f0=f0, b0=b0, s0=s0, b1=b1, b2=b2, nb=nb, s1=s1, s2=s2, ns=ns)</span><br><span class=\"line\"># Computing the MUSIC beamformer.</span><br><span class=\"line\">_, _, p2 = arf_beam_music(c0, xy, f0=f0, b0=b0, s0=s0, b1=b1, b2=b2, nb=nb, s1=s1, s2=s2, ns=ns, ne=nr-1)</span><br><span class=\"line\"># Normalizing beam power</span><br><span class=\"line\">p1 = np.abs(p1); p1 /= p1.max()</span><br><span class=\"line\">p2 = np.abs(p2); p2 /= p2.max()</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">## Visualizing the beam power results.</span><br><span class=\"line\"># Array configuration</span><br><span class=\"line\">plt.figure(figsize=(12, 8))</span><br><span class=\"line\">plt.subplot(221)</span><br><span class=\"line\">plt.scatter(xy[:, 0], xy[:, 1], marker=&#x27;v&#x27;, s=100, edgecolor=&#x27;k&#x27;, alpha=0.5)</span><br><span class=\"line\">plt.xlabel(&#x27;Easting (m)&#x27;, fontsize=14)</span><br><span class=\"line\">plt.ylabel(&#x27;Northing (m)&#x27;, fontsize=14)</span><br><span class=\"line\">plt.gca().tick_params(labelsize=12)</span><br><span class=\"line\">plt.axis(&#x27;equal&#x27;)</span><br><span class=\"line\">plt.grid(ls=&#x27;--&#x27;)</span><br><span class=\"line\"></span><br><span class=\"line\"># Comparing the accuracy</span><br><span class=\"line\">sn = int((s0-s.min())/(s[1]-s[0])); dsn = 2</span><br><span class=\"line\">pp1 = np.mean(p1[sn-dsn:sn+dsn], axis=0)</span><br><span class=\"line\">pp2 = np.mean(p2[sn-dsn:sn+dsn], axis=0)</span><br><span class=\"line\">pp1 /= pp1.max(); pp2 /= pp2.max()</span><br><span class=\"line\">ax = plt.subplot(222, projection=&#x27;polar&#x27;)</span><br><span class=\"line\">ax.plot(np.radians(b), pp1, &#x27;r&#x27;, label=&#x27;Bartlett&#x27;)</span><br><span class=\"line\">ax.plot(np.radians(b), pp2, &#x27;b&#x27;, label=&#x27;MUSIC&#x27;)</span><br><span class=\"line\">ax.plot([np.radians(b0), np.radians(b0)], [0, 1], &#x27;k--&#x27;, label=&#x27;True&#x27;)</span><br><span class=\"line\">ax.legend(fontsize=11)</span><br><span class=\"line\">ax.set_theta_zero_location(&#x27;N&#x27;)</span><br><span class=\"line\">ax.set_theta_direction(-1)</span><br><span class=\"line\">plt.gca().tick_params(labelsize=13)</span><br><span class=\"line\"></span><br><span class=\"line\"># Barlett beam power</span><br><span class=\"line\">ax = plt.subplot(223, projection=&#x27;polar&#x27;)</span><br><span class=\"line\">plt.pcolormesh(np.radians(b), s*1e3, p1, cmap=&#x27;gnuplot2_r&#x27;)</span><br><span class=\"line\">cbar = plt.colorbar(shrink=0.8, pad=0.075)</span><br><span class=\"line\">cbar.set_label(r&#x27;Barlett beam power&#x27;, fontsize=13)</span><br><span class=\"line\">cbar.ax.tick_params(labelsize=11)</span><br><span class=\"line\">ax.grid(color=&#x27;#333333&#x27;, ls=(10, (6, 5)), lw=0.5)</span><br><span class=\"line\">ax.tick_params(axis=&#x27;y&#x27;, colors=&#x27;k&#x27;, labelsize=13)</span><br><span class=\"line\">ax.set_theta_zero_location(&#x27;N&#x27;)</span><br><span class=\"line\">ax.set_theta_direction(-1)</span><br><span class=\"line\">ax.set_xlabel(&#x27;Slowness (s/km)&#x27;, fontsize=14)</span><br><span class=\"line\">ax.tick_params(labelsize=13)</span><br><span class=\"line\">ax.scatter(bb0, s0*1e3, marker=&#x27;o&#x27;, s=100, facecolor=&#x27;none&#x27;, edgecolor=&#x27;c&#x27;, lw=2)</span><br><span class=\"line\"></span><br><span class=\"line\"># MUSIC beam power</span><br><span class=\"line\">ax = plt.subplot(224, projection=&#x27;polar&#x27;)</span><br><span class=\"line\">plt.pcolormesh(np.radians(b), s*1e3, p2, cmap=&#x27;gnuplot2_r&#x27;)</span><br><span class=\"line\">cbar = plt.colorbar(shrink=0.8, pad=0.075)</span><br><span class=\"line\">cbar.set_label(r&#x27;MUSIC beam power&#x27;, fontsize=13)</span><br><span class=\"line\">cbar.ax.tick_params(labelsize=11)</span><br><span class=\"line\">ax.grid(color=&#x27;#333333&#x27;, ls=(10, (6, 5)), lw=0.5)</span><br><span class=\"line\">ax.tick_params(axis=&#x27;y&#x27;, colors=&#x27;k&#x27;, labelsize=13)</span><br><span class=\"line\">ax.set_theta_zero_location(&#x27;N&#x27;)</span><br><span class=\"line\">ax.set_theta_direction(-1)</span><br><span class=\"line\">ax.set_xlabel(&#x27;Slowness (s/km)&#x27;, fontsize=14)</span><br><span class=\"line\">ax.tick_params(labelsize=13)</span><br><span class=\"line\">ax.scatter(bb0, s0*1e3, marker=&#x27;o&#x27;, s=100, facecolor=&#x27;none&#x27;, edgecolor=&#x27;c&#x27;, lw=2)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p>参考文献：<br>Schmidt, R.O, “Multiple Emitter Location and Signal Parameter Estimation,” IEEE Trans. Antennas Propagation, Vol. AP-34 (March 1986), pp. 276–280.</p>"},{"title":"obspy去polezero类型仪器仪响应","abbrlink":"3ad19c75","date":"2024-07-25T05:40:34.000Z","_content":"&emsp;&emsp;有些时候数据下载下来只有polezero格式的仪器响应，那python脚本怎么去仪器响应呢？\n<!--less-->\n&emsp;&emsp;如果有polezero文件，那可以用attach_paz来读取。然后去仪器响应的脚本如下：\n```python\nimport numpy as np\nimport obspy\nimport matplotlib.pyplot as plt\nfrom obspy import read\nfrom obspy.io.sac import attach_paz\nfrom obspy.signal.invsim import corn_freq_2_paz\nfrom pathlib import Path\nfpath=\"/home/junxie/work/Snet/data/2016_08_16_01_00\"\np=Path(fpath)\ni=0\nfor file in p.rglob('*VX*.SAC'): #循环读取文件\n    st=read(file, debug_headers=True)\n    tr=st[0].copy()\n    aa=str(file).split(\"/\")\n    pz=str(file)+\"_PZ\" # 这就是paz文件\n    attach_paz(tr,pz)  # 贴到tr中\n    paz_1hz = corn_freq_2_paz(1.0, damp=0.707)  # 1Hz instrument\n    paz_1hz['sensitivity'] = 1.0\n    st.simulate(paz_simulate=paz_1hz) #去仪器响应\n```\n&emsp;&emsp;如果没有的话找到零点、极点和放大系数，赋值到paz里面，例如：\n```\nfrom obspy import read\nfrom obspy.signal.invsim import corn_freq_2_paz\nst = read()\npaz_sts2 = {'poles': [-0.037004+0.037016j, -0.037004-0.037016j,\n                      -251.33+0j,\n                      -131.04-467.29j, -131.04+467.29j],\n            'zeros': [0j, 0j],\n            'gain': 60077000.0,\n            'sensitivity': 2516778400.0}\npaz_1hz = corn_freq_2_paz(1.0, damp=0.707)\nst.simulate(paz_remove=paz_sts2, paz_simulate=paz_1hz)\n```\n","source":"_posts/2024-07-25-obspy-paz.md","raw":"---\ntitle: obspy去polezero类型仪器仪响应\ntags:\n  - python\n  - seismology\ncategories:\n  - work\nabbrlink: 3ad19c75\ndate: 2024-07-25 13:40:34\n---\n&emsp;&emsp;有些时候数据下载下来只有polezero格式的仪器响应，那python脚本怎么去仪器响应呢？\n<!--less-->\n&emsp;&emsp;如果有polezero文件，那可以用attach_paz来读取。然后去仪器响应的脚本如下：\n```python\nimport numpy as np\nimport obspy\nimport matplotlib.pyplot as plt\nfrom obspy import read\nfrom obspy.io.sac import attach_paz\nfrom obspy.signal.invsim import corn_freq_2_paz\nfrom pathlib import Path\nfpath=\"/home/junxie/work/Snet/data/2016_08_16_01_00\"\np=Path(fpath)\ni=0\nfor file in p.rglob('*VX*.SAC'): #循环读取文件\n    st=read(file, debug_headers=True)\n    tr=st[0].copy()\n    aa=str(file).split(\"/\")\n    pz=str(file)+\"_PZ\" # 这就是paz文件\n    attach_paz(tr,pz)  # 贴到tr中\n    paz_1hz = corn_freq_2_paz(1.0, damp=0.707)  # 1Hz instrument\n    paz_1hz['sensitivity'] = 1.0\n    st.simulate(paz_simulate=paz_1hz) #去仪器响应\n```\n&emsp;&emsp;如果没有的话找到零点、极点和放大系数，赋值到paz里面，例如：\n```\nfrom obspy import read\nfrom obspy.signal.invsim import corn_freq_2_paz\nst = read()\npaz_sts2 = {'poles': [-0.037004+0.037016j, -0.037004-0.037016j,\n                      -251.33+0j,\n                      -131.04-467.29j, -131.04+467.29j],\n            'zeros': [0j, 0j],\n            'gain': 60077000.0,\n            'sensitivity': 2516778400.0}\npaz_1hz = corn_freq_2_paz(1.0, damp=0.707)\nst.simulate(paz_remove=paz_sts2, paz_simulate=paz_1hz)\n```\n","slug":"obspy-paz","published":1,"updated":"2025-02-24T02:41:28.024Z","comments":1,"layout":"post","photos":[],"_id":"cmh498iq200acwvou158u7417","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>&emsp;&emsp;如果有polezero文件，那可以用attach_paz来读取。然后去仪器响应的脚本如下：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> obspy</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">from</span> obspy <span class=\"keyword\">import</span> read</span><br><span class=\"line\"><span class=\"keyword\">from</span> obspy.io.sac <span class=\"keyword\">import</span> attach_paz</span><br><span class=\"line\"><span class=\"keyword\">from</span> obspy.signal.invsim <span class=\"keyword\">import</span> corn_freq_2_paz</span><br><span class=\"line\"><span class=\"keyword\">from</span> pathlib <span class=\"keyword\">import</span> Path</span><br><span class=\"line\">fpath=<span class=\"string\">&quot;/home/junxie/work/Snet/data/2016_08_16_01_00&quot;</span></span><br><span class=\"line\">p=Path(fpath)</span><br><span class=\"line\">i=<span class=\"number\">0</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> file <span class=\"keyword\">in</span> p.rglob(<span class=\"string\">&#x27;*VX*.SAC&#x27;</span>): <span class=\"comment\">#循环读取文件</span></span><br><span class=\"line\">    st=read(file, debug_headers=<span class=\"literal\">True</span>)</span><br><span class=\"line\">    tr=st[<span class=\"number\">0</span>].copy()</span><br><span class=\"line\">    aa=<span class=\"built_in\">str</span>(file).split(<span class=\"string\">&quot;/&quot;</span>)</span><br><span class=\"line\">    pz=<span class=\"built_in\">str</span>(file)+<span class=\"string\">&quot;_PZ&quot;</span> <span class=\"comment\"># 这就是paz文件</span></span><br><span class=\"line\">    attach_paz(tr,pz)  <span class=\"comment\"># 贴到tr中</span></span><br><span class=\"line\">    paz_1hz = corn_freq_2_paz(<span class=\"number\">1.0</span>, damp=<span class=\"number\">0.707</span>)  <span class=\"comment\"># 1Hz instrument</span></span><br><span class=\"line\">    paz_1hz[<span class=\"string\">&#x27;sensitivity&#x27;</span>] = <span class=\"number\">1.0</span></span><br><span class=\"line\">    st.simulate(paz_simulate=paz_1hz) <span class=\"comment\">#去仪器响应</span></span><br></pre></td></tr></table></figure>\n<p>&emsp;&emsp;如果没有的话找到零点、极点和放大系数，赋值到paz里面，例如：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">from obspy import read</span><br><span class=\"line\">from obspy.signal.invsim import corn_freq_2_paz</span><br><span class=\"line\">st = read()</span><br><span class=\"line\">paz_sts2 = &#123;&#x27;poles&#x27;: [-0.037004+0.037016j, -0.037004-0.037016j,</span><br><span class=\"line\">                      -251.33+0j,</span><br><span class=\"line\">                      -131.04-467.29j, -131.04+467.29j],</span><br><span class=\"line\">            &#x27;zeros&#x27;: [0j, 0j],</span><br><span class=\"line\">            &#x27;gain&#x27;: 60077000.0,</span><br><span class=\"line\">            &#x27;sensitivity&#x27;: 2516778400.0&#125;</span><br><span class=\"line\">paz_1hz = corn_freq_2_paz(1.0, damp=0.707)</span><br><span class=\"line\">st.simulate(paz_remove=paz_sts2, paz_simulate=paz_1hz)</span><br></pre></td></tr></table></figure>","related_posts":[],"length":1140,"excerpt":"<p>&emsp;&emsp;有些时候数据下载下来只有polezero格式的仪器响应，那python脚本怎么去仪器响应呢？</p>","more":"<p>&emsp;&emsp;如果有polezero文件，那可以用attach_paz来读取。然后去仪器响应的脚本如下：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> obspy</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">from</span> obspy <span class=\"keyword\">import</span> read</span><br><span class=\"line\"><span class=\"keyword\">from</span> obspy.io.sac <span class=\"keyword\">import</span> attach_paz</span><br><span class=\"line\"><span class=\"keyword\">from</span> obspy.signal.invsim <span class=\"keyword\">import</span> corn_freq_2_paz</span><br><span class=\"line\"><span class=\"keyword\">from</span> pathlib <span class=\"keyword\">import</span> Path</span><br><span class=\"line\">fpath=<span class=\"string\">&quot;/home/junxie/work/Snet/data/2016_08_16_01_00&quot;</span></span><br><span class=\"line\">p=Path(fpath)</span><br><span class=\"line\">i=<span class=\"number\">0</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> file <span class=\"keyword\">in</span> p.rglob(<span class=\"string\">&#x27;*VX*.SAC&#x27;</span>): <span class=\"comment\">#循环读取文件</span></span><br><span class=\"line\">    st=read(file, debug_headers=<span class=\"literal\">True</span>)</span><br><span class=\"line\">    tr=st[<span class=\"number\">0</span>].copy()</span><br><span class=\"line\">    aa=<span class=\"built_in\">str</span>(file).split(<span class=\"string\">&quot;/&quot;</span>)</span><br><span class=\"line\">    pz=<span class=\"built_in\">str</span>(file)+<span class=\"string\">&quot;_PZ&quot;</span> <span class=\"comment\"># 这就是paz文件</span></span><br><span class=\"line\">    attach_paz(tr,pz)  <span class=\"comment\"># 贴到tr中</span></span><br><span class=\"line\">    paz_1hz = corn_freq_2_paz(<span class=\"number\">1.0</span>, damp=<span class=\"number\">0.707</span>)  <span class=\"comment\"># 1Hz instrument</span></span><br><span class=\"line\">    paz_1hz[<span class=\"string\">&#x27;sensitivity&#x27;</span>] = <span class=\"number\">1.0</span></span><br><span class=\"line\">    st.simulate(paz_simulate=paz_1hz) <span class=\"comment\">#去仪器响应</span></span><br></pre></td></tr></table></figure>\n<p>&emsp;&emsp;如果没有的话找到零点、极点和放大系数，赋值到paz里面，例如：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">from obspy import read</span><br><span class=\"line\">from obspy.signal.invsim import corn_freq_2_paz</span><br><span class=\"line\">st = read()</span><br><span class=\"line\">paz_sts2 = &#123;&#x27;poles&#x27;: [-0.037004+0.037016j, -0.037004-0.037016j,</span><br><span class=\"line\">                      -251.33+0j,</span><br><span class=\"line\">                      -131.04-467.29j, -131.04+467.29j],</span><br><span class=\"line\">            &#x27;zeros&#x27;: [0j, 0j],</span><br><span class=\"line\">            &#x27;gain&#x27;: 60077000.0,</span><br><span class=\"line\">            &#x27;sensitivity&#x27;: 2516778400.0&#125;</span><br><span class=\"line\">paz_1hz = corn_freq_2_paz(1.0, damp=0.707)</span><br><span class=\"line\">st.simulate(paz_remove=paz_sts2, paz_simulate=paz_1hz)</span><br></pre></td></tr></table></figure>"},{"title":"如何下载Fnet的台站列表","abbrlink":"f46e64ed","date":"2024-09-01T02:52:18.000Z","_content":"&emsp;&emsp;如何下载Fnet的台站列表？\n<!--less-->\n&emsp;&emsp;这里其实是一个网页抓取的工作。Fnet台站列表网址是https://www.fnet.bosai.go.jp/st_info/?LANG=en。那么下载其列表并保存到本地的python脚本如下：\n```\nimport pandas as pd\nimport requests\nurl = 'https://www.fnet.bosai.go.jp/st_info/?LANG=en'\nresponse = requests.get(url)\nprint(response.content)\ndfs = pd.read_html(response.content)\nif len(dfs) > 0:\n    df = dfs[2]\n    df.to_csv('fnet_station.csv',index=False)\n    print(\"表格已保存为 fent_station.csv 文件。\")\nelse:\n    print(\"未找到表格。\")\n```\n注意到保存下来的是第三个表dfs[2]。事实上该网页有多个表，如果抓取其他网站信息的时候需要打印出dfs，自己判断。\n","source":"_posts/2024-09-01-how-to-download-fnet-station-list.md","raw":"---\ntitle: 如何下载Fnet的台站列表\ncategories:\n  - work\ntags:\n  - web\nabbrlink: f46e64ed\ndate: 2024-09-01 10:52:18\n---\n&emsp;&emsp;如何下载Fnet的台站列表？\n<!--less-->\n&emsp;&emsp;这里其实是一个网页抓取的工作。Fnet台站列表网址是https://www.fnet.bosai.go.jp/st_info/?LANG=en。那么下载其列表并保存到本地的python脚本如下：\n```\nimport pandas as pd\nimport requests\nurl = 'https://www.fnet.bosai.go.jp/st_info/?LANG=en'\nresponse = requests.get(url)\nprint(response.content)\ndfs = pd.read_html(response.content)\nif len(dfs) > 0:\n    df = dfs[2]\n    df.to_csv('fnet_station.csv',index=False)\n    print(\"表格已保存为 fent_station.csv 文件。\")\nelse:\n    print(\"未找到表格。\")\n```\n注意到保存下来的是第三个表dfs[2]。事实上该网页有多个表，如果抓取其他网站信息的时候需要打印出dfs，自己判断。\n","slug":"how-to-download-fnet-station-list","published":1,"updated":"2024-09-01T03:02:40.385Z","comments":1,"layout":"post","photos":[],"_id":"cmh498iq200agwvougr0d2fbj","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>&emsp;&emsp;这里其实是一个网页抓取的工作。Fnet台站列表网址是<a href=\"https://www.fnet.bosai.go.jp/st_info/?LANG=en%E3%80%82%E9%82%A3%E4%B9%88%E4%B8%8B%E8%BD%BD%E5%85%B6%E5%88%97%E8%A1%A8%E5%B9%B6%E4%BF%9D%E5%AD%98%E5%88%B0%E6%9C%AC%E5%9C%B0%E7%9A%84python%E8%84%9A%E6%9C%AC%E5%A6%82%E4%B8%8B%EF%BC%9A\">https://www.fnet.bosai.go.jp/st_info/?LANG=en。那么下载其列表并保存到本地的python脚本如下：</a></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">import pandas as pd</span><br><span class=\"line\">import requests</span><br><span class=\"line\">url = &#x27;https://www.fnet.bosai.go.jp/st_info/?LANG=en&#x27;</span><br><span class=\"line\">response = requests.get(url)</span><br><span class=\"line\">print(response.content)</span><br><span class=\"line\">dfs = pd.read_html(response.content)</span><br><span class=\"line\">if len(dfs) &gt; 0:</span><br><span class=\"line\">    df = dfs[2]</span><br><span class=\"line\">    df.to_csv(&#x27;fnet_station.csv&#x27;,index=False)</span><br><span class=\"line\">    print(&quot;表格已保存为 fent_station.csv 文件。&quot;)</span><br><span class=\"line\">else:</span><br><span class=\"line\">    print(&quot;未找到表格。&quot;)</span><br></pre></td></tr></table></figure>\n<p>注意到保存下来的是第三个表dfs[2]。事实上该网页有多个表，如果抓取其他网站信息的时候需要打印出dfs，自己判断。</p>","related_posts":[],"length":532,"excerpt":"<p>&emsp;&emsp;如何下载Fnet的台站列表？</p>","more":"<p>&emsp;&emsp;这里其实是一个网页抓取的工作。Fnet台站列表网址是<a href=\"https://www.fnet.bosai.go.jp/st_info/?LANG=en%E3%80%82%E9%82%A3%E4%B9%88%E4%B8%8B%E8%BD%BD%E5%85%B6%E5%88%97%E8%A1%A8%E5%B9%B6%E4%BF%9D%E5%AD%98%E5%88%B0%E6%9C%AC%E5%9C%B0%E7%9A%84python%E8%84%9A%E6%9C%AC%E5%A6%82%E4%B8%8B%EF%BC%9A\">https://www.fnet.bosai.go.jp/st_info/?LANG=en。那么下载其列表并保存到本地的python脚本如下：</a></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">import pandas as pd</span><br><span class=\"line\">import requests</span><br><span class=\"line\">url = &#x27;https://www.fnet.bosai.go.jp/st_info/?LANG=en&#x27;</span><br><span class=\"line\">response = requests.get(url)</span><br><span class=\"line\">print(response.content)</span><br><span class=\"line\">dfs = pd.read_html(response.content)</span><br><span class=\"line\">if len(dfs) &gt; 0:</span><br><span class=\"line\">    df = dfs[2]</span><br><span class=\"line\">    df.to_csv(&#x27;fnet_station.csv&#x27;,index=False)</span><br><span class=\"line\">    print(&quot;表格已保存为 fent_station.csv 文件。&quot;)</span><br><span class=\"line\">else:</span><br><span class=\"line\">    print(&quot;未找到表格。&quot;)</span><br></pre></td></tr></table></figure>\n<p>注意到保存下来的是第三个表dfs[2]。事实上该网页有多个表，如果抓取其他网站信息的时候需要打印出dfs，自己判断。</p>"},{"title":"文献阅读（十九）","abbrlink":"9989b72","date":"2024-09-03T13:58:47.000Z","_content":"[Estimation of the Orientations of the S-net Cabled Ocean-Bottom Sensors](https://pubs.geoscienceworld.org/ssa/srl/article-abstract/90/6/2175/573516/Estimation-of-the-Orientations-of-the-S-net-Cabled)\n\n<!--less-->\n### 摘要\n\n海沟地震和海啸观测网（S-net）是一种新颖的海底观测站网络，覆盖了日本东北部外海的广阔区域。为了充分利用S-net数据，我们估计了所有150个S-net站点的传感器方向，因为没有这些信息，就无法确定测量在地理坐标中的方位。我们确定了每个站点传感器方向的三个参数：电缆长轴的倾斜角度、围绕长轴的旋转角度和长轴的方位角。我们使用记录重力加速度的加速度计的直流分量来估计倾斜和旋转角度。除了2016年8月20日Mw 6.0三陆海沟地震和2016年11月20日Mw 6.9福岛地震造成的旋转角度大于1°的余震步变外，大多数站点在2016年至2018年期间的倾斜和旋转角度都在0.001°至0.1°的范围内略有变化。我们通过长周期瑞利波的质点运动估计了长轴的方位角。我们使用了7至14个远震事件（Mw 7.0-8.2）在0.01-0.03 Hz的加速度计记录。方位角被限制在95%置信区间的±3°-12°内。在根据估计的传感器方向校正原始波形后，我们确认了整个S-net站点内的相干波形，以及径向和横向分量中瑞利波和洛夫波的分离。波形也与陆地上的宽频带站点相干。我们提供了估计的传感器方向和转换矩阵，用于从XYZ坐标转换为东西向上（ENU）分量。估计的方向可以作为基于S-net数据进一步进行地震和地壳探测的基础资源。\n\n### 相关研究的重要性\n\n1. **提高地震和海啸预警的准确性**：通过精确的海底观测，可以更好地理解地震和海啸的产生机制，从而提高预警系统的准确性。\n2. **增进对地壳和地幔结构的理解**：海底地震观测提供了直接测量地壳和地幔结构的手段，有助于揭示地球内部的动力学过程。\n3. **支持灾害风险评估和管理**：准确的地震和海啸数据对于评估灾害风险、制定减灾策略和提高公共安全至关重要。\n\n### 前人研究及不足\n\n- **前人研究**：\n  - S-net的部署和初步观测结果（Kanazawa et al., 2016; Mochizuki et al., 2016; Uehira et al., 2016）。\n  - 利用S-net数据进行地震定位和震源机制研究（Nakamura and Hayashimoto, 2019）。\n\n- **研究不足**：\n  - 传感器方向的不确定性限制了数据的精确分析和解释。\n  - 缺乏对传感器方向变化的长期监测和校正。\n\n### 本文使用的数据和方法\n\n- **数据**：S-net的加速度计记录，包括强震传感器和高灵敏度加速度计的数据。\n- **方法**：\n  - 使用加速度计的直流分量估计倾斜和旋转角度。\n  - 利用长周期瑞利波的粒子运动估计传感器的方位角。\n\n### 本文结果\n\n- 确定了所有150个S-net站点的传感器方向。\n- 发现倾斜和旋转角度在大多数站点在2016年至2018年期间相对稳定。\n- 通过校正波形，确认了S-net站点内的波形相干性和与陆地宽频带站点的一致性。\n\n### 本文创新之处和贡献\n\n- **创新之处**：首次系统地估计了S-net所有站点的传感器方向，为精确的地震和地壳数据分析提供了基础。\n- **贡献**：提供了传感器方向的估计值和转换矩阵，这些信息对于未来的地震学和地壳探测研究具有重要价值。\n\n### 本文不足\n\n- 数据分析可能受到传感器安装和海底环境变化的影响。\n- 需要进一步验证传感器方向估计的长期稳定性和准确性。\n\n","source":"_posts/2024-09-03-paper-reading-19.md","raw":"---\ntitle: 文献阅读（十九）\ncategories:\n  - work\ntags:\n  - paper\nabbrlink: 9989b72\ndate: 2024-09-03 21:58:47\n---\n[Estimation of the Orientations of the S-net Cabled Ocean-Bottom Sensors](https://pubs.geoscienceworld.org/ssa/srl/article-abstract/90/6/2175/573516/Estimation-of-the-Orientations-of-the-S-net-Cabled)\n\n<!--less-->\n### 摘要\n\n海沟地震和海啸观测网（S-net）是一种新颖的海底观测站网络，覆盖了日本东北部外海的广阔区域。为了充分利用S-net数据，我们估计了所有150个S-net站点的传感器方向，因为没有这些信息，就无法确定测量在地理坐标中的方位。我们确定了每个站点传感器方向的三个参数：电缆长轴的倾斜角度、围绕长轴的旋转角度和长轴的方位角。我们使用记录重力加速度的加速度计的直流分量来估计倾斜和旋转角度。除了2016年8月20日Mw 6.0三陆海沟地震和2016年11月20日Mw 6.9福岛地震造成的旋转角度大于1°的余震步变外，大多数站点在2016年至2018年期间的倾斜和旋转角度都在0.001°至0.1°的范围内略有变化。我们通过长周期瑞利波的质点运动估计了长轴的方位角。我们使用了7至14个远震事件（Mw 7.0-8.2）在0.01-0.03 Hz的加速度计记录。方位角被限制在95%置信区间的±3°-12°内。在根据估计的传感器方向校正原始波形后，我们确认了整个S-net站点内的相干波形，以及径向和横向分量中瑞利波和洛夫波的分离。波形也与陆地上的宽频带站点相干。我们提供了估计的传感器方向和转换矩阵，用于从XYZ坐标转换为东西向上（ENU）分量。估计的方向可以作为基于S-net数据进一步进行地震和地壳探测的基础资源。\n\n### 相关研究的重要性\n\n1. **提高地震和海啸预警的准确性**：通过精确的海底观测，可以更好地理解地震和海啸的产生机制，从而提高预警系统的准确性。\n2. **增进对地壳和地幔结构的理解**：海底地震观测提供了直接测量地壳和地幔结构的手段，有助于揭示地球内部的动力学过程。\n3. **支持灾害风险评估和管理**：准确的地震和海啸数据对于评估灾害风险、制定减灾策略和提高公共安全至关重要。\n\n### 前人研究及不足\n\n- **前人研究**：\n  - S-net的部署和初步观测结果（Kanazawa et al., 2016; Mochizuki et al., 2016; Uehira et al., 2016）。\n  - 利用S-net数据进行地震定位和震源机制研究（Nakamura and Hayashimoto, 2019）。\n\n- **研究不足**：\n  - 传感器方向的不确定性限制了数据的精确分析和解释。\n  - 缺乏对传感器方向变化的长期监测和校正。\n\n### 本文使用的数据和方法\n\n- **数据**：S-net的加速度计记录，包括强震传感器和高灵敏度加速度计的数据。\n- **方法**：\n  - 使用加速度计的直流分量估计倾斜和旋转角度。\n  - 利用长周期瑞利波的粒子运动估计传感器的方位角。\n\n### 本文结果\n\n- 确定了所有150个S-net站点的传感器方向。\n- 发现倾斜和旋转角度在大多数站点在2016年至2018年期间相对稳定。\n- 通过校正波形，确认了S-net站点内的波形相干性和与陆地宽频带站点的一致性。\n\n### 本文创新之处和贡献\n\n- **创新之处**：首次系统地估计了S-net所有站点的传感器方向，为精确的地震和地壳数据分析提供了基础。\n- **贡献**：提供了传感器方向的估计值和转换矩阵，这些信息对于未来的地震学和地壳探测研究具有重要价值。\n\n### 本文不足\n\n- 数据分析可能受到传感器安装和海底环境变化的影响。\n- 需要进一步验证传感器方向估计的长期稳定性和准确性。\n\n","slug":"paper-reading-19","published":1,"updated":"2024-09-03T14:12:28.701Z","comments":1,"layout":"post","photos":[],"_id":"cmh498iq300ajwvoub6x09ubt","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><h3 id=\"摘要\"><a href=\"#摘要\" class=\"headerlink\" title=\"摘要\"></a>摘要</h3><p>海沟地震和海啸观测网（S-net）是一种新颖的海底观测站网络，覆盖了日本东北部外海的广阔区域。为了充分利用S-net数据，我们估计了所有150个S-net站点的传感器方向，因为没有这些信息，就无法确定测量在地理坐标中的方位。我们确定了每个站点传感器方向的三个参数：电缆长轴的倾斜角度、围绕长轴的旋转角度和长轴的方位角。我们使用记录重力加速度的加速度计的直流分量来估计倾斜和旋转角度。除了2016年8月20日Mw 6.0三陆海沟地震和2016年11月20日Mw 6.9福岛地震造成的旋转角度大于1°的余震步变外，大多数站点在2016年至2018年期间的倾斜和旋转角度都在0.001°至0.1°的范围内略有变化。我们通过长周期瑞利波的质点运动估计了长轴的方位角。我们使用了7至14个远震事件（Mw 7.0-8.2）在0.01-0.03 Hz的加速度计记录。方位角被限制在95%置信区间的±3°-12°内。在根据估计的传感器方向校正原始波形后，我们确认了整个S-net站点内的相干波形，以及径向和横向分量中瑞利波和洛夫波的分离。波形也与陆地上的宽频带站点相干。我们提供了估计的传感器方向和转换矩阵，用于从XYZ坐标转换为东西向上（ENU）分量。估计的方向可以作为基于S-net数据进一步进行地震和地壳探测的基础资源。</p>\n<h3 id=\"相关研究的重要性\"><a href=\"#相关研究的重要性\" class=\"headerlink\" title=\"相关研究的重要性\"></a>相关研究的重要性</h3><ol>\n<li><strong>提高地震和海啸预警的准确性</strong>：通过精确的海底观测，可以更好地理解地震和海啸的产生机制，从而提高预警系统的准确性。</li>\n<li><strong>增进对地壳和地幔结构的理解</strong>：海底地震观测提供了直接测量地壳和地幔结构的手段，有助于揭示地球内部的动力学过程。</li>\n<li><strong>支持灾害风险评估和管理</strong>：准确的地震和海啸数据对于评估灾害风险、制定减灾策略和提高公共安全至关重要。</li>\n</ol>\n<h3 id=\"前人研究及不足\"><a href=\"#前人研究及不足\" class=\"headerlink\" title=\"前人研究及不足\"></a>前人研究及不足</h3><ul>\n<li><p><strong>前人研究</strong>：</p>\n<ul>\n<li>S-net的部署和初步观测结果（Kanazawa et al., 2016; Mochizuki et al., 2016; Uehira et al., 2016）。</li>\n<li>利用S-net数据进行地震定位和震源机制研究（Nakamura and Hayashimoto, 2019）。</li>\n</ul>\n</li>\n<li><p><strong>研究不足</strong>：</p>\n<ul>\n<li>传感器方向的不确定性限制了数据的精确分析和解释。</li>\n<li>缺乏对传感器方向变化的长期监测和校正。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"本文使用的数据和方法\"><a href=\"#本文使用的数据和方法\" class=\"headerlink\" title=\"本文使用的数据和方法\"></a>本文使用的数据和方法</h3><ul>\n<li><strong>数据</strong>：S-net的加速度计记录，包括强震传感器和高灵敏度加速度计的数据。</li>\n<li><strong>方法</strong>：<ul>\n<li>使用加速度计的直流分量估计倾斜和旋转角度。</li>\n<li>利用长周期瑞利波的粒子运动估计传感器的方位角。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"本文结果\"><a href=\"#本文结果\" class=\"headerlink\" title=\"本文结果\"></a>本文结果</h3><ul>\n<li>确定了所有150个S-net站点的传感器方向。</li>\n<li>发现倾斜和旋转角度在大多数站点在2016年至2018年期间相对稳定。</li>\n<li>通过校正波形，确认了S-net站点内的波形相干性和与陆地宽频带站点的一致性。</li>\n</ul>\n<h3 id=\"本文创新之处和贡献\"><a href=\"#本文创新之处和贡献\" class=\"headerlink\" title=\"本文创新之处和贡献\"></a>本文创新之处和贡献</h3><ul>\n<li><strong>创新之处</strong>：首次系统地估计了S-net所有站点的传感器方向，为精确的地震和地壳数据分析提供了基础。</li>\n<li><strong>贡献</strong>：提供了传感器方向的估计值和转换矩阵，这些信息对于未来的地震学和地壳探测研究具有重要价值。</li>\n</ul>\n<h3 id=\"本文不足\"><a href=\"#本文不足\" class=\"headerlink\" title=\"本文不足\"></a>本文不足</h3><ul>\n<li>数据分析可能受到传感器安装和海底环境变化的影响。</li>\n<li>需要进一步验证传感器方向估计的长期稳定性和准确性。</li>\n</ul>","related_posts":["paper-reading-20.html"],"length":1315,"excerpt":"<p><a href=\"https://pubs.geoscienceworld.org/ssa/srl/article-abstract/90/6/2175/573516/Estimation-of-the-Orientations-of-the-S-net-Cabled\">Estimation of the Orientations of the S-net Cabled Ocean-Bottom Sensors</a></p>","more":"<h3 id=\"摘要\"><a href=\"#摘要\" class=\"headerlink\" title=\"摘要\"></a>摘要</h3><p>海沟地震和海啸观测网（S-net）是一种新颖的海底观测站网络，覆盖了日本东北部外海的广阔区域。为了充分利用S-net数据，我们估计了所有150个S-net站点的传感器方向，因为没有这些信息，就无法确定测量在地理坐标中的方位。我们确定了每个站点传感器方向的三个参数：电缆长轴的倾斜角度、围绕长轴的旋转角度和长轴的方位角。我们使用记录重力加速度的加速度计的直流分量来估计倾斜和旋转角度。除了2016年8月20日Mw 6.0三陆海沟地震和2016年11月20日Mw 6.9福岛地震造成的旋转角度大于1°的余震步变外，大多数站点在2016年至2018年期间的倾斜和旋转角度都在0.001°至0.1°的范围内略有变化。我们通过长周期瑞利波的质点运动估计了长轴的方位角。我们使用了7至14个远震事件（Mw 7.0-8.2）在0.01-0.03 Hz的加速度计记录。方位角被限制在95%置信区间的±3°-12°内。在根据估计的传感器方向校正原始波形后，我们确认了整个S-net站点内的相干波形，以及径向和横向分量中瑞利波和洛夫波的分离。波形也与陆地上的宽频带站点相干。我们提供了估计的传感器方向和转换矩阵，用于从XYZ坐标转换为东西向上（ENU）分量。估计的方向可以作为基于S-net数据进一步进行地震和地壳探测的基础资源。</p>\n<h3 id=\"相关研究的重要性\"><a href=\"#相关研究的重要性\" class=\"headerlink\" title=\"相关研究的重要性\"></a>相关研究的重要性</h3><ol>\n<li><strong>提高地震和海啸预警的准确性</strong>：通过精确的海底观测，可以更好地理解地震和海啸的产生机制，从而提高预警系统的准确性。</li>\n<li><strong>增进对地壳和地幔结构的理解</strong>：海底地震观测提供了直接测量地壳和地幔结构的手段，有助于揭示地球内部的动力学过程。</li>\n<li><strong>支持灾害风险评估和管理</strong>：准确的地震和海啸数据对于评估灾害风险、制定减灾策略和提高公共安全至关重要。</li>\n</ol>\n<h3 id=\"前人研究及不足\"><a href=\"#前人研究及不足\" class=\"headerlink\" title=\"前人研究及不足\"></a>前人研究及不足</h3><ul>\n<li><p><strong>前人研究</strong>：</p>\n<ul>\n<li>S-net的部署和初步观测结果（Kanazawa et al., 2016; Mochizuki et al., 2016; Uehira et al., 2016）。</li>\n<li>利用S-net数据进行地震定位和震源机制研究（Nakamura and Hayashimoto, 2019）。</li>\n</ul>\n</li>\n<li><p><strong>研究不足</strong>：</p>\n<ul>\n<li>传感器方向的不确定性限制了数据的精确分析和解释。</li>\n<li>缺乏对传感器方向变化的长期监测和校正。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"本文使用的数据和方法\"><a href=\"#本文使用的数据和方法\" class=\"headerlink\" title=\"本文使用的数据和方法\"></a>本文使用的数据和方法</h3><ul>\n<li><strong>数据</strong>：S-net的加速度计记录，包括强震传感器和高灵敏度加速度计的数据。</li>\n<li><strong>方法</strong>：<ul>\n<li>使用加速度计的直流分量估计倾斜和旋转角度。</li>\n<li>利用长周期瑞利波的粒子运动估计传感器的方位角。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"本文结果\"><a href=\"#本文结果\" class=\"headerlink\" title=\"本文结果\"></a>本文结果</h3><ul>\n<li>确定了所有150个S-net站点的传感器方向。</li>\n<li>发现倾斜和旋转角度在大多数站点在2016年至2018年期间相对稳定。</li>\n<li>通过校正波形，确认了S-net站点内的波形相干性和与陆地宽频带站点的一致性。</li>\n</ul>\n<h3 id=\"本文创新之处和贡献\"><a href=\"#本文创新之处和贡献\" class=\"headerlink\" title=\"本文创新之处和贡献\"></a>本文创新之处和贡献</h3><ul>\n<li><strong>创新之处</strong>：首次系统地估计了S-net所有站点的传感器方向，为精确的地震和地壳数据分析提供了基础。</li>\n<li><strong>贡献</strong>：提供了传感器方向的估计值和转换矩阵，这些信息对于未来的地震学和地壳探测研究具有重要价值。</li>\n</ul>\n<h3 id=\"本文不足\"><a href=\"#本文不足\" class=\"headerlink\" title=\"本文不足\"></a>本文不足</h3><ul>\n<li>数据分析可能受到传感器安装和海底环境变化的影响。</li>\n<li>需要进一步验证传感器方向估计的长期稳定性和准确性。</li>\n</ul>"},{"title":"文献阅读（二十）","abbrlink":"750e9151","date":"2024-09-09T14:01:19.000Z","_content":"&emsp;&emsp;[Using Ocean Ambient Sound to Measure Local Integrated Deep Ocean Temperature](https://agupubs.onlinelibrary.wiley.com/doi/10.1029/2024GL108943?af=R)\n<!--less-->\n### 摘要翻译\n\n测量深海温度变化对于理解地球系统如何应对气候变化至关重要。在这项工作中，我们提出了一种方法，利用声学传播的被动估计来测量局部（约3公里）空间尺度上的深度平均深海温度。这些深海温度的被动声学估计可以与现有的和未来的被动声学监测基础设施一起使用，为海洋提供补充观测，尤其是在海洋观测覆盖不足的区域。利用8年的环境声数据，我们展示了被动估计与全球海洋模型和ARGO浮标测量的一致性。与HYCOM海洋模型的均方根差为0.13°C，与ARGO测量的均方根差为0.086°C。\n\n### 相关研究的重要性\n\n1. **气候变化监测**：深海温度是气候变化的关键指标，对预测未来气候变化模式至关重要。\n2. **海洋生态系统影响**：深海温度的变化影响海洋生态系统的健康和生物多样性。\n3. **海洋洋流和循环**：深海温度数据对于理解海洋环流和热量传输至关重要。\n\n### 前人相关研究及其不足\n\n- **Bensen et al. (2007)**：利用环境噪声数据获得可靠的宽带表面波色散测量。*不足*：可能没有充分考虑海洋环境的复杂性。\n- **Brooks & Gerstoft (2009)**：在热带风暴期间从20-100 Hz噪声的交叉相关中近似格林函数。*不足*：研究可能受限于特定环境条件。\n- **Woolfe & Sabra (2015)**：使用深海环境噪声监测温度变化。*不足*：可能缺乏长期和大规模的数据支持。\n\n### 本文使用的数据和方法\n\n- **数据**：使用了8年的OOI环境声数据，由两个海底水听器记录。\n- **方法**：利用环境噪声干涉测量技术估计声学格林函数，通过分析声波传播时间来估计深度平均水温。\n\n### 获得的结果\n\n- 与HYCOM海洋模型的均方根差为0.13°C。\n- 与ARGO浮标测量的均方根差为0.086°C。\n\n### 本文创新之处和贡献\n\n- **创新之处**：首次在深海环境中使用被动声学监测技术来测量局部积分温度。\n- **贡献**：提供了一种新的深海温度监测方法，可以补充现有的观测手段，特别是在观测覆盖不足的区域。\n\n### 本文的不足\n\n- **数据范围**：研究仅限于特定的海洋区域，可能需要更广泛的数据来验证方法的普适性。\n- **环境因素**：可能未充分考虑所有可能影响声波传播的环境因素，如海底地形变化。\n","source":"_posts/2024-09-09-paper-reading-20.md","raw":"---\ntitle: 文献阅读（二十）\ncategories:\n  - work\ntags:\n  - paper\nabbrlink: '750e9151'\ndate: 2024-09-09 22:01:19\n---\n&emsp;&emsp;[Using Ocean Ambient Sound to Measure Local Integrated Deep Ocean Temperature](https://agupubs.onlinelibrary.wiley.com/doi/10.1029/2024GL108943?af=R)\n<!--less-->\n### 摘要翻译\n\n测量深海温度变化对于理解地球系统如何应对气候变化至关重要。在这项工作中，我们提出了一种方法，利用声学传播的被动估计来测量局部（约3公里）空间尺度上的深度平均深海温度。这些深海温度的被动声学估计可以与现有的和未来的被动声学监测基础设施一起使用，为海洋提供补充观测，尤其是在海洋观测覆盖不足的区域。利用8年的环境声数据，我们展示了被动估计与全球海洋模型和ARGO浮标测量的一致性。与HYCOM海洋模型的均方根差为0.13°C，与ARGO测量的均方根差为0.086°C。\n\n### 相关研究的重要性\n\n1. **气候变化监测**：深海温度是气候变化的关键指标，对预测未来气候变化模式至关重要。\n2. **海洋生态系统影响**：深海温度的变化影响海洋生态系统的健康和生物多样性。\n3. **海洋洋流和循环**：深海温度数据对于理解海洋环流和热量传输至关重要。\n\n### 前人相关研究及其不足\n\n- **Bensen et al. (2007)**：利用环境噪声数据获得可靠的宽带表面波色散测量。*不足*：可能没有充分考虑海洋环境的复杂性。\n- **Brooks & Gerstoft (2009)**：在热带风暴期间从20-100 Hz噪声的交叉相关中近似格林函数。*不足*：研究可能受限于特定环境条件。\n- **Woolfe & Sabra (2015)**：使用深海环境噪声监测温度变化。*不足*：可能缺乏长期和大规模的数据支持。\n\n### 本文使用的数据和方法\n\n- **数据**：使用了8年的OOI环境声数据，由两个海底水听器记录。\n- **方法**：利用环境噪声干涉测量技术估计声学格林函数，通过分析声波传播时间来估计深度平均水温。\n\n### 获得的结果\n\n- 与HYCOM海洋模型的均方根差为0.13°C。\n- 与ARGO浮标测量的均方根差为0.086°C。\n\n### 本文创新之处和贡献\n\n- **创新之处**：首次在深海环境中使用被动声学监测技术来测量局部积分温度。\n- **贡献**：提供了一种新的深海温度监测方法，可以补充现有的观测手段，特别是在观测覆盖不足的区域。\n\n### 本文的不足\n\n- **数据范围**：研究仅限于特定的海洋区域，可能需要更广泛的数据来验证方法的普适性。\n- **环境因素**：可能未充分考虑所有可能影响声波传播的环境因素，如海底地形变化。\n","slug":"paper-reading-20","published":1,"updated":"2024-10-05T05:19:34.234Z","comments":1,"layout":"post","photos":[],"_id":"cmh498iq300anwvoudugq7h9j","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><h3 id=\"摘要翻译\"><a href=\"#摘要翻译\" class=\"headerlink\" title=\"摘要翻译\"></a>摘要翻译</h3><p>测量深海温度变化对于理解地球系统如何应对气候变化至关重要。在这项工作中，我们提出了一种方法，利用声学传播的被动估计来测量局部（约3公里）空间尺度上的深度平均深海温度。这些深海温度的被动声学估计可以与现有的和未来的被动声学监测基础设施一起使用，为海洋提供补充观测，尤其是在海洋观测覆盖不足的区域。利用8年的环境声数据，我们展示了被动估计与全球海洋模型和ARGO浮标测量的一致性。与HYCOM海洋模型的均方根差为0.13°C，与ARGO测量的均方根差为0.086°C。</p>\n<h3 id=\"相关研究的重要性\"><a href=\"#相关研究的重要性\" class=\"headerlink\" title=\"相关研究的重要性\"></a>相关研究的重要性</h3><ol>\n<li><strong>气候变化监测</strong>：深海温度是气候变化的关键指标，对预测未来气候变化模式至关重要。</li>\n<li><strong>海洋生态系统影响</strong>：深海温度的变化影响海洋生态系统的健康和生物多样性。</li>\n<li><strong>海洋洋流和循环</strong>：深海温度数据对于理解海洋环流和热量传输至关重要。</li>\n</ol>\n<h3 id=\"前人相关研究及其不足\"><a href=\"#前人相关研究及其不足\" class=\"headerlink\" title=\"前人相关研究及其不足\"></a>前人相关研究及其不足</h3><ul>\n<li>**Bensen et al. (2007)*<em>：利用环境噪声数据获得可靠的宽带表面波色散测量。</em>不足*：可能没有充分考虑海洋环境的复杂性。</li>\n<li>**Brooks &amp; Gerstoft (2009)*<em>：在热带风暴期间从20-100 Hz噪声的交叉相关中近似格林函数。</em>不足*：研究可能受限于特定环境条件。</li>\n<li>**Woolfe &amp; Sabra (2015)*<em>：使用深海环境噪声监测温度变化。</em>不足*：可能缺乏长期和大规模的数据支持。</li>\n</ul>\n<h3 id=\"本文使用的数据和方法\"><a href=\"#本文使用的数据和方法\" class=\"headerlink\" title=\"本文使用的数据和方法\"></a>本文使用的数据和方法</h3><ul>\n<li><strong>数据</strong>：使用了8年的OOI环境声数据，由两个海底水听器记录。</li>\n<li><strong>方法</strong>：利用环境噪声干涉测量技术估计声学格林函数，通过分析声波传播时间来估计深度平均水温。</li>\n</ul>\n<h3 id=\"获得的结果\"><a href=\"#获得的结果\" class=\"headerlink\" title=\"获得的结果\"></a>获得的结果</h3><ul>\n<li>与HYCOM海洋模型的均方根差为0.13°C。</li>\n<li>与ARGO浮标测量的均方根差为0.086°C。</li>\n</ul>\n<h3 id=\"本文创新之处和贡献\"><a href=\"#本文创新之处和贡献\" class=\"headerlink\" title=\"本文创新之处和贡献\"></a>本文创新之处和贡献</h3><ul>\n<li><strong>创新之处</strong>：首次在深海环境中使用被动声学监测技术来测量局部积分温度。</li>\n<li><strong>贡献</strong>：提供了一种新的深海温度监测方法，可以补充现有的观测手段，特别是在观测覆盖不足的区域。</li>\n</ul>\n<h3 id=\"本文的不足\"><a href=\"#本文的不足\" class=\"headerlink\" title=\"本文的不足\"></a>本文的不足</h3><ul>\n<li><strong>数据范围</strong>：研究仅限于特定的海洋区域，可能需要更广泛的数据来验证方法的普适性。</li>\n<li><strong>环境因素</strong>：可能未充分考虑所有可能影响声波传播的环境因素，如海底地形变化。</li>\n</ul>","related_posts":["paper-reading-18.html","paper-reading-19.html"],"length":940,"excerpt":"<p>&emsp;&emsp;<a href=\"https://agupubs.onlinelibrary.wiley.com/doi/10.1029/2024GL108943?af=R\">Using Ocean Ambient Sound to Measure Local Integrated Deep Ocean Temperature</a></p>","more":"<h3 id=\"摘要翻译\"><a href=\"#摘要翻译\" class=\"headerlink\" title=\"摘要翻译\"></a>摘要翻译</h3><p>测量深海温度变化对于理解地球系统如何应对气候变化至关重要。在这项工作中，我们提出了一种方法，利用声学传播的被动估计来测量局部（约3公里）空间尺度上的深度平均深海温度。这些深海温度的被动声学估计可以与现有的和未来的被动声学监测基础设施一起使用，为海洋提供补充观测，尤其是在海洋观测覆盖不足的区域。利用8年的环境声数据，我们展示了被动估计与全球海洋模型和ARGO浮标测量的一致性。与HYCOM海洋模型的均方根差为0.13°C，与ARGO测量的均方根差为0.086°C。</p>\n<h3 id=\"相关研究的重要性\"><a href=\"#相关研究的重要性\" class=\"headerlink\" title=\"相关研究的重要性\"></a>相关研究的重要性</h3><ol>\n<li><strong>气候变化监测</strong>：深海温度是气候变化的关键指标，对预测未来气候变化模式至关重要。</li>\n<li><strong>海洋生态系统影响</strong>：深海温度的变化影响海洋生态系统的健康和生物多样性。</li>\n<li><strong>海洋洋流和循环</strong>：深海温度数据对于理解海洋环流和热量传输至关重要。</li>\n</ol>\n<h3 id=\"前人相关研究及其不足\"><a href=\"#前人相关研究及其不足\" class=\"headerlink\" title=\"前人相关研究及其不足\"></a>前人相关研究及其不足</h3><ul>\n<li>**Bensen et al. (2007)*<em>：利用环境噪声数据获得可靠的宽带表面波色散测量。</em>不足*：可能没有充分考虑海洋环境的复杂性。</li>\n<li>**Brooks &amp; Gerstoft (2009)*<em>：在热带风暴期间从20-100 Hz噪声的交叉相关中近似格林函数。</em>不足*：研究可能受限于特定环境条件。</li>\n<li>**Woolfe &amp; Sabra (2015)*<em>：使用深海环境噪声监测温度变化。</em>不足*：可能缺乏长期和大规模的数据支持。</li>\n</ul>\n<h3 id=\"本文使用的数据和方法\"><a href=\"#本文使用的数据和方法\" class=\"headerlink\" title=\"本文使用的数据和方法\"></a>本文使用的数据和方法</h3><ul>\n<li><strong>数据</strong>：使用了8年的OOI环境声数据，由两个海底水听器记录。</li>\n<li><strong>方法</strong>：利用环境噪声干涉测量技术估计声学格林函数，通过分析声波传播时间来估计深度平均水温。</li>\n</ul>\n<h3 id=\"获得的结果\"><a href=\"#获得的结果\" class=\"headerlink\" title=\"获得的结果\"></a>获得的结果</h3><ul>\n<li>与HYCOM海洋模型的均方根差为0.13°C。</li>\n<li>与ARGO浮标测量的均方根差为0.086°C。</li>\n</ul>\n<h3 id=\"本文创新之处和贡献\"><a href=\"#本文创新之处和贡献\" class=\"headerlink\" title=\"本文创新之处和贡献\"></a>本文创新之处和贡献</h3><ul>\n<li><strong>创新之处</strong>：首次在深海环境中使用被动声学监测技术来测量局部积分温度。</li>\n<li><strong>贡献</strong>：提供了一种新的深海温度监测方法，可以补充现有的观测手段，特别是在观测覆盖不足的区域。</li>\n</ul>\n<h3 id=\"本文的不足\"><a href=\"#本文的不足\" class=\"headerlink\" title=\"本文的不足\"></a>本文的不足</h3><ul>\n<li><strong>数据范围</strong>：研究仅限于特定的海洋区域，可能需要更广泛的数据来验证方法的普适性。</li>\n<li><strong>环境因素</strong>：可能未充分考虑所有可能影响声波传播的环境因素，如海底地形变化。</li>\n</ul>"},{"title":"文献阅读（二十一）","abbrlink":"81385f98","date":"2024-10-05T05:13:07.000Z","_content":"&emsp;&emsp;[Global scale analysis and modelling of primary microseisms](https://academic.oup.com/gji/article/218/1/560/5421624)\n<!--less-->\n### 摘要翻译\n\n第一类地脉动是地球上研究较少的地震背景振动。证据表明，这些振动的来源是由海洋重力波与海底地形耦合引起的。因此，这些来源应该位于小于海洋波长的水深处。利用最先进的海浪模型，我们进行了首次全球规模的初级微震垂直分量功率谱密度的地震建模。我们的建模使我们能够推断，在南半球观测到的初级微震的弱季节性与源的弱局部季节性相对应。此外，对主要贡献于每个台站的源区域的系统分析揭示，北大西洋东西两侧的台站对频率依赖的源区域都很敏感。在低频（即0.05赫兹）下，主要的源区域可能位于距离台站数千公里之外。这一观察表明，在最近的海岸识别初级微震的源区域可能会产生误导。\n\n### 相关研究的重要性\n\n1. **了解地球的自然振动**：初级微震是理解地球内部动力学和海洋与地壳相互作用的重要途径。\n2. **环境监测**：微震活动与海洋活动紧密相关，可用于监测气候变化和海啸等自然灾害。\n3. **地震学研究**：微震的研究有助于改进地震波传播理论，提高地震预测的准确性。\n\n### 前人研究及不足\n\n1. **Hasselmann (1963)**：首次提出了海洋重力波与海底地形相互作用产生微震的理论。\n2. **Haubrich et al. (1963)**：通过比较微震和涌浪的频谱，确定了近岸区域的微震源。\n3. **Juretzek & Hadziioannou (2016, 2017)**：使用波束形成分析推断了初级微震频率带中瑞利波和勒夫波的源位置。\n\n**不足**：\n- 这些研究主要集中在局部区域，缺乏全球尺度的系统分析。\n- 对于微震源的季节性变化和频率依赖性研究不足。\n- 缺乏对远离台站的源区域的深入研究。\n\n### 本文使用的数据和方法\n\n- **数据**：使用Geoscope网络的24个地震台站在2013年记录的连续地震数据。\n- **方法**：采用最先进的海洋波模型WAVEWATCH III进行全球规模的地震建模。\n\n### 本文结果\n\n- 确定了全球初级微震的源区域。\n- 发现南半球初级微震的弱季节性与源的弱季节性相对应。\n- 揭示了北大西洋东西两侧台站对频率依赖的源区域的敏感性。\n\n### 本文创新之处和贡献\n\n1. **全球规模建模**：首次进行全球规模的初级微震建模。\n2. **季节性分析**：提供了南半球微震季节性变化的新见解。\n3. **频率依赖性研究**：揭示了低频下微震源区域的远程特性。\n\n### 本文不足\n\n- **模型简化**：在模型中未考虑局部场地效应和三维传播效应。\n- **数据限制**：研究基于2013年的数据，可能需要更多年份的数据来验证模型的稳定性。\n","source":"_posts/2024-10-05-paper-reading-21.md","raw":"---\ntitle: 文献阅读（二十一）\ncategories:\n  - work\ntags:\n  - paper\nabbrlink: 81385f98\ndate: 2024-10-05 13:13:07\n---\n&emsp;&emsp;[Global scale analysis and modelling of primary microseisms](https://academic.oup.com/gji/article/218/1/560/5421624)\n<!--less-->\n### 摘要翻译\n\n第一类地脉动是地球上研究较少的地震背景振动。证据表明，这些振动的来源是由海洋重力波与海底地形耦合引起的。因此，这些来源应该位于小于海洋波长的水深处。利用最先进的海浪模型，我们进行了首次全球规模的初级微震垂直分量功率谱密度的地震建模。我们的建模使我们能够推断，在南半球观测到的初级微震的弱季节性与源的弱局部季节性相对应。此外，对主要贡献于每个台站的源区域的系统分析揭示，北大西洋东西两侧的台站对频率依赖的源区域都很敏感。在低频（即0.05赫兹）下，主要的源区域可能位于距离台站数千公里之外。这一观察表明，在最近的海岸识别初级微震的源区域可能会产生误导。\n\n### 相关研究的重要性\n\n1. **了解地球的自然振动**：初级微震是理解地球内部动力学和海洋与地壳相互作用的重要途径。\n2. **环境监测**：微震活动与海洋活动紧密相关，可用于监测气候变化和海啸等自然灾害。\n3. **地震学研究**：微震的研究有助于改进地震波传播理论，提高地震预测的准确性。\n\n### 前人研究及不足\n\n1. **Hasselmann (1963)**：首次提出了海洋重力波与海底地形相互作用产生微震的理论。\n2. **Haubrich et al. (1963)**：通过比较微震和涌浪的频谱，确定了近岸区域的微震源。\n3. **Juretzek & Hadziioannou (2016, 2017)**：使用波束形成分析推断了初级微震频率带中瑞利波和勒夫波的源位置。\n\n**不足**：\n- 这些研究主要集中在局部区域，缺乏全球尺度的系统分析。\n- 对于微震源的季节性变化和频率依赖性研究不足。\n- 缺乏对远离台站的源区域的深入研究。\n\n### 本文使用的数据和方法\n\n- **数据**：使用Geoscope网络的24个地震台站在2013年记录的连续地震数据。\n- **方法**：采用最先进的海洋波模型WAVEWATCH III进行全球规模的地震建模。\n\n### 本文结果\n\n- 确定了全球初级微震的源区域。\n- 发现南半球初级微震的弱季节性与源的弱季节性相对应。\n- 揭示了北大西洋东西两侧台站对频率依赖的源区域的敏感性。\n\n### 本文创新之处和贡献\n\n1. **全球规模建模**：首次进行全球规模的初级微震建模。\n2. **季节性分析**：提供了南半球微震季节性变化的新见解。\n3. **频率依赖性研究**：揭示了低频下微震源区域的远程特性。\n\n### 本文不足\n\n- **模型简化**：在模型中未考虑局部场地效应和三维传播效应。\n- **数据限制**：研究基于2013年的数据，可能需要更多年份的数据来验证模型的稳定性。\n","slug":"paper-reading-21","published":1,"updated":"2024-10-05T05:19:48.638Z","comments":1,"layout":"post","photos":[],"_id":"cmh498iq400aqwvoughwb2un5","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><h3 id=\"摘要翻译\"><a href=\"#摘要翻译\" class=\"headerlink\" title=\"摘要翻译\"></a>摘要翻译</h3><p>第一类地脉动是地球上研究较少的地震背景振动。证据表明，这些振动的来源是由海洋重力波与海底地形耦合引起的。因此，这些来源应该位于小于海洋波长的水深处。利用最先进的海浪模型，我们进行了首次全球规模的初级微震垂直分量功率谱密度的地震建模。我们的建模使我们能够推断，在南半球观测到的初级微震的弱季节性与源的弱局部季节性相对应。此外，对主要贡献于每个台站的源区域的系统分析揭示，北大西洋东西两侧的台站对频率依赖的源区域都很敏感。在低频（即0.05赫兹）下，主要的源区域可能位于距离台站数千公里之外。这一观察表明，在最近的海岸识别初级微震的源区域可能会产生误导。</p>\n<h3 id=\"相关研究的重要性\"><a href=\"#相关研究的重要性\" class=\"headerlink\" title=\"相关研究的重要性\"></a>相关研究的重要性</h3><ol>\n<li><strong>了解地球的自然振动</strong>：初级微震是理解地球内部动力学和海洋与地壳相互作用的重要途径。</li>\n<li><strong>环境监测</strong>：微震活动与海洋活动紧密相关，可用于监测气候变化和海啸等自然灾害。</li>\n<li><strong>地震学研究</strong>：微震的研究有助于改进地震波传播理论，提高地震预测的准确性。</li>\n</ol>\n<h3 id=\"前人研究及不足\"><a href=\"#前人研究及不足\" class=\"headerlink\" title=\"前人研究及不足\"></a>前人研究及不足</h3><ol>\n<li>**Hasselmann (1963)**：首次提出了海洋重力波与海底地形相互作用产生微震的理论。</li>\n<li>**Haubrich et al. (1963)**：通过比较微震和涌浪的频谱，确定了近岸区域的微震源。</li>\n<li>**Juretzek &amp; Hadziioannou (2016, 2017)**：使用波束形成分析推断了初级微震频率带中瑞利波和勒夫波的源位置。</li>\n</ol>\n<p><strong>不足</strong>：</p>\n<ul>\n<li>这些研究主要集中在局部区域，缺乏全球尺度的系统分析。</li>\n<li>对于微震源的季节性变化和频率依赖性研究不足。</li>\n<li>缺乏对远离台站的源区域的深入研究。</li>\n</ul>\n<h3 id=\"本文使用的数据和方法\"><a href=\"#本文使用的数据和方法\" class=\"headerlink\" title=\"本文使用的数据和方法\"></a>本文使用的数据和方法</h3><ul>\n<li><strong>数据</strong>：使用Geoscope网络的24个地震台站在2013年记录的连续地震数据。</li>\n<li><strong>方法</strong>：采用最先进的海洋波模型WAVEWATCH III进行全球规模的地震建模。</li>\n</ul>\n<h3 id=\"本文结果\"><a href=\"#本文结果\" class=\"headerlink\" title=\"本文结果\"></a>本文结果</h3><ul>\n<li>确定了全球初级微震的源区域。</li>\n<li>发现南半球初级微震的弱季节性与源的弱季节性相对应。</li>\n<li>揭示了北大西洋东西两侧台站对频率依赖的源区域的敏感性。</li>\n</ul>\n<h3 id=\"本文创新之处和贡献\"><a href=\"#本文创新之处和贡献\" class=\"headerlink\" title=\"本文创新之处和贡献\"></a>本文创新之处和贡献</h3><ol>\n<li><strong>全球规模建模</strong>：首次进行全球规模的初级微震建模。</li>\n<li><strong>季节性分析</strong>：提供了南半球微震季节性变化的新见解。</li>\n<li><strong>频率依赖性研究</strong>：揭示了低频下微震源区域的远程特性。</li>\n</ol>\n<h3 id=\"本文不足\"><a href=\"#本文不足\" class=\"headerlink\" title=\"本文不足\"></a>本文不足</h3><ul>\n<li><strong>模型简化</strong>：在模型中未考虑局部场地效应和三维传播效应。</li>\n<li><strong>数据限制</strong>：研究基于2013年的数据，可能需要更多年份的数据来验证模型的稳定性。</li>\n</ul>","related_posts":[],"length":1013,"excerpt":"<p>&emsp;&emsp;<a href=\"https://academic.oup.com/gji/article/218/1/560/5421624\">Global scale analysis and modelling of primary microseisms</a></p>","more":"<h3 id=\"摘要翻译\"><a href=\"#摘要翻译\" class=\"headerlink\" title=\"摘要翻译\"></a>摘要翻译</h3><p>第一类地脉动是地球上研究较少的地震背景振动。证据表明，这些振动的来源是由海洋重力波与海底地形耦合引起的。因此，这些来源应该位于小于海洋波长的水深处。利用最先进的海浪模型，我们进行了首次全球规模的初级微震垂直分量功率谱密度的地震建模。我们的建模使我们能够推断，在南半球观测到的初级微震的弱季节性与源的弱局部季节性相对应。此外，对主要贡献于每个台站的源区域的系统分析揭示，北大西洋东西两侧的台站对频率依赖的源区域都很敏感。在低频（即0.05赫兹）下，主要的源区域可能位于距离台站数千公里之外。这一观察表明，在最近的海岸识别初级微震的源区域可能会产生误导。</p>\n<h3 id=\"相关研究的重要性\"><a href=\"#相关研究的重要性\" class=\"headerlink\" title=\"相关研究的重要性\"></a>相关研究的重要性</h3><ol>\n<li><strong>了解地球的自然振动</strong>：初级微震是理解地球内部动力学和海洋与地壳相互作用的重要途径。</li>\n<li><strong>环境监测</strong>：微震活动与海洋活动紧密相关，可用于监测气候变化和海啸等自然灾害。</li>\n<li><strong>地震学研究</strong>：微震的研究有助于改进地震波传播理论，提高地震预测的准确性。</li>\n</ol>\n<h3 id=\"前人研究及不足\"><a href=\"#前人研究及不足\" class=\"headerlink\" title=\"前人研究及不足\"></a>前人研究及不足</h3><ol>\n<li>**Hasselmann (1963)**：首次提出了海洋重力波与海底地形相互作用产生微震的理论。</li>\n<li>**Haubrich et al. (1963)**：通过比较微震和涌浪的频谱，确定了近岸区域的微震源。</li>\n<li>**Juretzek &amp; Hadziioannou (2016, 2017)**：使用波束形成分析推断了初级微震频率带中瑞利波和勒夫波的源位置。</li>\n</ol>\n<p><strong>不足</strong>：</p>\n<ul>\n<li>这些研究主要集中在局部区域，缺乏全球尺度的系统分析。</li>\n<li>对于微震源的季节性变化和频率依赖性研究不足。</li>\n<li>缺乏对远离台站的源区域的深入研究。</li>\n</ul>\n<h3 id=\"本文使用的数据和方法\"><a href=\"#本文使用的数据和方法\" class=\"headerlink\" title=\"本文使用的数据和方法\"></a>本文使用的数据和方法</h3><ul>\n<li><strong>数据</strong>：使用Geoscope网络的24个地震台站在2013年记录的连续地震数据。</li>\n<li><strong>方法</strong>：采用最先进的海洋波模型WAVEWATCH III进行全球规模的地震建模。</li>\n</ul>\n<h3 id=\"本文结果\"><a href=\"#本文结果\" class=\"headerlink\" title=\"本文结果\"></a>本文结果</h3><ul>\n<li>确定了全球初级微震的源区域。</li>\n<li>发现南半球初级微震的弱季节性与源的弱季节性相对应。</li>\n<li>揭示了北大西洋东西两侧台站对频率依赖的源区域的敏感性。</li>\n</ul>\n<h3 id=\"本文创新之处和贡献\"><a href=\"#本文创新之处和贡献\" class=\"headerlink\" title=\"本文创新之处和贡献\"></a>本文创新之处和贡献</h3><ol>\n<li><strong>全球规模建模</strong>：首次进行全球规模的初级微震建模。</li>\n<li><strong>季节性分析</strong>：提供了南半球微震季节性变化的新见解。</li>\n<li><strong>频率依赖性研究</strong>：揭示了低频下微震源区域的远程特性。</li>\n</ol>\n<h3 id=\"本文不足\"><a href=\"#本文不足\" class=\"headerlink\" title=\"本文不足\"></a>本文不足</h3><ul>\n<li><strong>模型简化</strong>：在模型中未考虑局部场地效应和三维传播效应。</li>\n<li><strong>数据限制</strong>：研究基于2013年的数据，可能需要更多年份的数据来验证模型的稳定性。</li>\n</ul>"},{"title":"高效bash脚本","abbrlink":"6a8b5c38","date":"2024-10-12T00:53:03.000Z","_content":"&emsp;&emsp;转学习到的高效bash脚本。\n<!--less-->\n# build-in commands\n```bash\nif [[ \"$var\" -eq 3 ]];then\n   echo \"hello\"\nfi\n```\n\n# minimize subshells\n```bash\noutput=$(<input.txt)\n```\n\n# array\n```bash\ncolor=(\"red\" \"yellow\" \"blue\")\nfor col in \"${color[@]}\";\ndo\n   echo $col\ndone\n```\n\n# enable noclobber\n可以防止overwrite。\n```\nset -o noclobber\n```\n\n# file operation\n```\nwhile IFS= read -f line\ndo\necho $line\ndone <input.txt\n```\n\n# parallel processing\n```\ncat urls.txt | xargs -n 1 -P 4 curl -O\n```\n\n# error handling\n脚本一出错就退出来。\n```\nset -e\n```\n个性化出错信息。\n```\ncommand || { echo \"command failded\"; exit 1; }\n``` \ntrap signals \n```\ntrap 'echo \"error occurred\"; cleanup; exit1' ERR\nfunction cleanup(){\n   #clean up command\n}\n```\nvalidate inputs\n```\nif [[ -z \"$1\" ]];then\n   echo \"Usage: $0 <argument>\"\n   exit 1\nfi\n```\nlogging\n```\nlogfile=\"script.log\"\nexec > >(tee -i $logfile)\nexec 2>&1\n\necho \"script started\"\n```\n\n# 系统任务\n\n系统备份\n```\nset -e\ntrap ' echo \"Backup failed\"; exit 1' ERR\nbk_up=\"/bak_dir\"\nts=$(date +%Y%m%d%H%M%S)\nbkup_file=\"${bk_up}/backup_${ts}.tar.gz\"\ntar czf \"$bkup_file\" backup_files\n```\n系统监测\n```\nthreshold=80\npartition=\"/dev/sda1\"\nusage=$(df -h | grep \"$partition\" | awk '{print $5}' | sed 's/%//')\nif [[ \"$usage\" -gt \"$threshold\" ]];then\n   echo \"disk usage of $partition is above $threshold%\"\nfi\n```\n用户管理\n```\nfunction add_user() {\n    local username=$1\n    useradd \"$username\" && echo \"User $username added successfully.\"\n}\n\nfunction remove_user() {\n}\ncase $1 in \n    add)\n       add_user \"$2\"\n       ;;\n    remove)\n       remove_user \"$2\"\n       ;;\n    *)\n       echo \"Usage : $0 {add|remove} <username>\"\n       exit 1\n       ;;\nesac\n```\n自动更新\n```\nset -e\ntrap 'echo \"update failed\"; exit 1 ' ERR\n\napt-get update && apt-get upgrade -y\n```\n网络配置\n```\nfunction configure_network(){\n     local interface=$1\n     local ip_address=$$2\n     local gateway=$3\n     \n     cat <<EOF >/etc/network/interfaces\nauto $interface\niface $interface inet static\n     address $ip_address\n     gateway $gateway\nEOF\n     systemctl restart networking\n     echo \"network configured on $interface\"\n}\n```\n","source":"_posts/2024-10-12-efficient-shell-script.md","raw":"---\ntitle: 高效bash脚本\ntags:\n  - Linux\nabbrlink: 6a8b5c38\ndate: 2024-10-12 08:53:03\n---\n&emsp;&emsp;转学习到的高效bash脚本。\n<!--less-->\n# build-in commands\n```bash\nif [[ \"$var\" -eq 3 ]];then\n   echo \"hello\"\nfi\n```\n\n# minimize subshells\n```bash\noutput=$(<input.txt)\n```\n\n# array\n```bash\ncolor=(\"red\" \"yellow\" \"blue\")\nfor col in \"${color[@]}\";\ndo\n   echo $col\ndone\n```\n\n# enable noclobber\n可以防止overwrite。\n```\nset -o noclobber\n```\n\n# file operation\n```\nwhile IFS= read -f line\ndo\necho $line\ndone <input.txt\n```\n\n# parallel processing\n```\ncat urls.txt | xargs -n 1 -P 4 curl -O\n```\n\n# error handling\n脚本一出错就退出来。\n```\nset -e\n```\n个性化出错信息。\n```\ncommand || { echo \"command failded\"; exit 1; }\n``` \ntrap signals \n```\ntrap 'echo \"error occurred\"; cleanup; exit1' ERR\nfunction cleanup(){\n   #clean up command\n}\n```\nvalidate inputs\n```\nif [[ -z \"$1\" ]];then\n   echo \"Usage: $0 <argument>\"\n   exit 1\nfi\n```\nlogging\n```\nlogfile=\"script.log\"\nexec > >(tee -i $logfile)\nexec 2>&1\n\necho \"script started\"\n```\n\n# 系统任务\n\n系统备份\n```\nset -e\ntrap ' echo \"Backup failed\"; exit 1' ERR\nbk_up=\"/bak_dir\"\nts=$(date +%Y%m%d%H%M%S)\nbkup_file=\"${bk_up}/backup_${ts}.tar.gz\"\ntar czf \"$bkup_file\" backup_files\n```\n系统监测\n```\nthreshold=80\npartition=\"/dev/sda1\"\nusage=$(df -h | grep \"$partition\" | awk '{print $5}' | sed 's/%//')\nif [[ \"$usage\" -gt \"$threshold\" ]];then\n   echo \"disk usage of $partition is above $threshold%\"\nfi\n```\n用户管理\n```\nfunction add_user() {\n    local username=$1\n    useradd \"$username\" && echo \"User $username added successfully.\"\n}\n\nfunction remove_user() {\n}\ncase $1 in \n    add)\n       add_user \"$2\"\n       ;;\n    remove)\n       remove_user \"$2\"\n       ;;\n    *)\n       echo \"Usage : $0 {add|remove} <username>\"\n       exit 1\n       ;;\nesac\n```\n自动更新\n```\nset -e\ntrap 'echo \"update failed\"; exit 1 ' ERR\n\napt-get update && apt-get upgrade -y\n```\n网络配置\n```\nfunction configure_network(){\n     local interface=$1\n     local ip_address=$$2\n     local gateway=$3\n     \n     cat <<EOF >/etc/network/interfaces\nauto $interface\niface $interface inet static\n     address $ip_address\n     gateway $gateway\nEOF\n     systemctl restart networking\n     echo \"network configured on $interface\"\n}\n```\n","slug":"efficient-shell-script","published":1,"updated":"2024-10-12T05:42:05.998Z","comments":1,"layout":"post","photos":[],"_id":"cmh498iq400auwvouawxthi7t","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><h1 id=\"build-in-commands\"><a href=\"#build-in-commands\" class=\"headerlink\" title=\"build-in commands\"></a>build-in commands</h1><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">if</span> [[ <span class=\"string\">&quot;<span class=\"variable\">$var</span>&quot;</span> -eq 3 ]];<span class=\"keyword\">then</span></span><br><span class=\"line\">   <span class=\"built_in\">echo</span> <span class=\"string\">&quot;hello&quot;</span></span><br><span class=\"line\"><span class=\"keyword\">fi</span></span><br></pre></td></tr></table></figure>\n\n<h1 id=\"minimize-subshells\"><a href=\"#minimize-subshells\" class=\"headerlink\" title=\"minimize subshells\"></a>minimize subshells</h1><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">output=$(&lt;input.txt)</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"array\"><a href=\"#array\" class=\"headerlink\" title=\"array\"></a>array</h1><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">color=(<span class=\"string\">&quot;red&quot;</span> <span class=\"string\">&quot;yellow&quot;</span> <span class=\"string\">&quot;blue&quot;</span>)</span><br><span class=\"line\"><span class=\"keyword\">for</span> col <span class=\"keyword\">in</span> <span class=\"string\">&quot;<span class=\"variable\">$&#123;color[@]&#125;</span>&quot;</span>;</span><br><span class=\"line\"><span class=\"keyword\">do</span></span><br><span class=\"line\">   <span class=\"built_in\">echo</span> <span class=\"variable\">$col</span></span><br><span class=\"line\"><span class=\"keyword\">done</span></span><br></pre></td></tr></table></figure>\n\n<h1 id=\"enable-noclobber\"><a href=\"#enable-noclobber\" class=\"headerlink\" title=\"enable noclobber\"></a>enable noclobber</h1><p>可以防止overwrite。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">set -o noclobber</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"file-operation\"><a href=\"#file-operation\" class=\"headerlink\" title=\"file operation\"></a>file operation</h1><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">while IFS= read -f line</span><br><span class=\"line\">do</span><br><span class=\"line\">echo $line</span><br><span class=\"line\">done &lt;input.txt</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"parallel-processing\"><a href=\"#parallel-processing\" class=\"headerlink\" title=\"parallel processing\"></a>parallel processing</h1><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cat urls.txt | xargs -n 1 -P 4 curl -O</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"error-handling\"><a href=\"#error-handling\" class=\"headerlink\" title=\"error handling\"></a>error handling</h1><p>脚本一出错就退出来。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">set -e</span><br></pre></td></tr></table></figure>\n<p>个性化出错信息。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">command || &#123; echo &quot;command failded&quot;; exit 1; &#125;</span><br></pre></td></tr></table></figure>\n<p>trap signals </p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">trap &#x27;echo &quot;error occurred&quot;; cleanup; exit1&#x27; ERR</span><br><span class=\"line\">function cleanup()&#123;</span><br><span class=\"line\">   #clean up command</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>validate inputs</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">if [[ -z &quot;$1&quot; ]];then</span><br><span class=\"line\">   echo &quot;Usage: $0 &lt;argument&gt;&quot;</span><br><span class=\"line\">   exit 1</span><br><span class=\"line\">fi</span><br></pre></td></tr></table></figure>\n<p>logging</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">logfile=&quot;script.log&quot;</span><br><span class=\"line\">exec &gt; &gt;(tee -i $logfile)</span><br><span class=\"line\">exec 2&gt;&amp;1</span><br><span class=\"line\"></span><br><span class=\"line\">echo &quot;script started&quot;</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"系统任务\"><a href=\"#系统任务\" class=\"headerlink\" title=\"系统任务\"></a>系统任务</h1><p>系统备份</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">set -e</span><br><span class=\"line\">trap &#x27; echo &quot;Backup failed&quot;; exit 1&#x27; ERR</span><br><span class=\"line\">bk_up=&quot;/bak_dir&quot;</span><br><span class=\"line\">ts=$(date +%Y%m%d%H%M%S)</span><br><span class=\"line\">bkup_file=&quot;$&#123;bk_up&#125;/backup_$&#123;ts&#125;.tar.gz&quot;</span><br><span class=\"line\">tar czf &quot;$bkup_file&quot; backup_files</span><br></pre></td></tr></table></figure>\n<p>系统监测</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">threshold=80</span><br><span class=\"line\">partition=&quot;/dev/sda1&quot;</span><br><span class=\"line\">usage=$(df -h | grep &quot;$partition&quot; | awk &#x27;&#123;print $5&#125;&#x27; | sed &#x27;s/%//&#x27;)</span><br><span class=\"line\">if [[ &quot;$usage&quot; -gt &quot;$threshold&quot; ]];then</span><br><span class=\"line\">   echo &quot;disk usage of $partition is above $threshold%&quot;</span><br><span class=\"line\">fi</span><br></pre></td></tr></table></figure>\n<p>用户管理</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">function add_user() &#123;</span><br><span class=\"line\">    local username=$1</span><br><span class=\"line\">    useradd &quot;$username&quot; &amp;&amp; echo &quot;User $username added successfully.&quot;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">function remove_user() &#123;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">case $1 in </span><br><span class=\"line\">    add)</span><br><span class=\"line\">       add_user &quot;$2&quot;</span><br><span class=\"line\">       ;;</span><br><span class=\"line\">    remove)</span><br><span class=\"line\">       remove_user &quot;$2&quot;</span><br><span class=\"line\">       ;;</span><br><span class=\"line\">    *)</span><br><span class=\"line\">       echo &quot;Usage : $0 &#123;add|remove&#125; &lt;username&gt;&quot;</span><br><span class=\"line\">       exit 1</span><br><span class=\"line\">       ;;</span><br><span class=\"line\">esac</span><br></pre></td></tr></table></figure>\n<p>自动更新</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">set -e</span><br><span class=\"line\">trap &#x27;echo &quot;update failed&quot;; exit 1 &#x27; ERR</span><br><span class=\"line\"></span><br><span class=\"line\">apt-get update &amp;&amp; apt-get upgrade -y</span><br></pre></td></tr></table></figure>\n<p>网络配置</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">function configure_network()&#123;</span><br><span class=\"line\">     local interface=$1</span><br><span class=\"line\">     local ip_address=$$2</span><br><span class=\"line\">     local gateway=$3</span><br><span class=\"line\">     </span><br><span class=\"line\">     cat &lt;&lt;EOF &gt;/etc/network/interfaces</span><br><span class=\"line\">auto $interface</span><br><span class=\"line\">iface $interface inet static</span><br><span class=\"line\">     address $ip_address</span><br><span class=\"line\">     gateway $gateway</span><br><span class=\"line\">EOF</span><br><span class=\"line\">     systemctl restart networking</span><br><span class=\"line\">     echo &quot;network configured on $interface&quot;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>","related_posts":["no-file-found-in-LaTeX.html","add_counter.html","install-and-backup-mediawiki.html","to-desk.html"],"length":2079,"excerpt":"<p>&emsp;&emsp;转学习到的高效bash脚本。</p>","more":"<h1 id=\"build-in-commands\"><a href=\"#build-in-commands\" class=\"headerlink\" title=\"build-in commands\"></a>build-in commands</h1><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">if</span> [[ <span class=\"string\">&quot;<span class=\"variable\">$var</span>&quot;</span> -eq 3 ]];<span class=\"keyword\">then</span></span><br><span class=\"line\">   <span class=\"built_in\">echo</span> <span class=\"string\">&quot;hello&quot;</span></span><br><span class=\"line\"><span class=\"keyword\">fi</span></span><br></pre></td></tr></table></figure>\n\n<h1 id=\"minimize-subshells\"><a href=\"#minimize-subshells\" class=\"headerlink\" title=\"minimize subshells\"></a>minimize subshells</h1><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">output=$(&lt;input.txt)</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"array\"><a href=\"#array\" class=\"headerlink\" title=\"array\"></a>array</h1><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">color=(<span class=\"string\">&quot;red&quot;</span> <span class=\"string\">&quot;yellow&quot;</span> <span class=\"string\">&quot;blue&quot;</span>)</span><br><span class=\"line\"><span class=\"keyword\">for</span> col <span class=\"keyword\">in</span> <span class=\"string\">&quot;<span class=\"variable\">$&#123;color[@]&#125;</span>&quot;</span>;</span><br><span class=\"line\"><span class=\"keyword\">do</span></span><br><span class=\"line\">   <span class=\"built_in\">echo</span> <span class=\"variable\">$col</span></span><br><span class=\"line\"><span class=\"keyword\">done</span></span><br></pre></td></tr></table></figure>\n\n<h1 id=\"enable-noclobber\"><a href=\"#enable-noclobber\" class=\"headerlink\" title=\"enable noclobber\"></a>enable noclobber</h1><p>可以防止overwrite。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">set -o noclobber</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"file-operation\"><a href=\"#file-operation\" class=\"headerlink\" title=\"file operation\"></a>file operation</h1><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">while IFS= read -f line</span><br><span class=\"line\">do</span><br><span class=\"line\">echo $line</span><br><span class=\"line\">done &lt;input.txt</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"parallel-processing\"><a href=\"#parallel-processing\" class=\"headerlink\" title=\"parallel processing\"></a>parallel processing</h1><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cat urls.txt | xargs -n 1 -P 4 curl -O</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"error-handling\"><a href=\"#error-handling\" class=\"headerlink\" title=\"error handling\"></a>error handling</h1><p>脚本一出错就退出来。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">set -e</span><br></pre></td></tr></table></figure>\n<p>个性化出错信息。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">command || &#123; echo &quot;command failded&quot;; exit 1; &#125;</span><br></pre></td></tr></table></figure>\n<p>trap signals </p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">trap &#x27;echo &quot;error occurred&quot;; cleanup; exit1&#x27; ERR</span><br><span class=\"line\">function cleanup()&#123;</span><br><span class=\"line\">   #clean up command</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>validate inputs</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">if [[ -z &quot;$1&quot; ]];then</span><br><span class=\"line\">   echo &quot;Usage: $0 &lt;argument&gt;&quot;</span><br><span class=\"line\">   exit 1</span><br><span class=\"line\">fi</span><br></pre></td></tr></table></figure>\n<p>logging</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">logfile=&quot;script.log&quot;</span><br><span class=\"line\">exec &gt; &gt;(tee -i $logfile)</span><br><span class=\"line\">exec 2&gt;&amp;1</span><br><span class=\"line\"></span><br><span class=\"line\">echo &quot;script started&quot;</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"系统任务\"><a href=\"#系统任务\" class=\"headerlink\" title=\"系统任务\"></a>系统任务</h1><p>系统备份</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">set -e</span><br><span class=\"line\">trap &#x27; echo &quot;Backup failed&quot;; exit 1&#x27; ERR</span><br><span class=\"line\">bk_up=&quot;/bak_dir&quot;</span><br><span class=\"line\">ts=$(date +%Y%m%d%H%M%S)</span><br><span class=\"line\">bkup_file=&quot;$&#123;bk_up&#125;/backup_$&#123;ts&#125;.tar.gz&quot;</span><br><span class=\"line\">tar czf &quot;$bkup_file&quot; backup_files</span><br></pre></td></tr></table></figure>\n<p>系统监测</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">threshold=80</span><br><span class=\"line\">partition=&quot;/dev/sda1&quot;</span><br><span class=\"line\">usage=$(df -h | grep &quot;$partition&quot; | awk &#x27;&#123;print $5&#125;&#x27; | sed &#x27;s/%//&#x27;)</span><br><span class=\"line\">if [[ &quot;$usage&quot; -gt &quot;$threshold&quot; ]];then</span><br><span class=\"line\">   echo &quot;disk usage of $partition is above $threshold%&quot;</span><br><span class=\"line\">fi</span><br></pre></td></tr></table></figure>\n<p>用户管理</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">function add_user() &#123;</span><br><span class=\"line\">    local username=$1</span><br><span class=\"line\">    useradd &quot;$username&quot; &amp;&amp; echo &quot;User $username added successfully.&quot;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">function remove_user() &#123;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">case $1 in </span><br><span class=\"line\">    add)</span><br><span class=\"line\">       add_user &quot;$2&quot;</span><br><span class=\"line\">       ;;</span><br><span class=\"line\">    remove)</span><br><span class=\"line\">       remove_user &quot;$2&quot;</span><br><span class=\"line\">       ;;</span><br><span class=\"line\">    *)</span><br><span class=\"line\">       echo &quot;Usage : $0 &#123;add|remove&#125; &lt;username&gt;&quot;</span><br><span class=\"line\">       exit 1</span><br><span class=\"line\">       ;;</span><br><span class=\"line\">esac</span><br></pre></td></tr></table></figure>\n<p>自动更新</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">set -e</span><br><span class=\"line\">trap &#x27;echo &quot;update failed&quot;; exit 1 &#x27; ERR</span><br><span class=\"line\"></span><br><span class=\"line\">apt-get update &amp;&amp; apt-get upgrade -y</span><br></pre></td></tr></table></figure>\n<p>网络配置</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">function configure_network()&#123;</span><br><span class=\"line\">     local interface=$1</span><br><span class=\"line\">     local ip_address=$$2</span><br><span class=\"line\">     local gateway=$3</span><br><span class=\"line\">     </span><br><span class=\"line\">     cat &lt;&lt;EOF &gt;/etc/network/interfaces</span><br><span class=\"line\">auto $interface</span><br><span class=\"line\">iface $interface inet static</span><br><span class=\"line\">     address $ip_address</span><br><span class=\"line\">     gateway $gateway</span><br><span class=\"line\">EOF</span><br><span class=\"line\">     systemctl restart networking</span><br><span class=\"line\">     echo &quot;network configured on $interface&quot;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>"},{"title":"文献阅读（二十二）","abbrlink":"b12eb340","date":"2024-10-29T16:10:32.000Z","_content":"&emsp;&emsp;[A Simple Law for Ice-Shelf Calving](https://www.science.org/doi/10.1126/science.1162543)\n<!--less-->\n\n### 摘要翻译\n\n&emsp;&emsp;本文研究了南极和格陵兰岛的冰架在形成冰山前的崩解过程。目前，冰盖模型面临的一个主要问题是缺乏基于物理的冰架崩解法则。冰架与海湾壁或海底高地的摩擦提供了冰盖流动的阻力；这种阻力的减少会导致冰盖流动加速，进而导致海平面上升。冰架的长度增加会增加侧摩擦和遇到海底高地的概率，而这些无法在没有崩解法则的情况下计算。我们假设沿流冰架的扩展是控制崩解的主要因素。为了验证这一假设，我们收集了不同冰架的新数据和已发表的数据（表S1），选择这些数据是为了代表性而非全面性。除了一些壮观的例子外，崩解通量远大于长度变化。因此，冰架前端的速度大致等于崩解通量（c），而沿流速度梯度给出了适当的扩展速率（e˙）。所有数据都避开了剪切边缘，主要位于中心线附近。结果与我们的假设一致。最佳幂律拟合为 c = 15,000e˙0.43 m/year，解释了91%的方差（对数-对数空间中的线性回归为62%）；使用 c = 12,000 e˙0.33 表示对扩展应力的线性依赖，解释了88%的方差（对数-对数为43%）。残差表明较窄的冰架崩解速度较慢。侧向剪切将裂缝开启应力从崩解前沿旋转开来，同时有利于较小的冰山和容易愈合的剪切裂缝。模型 c = 0.039(e˙w)1.9 m/year（半宽w以米为单位）解释了超过95%的方差（对数-对数空间中为92%）。崩解率与厚度H相关，但幂律拟合 c(H) 仅解释了69%的方差（对数-对数为84%）；涉及 c(e˙) 和 c(e˙w) 的拟合残差与H没有强相关性。尽管如此，扩展应力随H增加，人们可能会预期断裂，因此崩解，取决于变形工作完成的速率，因此与 e˙H 成正比。包括 (e˙wH) 的最佳拟合幂律为 c = 0.022(e˙wH)0.98 m/year；图1显示了通过原点的线性拟合 c = 0.016 e˙wH m/year，每个解释了89%的方差（对数-对数为93%）（SOM文本）。数据不允许在这些或其他可能的关系中进行选择，但后者是物理上有动机的并且简单。c随e˙增加的一个含义是，几乎所有未受支撑的冰架都将无条件不稳定，因为厚度（因此扩展速率）在流动方向上减小，但速度增加；崩解事件将冰架前沿移入更厚、更快扩展、因此更快崩解的冰中，这些冰供应得更慢。数值实验表明适当的支撑可以稳定冰架。这与观察结果一致：从足够快的输入足够薄（因此扩展缓慢）的冰中可以形成极长的“冰舌”，冰架通常观察到在支撑点附近终止，失去支撑后冰架迅速缩小。尽管我们没有学到完整的崩解法则，但我们建议，从冰架的相互比较中得出的关系可能比以往任何时候都更令人鼓舞，因此值得进一步测试，并在冰流模型中谨慎实施。\n\n### 相关研究的重要性\n\n1. **海平面上升**：冰架崩解是全球海平面变化的关键因素，了解其机制对于预测未来海平面变化至关重要。\n2. **气候变化研究**：冰架崩解与气候变化紧密相关，研究崩解过程有助于理解全球气候变化的影响。\n3. **冰盖稳定性**：了解冰架崩解机制对于评估冰盖稳定性和长期存续性至关重要。\n\n### 前人研究及不足\n\n- **Meier (1990)**：在《Sea-Level Change》中讨论了冰架崩解对海平面变化的影响，但未提出基于物理的崩解法则。\n- **Dupont & Alley (2005)**：研究了冰架流动与崩解的关系，但未全面解释崩解过程的物理机制。\n- **不足**：缺乏一个全面的、基于物理的崩解法则，无法准确预测冰架崩解对海平面变化的影响。\n\n### 本文使用的数据和方法\n\n- **数据**：收集了不同冰架的新数据和已发表的数据（表S1），包括冰架的厚度、半宽、速度等。\n- **方法**：通过最佳幂律拟合和线性回归分析，研究冰架崩解通量与冰架扩展速率之间的关系。\n\n### 本文结果\n\n- **结果**：发现冰架崩解通量与冰架扩展速率的0.43次幂成正比，解释了91%的方差；冰架崩解率与冰架厚度、半宽和应变率的乘积成正比，解释了89%的方差。\n\n### 本文创新之处及贡献\n\n1. **创新**：提出了一个基于物理的冰架崩解法则，即冰架崩解通量与冰架扩展速率的幂律关系。\n2. **贡献**：为冰流模型提供了一个可能的崩解法则，有助于更准确地预测冰架崩解对海平面变化的影响。\n\n### 本文不足\n\n- **数据限制**：数据集并非全面，可能影响结果的普适性。\n- **模型简化**：模型假设沿流冰架扩展是控制崩解的主要因素，可能忽略了其他影响因素。\n\n","source":"_posts/2024-10-30-paper-reading-22.md","raw":"---\ntitle: 文献阅读（二十二）\ncategories:\n  - work\ntags:\n  - paper\nabbrlink: b12eb340\ndate: 2024-10-30 00:10:32\n---\n&emsp;&emsp;[A Simple Law for Ice-Shelf Calving](https://www.science.org/doi/10.1126/science.1162543)\n<!--less-->\n\n### 摘要翻译\n\n&emsp;&emsp;本文研究了南极和格陵兰岛的冰架在形成冰山前的崩解过程。目前，冰盖模型面临的一个主要问题是缺乏基于物理的冰架崩解法则。冰架与海湾壁或海底高地的摩擦提供了冰盖流动的阻力；这种阻力的减少会导致冰盖流动加速，进而导致海平面上升。冰架的长度增加会增加侧摩擦和遇到海底高地的概率，而这些无法在没有崩解法则的情况下计算。我们假设沿流冰架的扩展是控制崩解的主要因素。为了验证这一假设，我们收集了不同冰架的新数据和已发表的数据（表S1），选择这些数据是为了代表性而非全面性。除了一些壮观的例子外，崩解通量远大于长度变化。因此，冰架前端的速度大致等于崩解通量（c），而沿流速度梯度给出了适当的扩展速率（e˙）。所有数据都避开了剪切边缘，主要位于中心线附近。结果与我们的假设一致。最佳幂律拟合为 c = 15,000e˙0.43 m/year，解释了91%的方差（对数-对数空间中的线性回归为62%）；使用 c = 12,000 e˙0.33 表示对扩展应力的线性依赖，解释了88%的方差（对数-对数为43%）。残差表明较窄的冰架崩解速度较慢。侧向剪切将裂缝开启应力从崩解前沿旋转开来，同时有利于较小的冰山和容易愈合的剪切裂缝。模型 c = 0.039(e˙w)1.9 m/year（半宽w以米为单位）解释了超过95%的方差（对数-对数空间中为92%）。崩解率与厚度H相关，但幂律拟合 c(H) 仅解释了69%的方差（对数-对数为84%）；涉及 c(e˙) 和 c(e˙w) 的拟合残差与H没有强相关性。尽管如此，扩展应力随H增加，人们可能会预期断裂，因此崩解，取决于变形工作完成的速率，因此与 e˙H 成正比。包括 (e˙wH) 的最佳拟合幂律为 c = 0.022(e˙wH)0.98 m/year；图1显示了通过原点的线性拟合 c = 0.016 e˙wH m/year，每个解释了89%的方差（对数-对数为93%）（SOM文本）。数据不允许在这些或其他可能的关系中进行选择，但后者是物理上有动机的并且简单。c随e˙增加的一个含义是，几乎所有未受支撑的冰架都将无条件不稳定，因为厚度（因此扩展速率）在流动方向上减小，但速度增加；崩解事件将冰架前沿移入更厚、更快扩展、因此更快崩解的冰中，这些冰供应得更慢。数值实验表明适当的支撑可以稳定冰架。这与观察结果一致：从足够快的输入足够薄（因此扩展缓慢）的冰中可以形成极长的“冰舌”，冰架通常观察到在支撑点附近终止，失去支撑后冰架迅速缩小。尽管我们没有学到完整的崩解法则，但我们建议，从冰架的相互比较中得出的关系可能比以往任何时候都更令人鼓舞，因此值得进一步测试，并在冰流模型中谨慎实施。\n\n### 相关研究的重要性\n\n1. **海平面上升**：冰架崩解是全球海平面变化的关键因素，了解其机制对于预测未来海平面变化至关重要。\n2. **气候变化研究**：冰架崩解与气候变化紧密相关，研究崩解过程有助于理解全球气候变化的影响。\n3. **冰盖稳定性**：了解冰架崩解机制对于评估冰盖稳定性和长期存续性至关重要。\n\n### 前人研究及不足\n\n- **Meier (1990)**：在《Sea-Level Change》中讨论了冰架崩解对海平面变化的影响，但未提出基于物理的崩解法则。\n- **Dupont & Alley (2005)**：研究了冰架流动与崩解的关系，但未全面解释崩解过程的物理机制。\n- **不足**：缺乏一个全面的、基于物理的崩解法则，无法准确预测冰架崩解对海平面变化的影响。\n\n### 本文使用的数据和方法\n\n- **数据**：收集了不同冰架的新数据和已发表的数据（表S1），包括冰架的厚度、半宽、速度等。\n- **方法**：通过最佳幂律拟合和线性回归分析，研究冰架崩解通量与冰架扩展速率之间的关系。\n\n### 本文结果\n\n- **结果**：发现冰架崩解通量与冰架扩展速率的0.43次幂成正比，解释了91%的方差；冰架崩解率与冰架厚度、半宽和应变率的乘积成正比，解释了89%的方差。\n\n### 本文创新之处及贡献\n\n1. **创新**：提出了一个基于物理的冰架崩解法则，即冰架崩解通量与冰架扩展速率的幂律关系。\n2. **贡献**：为冰流模型提供了一个可能的崩解法则，有助于更准确地预测冰架崩解对海平面变化的影响。\n\n### 本文不足\n\n- **数据限制**：数据集并非全面，可能影响结果的普适性。\n- **模型简化**：模型假设沿流冰架扩展是控制崩解的主要因素，可能忽略了其他影响因素。\n\n","slug":"paper-reading-22","published":1,"updated":"2024-11-02T06:33:46.621Z","comments":1,"layout":"post","photos":[],"_id":"cmh498iq500axwvoufua4hda1","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><h3 id=\"摘要翻译\"><a href=\"#摘要翻译\" class=\"headerlink\" title=\"摘要翻译\"></a>摘要翻译</h3><p>&emsp;&emsp;本文研究了南极和格陵兰岛的冰架在形成冰山前的崩解过程。目前，冰盖模型面临的一个主要问题是缺乏基于物理的冰架崩解法则。冰架与海湾壁或海底高地的摩擦提供了冰盖流动的阻力；这种阻力的减少会导致冰盖流动加速，进而导致海平面上升。冰架的长度增加会增加侧摩擦和遇到海底高地的概率，而这些无法在没有崩解法则的情况下计算。我们假设沿流冰架的扩展是控制崩解的主要因素。为了验证这一假设，我们收集了不同冰架的新数据和已发表的数据（表S1），选择这些数据是为了代表性而非全面性。除了一些壮观的例子外，崩解通量远大于长度变化。因此，冰架前端的速度大致等于崩解通量（c），而沿流速度梯度给出了适当的扩展速率（e˙）。所有数据都避开了剪切边缘，主要位于中心线附近。结果与我们的假设一致。最佳幂律拟合为 c &#x3D; 15,000e˙0.43 m&#x2F;year，解释了91%的方差（对数-对数空间中的线性回归为62%）；使用 c &#x3D; 12,000 e˙0.33 表示对扩展应力的线性依赖，解释了88%的方差（对数-对数为43%）。残差表明较窄的冰架崩解速度较慢。侧向剪切将裂缝开启应力从崩解前沿旋转开来，同时有利于较小的冰山和容易愈合的剪切裂缝。模型 c &#x3D; 0.039(e˙w)1.9 m&#x2F;year（半宽w以米为单位）解释了超过95%的方差（对数-对数空间中为92%）。崩解率与厚度H相关，但幂律拟合 c(H) 仅解释了69%的方差（对数-对数为84%）；涉及 c(e˙) 和 c(e˙w) 的拟合残差与H没有强相关性。尽管如此，扩展应力随H增加，人们可能会预期断裂，因此崩解，取决于变形工作完成的速率，因此与 e˙H 成正比。包括 (e˙wH) 的最佳拟合幂律为 c &#x3D; 0.022(e˙wH)0.98 m&#x2F;year；图1显示了通过原点的线性拟合 c &#x3D; 0.016 e˙wH m&#x2F;year，每个解释了89%的方差（对数-对数为93%）（SOM文本）。数据不允许在这些或其他可能的关系中进行选择，但后者是物理上有动机的并且简单。c随e˙增加的一个含义是，几乎所有未受支撑的冰架都将无条件不稳定，因为厚度（因此扩展速率）在流动方向上减小，但速度增加；崩解事件将冰架前沿移入更厚、更快扩展、因此更快崩解的冰中，这些冰供应得更慢。数值实验表明适当的支撑可以稳定冰架。这与观察结果一致：从足够快的输入足够薄（因此扩展缓慢）的冰中可以形成极长的“冰舌”，冰架通常观察到在支撑点附近终止，失去支撑后冰架迅速缩小。尽管我们没有学到完整的崩解法则，但我们建议，从冰架的相互比较中得出的关系可能比以往任何时候都更令人鼓舞，因此值得进一步测试，并在冰流模型中谨慎实施。</p>\n<h3 id=\"相关研究的重要性\"><a href=\"#相关研究的重要性\" class=\"headerlink\" title=\"相关研究的重要性\"></a>相关研究的重要性</h3><ol>\n<li><strong>海平面上升</strong>：冰架崩解是全球海平面变化的关键因素，了解其机制对于预测未来海平面变化至关重要。</li>\n<li><strong>气候变化研究</strong>：冰架崩解与气候变化紧密相关，研究崩解过程有助于理解全球气候变化的影响。</li>\n<li><strong>冰盖稳定性</strong>：了解冰架崩解机制对于评估冰盖稳定性和长期存续性至关重要。</li>\n</ol>\n<h3 id=\"前人研究及不足\"><a href=\"#前人研究及不足\" class=\"headerlink\" title=\"前人研究及不足\"></a>前人研究及不足</h3><ul>\n<li>**Meier (1990)**：在《Sea-Level Change》中讨论了冰架崩解对海平面变化的影响，但未提出基于物理的崩解法则。</li>\n<li>**Dupont &amp; Alley (2005)**：研究了冰架流动与崩解的关系，但未全面解释崩解过程的物理机制。</li>\n<li><strong>不足</strong>：缺乏一个全面的、基于物理的崩解法则，无法准确预测冰架崩解对海平面变化的影响。</li>\n</ul>\n<h3 id=\"本文使用的数据和方法\"><a href=\"#本文使用的数据和方法\" class=\"headerlink\" title=\"本文使用的数据和方法\"></a>本文使用的数据和方法</h3><ul>\n<li><strong>数据</strong>：收集了不同冰架的新数据和已发表的数据（表S1），包括冰架的厚度、半宽、速度等。</li>\n<li><strong>方法</strong>：通过最佳幂律拟合和线性回归分析，研究冰架崩解通量与冰架扩展速率之间的关系。</li>\n</ul>\n<h3 id=\"本文结果\"><a href=\"#本文结果\" class=\"headerlink\" title=\"本文结果\"></a>本文结果</h3><ul>\n<li><strong>结果</strong>：发现冰架崩解通量与冰架扩展速率的0.43次幂成正比，解释了91%的方差；冰架崩解率与冰架厚度、半宽和应变率的乘积成正比，解释了89%的方差。</li>\n</ul>\n<h3 id=\"本文创新之处及贡献\"><a href=\"#本文创新之处及贡献\" class=\"headerlink\" title=\"本文创新之处及贡献\"></a>本文创新之处及贡献</h3><ol>\n<li><strong>创新</strong>：提出了一个基于物理的冰架崩解法则，即冰架崩解通量与冰架扩展速率的幂律关系。</li>\n<li><strong>贡献</strong>：为冰流模型提供了一个可能的崩解法则，有助于更准确地预测冰架崩解对海平面变化的影响。</li>\n</ol>\n<h3 id=\"本文不足\"><a href=\"#本文不足\" class=\"headerlink\" title=\"本文不足\"></a>本文不足</h3><ul>\n<li><strong>数据限制</strong>：数据集并非全面，可能影响结果的普适性。</li>\n<li><strong>模型简化</strong>：模型假设沿流冰架扩展是控制崩解的主要因素，可能忽略了其他影响因素。</li>\n</ul>","related_posts":[],"length":1804,"excerpt":"<p>&emsp;&emsp;<a href=\"https://www.science.org/doi/10.1126/science.1162543\">A Simple Law for Ice-Shelf Calving</a></p>","more":"<h3 id=\"摘要翻译\"><a href=\"#摘要翻译\" class=\"headerlink\" title=\"摘要翻译\"></a>摘要翻译</h3><p>&emsp;&emsp;本文研究了南极和格陵兰岛的冰架在形成冰山前的崩解过程。目前，冰盖模型面临的一个主要问题是缺乏基于物理的冰架崩解法则。冰架与海湾壁或海底高地的摩擦提供了冰盖流动的阻力；这种阻力的减少会导致冰盖流动加速，进而导致海平面上升。冰架的长度增加会增加侧摩擦和遇到海底高地的概率，而这些无法在没有崩解法则的情况下计算。我们假设沿流冰架的扩展是控制崩解的主要因素。为了验证这一假设，我们收集了不同冰架的新数据和已发表的数据（表S1），选择这些数据是为了代表性而非全面性。除了一些壮观的例子外，崩解通量远大于长度变化。因此，冰架前端的速度大致等于崩解通量（c），而沿流速度梯度给出了适当的扩展速率（e˙）。所有数据都避开了剪切边缘，主要位于中心线附近。结果与我们的假设一致。最佳幂律拟合为 c &#x3D; 15,000e˙0.43 m&#x2F;year，解释了91%的方差（对数-对数空间中的线性回归为62%）；使用 c &#x3D; 12,000 e˙0.33 表示对扩展应力的线性依赖，解释了88%的方差（对数-对数为43%）。残差表明较窄的冰架崩解速度较慢。侧向剪切将裂缝开启应力从崩解前沿旋转开来，同时有利于较小的冰山和容易愈合的剪切裂缝。模型 c &#x3D; 0.039(e˙w)1.9 m&#x2F;year（半宽w以米为单位）解释了超过95%的方差（对数-对数空间中为92%）。崩解率与厚度H相关，但幂律拟合 c(H) 仅解释了69%的方差（对数-对数为84%）；涉及 c(e˙) 和 c(e˙w) 的拟合残差与H没有强相关性。尽管如此，扩展应力随H增加，人们可能会预期断裂，因此崩解，取决于变形工作完成的速率，因此与 e˙H 成正比。包括 (e˙wH) 的最佳拟合幂律为 c &#x3D; 0.022(e˙wH)0.98 m&#x2F;year；图1显示了通过原点的线性拟合 c &#x3D; 0.016 e˙wH m&#x2F;year，每个解释了89%的方差（对数-对数为93%）（SOM文本）。数据不允许在这些或其他可能的关系中进行选择，但后者是物理上有动机的并且简单。c随e˙增加的一个含义是，几乎所有未受支撑的冰架都将无条件不稳定，因为厚度（因此扩展速率）在流动方向上减小，但速度增加；崩解事件将冰架前沿移入更厚、更快扩展、因此更快崩解的冰中，这些冰供应得更慢。数值实验表明适当的支撑可以稳定冰架。这与观察结果一致：从足够快的输入足够薄（因此扩展缓慢）的冰中可以形成极长的“冰舌”，冰架通常观察到在支撑点附近终止，失去支撑后冰架迅速缩小。尽管我们没有学到完整的崩解法则，但我们建议，从冰架的相互比较中得出的关系可能比以往任何时候都更令人鼓舞，因此值得进一步测试，并在冰流模型中谨慎实施。</p>\n<h3 id=\"相关研究的重要性\"><a href=\"#相关研究的重要性\" class=\"headerlink\" title=\"相关研究的重要性\"></a>相关研究的重要性</h3><ol>\n<li><strong>海平面上升</strong>：冰架崩解是全球海平面变化的关键因素，了解其机制对于预测未来海平面变化至关重要。</li>\n<li><strong>气候变化研究</strong>：冰架崩解与气候变化紧密相关，研究崩解过程有助于理解全球气候变化的影响。</li>\n<li><strong>冰盖稳定性</strong>：了解冰架崩解机制对于评估冰盖稳定性和长期存续性至关重要。</li>\n</ol>\n<h3 id=\"前人研究及不足\"><a href=\"#前人研究及不足\" class=\"headerlink\" title=\"前人研究及不足\"></a>前人研究及不足</h3><ul>\n<li>**Meier (1990)**：在《Sea-Level Change》中讨论了冰架崩解对海平面变化的影响，但未提出基于物理的崩解法则。</li>\n<li>**Dupont &amp; Alley (2005)**：研究了冰架流动与崩解的关系，但未全面解释崩解过程的物理机制。</li>\n<li><strong>不足</strong>：缺乏一个全面的、基于物理的崩解法则，无法准确预测冰架崩解对海平面变化的影响。</li>\n</ul>\n<h3 id=\"本文使用的数据和方法\"><a href=\"#本文使用的数据和方法\" class=\"headerlink\" title=\"本文使用的数据和方法\"></a>本文使用的数据和方法</h3><ul>\n<li><strong>数据</strong>：收集了不同冰架的新数据和已发表的数据（表S1），包括冰架的厚度、半宽、速度等。</li>\n<li><strong>方法</strong>：通过最佳幂律拟合和线性回归分析，研究冰架崩解通量与冰架扩展速率之间的关系。</li>\n</ul>\n<h3 id=\"本文结果\"><a href=\"#本文结果\" class=\"headerlink\" title=\"本文结果\"></a>本文结果</h3><ul>\n<li><strong>结果</strong>：发现冰架崩解通量与冰架扩展速率的0.43次幂成正比，解释了91%的方差；冰架崩解率与冰架厚度、半宽和应变率的乘积成正比，解释了89%的方差。</li>\n</ul>\n<h3 id=\"本文创新之处及贡献\"><a href=\"#本文创新之处及贡献\" class=\"headerlink\" title=\"本文创新之处及贡献\"></a>本文创新之处及贡献</h3><ol>\n<li><strong>创新</strong>：提出了一个基于物理的冰架崩解法则，即冰架崩解通量与冰架扩展速率的幂律关系。</li>\n<li><strong>贡献</strong>：为冰流模型提供了一个可能的崩解法则，有助于更准确地预测冰架崩解对海平面变化的影响。</li>\n</ol>\n<h3 id=\"本文不足\"><a href=\"#本文不足\" class=\"headerlink\" title=\"本文不足\"></a>本文不足</h3><ul>\n<li><strong>数据限制</strong>：数据集并非全面，可能影响结果的普适性。</li>\n<li><strong>模型简化</strong>：模型假设沿流冰架扩展是控制崩解的主要因素，可能忽略了其他影响因素。</li>\n</ul>"},{"title":"文献阅读(23)","abbrlink":"fe1f80b9","date":"2024-11-02T04:07:57.000Z","_content":"&emsp;&emsp;[Drivers of Recurring Seasonal Cycle of Glacier Calving Styles and Patterns](https://www.frontiersin.org/journals/earth-science/articles/10.3389/feart.2021.667717/full)\n<!--less-->\n### 摘要翻译\n\n**冰川崩解样式和模式的季节性周期的驱动因素**\n\n&emsp;&emsp;崩解是格陵兰冰盖质量损失的关键过程。此外，由于观测不足，崩解在当前冰川流动模型和预测中造成了巨大的不确定性。在这里，我们通过使用高分辨率的地面雷达干涉仪（TRI）数据、6年的连续日和小时时间序列图像以及在两次实地活动中记录的10秒时间序列图像，来研究崩解事件的频率、体积和样式。结果表明，Eqip Sermia的崩解前沿，这是一个快速流动、高度裂缝化的西格陵兰出口冰川，呈现出明显的季节性周期，并在亚冰川排放羽流、浅床地形和冰前冰混杂物的存在和退却期间显示出独特的模式。崩解事件的体积、频率和样式随季节循环的状态变化而强烈变化。在具有不同床面地形、水深和崩解前沿坡度的三个不同前沿扇区之间观察到显著的空间差异。在冰混杂物消失和峡湾表面附近的融水羽流变得可见的同时，早期融季的崩解活动显著增加。在浅水区域观察到前沿的减少后退，而在亚冰川融水羽流的位置观察到加速后退。随着这些羽流在融季初的出现，可能由于前沿的削弱而发生了更大的全厚度崩解事件。后来在融季，亚冰川融水羽流处的崩解活动与邻近区域相似，表明羽流的存在对崩解变得不那么重要。结果强调了亚冰川排放和床面地形对前沿几何形状、崩解过程的时间变化性以及崩解样式的变异性的重要性。\n\n### 第一作者介绍\n\n- **姓名**：Andrea Kneib-Walter\n- **工作单位**：苏黎世大学地理系冰川学和地貌动力学组，瑞士苏黎世；苏黎世联邦理工学院水文学、冰川学和水力学实验室，瑞士苏黎世。\n- **其他工作**：Andrea Kneib-Walter在冰川学领域有着丰富的研究经验，特别是在冰川崩解、冰川动力学和冰盖变化等方面。她的工作涉及到使用地面雷达干涉仪（TRI）和其他遥感技术来监测和分析冰川前沿的变化。\n\n### 相关研究的重要性\n\n1. **海平面上升**：冰川崩解对海平面上升有直接影响，特别是在全球变暖的背景下，这一过程加速了冰盖质量的损失。\n2. **气候变化反馈机制**：冰川崩解与气候变化之间的相互作用是理解全球气候变化反馈机制的关键。\n3. **冰川动力学模型**：准确的冰川崩解模型对于预测未来冰川变化和海平面上升至关重要。\n\n### 前人研究及不足\n\n- **Joughin et al. (2004)**：研究了格陵兰Jakobshavn Isbræ冰川的快速变化，但未能详细解释崩解过程的物理机制。\n- **Nick et al. (2009)**：发现格陵兰出口冰川的大规模变化是由冰川末端触发的，但缺乏对崩解过程的直接观测。\n- **不足**：大多数研究依赖于时间平均的崩解率，而不是观察单个崩解事件和研究崩解的时间和空间变化。\n\n### 本文使用的数据和方法\n\n- **数据**：\n  - 高分辨率地面雷达干涉仪（TRI）数据。\n  - 6年的连续日和小时时间序列图像。\n  - 两次实地活动中记录的10秒时间序列图像。\n- **方法**：\n  - 使用TRI数据通过计算得到的高程模型差异来获取崩解事件的体积目录。\n  - 连续的时间序列图像用于解释TRI派生崩解事件在季节循环中的不同模式。\n  - 10秒时间序列图像用作验证数据，并提供崩解类型的信息。\n\n### 本文结果\n\n- **结果**：\n  - Eqip Sermia冰川的崩解模式和样式因冰川前沿的不同几何形状而异，并在一年中强烈变化。\n  - 冰川前沿的时间和空间演变受床和峡湾地形以及融水羽流的出现控制。\n  - 短期气温或潮汐变化似乎对崩解活动没有直接影响。\n\n### 本文创新之处及贡献\n\n1. **创新**：结合了高分辨率TRI数据和连续时间序列图像，提供了冰川崩解事件的详细分析。\n2. **贡献**：强调了亚冰川排放和床面地形对冰川前沿几何形状、崩解过程的时间变化性以及崩解样式变异性的重要性。\n\n### 本文不足\n\n- **数据限制**：研究仅限于Eqip Sermia冰川，可能无法直接推广到其他冰川。\n- **方法限制**：TRI和其他遥感技术可能无法捕捉到所有小型崩解事件，且对天气条件有一定依赖。\n\n","source":"_posts/2024-11-02-paper-reading-23.md","raw":"---\ntitle: 文献阅读(23)\ncategories:\n  - work\ntags:\n  - paper\nabbrlink: fe1f80b9\ndate: 2024-11-02 12:07:57\n---\n&emsp;&emsp;[Drivers of Recurring Seasonal Cycle of Glacier Calving Styles and Patterns](https://www.frontiersin.org/journals/earth-science/articles/10.3389/feart.2021.667717/full)\n<!--less-->\n### 摘要翻译\n\n**冰川崩解样式和模式的季节性周期的驱动因素**\n\n&emsp;&emsp;崩解是格陵兰冰盖质量损失的关键过程。此外，由于观测不足，崩解在当前冰川流动模型和预测中造成了巨大的不确定性。在这里，我们通过使用高分辨率的地面雷达干涉仪（TRI）数据、6年的连续日和小时时间序列图像以及在两次实地活动中记录的10秒时间序列图像，来研究崩解事件的频率、体积和样式。结果表明，Eqip Sermia的崩解前沿，这是一个快速流动、高度裂缝化的西格陵兰出口冰川，呈现出明显的季节性周期，并在亚冰川排放羽流、浅床地形和冰前冰混杂物的存在和退却期间显示出独特的模式。崩解事件的体积、频率和样式随季节循环的状态变化而强烈变化。在具有不同床面地形、水深和崩解前沿坡度的三个不同前沿扇区之间观察到显著的空间差异。在冰混杂物消失和峡湾表面附近的融水羽流变得可见的同时，早期融季的崩解活动显著增加。在浅水区域观察到前沿的减少后退，而在亚冰川融水羽流的位置观察到加速后退。随着这些羽流在融季初的出现，可能由于前沿的削弱而发生了更大的全厚度崩解事件。后来在融季，亚冰川融水羽流处的崩解活动与邻近区域相似，表明羽流的存在对崩解变得不那么重要。结果强调了亚冰川排放和床面地形对前沿几何形状、崩解过程的时间变化性以及崩解样式的变异性的重要性。\n\n### 第一作者介绍\n\n- **姓名**：Andrea Kneib-Walter\n- **工作单位**：苏黎世大学地理系冰川学和地貌动力学组，瑞士苏黎世；苏黎世联邦理工学院水文学、冰川学和水力学实验室，瑞士苏黎世。\n- **其他工作**：Andrea Kneib-Walter在冰川学领域有着丰富的研究经验，特别是在冰川崩解、冰川动力学和冰盖变化等方面。她的工作涉及到使用地面雷达干涉仪（TRI）和其他遥感技术来监测和分析冰川前沿的变化。\n\n### 相关研究的重要性\n\n1. **海平面上升**：冰川崩解对海平面上升有直接影响，特别是在全球变暖的背景下，这一过程加速了冰盖质量的损失。\n2. **气候变化反馈机制**：冰川崩解与气候变化之间的相互作用是理解全球气候变化反馈机制的关键。\n3. **冰川动力学模型**：准确的冰川崩解模型对于预测未来冰川变化和海平面上升至关重要。\n\n### 前人研究及不足\n\n- **Joughin et al. (2004)**：研究了格陵兰Jakobshavn Isbræ冰川的快速变化，但未能详细解释崩解过程的物理机制。\n- **Nick et al. (2009)**：发现格陵兰出口冰川的大规模变化是由冰川末端触发的，但缺乏对崩解过程的直接观测。\n- **不足**：大多数研究依赖于时间平均的崩解率，而不是观察单个崩解事件和研究崩解的时间和空间变化。\n\n### 本文使用的数据和方法\n\n- **数据**：\n  - 高分辨率地面雷达干涉仪（TRI）数据。\n  - 6年的连续日和小时时间序列图像。\n  - 两次实地活动中记录的10秒时间序列图像。\n- **方法**：\n  - 使用TRI数据通过计算得到的高程模型差异来获取崩解事件的体积目录。\n  - 连续的时间序列图像用于解释TRI派生崩解事件在季节循环中的不同模式。\n  - 10秒时间序列图像用作验证数据，并提供崩解类型的信息。\n\n### 本文结果\n\n- **结果**：\n  - Eqip Sermia冰川的崩解模式和样式因冰川前沿的不同几何形状而异，并在一年中强烈变化。\n  - 冰川前沿的时间和空间演变受床和峡湾地形以及融水羽流的出现控制。\n  - 短期气温或潮汐变化似乎对崩解活动没有直接影响。\n\n### 本文创新之处及贡献\n\n1. **创新**：结合了高分辨率TRI数据和连续时间序列图像，提供了冰川崩解事件的详细分析。\n2. **贡献**：强调了亚冰川排放和床面地形对冰川前沿几何形状、崩解过程的时间变化性以及崩解样式变异性的重要性。\n\n### 本文不足\n\n- **数据限制**：研究仅限于Eqip Sermia冰川，可能无法直接推广到其他冰川。\n- **方法限制**：TRI和其他遥感技术可能无法捕捉到所有小型崩解事件，且对天气条件有一定依赖。\n\n","slug":"paper-reading-23","published":1,"updated":"2024-11-02T07:49:22.068Z","comments":1,"layout":"post","photos":[],"_id":"cmh498iq500b1wvou6tve0g4i","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><h3 id=\"摘要翻译\"><a href=\"#摘要翻译\" class=\"headerlink\" title=\"摘要翻译\"></a>摘要翻译</h3><p><strong>冰川崩解样式和模式的季节性周期的驱动因素</strong></p>\n<p>&emsp;&emsp;崩解是格陵兰冰盖质量损失的关键过程。此外，由于观测不足，崩解在当前冰川流动模型和预测中造成了巨大的不确定性。在这里，我们通过使用高分辨率的地面雷达干涉仪（TRI）数据、6年的连续日和小时时间序列图像以及在两次实地活动中记录的10秒时间序列图像，来研究崩解事件的频率、体积和样式。结果表明，Eqip Sermia的崩解前沿，这是一个快速流动、高度裂缝化的西格陵兰出口冰川，呈现出明显的季节性周期，并在亚冰川排放羽流、浅床地形和冰前冰混杂物的存在和退却期间显示出独特的模式。崩解事件的体积、频率和样式随季节循环的状态变化而强烈变化。在具有不同床面地形、水深和崩解前沿坡度的三个不同前沿扇区之间观察到显著的空间差异。在冰混杂物消失和峡湾表面附近的融水羽流变得可见的同时，早期融季的崩解活动显著增加。在浅水区域观察到前沿的减少后退，而在亚冰川融水羽流的位置观察到加速后退。随着这些羽流在融季初的出现，可能由于前沿的削弱而发生了更大的全厚度崩解事件。后来在融季，亚冰川融水羽流处的崩解活动与邻近区域相似，表明羽流的存在对崩解变得不那么重要。结果强调了亚冰川排放和床面地形对前沿几何形状、崩解过程的时间变化性以及崩解样式的变异性的重要性。</p>\n<h3 id=\"第一作者介绍\"><a href=\"#第一作者介绍\" class=\"headerlink\" title=\"第一作者介绍\"></a>第一作者介绍</h3><ul>\n<li><strong>姓名</strong>：Andrea Kneib-Walter</li>\n<li><strong>工作单位</strong>：苏黎世大学地理系冰川学和地貌动力学组，瑞士苏黎世；苏黎世联邦理工学院水文学、冰川学和水力学实验室，瑞士苏黎世。</li>\n<li><strong>其他工作</strong>：Andrea Kneib-Walter在冰川学领域有着丰富的研究经验，特别是在冰川崩解、冰川动力学和冰盖变化等方面。她的工作涉及到使用地面雷达干涉仪（TRI）和其他遥感技术来监测和分析冰川前沿的变化。</li>\n</ul>\n<h3 id=\"相关研究的重要性\"><a href=\"#相关研究的重要性\" class=\"headerlink\" title=\"相关研究的重要性\"></a>相关研究的重要性</h3><ol>\n<li><strong>海平面上升</strong>：冰川崩解对海平面上升有直接影响，特别是在全球变暖的背景下，这一过程加速了冰盖质量的损失。</li>\n<li><strong>气候变化反馈机制</strong>：冰川崩解与气候变化之间的相互作用是理解全球气候变化反馈机制的关键。</li>\n<li><strong>冰川动力学模型</strong>：准确的冰川崩解模型对于预测未来冰川变化和海平面上升至关重要。</li>\n</ol>\n<h3 id=\"前人研究及不足\"><a href=\"#前人研究及不足\" class=\"headerlink\" title=\"前人研究及不足\"></a>前人研究及不足</h3><ul>\n<li>**Joughin et al. (2004)**：研究了格陵兰Jakobshavn Isbræ冰川的快速变化，但未能详细解释崩解过程的物理机制。</li>\n<li>**Nick et al. (2009)**：发现格陵兰出口冰川的大规模变化是由冰川末端触发的，但缺乏对崩解过程的直接观测。</li>\n<li><strong>不足</strong>：大多数研究依赖于时间平均的崩解率，而不是观察单个崩解事件和研究崩解的时间和空间变化。</li>\n</ul>\n<h3 id=\"本文使用的数据和方法\"><a href=\"#本文使用的数据和方法\" class=\"headerlink\" title=\"本文使用的数据和方法\"></a>本文使用的数据和方法</h3><ul>\n<li><strong>数据</strong>：<ul>\n<li>高分辨率地面雷达干涉仪（TRI）数据。</li>\n<li>6年的连续日和小时时间序列图像。</li>\n<li>两次实地活动中记录的10秒时间序列图像。</li>\n</ul>\n</li>\n<li><strong>方法</strong>：<ul>\n<li>使用TRI数据通过计算得到的高程模型差异来获取崩解事件的体积目录。</li>\n<li>连续的时间序列图像用于解释TRI派生崩解事件在季节循环中的不同模式。</li>\n<li>10秒时间序列图像用作验证数据，并提供崩解类型的信息。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"本文结果\"><a href=\"#本文结果\" class=\"headerlink\" title=\"本文结果\"></a>本文结果</h3><ul>\n<li><strong>结果</strong>：<ul>\n<li>Eqip Sermia冰川的崩解模式和样式因冰川前沿的不同几何形状而异，并在一年中强烈变化。</li>\n<li>冰川前沿的时间和空间演变受床和峡湾地形以及融水羽流的出现控制。</li>\n<li>短期气温或潮汐变化似乎对崩解活动没有直接影响。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"本文创新之处及贡献\"><a href=\"#本文创新之处及贡献\" class=\"headerlink\" title=\"本文创新之处及贡献\"></a>本文创新之处及贡献</h3><ol>\n<li><strong>创新</strong>：结合了高分辨率TRI数据和连续时间序列图像，提供了冰川崩解事件的详细分析。</li>\n<li><strong>贡献</strong>：强调了亚冰川排放和床面地形对冰川前沿几何形状、崩解过程的时间变化性以及崩解样式变异性的重要性。</li>\n</ol>\n<h3 id=\"本文不足\"><a href=\"#本文不足\" class=\"headerlink\" title=\"本文不足\"></a>本文不足</h3><ul>\n<li><strong>数据限制</strong>：研究仅限于Eqip Sermia冰川，可能无法直接推广到其他冰川。</li>\n<li><strong>方法限制</strong>：TRI和其他遥感技术可能无法捕捉到所有小型崩解事件，且对天气条件有一定依赖。</li>\n</ul>","related_posts":[],"length":1587,"excerpt":"<p>&emsp;&emsp;<a href=\"https://www.frontiersin.org/journals/earth-science/articles/10.3389/feart.2021.667717/full\">Drivers of Recurring Seasonal Cycle of Glacier Calving Styles and Patterns</a></p>","more":"<h3 id=\"摘要翻译\"><a href=\"#摘要翻译\" class=\"headerlink\" title=\"摘要翻译\"></a>摘要翻译</h3><p><strong>冰川崩解样式和模式的季节性周期的驱动因素</strong></p>\n<p>&emsp;&emsp;崩解是格陵兰冰盖质量损失的关键过程。此外，由于观测不足，崩解在当前冰川流动模型和预测中造成了巨大的不确定性。在这里，我们通过使用高分辨率的地面雷达干涉仪（TRI）数据、6年的连续日和小时时间序列图像以及在两次实地活动中记录的10秒时间序列图像，来研究崩解事件的频率、体积和样式。结果表明，Eqip Sermia的崩解前沿，这是一个快速流动、高度裂缝化的西格陵兰出口冰川，呈现出明显的季节性周期，并在亚冰川排放羽流、浅床地形和冰前冰混杂物的存在和退却期间显示出独特的模式。崩解事件的体积、频率和样式随季节循环的状态变化而强烈变化。在具有不同床面地形、水深和崩解前沿坡度的三个不同前沿扇区之间观察到显著的空间差异。在冰混杂物消失和峡湾表面附近的融水羽流变得可见的同时，早期融季的崩解活动显著增加。在浅水区域观察到前沿的减少后退，而在亚冰川融水羽流的位置观察到加速后退。随着这些羽流在融季初的出现，可能由于前沿的削弱而发生了更大的全厚度崩解事件。后来在融季，亚冰川融水羽流处的崩解活动与邻近区域相似，表明羽流的存在对崩解变得不那么重要。结果强调了亚冰川排放和床面地形对前沿几何形状、崩解过程的时间变化性以及崩解样式的变异性的重要性。</p>\n<h3 id=\"第一作者介绍\"><a href=\"#第一作者介绍\" class=\"headerlink\" title=\"第一作者介绍\"></a>第一作者介绍</h3><ul>\n<li><strong>姓名</strong>：Andrea Kneib-Walter</li>\n<li><strong>工作单位</strong>：苏黎世大学地理系冰川学和地貌动力学组，瑞士苏黎世；苏黎世联邦理工学院水文学、冰川学和水力学实验室，瑞士苏黎世。</li>\n<li><strong>其他工作</strong>：Andrea Kneib-Walter在冰川学领域有着丰富的研究经验，特别是在冰川崩解、冰川动力学和冰盖变化等方面。她的工作涉及到使用地面雷达干涉仪（TRI）和其他遥感技术来监测和分析冰川前沿的变化。</li>\n</ul>\n<h3 id=\"相关研究的重要性\"><a href=\"#相关研究的重要性\" class=\"headerlink\" title=\"相关研究的重要性\"></a>相关研究的重要性</h3><ol>\n<li><strong>海平面上升</strong>：冰川崩解对海平面上升有直接影响，特别是在全球变暖的背景下，这一过程加速了冰盖质量的损失。</li>\n<li><strong>气候变化反馈机制</strong>：冰川崩解与气候变化之间的相互作用是理解全球气候变化反馈机制的关键。</li>\n<li><strong>冰川动力学模型</strong>：准确的冰川崩解模型对于预测未来冰川变化和海平面上升至关重要。</li>\n</ol>\n<h3 id=\"前人研究及不足\"><a href=\"#前人研究及不足\" class=\"headerlink\" title=\"前人研究及不足\"></a>前人研究及不足</h3><ul>\n<li>**Joughin et al. (2004)**：研究了格陵兰Jakobshavn Isbræ冰川的快速变化，但未能详细解释崩解过程的物理机制。</li>\n<li>**Nick et al. (2009)**：发现格陵兰出口冰川的大规模变化是由冰川末端触发的，但缺乏对崩解过程的直接观测。</li>\n<li><strong>不足</strong>：大多数研究依赖于时间平均的崩解率，而不是观察单个崩解事件和研究崩解的时间和空间变化。</li>\n</ul>\n<h3 id=\"本文使用的数据和方法\"><a href=\"#本文使用的数据和方法\" class=\"headerlink\" title=\"本文使用的数据和方法\"></a>本文使用的数据和方法</h3><ul>\n<li><strong>数据</strong>：<ul>\n<li>高分辨率地面雷达干涉仪（TRI）数据。</li>\n<li>6年的连续日和小时时间序列图像。</li>\n<li>两次实地活动中记录的10秒时间序列图像。</li>\n</ul>\n</li>\n<li><strong>方法</strong>：<ul>\n<li>使用TRI数据通过计算得到的高程模型差异来获取崩解事件的体积目录。</li>\n<li>连续的时间序列图像用于解释TRI派生崩解事件在季节循环中的不同模式。</li>\n<li>10秒时间序列图像用作验证数据，并提供崩解类型的信息。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"本文结果\"><a href=\"#本文结果\" class=\"headerlink\" title=\"本文结果\"></a>本文结果</h3><ul>\n<li><strong>结果</strong>：<ul>\n<li>Eqip Sermia冰川的崩解模式和样式因冰川前沿的不同几何形状而异，并在一年中强烈变化。</li>\n<li>冰川前沿的时间和空间演变受床和峡湾地形以及融水羽流的出现控制。</li>\n<li>短期气温或潮汐变化似乎对崩解活动没有直接影响。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"本文创新之处及贡献\"><a href=\"#本文创新之处及贡献\" class=\"headerlink\" title=\"本文创新之处及贡献\"></a>本文创新之处及贡献</h3><ol>\n<li><strong>创新</strong>：结合了高分辨率TRI数据和连续时间序列图像，提供了冰川崩解事件的详细分析。</li>\n<li><strong>贡献</strong>：强调了亚冰川排放和床面地形对冰川前沿几何形状、崩解过程的时间变化性以及崩解样式变异性的重要性。</li>\n</ol>\n<h3 id=\"本文不足\"><a href=\"#本文不足\" class=\"headerlink\" title=\"本文不足\"></a>本文不足</h3><ul>\n<li><strong>数据限制</strong>：研究仅限于Eqip Sermia冰川，可能无法直接推广到其他冰川。</li>\n<li><strong>方法限制</strong>：TRI和其他遥感技术可能无法捕捉到所有小型崩解事件，且对天气条件有一定依赖。</li>\n</ul>"},{"title":"文献阅读(24)","abbrlink":"a4991401","date":"2024-11-07T13:55:03.000Z","_content":"&emsp;&emsp;[Glacial seismology](https://iopscience.iop.org/article/10.1088/1361-6633/aa8473)\n<!--less-->\n### 摘要翻译\n\n地震源和波传播研究有助于理解冰川及其周围环境中的结构、传输、断裂力学、质量平衡等过程。由冰川生成的地震波与地球主体耦合良好，能够被地震仪在从局部到全球的范围内记录。尽管活跃冰川的断裂、消融、融化以及/或者高度不规则的环境可能极为不稳定和危险，但在稳定的近冰或岩石地点通常可以进行有信息量的地震测量。地震学还有助于新兴的研究领域，即大气、海洋、固体地球和冰冻圈之间的弹性波和重力波耦合。最近科学和技术的进步已经促成了冰川学和地震学之间的合作，这些合作涵盖了广泛的尺度和过程。这包括对冰冻圈系统对气候变化和其他环境条件响应的深入了解。在这里，我们回顾了相关的基础物理和冰川学知识，并提供了对冰川地震学当前状态及其快速发展的未来方向的广泛回顾。\n\n### 第一作者信息\n\n- **姓名**：Richard C. Aster\n- **工作单位**：美国科罗拉多州立大学地球科学系和华纳自然资源学院\n- **教育背景**：1991年在斯克里普斯海洋学研究所获得博士学位\n- **其他工作**：Aster教授曾在南极洲、西南极洲的多个地点、埃里伯斯火山和南极点进行过多个赛季的现场项目。\n\n### 相关研究的重要性\n\n1. **冰冻圈变化监测**：冰川地震学提供了一种监测冰冻圈变化的手段，这对于理解全球气候变化和海平面上升至关重要。\n2. **环境变化响应**：通过研究冰川地震活动，可以更好地理解冰冻圈系统对气候变化的响应。\n3. **灾害预警**：冰川地震学有助于预测冰川崩解等自然灾害，对灾害预防和减灾具有重要意义。\n\n### 相关研究的主要方向\n\n1. **冰川内部结构和动力学**：研究冰川内部结构和动力学过程，如冰川流动、断裂和变形。\n2. **冰川与地球的耦合**：研究冰川产生的地震波与地球主体的耦合机制。\n3. **冰川地震波的传播和记录**：研究冰川地震波在地球中的传播特性和记录技术。\n4. **冰川对气候变化的响应**：研究冰川如何响应气候变化和其他环境条件。\n\n### 对应主要研究内容\n\n1. **冰川地震波的产生机制**：研究冰川地震波的产生和传播，包括冰川流动、断裂和冰山崩解等过程。\n2. **冰川地震学与地球物理的交叉**：利用地震学方法研究冰川的物理特性，如冰川的密度、粘度和弹性模量。\n3. **冰川变化的长期监测**：通过地震学数据监测冰川的长期变化，包括冰川厚度、速度和表面高度的变化。\n\n### 研究趋势\n\n1. **多学科融合**：冰川地震学是一个多学科交叉领域，涉及地球物理学、冰川学、气候学等多个学科。\n2. **技术进步**：随着地震学仪器和技术的进步，对冰川的监测和研究变得更加精确和全面。\n3. **全球变化监测**：随着全球气候变化的加剧，对冰川变化的监测和研究需求日益增加。\n\n### 研究重点和难题\n\n1. **冰川内部结构的精确成像**：精确地成像冰川内部结构仍然是一个挑战，需要更先进的技术和方法。\n2. **冰川动力学的全面理解**：全面理解冰川动力学过程，包括冰川流动、断裂和变形机制。\n3. **气候变化对冰川的影响**：研究气候变化如何影响冰川的稳定性和动态，以及这些变化对海平面上升的潜在影响。\n4. **数据采集和分析**：在极端环境下进行长期、高质量的地震数据采集和分析仍然是一个挑战。\n\n","source":"_posts/2024-11-07-paper-reading-24.md","raw":"---\ntitle: 文献阅读(24)\ncategories:\n  - work\ntags:\n  - paper\nabbrlink: a4991401\ndate: 2024-11-07 21:55:03\n---\n&emsp;&emsp;[Glacial seismology](https://iopscience.iop.org/article/10.1088/1361-6633/aa8473)\n<!--less-->\n### 摘要翻译\n\n地震源和波传播研究有助于理解冰川及其周围环境中的结构、传输、断裂力学、质量平衡等过程。由冰川生成的地震波与地球主体耦合良好，能够被地震仪在从局部到全球的范围内记录。尽管活跃冰川的断裂、消融、融化以及/或者高度不规则的环境可能极为不稳定和危险，但在稳定的近冰或岩石地点通常可以进行有信息量的地震测量。地震学还有助于新兴的研究领域，即大气、海洋、固体地球和冰冻圈之间的弹性波和重力波耦合。最近科学和技术的进步已经促成了冰川学和地震学之间的合作，这些合作涵盖了广泛的尺度和过程。这包括对冰冻圈系统对气候变化和其他环境条件响应的深入了解。在这里，我们回顾了相关的基础物理和冰川学知识，并提供了对冰川地震学当前状态及其快速发展的未来方向的广泛回顾。\n\n### 第一作者信息\n\n- **姓名**：Richard C. Aster\n- **工作单位**：美国科罗拉多州立大学地球科学系和华纳自然资源学院\n- **教育背景**：1991年在斯克里普斯海洋学研究所获得博士学位\n- **其他工作**：Aster教授曾在南极洲、西南极洲的多个地点、埃里伯斯火山和南极点进行过多个赛季的现场项目。\n\n### 相关研究的重要性\n\n1. **冰冻圈变化监测**：冰川地震学提供了一种监测冰冻圈变化的手段，这对于理解全球气候变化和海平面上升至关重要。\n2. **环境变化响应**：通过研究冰川地震活动，可以更好地理解冰冻圈系统对气候变化的响应。\n3. **灾害预警**：冰川地震学有助于预测冰川崩解等自然灾害，对灾害预防和减灾具有重要意义。\n\n### 相关研究的主要方向\n\n1. **冰川内部结构和动力学**：研究冰川内部结构和动力学过程，如冰川流动、断裂和变形。\n2. **冰川与地球的耦合**：研究冰川产生的地震波与地球主体的耦合机制。\n3. **冰川地震波的传播和记录**：研究冰川地震波在地球中的传播特性和记录技术。\n4. **冰川对气候变化的响应**：研究冰川如何响应气候变化和其他环境条件。\n\n### 对应主要研究内容\n\n1. **冰川地震波的产生机制**：研究冰川地震波的产生和传播，包括冰川流动、断裂和冰山崩解等过程。\n2. **冰川地震学与地球物理的交叉**：利用地震学方法研究冰川的物理特性，如冰川的密度、粘度和弹性模量。\n3. **冰川变化的长期监测**：通过地震学数据监测冰川的长期变化，包括冰川厚度、速度和表面高度的变化。\n\n### 研究趋势\n\n1. **多学科融合**：冰川地震学是一个多学科交叉领域，涉及地球物理学、冰川学、气候学等多个学科。\n2. **技术进步**：随着地震学仪器和技术的进步，对冰川的监测和研究变得更加精确和全面。\n3. **全球变化监测**：随着全球气候变化的加剧，对冰川变化的监测和研究需求日益增加。\n\n### 研究重点和难题\n\n1. **冰川内部结构的精确成像**：精确地成像冰川内部结构仍然是一个挑战，需要更先进的技术和方法。\n2. **冰川动力学的全面理解**：全面理解冰川动力学过程，包括冰川流动、断裂和变形机制。\n3. **气候变化对冰川的影响**：研究气候变化如何影响冰川的稳定性和动态，以及这些变化对海平面上升的潜在影响。\n4. **数据采集和分析**：在极端环境下进行长期、高质量的地震数据采集和分析仍然是一个挑战。\n\n","slug":"paper-reading-24","published":1,"updated":"2025-02-10T10:41:08.832Z","comments":1,"layout":"post","photos":[],"_id":"cmh498iq600b4wvou9z4jdbjg","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><h3 id=\"摘要翻译\"><a href=\"#摘要翻译\" class=\"headerlink\" title=\"摘要翻译\"></a>摘要翻译</h3><p>地震源和波传播研究有助于理解冰川及其周围环境中的结构、传输、断裂力学、质量平衡等过程。由冰川生成的地震波与地球主体耦合良好，能够被地震仪在从局部到全球的范围内记录。尽管活跃冰川的断裂、消融、融化以及&#x2F;或者高度不规则的环境可能极为不稳定和危险，但在稳定的近冰或岩石地点通常可以进行有信息量的地震测量。地震学还有助于新兴的研究领域，即大气、海洋、固体地球和冰冻圈之间的弹性波和重力波耦合。最近科学和技术的进步已经促成了冰川学和地震学之间的合作，这些合作涵盖了广泛的尺度和过程。这包括对冰冻圈系统对气候变化和其他环境条件响应的深入了解。在这里，我们回顾了相关的基础物理和冰川学知识，并提供了对冰川地震学当前状态及其快速发展的未来方向的广泛回顾。</p>\n<h3 id=\"第一作者信息\"><a href=\"#第一作者信息\" class=\"headerlink\" title=\"第一作者信息\"></a>第一作者信息</h3><ul>\n<li><strong>姓名</strong>：Richard C. Aster</li>\n<li><strong>工作单位</strong>：美国科罗拉多州立大学地球科学系和华纳自然资源学院</li>\n<li><strong>教育背景</strong>：1991年在斯克里普斯海洋学研究所获得博士学位</li>\n<li><strong>其他工作</strong>：Aster教授曾在南极洲、西南极洲的多个地点、埃里伯斯火山和南极点进行过多个赛季的现场项目。</li>\n</ul>\n<h3 id=\"相关研究的重要性\"><a href=\"#相关研究的重要性\" class=\"headerlink\" title=\"相关研究的重要性\"></a>相关研究的重要性</h3><ol>\n<li><strong>冰冻圈变化监测</strong>：冰川地震学提供了一种监测冰冻圈变化的手段，这对于理解全球气候变化和海平面上升至关重要。</li>\n<li><strong>环境变化响应</strong>：通过研究冰川地震活动，可以更好地理解冰冻圈系统对气候变化的响应。</li>\n<li><strong>灾害预警</strong>：冰川地震学有助于预测冰川崩解等自然灾害，对灾害预防和减灾具有重要意义。</li>\n</ol>\n<h3 id=\"相关研究的主要方向\"><a href=\"#相关研究的主要方向\" class=\"headerlink\" title=\"相关研究的主要方向\"></a>相关研究的主要方向</h3><ol>\n<li><strong>冰川内部结构和动力学</strong>：研究冰川内部结构和动力学过程，如冰川流动、断裂和变形。</li>\n<li><strong>冰川与地球的耦合</strong>：研究冰川产生的地震波与地球主体的耦合机制。</li>\n<li><strong>冰川地震波的传播和记录</strong>：研究冰川地震波在地球中的传播特性和记录技术。</li>\n<li><strong>冰川对气候变化的响应</strong>：研究冰川如何响应气候变化和其他环境条件。</li>\n</ol>\n<h3 id=\"对应主要研究内容\"><a href=\"#对应主要研究内容\" class=\"headerlink\" title=\"对应主要研究内容\"></a>对应主要研究内容</h3><ol>\n<li><strong>冰川地震波的产生机制</strong>：研究冰川地震波的产生和传播，包括冰川流动、断裂和冰山崩解等过程。</li>\n<li><strong>冰川地震学与地球物理的交叉</strong>：利用地震学方法研究冰川的物理特性，如冰川的密度、粘度和弹性模量。</li>\n<li><strong>冰川变化的长期监测</strong>：通过地震学数据监测冰川的长期变化，包括冰川厚度、速度和表面高度的变化。</li>\n</ol>\n<h3 id=\"研究趋势\"><a href=\"#研究趋势\" class=\"headerlink\" title=\"研究趋势\"></a>研究趋势</h3><ol>\n<li><strong>多学科融合</strong>：冰川地震学是一个多学科交叉领域，涉及地球物理学、冰川学、气候学等多个学科。</li>\n<li><strong>技术进步</strong>：随着地震学仪器和技术的进步，对冰川的监测和研究变得更加精确和全面。</li>\n<li><strong>全球变化监测</strong>：随着全球气候变化的加剧，对冰川变化的监测和研究需求日益增加。</li>\n</ol>\n<h3 id=\"研究重点和难题\"><a href=\"#研究重点和难题\" class=\"headerlink\" title=\"研究重点和难题\"></a>研究重点和难题</h3><ol>\n<li><strong>冰川内部结构的精确成像</strong>：精确地成像冰川内部结构仍然是一个挑战，需要更先进的技术和方法。</li>\n<li><strong>冰川动力学的全面理解</strong>：全面理解冰川动力学过程，包括冰川流动、断裂和变形机制。</li>\n<li><strong>气候变化对冰川的影响</strong>：研究气候变化如何影响冰川的稳定性和动态，以及这些变化对海平面上升的潜在影响。</li>\n<li><strong>数据采集和分析</strong>：在极端环境下进行长期、高质量的地震数据采集和分析仍然是一个挑战。</li>\n</ol>","related_posts":[],"length":1209,"excerpt":"<p>&emsp;&emsp;<a href=\"https://iopscience.iop.org/article/10.1088/1361-6633/aa8473\">Glacial seismology</a></p>","more":"<h3 id=\"摘要翻译\"><a href=\"#摘要翻译\" class=\"headerlink\" title=\"摘要翻译\"></a>摘要翻译</h3><p>地震源和波传播研究有助于理解冰川及其周围环境中的结构、传输、断裂力学、质量平衡等过程。由冰川生成的地震波与地球主体耦合良好，能够被地震仪在从局部到全球的范围内记录。尽管活跃冰川的断裂、消融、融化以及&#x2F;或者高度不规则的环境可能极为不稳定和危险，但在稳定的近冰或岩石地点通常可以进行有信息量的地震测量。地震学还有助于新兴的研究领域，即大气、海洋、固体地球和冰冻圈之间的弹性波和重力波耦合。最近科学和技术的进步已经促成了冰川学和地震学之间的合作，这些合作涵盖了广泛的尺度和过程。这包括对冰冻圈系统对气候变化和其他环境条件响应的深入了解。在这里，我们回顾了相关的基础物理和冰川学知识，并提供了对冰川地震学当前状态及其快速发展的未来方向的广泛回顾。</p>\n<h3 id=\"第一作者信息\"><a href=\"#第一作者信息\" class=\"headerlink\" title=\"第一作者信息\"></a>第一作者信息</h3><ul>\n<li><strong>姓名</strong>：Richard C. Aster</li>\n<li><strong>工作单位</strong>：美国科罗拉多州立大学地球科学系和华纳自然资源学院</li>\n<li><strong>教育背景</strong>：1991年在斯克里普斯海洋学研究所获得博士学位</li>\n<li><strong>其他工作</strong>：Aster教授曾在南极洲、西南极洲的多个地点、埃里伯斯火山和南极点进行过多个赛季的现场项目。</li>\n</ul>\n<h3 id=\"相关研究的重要性\"><a href=\"#相关研究的重要性\" class=\"headerlink\" title=\"相关研究的重要性\"></a>相关研究的重要性</h3><ol>\n<li><strong>冰冻圈变化监测</strong>：冰川地震学提供了一种监测冰冻圈变化的手段，这对于理解全球气候变化和海平面上升至关重要。</li>\n<li><strong>环境变化响应</strong>：通过研究冰川地震活动，可以更好地理解冰冻圈系统对气候变化的响应。</li>\n<li><strong>灾害预警</strong>：冰川地震学有助于预测冰川崩解等自然灾害，对灾害预防和减灾具有重要意义。</li>\n</ol>\n<h3 id=\"相关研究的主要方向\"><a href=\"#相关研究的主要方向\" class=\"headerlink\" title=\"相关研究的主要方向\"></a>相关研究的主要方向</h3><ol>\n<li><strong>冰川内部结构和动力学</strong>：研究冰川内部结构和动力学过程，如冰川流动、断裂和变形。</li>\n<li><strong>冰川与地球的耦合</strong>：研究冰川产生的地震波与地球主体的耦合机制。</li>\n<li><strong>冰川地震波的传播和记录</strong>：研究冰川地震波在地球中的传播特性和记录技术。</li>\n<li><strong>冰川对气候变化的响应</strong>：研究冰川如何响应气候变化和其他环境条件。</li>\n</ol>\n<h3 id=\"对应主要研究内容\"><a href=\"#对应主要研究内容\" class=\"headerlink\" title=\"对应主要研究内容\"></a>对应主要研究内容</h3><ol>\n<li><strong>冰川地震波的产生机制</strong>：研究冰川地震波的产生和传播，包括冰川流动、断裂和冰山崩解等过程。</li>\n<li><strong>冰川地震学与地球物理的交叉</strong>：利用地震学方法研究冰川的物理特性，如冰川的密度、粘度和弹性模量。</li>\n<li><strong>冰川变化的长期监测</strong>：通过地震学数据监测冰川的长期变化，包括冰川厚度、速度和表面高度的变化。</li>\n</ol>\n<h3 id=\"研究趋势\"><a href=\"#研究趋势\" class=\"headerlink\" title=\"研究趋势\"></a>研究趋势</h3><ol>\n<li><strong>多学科融合</strong>：冰川地震学是一个多学科交叉领域，涉及地球物理学、冰川学、气候学等多个学科。</li>\n<li><strong>技术进步</strong>：随着地震学仪器和技术的进步，对冰川的监测和研究变得更加精确和全面。</li>\n<li><strong>全球变化监测</strong>：随着全球气候变化的加剧，对冰川变化的监测和研究需求日益增加。</li>\n</ol>\n<h3 id=\"研究重点和难题\"><a href=\"#研究重点和难题\" class=\"headerlink\" title=\"研究重点和难题\"></a>研究重点和难题</h3><ol>\n<li><strong>冰川内部结构的精确成像</strong>：精确地成像冰川内部结构仍然是一个挑战，需要更先进的技术和方法。</li>\n<li><strong>冰川动力学的全面理解</strong>：全面理解冰川动力学过程，包括冰川流动、断裂和变形机制。</li>\n<li><strong>气候变化对冰川的影响</strong>：研究气候变化如何影响冰川的稳定性和动态，以及这些变化对海平面上升的潜在影响。</li>\n<li><strong>数据采集和分析</strong>：在极端环境下进行长期、高质量的地震数据采集和分析仍然是一个挑战。</li>\n</ol>"},{"title":"记一次找回Linux启动项的经历","abbrlink":"24f52a76","date":"2024-12-19T09:16:35.000Z","_content":"&emsp;&emsp;记一次找回Linux启动项的经历\n<!--less-->\n&emsp;&emsp;我的笔记本是Windows10和Fedora40的双系统。平时都在Fedora下面干活，因此给windows的C盘分配了120G。然而Linux下面对于word的支持不太行，因此也需要在windows下面处理文档。谁知最近空间告急，磁盘标志频频翻红。眼看window就没办法再用了。\n\n&emsp;&emsp;于是在网上搜索怎么清理C盘，结果尝试了大量的网上和Kimi的方法，发现：C盘里除了回收站和浏览器的缓存几乎不可能再干净了。估计是之前也尝试过了。\n\n&emsp;&emsp;然后我想到好像可以压缩一下D盘，然后分一些给C。于是准备开始压缩。D盘近700G，只用了300G左右，里面除了重要数据和文件还有我当时为了减小C盘将默认安装到C盘的程序安装到D盘的文件。我打开了磁盘管理工具，尝试压缩，结果D盘只能压1.7G。震惊了。那是有多乱啊，让系统优化整理吧。一套连招下来，D盘还是只能压缩1.7G。\n\n&emsp;&emsp;Kimi也来帮忙解决问题，按照它给的方法，还是没啥用。不过Kimi会搜索啊，他建议用外部软件啊。我找到了傲梅分区助手。下载下来安装好。压缩空间、合并、清理等按钮很清晰。那就压缩、合并。\n\n&emsp;&emsp;来回捣腾，C盘成了320G，D盘500G。然后重启，欸！我的Linux呢？直接当看不见了啊。这我熟啊，以前也就重装呗。这次问问Kimi吧，kimi告诉说要这样这样。问问豆包，豆包说要这样这样。\n\n&emsp;&emsp;有点麻烦啊。不过kimi说实在不行就整第三方软件呗，推荐easyuefi。\n\n&emsp;&emsp;这个也不得了，就两个按钮。一点就出来了。把Fedora放到第一位。重启。搞定。\n\n&emsp;&emsp;AI真的好方便。以前要解决这些问题得在网上使劲搜，关键字不准还搜不出来。现在kimi啥的帮你搜索，整理，效率有三层楼那么高啊。另外现在的程序都好用到爆。按钮字大到恨不得占满屏幕，功能简单到你一点击啥都解决了。\n\n&emsp;&emsp;这些工具真的提高了完成一个工作的效率，重点还是要清楚你自己要干什么，然而在提高效率的同时也可能让人懈怠。总是依赖工具，那就麻烦了。\n\n&emsp;&emsp;咋突然让我想到了钢铁侠，脱去那个战衣，你还是啥？\n","source":"_posts/2024-12-19-find-linux-back.md","raw":"---\ntitle: 记一次找回Linux启动项的经历\ncategories:\n  - Linux\ntags:\n  - Linux\nabbrlink: 24f52a76\ndate: 2024-12-19 17:16:35\n---\n&emsp;&emsp;记一次找回Linux启动项的经历\n<!--less-->\n&emsp;&emsp;我的笔记本是Windows10和Fedora40的双系统。平时都在Fedora下面干活，因此给windows的C盘分配了120G。然而Linux下面对于word的支持不太行，因此也需要在windows下面处理文档。谁知最近空间告急，磁盘标志频频翻红。眼看window就没办法再用了。\n\n&emsp;&emsp;于是在网上搜索怎么清理C盘，结果尝试了大量的网上和Kimi的方法，发现：C盘里除了回收站和浏览器的缓存几乎不可能再干净了。估计是之前也尝试过了。\n\n&emsp;&emsp;然后我想到好像可以压缩一下D盘，然后分一些给C。于是准备开始压缩。D盘近700G，只用了300G左右，里面除了重要数据和文件还有我当时为了减小C盘将默认安装到C盘的程序安装到D盘的文件。我打开了磁盘管理工具，尝试压缩，结果D盘只能压1.7G。震惊了。那是有多乱啊，让系统优化整理吧。一套连招下来，D盘还是只能压缩1.7G。\n\n&emsp;&emsp;Kimi也来帮忙解决问题，按照它给的方法，还是没啥用。不过Kimi会搜索啊，他建议用外部软件啊。我找到了傲梅分区助手。下载下来安装好。压缩空间、合并、清理等按钮很清晰。那就压缩、合并。\n\n&emsp;&emsp;来回捣腾，C盘成了320G，D盘500G。然后重启，欸！我的Linux呢？直接当看不见了啊。这我熟啊，以前也就重装呗。这次问问Kimi吧，kimi告诉说要这样这样。问问豆包，豆包说要这样这样。\n\n&emsp;&emsp;有点麻烦啊。不过kimi说实在不行就整第三方软件呗，推荐easyuefi。\n\n&emsp;&emsp;这个也不得了，就两个按钮。一点就出来了。把Fedora放到第一位。重启。搞定。\n\n&emsp;&emsp;AI真的好方便。以前要解决这些问题得在网上使劲搜，关键字不准还搜不出来。现在kimi啥的帮你搜索，整理，效率有三层楼那么高啊。另外现在的程序都好用到爆。按钮字大到恨不得占满屏幕，功能简单到你一点击啥都解决了。\n\n&emsp;&emsp;这些工具真的提高了完成一个工作的效率，重点还是要清楚你自己要干什么，然而在提高效率的同时也可能让人懈怠。总是依赖工具，那就麻烦了。\n\n&emsp;&emsp;咋突然让我想到了钢铁侠，脱去那个战衣，你还是啥？\n","slug":"find-linux-back","published":1,"updated":"2024-12-19T11:39:05.492Z","comments":1,"layout":"post","photos":[],"_id":"cmh498iq600b7wvouewcac68n","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>&emsp;&emsp;我的笔记本是Windows10和Fedora40的双系统。平时都在Fedora下面干活，因此给windows的C盘分配了120G。然而Linux下面对于word的支持不太行，因此也需要在windows下面处理文档。谁知最近空间告急，磁盘标志频频翻红。眼看window就没办法再用了。</p>\n<p>&emsp;&emsp;于是在网上搜索怎么清理C盘，结果尝试了大量的网上和Kimi的方法，发现：C盘里除了回收站和浏览器的缓存几乎不可能再干净了。估计是之前也尝试过了。</p>\n<p>&emsp;&emsp;然后我想到好像可以压缩一下D盘，然后分一些给C。于是准备开始压缩。D盘近700G，只用了300G左右，里面除了重要数据和文件还有我当时为了减小C盘将默认安装到C盘的程序安装到D盘的文件。我打开了磁盘管理工具，尝试压缩，结果D盘只能压1.7G。震惊了。那是有多乱啊，让系统优化整理吧。一套连招下来，D盘还是只能压缩1.7G。</p>\n<p>&emsp;&emsp;Kimi也来帮忙解决问题，按照它给的方法，还是没啥用。不过Kimi会搜索啊，他建议用外部软件啊。我找到了傲梅分区助手。下载下来安装好。压缩空间、合并、清理等按钮很清晰。那就压缩、合并。</p>\n<p>&emsp;&emsp;来回捣腾，C盘成了320G，D盘500G。然后重启，欸！我的Linux呢？直接当看不见了啊。这我熟啊，以前也就重装呗。这次问问Kimi吧，kimi告诉说要这样这样。问问豆包，豆包说要这样这样。</p>\n<p>&emsp;&emsp;有点麻烦啊。不过kimi说实在不行就整第三方软件呗，推荐easyuefi。</p>\n<p>&emsp;&emsp;这个也不得了，就两个按钮。一点就出来了。把Fedora放到第一位。重启。搞定。</p>\n<p>&emsp;&emsp;AI真的好方便。以前要解决这些问题得在网上使劲搜，关键字不准还搜不出来。现在kimi啥的帮你搜索，整理，效率有三层楼那么高啊。另外现在的程序都好用到爆。按钮字大到恨不得占满屏幕，功能简单到你一点击啥都解决了。</p>\n<p>&emsp;&emsp;这些工具真的提高了完成一个工作的效率，重点还是要清楚你自己要干什么，然而在提高效率的同时也可能让人懈怠。总是依赖工具，那就麻烦了。</p>\n<p>&emsp;&emsp;咋突然让我想到了钢铁侠，脱去那个战衣，你还是啥？</p>","related_posts":[],"length":979,"excerpt":"<p>&emsp;&emsp;记一次找回Linux启动项的经历</p>","more":"<p>&emsp;&emsp;我的笔记本是Windows10和Fedora40的双系统。平时都在Fedora下面干活，因此给windows的C盘分配了120G。然而Linux下面对于word的支持不太行，因此也需要在windows下面处理文档。谁知最近空间告急，磁盘标志频频翻红。眼看window就没办法再用了。</p>\n<p>&emsp;&emsp;于是在网上搜索怎么清理C盘，结果尝试了大量的网上和Kimi的方法，发现：C盘里除了回收站和浏览器的缓存几乎不可能再干净了。估计是之前也尝试过了。</p>\n<p>&emsp;&emsp;然后我想到好像可以压缩一下D盘，然后分一些给C。于是准备开始压缩。D盘近700G，只用了300G左右，里面除了重要数据和文件还有我当时为了减小C盘将默认安装到C盘的程序安装到D盘的文件。我打开了磁盘管理工具，尝试压缩，结果D盘只能压1.7G。震惊了。那是有多乱啊，让系统优化整理吧。一套连招下来，D盘还是只能压缩1.7G。</p>\n<p>&emsp;&emsp;Kimi也来帮忙解决问题，按照它给的方法，还是没啥用。不过Kimi会搜索啊，他建议用外部软件啊。我找到了傲梅分区助手。下载下来安装好。压缩空间、合并、清理等按钮很清晰。那就压缩、合并。</p>\n<p>&emsp;&emsp;来回捣腾，C盘成了320G，D盘500G。然后重启，欸！我的Linux呢？直接当看不见了啊。这我熟啊，以前也就重装呗。这次问问Kimi吧，kimi告诉说要这样这样。问问豆包，豆包说要这样这样。</p>\n<p>&emsp;&emsp;有点麻烦啊。不过kimi说实在不行就整第三方软件呗，推荐easyuefi。</p>\n<p>&emsp;&emsp;这个也不得了，就两个按钮。一点就出来了。把Fedora放到第一位。重启。搞定。</p>\n<p>&emsp;&emsp;AI真的好方便。以前要解决这些问题得在网上使劲搜，关键字不准还搜不出来。现在kimi啥的帮你搜索，整理，效率有三层楼那么高啊。另外现在的程序都好用到爆。按钮字大到恨不得占满屏幕，功能简单到你一点击啥都解决了。</p>\n<p>&emsp;&emsp;这些工具真的提高了完成一个工作的效率，重点还是要清楚你自己要干什么，然而在提高效率的同时也可能让人懈怠。总是依赖工具，那就麻烦了。</p>\n<p>&emsp;&emsp;咋突然让我想到了钢铁侠，脱去那个战衣，你还是啥？</p>"},{"title":"如何在自己电脑中部署deepseek","abbrlink":"869ca85c","date":"2025-02-05T08:00:13.000Z","_content":"&emsp;&emsp;deepseek很火，我也来凑热闹。之前发布的一些LLM都没关注本地部署，因为似乎要钱，而deepseek是免费的（贫穷限制了我的想象）。\n<!--less-->\n# Windows下deepseek部署\n&emsp;&emsp;首先是在windows下下载[ollama](https://ollama.com/download)并安装。然后在cmd下运行:\n```bash\nollama run deepseek-r1:7b\n```\n其实安装时输入deepseek-r1默认就是7b，大小有4.7G。当然还有其他的版本，自己去搜索并根据自己的GPU大小进行安装。\n安装完之后出现了\n\n\">>>\"\n\n就可以对话了。下次要调用就在cmd中重新运行命令:\n```\nollama run deepseek-r1\n```\n\n# Linux下deepseek部署\n&emsp;&emsp;在Linux下面则这样安装ollama，命令:\n```\ncurl -fsSL https://ollama.com/install.sh | sh\n```\n这个命令是从github下载ollama进行安装。得保证你能连接到github。接下来安装deepseek:\n```\nollama run deepseek-r1:7b\n```\n\n# deepseek与zotero结合\ndeepseek可以和zotero结合进行本地的文献阅读。\n这个时候就要安装awsome GPT，位置在[zotero中文社区](https://zotero-chinese.com/plugins/)。配置可以参考[这里](https://zhuanlan.zhihu.com/p/20850142386)。我尝试了一下，没有搞定。有机会再整。\n\n\n# 图像生成大模型Janus-Pro-7B本地部署\n&emsp;&emsp;另外DeepSeek发布的多模态大模型Janus-Pro-7B支持图像生成，也可以[本地部署](https://www.upx8.com/4681)，超厉害。\n## 安装Git和conda\n## 创建环境：\n```\nconda create -n mp python=3.10 -y\nconda activate mp\n```\n## 克隆Janus\n```\ngit clone https://github.com/deepseek-ai/Janus.git\ncd Janus\n```\n## 安装依赖\n```\npip install -e .\n```\n## 安装Graio(UI)\n```\npip install gradio\npip uninstall torch torchvision torchaudio -y\npip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n```\n## 运行\n```\npython demo/app_januspro.py\n```\n调用gpu运行\n```\npython demo/app_januspro.py --device cuda\n```\n打开本地链接http://127.0.0.1:7860就可以使用。\n\n理想很丰满，现实很骨感，还是没搞定，有时间再整。\n","source":"_posts/2025-02-05-how-to-install-deepseek.md","raw":"---\ntitle: 如何在自己电脑中部署deepseek\ncategories:\n  - Linux\ntags:\n  - Linux\nabbrlink: 869ca85c\ndate: 2025-02-05 16:00:13\n---\n&emsp;&emsp;deepseek很火，我也来凑热闹。之前发布的一些LLM都没关注本地部署，因为似乎要钱，而deepseek是免费的（贫穷限制了我的想象）。\n<!--less-->\n# Windows下deepseek部署\n&emsp;&emsp;首先是在windows下下载[ollama](https://ollama.com/download)并安装。然后在cmd下运行:\n```bash\nollama run deepseek-r1:7b\n```\n其实安装时输入deepseek-r1默认就是7b，大小有4.7G。当然还有其他的版本，自己去搜索并根据自己的GPU大小进行安装。\n安装完之后出现了\n\n\">>>\"\n\n就可以对话了。下次要调用就在cmd中重新运行命令:\n```\nollama run deepseek-r1\n```\n\n# Linux下deepseek部署\n&emsp;&emsp;在Linux下面则这样安装ollama，命令:\n```\ncurl -fsSL https://ollama.com/install.sh | sh\n```\n这个命令是从github下载ollama进行安装。得保证你能连接到github。接下来安装deepseek:\n```\nollama run deepseek-r1:7b\n```\n\n# deepseek与zotero结合\ndeepseek可以和zotero结合进行本地的文献阅读。\n这个时候就要安装awsome GPT，位置在[zotero中文社区](https://zotero-chinese.com/plugins/)。配置可以参考[这里](https://zhuanlan.zhihu.com/p/20850142386)。我尝试了一下，没有搞定。有机会再整。\n\n\n# 图像生成大模型Janus-Pro-7B本地部署\n&emsp;&emsp;另外DeepSeek发布的多模态大模型Janus-Pro-7B支持图像生成，也可以[本地部署](https://www.upx8.com/4681)，超厉害。\n## 安装Git和conda\n## 创建环境：\n```\nconda create -n mp python=3.10 -y\nconda activate mp\n```\n## 克隆Janus\n```\ngit clone https://github.com/deepseek-ai/Janus.git\ncd Janus\n```\n## 安装依赖\n```\npip install -e .\n```\n## 安装Graio(UI)\n```\npip install gradio\npip uninstall torch torchvision torchaudio -y\npip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n```\n## 运行\n```\npython demo/app_januspro.py\n```\n调用gpu运行\n```\npython demo/app_januspro.py --device cuda\n```\n打开本地链接http://127.0.0.1:7860就可以使用。\n\n理想很丰满，现实很骨感，还是没搞定，有时间再整。\n","slug":"how-to-install-deepseek","published":1,"updated":"2025-02-05T08:30:08.930Z","comments":1,"layout":"post","photos":[],"_id":"cmh498iq700bbwvou4zygd0cd","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><h1 id=\"Windows下deepseek部署\"><a href=\"#Windows下deepseek部署\" class=\"headerlink\" title=\"Windows下deepseek部署\"></a>Windows下deepseek部署</h1><p>&emsp;&emsp;首先是在windows下下载<a href=\"https://ollama.com/download\">ollama</a>并安装。然后在cmd下运行:</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ollama run deepseek-r1:7b</span><br></pre></td></tr></table></figure>\n<p>其实安装时输入deepseek-r1默认就是7b，大小有4.7G。当然还有其他的版本，自己去搜索并根据自己的GPU大小进行安装。<br>安装完之后出现了</p>\n<p>“&gt;&gt;&gt;”</p>\n<p>就可以对话了。下次要调用就在cmd中重新运行命令:</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ollama run deepseek-r1</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"Linux下deepseek部署\"><a href=\"#Linux下deepseek部署\" class=\"headerlink\" title=\"Linux下deepseek部署\"></a>Linux下deepseek部署</h1><p>&emsp;&emsp;在Linux下面则这样安装ollama，命令:</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">curl -fsSL https://ollama.com/install.sh | sh</span><br></pre></td></tr></table></figure>\n<p>这个命令是从github下载ollama进行安装。得保证你能连接到github。接下来安装deepseek:</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ollama run deepseek-r1:7b</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"deepseek与zotero结合\"><a href=\"#deepseek与zotero结合\" class=\"headerlink\" title=\"deepseek与zotero结合\"></a>deepseek与zotero结合</h1><p>deepseek可以和zotero结合进行本地的文献阅读。<br>这个时候就要安装awsome GPT，位置在<a href=\"https://zotero-chinese.com/plugins/\">zotero中文社区</a>。配置可以参考<a href=\"https://zhuanlan.zhihu.com/p/20850142386\">这里</a>。我尝试了一下，没有搞定。有机会再整。</p>\n<h1 id=\"图像生成大模型Janus-Pro-7B本地部署\"><a href=\"#图像生成大模型Janus-Pro-7B本地部署\" class=\"headerlink\" title=\"图像生成大模型Janus-Pro-7B本地部署\"></a>图像生成大模型Janus-Pro-7B本地部署</h1><p>&emsp;&emsp;另外DeepSeek发布的多模态大模型Janus-Pro-7B支持图像生成，也可以<a href=\"https://www.upx8.com/4681\">本地部署</a>，超厉害。</p>\n<h2 id=\"安装Git和conda\"><a href=\"#安装Git和conda\" class=\"headerlink\" title=\"安装Git和conda\"></a>安装Git和conda</h2><h2 id=\"创建环境：\"><a href=\"#创建环境：\" class=\"headerlink\" title=\"创建环境：\"></a>创建环境：</h2><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">conda create -n mp python=3.10 -y</span><br><span class=\"line\">conda activate mp</span><br></pre></td></tr></table></figure>\n<h2 id=\"克隆Janus\"><a href=\"#克隆Janus\" class=\"headerlink\" title=\"克隆Janus\"></a>克隆Janus</h2><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git clone https://github.com/deepseek-ai/Janus.git</span><br><span class=\"line\">cd Janus</span><br></pre></td></tr></table></figure>\n<h2 id=\"安装依赖\"><a href=\"#安装依赖\" class=\"headerlink\" title=\"安装依赖\"></a>安装依赖</h2><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pip install -e .</span><br></pre></td></tr></table></figure>\n<h2 id=\"安装Graio-UI\"><a href=\"#安装Graio-UI\" class=\"headerlink\" title=\"安装Graio(UI)\"></a>安装Graio(UI)</h2><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pip install gradio</span><br><span class=\"line\">pip uninstall torch torchvision torchaudio -y</span><br><span class=\"line\">pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121</span><br></pre></td></tr></table></figure>\n<h2 id=\"运行\"><a href=\"#运行\" class=\"headerlink\" title=\"运行\"></a>运行</h2><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">python demo/app_januspro.py</span><br></pre></td></tr></table></figure>\n<p>调用gpu运行</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">python demo/app_januspro.py --device cuda</span><br></pre></td></tr></table></figure>\n<p>打开本地链接<a href=\"http://127.0.0.1:7860就可以使用。\">http://127.0.0.1:7860就可以使用。</a></p>\n<p>理想很丰满，现实很骨感，还是没搞定，有时间再整。</p>","related_posts":[],"length":1092,"excerpt":"<p>&emsp;&emsp;deepseek很火，我也来凑热闹。之前发布的一些LLM都没关注本地部署，因为似乎要钱，而deepseek是免费的（贫穷限制了我的想象）。</p>","more":"<h1 id=\"Windows下deepseek部署\"><a href=\"#Windows下deepseek部署\" class=\"headerlink\" title=\"Windows下deepseek部署\"></a>Windows下deepseek部署</h1><p>&emsp;&emsp;首先是在windows下下载<a href=\"https://ollama.com/download\">ollama</a>并安装。然后在cmd下运行:</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ollama run deepseek-r1:7b</span><br></pre></td></tr></table></figure>\n<p>其实安装时输入deepseek-r1默认就是7b，大小有4.7G。当然还有其他的版本，自己去搜索并根据自己的GPU大小进行安装。<br>安装完之后出现了</p>\n<p>“&gt;&gt;&gt;”</p>\n<p>就可以对话了。下次要调用就在cmd中重新运行命令:</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ollama run deepseek-r1</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"Linux下deepseek部署\"><a href=\"#Linux下deepseek部署\" class=\"headerlink\" title=\"Linux下deepseek部署\"></a>Linux下deepseek部署</h1><p>&emsp;&emsp;在Linux下面则这样安装ollama，命令:</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">curl -fsSL https://ollama.com/install.sh | sh</span><br></pre></td></tr></table></figure>\n<p>这个命令是从github下载ollama进行安装。得保证你能连接到github。接下来安装deepseek:</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ollama run deepseek-r1:7b</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"deepseek与zotero结合\"><a href=\"#deepseek与zotero结合\" class=\"headerlink\" title=\"deepseek与zotero结合\"></a>deepseek与zotero结合</h1><p>deepseek可以和zotero结合进行本地的文献阅读。<br>这个时候就要安装awsome GPT，位置在<a href=\"https://zotero-chinese.com/plugins/\">zotero中文社区</a>。配置可以参考<a href=\"https://zhuanlan.zhihu.com/p/20850142386\">这里</a>。我尝试了一下，没有搞定。有机会再整。</p>\n<h1 id=\"图像生成大模型Janus-Pro-7B本地部署\"><a href=\"#图像生成大模型Janus-Pro-7B本地部署\" class=\"headerlink\" title=\"图像生成大模型Janus-Pro-7B本地部署\"></a>图像生成大模型Janus-Pro-7B本地部署</h1><p>&emsp;&emsp;另外DeepSeek发布的多模态大模型Janus-Pro-7B支持图像生成，也可以<a href=\"https://www.upx8.com/4681\">本地部署</a>，超厉害。</p>\n<h2 id=\"安装Git和conda\"><a href=\"#安装Git和conda\" class=\"headerlink\" title=\"安装Git和conda\"></a>安装Git和conda</h2><h2 id=\"创建环境：\"><a href=\"#创建环境：\" class=\"headerlink\" title=\"创建环境：\"></a>创建环境：</h2><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">conda create -n mp python=3.10 -y</span><br><span class=\"line\">conda activate mp</span><br></pre></td></tr></table></figure>\n<h2 id=\"克隆Janus\"><a href=\"#克隆Janus\" class=\"headerlink\" title=\"克隆Janus\"></a>克隆Janus</h2><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git clone https://github.com/deepseek-ai/Janus.git</span><br><span class=\"line\">cd Janus</span><br></pre></td></tr></table></figure>\n<h2 id=\"安装依赖\"><a href=\"#安装依赖\" class=\"headerlink\" title=\"安装依赖\"></a>安装依赖</h2><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pip install -e .</span><br></pre></td></tr></table></figure>\n<h2 id=\"安装Graio-UI\"><a href=\"#安装Graio-UI\" class=\"headerlink\" title=\"安装Graio(UI)\"></a>安装Graio(UI)</h2><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pip install gradio</span><br><span class=\"line\">pip uninstall torch torchvision torchaudio -y</span><br><span class=\"line\">pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121</span><br></pre></td></tr></table></figure>\n<h2 id=\"运行\"><a href=\"#运行\" class=\"headerlink\" title=\"运行\"></a>运行</h2><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">python demo/app_januspro.py</span><br></pre></td></tr></table></figure>\n<p>调用gpu运行</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">python demo/app_januspro.py --device cuda</span><br></pre></td></tr></table></figure>\n<p>打开本地链接<a href=\"http://127.0.0.1:7860就可以使用。\">http://127.0.0.1:7860就可以使用。</a></p>\n<p>理想很丰满，现实很骨感，还是没搞定，有时间再整。</p>"},{"title":"文献阅读(25)","abbrlink":"177c258c","date":"2025-02-10T10:33:37.000Z","_content":"&emsp;&emsp;[Hidden cascades of seismic ice stream deformation](https://www.science.org/doi/10.1126/science.adp8094)\n<!--less-->\n### 摘要\n\n本文研究了格陵兰冰盖东北冰流（NEGIS）中的冰流变形机制。通过在东格陵兰冰芯项目（EastGRIP）的钻孔中部署分布式声学传感（DAS）技术，我们观测到了一种与常规冰流非线性粘性流变学不一致的冰变形模式：冰内地震事件级联。这些事件级联在冰芯中表现为类似地质推覆构造的结构，表明冰流内部发生了脆性变形。本文通过分析DAS数据，揭示了这些冰内地震事件的特征和成因，并探讨了其对冰流动力学的影响。\n\n### 相关研究的重要性\n- 冰流动力学：理解冰流的变形机制对于预测冰盖在气候变化中的行为至关重要，这直接影响到全球海平面上升的预测。\n- 冰盖模拟：准确的冰盖模拟需要精确的冰流流变学模型，这对于评估冰盖对气候变化的响应和未来的海平面上升具有重要意义。\n- 冰芯研究：冰芯中的微观结构和化学成分可以提供冰流历史和环境条件的线索，有助于理解冰流的物理过程。\n\n### 前人相关研究及不足\n- 冰流模拟的局限性：\n - 研究：前人研究主要依赖于Glen流变学定律来模拟冰流的粘性流动（如参考文献49）。\n - 不足：这些模型在小尺度上（如冰流的代表性体积单元，RVE）的适用性受到质疑，因为它们无法解释冰流中的脆性变形现象（如参考文献50）。\n- 冰流变形机制：\n  - 研究：前人研究通过冰芯晶体学和地质物理方法研究冰流的变形机制（如参考文献12、13）。\n  - 不足：这些研究主要集中在冰流的粘性流动，对冰流中的脆性变形机制了解有限。\n- 冰流中的地震活动：\n  - 研究：前人研究观测到冰流中的微地震活动，但主要集中在冰床和表面裂缝区域（如参考文献34、35）。\n  - 不足：这些研究未能解释冰流内部的地震活动，特别是与冰流变形机制的关系。\n\n### 本文使用的数据和方法\n- **数据：**\n  - DAS数据：本文使用了在东格陵兰冰芯项目（EastGRIP）钻孔中部署的分布式声学传感（DAS）技术获取的数据。\n  - 冰芯数据：结合了东格陵兰冰芯项目的冰芯数据，包括冰芯的微观结构和化学成分。\n- **方法：**\n  - DAS技术：通过DAS技术记录冰流中的地震活动，分析地震事件的特征和成因。\n  - 波场模拟：通过波场模拟技术，验证观测到的地震事件的成因机制。\n  - 冰流模型：结合冰流模型，探讨冰内地震活动对冰流动力学的影响。\n### 本文获得的结果\n- 冰内地震事件特征：\n - 观测到冰流内部的地震事件级联，这些事件具有明显的垂直反演对称性，且传播速度介于S波和P波之间。\n - 这些事件级联在冰芯中表现为类似地质推覆构造的结构，表明冰流内部发生了脆性变形。\n- 成因机制：\n - 通过波场模拟，推断这些地震事件是由水平断层面上的滑动引起的，且这些断层面可能由火山灰层中的杂质促进的晶界裂纹引发。\n - 这些事件级联可能与冰流中的宏观塑性变形有关，且这种变形机制在冰流中较为常见。\n- 对冰流动力学的影响：\n - 保守估计表明，这些地震事件级联可能产生与GPS测量的水平应变率相当的应变率，对冰流的宏观变形有显著贡献。\n - 这些观测结果表明，冰流的代表性体积单元（RVE）可能在千米尺度上，而不是厘米尺度。\n### 本文的创新之处和贡献\n- 创新之处：\n  - 首次使用DAS技术：首次在冰流研究中使用DAS技术，揭示了冰流内部的地震活动。\n  - 揭示脆性变形机制：首次揭示了冰流内部的脆性变形机制，与常规的粘性流变学不一致。\n- 贡献：\n  - 改进冰流模型：为改进现有的冰流模型提供了新的数据和理论依据，特别是在小尺度上的冰流变形机制。\n  - 提高海平面上升预测的准确性：通过更准确的冰流模型，提高对冰盖质量损失和海平面上升的预测准确性。\n### 本文的不足\n- 空间分布的不确定性：\n - 本文观测到的冰内地震活动的空间分布尚不明确，需要更多的观测数据来验证其在冰流中的普遍性。\n- 时间分布的不确定性：\n - 本文的观测时间较短，需要更长时间的观测数据来验证冰内地震活动的时间分布特征。\n- 模型的局限性：\n - 本文提出的冰流模型仍存在一定的局限性，需要进一步的实验和观测数据来验证和完善。\n### 总结\n- 本文通过在东格陵兰冰芯项目中部署DAS技术，揭示了冰流内部的地震活动和脆性变形机制，为改进冰流模型和提高海平面上升预测的准确性提供了新的数据和理论依据。尽管本文在空间和时间分布的观测上存在一定的局限性，但其创新性和贡献为未来的研究提供了重要的方向。\n","source":"_posts/2025-02-10-paper-reading-25.md","raw":"---\ntitle: 文献阅读(25)\ncategories:\n  - work\ntags:\n  - paper\nabbrlink: 177c258c\ndate: 2025-02-10 18:33:37\n---\n&emsp;&emsp;[Hidden cascades of seismic ice stream deformation](https://www.science.org/doi/10.1126/science.adp8094)\n<!--less-->\n### 摘要\n\n本文研究了格陵兰冰盖东北冰流（NEGIS）中的冰流变形机制。通过在东格陵兰冰芯项目（EastGRIP）的钻孔中部署分布式声学传感（DAS）技术，我们观测到了一种与常规冰流非线性粘性流变学不一致的冰变形模式：冰内地震事件级联。这些事件级联在冰芯中表现为类似地质推覆构造的结构，表明冰流内部发生了脆性变形。本文通过分析DAS数据，揭示了这些冰内地震事件的特征和成因，并探讨了其对冰流动力学的影响。\n\n### 相关研究的重要性\n- 冰流动力学：理解冰流的变形机制对于预测冰盖在气候变化中的行为至关重要，这直接影响到全球海平面上升的预测。\n- 冰盖模拟：准确的冰盖模拟需要精确的冰流流变学模型，这对于评估冰盖对气候变化的响应和未来的海平面上升具有重要意义。\n- 冰芯研究：冰芯中的微观结构和化学成分可以提供冰流历史和环境条件的线索，有助于理解冰流的物理过程。\n\n### 前人相关研究及不足\n- 冰流模拟的局限性：\n - 研究：前人研究主要依赖于Glen流变学定律来模拟冰流的粘性流动（如参考文献49）。\n - 不足：这些模型在小尺度上（如冰流的代表性体积单元，RVE）的适用性受到质疑，因为它们无法解释冰流中的脆性变形现象（如参考文献50）。\n- 冰流变形机制：\n  - 研究：前人研究通过冰芯晶体学和地质物理方法研究冰流的变形机制（如参考文献12、13）。\n  - 不足：这些研究主要集中在冰流的粘性流动，对冰流中的脆性变形机制了解有限。\n- 冰流中的地震活动：\n  - 研究：前人研究观测到冰流中的微地震活动，但主要集中在冰床和表面裂缝区域（如参考文献34、35）。\n  - 不足：这些研究未能解释冰流内部的地震活动，特别是与冰流变形机制的关系。\n\n### 本文使用的数据和方法\n- **数据：**\n  - DAS数据：本文使用了在东格陵兰冰芯项目（EastGRIP）钻孔中部署的分布式声学传感（DAS）技术获取的数据。\n  - 冰芯数据：结合了东格陵兰冰芯项目的冰芯数据，包括冰芯的微观结构和化学成分。\n- **方法：**\n  - DAS技术：通过DAS技术记录冰流中的地震活动，分析地震事件的特征和成因。\n  - 波场模拟：通过波场模拟技术，验证观测到的地震事件的成因机制。\n  - 冰流模型：结合冰流模型，探讨冰内地震活动对冰流动力学的影响。\n### 本文获得的结果\n- 冰内地震事件特征：\n - 观测到冰流内部的地震事件级联，这些事件具有明显的垂直反演对称性，且传播速度介于S波和P波之间。\n - 这些事件级联在冰芯中表现为类似地质推覆构造的结构，表明冰流内部发生了脆性变形。\n- 成因机制：\n - 通过波场模拟，推断这些地震事件是由水平断层面上的滑动引起的，且这些断层面可能由火山灰层中的杂质促进的晶界裂纹引发。\n - 这些事件级联可能与冰流中的宏观塑性变形有关，且这种变形机制在冰流中较为常见。\n- 对冰流动力学的影响：\n - 保守估计表明，这些地震事件级联可能产生与GPS测量的水平应变率相当的应变率，对冰流的宏观变形有显著贡献。\n - 这些观测结果表明，冰流的代表性体积单元（RVE）可能在千米尺度上，而不是厘米尺度。\n### 本文的创新之处和贡献\n- 创新之处：\n  - 首次使用DAS技术：首次在冰流研究中使用DAS技术，揭示了冰流内部的地震活动。\n  - 揭示脆性变形机制：首次揭示了冰流内部的脆性变形机制，与常规的粘性流变学不一致。\n- 贡献：\n  - 改进冰流模型：为改进现有的冰流模型提供了新的数据和理论依据，特别是在小尺度上的冰流变形机制。\n  - 提高海平面上升预测的准确性：通过更准确的冰流模型，提高对冰盖质量损失和海平面上升的预测准确性。\n### 本文的不足\n- 空间分布的不确定性：\n - 本文观测到的冰内地震活动的空间分布尚不明确，需要更多的观测数据来验证其在冰流中的普遍性。\n- 时间分布的不确定性：\n - 本文的观测时间较短，需要更长时间的观测数据来验证冰内地震活动的时间分布特征。\n- 模型的局限性：\n - 本文提出的冰流模型仍存在一定的局限性，需要进一步的实验和观测数据来验证和完善。\n### 总结\n- 本文通过在东格陵兰冰芯项目中部署DAS技术，揭示了冰流内部的地震活动和脆性变形机制，为改进冰流模型和提高海平面上升预测的准确性提供了新的数据和理论依据。尽管本文在空间和时间分布的观测上存在一定的局限性，但其创新性和贡献为未来的研究提供了重要的方向。\n","slug":"paper-reading-25","published":1,"updated":"2025-02-10T10:41:08.035Z","comments":1,"layout":"post","photos":[],"_id":"cmh498iq700bewvou9spi1ea3","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><h3 id=\"摘要\"><a href=\"#摘要\" class=\"headerlink\" title=\"摘要\"></a>摘要</h3><p>本文研究了格陵兰冰盖东北冰流（NEGIS）中的冰流变形机制。通过在东格陵兰冰芯项目（EastGRIP）的钻孔中部署分布式声学传感（DAS）技术，我们观测到了一种与常规冰流非线性粘性流变学不一致的冰变形模式：冰内地震事件级联。这些事件级联在冰芯中表现为类似地质推覆构造的结构，表明冰流内部发生了脆性变形。本文通过分析DAS数据，揭示了这些冰内地震事件的特征和成因，并探讨了其对冰流动力学的影响。</p>\n<h3 id=\"相关研究的重要性\"><a href=\"#相关研究的重要性\" class=\"headerlink\" title=\"相关研究的重要性\"></a>相关研究的重要性</h3><ul>\n<li>冰流动力学：理解冰流的变形机制对于预测冰盖在气候变化中的行为至关重要，这直接影响到全球海平面上升的预测。</li>\n<li>冰盖模拟：准确的冰盖模拟需要精确的冰流流变学模型，这对于评估冰盖对气候变化的响应和未来的海平面上升具有重要意义。</li>\n<li>冰芯研究：冰芯中的微观结构和化学成分可以提供冰流历史和环境条件的线索，有助于理解冰流的物理过程。</li>\n</ul>\n<h3 id=\"前人相关研究及不足\"><a href=\"#前人相关研究及不足\" class=\"headerlink\" title=\"前人相关研究及不足\"></a>前人相关研究及不足</h3><ul>\n<li>冰流模拟的局限性：</li>\n<li>研究：前人研究主要依赖于Glen流变学定律来模拟冰流的粘性流动（如参考文献49）。</li>\n<li>不足：这些模型在小尺度上（如冰流的代表性体积单元，RVE）的适用性受到质疑，因为它们无法解释冰流中的脆性变形现象（如参考文献50）。</li>\n<li>冰流变形机制：<ul>\n<li>研究：前人研究通过冰芯晶体学和地质物理方法研究冰流的变形机制（如参考文献12、13）。</li>\n<li>不足：这些研究主要集中在冰流的粘性流动，对冰流中的脆性变形机制了解有限。</li>\n</ul>\n</li>\n<li>冰流中的地震活动：<ul>\n<li>研究：前人研究观测到冰流中的微地震活动，但主要集中在冰床和表面裂缝区域（如参考文献34、35）。</li>\n<li>不足：这些研究未能解释冰流内部的地震活动，特别是与冰流变形机制的关系。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"本文使用的数据和方法\"><a href=\"#本文使用的数据和方法\" class=\"headerlink\" title=\"本文使用的数据和方法\"></a>本文使用的数据和方法</h3><ul>\n<li><strong>数据：</strong><ul>\n<li>DAS数据：本文使用了在东格陵兰冰芯项目（EastGRIP）钻孔中部署的分布式声学传感（DAS）技术获取的数据。</li>\n<li>冰芯数据：结合了东格陵兰冰芯项目的冰芯数据，包括冰芯的微观结构和化学成分。</li>\n</ul>\n</li>\n<li><strong>方法：</strong><ul>\n<li>DAS技术：通过DAS技术记录冰流中的地震活动，分析地震事件的特征和成因。</li>\n<li>波场模拟：通过波场模拟技术，验证观测到的地震事件的成因机制。</li>\n<li>冰流模型：结合冰流模型，探讨冰内地震活动对冰流动力学的影响。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"本文获得的结果\"><a href=\"#本文获得的结果\" class=\"headerlink\" title=\"本文获得的结果\"></a>本文获得的结果</h3><ul>\n<li>冰内地震事件特征：</li>\n<li>观测到冰流内部的地震事件级联，这些事件具有明显的垂直反演对称性，且传播速度介于S波和P波之间。</li>\n<li>这些事件级联在冰芯中表现为类似地质推覆构造的结构，表明冰流内部发生了脆性变形。</li>\n<li>成因机制：</li>\n<li>通过波场模拟，推断这些地震事件是由水平断层面上的滑动引起的，且这些断层面可能由火山灰层中的杂质促进的晶界裂纹引发。</li>\n<li>这些事件级联可能与冰流中的宏观塑性变形有关，且这种变形机制在冰流中较为常见。</li>\n<li>对冰流动力学的影响：</li>\n<li>保守估计表明，这些地震事件级联可能产生与GPS测量的水平应变率相当的应变率，对冰流的宏观变形有显著贡献。</li>\n<li>这些观测结果表明，冰流的代表性体积单元（RVE）可能在千米尺度上，而不是厘米尺度。</li>\n</ul>\n<h3 id=\"本文的创新之处和贡献\"><a href=\"#本文的创新之处和贡献\" class=\"headerlink\" title=\"本文的创新之处和贡献\"></a>本文的创新之处和贡献</h3><ul>\n<li>创新之处：<ul>\n<li>首次使用DAS技术：首次在冰流研究中使用DAS技术，揭示了冰流内部的地震活动。</li>\n<li>揭示脆性变形机制：首次揭示了冰流内部的脆性变形机制，与常规的粘性流变学不一致。</li>\n</ul>\n</li>\n<li>贡献：<ul>\n<li>改进冰流模型：为改进现有的冰流模型提供了新的数据和理论依据，特别是在小尺度上的冰流变形机制。</li>\n<li>提高海平面上升预测的准确性：通过更准确的冰流模型，提高对冰盖质量损失和海平面上升的预测准确性。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"本文的不足\"><a href=\"#本文的不足\" class=\"headerlink\" title=\"本文的不足\"></a>本文的不足</h3><ul>\n<li>空间分布的不确定性：</li>\n<li>本文观测到的冰内地震活动的空间分布尚不明确，需要更多的观测数据来验证其在冰流中的普遍性。</li>\n<li>时间分布的不确定性：</li>\n<li>本文的观测时间较短，需要更长时间的观测数据来验证冰内地震活动的时间分布特征。</li>\n<li>模型的局限性：</li>\n<li>本文提出的冰流模型仍存在一定的局限性，需要进一步的实验和观测数据来验证和完善。</li>\n</ul>\n<h3 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h3><ul>\n<li>本文通过在东格陵兰冰芯项目中部署DAS技术，揭示了冰流内部的地震活动和脆性变形机制，为改进冰流模型和提高海平面上升预测的准确性提供了新的数据和理论依据。尽管本文在空间和时间分布的观测上存在一定的局限性，但其创新性和贡献为未来的研究提供了重要的方向。</li>\n</ul>","related_posts":[],"length":1699,"excerpt":"<p>&emsp;&emsp;<a href=\"https://www.science.org/doi/10.1126/science.adp8094\">Hidden cascades of seismic ice stream deformation</a></p>","more":"<h3 id=\"摘要\"><a href=\"#摘要\" class=\"headerlink\" title=\"摘要\"></a>摘要</h3><p>本文研究了格陵兰冰盖东北冰流（NEGIS）中的冰流变形机制。通过在东格陵兰冰芯项目（EastGRIP）的钻孔中部署分布式声学传感（DAS）技术，我们观测到了一种与常规冰流非线性粘性流变学不一致的冰变形模式：冰内地震事件级联。这些事件级联在冰芯中表现为类似地质推覆构造的结构，表明冰流内部发生了脆性变形。本文通过分析DAS数据，揭示了这些冰内地震事件的特征和成因，并探讨了其对冰流动力学的影响。</p>\n<h3 id=\"相关研究的重要性\"><a href=\"#相关研究的重要性\" class=\"headerlink\" title=\"相关研究的重要性\"></a>相关研究的重要性</h3><ul>\n<li>冰流动力学：理解冰流的变形机制对于预测冰盖在气候变化中的行为至关重要，这直接影响到全球海平面上升的预测。</li>\n<li>冰盖模拟：准确的冰盖模拟需要精确的冰流流变学模型，这对于评估冰盖对气候变化的响应和未来的海平面上升具有重要意义。</li>\n<li>冰芯研究：冰芯中的微观结构和化学成分可以提供冰流历史和环境条件的线索，有助于理解冰流的物理过程。</li>\n</ul>\n<h3 id=\"前人相关研究及不足\"><a href=\"#前人相关研究及不足\" class=\"headerlink\" title=\"前人相关研究及不足\"></a>前人相关研究及不足</h3><ul>\n<li>冰流模拟的局限性：</li>\n<li>研究：前人研究主要依赖于Glen流变学定律来模拟冰流的粘性流动（如参考文献49）。</li>\n<li>不足：这些模型在小尺度上（如冰流的代表性体积单元，RVE）的适用性受到质疑，因为它们无法解释冰流中的脆性变形现象（如参考文献50）。</li>\n<li>冰流变形机制：<ul>\n<li>研究：前人研究通过冰芯晶体学和地质物理方法研究冰流的变形机制（如参考文献12、13）。</li>\n<li>不足：这些研究主要集中在冰流的粘性流动，对冰流中的脆性变形机制了解有限。</li>\n</ul>\n</li>\n<li>冰流中的地震活动：<ul>\n<li>研究：前人研究观测到冰流中的微地震活动，但主要集中在冰床和表面裂缝区域（如参考文献34、35）。</li>\n<li>不足：这些研究未能解释冰流内部的地震活动，特别是与冰流变形机制的关系。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"本文使用的数据和方法\"><a href=\"#本文使用的数据和方法\" class=\"headerlink\" title=\"本文使用的数据和方法\"></a>本文使用的数据和方法</h3><ul>\n<li><strong>数据：</strong><ul>\n<li>DAS数据：本文使用了在东格陵兰冰芯项目（EastGRIP）钻孔中部署的分布式声学传感（DAS）技术获取的数据。</li>\n<li>冰芯数据：结合了东格陵兰冰芯项目的冰芯数据，包括冰芯的微观结构和化学成分。</li>\n</ul>\n</li>\n<li><strong>方法：</strong><ul>\n<li>DAS技术：通过DAS技术记录冰流中的地震活动，分析地震事件的特征和成因。</li>\n<li>波场模拟：通过波场模拟技术，验证观测到的地震事件的成因机制。</li>\n<li>冰流模型：结合冰流模型，探讨冰内地震活动对冰流动力学的影响。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"本文获得的结果\"><a href=\"#本文获得的结果\" class=\"headerlink\" title=\"本文获得的结果\"></a>本文获得的结果</h3><ul>\n<li>冰内地震事件特征：</li>\n<li>观测到冰流内部的地震事件级联，这些事件具有明显的垂直反演对称性，且传播速度介于S波和P波之间。</li>\n<li>这些事件级联在冰芯中表现为类似地质推覆构造的结构，表明冰流内部发生了脆性变形。</li>\n<li>成因机制：</li>\n<li>通过波场模拟，推断这些地震事件是由水平断层面上的滑动引起的，且这些断层面可能由火山灰层中的杂质促进的晶界裂纹引发。</li>\n<li>这些事件级联可能与冰流中的宏观塑性变形有关，且这种变形机制在冰流中较为常见。</li>\n<li>对冰流动力学的影响：</li>\n<li>保守估计表明，这些地震事件级联可能产生与GPS测量的水平应变率相当的应变率，对冰流的宏观变形有显著贡献。</li>\n<li>这些观测结果表明，冰流的代表性体积单元（RVE）可能在千米尺度上，而不是厘米尺度。</li>\n</ul>\n<h3 id=\"本文的创新之处和贡献\"><a href=\"#本文的创新之处和贡献\" class=\"headerlink\" title=\"本文的创新之处和贡献\"></a>本文的创新之处和贡献</h3><ul>\n<li>创新之处：<ul>\n<li>首次使用DAS技术：首次在冰流研究中使用DAS技术，揭示了冰流内部的地震活动。</li>\n<li>揭示脆性变形机制：首次揭示了冰流内部的脆性变形机制，与常规的粘性流变学不一致。</li>\n</ul>\n</li>\n<li>贡献：<ul>\n<li>改进冰流模型：为改进现有的冰流模型提供了新的数据和理论依据，特别是在小尺度上的冰流变形机制。</li>\n<li>提高海平面上升预测的准确性：通过更准确的冰流模型，提高对冰盖质量损失和海平面上升的预测准确性。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"本文的不足\"><a href=\"#本文的不足\" class=\"headerlink\" title=\"本文的不足\"></a>本文的不足</h3><ul>\n<li>空间分布的不确定性：</li>\n<li>本文观测到的冰内地震活动的空间分布尚不明确，需要更多的观测数据来验证其在冰流中的普遍性。</li>\n<li>时间分布的不确定性：</li>\n<li>本文的观测时间较短，需要更长时间的观测数据来验证冰内地震活动的时间分布特征。</li>\n<li>模型的局限性：</li>\n<li>本文提出的冰流模型仍存在一定的局限性，需要进一步的实验和观测数据来验证和完善。</li>\n</ul>\n<h3 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h3><ul>\n<li>本文通过在东格陵兰冰芯项目中部署DAS技术，揭示了冰流内部的地震活动和脆性变形机制，为改进冰流模型和提高海平面上升预测的准确性提供了新的数据和理论依据。尽管本文在空间和时间分布的观测上存在一定的局限性，但其创新性和贡献为未来的研究提供了重要的方向。</li>\n</ul>"},{"title":"文献阅读(26)","abbrlink":"96af7683","date":"2025-02-14T06:48:50.000Z","_content":"&emsp;&emsp;[Depth-dependent seismic sensing of groundwater recovery from the atmospheric-river storms of 2023](https://www.science.org/doi/10.1126/science.adr6139)\n<!--less-->\n### 摘要\n\n2023年初，一系列强烈的气河风暴缓解了加利福尼亚州的历史性干旱，但地下水恢复的空间和时间范围仍然知之甚少。我们利用地震背景噪声干涉测量技术追踪了大洛杉矶地区二十年地下水的变化。得到的地震水文图揭示了地下水和地表水干旱的不同表现：尽管2023年湿润季节地表和近地表水储量几乎完全恢复，但自2006年以来失去的地下水只有大约25%得到恢复。从十年尺度来看，我们发现在50米深度以下的含水层中有大量枯竭，仅有限的风暴相关恢复。我们的分析强调了使用高分辨率工具（如地震感应）监测深含水层的必要性，以更全面地评估总水资源短缺情况。\n\n### 相关研究的重要性\n- 理解地下水恢复情况：\n研究有助于了解在极端天气事件后地下水恢复的空间和时间范围。\n提供了对自然补给机制在补充地下水储量方面的有效性的见解。\n- 水资源管理：\n研究结果对于应对极端天气事件和长期干旱的水资源管理策略至关重要。\n强调了监测深含水层以全面评估总水资源短缺的必要性。\n- 气候适应性：\n研究结果为气候适应性策略提供了信息，识别了表层水库的局限性和地下水水库的重要性。\n支持发展增强地下水储存和管理的政策。\n\n### 前人相关研究及不足\n- 地下水监测：\n - 传统方法如井数据昂贵且空间分布稀疏，无法捕捉含水层的异质性。\n - 例子：点尺度井数据不足以进行流域尺度分析。\n- 遥感技术：\n - 卫星遥感和航空调查提供了有价值的数据，但可能缺乏必要的时空分辨率。\n - 例子：GRACE和GRACE-FO任务提供的空间分辨率较低，时间分辨率为每月一次。\n- 水文模型：\n - 模型通常依赖于假设和简化，可能无法准确反映实际情况。\n - 例子：简化的水量平衡模型可能无法考虑复杂的水文地质结构。\n\n### 本文使用的数据和方法\n- 数据：\n - 地震数据：由南加州地震网络的68个站点记录。\n - 重力数据：来自GRACE和GRACE-FO任务。\n - 水文数据：包括降水、地下水井数据、GPS测量、水文模拟等。\n- 方法：\n - 地震干涉测量：使用先进技术测量地震速度的微小变化。\n - 地震水文图：推导出以追踪深度处水储量的变化。\n - 垂直地震水文图（VSHs）：用于理解含水层动态的垂直变化。\n\n### 研究结果\n- 地下水恢复：\n - 2023年地表和近地表水储量几乎完全恢复。\n - 自2006年以来失去的地下水只有大约25%得到恢复。\n - 50米深度以下的含水层中有大量枯竭，仅有限的风暴相关恢复。\n- 深度分布：\n - 地下水损失范围广泛，最大达到约500米深度处的季节性变化的450%以上。\n - 2023年恢复量约为季节性变化的120%。\n- 空间变化：\n - 在圣加布里埃尔盆地西部和惠提尔狭隘附近，浅层到中层含水层的地下水补给显著。\n\n### 创新点、贡献和不足\n- 创新点：\n - 高分辨率地震感应：提供了详细的地下水动态深度剖面。\n - 深度依赖的地震干旱指数（Seismic-DI）：一种新的工具，用于量化地下水干旱状况。\n- 贡献：\n - 提供了对极端天气事件后地下水恢复情况的全面评估。\n - 强调了监测深含水层以全面了解水资源短缺的必要性。\n - 提供了一种新的工具（Seismic-DI），用于高时空分辨率的地下水干旱监测。\n- 不足：\n - 研究主要集中在大洛杉矶地区，其发现可能不适用于其他地区。\n - 地震数据可能无法捕捉高度异质性含水层中地下水动态的所有复杂性。\n - 需要在不同的水文地质设置中进一步验证和校准Seismic-DI。\n","source":"_posts/2025-02-14-paper-reading-26.md","raw":"---\ntitle: 文献阅读(26)\ncategories:\n  - work\ntags:\n  - paper\nabbrlink: 96af7683\ndate: 2025-02-14 14:48:50\n---\n&emsp;&emsp;[Depth-dependent seismic sensing of groundwater recovery from the atmospheric-river storms of 2023](https://www.science.org/doi/10.1126/science.adr6139)\n<!--less-->\n### 摘要\n\n2023年初，一系列强烈的气河风暴缓解了加利福尼亚州的历史性干旱，但地下水恢复的空间和时间范围仍然知之甚少。我们利用地震背景噪声干涉测量技术追踪了大洛杉矶地区二十年地下水的变化。得到的地震水文图揭示了地下水和地表水干旱的不同表现：尽管2023年湿润季节地表和近地表水储量几乎完全恢复，但自2006年以来失去的地下水只有大约25%得到恢复。从十年尺度来看，我们发现在50米深度以下的含水层中有大量枯竭，仅有限的风暴相关恢复。我们的分析强调了使用高分辨率工具（如地震感应）监测深含水层的必要性，以更全面地评估总水资源短缺情况。\n\n### 相关研究的重要性\n- 理解地下水恢复情况：\n研究有助于了解在极端天气事件后地下水恢复的空间和时间范围。\n提供了对自然补给机制在补充地下水储量方面的有效性的见解。\n- 水资源管理：\n研究结果对于应对极端天气事件和长期干旱的水资源管理策略至关重要。\n强调了监测深含水层以全面评估总水资源短缺的必要性。\n- 气候适应性：\n研究结果为气候适应性策略提供了信息，识别了表层水库的局限性和地下水水库的重要性。\n支持发展增强地下水储存和管理的政策。\n\n### 前人相关研究及不足\n- 地下水监测：\n - 传统方法如井数据昂贵且空间分布稀疏，无法捕捉含水层的异质性。\n - 例子：点尺度井数据不足以进行流域尺度分析。\n- 遥感技术：\n - 卫星遥感和航空调查提供了有价值的数据，但可能缺乏必要的时空分辨率。\n - 例子：GRACE和GRACE-FO任务提供的空间分辨率较低，时间分辨率为每月一次。\n- 水文模型：\n - 模型通常依赖于假设和简化，可能无法准确反映实际情况。\n - 例子：简化的水量平衡模型可能无法考虑复杂的水文地质结构。\n\n### 本文使用的数据和方法\n- 数据：\n - 地震数据：由南加州地震网络的68个站点记录。\n - 重力数据：来自GRACE和GRACE-FO任务。\n - 水文数据：包括降水、地下水井数据、GPS测量、水文模拟等。\n- 方法：\n - 地震干涉测量：使用先进技术测量地震速度的微小变化。\n - 地震水文图：推导出以追踪深度处水储量的变化。\n - 垂直地震水文图（VSHs）：用于理解含水层动态的垂直变化。\n\n### 研究结果\n- 地下水恢复：\n - 2023年地表和近地表水储量几乎完全恢复。\n - 自2006年以来失去的地下水只有大约25%得到恢复。\n - 50米深度以下的含水层中有大量枯竭，仅有限的风暴相关恢复。\n- 深度分布：\n - 地下水损失范围广泛，最大达到约500米深度处的季节性变化的450%以上。\n - 2023年恢复量约为季节性变化的120%。\n- 空间变化：\n - 在圣加布里埃尔盆地西部和惠提尔狭隘附近，浅层到中层含水层的地下水补给显著。\n\n### 创新点、贡献和不足\n- 创新点：\n - 高分辨率地震感应：提供了详细的地下水动态深度剖面。\n - 深度依赖的地震干旱指数（Seismic-DI）：一种新的工具，用于量化地下水干旱状况。\n- 贡献：\n - 提供了对极端天气事件后地下水恢复情况的全面评估。\n - 强调了监测深含水层以全面了解水资源短缺的必要性。\n - 提供了一种新的工具（Seismic-DI），用于高时空分辨率的地下水干旱监测。\n- 不足：\n - 研究主要集中在大洛杉矶地区，其发现可能不适用于其他地区。\n - 地震数据可能无法捕捉高度异质性含水层中地下水动态的所有复杂性。\n - 需要在不同的水文地质设置中进一步验证和校准Seismic-DI。\n","slug":"paper-reading-26","published":1,"updated":"2025-02-14T06:59:08.702Z","comments":1,"layout":"post","photos":[],"_id":"cmh498iq700biwvouhug50cg3","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><h3 id=\"摘要\"><a href=\"#摘要\" class=\"headerlink\" title=\"摘要\"></a>摘要</h3><p>2023年初，一系列强烈的气河风暴缓解了加利福尼亚州的历史性干旱，但地下水恢复的空间和时间范围仍然知之甚少。我们利用地震背景噪声干涉测量技术追踪了大洛杉矶地区二十年地下水的变化。得到的地震水文图揭示了地下水和地表水干旱的不同表现：尽管2023年湿润季节地表和近地表水储量几乎完全恢复，但自2006年以来失去的地下水只有大约25%得到恢复。从十年尺度来看，我们发现在50米深度以下的含水层中有大量枯竭，仅有限的风暴相关恢复。我们的分析强调了使用高分辨率工具（如地震感应）监测深含水层的必要性，以更全面地评估总水资源短缺情况。</p>\n<h3 id=\"相关研究的重要性\"><a href=\"#相关研究的重要性\" class=\"headerlink\" title=\"相关研究的重要性\"></a>相关研究的重要性</h3><ul>\n<li>理解地下水恢复情况：<br>研究有助于了解在极端天气事件后地下水恢复的空间和时间范围。<br>提供了对自然补给机制在补充地下水储量方面的有效性的见解。</li>\n<li>水资源管理：<br>研究结果对于应对极端天气事件和长期干旱的水资源管理策略至关重要。<br>强调了监测深含水层以全面评估总水资源短缺的必要性。</li>\n<li>气候适应性：<br>研究结果为气候适应性策略提供了信息，识别了表层水库的局限性和地下水水库的重要性。<br>支持发展增强地下水储存和管理的政策。</li>\n</ul>\n<h3 id=\"前人相关研究及不足\"><a href=\"#前人相关研究及不足\" class=\"headerlink\" title=\"前人相关研究及不足\"></a>前人相关研究及不足</h3><ul>\n<li>地下水监测：</li>\n<li>传统方法如井数据昂贵且空间分布稀疏，无法捕捉含水层的异质性。</li>\n<li>例子：点尺度井数据不足以进行流域尺度分析。</li>\n<li>遥感技术：</li>\n<li>卫星遥感和航空调查提供了有价值的数据，但可能缺乏必要的时空分辨率。</li>\n<li>例子：GRACE和GRACE-FO任务提供的空间分辨率较低，时间分辨率为每月一次。</li>\n<li>水文模型：</li>\n<li>模型通常依赖于假设和简化，可能无法准确反映实际情况。</li>\n<li>例子：简化的水量平衡模型可能无法考虑复杂的水文地质结构。</li>\n</ul>\n<h3 id=\"本文使用的数据和方法\"><a href=\"#本文使用的数据和方法\" class=\"headerlink\" title=\"本文使用的数据和方法\"></a>本文使用的数据和方法</h3><ul>\n<li>数据：</li>\n<li>地震数据：由南加州地震网络的68个站点记录。</li>\n<li>重力数据：来自GRACE和GRACE-FO任务。</li>\n<li>水文数据：包括降水、地下水井数据、GPS测量、水文模拟等。</li>\n<li>方法：</li>\n<li>地震干涉测量：使用先进技术测量地震速度的微小变化。</li>\n<li>地震水文图：推导出以追踪深度处水储量的变化。</li>\n<li>垂直地震水文图（VSHs）：用于理解含水层动态的垂直变化。</li>\n</ul>\n<h3 id=\"研究结果\"><a href=\"#研究结果\" class=\"headerlink\" title=\"研究结果\"></a>研究结果</h3><ul>\n<li>地下水恢复：</li>\n<li>2023年地表和近地表水储量几乎完全恢复。</li>\n<li>自2006年以来失去的地下水只有大约25%得到恢复。</li>\n<li>50米深度以下的含水层中有大量枯竭，仅有限的风暴相关恢复。</li>\n<li>深度分布：</li>\n<li>地下水损失范围广泛，最大达到约500米深度处的季节性变化的450%以上。</li>\n<li>2023年恢复量约为季节性变化的120%。</li>\n<li>空间变化：</li>\n<li>在圣加布里埃尔盆地西部和惠提尔狭隘附近，浅层到中层含水层的地下水补给显著。</li>\n</ul>\n<h3 id=\"创新点、贡献和不足\"><a href=\"#创新点、贡献和不足\" class=\"headerlink\" title=\"创新点、贡献和不足\"></a>创新点、贡献和不足</h3><ul>\n<li>创新点：</li>\n<li>高分辨率地震感应：提供了详细的地下水动态深度剖面。</li>\n<li>深度依赖的地震干旱指数（Seismic-DI）：一种新的工具，用于量化地下水干旱状况。</li>\n<li>贡献：</li>\n<li>提供了对极端天气事件后地下水恢复情况的全面评估。</li>\n<li>强调了监测深含水层以全面了解水资源短缺的必要性。</li>\n<li>提供了一种新的工具（Seismic-DI），用于高时空分辨率的地下水干旱监测。</li>\n<li>不足：</li>\n<li>研究主要集中在大洛杉矶地区，其发现可能不适用于其他地区。</li>\n<li>地震数据可能无法捕捉高度异质性含水层中地下水动态的所有复杂性。</li>\n<li>需要在不同的水文地质设置中进一步验证和校准Seismic-DI。</li>\n</ul>","related_posts":["code-and-project2.html","paper-reading-7.html"],"length":1389,"excerpt":"<p>&emsp;&emsp;<a href=\"https://www.science.org/doi/10.1126/science.adr6139\">Depth-dependent seismic sensing of groundwater recovery from the atmospheric-river storms of 2023</a></p>","more":"<h3 id=\"摘要\"><a href=\"#摘要\" class=\"headerlink\" title=\"摘要\"></a>摘要</h3><p>2023年初，一系列强烈的气河风暴缓解了加利福尼亚州的历史性干旱，但地下水恢复的空间和时间范围仍然知之甚少。我们利用地震背景噪声干涉测量技术追踪了大洛杉矶地区二十年地下水的变化。得到的地震水文图揭示了地下水和地表水干旱的不同表现：尽管2023年湿润季节地表和近地表水储量几乎完全恢复，但自2006年以来失去的地下水只有大约25%得到恢复。从十年尺度来看，我们发现在50米深度以下的含水层中有大量枯竭，仅有限的风暴相关恢复。我们的分析强调了使用高分辨率工具（如地震感应）监测深含水层的必要性，以更全面地评估总水资源短缺情况。</p>\n<h3 id=\"相关研究的重要性\"><a href=\"#相关研究的重要性\" class=\"headerlink\" title=\"相关研究的重要性\"></a>相关研究的重要性</h3><ul>\n<li>理解地下水恢复情况：<br>研究有助于了解在极端天气事件后地下水恢复的空间和时间范围。<br>提供了对自然补给机制在补充地下水储量方面的有效性的见解。</li>\n<li>水资源管理：<br>研究结果对于应对极端天气事件和长期干旱的水资源管理策略至关重要。<br>强调了监测深含水层以全面评估总水资源短缺的必要性。</li>\n<li>气候适应性：<br>研究结果为气候适应性策略提供了信息，识别了表层水库的局限性和地下水水库的重要性。<br>支持发展增强地下水储存和管理的政策。</li>\n</ul>\n<h3 id=\"前人相关研究及不足\"><a href=\"#前人相关研究及不足\" class=\"headerlink\" title=\"前人相关研究及不足\"></a>前人相关研究及不足</h3><ul>\n<li>地下水监测：</li>\n<li>传统方法如井数据昂贵且空间分布稀疏，无法捕捉含水层的异质性。</li>\n<li>例子：点尺度井数据不足以进行流域尺度分析。</li>\n<li>遥感技术：</li>\n<li>卫星遥感和航空调查提供了有价值的数据，但可能缺乏必要的时空分辨率。</li>\n<li>例子：GRACE和GRACE-FO任务提供的空间分辨率较低，时间分辨率为每月一次。</li>\n<li>水文模型：</li>\n<li>模型通常依赖于假设和简化，可能无法准确反映实际情况。</li>\n<li>例子：简化的水量平衡模型可能无法考虑复杂的水文地质结构。</li>\n</ul>\n<h3 id=\"本文使用的数据和方法\"><a href=\"#本文使用的数据和方法\" class=\"headerlink\" title=\"本文使用的数据和方法\"></a>本文使用的数据和方法</h3><ul>\n<li>数据：</li>\n<li>地震数据：由南加州地震网络的68个站点记录。</li>\n<li>重力数据：来自GRACE和GRACE-FO任务。</li>\n<li>水文数据：包括降水、地下水井数据、GPS测量、水文模拟等。</li>\n<li>方法：</li>\n<li>地震干涉测量：使用先进技术测量地震速度的微小变化。</li>\n<li>地震水文图：推导出以追踪深度处水储量的变化。</li>\n<li>垂直地震水文图（VSHs）：用于理解含水层动态的垂直变化。</li>\n</ul>\n<h3 id=\"研究结果\"><a href=\"#研究结果\" class=\"headerlink\" title=\"研究结果\"></a>研究结果</h3><ul>\n<li>地下水恢复：</li>\n<li>2023年地表和近地表水储量几乎完全恢复。</li>\n<li>自2006年以来失去的地下水只有大约25%得到恢复。</li>\n<li>50米深度以下的含水层中有大量枯竭，仅有限的风暴相关恢复。</li>\n<li>深度分布：</li>\n<li>地下水损失范围广泛，最大达到约500米深度处的季节性变化的450%以上。</li>\n<li>2023年恢复量约为季节性变化的120%。</li>\n<li>空间变化：</li>\n<li>在圣加布里埃尔盆地西部和惠提尔狭隘附近，浅层到中层含水层的地下水补给显著。</li>\n</ul>\n<h3 id=\"创新点、贡献和不足\"><a href=\"#创新点、贡献和不足\" class=\"headerlink\" title=\"创新点、贡献和不足\"></a>创新点、贡献和不足</h3><ul>\n<li>创新点：</li>\n<li>高分辨率地震感应：提供了详细的地下水动态深度剖面。</li>\n<li>深度依赖的地震干旱指数（Seismic-DI）：一种新的工具，用于量化地下水干旱状况。</li>\n<li>贡献：</li>\n<li>提供了对极端天气事件后地下水恢复情况的全面评估。</li>\n<li>强调了监测深含水层以全面了解水资源短缺的必要性。</li>\n<li>提供了一种新的工具（Seismic-DI），用于高时空分辨率的地下水干旱监测。</li>\n<li>不足：</li>\n<li>研究主要集中在大洛杉矶地区，其发现可能不适用于其他地区。</li>\n<li>地震数据可能无法捕捉高度异质性含水层中地下水动态的所有复杂性。</li>\n<li>需要在不同的水文地质设置中进一步验证和校准Seismic-DI。</li>\n</ul>"},{"title":"有趣的程序和项目（二）","abbrlink":"268ecf29","date":"2025-04-17T07:55:44.000Z","_content":"1. [Fast analysis of the seismic rupture](https://ssa2py.readthedocs.io/en/stable/basic_info.html) SSA2py is an emergent python based software that allows fast analysis of the seismic rupture, making possible the near-realtime identification of the rupture characteristics after a significant seismic event. \n2. [Fast matching filter](https://github.com/beridel/fast_matched_filter) Seismic matched-filter search for both CPU and GPU architectures.\n3. [MUSIC Teleseismic Back-Projection](https://github.com/lsmeng/MUSICBP) Perform the Back-Projection Imaging on the seismograms of large earthquakes recorded by large-scale dense arrays.\n4. [Seismic_BPMF](https://ebeauce.github.io/Seismic_BPMF/index.html) Fully automated workflow for earthquake detection and location with the backprojection and matched filtering methods.\n5. [ARRU_seismic_backprojection](https://github.com/tso1257771/Attention-Recurrent-Residual-U-Net-for-earthquake-detection) ARRU Phase Picker: Attention Recurrent‐Residual U‐Net for Picking Seismic P‐ and S‐Phase Arrivals.\n6. [earthquake_back_projection](https://github.com/ajay6763/earthquake_back_projection) Back-projection of high-frequency radiation from earthquake source using multiple arrays. Methodology is based on Ishii (2012). \n7. [earthquake_detection](https://github.com/ebeauce/earthquake_detection_EB_et_al_2019) Codes used in the earthquake detection and location method presented in Beauce et al. 2019, DOI: 10.1029/2019JB018110. A real data example is also provided.\n8. [beampower](https://ebeauce.github.io/beampower/introduction.html) Fast routines for seismic backprojection/beamforming for both CPU and GPU architectures.\n9. [Iterative Linear Stress Inversion (ILSI)](https://ebeauce.github.io/ILSI/) Python package for stress tensor inversion. \n10. [Pyrocko](https://git.pyrocko.org/pyrocko/pyrocko/) A Python framework for efficient use of pre-computed Green's functions in seismological and other physical forward and inverse source problems.\n\n\n","source":"_posts/2025-04-17-code-and-project2.md","raw":"---\ntitle: 有趣的程序和项目（二）\ntags:\n  - code\n  - project\ncategories:\n  - work\nabbrlink: 268ecf29\ndate: 2025-04-17 15:55:44\n---\n1. [Fast analysis of the seismic rupture](https://ssa2py.readthedocs.io/en/stable/basic_info.html) SSA2py is an emergent python based software that allows fast analysis of the seismic rupture, making possible the near-realtime identification of the rupture characteristics after a significant seismic event. \n2. [Fast matching filter](https://github.com/beridel/fast_matched_filter) Seismic matched-filter search for both CPU and GPU architectures.\n3. [MUSIC Teleseismic Back-Projection](https://github.com/lsmeng/MUSICBP) Perform the Back-Projection Imaging on the seismograms of large earthquakes recorded by large-scale dense arrays.\n4. [Seismic_BPMF](https://ebeauce.github.io/Seismic_BPMF/index.html) Fully automated workflow for earthquake detection and location with the backprojection and matched filtering methods.\n5. [ARRU_seismic_backprojection](https://github.com/tso1257771/Attention-Recurrent-Residual-U-Net-for-earthquake-detection) ARRU Phase Picker: Attention Recurrent‐Residual U‐Net for Picking Seismic P‐ and S‐Phase Arrivals.\n6. [earthquake_back_projection](https://github.com/ajay6763/earthquake_back_projection) Back-projection of high-frequency radiation from earthquake source using multiple arrays. Methodology is based on Ishii (2012). \n7. [earthquake_detection](https://github.com/ebeauce/earthquake_detection_EB_et_al_2019) Codes used in the earthquake detection and location method presented in Beauce et al. 2019, DOI: 10.1029/2019JB018110. A real data example is also provided.\n8. [beampower](https://ebeauce.github.io/beampower/introduction.html) Fast routines for seismic backprojection/beamforming for both CPU and GPU architectures.\n9. [Iterative Linear Stress Inversion (ILSI)](https://ebeauce.github.io/ILSI/) Python package for stress tensor inversion. \n10. [Pyrocko](https://git.pyrocko.org/pyrocko/pyrocko/) A Python framework for efficient use of pre-computed Green's functions in seismological and other physical forward and inverse source problems.\n\n\n","slug":"code-and-project2","published":1,"updated":"2025-04-19T02:30:01.980Z","comments":1,"layout":"post","photos":[],"_id":"cmh498iq800blwvou2uct6eg9","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><ol>\n<li><a href=\"https://ssa2py.readthedocs.io/en/stable/basic_info.html\">Fast analysis of the seismic rupture</a> SSA2py is an emergent python based software that allows fast analysis of the seismic rupture, making possible the near-realtime identification of the rupture characteristics after a significant seismic event. </li>\n<li><a href=\"https://github.com/beridel/fast_matched_filter\">Fast matching filter</a> Seismic matched-filter search for both CPU and GPU architectures.</li>\n<li><a href=\"https://github.com/lsmeng/MUSICBP\">MUSIC Teleseismic Back-Projection</a> Perform the Back-Projection Imaging on the seismograms of large earthquakes recorded by large-scale dense arrays.</li>\n<li><a href=\"https://ebeauce.github.io/Seismic_BPMF/index.html\">Seismic_BPMF</a> Fully automated workflow for earthquake detection and location with the backprojection and matched filtering methods.</li>\n<li><a href=\"https://github.com/tso1257771/Attention-Recurrent-Residual-U-Net-for-earthquake-detection\">ARRU_seismic_backprojection</a> ARRU Phase Picker: Attention Recurrent‐Residual U‐Net for Picking Seismic P‐ and S‐Phase Arrivals.</li>\n<li><a href=\"https://github.com/ajay6763/earthquake_back_projection\">earthquake_back_projection</a> Back-projection of high-frequency radiation from earthquake source using multiple arrays. Methodology is based on Ishii (2012). </li>\n<li><a href=\"https://github.com/ebeauce/earthquake_detection_EB_et_al_2019\">earthquake_detection</a> Codes used in the earthquake detection and location method presented in Beauce et al. 2019, DOI: 10.1029&#x2F;2019JB018110. A real data example is also provided.</li>\n<li><a href=\"https://ebeauce.github.io/beampower/introduction.html\">beampower</a> Fast routines for seismic backprojection&#x2F;beamforming for both CPU and GPU architectures.</li>\n<li><a href=\"https://ebeauce.github.io/ILSI/\">Iterative Linear Stress Inversion (ILSI)</a> Python package for stress tensor inversion. </li>\n<li><a href=\"https://git.pyrocko.org/pyrocko/pyrocko/\">Pyrocko</a> A Python framework for efficient use of pre-computed Green’s functions in seismological and other physical forward and inverse source problems.</li>\n</ol>\n","related_posts":["object-detection.html","code-and-project1.html","paper-reading-7.html","distribute-package.html","paper-reading-26.html"],"length":1237,"excerpt":"","more":"<ol>\n<li><a href=\"https://ssa2py.readthedocs.io/en/stable/basic_info.html\">Fast analysis of the seismic rupture</a> SSA2py is an emergent python based software that allows fast analysis of the seismic rupture, making possible the near-realtime identification of the rupture characteristics after a significant seismic event. </li>\n<li><a href=\"https://github.com/beridel/fast_matched_filter\">Fast matching filter</a> Seismic matched-filter search for both CPU and GPU architectures.</li>\n<li><a href=\"https://github.com/lsmeng/MUSICBP\">MUSIC Teleseismic Back-Projection</a> Perform the Back-Projection Imaging on the seismograms of large earthquakes recorded by large-scale dense arrays.</li>\n<li><a href=\"https://ebeauce.github.io/Seismic_BPMF/index.html\">Seismic_BPMF</a> Fully automated workflow for earthquake detection and location with the backprojection and matched filtering methods.</li>\n<li><a href=\"https://github.com/tso1257771/Attention-Recurrent-Residual-U-Net-for-earthquake-detection\">ARRU_seismic_backprojection</a> ARRU Phase Picker: Attention Recurrent‐Residual U‐Net for Picking Seismic P‐ and S‐Phase Arrivals.</li>\n<li><a href=\"https://github.com/ajay6763/earthquake_back_projection\">earthquake_back_projection</a> Back-projection of high-frequency radiation from earthquake source using multiple arrays. Methodology is based on Ishii (2012). </li>\n<li><a href=\"https://github.com/ebeauce/earthquake_detection_EB_et_al_2019\">earthquake_detection</a> Codes used in the earthquake detection and location method presented in Beauce et al. 2019, DOI: 10.1029&#x2F;2019JB018110. A real data example is also provided.</li>\n<li><a href=\"https://ebeauce.github.io/beampower/introduction.html\">beampower</a> Fast routines for seismic backprojection&#x2F;beamforming for both CPU and GPU architectures.</li>\n<li><a href=\"https://ebeauce.github.io/ILSI/\">Iterative Linear Stress Inversion (ILSI)</a> Python package for stress tensor inversion. </li>\n<li><a href=\"https://git.pyrocko.org/pyrocko/pyrocko/\">Pyrocko</a> A Python framework for efficient use of pre-computed Green’s functions in seismological and other physical forward and inverse source problems.</li>\n</ol>\n"},{"title":"obspy下载连续背景噪声数据","abbrlink":"cb1143bd","date":"2025-04-21T13:17:55.000Z","_content":"利用obspy的MassDownloader下载连续的波形示例。\n```python\nimport obspy\nfrom obspy.clients.fdsn.mass_downloader import RectangularDomain, CircularDomain, \\\n    Restrictions, MassDownloader\n# Rectangular domain containing parts of southern Germany.\n#domain = RectangularDomain(minlatitude=-15, maxlatitude=18,\n#                           minlongitude=10, maxlongitude=22)\ndomain = CircularDomain(\n        latitude=0,\n        longitude=0,\n        minradius=0.0,\n        maxradius=12.0\n        )\nrestrictions = Restrictions(\n    # Get data for a whole year.\n    starttime=obspy.UTCDateTime(2005, 1, 15),\n    endtime=obspy.UTCDateTime(2007, 10, 15),\n    # Chunk it to have one file per day.\n    chunklength_in_sec=86400,\n    # Considering the enormous amount of data associated with continuous\n    # requests, you might want to limit the data based on SEED identifiers.\n    # If the location code is specified, the location priority list is not\n    # used; the same is true for the channel argument and priority list.\n    network=\"??\", station=\"????\", location=\"*\", channel=\"LHZ\",\n    # The typical use case for such a data set are noise correlations where\n    # gaps are dealt with at a later stage.\n    reject_channels_with_gaps=False,\n    # Same is true with the minimum length. All data might be useful.\n    minimum_length=0.0,\n    # Guard against the same station having different names.\n    minimum_interstation_distance_in_m=100.0)\n# Restrict the number of providers if you know which serve the desired\n# data. If in doubt just don't specify - then all providers will be\n# queried.\n#mdl = MassDownloader(providers=[\"IRIS\",\"USGS\",\"GFZ\"])\nmdl = MassDownloader()\nmdl.download(domain, restrictions, mseed_storage=\"waveforms\",\n             stationxml_storage=\"stations\")\n```\n","source":"_posts/2025-04-21-down-ambient-noise-py.md","raw":"---\ntitle: obspy下载连续背景噪声数据\ntags:\n  - obspy\n  - python\ncategories:\n  - work\nabbrlink: cb1143bd\ndate: 2025-04-21 21:17:55\n---\n利用obspy的MassDownloader下载连续的波形示例。\n```python\nimport obspy\nfrom obspy.clients.fdsn.mass_downloader import RectangularDomain, CircularDomain, \\\n    Restrictions, MassDownloader\n# Rectangular domain containing parts of southern Germany.\n#domain = RectangularDomain(minlatitude=-15, maxlatitude=18,\n#                           minlongitude=10, maxlongitude=22)\ndomain = CircularDomain(\n        latitude=0,\n        longitude=0,\n        minradius=0.0,\n        maxradius=12.0\n        )\nrestrictions = Restrictions(\n    # Get data for a whole year.\n    starttime=obspy.UTCDateTime(2005, 1, 15),\n    endtime=obspy.UTCDateTime(2007, 10, 15),\n    # Chunk it to have one file per day.\n    chunklength_in_sec=86400,\n    # Considering the enormous amount of data associated with continuous\n    # requests, you might want to limit the data based on SEED identifiers.\n    # If the location code is specified, the location priority list is not\n    # used; the same is true for the channel argument and priority list.\n    network=\"??\", station=\"????\", location=\"*\", channel=\"LHZ\",\n    # The typical use case for such a data set are noise correlations where\n    # gaps are dealt with at a later stage.\n    reject_channels_with_gaps=False,\n    # Same is true with the minimum length. All data might be useful.\n    minimum_length=0.0,\n    # Guard against the same station having different names.\n    minimum_interstation_distance_in_m=100.0)\n# Restrict the number of providers if you know which serve the desired\n# data. If in doubt just don't specify - then all providers will be\n# queried.\n#mdl = MassDownloader(providers=[\"IRIS\",\"USGS\",\"GFZ\"])\nmdl = MassDownloader()\nmdl.download(domain, restrictions, mseed_storage=\"waveforms\",\n             stationxml_storage=\"stations\")\n```\n","slug":"down-ambient-noise-py","published":1,"updated":"2025-04-21T13:23:00.240Z","comments":1,"layout":"post","photos":[],"_id":"cmh498iq800bpwvou0dce8zp9","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>利用obspy的MassDownloader下载连续的波形示例。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> obspy</span><br><span class=\"line\"><span class=\"keyword\">from</span> obspy.clients.fdsn.mass_downloader <span class=\"keyword\">import</span> RectangularDomain, CircularDomain, \\</span><br><span class=\"line\">    Restrictions, MassDownloader</span><br><span class=\"line\"><span class=\"comment\"># Rectangular domain containing parts of southern Germany.</span></span><br><span class=\"line\"><span class=\"comment\">#domain = RectangularDomain(minlatitude=-15, maxlatitude=18,</span></span><br><span class=\"line\"><span class=\"comment\">#                           minlongitude=10, maxlongitude=22)</span></span><br><span class=\"line\">domain = CircularDomain(</span><br><span class=\"line\">        latitude=<span class=\"number\">0</span>,</span><br><span class=\"line\">        longitude=<span class=\"number\">0</span>,</span><br><span class=\"line\">        minradius=<span class=\"number\">0.0</span>,</span><br><span class=\"line\">        maxradius=<span class=\"number\">12.0</span></span><br><span class=\"line\">        )</span><br><span class=\"line\">restrictions = Restrictions(</span><br><span class=\"line\">    <span class=\"comment\"># Get data for a whole year.</span></span><br><span class=\"line\">    starttime=obspy.UTCDateTime(<span class=\"number\">2005</span>, <span class=\"number\">1</span>, <span class=\"number\">15</span>),</span><br><span class=\"line\">    endtime=obspy.UTCDateTime(<span class=\"number\">2007</span>, <span class=\"number\">10</span>, <span class=\"number\">15</span>),</span><br><span class=\"line\">    <span class=\"comment\"># Chunk it to have one file per day.</span></span><br><span class=\"line\">    chunklength_in_sec=<span class=\"number\">86400</span>,</span><br><span class=\"line\">    <span class=\"comment\"># Considering the enormous amount of data associated with continuous</span></span><br><span class=\"line\">    <span class=\"comment\"># requests, you might want to limit the data based on SEED identifiers.</span></span><br><span class=\"line\">    <span class=\"comment\"># If the location code is specified, the location priority list is not</span></span><br><span class=\"line\">    <span class=\"comment\"># used; the same is true for the channel argument and priority list.</span></span><br><span class=\"line\">    network=<span class=\"string\">&quot;??&quot;</span>, station=<span class=\"string\">&quot;????&quot;</span>, location=<span class=\"string\">&quot;*&quot;</span>, channel=<span class=\"string\">&quot;LHZ&quot;</span>,</span><br><span class=\"line\">    <span class=\"comment\"># The typical use case for such a data set are noise correlations where</span></span><br><span class=\"line\">    <span class=\"comment\"># gaps are dealt with at a later stage.</span></span><br><span class=\"line\">    reject_channels_with_gaps=<span class=\"literal\">False</span>,</span><br><span class=\"line\">    <span class=\"comment\"># Same is true with the minimum length. All data might be useful.</span></span><br><span class=\"line\">    minimum_length=<span class=\"number\">0.0</span>,</span><br><span class=\"line\">    <span class=\"comment\"># Guard against the same station having different names.</span></span><br><span class=\"line\">    minimum_interstation_distance_in_m=<span class=\"number\">100.0</span>)</span><br><span class=\"line\"><span class=\"comment\"># Restrict the number of providers if you know which serve the desired</span></span><br><span class=\"line\"><span class=\"comment\"># data. If in doubt just don&#x27;t specify - then all providers will be</span></span><br><span class=\"line\"><span class=\"comment\"># queried.</span></span><br><span class=\"line\"><span class=\"comment\">#mdl = MassDownloader(providers=[&quot;IRIS&quot;,&quot;USGS&quot;,&quot;GFZ&quot;])</span></span><br><span class=\"line\">mdl = MassDownloader()</span><br><span class=\"line\">mdl.download(domain, restrictions, mseed_storage=<span class=\"string\">&quot;waveforms&quot;</span>,</span><br><span class=\"line\">             stationxml_storage=<span class=\"string\">&quot;stations&quot;</span>)</span><br></pre></td></tr></table></figure>\n","related_posts":[],"length":1552,"excerpt":"","more":"<p>利用obspy的MassDownloader下载连续的波形示例。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> obspy</span><br><span class=\"line\"><span class=\"keyword\">from</span> obspy.clients.fdsn.mass_downloader <span class=\"keyword\">import</span> RectangularDomain, CircularDomain, \\</span><br><span class=\"line\">    Restrictions, MassDownloader</span><br><span class=\"line\"><span class=\"comment\"># Rectangular domain containing parts of southern Germany.</span></span><br><span class=\"line\"><span class=\"comment\">#domain = RectangularDomain(minlatitude=-15, maxlatitude=18,</span></span><br><span class=\"line\"><span class=\"comment\">#                           minlongitude=10, maxlongitude=22)</span></span><br><span class=\"line\">domain = CircularDomain(</span><br><span class=\"line\">        latitude=<span class=\"number\">0</span>,</span><br><span class=\"line\">        longitude=<span class=\"number\">0</span>,</span><br><span class=\"line\">        minradius=<span class=\"number\">0.0</span>,</span><br><span class=\"line\">        maxradius=<span class=\"number\">12.0</span></span><br><span class=\"line\">        )</span><br><span class=\"line\">restrictions = Restrictions(</span><br><span class=\"line\">    <span class=\"comment\"># Get data for a whole year.</span></span><br><span class=\"line\">    starttime=obspy.UTCDateTime(<span class=\"number\">2005</span>, <span class=\"number\">1</span>, <span class=\"number\">15</span>),</span><br><span class=\"line\">    endtime=obspy.UTCDateTime(<span class=\"number\">2007</span>, <span class=\"number\">10</span>, <span class=\"number\">15</span>),</span><br><span class=\"line\">    <span class=\"comment\"># Chunk it to have one file per day.</span></span><br><span class=\"line\">    chunklength_in_sec=<span class=\"number\">86400</span>,</span><br><span class=\"line\">    <span class=\"comment\"># Considering the enormous amount of data associated with continuous</span></span><br><span class=\"line\">    <span class=\"comment\"># requests, you might want to limit the data based on SEED identifiers.</span></span><br><span class=\"line\">    <span class=\"comment\"># If the location code is specified, the location priority list is not</span></span><br><span class=\"line\">    <span class=\"comment\"># used; the same is true for the channel argument and priority list.</span></span><br><span class=\"line\">    network=<span class=\"string\">&quot;??&quot;</span>, station=<span class=\"string\">&quot;????&quot;</span>, location=<span class=\"string\">&quot;*&quot;</span>, channel=<span class=\"string\">&quot;LHZ&quot;</span>,</span><br><span class=\"line\">    <span class=\"comment\"># The typical use case for such a data set are noise correlations where</span></span><br><span class=\"line\">    <span class=\"comment\"># gaps are dealt with at a later stage.</span></span><br><span class=\"line\">    reject_channels_with_gaps=<span class=\"literal\">False</span>,</span><br><span class=\"line\">    <span class=\"comment\"># Same is true with the minimum length. All data might be useful.</span></span><br><span class=\"line\">    minimum_length=<span class=\"number\">0.0</span>,</span><br><span class=\"line\">    <span class=\"comment\"># Guard against the same station having different names.</span></span><br><span class=\"line\">    minimum_interstation_distance_in_m=<span class=\"number\">100.0</span>)</span><br><span class=\"line\"><span class=\"comment\"># Restrict the number of providers if you know which serve the desired</span></span><br><span class=\"line\"><span class=\"comment\"># data. If in doubt just don&#x27;t specify - then all providers will be</span></span><br><span class=\"line\"><span class=\"comment\"># queried.</span></span><br><span class=\"line\"><span class=\"comment\">#mdl = MassDownloader(providers=[&quot;IRIS&quot;,&quot;USGS&quot;,&quot;GFZ&quot;])</span></span><br><span class=\"line\">mdl = MassDownloader()</span><br><span class=\"line\">mdl.download(domain, restrictions, mseed_storage=<span class=\"string\">&quot;waveforms&quot;</span>,</span><br><span class=\"line\">             stationxml_storage=<span class=\"string\">&quot;stations&quot;</span>)</span><br></pre></td></tr></table></figure>\n"},{"title":"如何下载Fnet数据","abbrlink":"98618e37","date":"2025-04-22T00:36:57.000Z","_content":"感谢Seisman写了[FnetPy](https://github.com/seisman/FnetPy),可以很方便地下载数据。\n安装：\n```\npip install https://github.com/seisman/FnetPy/archive/master.zip\n```\n例子：\n```\nimport os\nfrom obspy.io.xseed import Parser\nfrom FnetPy import Client\nfrom datetime import datetime,timedelta\nfrom obspy import read_inventory,read,Trace\nfrom datetime import datetime\nclient = Client('用户名', '密码')\n\ncurrent_date=datetime(2013,1,1,0,0)\n#current_date=datetime(2004,12,30,0,0)\nend_date=datetime(2025,1,1,0,0)\noutput_dir='./seed'\nraw_dir='./raw'\nresp_dir='./resp'\nos.makedirs(output_dir, exist_ok=True)\nos.makedirs(raw_dir, exist_ok=True)\nos.makedirs(resp_dir, exist_ok=True)\nwhile (current_date<end_date):\n    start_time = current_data\n    start_str = current_date.strftime(\"%Y_%m_%d_%H_%M_%S\")\n    name=start_str+\".seed\"\n    fname=os.path.join(raw_dir,name)\n    output_file=os.path.join(output_dir, name)\n    if os.path.exists(output_file):\n        print(f\"[跳过] 文件已存在: {output_file}\")\n        current_date+=timedelta(days=1)\n        continue\n    open(output_file, 'wb').close()  # 创建空文件\n    if not os.path.exists(fname):\n        print('download data from '+str(start_time)+' to '+str(end_time))\n        client.get_waveform(start_time, duration_in_seconds=86400+3600,component=\"LHZ\",filename=fname) # download\n        print('download '+fname+' down!')\n    current_date+=timedelta(days=1)\n    st = read(fname) # read\n    parser = Parser(fname) #parse\n    parser.write_resp(resp_dir, zipped=False)\n    for tr in st:\n        resp_file = f\"RESP.{tr.get_id()}\"\n        inv = read_inventory(os.path.join(resp_dir, resp_file))\n        tr.remove_response(inventory=inv, output=\"VEL\")\n        #print(tr.stats)\n    st.write(output_file, format=\"MSEED\")\nprint('Finished')\n```\n这个脚本可以下载2013到2025年Fnet所有台站的LHZ连续波形数据，数据长度为25小时，overlap 1小时。去除仪器响应后的速度记录存放在seed文件夹中。每天的数据名称为%Y_%m_%d_%H_%M_%S.seed。账户需要去NIED去申请，当然用我的也可以。\n","source":"_posts/2025-04-22-download-fnet-data-py.md","raw":"---\ntitle: 如何下载Fnet数据\ntags:\n  - python\ncategories:\n  - work\nabbrlink: '98618e37'\ndate: 2025-04-22 08:36:57\n---\n感谢Seisman写了[FnetPy](https://github.com/seisman/FnetPy),可以很方便地下载数据。\n安装：\n```\npip install https://github.com/seisman/FnetPy/archive/master.zip\n```\n例子：\n```\nimport os\nfrom obspy.io.xseed import Parser\nfrom FnetPy import Client\nfrom datetime import datetime,timedelta\nfrom obspy import read_inventory,read,Trace\nfrom datetime import datetime\nclient = Client('用户名', '密码')\n\ncurrent_date=datetime(2013,1,1,0,0)\n#current_date=datetime(2004,12,30,0,0)\nend_date=datetime(2025,1,1,0,0)\noutput_dir='./seed'\nraw_dir='./raw'\nresp_dir='./resp'\nos.makedirs(output_dir, exist_ok=True)\nos.makedirs(raw_dir, exist_ok=True)\nos.makedirs(resp_dir, exist_ok=True)\nwhile (current_date<end_date):\n    start_time = current_data\n    start_str = current_date.strftime(\"%Y_%m_%d_%H_%M_%S\")\n    name=start_str+\".seed\"\n    fname=os.path.join(raw_dir,name)\n    output_file=os.path.join(output_dir, name)\n    if os.path.exists(output_file):\n        print(f\"[跳过] 文件已存在: {output_file}\")\n        current_date+=timedelta(days=1)\n        continue\n    open(output_file, 'wb').close()  # 创建空文件\n    if not os.path.exists(fname):\n        print('download data from '+str(start_time)+' to '+str(end_time))\n        client.get_waveform(start_time, duration_in_seconds=86400+3600,component=\"LHZ\",filename=fname) # download\n        print('download '+fname+' down!')\n    current_date+=timedelta(days=1)\n    st = read(fname) # read\n    parser = Parser(fname) #parse\n    parser.write_resp(resp_dir, zipped=False)\n    for tr in st:\n        resp_file = f\"RESP.{tr.get_id()}\"\n        inv = read_inventory(os.path.join(resp_dir, resp_file))\n        tr.remove_response(inventory=inv, output=\"VEL\")\n        #print(tr.stats)\n    st.write(output_file, format=\"MSEED\")\nprint('Finished')\n```\n这个脚本可以下载2013到2025年Fnet所有台站的LHZ连续波形数据，数据长度为25小时，overlap 1小时。去除仪器响应后的速度记录存放在seed文件夹中。每天的数据名称为%Y_%m_%d_%H_%M_%S.seed。账户需要去NIED去申请，当然用我的也可以。\n","slug":"download-fnet-data-py","published":1,"updated":"2025-04-22T00:54:00.522Z","comments":1,"layout":"post","photos":[],"_id":"cmh498iq900bswvougtvv2upr","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>感谢Seisman写了<a href=\"https://github.com/seisman/FnetPy\">FnetPy</a>,可以很方便地下载数据。<br>安装：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pip install https://github.com/seisman/FnetPy/archive/master.zip</span><br></pre></td></tr></table></figure>\n<p>例子：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">import os</span><br><span class=\"line\">from obspy.io.xseed import Parser</span><br><span class=\"line\">from FnetPy import Client</span><br><span class=\"line\">from datetime import datetime,timedelta</span><br><span class=\"line\">from obspy import read_inventory,read,Trace</span><br><span class=\"line\">from datetime import datetime</span><br><span class=\"line\">client = Client(&#x27;用户名&#x27;, &#x27;密码&#x27;)</span><br><span class=\"line\"></span><br><span class=\"line\">current_date=datetime(2013,1,1,0,0)</span><br><span class=\"line\">#current_date=datetime(2004,12,30,0,0)</span><br><span class=\"line\">end_date=datetime(2025,1,1,0,0)</span><br><span class=\"line\">output_dir=&#x27;./seed&#x27;</span><br><span class=\"line\">raw_dir=&#x27;./raw&#x27;</span><br><span class=\"line\">resp_dir=&#x27;./resp&#x27;</span><br><span class=\"line\">os.makedirs(output_dir, exist_ok=True)</span><br><span class=\"line\">os.makedirs(raw_dir, exist_ok=True)</span><br><span class=\"line\">os.makedirs(resp_dir, exist_ok=True)</span><br><span class=\"line\">while (current_date&lt;end_date):</span><br><span class=\"line\">    start_time = current_data</span><br><span class=\"line\">    start_str = current_date.strftime(&quot;%Y_%m_%d_%H_%M_%S&quot;)</span><br><span class=\"line\">    name=start_str+&quot;.seed&quot;</span><br><span class=\"line\">    fname=os.path.join(raw_dir,name)</span><br><span class=\"line\">    output_file=os.path.join(output_dir, name)</span><br><span class=\"line\">    if os.path.exists(output_file):</span><br><span class=\"line\">        print(f&quot;[跳过] 文件已存在: &#123;output_file&#125;&quot;)</span><br><span class=\"line\">        current_date+=timedelta(days=1)</span><br><span class=\"line\">        continue</span><br><span class=\"line\">    open(output_file, &#x27;wb&#x27;).close()  # 创建空文件</span><br><span class=\"line\">    if not os.path.exists(fname):</span><br><span class=\"line\">        print(&#x27;download data from &#x27;+str(start_time)+&#x27; to &#x27;+str(end_time))</span><br><span class=\"line\">        client.get_waveform(start_time, duration_in_seconds=86400+3600,component=&quot;LHZ&quot;,filename=fname) # download</span><br><span class=\"line\">        print(&#x27;download &#x27;+fname+&#x27; down!&#x27;)</span><br><span class=\"line\">    current_date+=timedelta(days=1)</span><br><span class=\"line\">    st = read(fname) # read</span><br><span class=\"line\">    parser = Parser(fname) #parse</span><br><span class=\"line\">    parser.write_resp(resp_dir, zipped=False)</span><br><span class=\"line\">    for tr in st:</span><br><span class=\"line\">        resp_file = f&quot;RESP.&#123;tr.get_id()&#125;&quot;</span><br><span class=\"line\">        inv = read_inventory(os.path.join(resp_dir, resp_file))</span><br><span class=\"line\">        tr.remove_response(inventory=inv, output=&quot;VEL&quot;)</span><br><span class=\"line\">        #print(tr.stats)</span><br><span class=\"line\">    st.write(output_file, format=&quot;MSEED&quot;)</span><br><span class=\"line\">print(&#x27;Finished&#x27;)</span><br></pre></td></tr></table></figure>\n<p>这个脚本可以下载2013到2025年Fnet所有台站的LHZ连续波形数据，数据长度为25小时，overlap 1小时。去除仪器响应后的速度记录存放在seed文件夹中。每天的数据名称为%Y_%m_%d_%H_%M_%S.seed。账户需要去NIED去申请，当然用我的也可以。</p>\n","related_posts":[],"length":1842,"excerpt":"","more":"<p>感谢Seisman写了<a href=\"https://github.com/seisman/FnetPy\">FnetPy</a>,可以很方便地下载数据。<br>安装：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pip install https://github.com/seisman/FnetPy/archive/master.zip</span><br></pre></td></tr></table></figure>\n<p>例子：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">import os</span><br><span class=\"line\">from obspy.io.xseed import Parser</span><br><span class=\"line\">from FnetPy import Client</span><br><span class=\"line\">from datetime import datetime,timedelta</span><br><span class=\"line\">from obspy import read_inventory,read,Trace</span><br><span class=\"line\">from datetime import datetime</span><br><span class=\"line\">client = Client(&#x27;用户名&#x27;, &#x27;密码&#x27;)</span><br><span class=\"line\"></span><br><span class=\"line\">current_date=datetime(2013,1,1,0,0)</span><br><span class=\"line\">#current_date=datetime(2004,12,30,0,0)</span><br><span class=\"line\">end_date=datetime(2025,1,1,0,0)</span><br><span class=\"line\">output_dir=&#x27;./seed&#x27;</span><br><span class=\"line\">raw_dir=&#x27;./raw&#x27;</span><br><span class=\"line\">resp_dir=&#x27;./resp&#x27;</span><br><span class=\"line\">os.makedirs(output_dir, exist_ok=True)</span><br><span class=\"line\">os.makedirs(raw_dir, exist_ok=True)</span><br><span class=\"line\">os.makedirs(resp_dir, exist_ok=True)</span><br><span class=\"line\">while (current_date&lt;end_date):</span><br><span class=\"line\">    start_time = current_data</span><br><span class=\"line\">    start_str = current_date.strftime(&quot;%Y_%m_%d_%H_%M_%S&quot;)</span><br><span class=\"line\">    name=start_str+&quot;.seed&quot;</span><br><span class=\"line\">    fname=os.path.join(raw_dir,name)</span><br><span class=\"line\">    output_file=os.path.join(output_dir, name)</span><br><span class=\"line\">    if os.path.exists(output_file):</span><br><span class=\"line\">        print(f&quot;[跳过] 文件已存在: &#123;output_file&#125;&quot;)</span><br><span class=\"line\">        current_date+=timedelta(days=1)</span><br><span class=\"line\">        continue</span><br><span class=\"line\">    open(output_file, &#x27;wb&#x27;).close()  # 创建空文件</span><br><span class=\"line\">    if not os.path.exists(fname):</span><br><span class=\"line\">        print(&#x27;download data from &#x27;+str(start_time)+&#x27; to &#x27;+str(end_time))</span><br><span class=\"line\">        client.get_waveform(start_time, duration_in_seconds=86400+3600,component=&quot;LHZ&quot;,filename=fname) # download</span><br><span class=\"line\">        print(&#x27;download &#x27;+fname+&#x27; down!&#x27;)</span><br><span class=\"line\">    current_date+=timedelta(days=1)</span><br><span class=\"line\">    st = read(fname) # read</span><br><span class=\"line\">    parser = Parser(fname) #parse</span><br><span class=\"line\">    parser.write_resp(resp_dir, zipped=False)</span><br><span class=\"line\">    for tr in st:</span><br><span class=\"line\">        resp_file = f&quot;RESP.&#123;tr.get_id()&#125;&quot;</span><br><span class=\"line\">        inv = read_inventory(os.path.join(resp_dir, resp_file))</span><br><span class=\"line\">        tr.remove_response(inventory=inv, output=&quot;VEL&quot;)</span><br><span class=\"line\">        #print(tr.stats)</span><br><span class=\"line\">    st.write(output_file, format=&quot;MSEED&quot;)</span><br><span class=\"line\">print(&#x27;Finished&#x27;)</span><br></pre></td></tr></table></figure>\n<p>这个脚本可以下载2013到2025年Fnet所有台站的LHZ连续波形数据，数据长度为25小时，overlap 1小时。去除仪器响应后的速度记录存放在seed文件夹中。每天的数据名称为%Y_%m_%d_%H_%M_%S.seed。账户需要去NIED去申请，当然用我的也可以。</p>\n"},{"title":"文献阅读(27)","abbrlink":"8fb447c2","date":"2025-04-23T07:42:03.000Z","_content":"&emsp;&emsp;[Coherence-Based Characterization of a Long-Period Monochromatic Seismic Signal](https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2024GL113290)\n<!--less-->\n### 摘要\n持续的地震数据分析能够识别与地球内部或地表物理过程相关的信号 。表征地震信号有助于深入了解源过程和地球的结构特征 。通过对长周期（25 - 100秒）面波的全球地震网络分析，已经检测到了一些未通过高频体波分析识别出的地震事件 。然而，全球范围内探测具有窄谱峰的持久单色信号仍然具有挑战性，这些信号携带着有关地质和环境过程的宝贵信息 。我们开发了一种基于相干性的方法，用于在全球范围内表征长周期单色地震信号 。除了来自几内亚湾、瓦努阿图群岛和一座海底火山的信号外，我们还观测到来自加拿大北极地区的一个此前未识别的信号，可能与冰川动态有关 。我们的方法探索了连续地震数据中的长周期单色地震信号，为未来研究表征这些信号在地球表面产生的物理过程奠定了基础 。\n\n### 相关研究的重要性\n以下是相关研究的一些重要性：\n- **深化地球物理过程理解**：有助于深入了解地球内部的物理过程，如地震的发生机制、岩浆的运移等。\n- **改进地震监测技术**：推动地震监测技术的发展，提高地震事件的检测能力。\n- **揭示地质灾害成因**：为地质灾害的预测和防范提供科学依据，减少灾害带来的损失。\n- **监测环境变化**：通过监测与环境变化相关的地震信号，如冰川融化、火山活动等，为环境科学研究提供数据支持。\n\n### 前人的相关研究及不足\n以下是前人的一些相关研究及不足：\n- **Shearer（1994）**：通过堆叠长周期面波使用匹配滤波技术，检测到32个未识别事件，大多数事件位于南半球的大洋中脊。**不足**：依赖于速度模型的准确性，速度模型的不准确可能会引入事件检测的不确定性。\n- **Ekström（2006）**：分析了10年的全球地震数据，检测到约1300个未识别事件，主要由格陵兰和南极的冰川崩解产生。**不足**：难以检测到具有窄频率带、长持续时间和不清晰起始时间的单色信号。\n- **Poli（2024）**：应用基于迁移算法的分析，发现了约1766个未识别事件，主要位于极地地区、大洋中脊和构造边界。**不足**：对信号的物理机制理解不够深入，需要进一步研究。\n\n### 本文使用的数据和方法\n- **数据**：本文使用了日本F-net网络中的72个宽频带地震台站记录的信号数据，收集了从2003年1月1日至2022年12月31日的连续数据。\n- **方法**：提出了基于相干性的方法，计算区域地震阵列中所有台站对的网络平均相干性，通过波束形成和匹配滤波等技术来识别和定位信号源。\n\n### 本文获得的结果\n- 识别出了多个已知和未知的信号源，包括来自几内亚湾、瓦努阿图群岛、Fukutoku-Okanoba海底火山和加拿大北极群岛的信号。\n- 通过匹配滤波方法，发现加拿大北极地区存在新的冰川地震活动。\n- 揭示了26秒微震在南半球冬季的高发生率，以及瓦努阿图弧在某些年份的信号爆发。\n\n### 本文的创新之处\n- 提出了基于相干性的新方法，有效解决了传统方法在检测长周期单色地震信号时的不足。\n- 成功识别了来自加拿大北极群岛的 previously 未被识别的信号，拓展了对极地地区地震活动的认识。\n- 通过匹配滤波方法，首次发现了加拿大北极地区的重复冰川地震活动。\n\n### 本文的贡献\n- 为系统检测和表征火山和环境信号提供了新方法，有助于更好地理解这些信号的物理机制。\n- 丰富了全球地震信号的观测和研究，为地震学和地球物理学研究提供了新的数据和案例。\n- 对监测和研究气候变化对极地地区的影响具有重要意义。\n\n### 本文的不足\n- 在定位信号源时，假设面波沿小圆弧大圆路径传播，这可能会引入系统误差。\n- 对信号的物理机制解释存在一定的不确定性，需要更多的研究来验证。\n- 分析主要基于日本的地震台网数据，可能在信号检测和定位的全球覆盖范围上存在局限性。\n","source":"_posts/2025-04-23-paper-reading-27.md","raw":"---\ntitle: 文献阅读(27)\ntags:\n  - paper\ncategories:\n  - work\nabbrlink: 8fb447c2\ndate: 2025-04-23 15:42:03\n---\n&emsp;&emsp;[Coherence-Based Characterization of a Long-Period Monochromatic Seismic Signal](https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2024GL113290)\n<!--less-->\n### 摘要\n持续的地震数据分析能够识别与地球内部或地表物理过程相关的信号 。表征地震信号有助于深入了解源过程和地球的结构特征 。通过对长周期（25 - 100秒）面波的全球地震网络分析，已经检测到了一些未通过高频体波分析识别出的地震事件 。然而，全球范围内探测具有窄谱峰的持久单色信号仍然具有挑战性，这些信号携带着有关地质和环境过程的宝贵信息 。我们开发了一种基于相干性的方法，用于在全球范围内表征长周期单色地震信号 。除了来自几内亚湾、瓦努阿图群岛和一座海底火山的信号外，我们还观测到来自加拿大北极地区的一个此前未识别的信号，可能与冰川动态有关 。我们的方法探索了连续地震数据中的长周期单色地震信号，为未来研究表征这些信号在地球表面产生的物理过程奠定了基础 。\n\n### 相关研究的重要性\n以下是相关研究的一些重要性：\n- **深化地球物理过程理解**：有助于深入了解地球内部的物理过程，如地震的发生机制、岩浆的运移等。\n- **改进地震监测技术**：推动地震监测技术的发展，提高地震事件的检测能力。\n- **揭示地质灾害成因**：为地质灾害的预测和防范提供科学依据，减少灾害带来的损失。\n- **监测环境变化**：通过监测与环境变化相关的地震信号，如冰川融化、火山活动等，为环境科学研究提供数据支持。\n\n### 前人的相关研究及不足\n以下是前人的一些相关研究及不足：\n- **Shearer（1994）**：通过堆叠长周期面波使用匹配滤波技术，检测到32个未识别事件，大多数事件位于南半球的大洋中脊。**不足**：依赖于速度模型的准确性，速度模型的不准确可能会引入事件检测的不确定性。\n- **Ekström（2006）**：分析了10年的全球地震数据，检测到约1300个未识别事件，主要由格陵兰和南极的冰川崩解产生。**不足**：难以检测到具有窄频率带、长持续时间和不清晰起始时间的单色信号。\n- **Poli（2024）**：应用基于迁移算法的分析，发现了约1766个未识别事件，主要位于极地地区、大洋中脊和构造边界。**不足**：对信号的物理机制理解不够深入，需要进一步研究。\n\n### 本文使用的数据和方法\n- **数据**：本文使用了日本F-net网络中的72个宽频带地震台站记录的信号数据，收集了从2003年1月1日至2022年12月31日的连续数据。\n- **方法**：提出了基于相干性的方法，计算区域地震阵列中所有台站对的网络平均相干性，通过波束形成和匹配滤波等技术来识别和定位信号源。\n\n### 本文获得的结果\n- 识别出了多个已知和未知的信号源，包括来自几内亚湾、瓦努阿图群岛、Fukutoku-Okanoba海底火山和加拿大北极群岛的信号。\n- 通过匹配滤波方法，发现加拿大北极地区存在新的冰川地震活动。\n- 揭示了26秒微震在南半球冬季的高发生率，以及瓦努阿图弧在某些年份的信号爆发。\n\n### 本文的创新之处\n- 提出了基于相干性的新方法，有效解决了传统方法在检测长周期单色地震信号时的不足。\n- 成功识别了来自加拿大北极群岛的 previously 未被识别的信号，拓展了对极地地区地震活动的认识。\n- 通过匹配滤波方法，首次发现了加拿大北极地区的重复冰川地震活动。\n\n### 本文的贡献\n- 为系统检测和表征火山和环境信号提供了新方法，有助于更好地理解这些信号的物理机制。\n- 丰富了全球地震信号的观测和研究，为地震学和地球物理学研究提供了新的数据和案例。\n- 对监测和研究气候变化对极地地区的影响具有重要意义。\n\n### 本文的不足\n- 在定位信号源时，假设面波沿小圆弧大圆路径传播，这可能会引入系统误差。\n- 对信号的物理机制解释存在一定的不确定性，需要更多的研究来验证。\n- 分析主要基于日本的地震台网数据，可能在信号检测和定位的全球覆盖范围上存在局限性。\n","slug":"paper-reading-27","published":1,"updated":"2025-04-23T07:47:29.840Z","comments":1,"layout":"post","photos":[],"_id":"cmh498iqc00bwwvou9hpmdj0d","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><h3 id=\"摘要\"><a href=\"#摘要\" class=\"headerlink\" title=\"摘要\"></a>摘要</h3><p>持续的地震数据分析能够识别与地球内部或地表物理过程相关的信号 。表征地震信号有助于深入了解源过程和地球的结构特征 。通过对长周期（25 - 100秒）面波的全球地震网络分析，已经检测到了一些未通过高频体波分析识别出的地震事件 。然而，全球范围内探测具有窄谱峰的持久单色信号仍然具有挑战性，这些信号携带着有关地质和环境过程的宝贵信息 。我们开发了一种基于相干性的方法，用于在全球范围内表征长周期单色地震信号 。除了来自几内亚湾、瓦努阿图群岛和一座海底火山的信号外，我们还观测到来自加拿大北极地区的一个此前未识别的信号，可能与冰川动态有关 。我们的方法探索了连续地震数据中的长周期单色地震信号，为未来研究表征这些信号在地球表面产生的物理过程奠定了基础 。</p>\n<h3 id=\"相关研究的重要性\"><a href=\"#相关研究的重要性\" class=\"headerlink\" title=\"相关研究的重要性\"></a>相关研究的重要性</h3><p>以下是相关研究的一些重要性：</p>\n<ul>\n<li><strong>深化地球物理过程理解</strong>：有助于深入了解地球内部的物理过程，如地震的发生机制、岩浆的运移等。</li>\n<li><strong>改进地震监测技术</strong>：推动地震监测技术的发展，提高地震事件的检测能力。</li>\n<li><strong>揭示地质灾害成因</strong>：为地质灾害的预测和防范提供科学依据，减少灾害带来的损失。</li>\n<li><strong>监测环境变化</strong>：通过监测与环境变化相关的地震信号，如冰川融化、火山活动等，为环境科学研究提供数据支持。</li>\n</ul>\n<h3 id=\"前人的相关研究及不足\"><a href=\"#前人的相关研究及不足\" class=\"headerlink\" title=\"前人的相关研究及不足\"></a>前人的相关研究及不足</h3><p>以下是前人的一些相关研究及不足：</p>\n<ul>\n<li><strong>Shearer（1994）</strong>：通过堆叠长周期面波使用匹配滤波技术，检测到32个未识别事件，大多数事件位于南半球的大洋中脊。<strong>不足</strong>：依赖于速度模型的准确性，速度模型的不准确可能会引入事件检测的不确定性。</li>\n<li><strong>Ekström（2006）</strong>：分析了10年的全球地震数据，检测到约1300个未识别事件，主要由格陵兰和南极的冰川崩解产生。<strong>不足</strong>：难以检测到具有窄频率带、长持续时间和不清晰起始时间的单色信号。</li>\n<li><strong>Poli（2024）</strong>：应用基于迁移算法的分析，发现了约1766个未识别事件，主要位于极地地区、大洋中脊和构造边界。<strong>不足</strong>：对信号的物理机制理解不够深入，需要进一步研究。</li>\n</ul>\n<h3 id=\"本文使用的数据和方法\"><a href=\"#本文使用的数据和方法\" class=\"headerlink\" title=\"本文使用的数据和方法\"></a>本文使用的数据和方法</h3><ul>\n<li><strong>数据</strong>：本文使用了日本F-net网络中的72个宽频带地震台站记录的信号数据，收集了从2003年1月1日至2022年12月31日的连续数据。</li>\n<li><strong>方法</strong>：提出了基于相干性的方法，计算区域地震阵列中所有台站对的网络平均相干性，通过波束形成和匹配滤波等技术来识别和定位信号源。</li>\n</ul>\n<h3 id=\"本文获得的结果\"><a href=\"#本文获得的结果\" class=\"headerlink\" title=\"本文获得的结果\"></a>本文获得的结果</h3><ul>\n<li>识别出了多个已知和未知的信号源，包括来自几内亚湾、瓦努阿图群岛、Fukutoku-Okanoba海底火山和加拿大北极群岛的信号。</li>\n<li>通过匹配滤波方法，发现加拿大北极地区存在新的冰川地震活动。</li>\n<li>揭示了26秒微震在南半球冬季的高发生率，以及瓦努阿图弧在某些年份的信号爆发。</li>\n</ul>\n<h3 id=\"本文的创新之处\"><a href=\"#本文的创新之处\" class=\"headerlink\" title=\"本文的创新之处\"></a>本文的创新之处</h3><ul>\n<li>提出了基于相干性的新方法，有效解决了传统方法在检测长周期单色地震信号时的不足。</li>\n<li>成功识别了来自加拿大北极群岛的 previously 未被识别的信号，拓展了对极地地区地震活动的认识。</li>\n<li>通过匹配滤波方法，首次发现了加拿大北极地区的重复冰川地震活动。</li>\n</ul>\n<h3 id=\"本文的贡献\"><a href=\"#本文的贡献\" class=\"headerlink\" title=\"本文的贡献\"></a>本文的贡献</h3><ul>\n<li>为系统检测和表征火山和环境信号提供了新方法，有助于更好地理解这些信号的物理机制。</li>\n<li>丰富了全球地震信号的观测和研究，为地震学和地球物理学研究提供了新的数据和案例。</li>\n<li>对监测和研究气候变化对极地地区的影响具有重要意义。</li>\n</ul>\n<h3 id=\"本文的不足\"><a href=\"#本文的不足\" class=\"headerlink\" title=\"本文的不足\"></a>本文的不足</h3><ul>\n<li>在定位信号源时，假设面波沿小圆弧大圆路径传播，这可能会引入系统误差。</li>\n<li>对信号的物理机制解释存在一定的不确定性，需要更多的研究来验证。</li>\n<li>分析主要基于日本的地震台网数据，可能在信号检测和定位的全球覆盖范围上存在局限性。</li>\n</ul>","related_posts":[],"length":1511,"excerpt":"<p>&emsp;&emsp;<a href=\"https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2024GL113290\">Coherence-Based Characterization of a Long-Period Monochromatic Seismic Signal</a></p>","more":"<h3 id=\"摘要\"><a href=\"#摘要\" class=\"headerlink\" title=\"摘要\"></a>摘要</h3><p>持续的地震数据分析能够识别与地球内部或地表物理过程相关的信号 。表征地震信号有助于深入了解源过程和地球的结构特征 。通过对长周期（25 - 100秒）面波的全球地震网络分析，已经检测到了一些未通过高频体波分析识别出的地震事件 。然而，全球范围内探测具有窄谱峰的持久单色信号仍然具有挑战性，这些信号携带着有关地质和环境过程的宝贵信息 。我们开发了一种基于相干性的方法，用于在全球范围内表征长周期单色地震信号 。除了来自几内亚湾、瓦努阿图群岛和一座海底火山的信号外，我们还观测到来自加拿大北极地区的一个此前未识别的信号，可能与冰川动态有关 。我们的方法探索了连续地震数据中的长周期单色地震信号，为未来研究表征这些信号在地球表面产生的物理过程奠定了基础 。</p>\n<h3 id=\"相关研究的重要性\"><a href=\"#相关研究的重要性\" class=\"headerlink\" title=\"相关研究的重要性\"></a>相关研究的重要性</h3><p>以下是相关研究的一些重要性：</p>\n<ul>\n<li><strong>深化地球物理过程理解</strong>：有助于深入了解地球内部的物理过程，如地震的发生机制、岩浆的运移等。</li>\n<li><strong>改进地震监测技术</strong>：推动地震监测技术的发展，提高地震事件的检测能力。</li>\n<li><strong>揭示地质灾害成因</strong>：为地质灾害的预测和防范提供科学依据，减少灾害带来的损失。</li>\n<li><strong>监测环境变化</strong>：通过监测与环境变化相关的地震信号，如冰川融化、火山活动等，为环境科学研究提供数据支持。</li>\n</ul>\n<h3 id=\"前人的相关研究及不足\"><a href=\"#前人的相关研究及不足\" class=\"headerlink\" title=\"前人的相关研究及不足\"></a>前人的相关研究及不足</h3><p>以下是前人的一些相关研究及不足：</p>\n<ul>\n<li><strong>Shearer（1994）</strong>：通过堆叠长周期面波使用匹配滤波技术，检测到32个未识别事件，大多数事件位于南半球的大洋中脊。<strong>不足</strong>：依赖于速度模型的准确性，速度模型的不准确可能会引入事件检测的不确定性。</li>\n<li><strong>Ekström（2006）</strong>：分析了10年的全球地震数据，检测到约1300个未识别事件，主要由格陵兰和南极的冰川崩解产生。<strong>不足</strong>：难以检测到具有窄频率带、长持续时间和不清晰起始时间的单色信号。</li>\n<li><strong>Poli（2024）</strong>：应用基于迁移算法的分析，发现了约1766个未识别事件，主要位于极地地区、大洋中脊和构造边界。<strong>不足</strong>：对信号的物理机制理解不够深入，需要进一步研究。</li>\n</ul>\n<h3 id=\"本文使用的数据和方法\"><a href=\"#本文使用的数据和方法\" class=\"headerlink\" title=\"本文使用的数据和方法\"></a>本文使用的数据和方法</h3><ul>\n<li><strong>数据</strong>：本文使用了日本F-net网络中的72个宽频带地震台站记录的信号数据，收集了从2003年1月1日至2022年12月31日的连续数据。</li>\n<li><strong>方法</strong>：提出了基于相干性的方法，计算区域地震阵列中所有台站对的网络平均相干性，通过波束形成和匹配滤波等技术来识别和定位信号源。</li>\n</ul>\n<h3 id=\"本文获得的结果\"><a href=\"#本文获得的结果\" class=\"headerlink\" title=\"本文获得的结果\"></a>本文获得的结果</h3><ul>\n<li>识别出了多个已知和未知的信号源，包括来自几内亚湾、瓦努阿图群岛、Fukutoku-Okanoba海底火山和加拿大北极群岛的信号。</li>\n<li>通过匹配滤波方法，发现加拿大北极地区存在新的冰川地震活动。</li>\n<li>揭示了26秒微震在南半球冬季的高发生率，以及瓦努阿图弧在某些年份的信号爆发。</li>\n</ul>\n<h3 id=\"本文的创新之处\"><a href=\"#本文的创新之处\" class=\"headerlink\" title=\"本文的创新之处\"></a>本文的创新之处</h3><ul>\n<li>提出了基于相干性的新方法，有效解决了传统方法在检测长周期单色地震信号时的不足。</li>\n<li>成功识别了来自加拿大北极群岛的 previously 未被识别的信号，拓展了对极地地区地震活动的认识。</li>\n<li>通过匹配滤波方法，首次发现了加拿大北极地区的重复冰川地震活动。</li>\n</ul>\n<h3 id=\"本文的贡献\"><a href=\"#本文的贡献\" class=\"headerlink\" title=\"本文的贡献\"></a>本文的贡献</h3><ul>\n<li>为系统检测和表征火山和环境信号提供了新方法，有助于更好地理解这些信号的物理机制。</li>\n<li>丰富了全球地震信号的观测和研究，为地震学和地球物理学研究提供了新的数据和案例。</li>\n<li>对监测和研究气候变化对极地地区的影响具有重要意义。</li>\n</ul>\n<h3 id=\"本文的不足\"><a href=\"#本文的不足\" class=\"headerlink\" title=\"本文的不足\"></a>本文的不足</h3><ul>\n<li>在定位信号源时，假设面波沿小圆弧大圆路径传播，这可能会引入系统误差。</li>\n<li>对信号的物理机制解释存在一定的不确定性，需要更多的研究来验证。</li>\n<li>分析主要基于日本的地震台网数据，可能在信号检测和定位的全球覆盖范围上存在局限性。</li>\n</ul>"},{"title":"去仪器响应练习","abbrlink":"6d0f71ef","date":"2025-04-23T07:14:23.000Z","_content":"用我的脚本下载了一堆的miniseed放在seed下，仪器响应文件放在resp文件夹下，利用obspy去除仪器响应，还保存为miniseed。\n```\nimport os\nfrom glob import glob\nfrom obspy import read, read_inventory\n# 设置路径\nseed_folder = \"seed\"\nresp_folder = \"resp\"\noutput_folder = \"seed_corrected\"\nos.makedirs(output_folder, exist_ok=True)\nseed_files = glob(os.path.join(seed_folder, \"*.seed\"))   # 遍历所有 seed 文件\nfor seed_file in seed_files:\n    print(f\"Processing {os.path.basename(seed_file)}\")\n    try:\n        st = read(seed_file)   # 读取 MiniSEED 数据\n        for tr in st:\n            net = tr.stats.network\n            sta = tr.stats.station\n            loc = tr.stats.location\n            cha = tr.stats.channel\n            resp_file = os.path.join(resp_folder, f\"RESP.{net}.{sta}.{loc}.{cha}\") # 构造 RESP 文件路径\n            if not os.path.exists(resp_file):\n                print(f\"RESP file not found: {resp_file}, skipping trace.\")\n                continue\n            inventory = read_inventory(resp_file)   # 读取 RESP 文件作为 inventory\n            # 去除仪器响应\n            tr.remove_response(inventory=inventory, output=\"VEL\", pre_filt=[0.001, 0.002, 0.3, 0.45 ], zero_mean=True, taper=True)\n        output_file = os.path.join(output_folder, os.path.basename(seed_file)) # 输出文件名\n        st.write(output_file, format=\"MSEED\")\n        print(f\"Saved corrected data to {output_file}\\n\")\n    except Exception as e:\n        print(f\"Error processing {seed_file}: {e}\")\n```\n","source":"_posts/2025-04-23-remove-response-miniseed.md","raw":"---\ntitle: 去仪器响应练习\ntags:\n  - python\ncategories:\n  - seismology\nabbrlink: 6d0f71ef\ndate: 2025-04-23 15:14:23\n---\n用我的脚本下载了一堆的miniseed放在seed下，仪器响应文件放在resp文件夹下，利用obspy去除仪器响应，还保存为miniseed。\n```\nimport os\nfrom glob import glob\nfrom obspy import read, read_inventory\n# 设置路径\nseed_folder = \"seed\"\nresp_folder = \"resp\"\noutput_folder = \"seed_corrected\"\nos.makedirs(output_folder, exist_ok=True)\nseed_files = glob(os.path.join(seed_folder, \"*.seed\"))   # 遍历所有 seed 文件\nfor seed_file in seed_files:\n    print(f\"Processing {os.path.basename(seed_file)}\")\n    try:\n        st = read(seed_file)   # 读取 MiniSEED 数据\n        for tr in st:\n            net = tr.stats.network\n            sta = tr.stats.station\n            loc = tr.stats.location\n            cha = tr.stats.channel\n            resp_file = os.path.join(resp_folder, f\"RESP.{net}.{sta}.{loc}.{cha}\") # 构造 RESP 文件路径\n            if not os.path.exists(resp_file):\n                print(f\"RESP file not found: {resp_file}, skipping trace.\")\n                continue\n            inventory = read_inventory(resp_file)   # 读取 RESP 文件作为 inventory\n            # 去除仪器响应\n            tr.remove_response(inventory=inventory, output=\"VEL\", pre_filt=[0.001, 0.002, 0.3, 0.45 ], zero_mean=True, taper=True)\n        output_file = os.path.join(output_folder, os.path.basename(seed_file)) # 输出文件名\n        st.write(output_file, format=\"MSEED\")\n        print(f\"Saved corrected data to {output_file}\\n\")\n    except Exception as e:\n        print(f\"Error processing {seed_file}: {e}\")\n```\n","slug":"remove-response-miniseed","published":1,"updated":"2025-04-23T07:18:54.078Z","comments":1,"layout":"post","photos":[],"_id":"cmh498iqc00bzwvou9lnd56t9","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>用我的脚本下载了一堆的miniseed放在seed下，仪器响应文件放在resp文件夹下，利用obspy去除仪器响应，还保存为miniseed。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">import os</span><br><span class=\"line\">from glob import glob</span><br><span class=\"line\">from obspy import read, read_inventory</span><br><span class=\"line\"># 设置路径</span><br><span class=\"line\">seed_folder = &quot;seed&quot;</span><br><span class=\"line\">resp_folder = &quot;resp&quot;</span><br><span class=\"line\">output_folder = &quot;seed_corrected&quot;</span><br><span class=\"line\">os.makedirs(output_folder, exist_ok=True)</span><br><span class=\"line\">seed_files = glob(os.path.join(seed_folder, &quot;*.seed&quot;))   # 遍历所有 seed 文件</span><br><span class=\"line\">for seed_file in seed_files:</span><br><span class=\"line\">    print(f&quot;Processing &#123;os.path.basename(seed_file)&#125;&quot;)</span><br><span class=\"line\">    try:</span><br><span class=\"line\">        st = read(seed_file)   # 读取 MiniSEED 数据</span><br><span class=\"line\">        for tr in st:</span><br><span class=\"line\">            net = tr.stats.network</span><br><span class=\"line\">            sta = tr.stats.station</span><br><span class=\"line\">            loc = tr.stats.location</span><br><span class=\"line\">            cha = tr.stats.channel</span><br><span class=\"line\">            resp_file = os.path.join(resp_folder, f&quot;RESP.&#123;net&#125;.&#123;sta&#125;.&#123;loc&#125;.&#123;cha&#125;&quot;) # 构造 RESP 文件路径</span><br><span class=\"line\">            if not os.path.exists(resp_file):</span><br><span class=\"line\">                print(f&quot;RESP file not found: &#123;resp_file&#125;, skipping trace.&quot;)</span><br><span class=\"line\">                continue</span><br><span class=\"line\">            inventory = read_inventory(resp_file)   # 读取 RESP 文件作为 inventory</span><br><span class=\"line\">            # 去除仪器响应</span><br><span class=\"line\">            tr.remove_response(inventory=inventory, output=&quot;VEL&quot;, pre_filt=[0.001, 0.002, 0.3, 0.45 ], zero_mean=True, taper=True)</span><br><span class=\"line\">        output_file = os.path.join(output_folder, os.path.basename(seed_file)) # 输出文件名</span><br><span class=\"line\">        st.write(output_file, format=&quot;MSEED&quot;)</span><br><span class=\"line\">        print(f&quot;Saved corrected data to &#123;output_file&#125;\\n&quot;)</span><br><span class=\"line\">    except Exception as e:</span><br><span class=\"line\">        print(f&quot;Error processing &#123;seed_file&#125;: &#123;e&#125;&quot;)</span><br></pre></td></tr></table></figure>\n","related_posts":[],"length":1310,"excerpt":"","more":"<p>用我的脚本下载了一堆的miniseed放在seed下，仪器响应文件放在resp文件夹下，利用obspy去除仪器响应，还保存为miniseed。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">import os</span><br><span class=\"line\">from glob import glob</span><br><span class=\"line\">from obspy import read, read_inventory</span><br><span class=\"line\"># 设置路径</span><br><span class=\"line\">seed_folder = &quot;seed&quot;</span><br><span class=\"line\">resp_folder = &quot;resp&quot;</span><br><span class=\"line\">output_folder = &quot;seed_corrected&quot;</span><br><span class=\"line\">os.makedirs(output_folder, exist_ok=True)</span><br><span class=\"line\">seed_files = glob(os.path.join(seed_folder, &quot;*.seed&quot;))   # 遍历所有 seed 文件</span><br><span class=\"line\">for seed_file in seed_files:</span><br><span class=\"line\">    print(f&quot;Processing &#123;os.path.basename(seed_file)&#125;&quot;)</span><br><span class=\"line\">    try:</span><br><span class=\"line\">        st = read(seed_file)   # 读取 MiniSEED 数据</span><br><span class=\"line\">        for tr in st:</span><br><span class=\"line\">            net = tr.stats.network</span><br><span class=\"line\">            sta = tr.stats.station</span><br><span class=\"line\">            loc = tr.stats.location</span><br><span class=\"line\">            cha = tr.stats.channel</span><br><span class=\"line\">            resp_file = os.path.join(resp_folder, f&quot;RESP.&#123;net&#125;.&#123;sta&#125;.&#123;loc&#125;.&#123;cha&#125;&quot;) # 构造 RESP 文件路径</span><br><span class=\"line\">            if not os.path.exists(resp_file):</span><br><span class=\"line\">                print(f&quot;RESP file not found: &#123;resp_file&#125;, skipping trace.&quot;)</span><br><span class=\"line\">                continue</span><br><span class=\"line\">            inventory = read_inventory(resp_file)   # 读取 RESP 文件作为 inventory</span><br><span class=\"line\">            # 去除仪器响应</span><br><span class=\"line\">            tr.remove_response(inventory=inventory, output=&quot;VEL&quot;, pre_filt=[0.001, 0.002, 0.3, 0.45 ], zero_mean=True, taper=True)</span><br><span class=\"line\">        output_file = os.path.join(output_folder, os.path.basename(seed_file)) # 输出文件名</span><br><span class=\"line\">        st.write(output_file, format=&quot;MSEED&quot;)</span><br><span class=\"line\">        print(f&quot;Saved corrected data to &#123;output_file&#125;\\n&quot;)</span><br><span class=\"line\">    except Exception as e:</span><br><span class=\"line\">        print(f&quot;Error processing &#123;seed_file&#125;: &#123;e&#125;&quot;)</span><br></pre></td></tr></table></figure>\n"},{"title":"下载地震数据练习","abbrlink":"ca92bb2a","date":"2025-04-24T07:33:35.000Z","_content":"&emsp;&emsp;接收函数或者其他方法需要下载地震波形数据。这里给出结合FetchEvent和obspy进行数据下载的例子。\n&emsp;&emsp;FetchEvent从地址https://github.com/EarthScope/fetch-scripts下载。他是用perl脚本写的。运行例子如下：\n```\n./FetchEvent -s 2006-01-01 -e 2007-05-01 --radius 5:12:95:28 --mag 5:10 -o event.lst\n```\n&emsp;&emsp;表示下载发生时间为2006-01-01到2007-05-01，位于以(5,12)(lat,lon)为中心，半径28-95度，震级5-10级的地震信息，保存到event.lst中。\n&emsp;&emsp;下载到的event.lst内容如下：\n```\n8037834 |2006/01/23 20:50:46.19Z |  6.9168| -77.7951|  24.0355|ISC|||MS,5.86,ISC|mb,6.16,ISC|Near west coast of Colombia\n```\n&emsp;&emsp;表示ID|时间|纬度|经度|深度|目录|||震级类型,震级,目录|震级类型,震级,目录|位置\n&emsp;&emsp;可以看出地震信息来自ISC目录，其实到[ISC](https://www.isc.ac.uk/iscbulletin/search/catalogue/)直接检索也很方便。\n\n&emsp;&emsp;接下来，下载XB台网所有台站接收到的地震理论P波到时前50秒到后150秒三分量数据。其中P波到时调用taup来计算。接下来去仪器响应，最后再截取P波前10秒到后60秒。保存为SAC格式，每个地震每个台站保存一个SAC，名称需包含地震时间震级及台站名。利用多线程ThreadPoolExecutor加速。脚本如下：\n```\nimport os\nfrom obspy import UTCDateTime, read_inventory\nfrom obspy.clients.fdsn import Client\nfrom obspy.taup import TauPyModel\nfrom obspy.geodetics import locations2degrees\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\n\nclient = Client(\"IRIS\")\nmodel = TauPyModel(\"iasp91\")\n\noutput_dir = \"processed_sac\"\nos.makedirs(output_dir, exist_ok=True)\n\nevent_file = \"event.lst\"\nexception_log = \"exceptions.txt\"\nthread_workers = 4  # 可调线程数\n\nwith open(event_file, \"r\") as f:\n    event_lines = [line.strip() for line in f if line.strip()]\n\nwith open(exception_log, \"w\") as elog:\n    elog.write(\"\")\n\ndef process_station(event_id, origin_time, magnitude, ev_lat, ev_lon, ev_dep, net, sta, sta_lat, sta_lon, sta_elev):\n    try:\n        # 使用 locations2degrees 计算震中距\n        dist_deg = locations2degrees(ev_lat, ev_lon, sta_lat, sta_lon)\n        print(dist_deg)\n        arrivals = model.get_travel_times(source_depth_in_km=ev_dep,\n                                          distance_in_degree=dist_deg,\n                                          phase_list=[\"P\"])\n        if not arrivals:\n            raise Exception(\"No P arrival\")\n\n        p_arrival = origin_time + arrivals[0].time\n        start_dl = p_arrival - 50\n        end_dl = p_arrival + 150\n\n        # 下载三分量数据\n        st = client.get_waveforms(network=net, station=sta, location=\"*\", channel=\"BH?\",\n                                  starttime=start_dl, endtime=end_dl,\n                                  attach_response=True)\n\n        # 去响应\n        st.remove_response(output=\"VEL\", pre_filt=(0.01, 0.02, 8, 10), taper=True, zero_mean=True, taper_fraction=0.05)\n\n        # 截取有效窗口\n        st.trim(starttime=p_arrival - 10, endtime=p_arrival + 60)\n\n        # 检查是否为三分量\n        if not all(comp in [tr.stats.channel[-1] for tr in st] for comp in [\"N\", \"E\", \"Z\"]):\n            raise Exception(\"Incomplete 3-component data\")\n\n        # 写入 SAC 文件并添加头段信息\n        for tr in st:\n            tr.stats.sac = tr.stats.get(\"sac\", {})\n            tr.stats.sac.stla = sta_lat\n            tr.stats.sac.stlo = sta_lon\n            tr.stats.sac.stel = sta_elev\n            tr.stats.sac.evla = ev_lat\n            tr.stats.sac.evlo = ev_lon\n            tr.stats.sac.evdp = ev_dep\n            tr.stats.sac.mag = float(magnitude) if magnitude != \"NA\" else 0.0\n\n            time_tag = origin_time.strftime(\"%Y%m%dT%H%M%S\")\n            chan = tr.stats.channel\n            filename = f\"{time_tag}_M{magnitude}_{net}.{sta}.{chan}.sac\"\n            filepath = os.path.join(output_dir, filename)\n            tr.write(filepath, format=\"SAC\")\n        return f\"{net}.{sta} ✅\"\n    except Exception as e:\n        with open(exception_log, \"a\") as elog:\n            elog.write(f\"{event_id} {net}.{sta} ❌ {str(e)}\\n\")\n        return f\"{net}.{sta} ❌ {str(e)}\"\n\ndef process_event(line):\n    results = []\n    parts = line.split(\"|\")\n    if len(parts) < 10:\n        return [\"跳过格式错误行\"]\n\n    evid = parts[0].strip()\n    time_str = parts[1].strip()\n    ev_lat = float(parts[2].strip())\n    ev_lon = float(parts[3].strip())\n    ev_dep = float(parts[4].strip())\n    mag_info = parts[8].strip()\n    magnitude = mag_info.split(\",\")[1] if \",\" in mag_info else \"NA\"\n\n    origin_time = UTCDateTime(time_str)\n    print(f\"\\n🟡 Processing event {evid} M{magnitude} @ {origin_time} ({ev_lat}, {ev_lon}, {ev_dep}km)\")\n\n    try:\n        inventory = client.get_stations(network=\"XB\", starttime=origin_time,\n                                        endtime=origin_time + 3600,\n                                        level=\"station\", channel=\"BH?\")\n        task_list = []\n        with ThreadPoolExecutor(max_workers=thread_workers) as executor:\n            for network in inventory:\n                for station in network:\n                    sta_lat = station.latitude\n                    sta_lon = station.longitude\n                    sta_elev = station.elevation\n                    sta = station.code\n                    net = network.code\n                    task = executor.submit(process_station, evid, origin_time, magnitude,\n                                           ev_lat, ev_lon, ev_dep, net, sta, sta_lat, sta_lon, sta_elev)\n                    task_list.append(task)\n\n            for task in as_completed(task_list):\n                results.append(task.result())\n\n    except Exception as e:\n        with open(exception_log, \"a\") as elog:\n            elog.write(f\"{evid} XB ERROR: {str(e)}\\n\")\n        results.append(f\"⚠️ Failed to process event {evid}: {e}\")\n    return results\n\n# 执行所有事件处理\nfor line in event_lines:\n    results = process_event(line)\n    for r in results:\n        print(r)\n```\n","source":"_posts/2025-04-24-download-earthquake-py.md","raw":"---\ntitle: 下载地震数据练习\ntags:\n  - python\ncategories:\n  - seismology\nabbrlink: ca92bb2a\ndate: 2025-04-24 15:33:35\n---\n&emsp;&emsp;接收函数或者其他方法需要下载地震波形数据。这里给出结合FetchEvent和obspy进行数据下载的例子。\n&emsp;&emsp;FetchEvent从地址https://github.com/EarthScope/fetch-scripts下载。他是用perl脚本写的。运行例子如下：\n```\n./FetchEvent -s 2006-01-01 -e 2007-05-01 --radius 5:12:95:28 --mag 5:10 -o event.lst\n```\n&emsp;&emsp;表示下载发生时间为2006-01-01到2007-05-01，位于以(5,12)(lat,lon)为中心，半径28-95度，震级5-10级的地震信息，保存到event.lst中。\n&emsp;&emsp;下载到的event.lst内容如下：\n```\n8037834 |2006/01/23 20:50:46.19Z |  6.9168| -77.7951|  24.0355|ISC|||MS,5.86,ISC|mb,6.16,ISC|Near west coast of Colombia\n```\n&emsp;&emsp;表示ID|时间|纬度|经度|深度|目录|||震级类型,震级,目录|震级类型,震级,目录|位置\n&emsp;&emsp;可以看出地震信息来自ISC目录，其实到[ISC](https://www.isc.ac.uk/iscbulletin/search/catalogue/)直接检索也很方便。\n\n&emsp;&emsp;接下来，下载XB台网所有台站接收到的地震理论P波到时前50秒到后150秒三分量数据。其中P波到时调用taup来计算。接下来去仪器响应，最后再截取P波前10秒到后60秒。保存为SAC格式，每个地震每个台站保存一个SAC，名称需包含地震时间震级及台站名。利用多线程ThreadPoolExecutor加速。脚本如下：\n```\nimport os\nfrom obspy import UTCDateTime, read_inventory\nfrom obspy.clients.fdsn import Client\nfrom obspy.taup import TauPyModel\nfrom obspy.geodetics import locations2degrees\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\n\nclient = Client(\"IRIS\")\nmodel = TauPyModel(\"iasp91\")\n\noutput_dir = \"processed_sac\"\nos.makedirs(output_dir, exist_ok=True)\n\nevent_file = \"event.lst\"\nexception_log = \"exceptions.txt\"\nthread_workers = 4  # 可调线程数\n\nwith open(event_file, \"r\") as f:\n    event_lines = [line.strip() for line in f if line.strip()]\n\nwith open(exception_log, \"w\") as elog:\n    elog.write(\"\")\n\ndef process_station(event_id, origin_time, magnitude, ev_lat, ev_lon, ev_dep, net, sta, sta_lat, sta_lon, sta_elev):\n    try:\n        # 使用 locations2degrees 计算震中距\n        dist_deg = locations2degrees(ev_lat, ev_lon, sta_lat, sta_lon)\n        print(dist_deg)\n        arrivals = model.get_travel_times(source_depth_in_km=ev_dep,\n                                          distance_in_degree=dist_deg,\n                                          phase_list=[\"P\"])\n        if not arrivals:\n            raise Exception(\"No P arrival\")\n\n        p_arrival = origin_time + arrivals[0].time\n        start_dl = p_arrival - 50\n        end_dl = p_arrival + 150\n\n        # 下载三分量数据\n        st = client.get_waveforms(network=net, station=sta, location=\"*\", channel=\"BH?\",\n                                  starttime=start_dl, endtime=end_dl,\n                                  attach_response=True)\n\n        # 去响应\n        st.remove_response(output=\"VEL\", pre_filt=(0.01, 0.02, 8, 10), taper=True, zero_mean=True, taper_fraction=0.05)\n\n        # 截取有效窗口\n        st.trim(starttime=p_arrival - 10, endtime=p_arrival + 60)\n\n        # 检查是否为三分量\n        if not all(comp in [tr.stats.channel[-1] for tr in st] for comp in [\"N\", \"E\", \"Z\"]):\n            raise Exception(\"Incomplete 3-component data\")\n\n        # 写入 SAC 文件并添加头段信息\n        for tr in st:\n            tr.stats.sac = tr.stats.get(\"sac\", {})\n            tr.stats.sac.stla = sta_lat\n            tr.stats.sac.stlo = sta_lon\n            tr.stats.sac.stel = sta_elev\n            tr.stats.sac.evla = ev_lat\n            tr.stats.sac.evlo = ev_lon\n            tr.stats.sac.evdp = ev_dep\n            tr.stats.sac.mag = float(magnitude) if magnitude != \"NA\" else 0.0\n\n            time_tag = origin_time.strftime(\"%Y%m%dT%H%M%S\")\n            chan = tr.stats.channel\n            filename = f\"{time_tag}_M{magnitude}_{net}.{sta}.{chan}.sac\"\n            filepath = os.path.join(output_dir, filename)\n            tr.write(filepath, format=\"SAC\")\n        return f\"{net}.{sta} ✅\"\n    except Exception as e:\n        with open(exception_log, \"a\") as elog:\n            elog.write(f\"{event_id} {net}.{sta} ❌ {str(e)}\\n\")\n        return f\"{net}.{sta} ❌ {str(e)}\"\n\ndef process_event(line):\n    results = []\n    parts = line.split(\"|\")\n    if len(parts) < 10:\n        return [\"跳过格式错误行\"]\n\n    evid = parts[0].strip()\n    time_str = parts[1].strip()\n    ev_lat = float(parts[2].strip())\n    ev_lon = float(parts[3].strip())\n    ev_dep = float(parts[4].strip())\n    mag_info = parts[8].strip()\n    magnitude = mag_info.split(\",\")[1] if \",\" in mag_info else \"NA\"\n\n    origin_time = UTCDateTime(time_str)\n    print(f\"\\n🟡 Processing event {evid} M{magnitude} @ {origin_time} ({ev_lat}, {ev_lon}, {ev_dep}km)\")\n\n    try:\n        inventory = client.get_stations(network=\"XB\", starttime=origin_time,\n                                        endtime=origin_time + 3600,\n                                        level=\"station\", channel=\"BH?\")\n        task_list = []\n        with ThreadPoolExecutor(max_workers=thread_workers) as executor:\n            for network in inventory:\n                for station in network:\n                    sta_lat = station.latitude\n                    sta_lon = station.longitude\n                    sta_elev = station.elevation\n                    sta = station.code\n                    net = network.code\n                    task = executor.submit(process_station, evid, origin_time, magnitude,\n                                           ev_lat, ev_lon, ev_dep, net, sta, sta_lat, sta_lon, sta_elev)\n                    task_list.append(task)\n\n            for task in as_completed(task_list):\n                results.append(task.result())\n\n    except Exception as e:\n        with open(exception_log, \"a\") as elog:\n            elog.write(f\"{evid} XB ERROR: {str(e)}\\n\")\n        results.append(f\"⚠️ Failed to process event {evid}: {e}\")\n    return results\n\n# 执行所有事件处理\nfor line in event_lines:\n    results = process_event(line)\n    for r in results:\n        print(r)\n```\n","slug":"download-earthquake-py","published":1,"updated":"2025-05-16T06:41:59.516Z","comments":1,"layout":"post","photos":[],"_id":"cmh498iqd00c3wvou6v5480u5","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>&emsp;&emsp;接收函数或者其他方法需要下载地震波形数据。这里给出结合FetchEvent和obspy进行数据下载的例子。<br>&emsp;&emsp;FetchEvent从地址<a href=\"https://github.com/EarthScope/fetch-scripts%E4%B8%8B%E8%BD%BD%E3%80%82%E4%BB%96%E6%98%AF%E7%94%A8perl%E8%84%9A%E6%9C%AC%E5%86%99%E7%9A%84%E3%80%82%E8%BF%90%E8%A1%8C%E4%BE%8B%E5%AD%90%E5%A6%82%E4%B8%8B%EF%BC%9A\">https://github.com/EarthScope/fetch-scripts下载。他是用perl脚本写的。运行例子如下：</a></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">./FetchEvent -s 2006-01-01 -e 2007-05-01 --radius 5:12:95:28 --mag 5:10 -o event.lst</span><br></pre></td></tr></table></figure>\n<p>&emsp;&emsp;表示下载发生时间为2006-01-01到2007-05-01，位于以(5,12)(lat,lon)为中心，半径28-95度，震级5-10级的地震信息，保存到event.lst中。<br>&emsp;&emsp;下载到的event.lst内容如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">8037834 |2006/01/23 20:50:46.19Z |  6.9168| -77.7951|  24.0355|ISC|||MS,5.86,ISC|mb,6.16,ISC|Near west coast of Colombia</span><br></pre></td></tr></table></figure>\n<p>&emsp;&emsp;表示ID|时间|纬度|经度|深度|目录|||震级类型,震级,目录|震级类型,震级,目录|位置<br>&emsp;&emsp;可以看出地震信息来自ISC目录，其实到<a href=\"https://www.isc.ac.uk/iscbulletin/search/catalogue/\">ISC</a>直接检索也很方便。</p>\n<p>&emsp;&emsp;接下来，下载XB台网所有台站接收到的地震理论P波到时前50秒到后150秒三分量数据。其中P波到时调用taup来计算。接下来去仪器响应，最后再截取P波前10秒到后60秒。保存为SAC格式，每个地震每个台站保存一个SAC，名称需包含地震时间震级及台站名。利用多线程ThreadPoolExecutor加速。脚本如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">import os</span><br><span class=\"line\">from obspy import UTCDateTime, read_inventory</span><br><span class=\"line\">from obspy.clients.fdsn import Client</span><br><span class=\"line\">from obspy.taup import TauPyModel</span><br><span class=\"line\">from obspy.geodetics import locations2degrees</span><br><span class=\"line\">from concurrent.futures import ThreadPoolExecutor, as_completed</span><br><span class=\"line\"></span><br><span class=\"line\">client = Client(&quot;IRIS&quot;)</span><br><span class=\"line\">model = TauPyModel(&quot;iasp91&quot;)</span><br><span class=\"line\"></span><br><span class=\"line\">output_dir = &quot;processed_sac&quot;</span><br><span class=\"line\">os.makedirs(output_dir, exist_ok=True)</span><br><span class=\"line\"></span><br><span class=\"line\">event_file = &quot;event.lst&quot;</span><br><span class=\"line\">exception_log = &quot;exceptions.txt&quot;</span><br><span class=\"line\">thread_workers = 4  # 可调线程数</span><br><span class=\"line\"></span><br><span class=\"line\">with open(event_file, &quot;r&quot;) as f:</span><br><span class=\"line\">    event_lines = [line.strip() for line in f if line.strip()]</span><br><span class=\"line\"></span><br><span class=\"line\">with open(exception_log, &quot;w&quot;) as elog:</span><br><span class=\"line\">    elog.write(&quot;&quot;)</span><br><span class=\"line\"></span><br><span class=\"line\">def process_station(event_id, origin_time, magnitude, ev_lat, ev_lon, ev_dep, net, sta, sta_lat, sta_lon, sta_elev):</span><br><span class=\"line\">    try:</span><br><span class=\"line\">        # 使用 locations2degrees 计算震中距</span><br><span class=\"line\">        dist_deg = locations2degrees(ev_lat, ev_lon, sta_lat, sta_lon)</span><br><span class=\"line\">        print(dist_deg)</span><br><span class=\"line\">        arrivals = model.get_travel_times(source_depth_in_km=ev_dep,</span><br><span class=\"line\">                                          distance_in_degree=dist_deg,</span><br><span class=\"line\">                                          phase_list=[&quot;P&quot;])</span><br><span class=\"line\">        if not arrivals:</span><br><span class=\"line\">            raise Exception(&quot;No P arrival&quot;)</span><br><span class=\"line\"></span><br><span class=\"line\">        p_arrival = origin_time + arrivals[0].time</span><br><span class=\"line\">        start_dl = p_arrival - 50</span><br><span class=\"line\">        end_dl = p_arrival + 150</span><br><span class=\"line\"></span><br><span class=\"line\">        # 下载三分量数据</span><br><span class=\"line\">        st = client.get_waveforms(network=net, station=sta, location=&quot;*&quot;, channel=&quot;BH?&quot;,</span><br><span class=\"line\">                                  starttime=start_dl, endtime=end_dl,</span><br><span class=\"line\">                                  attach_response=True)</span><br><span class=\"line\"></span><br><span class=\"line\">        # 去响应</span><br><span class=\"line\">        st.remove_response(output=&quot;VEL&quot;, pre_filt=(0.01, 0.02, 8, 10), taper=True, zero_mean=True, taper_fraction=0.05)</span><br><span class=\"line\"></span><br><span class=\"line\">        # 截取有效窗口</span><br><span class=\"line\">        st.trim(starttime=p_arrival - 10, endtime=p_arrival + 60)</span><br><span class=\"line\"></span><br><span class=\"line\">        # 检查是否为三分量</span><br><span class=\"line\">        if not all(comp in [tr.stats.channel[-1] for tr in st] for comp in [&quot;N&quot;, &quot;E&quot;, &quot;Z&quot;]):</span><br><span class=\"line\">            raise Exception(&quot;Incomplete 3-component data&quot;)</span><br><span class=\"line\"></span><br><span class=\"line\">        # 写入 SAC 文件并添加头段信息</span><br><span class=\"line\">        for tr in st:</span><br><span class=\"line\">            tr.stats.sac = tr.stats.get(&quot;sac&quot;, &#123;&#125;)</span><br><span class=\"line\">            tr.stats.sac.stla = sta_lat</span><br><span class=\"line\">            tr.stats.sac.stlo = sta_lon</span><br><span class=\"line\">            tr.stats.sac.stel = sta_elev</span><br><span class=\"line\">            tr.stats.sac.evla = ev_lat</span><br><span class=\"line\">            tr.stats.sac.evlo = ev_lon</span><br><span class=\"line\">            tr.stats.sac.evdp = ev_dep</span><br><span class=\"line\">            tr.stats.sac.mag = float(magnitude) if magnitude != &quot;NA&quot; else 0.0</span><br><span class=\"line\"></span><br><span class=\"line\">            time_tag = origin_time.strftime(&quot;%Y%m%dT%H%M%S&quot;)</span><br><span class=\"line\">            chan = tr.stats.channel</span><br><span class=\"line\">            filename = f&quot;&#123;time_tag&#125;_M&#123;magnitude&#125;_&#123;net&#125;.&#123;sta&#125;.&#123;chan&#125;.sac&quot;</span><br><span class=\"line\">            filepath = os.path.join(output_dir, filename)</span><br><span class=\"line\">            tr.write(filepath, format=&quot;SAC&quot;)</span><br><span class=\"line\">        return f&quot;&#123;net&#125;.&#123;sta&#125; ✅&quot;</span><br><span class=\"line\">    except Exception as e:</span><br><span class=\"line\">        with open(exception_log, &quot;a&quot;) as elog:</span><br><span class=\"line\">            elog.write(f&quot;&#123;event_id&#125; &#123;net&#125;.&#123;sta&#125; ❌ &#123;str(e)&#125;\\n&quot;)</span><br><span class=\"line\">        return f&quot;&#123;net&#125;.&#123;sta&#125; ❌ &#123;str(e)&#125;&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">def process_event(line):</span><br><span class=\"line\">    results = []</span><br><span class=\"line\">    parts = line.split(&quot;|&quot;)</span><br><span class=\"line\">    if len(parts) &lt; 10:</span><br><span class=\"line\">        return [&quot;跳过格式错误行&quot;]</span><br><span class=\"line\"></span><br><span class=\"line\">    evid = parts[0].strip()</span><br><span class=\"line\">    time_str = parts[1].strip()</span><br><span class=\"line\">    ev_lat = float(parts[2].strip())</span><br><span class=\"line\">    ev_lon = float(parts[3].strip())</span><br><span class=\"line\">    ev_dep = float(parts[4].strip())</span><br><span class=\"line\">    mag_info = parts[8].strip()</span><br><span class=\"line\">    magnitude = mag_info.split(&quot;,&quot;)[1] if &quot;,&quot; in mag_info else &quot;NA&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">    origin_time = UTCDateTime(time_str)</span><br><span class=\"line\">    print(f&quot;\\n🟡 Processing event &#123;evid&#125; M&#123;magnitude&#125; @ &#123;origin_time&#125; (&#123;ev_lat&#125;, &#123;ev_lon&#125;, &#123;ev_dep&#125;km)&quot;)</span><br><span class=\"line\"></span><br><span class=\"line\">    try:</span><br><span class=\"line\">        inventory = client.get_stations(network=&quot;XB&quot;, starttime=origin_time,</span><br><span class=\"line\">                                        endtime=origin_time + 3600,</span><br><span class=\"line\">                                        level=&quot;station&quot;, channel=&quot;BH?&quot;)</span><br><span class=\"line\">        task_list = []</span><br><span class=\"line\">        with ThreadPoolExecutor(max_workers=thread_workers) as executor:</span><br><span class=\"line\">            for network in inventory:</span><br><span class=\"line\">                for station in network:</span><br><span class=\"line\">                    sta_lat = station.latitude</span><br><span class=\"line\">                    sta_lon = station.longitude</span><br><span class=\"line\">                    sta_elev = station.elevation</span><br><span class=\"line\">                    sta = station.code</span><br><span class=\"line\">                    net = network.code</span><br><span class=\"line\">                    task = executor.submit(process_station, evid, origin_time, magnitude,</span><br><span class=\"line\">                                           ev_lat, ev_lon, ev_dep, net, sta, sta_lat, sta_lon, sta_elev)</span><br><span class=\"line\">                    task_list.append(task)</span><br><span class=\"line\"></span><br><span class=\"line\">            for task in as_completed(task_list):</span><br><span class=\"line\">                results.append(task.result())</span><br><span class=\"line\"></span><br><span class=\"line\">    except Exception as e:</span><br><span class=\"line\">        with open(exception_log, &quot;a&quot;) as elog:</span><br><span class=\"line\">            elog.write(f&quot;&#123;evid&#125; XB ERROR: &#123;str(e)&#125;\\n&quot;)</span><br><span class=\"line\">        results.append(f&quot;⚠️ Failed to process event &#123;evid&#125;: &#123;e&#125;&quot;)</span><br><span class=\"line\">    return results</span><br><span class=\"line\"></span><br><span class=\"line\"># 执行所有事件处理</span><br><span class=\"line\">for line in event_lines:</span><br><span class=\"line\">    results = process_event(line)</span><br><span class=\"line\">    for r in results:</span><br><span class=\"line\">        print(r)</span><br></pre></td></tr></table></figure>\n","related_posts":["download-continous-data-update.html"],"length":4837,"excerpt":"","more":"<p>&emsp;&emsp;接收函数或者其他方法需要下载地震波形数据。这里给出结合FetchEvent和obspy进行数据下载的例子。<br>&emsp;&emsp;FetchEvent从地址<a href=\"https://github.com/EarthScope/fetch-scripts%E4%B8%8B%E8%BD%BD%E3%80%82%E4%BB%96%E6%98%AF%E7%94%A8perl%E8%84%9A%E6%9C%AC%E5%86%99%E7%9A%84%E3%80%82%E8%BF%90%E8%A1%8C%E4%BE%8B%E5%AD%90%E5%A6%82%E4%B8%8B%EF%BC%9A\">https://github.com/EarthScope/fetch-scripts下载。他是用perl脚本写的。运行例子如下：</a></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">./FetchEvent -s 2006-01-01 -e 2007-05-01 --radius 5:12:95:28 --mag 5:10 -o event.lst</span><br></pre></td></tr></table></figure>\n<p>&emsp;&emsp;表示下载发生时间为2006-01-01到2007-05-01，位于以(5,12)(lat,lon)为中心，半径28-95度，震级5-10级的地震信息，保存到event.lst中。<br>&emsp;&emsp;下载到的event.lst内容如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">8037834 |2006/01/23 20:50:46.19Z |  6.9168| -77.7951|  24.0355|ISC|||MS,5.86,ISC|mb,6.16,ISC|Near west coast of Colombia</span><br></pre></td></tr></table></figure>\n<p>&emsp;&emsp;表示ID|时间|纬度|经度|深度|目录|||震级类型,震级,目录|震级类型,震级,目录|位置<br>&emsp;&emsp;可以看出地震信息来自ISC目录，其实到<a href=\"https://www.isc.ac.uk/iscbulletin/search/catalogue/\">ISC</a>直接检索也很方便。</p>\n<p>&emsp;&emsp;接下来，下载XB台网所有台站接收到的地震理论P波到时前50秒到后150秒三分量数据。其中P波到时调用taup来计算。接下来去仪器响应，最后再截取P波前10秒到后60秒。保存为SAC格式，每个地震每个台站保存一个SAC，名称需包含地震时间震级及台站名。利用多线程ThreadPoolExecutor加速。脚本如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">import os</span><br><span class=\"line\">from obspy import UTCDateTime, read_inventory</span><br><span class=\"line\">from obspy.clients.fdsn import Client</span><br><span class=\"line\">from obspy.taup import TauPyModel</span><br><span class=\"line\">from obspy.geodetics import locations2degrees</span><br><span class=\"line\">from concurrent.futures import ThreadPoolExecutor, as_completed</span><br><span class=\"line\"></span><br><span class=\"line\">client = Client(&quot;IRIS&quot;)</span><br><span class=\"line\">model = TauPyModel(&quot;iasp91&quot;)</span><br><span class=\"line\"></span><br><span class=\"line\">output_dir = &quot;processed_sac&quot;</span><br><span class=\"line\">os.makedirs(output_dir, exist_ok=True)</span><br><span class=\"line\"></span><br><span class=\"line\">event_file = &quot;event.lst&quot;</span><br><span class=\"line\">exception_log = &quot;exceptions.txt&quot;</span><br><span class=\"line\">thread_workers = 4  # 可调线程数</span><br><span class=\"line\"></span><br><span class=\"line\">with open(event_file, &quot;r&quot;) as f:</span><br><span class=\"line\">    event_lines = [line.strip() for line in f if line.strip()]</span><br><span class=\"line\"></span><br><span class=\"line\">with open(exception_log, &quot;w&quot;) as elog:</span><br><span class=\"line\">    elog.write(&quot;&quot;)</span><br><span class=\"line\"></span><br><span class=\"line\">def process_station(event_id, origin_time, magnitude, ev_lat, ev_lon, ev_dep, net, sta, sta_lat, sta_lon, sta_elev):</span><br><span class=\"line\">    try:</span><br><span class=\"line\">        # 使用 locations2degrees 计算震中距</span><br><span class=\"line\">        dist_deg = locations2degrees(ev_lat, ev_lon, sta_lat, sta_lon)</span><br><span class=\"line\">        print(dist_deg)</span><br><span class=\"line\">        arrivals = model.get_travel_times(source_depth_in_km=ev_dep,</span><br><span class=\"line\">                                          distance_in_degree=dist_deg,</span><br><span class=\"line\">                                          phase_list=[&quot;P&quot;])</span><br><span class=\"line\">        if not arrivals:</span><br><span class=\"line\">            raise Exception(&quot;No P arrival&quot;)</span><br><span class=\"line\"></span><br><span class=\"line\">        p_arrival = origin_time + arrivals[0].time</span><br><span class=\"line\">        start_dl = p_arrival - 50</span><br><span class=\"line\">        end_dl = p_arrival + 150</span><br><span class=\"line\"></span><br><span class=\"line\">        # 下载三分量数据</span><br><span class=\"line\">        st = client.get_waveforms(network=net, station=sta, location=&quot;*&quot;, channel=&quot;BH?&quot;,</span><br><span class=\"line\">                                  starttime=start_dl, endtime=end_dl,</span><br><span class=\"line\">                                  attach_response=True)</span><br><span class=\"line\"></span><br><span class=\"line\">        # 去响应</span><br><span class=\"line\">        st.remove_response(output=&quot;VEL&quot;, pre_filt=(0.01, 0.02, 8, 10), taper=True, zero_mean=True, taper_fraction=0.05)</span><br><span class=\"line\"></span><br><span class=\"line\">        # 截取有效窗口</span><br><span class=\"line\">        st.trim(starttime=p_arrival - 10, endtime=p_arrival + 60)</span><br><span class=\"line\"></span><br><span class=\"line\">        # 检查是否为三分量</span><br><span class=\"line\">        if not all(comp in [tr.stats.channel[-1] for tr in st] for comp in [&quot;N&quot;, &quot;E&quot;, &quot;Z&quot;]):</span><br><span class=\"line\">            raise Exception(&quot;Incomplete 3-component data&quot;)</span><br><span class=\"line\"></span><br><span class=\"line\">        # 写入 SAC 文件并添加头段信息</span><br><span class=\"line\">        for tr in st:</span><br><span class=\"line\">            tr.stats.sac = tr.stats.get(&quot;sac&quot;, &#123;&#125;)</span><br><span class=\"line\">            tr.stats.sac.stla = sta_lat</span><br><span class=\"line\">            tr.stats.sac.stlo = sta_lon</span><br><span class=\"line\">            tr.stats.sac.stel = sta_elev</span><br><span class=\"line\">            tr.stats.sac.evla = ev_lat</span><br><span class=\"line\">            tr.stats.sac.evlo = ev_lon</span><br><span class=\"line\">            tr.stats.sac.evdp = ev_dep</span><br><span class=\"line\">            tr.stats.sac.mag = float(magnitude) if magnitude != &quot;NA&quot; else 0.0</span><br><span class=\"line\"></span><br><span class=\"line\">            time_tag = origin_time.strftime(&quot;%Y%m%dT%H%M%S&quot;)</span><br><span class=\"line\">            chan = tr.stats.channel</span><br><span class=\"line\">            filename = f&quot;&#123;time_tag&#125;_M&#123;magnitude&#125;_&#123;net&#125;.&#123;sta&#125;.&#123;chan&#125;.sac&quot;</span><br><span class=\"line\">            filepath = os.path.join(output_dir, filename)</span><br><span class=\"line\">            tr.write(filepath, format=&quot;SAC&quot;)</span><br><span class=\"line\">        return f&quot;&#123;net&#125;.&#123;sta&#125; ✅&quot;</span><br><span class=\"line\">    except Exception as e:</span><br><span class=\"line\">        with open(exception_log, &quot;a&quot;) as elog:</span><br><span class=\"line\">            elog.write(f&quot;&#123;event_id&#125; &#123;net&#125;.&#123;sta&#125; ❌ &#123;str(e)&#125;\\n&quot;)</span><br><span class=\"line\">        return f&quot;&#123;net&#125;.&#123;sta&#125; ❌ &#123;str(e)&#125;&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">def process_event(line):</span><br><span class=\"line\">    results = []</span><br><span class=\"line\">    parts = line.split(&quot;|&quot;)</span><br><span class=\"line\">    if len(parts) &lt; 10:</span><br><span class=\"line\">        return [&quot;跳过格式错误行&quot;]</span><br><span class=\"line\"></span><br><span class=\"line\">    evid = parts[0].strip()</span><br><span class=\"line\">    time_str = parts[1].strip()</span><br><span class=\"line\">    ev_lat = float(parts[2].strip())</span><br><span class=\"line\">    ev_lon = float(parts[3].strip())</span><br><span class=\"line\">    ev_dep = float(parts[4].strip())</span><br><span class=\"line\">    mag_info = parts[8].strip()</span><br><span class=\"line\">    magnitude = mag_info.split(&quot;,&quot;)[1] if &quot;,&quot; in mag_info else &quot;NA&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">    origin_time = UTCDateTime(time_str)</span><br><span class=\"line\">    print(f&quot;\\n🟡 Processing event &#123;evid&#125; M&#123;magnitude&#125; @ &#123;origin_time&#125; (&#123;ev_lat&#125;, &#123;ev_lon&#125;, &#123;ev_dep&#125;km)&quot;)</span><br><span class=\"line\"></span><br><span class=\"line\">    try:</span><br><span class=\"line\">        inventory = client.get_stations(network=&quot;XB&quot;, starttime=origin_time,</span><br><span class=\"line\">                                        endtime=origin_time + 3600,</span><br><span class=\"line\">                                        level=&quot;station&quot;, channel=&quot;BH?&quot;)</span><br><span class=\"line\">        task_list = []</span><br><span class=\"line\">        with ThreadPoolExecutor(max_workers=thread_workers) as executor:</span><br><span class=\"line\">            for network in inventory:</span><br><span class=\"line\">                for station in network:</span><br><span class=\"line\">                    sta_lat = station.latitude</span><br><span class=\"line\">                    sta_lon = station.longitude</span><br><span class=\"line\">                    sta_elev = station.elevation</span><br><span class=\"line\">                    sta = station.code</span><br><span class=\"line\">                    net = network.code</span><br><span class=\"line\">                    task = executor.submit(process_station, evid, origin_time, magnitude,</span><br><span class=\"line\">                                           ev_lat, ev_lon, ev_dep, net, sta, sta_lat, sta_lon, sta_elev)</span><br><span class=\"line\">                    task_list.append(task)</span><br><span class=\"line\"></span><br><span class=\"line\">            for task in as_completed(task_list):</span><br><span class=\"line\">                results.append(task.result())</span><br><span class=\"line\"></span><br><span class=\"line\">    except Exception as e:</span><br><span class=\"line\">        with open(exception_log, &quot;a&quot;) as elog:</span><br><span class=\"line\">            elog.write(f&quot;&#123;evid&#125; XB ERROR: &#123;str(e)&#125;\\n&quot;)</span><br><span class=\"line\">        results.append(f&quot;⚠️ Failed to process event &#123;evid&#125;: &#123;e&#125;&quot;)</span><br><span class=\"line\">    return results</span><br><span class=\"line\"></span><br><span class=\"line\"># 执行所有事件处理</span><br><span class=\"line\">for line in event_lines:</span><br><span class=\"line\">    results = process_event(line)</span><br><span class=\"line\">    for r in results:</span><br><span class=\"line\">        print(r)</span><br></pre></td></tr></table></figure>\n"},{"title":"gmt怎么画箭头","abbrlink":"633f0a25","date":"2025-05-10T07:32:41.000Z","_content":"&emsp;&emsp;用gmt画箭头还是挺常见的。[GMT document](https://docs.generic-mapping-tools.org/dev/plot.html)和[GMT中文手册](https://docs.gmt-china.org/latest/basis/vector/)虽好，但如果网络不好不就歇菜了，还是记录一下吧，自己翻起来方便。画箭头参数是Sv(或SV)，自己调Sv之后的参数可以看效果。输入参数表示是x，y，angle，length。x，y表示箭头的起始坐标。angle是箭头指向，逆时针为正，x轴正向为0。length就是那个length了。\n```\necho 0 0 60 0.5i | gmt psxy -R -J -O -K -Sv0.25c+e0.2c -W0.5p -Gblack >>$ps\n```\n\n","source":"_posts/2025-05-10-gmt-arrow.md","raw":"---\ntitle: gmt怎么画箭头\ntags:\n  - gmt\n  - script\ncategories:\n  - gmt\nabbrlink: 633f0a25\ndate: 2025-05-10 15:32:41\n---\n&emsp;&emsp;用gmt画箭头还是挺常见的。[GMT document](https://docs.generic-mapping-tools.org/dev/plot.html)和[GMT中文手册](https://docs.gmt-china.org/latest/basis/vector/)虽好，但如果网络不好不就歇菜了，还是记录一下吧，自己翻起来方便。画箭头参数是Sv(或SV)，自己调Sv之后的参数可以看效果。输入参数表示是x，y，angle，length。x，y表示箭头的起始坐标。angle是箭头指向，逆时针为正，x轴正向为0。length就是那个length了。\n```\necho 0 0 60 0.5i | gmt psxy -R -J -O -K -Sv0.25c+e0.2c -W0.5p -Gblack >>$ps\n```\n\n","slug":"gmt-arrow","published":1,"updated":"2025-05-11T02:23:21.948Z","comments":1,"layout":"post","photos":[],"_id":"cmh498iqd00c7wvouhtlrfad4","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>&emsp;&emsp;用gmt画箭头还是挺常见的。<a href=\"https://docs.generic-mapping-tools.org/dev/plot.html\">GMT document</a>和<a href=\"https://docs.gmt-china.org/latest/basis/vector/\">GMT中文手册</a>虽好，但如果网络不好不就歇菜了，还是记录一下吧，自己翻起来方便。画箭头参数是Sv(或SV)，自己调Sv之后的参数可以看效果。输入参数表示是x，y，angle，length。x，y表示箭头的起始坐标。angle是箭头指向，逆时针为正，x轴正向为0。length就是那个length了。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">echo 0 0 60 0.5i | gmt psxy -R -J -O -K -Sv0.25c+e0.2c -W0.5p -Gblack &gt;&gt;$ps</span><br></pre></td></tr></table></figure>\n\n","related_posts":[],"length":253,"excerpt":"","more":"<p>&emsp;&emsp;用gmt画箭头还是挺常见的。<a href=\"https://docs.generic-mapping-tools.org/dev/plot.html\">GMT document</a>和<a href=\"https://docs.gmt-china.org/latest/basis/vector/\">GMT中文手册</a>虽好，但如果网络不好不就歇菜了，还是记录一下吧，自己翻起来方便。画箭头参数是Sv(或SV)，自己调Sv之后的参数可以看效果。输入参数表示是x，y，angle，length。x，y表示箭头的起始坐标。angle是箭头指向，逆时针为正，x轴正向为0。length就是那个length了。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">echo 0 0 60 0.5i | gmt psxy -R -J -O -K -Sv0.25c+e0.2c -W0.5p -Gblack &gt;&gt;$ps</span><br></pre></td></tr></table></figure>\n\n"},{"title":"鼠标点击位置记录","abbrlink":"1da3e56a","date":"2025-05-10T07:43:38.000Z","_content":"&emsp;&emsp;有些时候需要抓取别人图片中的点的信息，应该怎么整？当然是找作者要咯！不过有时可能没办法（例如可能联系不上作者/作者找不到数据了/作者不想给你/作者说你自己提取吧）或则并不需要他图片中的点的准确信息的时候，我们可以自己去点。之前有个perl脚本，但找不到了（这又体现了整理资料和做笔记的必要性），现在python很方便的，调用pynput的Listener就好了。记录鼠标点击的脚本如下：\n```\nfrom pynput.mouse import Listener\nimport logging\nfrom datetime import datetime\n\n# 配置日志记录\nlogging.basicConfig(\n    filename=\"mouse_clicks.log\",\n    level=logging.INFO,\n    format=\"%(asctime)s %(message)s\",\n    datefmt=\"%Y-%m-%dT%H:%M:%S\"\n)\n\ndef on_click(x, y, button, pressed):\n    if pressed:\n        message = f\"{x} {y}\"\n        print(message)  # 输出到屏幕\n        logging.info(message)  # 写入日志文件\n        if button == button.right:\n            # 停止监听器\n            return False\n\n# 启动鼠标监听器\nwith Listener(on_click=on_click) as listener:\n    try:\n        listener.join()\n    except KeyboardInterrupt:\n        print(\"监听器已被用户中断。\")\n```\n&emsp;&emsp;这个脚本会记录鼠标左键的位置，输出到mouse_clicks.log文件中。mouse_clicks.log文件有三列:\n\n2025-05-07T17:01:33 1977 1576\n\n分别表示点击的时间，x和y坐标。其中y坐标是下面大上面小。此外点击鼠标右键或者输入Ctrl+C就可以结束记录。我一般是怎么做的呢？我先点击图片左下角得到（x0,y0），点击右下角得到(x1,y0)，点击左上角得到(x0,y1)，然后点击你想要的点。得到mouse_clicks.log以后就可以这么画图（gmt）。\n```\ndat=mouse_clicks.log\n#获得x0,y0,x1,y1，他们是参考点\nx0=`awk 'NR==1{print $2}' ${dat}`\ny0=`awk 'NR==1{print $3}' ${dat}`\nx1=`awk 'NR==2{print $2}' ${dat}`\ny1=`awk 'NR==3{print $3}' ${dat}`\n#获得横纵轴长度（屏幕尺度）\nxs=`echo \"$x1-$x0\" |bc` \nys=`echo \"$y0-$y1\" |bc`\n\nawk -v x0=$x0 -v y0=$y0 -v xs=$xs -v ys=$ys 'NR>3{print ($2-x0)/xs*2000-1000,(y0-$3)/ys*1500}' ${dat} | gmt psxy -R -J -O -K -W3p,black >>$ps\n#这里（2000，1500）是横纵轴实际尺度，-1000表示实际位置调整。\n```\n&emsp;&emsp;注意，这种方法仅仅适用于线性笛卡尔坐标，其他的各种投影都不行。\n&emsp;&emsp;以后得加上这句：脚本/程序不保证正确性，自求多幅(no warranty/use at your own risk)。\n","source":"_posts/2025-05-10-mouse-click-monitoring.md","raw":"---\ntitle: 鼠标点击位置记录\ntags:\n  - python\ncategories:\n  - work\nabbrlink: 1da3e56a\ndate: 2025-05-10 15:43:38\n---\n&emsp;&emsp;有些时候需要抓取别人图片中的点的信息，应该怎么整？当然是找作者要咯！不过有时可能没办法（例如可能联系不上作者/作者找不到数据了/作者不想给你/作者说你自己提取吧）或则并不需要他图片中的点的准确信息的时候，我们可以自己去点。之前有个perl脚本，但找不到了（这又体现了整理资料和做笔记的必要性），现在python很方便的，调用pynput的Listener就好了。记录鼠标点击的脚本如下：\n```\nfrom pynput.mouse import Listener\nimport logging\nfrom datetime import datetime\n\n# 配置日志记录\nlogging.basicConfig(\n    filename=\"mouse_clicks.log\",\n    level=logging.INFO,\n    format=\"%(asctime)s %(message)s\",\n    datefmt=\"%Y-%m-%dT%H:%M:%S\"\n)\n\ndef on_click(x, y, button, pressed):\n    if pressed:\n        message = f\"{x} {y}\"\n        print(message)  # 输出到屏幕\n        logging.info(message)  # 写入日志文件\n        if button == button.right:\n            # 停止监听器\n            return False\n\n# 启动鼠标监听器\nwith Listener(on_click=on_click) as listener:\n    try:\n        listener.join()\n    except KeyboardInterrupt:\n        print(\"监听器已被用户中断。\")\n```\n&emsp;&emsp;这个脚本会记录鼠标左键的位置，输出到mouse_clicks.log文件中。mouse_clicks.log文件有三列:\n\n2025-05-07T17:01:33 1977 1576\n\n分别表示点击的时间，x和y坐标。其中y坐标是下面大上面小。此外点击鼠标右键或者输入Ctrl+C就可以结束记录。我一般是怎么做的呢？我先点击图片左下角得到（x0,y0），点击右下角得到(x1,y0)，点击左上角得到(x0,y1)，然后点击你想要的点。得到mouse_clicks.log以后就可以这么画图（gmt）。\n```\ndat=mouse_clicks.log\n#获得x0,y0,x1,y1，他们是参考点\nx0=`awk 'NR==1{print $2}' ${dat}`\ny0=`awk 'NR==1{print $3}' ${dat}`\nx1=`awk 'NR==2{print $2}' ${dat}`\ny1=`awk 'NR==3{print $3}' ${dat}`\n#获得横纵轴长度（屏幕尺度）\nxs=`echo \"$x1-$x0\" |bc` \nys=`echo \"$y0-$y1\" |bc`\n\nawk -v x0=$x0 -v y0=$y0 -v xs=$xs -v ys=$ys 'NR>3{print ($2-x0)/xs*2000-1000,(y0-$3)/ys*1500}' ${dat} | gmt psxy -R -J -O -K -W3p,black >>$ps\n#这里（2000，1500）是横纵轴实际尺度，-1000表示实际位置调整。\n```\n&emsp;&emsp;注意，这种方法仅仅适用于线性笛卡尔坐标，其他的各种投影都不行。\n&emsp;&emsp;以后得加上这句：脚本/程序不保证正确性，自求多幅(no warranty/use at your own risk)。\n","slug":"mouse-click-monitoring","published":1,"updated":"2025-05-11T02:22:46.618Z","comments":1,"layout":"post","photos":[],"_id":"cmh498iqe00cbwvou5tbghpij","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>&emsp;&emsp;有些时候需要抓取别人图片中的点的信息，应该怎么整？当然是找作者要咯！不过有时可能没办法（例如可能联系不上作者&#x2F;作者找不到数据了&#x2F;作者不想给你&#x2F;作者说你自己提取吧）或则并不需要他图片中的点的准确信息的时候，我们可以自己去点。之前有个perl脚本，但找不到了（这又体现了整理资料和做笔记的必要性），现在python很方便的，调用pynput的Listener就好了。记录鼠标点击的脚本如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">from pynput.mouse import Listener</span><br><span class=\"line\">import logging</span><br><span class=\"line\">from datetime import datetime</span><br><span class=\"line\"></span><br><span class=\"line\"># 配置日志记录</span><br><span class=\"line\">logging.basicConfig(</span><br><span class=\"line\">    filename=&quot;mouse_clicks.log&quot;,</span><br><span class=\"line\">    level=logging.INFO,</span><br><span class=\"line\">    format=&quot;%(asctime)s %(message)s&quot;,</span><br><span class=\"line\">    datefmt=&quot;%Y-%m-%dT%H:%M:%S&quot;</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\">def on_click(x, y, button, pressed):</span><br><span class=\"line\">    if pressed:</span><br><span class=\"line\">        message = f&quot;&#123;x&#125; &#123;y&#125;&quot;</span><br><span class=\"line\">        print(message)  # 输出到屏幕</span><br><span class=\"line\">        logging.info(message)  # 写入日志文件</span><br><span class=\"line\">        if button == button.right:</span><br><span class=\"line\">            # 停止监听器</span><br><span class=\"line\">            return False</span><br><span class=\"line\"></span><br><span class=\"line\"># 启动鼠标监听器</span><br><span class=\"line\">with Listener(on_click=on_click) as listener:</span><br><span class=\"line\">    try:</span><br><span class=\"line\">        listener.join()</span><br><span class=\"line\">    except KeyboardInterrupt:</span><br><span class=\"line\">        print(&quot;监听器已被用户中断。&quot;)</span><br></pre></td></tr></table></figure>\n<p>&emsp;&emsp;这个脚本会记录鼠标左键的位置，输出到mouse_clicks.log文件中。mouse_clicks.log文件有三列:</p>\n<p>2025-05-07T17:01:33 1977 1576</p>\n<p>分别表示点击的时间，x和y坐标。其中y坐标是下面大上面小。此外点击鼠标右键或者输入Ctrl+C就可以结束记录。我一般是怎么做的呢？我先点击图片左下角得到（x0,y0），点击右下角得到(x1,y0)，点击左上角得到(x0,y1)，然后点击你想要的点。得到mouse_clicks.log以后就可以这么画图（gmt）。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">dat=mouse_clicks.log</span><br><span class=\"line\">#获得x0,y0,x1,y1，他们是参考点</span><br><span class=\"line\">x0=`awk &#x27;NR==1&#123;print $2&#125;&#x27; $&#123;dat&#125;`</span><br><span class=\"line\">y0=`awk &#x27;NR==1&#123;print $3&#125;&#x27; $&#123;dat&#125;`</span><br><span class=\"line\">x1=`awk &#x27;NR==2&#123;print $2&#125;&#x27; $&#123;dat&#125;`</span><br><span class=\"line\">y1=`awk &#x27;NR==3&#123;print $3&#125;&#x27; $&#123;dat&#125;`</span><br><span class=\"line\">#获得横纵轴长度（屏幕尺度）</span><br><span class=\"line\">xs=`echo &quot;$x1-$x0&quot; |bc` </span><br><span class=\"line\">ys=`echo &quot;$y0-$y1&quot; |bc`</span><br><span class=\"line\"></span><br><span class=\"line\">awk -v x0=$x0 -v y0=$y0 -v xs=$xs -v ys=$ys &#x27;NR&gt;3&#123;print ($2-x0)/xs*2000-1000,(y0-$3)/ys*1500&#125;&#x27; $&#123;dat&#125; | gmt psxy -R -J -O -K -W3p,black &gt;&gt;$ps</span><br><span class=\"line\">#这里（2000，1500）是横纵轴实际尺度，-1000表示实际位置调整。</span><br></pre></td></tr></table></figure>\n<p>&emsp;&emsp;注意，这种方法仅仅适用于线性笛卡尔坐标，其他的各种投影都不行。<br>&emsp;&emsp;以后得加上这句：脚本&#x2F;程序不保证正确性，自求多幅(no warranty&#x2F;use at your own risk)。</p>\n","related_posts":[],"length":1741,"excerpt":"","more":"<p>&emsp;&emsp;有些时候需要抓取别人图片中的点的信息，应该怎么整？当然是找作者要咯！不过有时可能没办法（例如可能联系不上作者&#x2F;作者找不到数据了&#x2F;作者不想给你&#x2F;作者说你自己提取吧）或则并不需要他图片中的点的准确信息的时候，我们可以自己去点。之前有个perl脚本，但找不到了（这又体现了整理资料和做笔记的必要性），现在python很方便的，调用pynput的Listener就好了。记录鼠标点击的脚本如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">from pynput.mouse import Listener</span><br><span class=\"line\">import logging</span><br><span class=\"line\">from datetime import datetime</span><br><span class=\"line\"></span><br><span class=\"line\"># 配置日志记录</span><br><span class=\"line\">logging.basicConfig(</span><br><span class=\"line\">    filename=&quot;mouse_clicks.log&quot;,</span><br><span class=\"line\">    level=logging.INFO,</span><br><span class=\"line\">    format=&quot;%(asctime)s %(message)s&quot;,</span><br><span class=\"line\">    datefmt=&quot;%Y-%m-%dT%H:%M:%S&quot;</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\">def on_click(x, y, button, pressed):</span><br><span class=\"line\">    if pressed:</span><br><span class=\"line\">        message = f&quot;&#123;x&#125; &#123;y&#125;&quot;</span><br><span class=\"line\">        print(message)  # 输出到屏幕</span><br><span class=\"line\">        logging.info(message)  # 写入日志文件</span><br><span class=\"line\">        if button == button.right:</span><br><span class=\"line\">            # 停止监听器</span><br><span class=\"line\">            return False</span><br><span class=\"line\"></span><br><span class=\"line\"># 启动鼠标监听器</span><br><span class=\"line\">with Listener(on_click=on_click) as listener:</span><br><span class=\"line\">    try:</span><br><span class=\"line\">        listener.join()</span><br><span class=\"line\">    except KeyboardInterrupt:</span><br><span class=\"line\">        print(&quot;监听器已被用户中断。&quot;)</span><br></pre></td></tr></table></figure>\n<p>&emsp;&emsp;这个脚本会记录鼠标左键的位置，输出到mouse_clicks.log文件中。mouse_clicks.log文件有三列:</p>\n<p>2025-05-07T17:01:33 1977 1576</p>\n<p>分别表示点击的时间，x和y坐标。其中y坐标是下面大上面小。此外点击鼠标右键或者输入Ctrl+C就可以结束记录。我一般是怎么做的呢？我先点击图片左下角得到（x0,y0），点击右下角得到(x1,y0)，点击左上角得到(x0,y1)，然后点击你想要的点。得到mouse_clicks.log以后就可以这么画图（gmt）。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">dat=mouse_clicks.log</span><br><span class=\"line\">#获得x0,y0,x1,y1，他们是参考点</span><br><span class=\"line\">x0=`awk &#x27;NR==1&#123;print $2&#125;&#x27; $&#123;dat&#125;`</span><br><span class=\"line\">y0=`awk &#x27;NR==1&#123;print $3&#125;&#x27; $&#123;dat&#125;`</span><br><span class=\"line\">x1=`awk &#x27;NR==2&#123;print $2&#125;&#x27; $&#123;dat&#125;`</span><br><span class=\"line\">y1=`awk &#x27;NR==3&#123;print $3&#125;&#x27; $&#123;dat&#125;`</span><br><span class=\"line\">#获得横纵轴长度（屏幕尺度）</span><br><span class=\"line\">xs=`echo &quot;$x1-$x0&quot; |bc` </span><br><span class=\"line\">ys=`echo &quot;$y0-$y1&quot; |bc`</span><br><span class=\"line\"></span><br><span class=\"line\">awk -v x0=$x0 -v y0=$y0 -v xs=$xs -v ys=$ys &#x27;NR&gt;3&#123;print ($2-x0)/xs*2000-1000,(y0-$3)/ys*1500&#125;&#x27; $&#123;dat&#125; | gmt psxy -R -J -O -K -W3p,black &gt;&gt;$ps</span><br><span class=\"line\">#这里（2000，1500）是横纵轴实际尺度，-1000表示实际位置调整。</span><br></pre></td></tr></table></figure>\n<p>&emsp;&emsp;注意，这种方法仅仅适用于线性笛卡尔坐标，其他的各种投影都不行。<br>&emsp;&emsp;以后得加上这句：脚本&#x2F;程序不保证正确性，自求多幅(no warranty&#x2F;use at your own risk)。</p>\n"},{"title":"下载地震数据更新","abbrlink":"a1dc7bf4","date":"2025-05-16T06:39:46.000Z","_content":"&emsp;&emsp;以下是地震数据下载脚本更新。\n```\nimport os\nfrom obspy import UTCDateTime\nfrom obspy.clients.fdsn import Client\nfrom obspy.taup import TauPyModel\nfrom obspy.geodetics import locations2degrees\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\n\nclient = Client(\"IRIS\")\nmodel = TauPyModel(\"iasp91\")\n\noutput_dir = \"processed_sac\"\nos.makedirs(output_dir, exist_ok=True)\n\nevent_file = \"event.lst\"\nsta_file = \"sta.lst\"\nexception_log = \"exceptions.txt\"\nthread_workers = 4\n\n# 读取台站信息：net, sta, lat, lon, elev\nwith open(sta_file, \"r\") as sf:\n    sta_lines = [line.strip() for line in sf if line.strip()]\nsta_list = []\nfor line in sta_lines:\n    parts = line.split(\"|\")\n    if len(parts) >= 5:\n        net = parts[0].strip()\n        sta = parts[1].strip()\n        lat = float(parts[2])\n        lon = float(parts[3])\n        elev = float(parts[4])\n        sta_list.append((net, sta, lat, lon, elev))\n\n# 清空异常日志\nwith open(exception_log, \"w\") as elog:\n    elog.write(\"\")\n\ndef process_station(event_id, origin_time, magnitude, ev_lat, ev_lon, ev_dep,\n                    net, sta, sta_lat, sta_lon, sta_elev):\n    try:\n        dist_deg = locations2degrees(ev_lat, ev_lon, sta_lat, sta_lon)\n        arrivals = model.get_travel_times(source_depth_in_km=ev_dep,\n                                          distance_in_degree=dist_deg,\n                                          phase_list=[\"P\"])\n        if not arrivals:\n            raise Exception(\"No P arrival\")\n\n        p_arrival = origin_time + arrivals[0].time\n        start_dl = p_arrival - 50\n        end_dl = p_arrival + 150\n\n        st = client.get_waveforms(network=net, station=sta, location=\"*\", channel=\"BH?\",\n                                  starttime=start_dl, endtime=end_dl,\n                                  attach_response=True)\n\n        st.remove_response(output=\"VEL\", pre_filt=(0.01, 0.02, 8, 10),\n                           taper=True, zero_mean=True, taper_fraction=0.05)\n\n        st.trim(starttime=p_arrival - 10, endtime=p_arrival + 60)\n\n        comps = [tr.stats.channel[-1] for tr in st]\n        if not all(comp in comps for comp in [\"N\", \"E\", \"Z\"]):\n            raise Exception(\"Incomplete 3-component data\")\n\n        for tr in st:\n            tr.stats.sac = tr.stats.get(\"sac\", {})\n            tr.stats.sac.stla = sta_lat\n            tr.stats.sac.stlo = sta_lon\n            tr.stats.sac.stel = sta_elev\n            tr.stats.sac.evla = ev_lat\n            tr.stats.sac.evlo = ev_lon\n            tr.stats.sac.evdp = ev_dep\n            tr.stats.sac.mag = float(magnitude) if magnitude != \"NA\" else 0.0\n\n            time_tag = origin_time.strftime(\"%Y%m%dT%H%M%S\")\n            chan = tr.stats.channel\n            filename = f\"{time_tag}_M{magnitude}_{net}.{sta}.{chan}.sac\"\n            filepath = os.path.join(output_dir, filename)\n            tr.write(filepath, format=\"SAC\")\n\n        return f\"{net}.{sta} ✅\"\n\n    except Exception as e:\n        with open(exception_log, \"a\") as elog:\n            elog.write(f\"{event_id} {net}.{sta} ❌ {str(e)}\\n\")\n        return f\"{net}.{sta} ❌ {str(e)}\"\n\ndef process_event(line):\n    results = []\n    parts = line.split(\"|\")\n    if len(parts) < 10:\n        return [\"跳过格式错误行\"]\n\n    evid = parts[0].strip()\n    time_str = parts[1].strip()\n    ev_lat = float(parts[2].strip())\n    ev_lon = float(parts[3].strip())\n    ev_dep = float(parts[4].strip())\n    mag_info = parts[8].strip()\n    magnitude = mag_info.split(\",\")[1] if \",\" in mag_info else \"NA\"\n\n    origin_time = UTCDateTime(time_str)\n    print(f\"\\n🟡 Processing event {evid} M{magnitude} @ {origin_time} ({ev_lat}, {ev_lon}, {ev_dep}km)\")\n\n    try:\n        task_list = []\n        with ThreadPoolExecutor(max_workers=thread_workers) as executor:\n            for net, sta, sta_lat, sta_lon, sta_elev in sta_list:\n                task = executor.submit(process_station, evid, origin_time, magnitude,\n                                       ev_lat, ev_lon, ev_dep, net, sta, sta_lat, sta_lon, sta_elev)\n                task_list.append(task)\n\n            for task in as_completed(task_list):\n                results.append(task.result())\n\n    except Exception as e:\n        with open(exception_log, \"a\") as elog:\n            elog.write(f\"{evid} XB ERROR: {str(e)}\\n\")\n        results.append(f\"⚠️ Failed to process event {evid}: {e}\")\n    return results\n\n# 读取事件列表并执行\nwith open(event_file, \"r\") as f:\n    event_lines = [line.strip() for line in f if line.strip()]\n\nfor line in event_lines:\n    results = process_event(line)\n    for r in results:\n        print(r)\n```\n&emsp;&emsp;与之前的脚本:{% post_link 下载地震数据练习 %}不同的地方是多了文件sta.lst。其格式为：\nTA|140A|32.6408|-93.573997|56.0|\n台网|台站|纬度|经度|高程\n","source":"_posts/2025-05-16-download-eq-data.md","raw":"---\ntitle: 下载地震数据更新\ntags:\n  - python\ncategories:\n  - seismology\nabbrlink: a1dc7bf4\ndate: 2025-05-16 14:39:46\n---\n&emsp;&emsp;以下是地震数据下载脚本更新。\n```\nimport os\nfrom obspy import UTCDateTime\nfrom obspy.clients.fdsn import Client\nfrom obspy.taup import TauPyModel\nfrom obspy.geodetics import locations2degrees\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\n\nclient = Client(\"IRIS\")\nmodel = TauPyModel(\"iasp91\")\n\noutput_dir = \"processed_sac\"\nos.makedirs(output_dir, exist_ok=True)\n\nevent_file = \"event.lst\"\nsta_file = \"sta.lst\"\nexception_log = \"exceptions.txt\"\nthread_workers = 4\n\n# 读取台站信息：net, sta, lat, lon, elev\nwith open(sta_file, \"r\") as sf:\n    sta_lines = [line.strip() for line in sf if line.strip()]\nsta_list = []\nfor line in sta_lines:\n    parts = line.split(\"|\")\n    if len(parts) >= 5:\n        net = parts[0].strip()\n        sta = parts[1].strip()\n        lat = float(parts[2])\n        lon = float(parts[3])\n        elev = float(parts[4])\n        sta_list.append((net, sta, lat, lon, elev))\n\n# 清空异常日志\nwith open(exception_log, \"w\") as elog:\n    elog.write(\"\")\n\ndef process_station(event_id, origin_time, magnitude, ev_lat, ev_lon, ev_dep,\n                    net, sta, sta_lat, sta_lon, sta_elev):\n    try:\n        dist_deg = locations2degrees(ev_lat, ev_lon, sta_lat, sta_lon)\n        arrivals = model.get_travel_times(source_depth_in_km=ev_dep,\n                                          distance_in_degree=dist_deg,\n                                          phase_list=[\"P\"])\n        if not arrivals:\n            raise Exception(\"No P arrival\")\n\n        p_arrival = origin_time + arrivals[0].time\n        start_dl = p_arrival - 50\n        end_dl = p_arrival + 150\n\n        st = client.get_waveforms(network=net, station=sta, location=\"*\", channel=\"BH?\",\n                                  starttime=start_dl, endtime=end_dl,\n                                  attach_response=True)\n\n        st.remove_response(output=\"VEL\", pre_filt=(0.01, 0.02, 8, 10),\n                           taper=True, zero_mean=True, taper_fraction=0.05)\n\n        st.trim(starttime=p_arrival - 10, endtime=p_arrival + 60)\n\n        comps = [tr.stats.channel[-1] for tr in st]\n        if not all(comp in comps for comp in [\"N\", \"E\", \"Z\"]):\n            raise Exception(\"Incomplete 3-component data\")\n\n        for tr in st:\n            tr.stats.sac = tr.stats.get(\"sac\", {})\n            tr.stats.sac.stla = sta_lat\n            tr.stats.sac.stlo = sta_lon\n            tr.stats.sac.stel = sta_elev\n            tr.stats.sac.evla = ev_lat\n            tr.stats.sac.evlo = ev_lon\n            tr.stats.sac.evdp = ev_dep\n            tr.stats.sac.mag = float(magnitude) if magnitude != \"NA\" else 0.0\n\n            time_tag = origin_time.strftime(\"%Y%m%dT%H%M%S\")\n            chan = tr.stats.channel\n            filename = f\"{time_tag}_M{magnitude}_{net}.{sta}.{chan}.sac\"\n            filepath = os.path.join(output_dir, filename)\n            tr.write(filepath, format=\"SAC\")\n\n        return f\"{net}.{sta} ✅\"\n\n    except Exception as e:\n        with open(exception_log, \"a\") as elog:\n            elog.write(f\"{event_id} {net}.{sta} ❌ {str(e)}\\n\")\n        return f\"{net}.{sta} ❌ {str(e)}\"\n\ndef process_event(line):\n    results = []\n    parts = line.split(\"|\")\n    if len(parts) < 10:\n        return [\"跳过格式错误行\"]\n\n    evid = parts[0].strip()\n    time_str = parts[1].strip()\n    ev_lat = float(parts[2].strip())\n    ev_lon = float(parts[3].strip())\n    ev_dep = float(parts[4].strip())\n    mag_info = parts[8].strip()\n    magnitude = mag_info.split(\",\")[1] if \",\" in mag_info else \"NA\"\n\n    origin_time = UTCDateTime(time_str)\n    print(f\"\\n🟡 Processing event {evid} M{magnitude} @ {origin_time} ({ev_lat}, {ev_lon}, {ev_dep}km)\")\n\n    try:\n        task_list = []\n        with ThreadPoolExecutor(max_workers=thread_workers) as executor:\n            for net, sta, sta_lat, sta_lon, sta_elev in sta_list:\n                task = executor.submit(process_station, evid, origin_time, magnitude,\n                                       ev_lat, ev_lon, ev_dep, net, sta, sta_lat, sta_lon, sta_elev)\n                task_list.append(task)\n\n            for task in as_completed(task_list):\n                results.append(task.result())\n\n    except Exception as e:\n        with open(exception_log, \"a\") as elog:\n            elog.write(f\"{evid} XB ERROR: {str(e)}\\n\")\n        results.append(f\"⚠️ Failed to process event {evid}: {e}\")\n    return results\n\n# 读取事件列表并执行\nwith open(event_file, \"r\") as f:\n    event_lines = [line.strip() for line in f if line.strip()]\n\nfor line in event_lines:\n    results = process_event(line)\n    for r in results:\n        print(r)\n```\n&emsp;&emsp;与之前的脚本:{% post_link 下载地震数据练习 %}不同的地方是多了文件sta.lst。其格式为：\nTA|140A|32.6408|-93.573997|56.0|\n台网|台站|纬度|经度|高程\n","slug":"download-eq-data","published":1,"updated":"2025-05-16T06:46:19.646Z","comments":1,"layout":"post","photos":[],"_id":"cmh498iqe00cdwvou9wtxheij","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>&emsp;&emsp;以下是地震数据下载脚本更新。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">import os</span><br><span class=\"line\">from obspy import UTCDateTime</span><br><span class=\"line\">from obspy.clients.fdsn import Client</span><br><span class=\"line\">from obspy.taup import TauPyModel</span><br><span class=\"line\">from obspy.geodetics import locations2degrees</span><br><span class=\"line\">from concurrent.futures import ThreadPoolExecutor, as_completed</span><br><span class=\"line\"></span><br><span class=\"line\">client = Client(&quot;IRIS&quot;)</span><br><span class=\"line\">model = TauPyModel(&quot;iasp91&quot;)</span><br><span class=\"line\"></span><br><span class=\"line\">output_dir = &quot;processed_sac&quot;</span><br><span class=\"line\">os.makedirs(output_dir, exist_ok=True)</span><br><span class=\"line\"></span><br><span class=\"line\">event_file = &quot;event.lst&quot;</span><br><span class=\"line\">sta_file = &quot;sta.lst&quot;</span><br><span class=\"line\">exception_log = &quot;exceptions.txt&quot;</span><br><span class=\"line\">thread_workers = 4</span><br><span class=\"line\"></span><br><span class=\"line\"># 读取台站信息：net, sta, lat, lon, elev</span><br><span class=\"line\">with open(sta_file, &quot;r&quot;) as sf:</span><br><span class=\"line\">    sta_lines = [line.strip() for line in sf if line.strip()]</span><br><span class=\"line\">sta_list = []</span><br><span class=\"line\">for line in sta_lines:</span><br><span class=\"line\">    parts = line.split(&quot;|&quot;)</span><br><span class=\"line\">    if len(parts) &gt;= 5:</span><br><span class=\"line\">        net = parts[0].strip()</span><br><span class=\"line\">        sta = parts[1].strip()</span><br><span class=\"line\">        lat = float(parts[2])</span><br><span class=\"line\">        lon = float(parts[3])</span><br><span class=\"line\">        elev = float(parts[4])</span><br><span class=\"line\">        sta_list.append((net, sta, lat, lon, elev))</span><br><span class=\"line\"></span><br><span class=\"line\"># 清空异常日志</span><br><span class=\"line\">with open(exception_log, &quot;w&quot;) as elog:</span><br><span class=\"line\">    elog.write(&quot;&quot;)</span><br><span class=\"line\"></span><br><span class=\"line\">def process_station(event_id, origin_time, magnitude, ev_lat, ev_lon, ev_dep,</span><br><span class=\"line\">                    net, sta, sta_lat, sta_lon, sta_elev):</span><br><span class=\"line\">    try:</span><br><span class=\"line\">        dist_deg = locations2degrees(ev_lat, ev_lon, sta_lat, sta_lon)</span><br><span class=\"line\">        arrivals = model.get_travel_times(source_depth_in_km=ev_dep,</span><br><span class=\"line\">                                          distance_in_degree=dist_deg,</span><br><span class=\"line\">                                          phase_list=[&quot;P&quot;])</span><br><span class=\"line\">        if not arrivals:</span><br><span class=\"line\">            raise Exception(&quot;No P arrival&quot;)</span><br><span class=\"line\"></span><br><span class=\"line\">        p_arrival = origin_time + arrivals[0].time</span><br><span class=\"line\">        start_dl = p_arrival - 50</span><br><span class=\"line\">        end_dl = p_arrival + 150</span><br><span class=\"line\"></span><br><span class=\"line\">        st = client.get_waveforms(network=net, station=sta, location=&quot;*&quot;, channel=&quot;BH?&quot;,</span><br><span class=\"line\">                                  starttime=start_dl, endtime=end_dl,</span><br><span class=\"line\">                                  attach_response=True)</span><br><span class=\"line\"></span><br><span class=\"line\">        st.remove_response(output=&quot;VEL&quot;, pre_filt=(0.01, 0.02, 8, 10),</span><br><span class=\"line\">                           taper=True, zero_mean=True, taper_fraction=0.05)</span><br><span class=\"line\"></span><br><span class=\"line\">        st.trim(starttime=p_arrival - 10, endtime=p_arrival + 60)</span><br><span class=\"line\"></span><br><span class=\"line\">        comps = [tr.stats.channel[-1] for tr in st]</span><br><span class=\"line\">        if not all(comp in comps for comp in [&quot;N&quot;, &quot;E&quot;, &quot;Z&quot;]):</span><br><span class=\"line\">            raise Exception(&quot;Incomplete 3-component data&quot;)</span><br><span class=\"line\"></span><br><span class=\"line\">        for tr in st:</span><br><span class=\"line\">            tr.stats.sac = tr.stats.get(&quot;sac&quot;, &#123;&#125;)</span><br><span class=\"line\">            tr.stats.sac.stla = sta_lat</span><br><span class=\"line\">            tr.stats.sac.stlo = sta_lon</span><br><span class=\"line\">            tr.stats.sac.stel = sta_elev</span><br><span class=\"line\">            tr.stats.sac.evla = ev_lat</span><br><span class=\"line\">            tr.stats.sac.evlo = ev_lon</span><br><span class=\"line\">            tr.stats.sac.evdp = ev_dep</span><br><span class=\"line\">            tr.stats.sac.mag = float(magnitude) if magnitude != &quot;NA&quot; else 0.0</span><br><span class=\"line\"></span><br><span class=\"line\">            time_tag = origin_time.strftime(&quot;%Y%m%dT%H%M%S&quot;)</span><br><span class=\"line\">            chan = tr.stats.channel</span><br><span class=\"line\">            filename = f&quot;&#123;time_tag&#125;_M&#123;magnitude&#125;_&#123;net&#125;.&#123;sta&#125;.&#123;chan&#125;.sac&quot;</span><br><span class=\"line\">            filepath = os.path.join(output_dir, filename)</span><br><span class=\"line\">            tr.write(filepath, format=&quot;SAC&quot;)</span><br><span class=\"line\"></span><br><span class=\"line\">        return f&quot;&#123;net&#125;.&#123;sta&#125; ✅&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">    except Exception as e:</span><br><span class=\"line\">        with open(exception_log, &quot;a&quot;) as elog:</span><br><span class=\"line\">            elog.write(f&quot;&#123;event_id&#125; &#123;net&#125;.&#123;sta&#125; ❌ &#123;str(e)&#125;\\n&quot;)</span><br><span class=\"line\">        return f&quot;&#123;net&#125;.&#123;sta&#125; ❌ &#123;str(e)&#125;&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">def process_event(line):</span><br><span class=\"line\">    results = []</span><br><span class=\"line\">    parts = line.split(&quot;|&quot;)</span><br><span class=\"line\">    if len(parts) &lt; 10:</span><br><span class=\"line\">        return [&quot;跳过格式错误行&quot;]</span><br><span class=\"line\"></span><br><span class=\"line\">    evid = parts[0].strip()</span><br><span class=\"line\">    time_str = parts[1].strip()</span><br><span class=\"line\">    ev_lat = float(parts[2].strip())</span><br><span class=\"line\">    ev_lon = float(parts[3].strip())</span><br><span class=\"line\">    ev_dep = float(parts[4].strip())</span><br><span class=\"line\">    mag_info = parts[8].strip()</span><br><span class=\"line\">    magnitude = mag_info.split(&quot;,&quot;)[1] if &quot;,&quot; in mag_info else &quot;NA&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">    origin_time = UTCDateTime(time_str)</span><br><span class=\"line\">    print(f&quot;\\n🟡 Processing event &#123;evid&#125; M&#123;magnitude&#125; @ &#123;origin_time&#125; (&#123;ev_lat&#125;, &#123;ev_lon&#125;, &#123;ev_dep&#125;km)&quot;)</span><br><span class=\"line\"></span><br><span class=\"line\">    try:</span><br><span class=\"line\">        task_list = []</span><br><span class=\"line\">        with ThreadPoolExecutor(max_workers=thread_workers) as executor:</span><br><span class=\"line\">            for net, sta, sta_lat, sta_lon, sta_elev in sta_list:</span><br><span class=\"line\">                task = executor.submit(process_station, evid, origin_time, magnitude,</span><br><span class=\"line\">                                       ev_lat, ev_lon, ev_dep, net, sta, sta_lat, sta_lon, sta_elev)</span><br><span class=\"line\">                task_list.append(task)</span><br><span class=\"line\"></span><br><span class=\"line\">            for task in as_completed(task_list):</span><br><span class=\"line\">                results.append(task.result())</span><br><span class=\"line\"></span><br><span class=\"line\">    except Exception as e:</span><br><span class=\"line\">        with open(exception_log, &quot;a&quot;) as elog:</span><br><span class=\"line\">            elog.write(f&quot;&#123;evid&#125; XB ERROR: &#123;str(e)&#125;\\n&quot;)</span><br><span class=\"line\">        results.append(f&quot;⚠️ Failed to process event &#123;evid&#125;: &#123;e&#125;&quot;)</span><br><span class=\"line\">    return results</span><br><span class=\"line\"></span><br><span class=\"line\"># 读取事件列表并执行</span><br><span class=\"line\">with open(event_file, &quot;r&quot;) as f:</span><br><span class=\"line\">    event_lines = [line.strip() for line in f if line.strip()]</span><br><span class=\"line\"></span><br><span class=\"line\">for line in event_lines:</span><br><span class=\"line\">    results = process_event(line)</span><br><span class=\"line\">    for r in results:</span><br><span class=\"line\">        print(r)</span><br></pre></td></tr></table></figure>\n<p>&emsp;&emsp;与之前的脚本:<a href=\"/download-earthquake-py\" title=\"下载地震数据练习\">下载地震数据练习</a>不同的地方是多了文件sta.lst。其格式为：<br>TA|140A|32.6408|-93.573997|56.0|<br>台网|台站|纬度|经度|高程</p>\n","related_posts":[],"length":4256,"excerpt":"","more":"<p>&emsp;&emsp;以下是地震数据下载脚本更新。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">import os</span><br><span class=\"line\">from obspy import UTCDateTime</span><br><span class=\"line\">from obspy.clients.fdsn import Client</span><br><span class=\"line\">from obspy.taup import TauPyModel</span><br><span class=\"line\">from obspy.geodetics import locations2degrees</span><br><span class=\"line\">from concurrent.futures import ThreadPoolExecutor, as_completed</span><br><span class=\"line\"></span><br><span class=\"line\">client = Client(&quot;IRIS&quot;)</span><br><span class=\"line\">model = TauPyModel(&quot;iasp91&quot;)</span><br><span class=\"line\"></span><br><span class=\"line\">output_dir = &quot;processed_sac&quot;</span><br><span class=\"line\">os.makedirs(output_dir, exist_ok=True)</span><br><span class=\"line\"></span><br><span class=\"line\">event_file = &quot;event.lst&quot;</span><br><span class=\"line\">sta_file = &quot;sta.lst&quot;</span><br><span class=\"line\">exception_log = &quot;exceptions.txt&quot;</span><br><span class=\"line\">thread_workers = 4</span><br><span class=\"line\"></span><br><span class=\"line\"># 读取台站信息：net, sta, lat, lon, elev</span><br><span class=\"line\">with open(sta_file, &quot;r&quot;) as sf:</span><br><span class=\"line\">    sta_lines = [line.strip() for line in sf if line.strip()]</span><br><span class=\"line\">sta_list = []</span><br><span class=\"line\">for line in sta_lines:</span><br><span class=\"line\">    parts = line.split(&quot;|&quot;)</span><br><span class=\"line\">    if len(parts) &gt;= 5:</span><br><span class=\"line\">        net = parts[0].strip()</span><br><span class=\"line\">        sta = parts[1].strip()</span><br><span class=\"line\">        lat = float(parts[2])</span><br><span class=\"line\">        lon = float(parts[3])</span><br><span class=\"line\">        elev = float(parts[4])</span><br><span class=\"line\">        sta_list.append((net, sta, lat, lon, elev))</span><br><span class=\"line\"></span><br><span class=\"line\"># 清空异常日志</span><br><span class=\"line\">with open(exception_log, &quot;w&quot;) as elog:</span><br><span class=\"line\">    elog.write(&quot;&quot;)</span><br><span class=\"line\"></span><br><span class=\"line\">def process_station(event_id, origin_time, magnitude, ev_lat, ev_lon, ev_dep,</span><br><span class=\"line\">                    net, sta, sta_lat, sta_lon, sta_elev):</span><br><span class=\"line\">    try:</span><br><span class=\"line\">        dist_deg = locations2degrees(ev_lat, ev_lon, sta_lat, sta_lon)</span><br><span class=\"line\">        arrivals = model.get_travel_times(source_depth_in_km=ev_dep,</span><br><span class=\"line\">                                          distance_in_degree=dist_deg,</span><br><span class=\"line\">                                          phase_list=[&quot;P&quot;])</span><br><span class=\"line\">        if not arrivals:</span><br><span class=\"line\">            raise Exception(&quot;No P arrival&quot;)</span><br><span class=\"line\"></span><br><span class=\"line\">        p_arrival = origin_time + arrivals[0].time</span><br><span class=\"line\">        start_dl = p_arrival - 50</span><br><span class=\"line\">        end_dl = p_arrival + 150</span><br><span class=\"line\"></span><br><span class=\"line\">        st = client.get_waveforms(network=net, station=sta, location=&quot;*&quot;, channel=&quot;BH?&quot;,</span><br><span class=\"line\">                                  starttime=start_dl, endtime=end_dl,</span><br><span class=\"line\">                                  attach_response=True)</span><br><span class=\"line\"></span><br><span class=\"line\">        st.remove_response(output=&quot;VEL&quot;, pre_filt=(0.01, 0.02, 8, 10),</span><br><span class=\"line\">                           taper=True, zero_mean=True, taper_fraction=0.05)</span><br><span class=\"line\"></span><br><span class=\"line\">        st.trim(starttime=p_arrival - 10, endtime=p_arrival + 60)</span><br><span class=\"line\"></span><br><span class=\"line\">        comps = [tr.stats.channel[-1] for tr in st]</span><br><span class=\"line\">        if not all(comp in comps for comp in [&quot;N&quot;, &quot;E&quot;, &quot;Z&quot;]):</span><br><span class=\"line\">            raise Exception(&quot;Incomplete 3-component data&quot;)</span><br><span class=\"line\"></span><br><span class=\"line\">        for tr in st:</span><br><span class=\"line\">            tr.stats.sac = tr.stats.get(&quot;sac&quot;, &#123;&#125;)</span><br><span class=\"line\">            tr.stats.sac.stla = sta_lat</span><br><span class=\"line\">            tr.stats.sac.stlo = sta_lon</span><br><span class=\"line\">            tr.stats.sac.stel = sta_elev</span><br><span class=\"line\">            tr.stats.sac.evla = ev_lat</span><br><span class=\"line\">            tr.stats.sac.evlo = ev_lon</span><br><span class=\"line\">            tr.stats.sac.evdp = ev_dep</span><br><span class=\"line\">            tr.stats.sac.mag = float(magnitude) if magnitude != &quot;NA&quot; else 0.0</span><br><span class=\"line\"></span><br><span class=\"line\">            time_tag = origin_time.strftime(&quot;%Y%m%dT%H%M%S&quot;)</span><br><span class=\"line\">            chan = tr.stats.channel</span><br><span class=\"line\">            filename = f&quot;&#123;time_tag&#125;_M&#123;magnitude&#125;_&#123;net&#125;.&#123;sta&#125;.&#123;chan&#125;.sac&quot;</span><br><span class=\"line\">            filepath = os.path.join(output_dir, filename)</span><br><span class=\"line\">            tr.write(filepath, format=&quot;SAC&quot;)</span><br><span class=\"line\"></span><br><span class=\"line\">        return f&quot;&#123;net&#125;.&#123;sta&#125; ✅&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">    except Exception as e:</span><br><span class=\"line\">        with open(exception_log, &quot;a&quot;) as elog:</span><br><span class=\"line\">            elog.write(f&quot;&#123;event_id&#125; &#123;net&#125;.&#123;sta&#125; ❌ &#123;str(e)&#125;\\n&quot;)</span><br><span class=\"line\">        return f&quot;&#123;net&#125;.&#123;sta&#125; ❌ &#123;str(e)&#125;&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">def process_event(line):</span><br><span class=\"line\">    results = []</span><br><span class=\"line\">    parts = line.split(&quot;|&quot;)</span><br><span class=\"line\">    if len(parts) &lt; 10:</span><br><span class=\"line\">        return [&quot;跳过格式错误行&quot;]</span><br><span class=\"line\"></span><br><span class=\"line\">    evid = parts[0].strip()</span><br><span class=\"line\">    time_str = parts[1].strip()</span><br><span class=\"line\">    ev_lat = float(parts[2].strip())</span><br><span class=\"line\">    ev_lon = float(parts[3].strip())</span><br><span class=\"line\">    ev_dep = float(parts[4].strip())</span><br><span class=\"line\">    mag_info = parts[8].strip()</span><br><span class=\"line\">    magnitude = mag_info.split(&quot;,&quot;)[1] if &quot;,&quot; in mag_info else &quot;NA&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">    origin_time = UTCDateTime(time_str)</span><br><span class=\"line\">    print(f&quot;\\n🟡 Processing event &#123;evid&#125; M&#123;magnitude&#125; @ &#123;origin_time&#125; (&#123;ev_lat&#125;, &#123;ev_lon&#125;, &#123;ev_dep&#125;km)&quot;)</span><br><span class=\"line\"></span><br><span class=\"line\">    try:</span><br><span class=\"line\">        task_list = []</span><br><span class=\"line\">        with ThreadPoolExecutor(max_workers=thread_workers) as executor:</span><br><span class=\"line\">            for net, sta, sta_lat, sta_lon, sta_elev in sta_list:</span><br><span class=\"line\">                task = executor.submit(process_station, evid, origin_time, magnitude,</span><br><span class=\"line\">                                       ev_lat, ev_lon, ev_dep, net, sta, sta_lat, sta_lon, sta_elev)</span><br><span class=\"line\">                task_list.append(task)</span><br><span class=\"line\"></span><br><span class=\"line\">            for task in as_completed(task_list):</span><br><span class=\"line\">                results.append(task.result())</span><br><span class=\"line\"></span><br><span class=\"line\">    except Exception as e:</span><br><span class=\"line\">        with open(exception_log, &quot;a&quot;) as elog:</span><br><span class=\"line\">            elog.write(f&quot;&#123;evid&#125; XB ERROR: &#123;str(e)&#125;\\n&quot;)</span><br><span class=\"line\">        results.append(f&quot;⚠️ Failed to process event &#123;evid&#125;: &#123;e&#125;&quot;)</span><br><span class=\"line\">    return results</span><br><span class=\"line\"></span><br><span class=\"line\"># 读取事件列表并执行</span><br><span class=\"line\">with open(event_file, &quot;r&quot;) as f:</span><br><span class=\"line\">    event_lines = [line.strip() for line in f if line.strip()]</span><br><span class=\"line\"></span><br><span class=\"line\">for line in event_lines:</span><br><span class=\"line\">    results = process_event(line)</span><br><span class=\"line\">    for r in results:</span><br><span class=\"line\">        print(r)</span><br></pre></td></tr></table></figure>\n<p>&emsp;&emsp;与之前的脚本:<a href=\"/download-earthquake-py\" title=\"下载地震数据练习\">下载地震数据练习</a>不同的地方是多了文件sta.lst。其格式为：<br>TA|140A|32.6408|-93.573997|56.0|<br>台网|台站|纬度|经度|高程</p>\n"},{"title":"即“蠢”又“坏”？","abbrlink":"6eb40c53","date":"2025-05-31T10:50:20.000Z","_content":"&emsp;&emsp;人大约都是即“蠢”又“坏”的吧！\n<!--less-->\n&emsp;&emsp;不要误会，并不是你想象中的“蠢”和“坏”。我们在讨论某个“东西”的时候，有必要对这个“东西”的概念进行解释，否则会造成鸡同鸭讲，对牛弹琴的结果。另外你也会发现，像我这种学理的，总会在和别人讨论之前要明确“东西”的定义。人的语言其实还是挺匮乏的，难以完美表述自己心中所想，要是讨论的话题没有进行明确的定义，那就容易自说自话。有句话叫做人的冲突80%都是定义不明，也是说明这种状况。现在我也大约能够明白为什么小时候读国外的小说都觉得他们怎么写得那么“啰嗦”。原因是因为语言不够准确吧，需要提供冗余的信息，才不至于让人理解错误，以传达错误的信息。这是他们的办法，而我们选择了浪漫。\n&emsp;&emsp;好了，先说“蠢”吧，算了，还是一起说，因为似乎他们难以分开。这两个词都是形容词，都是评价。当我们在评价一个人或物的时候，我们通常是站在了一个价值观，或角度或利益在讲。我讲他们难以分开，是站在哪个角度呢？\n&emsp;&emsp;首先站在旁观者的角度，不带利益取舍的看吧。但又似乎不能，因为我也是人，所以几乎不能客观。但不管，姑且认为我是客观的吧，至少也可以试着幻想自己是一个外星物。从进化的角度来看吧。人付出了一些东西，演化出了大脑这个东西。大脑有很多神经元，连接，可以处理应付适应甚至改变很复杂的环境，从此大约不需要进化了啊。在此之前至少走到了动物界之巅了啊，说走上了生物之巅还为时尚早。\n&emsp;&emsp;脑子是个好东西。我们会思考了。不过我们思考的时候，上帝就笑了。我们以为我们很会思考，其实，不是的。大脑只要一思考是很消耗能量的。老祖宗在恶劣的生存条件下，填饱肚子都是个挑战，能分配给脑子的能量是不够的啊。就像你要跑个AI模型，没有显卡，CPU只能跑个简单小模型啊。例如“狗”都会的条件反射。\n&emsp;&emsp;好了，我们肯定不只会“狗”都会的条件反射。我们还会逻辑。真的吗？我不知道，因为逻辑真的会耗费更多能量。在思考这件事情上，我们可是很会省能量的。这就说到“蠢”的时候。我们进化出了脑子，是帮我们思考，处理复杂环境的，但同时，它太耗能量了，我们不能一刻不停的思考。我们有很多故有程序。举一个例子，有个程序叫做贴标签，或者叫指代，或者叫类比。\n&emsp;&emsp;你会发现这是很明显的吧。如果你不清楚，那我再解释一下。这其实到了我想说的重点之一了。贴标签这回事。例如，有一个人做了“坏事”你会用“坏人”这个标签贴在这个人脑门子上。于是它做了任何其他事情，在你贴了对应标签的系统里面都是怀着不好的目的，都是有着“坏人”该有的心思的。于是你的脑子省下了大把的力气和能量，不用去想仔细推敲他为什么要做这个事情，总之识别出他是一个坏人的话（或者叫贴上了标签），远离他，堤防着他准是没有错的。事实就是如此，贴标签对我们的演化很多时候是有利的啊。\n&emsp;&emsp;这可以部分解释我的朋友圈的“怪相”了吧。什么“怪相”？那就是：谁谁谁发某某期刊了。是不是很好玩了，这里有个标签不知道你看到没。那就是某某期刊了啊。某某期刊其实是没有什么问题的，无非就是我们把某某期刊贴上了“好”期刊的标签了啊。大概也是大家省能量了啊。贴上了“好”标签之后，我们就不用思考谁谁谁研究的是个啥了啊。管它是个啥，总是“好”的吧。\n&emsp;&emsp;好了，此话题不宜讲太多，多了就露馅了，不好看了啊。\n&emsp;&emsp;那么就来到“坏”的话题了啊。那什么是“坏”啊？提到“坏”，那你是不是应该就想到了“好”啊？那讲好坏的时候，我们的立场是什么呢？那无非还是DNA告诉我们的生存啊。当别人做的事情，直接或简介，近期或远期威胁到你的生存（或其他需求）的时候，你就会觉得他是“坏”的。\n&emsp;&emsp;那么又回到贴标签这回事了。有些时候贴标签是好的啊，因为对于我们的生存是有利的。如果大家都贴一个标签，把此标签封为圭臬，那就挺好的哈。然而有些家伙会利用人们贴标签（“蠢”）的习惯在里面干“坏”事，在标签之下干自己的勾当，就是“坏”的了啊。\n&emsp;&emsp;然而，话又说回来了。在做评价的时候是需要站在某一个立场的。所谓立场先行。那换一个立场，坏的也就是好的了。例如，对于利用“蠢”来干“坏”事的主体，其实他干的事情是对他自己“好”的啊，而且他打破了标签束缚，他还是“聪明”的啊。\n&emsp;&emsp;天地不仁，以万物为刍狗。天地是没有立场的，也就没有分别心了啊。\n&emsp;&emsp;阿门。阿弥陀佛。哈利路亚。人受到DNA的控制，同时又有自己的脑子，有各种需求难以摆脱，是没有办法成佛成圣的。\n&emsp;&emsp;大约人间是地狱，人间也是天堂。\n","source":"_posts/2025-05-31-bad-and-evil.md","raw":"---\ntitle: 即“蠢”又“坏”？\ntags:\n  - 乱笔\ncategories:\n  - 某日记\nabbrlink: 6eb40c53\ndate: 2025-05-31 18:50:20\n---\n&emsp;&emsp;人大约都是即“蠢”又“坏”的吧！\n<!--less-->\n&emsp;&emsp;不要误会，并不是你想象中的“蠢”和“坏”。我们在讨论某个“东西”的时候，有必要对这个“东西”的概念进行解释，否则会造成鸡同鸭讲，对牛弹琴的结果。另外你也会发现，像我这种学理的，总会在和别人讨论之前要明确“东西”的定义。人的语言其实还是挺匮乏的，难以完美表述自己心中所想，要是讨论的话题没有进行明确的定义，那就容易自说自话。有句话叫做人的冲突80%都是定义不明，也是说明这种状况。现在我也大约能够明白为什么小时候读国外的小说都觉得他们怎么写得那么“啰嗦”。原因是因为语言不够准确吧，需要提供冗余的信息，才不至于让人理解错误，以传达错误的信息。这是他们的办法，而我们选择了浪漫。\n&emsp;&emsp;好了，先说“蠢”吧，算了，还是一起说，因为似乎他们难以分开。这两个词都是形容词，都是评价。当我们在评价一个人或物的时候，我们通常是站在了一个价值观，或角度或利益在讲。我讲他们难以分开，是站在哪个角度呢？\n&emsp;&emsp;首先站在旁观者的角度，不带利益取舍的看吧。但又似乎不能，因为我也是人，所以几乎不能客观。但不管，姑且认为我是客观的吧，至少也可以试着幻想自己是一个外星物。从进化的角度来看吧。人付出了一些东西，演化出了大脑这个东西。大脑有很多神经元，连接，可以处理应付适应甚至改变很复杂的环境，从此大约不需要进化了啊。在此之前至少走到了动物界之巅了啊，说走上了生物之巅还为时尚早。\n&emsp;&emsp;脑子是个好东西。我们会思考了。不过我们思考的时候，上帝就笑了。我们以为我们很会思考，其实，不是的。大脑只要一思考是很消耗能量的。老祖宗在恶劣的生存条件下，填饱肚子都是个挑战，能分配给脑子的能量是不够的啊。就像你要跑个AI模型，没有显卡，CPU只能跑个简单小模型啊。例如“狗”都会的条件反射。\n&emsp;&emsp;好了，我们肯定不只会“狗”都会的条件反射。我们还会逻辑。真的吗？我不知道，因为逻辑真的会耗费更多能量。在思考这件事情上，我们可是很会省能量的。这就说到“蠢”的时候。我们进化出了脑子，是帮我们思考，处理复杂环境的，但同时，它太耗能量了，我们不能一刻不停的思考。我们有很多故有程序。举一个例子，有个程序叫做贴标签，或者叫指代，或者叫类比。\n&emsp;&emsp;你会发现这是很明显的吧。如果你不清楚，那我再解释一下。这其实到了我想说的重点之一了。贴标签这回事。例如，有一个人做了“坏事”你会用“坏人”这个标签贴在这个人脑门子上。于是它做了任何其他事情，在你贴了对应标签的系统里面都是怀着不好的目的，都是有着“坏人”该有的心思的。于是你的脑子省下了大把的力气和能量，不用去想仔细推敲他为什么要做这个事情，总之识别出他是一个坏人的话（或者叫贴上了标签），远离他，堤防着他准是没有错的。事实就是如此，贴标签对我们的演化很多时候是有利的啊。\n&emsp;&emsp;这可以部分解释我的朋友圈的“怪相”了吧。什么“怪相”？那就是：谁谁谁发某某期刊了。是不是很好玩了，这里有个标签不知道你看到没。那就是某某期刊了啊。某某期刊其实是没有什么问题的，无非就是我们把某某期刊贴上了“好”期刊的标签了啊。大概也是大家省能量了啊。贴上了“好”标签之后，我们就不用思考谁谁谁研究的是个啥了啊。管它是个啥，总是“好”的吧。\n&emsp;&emsp;好了，此话题不宜讲太多，多了就露馅了，不好看了啊。\n&emsp;&emsp;那么就来到“坏”的话题了啊。那什么是“坏”啊？提到“坏”，那你是不是应该就想到了“好”啊？那讲好坏的时候，我们的立场是什么呢？那无非还是DNA告诉我们的生存啊。当别人做的事情，直接或简介，近期或远期威胁到你的生存（或其他需求）的时候，你就会觉得他是“坏”的。\n&emsp;&emsp;那么又回到贴标签这回事了。有些时候贴标签是好的啊，因为对于我们的生存是有利的。如果大家都贴一个标签，把此标签封为圭臬，那就挺好的哈。然而有些家伙会利用人们贴标签（“蠢”）的习惯在里面干“坏”事，在标签之下干自己的勾当，就是“坏”的了啊。\n&emsp;&emsp;然而，话又说回来了。在做评价的时候是需要站在某一个立场的。所谓立场先行。那换一个立场，坏的也就是好的了。例如，对于利用“蠢”来干“坏”事的主体，其实他干的事情是对他自己“好”的啊，而且他打破了标签束缚，他还是“聪明”的啊。\n&emsp;&emsp;天地不仁，以万物为刍狗。天地是没有立场的，也就没有分别心了啊。\n&emsp;&emsp;阿门。阿弥陀佛。哈利路亚。人受到DNA的控制，同时又有自己的脑子，有各种需求难以摆脱，是没有办法成佛成圣的。\n&emsp;&emsp;大约人间是地狱，人间也是天堂。\n","slug":"bad-and-evil","published":1,"updated":"2025-06-01T11:18:51.192Z","comments":1,"layout":"post","photos":[],"_id":"cmh498iqf00chwvouglttbu7x","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>&emsp;&emsp;不要误会，并不是你想象中的“蠢”和“坏”。我们在讨论某个“东西”的时候，有必要对这个“东西”的概念进行解释，否则会造成鸡同鸭讲，对牛弹琴的结果。另外你也会发现，像我这种学理的，总会在和别人讨论之前要明确“东西”的定义。人的语言其实还是挺匮乏的，难以完美表述自己心中所想，要是讨论的话题没有进行明确的定义，那就容易自说自话。有句话叫做人的冲突80%都是定义不明，也是说明这种状况。现在我也大约能够明白为什么小时候读国外的小说都觉得他们怎么写得那么“啰嗦”。原因是因为语言不够准确吧，需要提供冗余的信息，才不至于让人理解错误，以传达错误的信息。这是他们的办法，而我们选择了浪漫。<br>&emsp;&emsp;好了，先说“蠢”吧，算了，还是一起说，因为似乎他们难以分开。这两个词都是形容词，都是评价。当我们在评价一个人或物的时候，我们通常是站在了一个价值观，或角度或利益在讲。我讲他们难以分开，是站在哪个角度呢？<br>&emsp;&emsp;首先站在旁观者的角度，不带利益取舍的看吧。但又似乎不能，因为我也是人，所以几乎不能客观。但不管，姑且认为我是客观的吧，至少也可以试着幻想自己是一个外星物。从进化的角度来看吧。人付出了一些东西，演化出了大脑这个东西。大脑有很多神经元，连接，可以处理应付适应甚至改变很复杂的环境，从此大约不需要进化了啊。在此之前至少走到了动物界之巅了啊，说走上了生物之巅还为时尚早。<br>&emsp;&emsp;脑子是个好东西。我们会思考了。不过我们思考的时候，上帝就笑了。我们以为我们很会思考，其实，不是的。大脑只要一思考是很消耗能量的。老祖宗在恶劣的生存条件下，填饱肚子都是个挑战，能分配给脑子的能量是不够的啊。就像你要跑个AI模型，没有显卡，CPU只能跑个简单小模型啊。例如“狗”都会的条件反射。<br>&emsp;&emsp;好了，我们肯定不只会“狗”都会的条件反射。我们还会逻辑。真的吗？我不知道，因为逻辑真的会耗费更多能量。在思考这件事情上，我们可是很会省能量的。这就说到“蠢”的时候。我们进化出了脑子，是帮我们思考，处理复杂环境的，但同时，它太耗能量了，我们不能一刻不停的思考。我们有很多故有程序。举一个例子，有个程序叫做贴标签，或者叫指代，或者叫类比。<br>&emsp;&emsp;你会发现这是很明显的吧。如果你不清楚，那我再解释一下。这其实到了我想说的重点之一了。贴标签这回事。例如，有一个人做了“坏事”你会用“坏人”这个标签贴在这个人脑门子上。于是它做了任何其他事情，在你贴了对应标签的系统里面都是怀着不好的目的，都是有着“坏人”该有的心思的。于是你的脑子省下了大把的力气和能量，不用去想仔细推敲他为什么要做这个事情，总之识别出他是一个坏人的话（或者叫贴上了标签），远离他，堤防着他准是没有错的。事实就是如此，贴标签对我们的演化很多时候是有利的啊。<br>&emsp;&emsp;这可以部分解释我的朋友圈的“怪相”了吧。什么“怪相”？那就是：谁谁谁发某某期刊了。是不是很好玩了，这里有个标签不知道你看到没。那就是某某期刊了啊。某某期刊其实是没有什么问题的，无非就是我们把某某期刊贴上了“好”期刊的标签了啊。大概也是大家省能量了啊。贴上了“好”标签之后，我们就不用思考谁谁谁研究的是个啥了啊。管它是个啥，总是“好”的吧。<br>&emsp;&emsp;好了，此话题不宜讲太多，多了就露馅了，不好看了啊。<br>&emsp;&emsp;那么就来到“坏”的话题了啊。那什么是“坏”啊？提到“坏”，那你是不是应该就想到了“好”啊？那讲好坏的时候，我们的立场是什么呢？那无非还是DNA告诉我们的生存啊。当别人做的事情，直接或简介，近期或远期威胁到你的生存（或其他需求）的时候，你就会觉得他是“坏”的。<br>&emsp;&emsp;那么又回到贴标签这回事了。有些时候贴标签是好的啊，因为对于我们的生存是有利的。如果大家都贴一个标签，把此标签封为圭臬，那就挺好的哈。然而有些家伙会利用人们贴标签（“蠢”）的习惯在里面干“坏”事，在标签之下干自己的勾当，就是“坏”的了啊。<br>&emsp;&emsp;然而，话又说回来了。在做评价的时候是需要站在某一个立场的。所谓立场先行。那换一个立场，坏的也就是好的了。例如，对于利用“蠢”来干“坏”事的主体，其实他干的事情是对他自己“好”的啊，而且他打破了标签束缚，他还是“聪明”的啊。<br>&emsp;&emsp;天地不仁，以万物为刍狗。天地是没有立场的，也就没有分别心了啊。<br>&emsp;&emsp;阿门。阿弥陀佛。哈利路亚。人受到DNA的控制，同时又有自己的脑子，有各种需求难以摆脱，是没有办法成佛成圣的。<br>&emsp;&emsp;大约人间是地狱，人间也是天堂。</p>","related_posts":[],"length":1964,"excerpt":"<p>&emsp;&emsp;人大约都是即“蠢”又“坏”的吧！</p>","more":"<p>&emsp;&emsp;不要误会，并不是你想象中的“蠢”和“坏”。我们在讨论某个“东西”的时候，有必要对这个“东西”的概念进行解释，否则会造成鸡同鸭讲，对牛弹琴的结果。另外你也会发现，像我这种学理的，总会在和别人讨论之前要明确“东西”的定义。人的语言其实还是挺匮乏的，难以完美表述自己心中所想，要是讨论的话题没有进行明确的定义，那就容易自说自话。有句话叫做人的冲突80%都是定义不明，也是说明这种状况。现在我也大约能够明白为什么小时候读国外的小说都觉得他们怎么写得那么“啰嗦”。原因是因为语言不够准确吧，需要提供冗余的信息，才不至于让人理解错误，以传达错误的信息。这是他们的办法，而我们选择了浪漫。<br>&emsp;&emsp;好了，先说“蠢”吧，算了，还是一起说，因为似乎他们难以分开。这两个词都是形容词，都是评价。当我们在评价一个人或物的时候，我们通常是站在了一个价值观，或角度或利益在讲。我讲他们难以分开，是站在哪个角度呢？<br>&emsp;&emsp;首先站在旁观者的角度，不带利益取舍的看吧。但又似乎不能，因为我也是人，所以几乎不能客观。但不管，姑且认为我是客观的吧，至少也可以试着幻想自己是一个外星物。从进化的角度来看吧。人付出了一些东西，演化出了大脑这个东西。大脑有很多神经元，连接，可以处理应付适应甚至改变很复杂的环境，从此大约不需要进化了啊。在此之前至少走到了动物界之巅了啊，说走上了生物之巅还为时尚早。<br>&emsp;&emsp;脑子是个好东西。我们会思考了。不过我们思考的时候，上帝就笑了。我们以为我们很会思考，其实，不是的。大脑只要一思考是很消耗能量的。老祖宗在恶劣的生存条件下，填饱肚子都是个挑战，能分配给脑子的能量是不够的啊。就像你要跑个AI模型，没有显卡，CPU只能跑个简单小模型啊。例如“狗”都会的条件反射。<br>&emsp;&emsp;好了，我们肯定不只会“狗”都会的条件反射。我们还会逻辑。真的吗？我不知道，因为逻辑真的会耗费更多能量。在思考这件事情上，我们可是很会省能量的。这就说到“蠢”的时候。我们进化出了脑子，是帮我们思考，处理复杂环境的，但同时，它太耗能量了，我们不能一刻不停的思考。我们有很多故有程序。举一个例子，有个程序叫做贴标签，或者叫指代，或者叫类比。<br>&emsp;&emsp;你会发现这是很明显的吧。如果你不清楚，那我再解释一下。这其实到了我想说的重点之一了。贴标签这回事。例如，有一个人做了“坏事”你会用“坏人”这个标签贴在这个人脑门子上。于是它做了任何其他事情，在你贴了对应标签的系统里面都是怀着不好的目的，都是有着“坏人”该有的心思的。于是你的脑子省下了大把的力气和能量，不用去想仔细推敲他为什么要做这个事情，总之识别出他是一个坏人的话（或者叫贴上了标签），远离他，堤防着他准是没有错的。事实就是如此，贴标签对我们的演化很多时候是有利的啊。<br>&emsp;&emsp;这可以部分解释我的朋友圈的“怪相”了吧。什么“怪相”？那就是：谁谁谁发某某期刊了。是不是很好玩了，这里有个标签不知道你看到没。那就是某某期刊了啊。某某期刊其实是没有什么问题的，无非就是我们把某某期刊贴上了“好”期刊的标签了啊。大概也是大家省能量了啊。贴上了“好”标签之后，我们就不用思考谁谁谁研究的是个啥了啊。管它是个啥，总是“好”的吧。<br>&emsp;&emsp;好了，此话题不宜讲太多，多了就露馅了，不好看了啊。<br>&emsp;&emsp;那么就来到“坏”的话题了啊。那什么是“坏”啊？提到“坏”，那你是不是应该就想到了“好”啊？那讲好坏的时候，我们的立场是什么呢？那无非还是DNA告诉我们的生存啊。当别人做的事情，直接或简介，近期或远期威胁到你的生存（或其他需求）的时候，你就会觉得他是“坏”的。<br>&emsp;&emsp;那么又回到贴标签这回事了。有些时候贴标签是好的啊，因为对于我们的生存是有利的。如果大家都贴一个标签，把此标签封为圭臬，那就挺好的哈。然而有些家伙会利用人们贴标签（“蠢”）的习惯在里面干“坏”事，在标签之下干自己的勾当，就是“坏”的了啊。<br>&emsp;&emsp;然而，话又说回来了。在做评价的时候是需要站在某一个立场的。所谓立场先行。那换一个立场，坏的也就是好的了。例如，对于利用“蠢”来干“坏”事的主体，其实他干的事情是对他自己“好”的啊，而且他打破了标签束缚，他还是“聪明”的啊。<br>&emsp;&emsp;天地不仁，以万物为刍狗。天地是没有立场的，也就没有分别心了啊。<br>&emsp;&emsp;阿门。阿弥陀佛。哈利路亚。人受到DNA的控制，同时又有自己的脑子，有各种需求难以摆脱，是没有办法成佛成圣的。<br>&emsp;&emsp;大约人间是地狱，人间也是天堂。</p>"},{"title":"注意力机制","abbrlink":"141d1667","date":"2025-06-01T11:07:33.000Z","_content":"&emsp;&emsp;今天学习注意力机制（[Attention Mechanism](https://towardsdatascience.com/hands-on-attention-mechanism-for-time-series-classification-with-python/)）。\n<!--less-->\n&emsp;&emsp;注意力机制的核心思想是让模型能够动态聚焦于输入数据中最相关的部分。在时间序列分类中：\n工作原理：\n\n通过计算每个时间步的\"重要性分数\"（attention score）\n\n使用softmax函数将这些分数转换为0-1之间的权重\n\n对时间步特征进行加权求和，生成上下文向量（context vector）\n数学表示：\n\n   $e_i = f(h_i)$  # 计算每个隐藏状态h_i的能量分数\n   $α_i = exp(e_i) / Σ exp(e_j)$  # softmax归一化\n   $context = Σ (α_i * h_i)$  # 加权上下文向量\n与传统模型的对比：\n\n|模型类型 |处理变长异常能力 |可解释性 |计算效率|\n|-------|------|------|------|\n|FFN |❌ 固定位置依赖 |❌ 黑盒 |⭐⭐⭐⭐|\n|CNN |△ 局部感受野 |△ 中等 |⭐⭐⭐⭐|\n|Attention | ✅ 动态聚焦| ✅ 高（权重可视化）| ⭐⭐⭐|\n\n双向LSTM（BiLSTM）\n作用：作为特征提取器，捕获时间序列的前后依赖关系\n\n双向性：同时考虑过去和未来信息\n  \n  前向：h_forward = LSTM(从t=0到t=T)\n  后向：h_backward = LSTM(从t=T到t=0)\n  最终状态：h = [h_forward; h_backward]\n\n异常检测机制\n\n```mermaid\ngraph LR\n    A[原始正弦波] --> B[随机位置]\n    --> C[插入平坦段]\n    --> D[长度随机]\n    --> E[振幅/频率随机]\n    --> F[形成异常样本]\n```\n模型架构\n\n```python\nAttentionModel(\n  (lstm): LSTM(1, 32, bidirectional=True)\n  (attention): Sequential(\n    (0): Linear(in_features=64, out_features=64)\n    (1): Tanh()\n    (2): Linear(in_features=64, out_features=1)\n  )\n  (classifier): Sequential(\n    (0): Linear(in_features=64, out_features=1)\n    (1): Sigmoid()\n  )\n)\n```\n\n评估指标\nROC-AUC：衡量模型区分正负样本的能力\n\n值域[0,1]，>0.9表示优秀模型\nF1-Score：精确率和召回率的调和平均\n```\n   F1 = 2  (Precision  Recall) / (Precision + Recall)\n``` \n混淆矩阵：\n\n   |            |预测正常  |  预测异常|\n   |------|------|------|\n   |实际正常   |TN (真负例)  |FP (假正例)|\n   |实际异常   |FN (假负例)  |TP (真正例)|\n   \n\n\"学习注意力机制的最佳途径不是NLP而是时间序列\"\n优势：\n1. 复杂度降低：\n### NLP需要词嵌入/位置编码等额外层\n### 时间序列可直接使用原始数值数据\n### 示例：NLP处理流程 vs 时间序列处理\n```\n     # NLP\n     文本 → 分词 → 嵌入 → 位置编码 → 注意力\n     # 时间序列\n     原始信号 → 注意力\n``` \n2. 直观可视化：\n  时间序列的注意力权重可直接叠加在信号图上\n  NLP的注意力热力图需要专业知识解释\n3. 计算效率：\n  时间序列可生成小型合成数据集（文中5000样本）\n  训练在CPU上仅需几分钟（NLP模型通常需要GPU小时级训练）\n\n局限性：\n1. 语义理解缺失：\n NLP任务能更好展示注意力处理语义关系的能力\n 如：指代消解\"The animal didn't cross the street because it was too tired\"\n2. 实际应用偏差：\n  工业界注意力应用仍以NLP为主（BERT, GPT等）\n  时间序列注意力研究相对较少\n\n改进建议:\n1. 混合学习路径（推荐）\n\n```mermaid\ngraph TD\n    A[基础概念] --> B[时间序列示例]\n--> C[可视化理解]\n--> D[NLP进阶]\n--> E[CV扩展]\n```\n\n2. 增强时间序列实验设计\n  多类型异常：\n``` python\n  # 当前：仅平坦异常\n  wave[loc:end] = wave[loc] \n  \n  # 建议增加：\n  wave[loc:end] = 0  # 零值异常\n  wave[loc:end] = random_noise()  # 噪声异常\n  wave = add_spike(loc)  # 尖峰异常\n``` \n多变量时间序列：\n``` python\n    # 当前：单变量正弦波\n  X.shape = (5000, 500, 1)\n  \n  # 改进：多变量\n  X_multi = np.stack([sine_wave, \n                      cosine_wave, \n                      random_walk], axis=-1)\n```\n3. 模型架构优化\n\n多头注意力（Multi-Head Attention）：\n``` python\n    # 当前：单头\n  self.attention = nn.Sequential(...)\n  \n  # 改进：多头\n  self.multihead_attn = nn.MultiheadAttention(\n      embed_dim=64, num_heads=4\n  )\n``` \n位置编码增强：\n``` python\n    # 当前：依赖LSTM的顺序处理\n  # 改进：显式位置编码\n  position = torch.arange(0, seq_len).unsqueeze(1)\n  pe = torch.sin(position / 10000(2*i/d_model))\n``` \n4. 可解释性增强\n\n定量评估指标：\n``` python\n    def attention_accuracy(att_weights, anomaly_loc):\n      \"\"\"计算注意力聚焦异常区域的准确度\"\"\"\n      focus_region = att_weights.argmax()-10 : att_weights.argmax()+10\n      overlap = len(set(focus_region) & set(anomaly_loc))\n      return overlap / len(anomaly_loc)\n``` \n对比可视化：\n\n|样本类型 |正常样本| 异常样本|\n|------|------|------|\n|注意力分布| 均匀分布| 峰值在异常区|\n|典型模式| | |\n\n时间序列提供了更简洁直观的注意力学习路径。但在工业实践中，建议：\n1. 以时间序列作为入门起点\n2. 通过NLP任务深化语义理解\n3. 最终扩展到多模态应用\n\"注意力机制不是领域特定的工具，而是数据关系的动态透镜——时间序列提供了最干净的镜片来观察其本质。\"\n\npython脚本例子：\n```\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader, TensorDataset\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\n\n# 配置参数\nclass Config:\n    num_points = 500        # 时间序列长度\n    dataset_size = 5000     # 数据集大小\n    normal_ratio = 0.5      # 正常样本比例\n    min_freq = 1            # 最小频率\n    max_freq = 4            # 最大频率\n    min_amp = 1             # 最小振幅\n    max_amp = 10            # 最大振幅\n    min_loc_ratio = 0.0     # 异常位置最小比例\n    max_loc_ratio = 0.9     # 异常位置最大比例\n    min_length_ratio = 0.1  # 异常长度最小比例\n    max_length_ratio = 0.5  # 异常长度最大比例\n    batch_size = 32         # 批大小\n    lr = 0.001              # 学习率\n    num_epochs = 15         # 训练轮数\n    hidden_dim = 32         # LSTM隐藏层维度\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    patience = 5            # 早停耐心值\n\nconfig = Config()\n\n# 1. 数据生成\ndef generate_sine_wave(length, freq, amp):\n    \"\"\"生成正弦波\"\"\"\n    t = np.linspace(0, 2*np.pi, length)\n    return amp * np.sin(freq * t)\n\ndef generate_dataset(config):\n    \"\"\"生成数据集\"\"\"\n    X = []\n    y = []\n    \n    for _ in range(config.dataset_size):\n        # 随机生成频率和振幅\n        freq = np.random.uniform(config.min_freq, config.max_freq)\n        amp = np.random.uniform(config.min_amp, config.max_amp)\n        \n        # 生成正常或异常样本\n        if np.random.rand() < config.normal_ratio:\n            # 正常样本\n            wave = generate_sine_wave(config.num_points, freq, amp)\n            label = 0\n        else:\n            # 异常样本：生成正弦波并在随机位置插入平坦段\n            wave = generate_sine_wave(config.num_points, freq, amp)\n            # 随机选择异常位置和长度（按比例）\n            loc_ratio = np.random.uniform(config.min_loc_ratio, config.max_loc_ratio)\n            length_ratio = np.random.uniform(config.min_length_ratio, config.max_length_ratio)\n            loc = int(loc_ratio * config.num_points)\n            length = int(length_ratio * config.num_points)\n            end = min(loc + length, config.num_points)\n            # 将选定区域替换为常数值（取开始点的值）\n            wave[loc:end] = wave[loc]\n            label = 1\n        \n        X.append(wave)\n        y.append(label)\n    \n    # 转换为numpy数组\n    X = np.array(X)\n    y = np.array(y)\n    \n    # 转换为PyTorch张量\n    X_tensor = torch.tensor(X, dtype=torch.float32).unsqueeze(-1)  # (N, T, 1)\n    y_tensor = torch.tensor(y, dtype=torch.float32)  # (N,)\n    \n    return X_tensor, y_tensor\n\n# 2. 模型定义\nclass AttentionModel(nn.Module):\n    def __init__(self, input_dim=1, hidden_dim=32):\n        super(AttentionModel, self).__init__()\n        # 双向LSTM\n        self.lstm = nn.LSTM(\n            input_size=input_dim,\n            hidden_size=hidden_dim,\n            batch_first=True,\n            bidirectional=True\n        )\n        # 注意力权重计算\n        self.attention = nn.Sequential(\n            nn.Linear(2 * hidden_dim, 64),\n            nn.Tanh(),\n            nn.Linear(64, 1)\n        )\n        # 分类器\n        self.classifier = nn.Sequential(\n            nn.Linear(2 * hidden_dim, 1),\n            nn.Sigmoid()\n        )\n    \n    def forward(self, x):\n        # LSTM处理\n        lstm_out, _ = self.lstm(x)  # (batch_size, seq_len, 2*hidden_dim)\n        \n        # 计算注意力权重\n        e = self.attention(lstm_out).squeeze(-1)  # (batch_size, seq_len)\n        alpha = torch.softmax(e, dim=1)  # 归一化权重\n        alpha_expanded = alpha.unsqueeze(-1)  # (batch_size, seq_len, 1)\n        \n        # 加权得到上下文向量\n        context = torch.sum(alpha_expanded * lstm_out, dim=1)  # (batch_size, 2*hidden_dim)\n        \n        # 分类\n        out = self.classifier(context).squeeze(-1)  # (batch_size,)\n        return out, alpha\n\n# 3. 训练函数\ndef train_model(model, train_loader, val_loader, config):\n    model.to(config.device)\n    criterion = nn.BCELoss()\n    optimizer = optim.Adam(model.parameters(), lr=config.lr)\n    \n    best_val_loss = float('inf')\n    patience_counter = 0\n    \n    train_losses = []\n    val_losses = []\n    \n    for epoch in range(config.num_epochs):\n        # 训练阶段\n        model.train()\n        train_loss = 0.0\n        for batch_X, batch_y in train_loader:\n            batch_X, batch_y = batch_X.to(config.device), batch_y.to(config.device)\n            \n            optimizer.zero_grad()\n            outputs, _ = model(batch_X)\n            loss = criterion(outputs, batch_y)\n            loss.backward()\n            optimizer.step()\n            \n            train_loss += loss.item() * batch_X.size(0)\n        \n        # 计算平均训练损失\n        train_loss = train_loss / len(train_loader.dataset)\n        train_losses.append(train_loss)\n        \n        # 验证阶段\n        model.eval()\n        val_loss = 0.0\n        with torch.no_grad():\n            for batch_X, batch_y in val_loader:\n                batch_X, batch_y = batch_X.to(config.device), batch_y.to(config.device)\n                outputs, _ = model(batch_X)\n                loss = criterion(outputs, batch_y)\n                val_loss += loss.item() * batch_X.size(0)\n        \n        val_loss = val_loss / len(val_loader.dataset)\n        val_losses.append(val_loss)\n        \n        print(f'Epoch {epoch+1}/{config.num_epochs} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}')\n        \n        # 早停检查\n        if val_loss < best_val_loss:\n            best_val_loss = val_loss\n            patience_counter = 0\n            torch.save(model.state_dict(), 'best_model.pth')\n        else:\n            patience_counter += 1\n            if patience_counter >= config.patience:\n                print(f'Early stopping at epoch {epoch+1}')\n                break\n    \n    # 加载最佳模型\n    model.load_state_dict(torch.load('best_model.pth'))\n    return model, train_losses, val_losses\n\n# 4. 评估函数\ndef evaluate_model(model, test_loader, config):\n    model.eval()\n    y_true = []\n    y_pred = []\n    y_score = []\n    \n    with torch.no_grad():\n        for batch_X, batch_y in test_loader:\n            batch_X, batch_y = batch_X.to(config.device), batch_y.to(config.device)\n            outputs, _ = model(batch_X)\n            \n            # 收集真实标签和预测概率\n            y_true.extend(batch_y.cpu().numpy())\n            y_score.extend(outputs.cpu().numpy())\n            y_pred.extend((outputs > 0.5).float().cpu().numpy())\n    \n    # 计算指标\n    acc = accuracy_score(y_true, y_pred)\n    prec = precision_score(y_true, y_pred)\n    rec = recall_score(y_true, y_pred)\n    f1 = f1_score(y_true, y_pred)\n    auc = roc_auc_score(y_true, y_score)\n    cm = confusion_matrix(y_true, y_pred)\n    \n    print(f'Accuracy: {acc:.4f}')\n    print(f'Precision: {prec:.4f}')\n    print(f'Recall: {rec:.4f}')\n    print(f'F1 Score: {f1:.4f}')\n    print(f'ROC AUC: {auc:.4f}')\n    print('Confusion Matrix:')\n    print(cm)\n    \n    return acc, prec, rec, f1, auc, cm\n\n# 5. 可视化注意力\ndef plot_attention(wave, attention_weights, title='Attention Visualization'):\n    \"\"\"可视化注意力权重\"\"\"\n    wave = wave.squeeze()\n    attention_weights = attention_weights.squeeze()\n    \n    fig, ax1 = plt.subplots(figsize=(12, 4))\n    \n    # 绘制原始波形\n    ax1.plot(wave, 'b-', label='Signal')\n    ax1.set_xlabel('Time Step')\n    ax1.set_ylabel('Amplitude', color='b')\n    ax1.tick_params('y', colors='b')\n    \n    # 绘制注意力权重（红色虚线）\n    ax2 = ax1.twinx()\n    ax2.plot(attention_weights, 'r--', alpha=0.7, label='Attention')\n    ax2.set_ylabel('Attention Weight', color='r')\n    ax2.tick_params('y', colors='r')\n    ax2.set_ylim(0, 1.0)\n    \n    plt.title(title)\n    fig.tight_layout()\n    plt.show()\n\n# 主函数\ndef main():\n    # 生成数据\n    print(\"Generating dataset...\")\n    X, y = generate_dataset(config)\n    \n    # 划分训练集、验证集、测试集\n    X_train, X_temp, y_train, y_temp = train_test_split(\n        X, y, test_size=0.3, random_state=42\n    )\n    X_val, X_test, y_val, y_test = train_test_split(\n        X_temp, y_temp, test_size=0.5, random_state=42\n    )\n    \n    # 创建数据加载器\n    train_dataset = TensorDataset(X_train, y_train)\n    val_dataset = TensorDataset(X_val, y_val)\n    test_dataset = TensorDataset(X_test, y_test)\n    \n    train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True)\n    val_loader = DataLoader(val_dataset, batch_size=config.batch_size)\n    test_loader = DataLoader(test_dataset, batch_size=config.batch_size)\n    \n    # 初始化模型\n    model = AttentionModel(input_dim=1, hidden_dim=config.hidden_dim)\n    \n    # 训练模型\n    print(\"Training model...\")\n    model, train_losses, val_losses = train_model(model, train_loader, val_loader, config)\n    \n    # 评估模型\n    print(\"\\nEvaluating model on test set...\")\n    evaluate_model(model, test_loader, config)\n    \n    # 可视化训练过程\n    plt.figure(figsize=(10, 5))\n    plt.plot(train_losses, label='Train Loss')\n    plt.plot(val_losses, label='Validation Loss')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.title('Training and Validation Loss')\n    plt.show()\n    \n    # 可视化注意力机制\n    print(\"\\nVisualizing attention for sample examples...\")\n    model.eval()\n    with torch.no_grad():\n        # 随机选择一些测试样本\n        indices = np.random.choice(len(test_dataset), 4, replace=False)\n        for i in indices:\n            sample_X, sample_y = test_dataset[i]\n            sample_X = sample_X.unsqueeze(0).to(config.device)  # 增加批次维度\n            _, attention_weights = model(sample_X)\n            \n            # 转换回CPU和numpy\n            sample_X = sample_X.cpu().numpy().squeeze()\n            attention_weights = attention_weights.cpu().numpy().squeeze()\n            \n            # 绘制\n            title = f\"Sample {i} - {'Anomaly' if sample_y.item() == 1 else 'Normal'}\"\n            plot_attention(sample_X, attention_weights, title)\n\nif __name__ == \"__main__\":\n    main()\n```\n","source":"_posts/2025-06-01-attention-mechanism.md","raw":"---\ntitle: 注意力机制\ntags:\n  - python\ncategories:\n  - ai\nabbrlink: 141d1667\ndate: 2025-06-01 19:07:33\n---\n&emsp;&emsp;今天学习注意力机制（[Attention Mechanism](https://towardsdatascience.com/hands-on-attention-mechanism-for-time-series-classification-with-python/)）。\n<!--less-->\n&emsp;&emsp;注意力机制的核心思想是让模型能够动态聚焦于输入数据中最相关的部分。在时间序列分类中：\n工作原理：\n\n通过计算每个时间步的\"重要性分数\"（attention score）\n\n使用softmax函数将这些分数转换为0-1之间的权重\n\n对时间步特征进行加权求和，生成上下文向量（context vector）\n数学表示：\n\n   $e_i = f(h_i)$  # 计算每个隐藏状态h_i的能量分数\n   $α_i = exp(e_i) / Σ exp(e_j)$  # softmax归一化\n   $context = Σ (α_i * h_i)$  # 加权上下文向量\n与传统模型的对比：\n\n|模型类型 |处理变长异常能力 |可解释性 |计算效率|\n|-------|------|------|------|\n|FFN |❌ 固定位置依赖 |❌ 黑盒 |⭐⭐⭐⭐|\n|CNN |△ 局部感受野 |△ 中等 |⭐⭐⭐⭐|\n|Attention | ✅ 动态聚焦| ✅ 高（权重可视化）| ⭐⭐⭐|\n\n双向LSTM（BiLSTM）\n作用：作为特征提取器，捕获时间序列的前后依赖关系\n\n双向性：同时考虑过去和未来信息\n  \n  前向：h_forward = LSTM(从t=0到t=T)\n  后向：h_backward = LSTM(从t=T到t=0)\n  最终状态：h = [h_forward; h_backward]\n\n异常检测机制\n\n```mermaid\ngraph LR\n    A[原始正弦波] --> B[随机位置]\n    --> C[插入平坦段]\n    --> D[长度随机]\n    --> E[振幅/频率随机]\n    --> F[形成异常样本]\n```\n模型架构\n\n```python\nAttentionModel(\n  (lstm): LSTM(1, 32, bidirectional=True)\n  (attention): Sequential(\n    (0): Linear(in_features=64, out_features=64)\n    (1): Tanh()\n    (2): Linear(in_features=64, out_features=1)\n  )\n  (classifier): Sequential(\n    (0): Linear(in_features=64, out_features=1)\n    (1): Sigmoid()\n  )\n)\n```\n\n评估指标\nROC-AUC：衡量模型区分正负样本的能力\n\n值域[0,1]，>0.9表示优秀模型\nF1-Score：精确率和召回率的调和平均\n```\n   F1 = 2  (Precision  Recall) / (Precision + Recall)\n``` \n混淆矩阵：\n\n   |            |预测正常  |  预测异常|\n   |------|------|------|\n   |实际正常   |TN (真负例)  |FP (假正例)|\n   |实际异常   |FN (假负例)  |TP (真正例)|\n   \n\n\"学习注意力机制的最佳途径不是NLP而是时间序列\"\n优势：\n1. 复杂度降低：\n### NLP需要词嵌入/位置编码等额外层\n### 时间序列可直接使用原始数值数据\n### 示例：NLP处理流程 vs 时间序列处理\n```\n     # NLP\n     文本 → 分词 → 嵌入 → 位置编码 → 注意力\n     # 时间序列\n     原始信号 → 注意力\n``` \n2. 直观可视化：\n  时间序列的注意力权重可直接叠加在信号图上\n  NLP的注意力热力图需要专业知识解释\n3. 计算效率：\n  时间序列可生成小型合成数据集（文中5000样本）\n  训练在CPU上仅需几分钟（NLP模型通常需要GPU小时级训练）\n\n局限性：\n1. 语义理解缺失：\n NLP任务能更好展示注意力处理语义关系的能力\n 如：指代消解\"The animal didn't cross the street because it was too tired\"\n2. 实际应用偏差：\n  工业界注意力应用仍以NLP为主（BERT, GPT等）\n  时间序列注意力研究相对较少\n\n改进建议:\n1. 混合学习路径（推荐）\n\n```mermaid\ngraph TD\n    A[基础概念] --> B[时间序列示例]\n--> C[可视化理解]\n--> D[NLP进阶]\n--> E[CV扩展]\n```\n\n2. 增强时间序列实验设计\n  多类型异常：\n``` python\n  # 当前：仅平坦异常\n  wave[loc:end] = wave[loc] \n  \n  # 建议增加：\n  wave[loc:end] = 0  # 零值异常\n  wave[loc:end] = random_noise()  # 噪声异常\n  wave = add_spike(loc)  # 尖峰异常\n``` \n多变量时间序列：\n``` python\n    # 当前：单变量正弦波\n  X.shape = (5000, 500, 1)\n  \n  # 改进：多变量\n  X_multi = np.stack([sine_wave, \n                      cosine_wave, \n                      random_walk], axis=-1)\n```\n3. 模型架构优化\n\n多头注意力（Multi-Head Attention）：\n``` python\n    # 当前：单头\n  self.attention = nn.Sequential(...)\n  \n  # 改进：多头\n  self.multihead_attn = nn.MultiheadAttention(\n      embed_dim=64, num_heads=4\n  )\n``` \n位置编码增强：\n``` python\n    # 当前：依赖LSTM的顺序处理\n  # 改进：显式位置编码\n  position = torch.arange(0, seq_len).unsqueeze(1)\n  pe = torch.sin(position / 10000(2*i/d_model))\n``` \n4. 可解释性增强\n\n定量评估指标：\n``` python\n    def attention_accuracy(att_weights, anomaly_loc):\n      \"\"\"计算注意力聚焦异常区域的准确度\"\"\"\n      focus_region = att_weights.argmax()-10 : att_weights.argmax()+10\n      overlap = len(set(focus_region) & set(anomaly_loc))\n      return overlap / len(anomaly_loc)\n``` \n对比可视化：\n\n|样本类型 |正常样本| 异常样本|\n|------|------|------|\n|注意力分布| 均匀分布| 峰值在异常区|\n|典型模式| | |\n\n时间序列提供了更简洁直观的注意力学习路径。但在工业实践中，建议：\n1. 以时间序列作为入门起点\n2. 通过NLP任务深化语义理解\n3. 最终扩展到多模态应用\n\"注意力机制不是领域特定的工具，而是数据关系的动态透镜——时间序列提供了最干净的镜片来观察其本质。\"\n\npython脚本例子：\n```\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader, TensorDataset\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\n\n# 配置参数\nclass Config:\n    num_points = 500        # 时间序列长度\n    dataset_size = 5000     # 数据集大小\n    normal_ratio = 0.5      # 正常样本比例\n    min_freq = 1            # 最小频率\n    max_freq = 4            # 最大频率\n    min_amp = 1             # 最小振幅\n    max_amp = 10            # 最大振幅\n    min_loc_ratio = 0.0     # 异常位置最小比例\n    max_loc_ratio = 0.9     # 异常位置最大比例\n    min_length_ratio = 0.1  # 异常长度最小比例\n    max_length_ratio = 0.5  # 异常长度最大比例\n    batch_size = 32         # 批大小\n    lr = 0.001              # 学习率\n    num_epochs = 15         # 训练轮数\n    hidden_dim = 32         # LSTM隐藏层维度\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    patience = 5            # 早停耐心值\n\nconfig = Config()\n\n# 1. 数据生成\ndef generate_sine_wave(length, freq, amp):\n    \"\"\"生成正弦波\"\"\"\n    t = np.linspace(0, 2*np.pi, length)\n    return amp * np.sin(freq * t)\n\ndef generate_dataset(config):\n    \"\"\"生成数据集\"\"\"\n    X = []\n    y = []\n    \n    for _ in range(config.dataset_size):\n        # 随机生成频率和振幅\n        freq = np.random.uniform(config.min_freq, config.max_freq)\n        amp = np.random.uniform(config.min_amp, config.max_amp)\n        \n        # 生成正常或异常样本\n        if np.random.rand() < config.normal_ratio:\n            # 正常样本\n            wave = generate_sine_wave(config.num_points, freq, amp)\n            label = 0\n        else:\n            # 异常样本：生成正弦波并在随机位置插入平坦段\n            wave = generate_sine_wave(config.num_points, freq, amp)\n            # 随机选择异常位置和长度（按比例）\n            loc_ratio = np.random.uniform(config.min_loc_ratio, config.max_loc_ratio)\n            length_ratio = np.random.uniform(config.min_length_ratio, config.max_length_ratio)\n            loc = int(loc_ratio * config.num_points)\n            length = int(length_ratio * config.num_points)\n            end = min(loc + length, config.num_points)\n            # 将选定区域替换为常数值（取开始点的值）\n            wave[loc:end] = wave[loc]\n            label = 1\n        \n        X.append(wave)\n        y.append(label)\n    \n    # 转换为numpy数组\n    X = np.array(X)\n    y = np.array(y)\n    \n    # 转换为PyTorch张量\n    X_tensor = torch.tensor(X, dtype=torch.float32).unsqueeze(-1)  # (N, T, 1)\n    y_tensor = torch.tensor(y, dtype=torch.float32)  # (N,)\n    \n    return X_tensor, y_tensor\n\n# 2. 模型定义\nclass AttentionModel(nn.Module):\n    def __init__(self, input_dim=1, hidden_dim=32):\n        super(AttentionModel, self).__init__()\n        # 双向LSTM\n        self.lstm = nn.LSTM(\n            input_size=input_dim,\n            hidden_size=hidden_dim,\n            batch_first=True,\n            bidirectional=True\n        )\n        # 注意力权重计算\n        self.attention = nn.Sequential(\n            nn.Linear(2 * hidden_dim, 64),\n            nn.Tanh(),\n            nn.Linear(64, 1)\n        )\n        # 分类器\n        self.classifier = nn.Sequential(\n            nn.Linear(2 * hidden_dim, 1),\n            nn.Sigmoid()\n        )\n    \n    def forward(self, x):\n        # LSTM处理\n        lstm_out, _ = self.lstm(x)  # (batch_size, seq_len, 2*hidden_dim)\n        \n        # 计算注意力权重\n        e = self.attention(lstm_out).squeeze(-1)  # (batch_size, seq_len)\n        alpha = torch.softmax(e, dim=1)  # 归一化权重\n        alpha_expanded = alpha.unsqueeze(-1)  # (batch_size, seq_len, 1)\n        \n        # 加权得到上下文向量\n        context = torch.sum(alpha_expanded * lstm_out, dim=1)  # (batch_size, 2*hidden_dim)\n        \n        # 分类\n        out = self.classifier(context).squeeze(-1)  # (batch_size,)\n        return out, alpha\n\n# 3. 训练函数\ndef train_model(model, train_loader, val_loader, config):\n    model.to(config.device)\n    criterion = nn.BCELoss()\n    optimizer = optim.Adam(model.parameters(), lr=config.lr)\n    \n    best_val_loss = float('inf')\n    patience_counter = 0\n    \n    train_losses = []\n    val_losses = []\n    \n    for epoch in range(config.num_epochs):\n        # 训练阶段\n        model.train()\n        train_loss = 0.0\n        for batch_X, batch_y in train_loader:\n            batch_X, batch_y = batch_X.to(config.device), batch_y.to(config.device)\n            \n            optimizer.zero_grad()\n            outputs, _ = model(batch_X)\n            loss = criterion(outputs, batch_y)\n            loss.backward()\n            optimizer.step()\n            \n            train_loss += loss.item() * batch_X.size(0)\n        \n        # 计算平均训练损失\n        train_loss = train_loss / len(train_loader.dataset)\n        train_losses.append(train_loss)\n        \n        # 验证阶段\n        model.eval()\n        val_loss = 0.0\n        with torch.no_grad():\n            for batch_X, batch_y in val_loader:\n                batch_X, batch_y = batch_X.to(config.device), batch_y.to(config.device)\n                outputs, _ = model(batch_X)\n                loss = criterion(outputs, batch_y)\n                val_loss += loss.item() * batch_X.size(0)\n        \n        val_loss = val_loss / len(val_loader.dataset)\n        val_losses.append(val_loss)\n        \n        print(f'Epoch {epoch+1}/{config.num_epochs} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}')\n        \n        # 早停检查\n        if val_loss < best_val_loss:\n            best_val_loss = val_loss\n            patience_counter = 0\n            torch.save(model.state_dict(), 'best_model.pth')\n        else:\n            patience_counter += 1\n            if patience_counter >= config.patience:\n                print(f'Early stopping at epoch {epoch+1}')\n                break\n    \n    # 加载最佳模型\n    model.load_state_dict(torch.load('best_model.pth'))\n    return model, train_losses, val_losses\n\n# 4. 评估函数\ndef evaluate_model(model, test_loader, config):\n    model.eval()\n    y_true = []\n    y_pred = []\n    y_score = []\n    \n    with torch.no_grad():\n        for batch_X, batch_y in test_loader:\n            batch_X, batch_y = batch_X.to(config.device), batch_y.to(config.device)\n            outputs, _ = model(batch_X)\n            \n            # 收集真实标签和预测概率\n            y_true.extend(batch_y.cpu().numpy())\n            y_score.extend(outputs.cpu().numpy())\n            y_pred.extend((outputs > 0.5).float().cpu().numpy())\n    \n    # 计算指标\n    acc = accuracy_score(y_true, y_pred)\n    prec = precision_score(y_true, y_pred)\n    rec = recall_score(y_true, y_pred)\n    f1 = f1_score(y_true, y_pred)\n    auc = roc_auc_score(y_true, y_score)\n    cm = confusion_matrix(y_true, y_pred)\n    \n    print(f'Accuracy: {acc:.4f}')\n    print(f'Precision: {prec:.4f}')\n    print(f'Recall: {rec:.4f}')\n    print(f'F1 Score: {f1:.4f}')\n    print(f'ROC AUC: {auc:.4f}')\n    print('Confusion Matrix:')\n    print(cm)\n    \n    return acc, prec, rec, f1, auc, cm\n\n# 5. 可视化注意力\ndef plot_attention(wave, attention_weights, title='Attention Visualization'):\n    \"\"\"可视化注意力权重\"\"\"\n    wave = wave.squeeze()\n    attention_weights = attention_weights.squeeze()\n    \n    fig, ax1 = plt.subplots(figsize=(12, 4))\n    \n    # 绘制原始波形\n    ax1.plot(wave, 'b-', label='Signal')\n    ax1.set_xlabel('Time Step')\n    ax1.set_ylabel('Amplitude', color='b')\n    ax1.tick_params('y', colors='b')\n    \n    # 绘制注意力权重（红色虚线）\n    ax2 = ax1.twinx()\n    ax2.plot(attention_weights, 'r--', alpha=0.7, label='Attention')\n    ax2.set_ylabel('Attention Weight', color='r')\n    ax2.tick_params('y', colors='r')\n    ax2.set_ylim(0, 1.0)\n    \n    plt.title(title)\n    fig.tight_layout()\n    plt.show()\n\n# 主函数\ndef main():\n    # 生成数据\n    print(\"Generating dataset...\")\n    X, y = generate_dataset(config)\n    \n    # 划分训练集、验证集、测试集\n    X_train, X_temp, y_train, y_temp = train_test_split(\n        X, y, test_size=0.3, random_state=42\n    )\n    X_val, X_test, y_val, y_test = train_test_split(\n        X_temp, y_temp, test_size=0.5, random_state=42\n    )\n    \n    # 创建数据加载器\n    train_dataset = TensorDataset(X_train, y_train)\n    val_dataset = TensorDataset(X_val, y_val)\n    test_dataset = TensorDataset(X_test, y_test)\n    \n    train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True)\n    val_loader = DataLoader(val_dataset, batch_size=config.batch_size)\n    test_loader = DataLoader(test_dataset, batch_size=config.batch_size)\n    \n    # 初始化模型\n    model = AttentionModel(input_dim=1, hidden_dim=config.hidden_dim)\n    \n    # 训练模型\n    print(\"Training model...\")\n    model, train_losses, val_losses = train_model(model, train_loader, val_loader, config)\n    \n    # 评估模型\n    print(\"\\nEvaluating model on test set...\")\n    evaluate_model(model, test_loader, config)\n    \n    # 可视化训练过程\n    plt.figure(figsize=(10, 5))\n    plt.plot(train_losses, label='Train Loss')\n    plt.plot(val_losses, label='Validation Loss')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.title('Training and Validation Loss')\n    plt.show()\n    \n    # 可视化注意力机制\n    print(\"\\nVisualizing attention for sample examples...\")\n    model.eval()\n    with torch.no_grad():\n        # 随机选择一些测试样本\n        indices = np.random.choice(len(test_dataset), 4, replace=False)\n        for i in indices:\n            sample_X, sample_y = test_dataset[i]\n            sample_X = sample_X.unsqueeze(0).to(config.device)  # 增加批次维度\n            _, attention_weights = model(sample_X)\n            \n            # 转换回CPU和numpy\n            sample_X = sample_X.cpu().numpy().squeeze()\n            attention_weights = attention_weights.cpu().numpy().squeeze()\n            \n            # 绘制\n            title = f\"Sample {i} - {'Anomaly' if sample_y.item() == 1 else 'Normal'}\"\n            plot_attention(sample_X, attention_weights, title)\n\nif __name__ == \"__main__\":\n    main()\n```\n","slug":"attention-mechanism","published":1,"updated":"2025-06-01T13:01:23.897Z","comments":1,"layout":"post","photos":[],"_id":"cmh498iqg00ckwvou9ven8kv6","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>&emsp;&emsp;注意力机制的核心思想是让模型能够动态聚焦于输入数据中最相关的部分。在时间序列分类中：<br>工作原理：</p>\n<p>通过计算每个时间步的”重要性分数”（attention score）</p>\n<p>使用softmax函数将这些分数转换为0-1之间的权重</p>\n<p>对时间步特征进行加权求和，生成上下文向量（context vector）<br>数学表示：</p>\n<p>   $e_i &#x3D; f(h_i)$  # 计算每个隐藏状态h_i的能量分数<br>   $α_i &#x3D; exp(e_i) &#x2F; Σ exp(e_j)$  # softmax归一化<br>   $context &#x3D; Σ (α_i * h_i)$  # 加权上下文向量<br>与传统模型的对比：</p>\n<table>\n<thead>\n<tr>\n<th>模型类型</th>\n<th>处理变长异常能力</th>\n<th>可解释性</th>\n<th>计算效率</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>FFN</td>\n<td>❌ 固定位置依赖</td>\n<td>❌ 黑盒</td>\n<td>⭐⭐⭐⭐</td>\n</tr>\n<tr>\n<td>CNN</td>\n<td>△ 局部感受野</td>\n<td>△ 中等</td>\n<td>⭐⭐⭐⭐</td>\n</tr>\n<tr>\n<td>Attention</td>\n<td>✅ 动态聚焦</td>\n<td>✅ 高（权重可视化）</td>\n<td>⭐⭐⭐</td>\n</tr>\n</tbody></table>\n<p>双向LSTM（BiLSTM）<br>作用：作为特征提取器，捕获时间序列的前后依赖关系</p>\n<p>双向性：同时考虑过去和未来信息</p>\n<p>  前向：h_forward &#x3D; LSTM(从t&#x3D;0到t&#x3D;T)<br>  后向：h_backward &#x3D; LSTM(从t&#x3D;T到t&#x3D;0)<br>  最终状态：h &#x3D; [h_forward; h_backward]</p>\n<p>异常检测机制</p>\n<pre class=\"mermaid\">graph LR\n    A[原始正弦波] --> B[随机位置]\n    --> C[插入平坦段]\n    --> D[长度随机]\n    --> E[振幅/频率随机]\n    --> F[形成异常样本]</pre>\n<p>模型架构</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">AttentionModel(</span><br><span class=\"line\">  (lstm): LSTM(<span class=\"number\">1</span>, <span class=\"number\">32</span>, bidirectional=<span class=\"literal\">True</span>)</span><br><span class=\"line\">  (attention): Sequential(</span><br><span class=\"line\">    (<span class=\"number\">0</span>): Linear(in_features=<span class=\"number\">64</span>, out_features=<span class=\"number\">64</span>)</span><br><span class=\"line\">    (<span class=\"number\">1</span>): Tanh()</span><br><span class=\"line\">    (<span class=\"number\">2</span>): Linear(in_features=<span class=\"number\">64</span>, out_features=<span class=\"number\">1</span>)</span><br><span class=\"line\">  )</span><br><span class=\"line\">  (classifier): Sequential(</span><br><span class=\"line\">    (<span class=\"number\">0</span>): Linear(in_features=<span class=\"number\">64</span>, out_features=<span class=\"number\">1</span>)</span><br><span class=\"line\">    (<span class=\"number\">1</span>): Sigmoid()</span><br><span class=\"line\">  )</span><br><span class=\"line\">)</span><br></pre></td></tr></table></figure>\n\n<p>评估指标<br>ROC-AUC：衡量模型区分正负样本的能力</p>\n<p>值域[0,1]，&gt;0.9表示优秀模型<br>F1-Score：精确率和召回率的调和平均</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">F1 = 2  (Precision  Recall) / (Precision + Recall)</span><br></pre></td></tr></table></figure>\n<p>混淆矩阵：</p>\n<table>\n<thead>\n<tr>\n<th></th>\n<th>预测正常</th>\n<th>预测异常</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>实际正常</td>\n<td>TN (真负例)</td>\n<td>FP (假正例)</td>\n</tr>\n<tr>\n<td>实际异常</td>\n<td>FN (假负例)</td>\n<td>TP (真正例)</td>\n</tr>\n</tbody></table>\n<p>“学习注意力机制的最佳途径不是NLP而是时间序列”<br>优势：</p>\n<ol>\n<li>复杂度降低：</li>\n</ol>\n<h3 id=\"NLP需要词嵌入-位置编码等额外层\"><a href=\"#NLP需要词嵌入-位置编码等额外层\" class=\"headerlink\" title=\"NLP需要词嵌入&#x2F;位置编码等额外层\"></a>NLP需要词嵌入&#x2F;位置编码等额外层</h3><h3 id=\"时间序列可直接使用原始数值数据\"><a href=\"#时间序列可直接使用原始数值数据\" class=\"headerlink\" title=\"时间序列可直接使用原始数值数据\"></a>时间序列可直接使用原始数值数据</h3><h3 id=\"示例：NLP处理流程-vs-时间序列处理\"><a href=\"#示例：NLP处理流程-vs-时间序列处理\" class=\"headerlink\" title=\"示例：NLP处理流程 vs 时间序列处理\"></a>示例：NLP处理流程 vs 时间序列处理</h3><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># NLP</span><br><span class=\"line\">文本 → 分词 → 嵌入 → 位置编码 → 注意力</span><br><span class=\"line\"># 时间序列</span><br><span class=\"line\">原始信号 → 注意力</span><br></pre></td></tr></table></figure>\n<ol start=\"2\">\n<li>直观可视化：<br>  时间序列的注意力权重可直接叠加在信号图上<br>  NLP的注意力热力图需要专业知识解释</li>\n<li>计算效率：<br>  时间序列可生成小型合成数据集（文中5000样本）<br>  训练在CPU上仅需几分钟（NLP模型通常需要GPU小时级训练）</li>\n</ol>\n<p>局限性：</p>\n<ol>\n<li>语义理解缺失：<br> NLP任务能更好展示注意力处理语义关系的能力<br> 如：指代消解”The animal didn’t cross the street because it was too tired”</li>\n<li>实际应用偏差：<br>  工业界注意力应用仍以NLP为主（BERT, GPT等）<br>  时间序列注意力研究相对较少</li>\n</ol>\n<p>改进建议:</p>\n<ol>\n<li>混合学习路径（推荐）</li>\n</ol>\n<pre class=\"mermaid\">graph TD\n    A[基础概念] --> B[时间序列示例]\n--> C[可视化理解]\n--> D[NLP进阶]\n--> E[CV扩展]</pre>\n\n<ol start=\"2\">\n<li>增强时间序列实验设计<br>  多类型异常：<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 当前：仅平坦异常</span></span><br><span class=\"line\">wave[loc:end] = wave[loc] </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 建议增加：</span></span><br><span class=\"line\">wave[loc:end] = <span class=\"number\">0</span>  <span class=\"comment\"># 零值异常</span></span><br><span class=\"line\">wave[loc:end] = random_noise()  <span class=\"comment\"># 噪声异常</span></span><br><span class=\"line\">wave = add_spike(loc)  <span class=\"comment\"># 尖峰异常</span></span><br></pre></td></tr></table></figure>\n多变量时间序列：<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">  <span class=\"comment\"># 当前：单变量正弦波</span></span><br><span class=\"line\">X.shape = (<span class=\"number\">5000</span>, <span class=\"number\">500</span>, <span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 改进：多变量</span></span><br><span class=\"line\">X_multi = np.stack([sine_wave, </span><br><span class=\"line\">                    cosine_wave, </span><br><span class=\"line\">                    random_walk], axis=-<span class=\"number\">1</span>)</span><br></pre></td></tr></table></figure></li>\n<li>模型架构优化</li>\n</ol>\n<p>多头注意力（Multi-Head Attention）：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">  <span class=\"comment\"># 当前：单头</span></span><br><span class=\"line\"><span class=\"variable language_\">self</span>.attention = nn.Sequential(...)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 改进：多头</span></span><br><span class=\"line\"><span class=\"variable language_\">self</span>.multihead_attn = nn.MultiheadAttention(</span><br><span class=\"line\">    embed_dim=<span class=\"number\">64</span>, num_heads=<span class=\"number\">4</span></span><br><span class=\"line\">)</span><br></pre></td></tr></table></figure>\n<p>位置编码增强：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">  <span class=\"comment\"># 当前：依赖LSTM的顺序处理</span></span><br><span class=\"line\"><span class=\"comment\"># 改进：显式位置编码</span></span><br><span class=\"line\">position = torch.arange(<span class=\"number\">0</span>, seq_len).unsqueeze(<span class=\"number\">1</span>)</span><br><span class=\"line\">pe = torch.sin(position / <span class=\"number\">10000</span>(<span class=\"number\">2</span>*i/d_model))</span><br></pre></td></tr></table></figure>\n<ol start=\"4\">\n<li>可解释性增强</li>\n</ol>\n<p>定量评估指标：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">attention_accuracy</span>(<span class=\"params\">att_weights, anomaly_loc</span>):</span><br><span class=\"line\">  <span class=\"string\">&quot;&quot;&quot;计算注意力聚焦异常区域的准确度&quot;&quot;&quot;</span></span><br><span class=\"line\">  focus_region = att_weights.argmax()-<span class=\"number\">10</span> : att_weights.argmax()+<span class=\"number\">10</span></span><br><span class=\"line\">  overlap = <span class=\"built_in\">len</span>(<span class=\"built_in\">set</span>(focus_region) &amp; <span class=\"built_in\">set</span>(anomaly_loc))</span><br><span class=\"line\">  <span class=\"keyword\">return</span> overlap / <span class=\"built_in\">len</span>(anomaly_loc)</span><br></pre></td></tr></table></figure>\n<p>对比可视化：</p>\n<table>\n<thead>\n<tr>\n<th>样本类型</th>\n<th>正常样本</th>\n<th>异常样本</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>注意力分布</td>\n<td>均匀分布</td>\n<td>峰值在异常区</td>\n</tr>\n<tr>\n<td>典型模式</td>\n<td></td>\n<td></td>\n</tr>\n</tbody></table>\n<p>时间序列提供了更简洁直观的注意力学习路径。但在工业实践中，建议：</p>\n<ol>\n<li>以时间序列作为入门起点</li>\n<li>通过NLP任务深化语义理解</li>\n<li>最终扩展到多模态应用<br>“注意力机制不是领域特定的工具，而是数据关系的动态透镜——时间序列提供了最干净的镜片来观察其本质。”</li>\n</ol>\n<p>python脚本例子：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br><span class=\"line\">145</span><br><span class=\"line\">146</span><br><span class=\"line\">147</span><br><span class=\"line\">148</span><br><span class=\"line\">149</span><br><span class=\"line\">150</span><br><span class=\"line\">151</span><br><span class=\"line\">152</span><br><span class=\"line\">153</span><br><span class=\"line\">154</span><br><span class=\"line\">155</span><br><span class=\"line\">156</span><br><span class=\"line\">157</span><br><span class=\"line\">158</span><br><span class=\"line\">159</span><br><span class=\"line\">160</span><br><span class=\"line\">161</span><br><span class=\"line\">162</span><br><span class=\"line\">163</span><br><span class=\"line\">164</span><br><span class=\"line\">165</span><br><span class=\"line\">166</span><br><span class=\"line\">167</span><br><span class=\"line\">168</span><br><span class=\"line\">169</span><br><span class=\"line\">170</span><br><span class=\"line\">171</span><br><span class=\"line\">172</span><br><span class=\"line\">173</span><br><span class=\"line\">174</span><br><span class=\"line\">175</span><br><span class=\"line\">176</span><br><span class=\"line\">177</span><br><span class=\"line\">178</span><br><span class=\"line\">179</span><br><span class=\"line\">180</span><br><span class=\"line\">181</span><br><span class=\"line\">182</span><br><span class=\"line\">183</span><br><span class=\"line\">184</span><br><span class=\"line\">185</span><br><span class=\"line\">186</span><br><span class=\"line\">187</span><br><span class=\"line\">188</span><br><span class=\"line\">189</span><br><span class=\"line\">190</span><br><span class=\"line\">191</span><br><span class=\"line\">192</span><br><span class=\"line\">193</span><br><span class=\"line\">194</span><br><span class=\"line\">195</span><br><span class=\"line\">196</span><br><span class=\"line\">197</span><br><span class=\"line\">198</span><br><span class=\"line\">199</span><br><span class=\"line\">200</span><br><span class=\"line\">201</span><br><span class=\"line\">202</span><br><span class=\"line\">203</span><br><span class=\"line\">204</span><br><span class=\"line\">205</span><br><span class=\"line\">206</span><br><span class=\"line\">207</span><br><span class=\"line\">208</span><br><span class=\"line\">209</span><br><span class=\"line\">210</span><br><span class=\"line\">211</span><br><span class=\"line\">212</span><br><span class=\"line\">213</span><br><span class=\"line\">214</span><br><span class=\"line\">215</span><br><span class=\"line\">216</span><br><span class=\"line\">217</span><br><span class=\"line\">218</span><br><span class=\"line\">219</span><br><span class=\"line\">220</span><br><span class=\"line\">221</span><br><span class=\"line\">222</span><br><span class=\"line\">223</span><br><span class=\"line\">224</span><br><span class=\"line\">225</span><br><span class=\"line\">226</span><br><span class=\"line\">227</span><br><span class=\"line\">228</span><br><span class=\"line\">229</span><br><span class=\"line\">230</span><br><span class=\"line\">231</span><br><span class=\"line\">232</span><br><span class=\"line\">233</span><br><span class=\"line\">234</span><br><span class=\"line\">235</span><br><span class=\"line\">236</span><br><span class=\"line\">237</span><br><span class=\"line\">238</span><br><span class=\"line\">239</span><br><span class=\"line\">240</span><br><span class=\"line\">241</span><br><span class=\"line\">242</span><br><span class=\"line\">243</span><br><span class=\"line\">244</span><br><span class=\"line\">245</span><br><span class=\"line\">246</span><br><span class=\"line\">247</span><br><span class=\"line\">248</span><br><span class=\"line\">249</span><br><span class=\"line\">250</span><br><span class=\"line\">251</span><br><span class=\"line\">252</span><br><span class=\"line\">253</span><br><span class=\"line\">254</span><br><span class=\"line\">255</span><br><span class=\"line\">256</span><br><span class=\"line\">257</span><br><span class=\"line\">258</span><br><span class=\"line\">259</span><br><span class=\"line\">260</span><br><span class=\"line\">261</span><br><span class=\"line\">262</span><br><span class=\"line\">263</span><br><span class=\"line\">264</span><br><span class=\"line\">265</span><br><span class=\"line\">266</span><br><span class=\"line\">267</span><br><span class=\"line\">268</span><br><span class=\"line\">269</span><br><span class=\"line\">270</span><br><span class=\"line\">271</span><br><span class=\"line\">272</span><br><span class=\"line\">273</span><br><span class=\"line\">274</span><br><span class=\"line\">275</span><br><span class=\"line\">276</span><br><span class=\"line\">277</span><br><span class=\"line\">278</span><br><span class=\"line\">279</span><br><span class=\"line\">280</span><br><span class=\"line\">281</span><br><span class=\"line\">282</span><br><span class=\"line\">283</span><br><span class=\"line\">284</span><br><span class=\"line\">285</span><br><span class=\"line\">286</span><br><span class=\"line\">287</span><br><span class=\"line\">288</span><br><span class=\"line\">289</span><br><span class=\"line\">290</span><br><span class=\"line\">291</span><br><span class=\"line\">292</span><br><span class=\"line\">293</span><br><span class=\"line\">294</span><br><span class=\"line\">295</span><br><span class=\"line\">296</span><br><span class=\"line\">297</span><br><span class=\"line\">298</span><br><span class=\"line\">299</span><br><span class=\"line\">300</span><br><span class=\"line\">301</span><br><span class=\"line\">302</span><br><span class=\"line\">303</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">import numpy as np</span><br><span class=\"line\">import matplotlib.pyplot as plt</span><br><span class=\"line\">import torch</span><br><span class=\"line\">import torch.nn as nn</span><br><span class=\"line\">import torch.optim as optim</span><br><span class=\"line\">from torch.utils.data import Dataset, DataLoader, TensorDataset</span><br><span class=\"line\">from sklearn.model_selection import train_test_split</span><br><span class=\"line\">from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score</span><br><span class=\"line\"></span><br><span class=\"line\"># 配置参数</span><br><span class=\"line\">class Config:</span><br><span class=\"line\">    num_points = 500        # 时间序列长度</span><br><span class=\"line\">    dataset_size = 5000     # 数据集大小</span><br><span class=\"line\">    normal_ratio = 0.5      # 正常样本比例</span><br><span class=\"line\">    min_freq = 1            # 最小频率</span><br><span class=\"line\">    max_freq = 4            # 最大频率</span><br><span class=\"line\">    min_amp = 1             # 最小振幅</span><br><span class=\"line\">    max_amp = 10            # 最大振幅</span><br><span class=\"line\">    min_loc_ratio = 0.0     # 异常位置最小比例</span><br><span class=\"line\">    max_loc_ratio = 0.9     # 异常位置最大比例</span><br><span class=\"line\">    min_length_ratio = 0.1  # 异常长度最小比例</span><br><span class=\"line\">    max_length_ratio = 0.5  # 异常长度最大比例</span><br><span class=\"line\">    batch_size = 32         # 批大小</span><br><span class=\"line\">    lr = 0.001              # 学习率</span><br><span class=\"line\">    num_epochs = 15         # 训练轮数</span><br><span class=\"line\">    hidden_dim = 32         # LSTM隐藏层维度</span><br><span class=\"line\">    device = torch.device(&#x27;cuda&#x27; if torch.cuda.is_available() else &#x27;cpu&#x27;)</span><br><span class=\"line\">    patience = 5            # 早停耐心值</span><br><span class=\"line\"></span><br><span class=\"line\">config = Config()</span><br><span class=\"line\"></span><br><span class=\"line\"># 1. 数据生成</span><br><span class=\"line\">def generate_sine_wave(length, freq, amp):</span><br><span class=\"line\">    &quot;&quot;&quot;生成正弦波&quot;&quot;&quot;</span><br><span class=\"line\">    t = np.linspace(0, 2*np.pi, length)</span><br><span class=\"line\">    return amp * np.sin(freq * t)</span><br><span class=\"line\"></span><br><span class=\"line\">def generate_dataset(config):</span><br><span class=\"line\">    &quot;&quot;&quot;生成数据集&quot;&quot;&quot;</span><br><span class=\"line\">    X = []</span><br><span class=\"line\">    y = []</span><br><span class=\"line\">    </span><br><span class=\"line\">    for _ in range(config.dataset_size):</span><br><span class=\"line\">        # 随机生成频率和振幅</span><br><span class=\"line\">        freq = np.random.uniform(config.min_freq, config.max_freq)</span><br><span class=\"line\">        amp = np.random.uniform(config.min_amp, config.max_amp)</span><br><span class=\"line\">        </span><br><span class=\"line\">        # 生成正常或异常样本</span><br><span class=\"line\">        if np.random.rand() &lt; config.normal_ratio:</span><br><span class=\"line\">            # 正常样本</span><br><span class=\"line\">            wave = generate_sine_wave(config.num_points, freq, amp)</span><br><span class=\"line\">            label = 0</span><br><span class=\"line\">        else:</span><br><span class=\"line\">            # 异常样本：生成正弦波并在随机位置插入平坦段</span><br><span class=\"line\">            wave = generate_sine_wave(config.num_points, freq, amp)</span><br><span class=\"line\">            # 随机选择异常位置和长度（按比例）</span><br><span class=\"line\">            loc_ratio = np.random.uniform(config.min_loc_ratio, config.max_loc_ratio)</span><br><span class=\"line\">            length_ratio = np.random.uniform(config.min_length_ratio, config.max_length_ratio)</span><br><span class=\"line\">            loc = int(loc_ratio * config.num_points)</span><br><span class=\"line\">            length = int(length_ratio * config.num_points)</span><br><span class=\"line\">            end = min(loc + length, config.num_points)</span><br><span class=\"line\">            # 将选定区域替换为常数值（取开始点的值）</span><br><span class=\"line\">            wave[loc:end] = wave[loc]</span><br><span class=\"line\">            label = 1</span><br><span class=\"line\">        </span><br><span class=\"line\">        X.append(wave)</span><br><span class=\"line\">        y.append(label)</span><br><span class=\"line\">    </span><br><span class=\"line\">    # 转换为numpy数组</span><br><span class=\"line\">    X = np.array(X)</span><br><span class=\"line\">    y = np.array(y)</span><br><span class=\"line\">    </span><br><span class=\"line\">    # 转换为PyTorch张量</span><br><span class=\"line\">    X_tensor = torch.tensor(X, dtype=torch.float32).unsqueeze(-1)  # (N, T, 1)</span><br><span class=\"line\">    y_tensor = torch.tensor(y, dtype=torch.float32)  # (N,)</span><br><span class=\"line\">    </span><br><span class=\"line\">    return X_tensor, y_tensor</span><br><span class=\"line\"></span><br><span class=\"line\"># 2. 模型定义</span><br><span class=\"line\">class AttentionModel(nn.Module):</span><br><span class=\"line\">    def __init__(self, input_dim=1, hidden_dim=32):</span><br><span class=\"line\">        super(AttentionModel, self).__init__()</span><br><span class=\"line\">        # 双向LSTM</span><br><span class=\"line\">        self.lstm = nn.LSTM(</span><br><span class=\"line\">            input_size=input_dim,</span><br><span class=\"line\">            hidden_size=hidden_dim,</span><br><span class=\"line\">            batch_first=True,</span><br><span class=\"line\">            bidirectional=True</span><br><span class=\"line\">        )</span><br><span class=\"line\">        # 注意力权重计算</span><br><span class=\"line\">        self.attention = nn.Sequential(</span><br><span class=\"line\">            nn.Linear(2 * hidden_dim, 64),</span><br><span class=\"line\">            nn.Tanh(),</span><br><span class=\"line\">            nn.Linear(64, 1)</span><br><span class=\"line\">        )</span><br><span class=\"line\">        # 分类器</span><br><span class=\"line\">        self.classifier = nn.Sequential(</span><br><span class=\"line\">            nn.Linear(2 * hidden_dim, 1),</span><br><span class=\"line\">            nn.Sigmoid()</span><br><span class=\"line\">        )</span><br><span class=\"line\">    </span><br><span class=\"line\">    def forward(self, x):</span><br><span class=\"line\">        # LSTM处理</span><br><span class=\"line\">        lstm_out, _ = self.lstm(x)  # (batch_size, seq_len, 2*hidden_dim)</span><br><span class=\"line\">        </span><br><span class=\"line\">        # 计算注意力权重</span><br><span class=\"line\">        e = self.attention(lstm_out).squeeze(-1)  # (batch_size, seq_len)</span><br><span class=\"line\">        alpha = torch.softmax(e, dim=1)  # 归一化权重</span><br><span class=\"line\">        alpha_expanded = alpha.unsqueeze(-1)  # (batch_size, seq_len, 1)</span><br><span class=\"line\">        </span><br><span class=\"line\">        # 加权得到上下文向量</span><br><span class=\"line\">        context = torch.sum(alpha_expanded * lstm_out, dim=1)  # (batch_size, 2*hidden_dim)</span><br><span class=\"line\">        </span><br><span class=\"line\">        # 分类</span><br><span class=\"line\">        out = self.classifier(context).squeeze(-1)  # (batch_size,)</span><br><span class=\"line\">        return out, alpha</span><br><span class=\"line\"></span><br><span class=\"line\"># 3. 训练函数</span><br><span class=\"line\">def train_model(model, train_loader, val_loader, config):</span><br><span class=\"line\">    model.to(config.device)</span><br><span class=\"line\">    criterion = nn.BCELoss()</span><br><span class=\"line\">    optimizer = optim.Adam(model.parameters(), lr=config.lr)</span><br><span class=\"line\">    </span><br><span class=\"line\">    best_val_loss = float(&#x27;inf&#x27;)</span><br><span class=\"line\">    patience_counter = 0</span><br><span class=\"line\">    </span><br><span class=\"line\">    train_losses = []</span><br><span class=\"line\">    val_losses = []</span><br><span class=\"line\">    </span><br><span class=\"line\">    for epoch in range(config.num_epochs):</span><br><span class=\"line\">        # 训练阶段</span><br><span class=\"line\">        model.train()</span><br><span class=\"line\">        train_loss = 0.0</span><br><span class=\"line\">        for batch_X, batch_y in train_loader:</span><br><span class=\"line\">            batch_X, batch_y = batch_X.to(config.device), batch_y.to(config.device)</span><br><span class=\"line\">            </span><br><span class=\"line\">            optimizer.zero_grad()</span><br><span class=\"line\">            outputs, _ = model(batch_X)</span><br><span class=\"line\">            loss = criterion(outputs, batch_y)</span><br><span class=\"line\">            loss.backward()</span><br><span class=\"line\">            optimizer.step()</span><br><span class=\"line\">            </span><br><span class=\"line\">            train_loss += loss.item() * batch_X.size(0)</span><br><span class=\"line\">        </span><br><span class=\"line\">        # 计算平均训练损失</span><br><span class=\"line\">        train_loss = train_loss / len(train_loader.dataset)</span><br><span class=\"line\">        train_losses.append(train_loss)</span><br><span class=\"line\">        </span><br><span class=\"line\">        # 验证阶段</span><br><span class=\"line\">        model.eval()</span><br><span class=\"line\">        val_loss = 0.0</span><br><span class=\"line\">        with torch.no_grad():</span><br><span class=\"line\">            for batch_X, batch_y in val_loader:</span><br><span class=\"line\">                batch_X, batch_y = batch_X.to(config.device), batch_y.to(config.device)</span><br><span class=\"line\">                outputs, _ = model(batch_X)</span><br><span class=\"line\">                loss = criterion(outputs, batch_y)</span><br><span class=\"line\">                val_loss += loss.item() * batch_X.size(0)</span><br><span class=\"line\">        </span><br><span class=\"line\">        val_loss = val_loss / len(val_loader.dataset)</span><br><span class=\"line\">        val_losses.append(val_loss)</span><br><span class=\"line\">        </span><br><span class=\"line\">        print(f&#x27;Epoch &#123;epoch+1&#125;/&#123;config.num_epochs&#125; | Train Loss: &#123;train_loss:.4f&#125; | Val Loss: &#123;val_loss:.4f&#125;&#x27;)</span><br><span class=\"line\">        </span><br><span class=\"line\">        # 早停检查</span><br><span class=\"line\">        if val_loss &lt; best_val_loss:</span><br><span class=\"line\">            best_val_loss = val_loss</span><br><span class=\"line\">            patience_counter = 0</span><br><span class=\"line\">            torch.save(model.state_dict(), &#x27;best_model.pth&#x27;)</span><br><span class=\"line\">        else:</span><br><span class=\"line\">            patience_counter += 1</span><br><span class=\"line\">            if patience_counter &gt;= config.patience:</span><br><span class=\"line\">                print(f&#x27;Early stopping at epoch &#123;epoch+1&#125;&#x27;)</span><br><span class=\"line\">                break</span><br><span class=\"line\">    </span><br><span class=\"line\">    # 加载最佳模型</span><br><span class=\"line\">    model.load_state_dict(torch.load(&#x27;best_model.pth&#x27;))</span><br><span class=\"line\">    return model, train_losses, val_losses</span><br><span class=\"line\"></span><br><span class=\"line\"># 4. 评估函数</span><br><span class=\"line\">def evaluate_model(model, test_loader, config):</span><br><span class=\"line\">    model.eval()</span><br><span class=\"line\">    y_true = []</span><br><span class=\"line\">    y_pred = []</span><br><span class=\"line\">    y_score = []</span><br><span class=\"line\">    </span><br><span class=\"line\">    with torch.no_grad():</span><br><span class=\"line\">        for batch_X, batch_y in test_loader:</span><br><span class=\"line\">            batch_X, batch_y = batch_X.to(config.device), batch_y.to(config.device)</span><br><span class=\"line\">            outputs, _ = model(batch_X)</span><br><span class=\"line\">            </span><br><span class=\"line\">            # 收集真实标签和预测概率</span><br><span class=\"line\">            y_true.extend(batch_y.cpu().numpy())</span><br><span class=\"line\">            y_score.extend(outputs.cpu().numpy())</span><br><span class=\"line\">            y_pred.extend((outputs &gt; 0.5).float().cpu().numpy())</span><br><span class=\"line\">    </span><br><span class=\"line\">    # 计算指标</span><br><span class=\"line\">    acc = accuracy_score(y_true, y_pred)</span><br><span class=\"line\">    prec = precision_score(y_true, y_pred)</span><br><span class=\"line\">    rec = recall_score(y_true, y_pred)</span><br><span class=\"line\">    f1 = f1_score(y_true, y_pred)</span><br><span class=\"line\">    auc = roc_auc_score(y_true, y_score)</span><br><span class=\"line\">    cm = confusion_matrix(y_true, y_pred)</span><br><span class=\"line\">    </span><br><span class=\"line\">    print(f&#x27;Accuracy: &#123;acc:.4f&#125;&#x27;)</span><br><span class=\"line\">    print(f&#x27;Precision: &#123;prec:.4f&#125;&#x27;)</span><br><span class=\"line\">    print(f&#x27;Recall: &#123;rec:.4f&#125;&#x27;)</span><br><span class=\"line\">    print(f&#x27;F1 Score: &#123;f1:.4f&#125;&#x27;)</span><br><span class=\"line\">    print(f&#x27;ROC AUC: &#123;auc:.4f&#125;&#x27;)</span><br><span class=\"line\">    print(&#x27;Confusion Matrix:&#x27;)</span><br><span class=\"line\">    print(cm)</span><br><span class=\"line\">    </span><br><span class=\"line\">    return acc, prec, rec, f1, auc, cm</span><br><span class=\"line\"></span><br><span class=\"line\"># 5. 可视化注意力</span><br><span class=\"line\">def plot_attention(wave, attention_weights, title=&#x27;Attention Visualization&#x27;):</span><br><span class=\"line\">    &quot;&quot;&quot;可视化注意力权重&quot;&quot;&quot;</span><br><span class=\"line\">    wave = wave.squeeze()</span><br><span class=\"line\">    attention_weights = attention_weights.squeeze()</span><br><span class=\"line\">    </span><br><span class=\"line\">    fig, ax1 = plt.subplots(figsize=(12, 4))</span><br><span class=\"line\">    </span><br><span class=\"line\">    # 绘制原始波形</span><br><span class=\"line\">    ax1.plot(wave, &#x27;b-&#x27;, label=&#x27;Signal&#x27;)</span><br><span class=\"line\">    ax1.set_xlabel(&#x27;Time Step&#x27;)</span><br><span class=\"line\">    ax1.set_ylabel(&#x27;Amplitude&#x27;, color=&#x27;b&#x27;)</span><br><span class=\"line\">    ax1.tick_params(&#x27;y&#x27;, colors=&#x27;b&#x27;)</span><br><span class=\"line\">    </span><br><span class=\"line\">    # 绘制注意力权重（红色虚线）</span><br><span class=\"line\">    ax2 = ax1.twinx()</span><br><span class=\"line\">    ax2.plot(attention_weights, &#x27;r--&#x27;, alpha=0.7, label=&#x27;Attention&#x27;)</span><br><span class=\"line\">    ax2.set_ylabel(&#x27;Attention Weight&#x27;, color=&#x27;r&#x27;)</span><br><span class=\"line\">    ax2.tick_params(&#x27;y&#x27;, colors=&#x27;r&#x27;)</span><br><span class=\"line\">    ax2.set_ylim(0, 1.0)</span><br><span class=\"line\">    </span><br><span class=\"line\">    plt.title(title)</span><br><span class=\"line\">    fig.tight_layout()</span><br><span class=\"line\">    plt.show()</span><br><span class=\"line\"></span><br><span class=\"line\"># 主函数</span><br><span class=\"line\">def main():</span><br><span class=\"line\">    # 生成数据</span><br><span class=\"line\">    print(&quot;Generating dataset...&quot;)</span><br><span class=\"line\">    X, y = generate_dataset(config)</span><br><span class=\"line\">    </span><br><span class=\"line\">    # 划分训练集、验证集、测试集</span><br><span class=\"line\">    X_train, X_temp, y_train, y_temp = train_test_split(</span><br><span class=\"line\">        X, y, test_size=0.3, random_state=42</span><br><span class=\"line\">    )</span><br><span class=\"line\">    X_val, X_test, y_val, y_test = train_test_split(</span><br><span class=\"line\">        X_temp, y_temp, test_size=0.5, random_state=42</span><br><span class=\"line\">    )</span><br><span class=\"line\">    </span><br><span class=\"line\">    # 创建数据加载器</span><br><span class=\"line\">    train_dataset = TensorDataset(X_train, y_train)</span><br><span class=\"line\">    val_dataset = TensorDataset(X_val, y_val)</span><br><span class=\"line\">    test_dataset = TensorDataset(X_test, y_test)</span><br><span class=\"line\">    </span><br><span class=\"line\">    train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True)</span><br><span class=\"line\">    val_loader = DataLoader(val_dataset, batch_size=config.batch_size)</span><br><span class=\"line\">    test_loader = DataLoader(test_dataset, batch_size=config.batch_size)</span><br><span class=\"line\">    </span><br><span class=\"line\">    # 初始化模型</span><br><span class=\"line\">    model = AttentionModel(input_dim=1, hidden_dim=config.hidden_dim)</span><br><span class=\"line\">    </span><br><span class=\"line\">    # 训练模型</span><br><span class=\"line\">    print(&quot;Training model...&quot;)</span><br><span class=\"line\">    model, train_losses, val_losses = train_model(model, train_loader, val_loader, config)</span><br><span class=\"line\">    </span><br><span class=\"line\">    # 评估模型</span><br><span class=\"line\">    print(&quot;\\nEvaluating model on test set...&quot;)</span><br><span class=\"line\">    evaluate_model(model, test_loader, config)</span><br><span class=\"line\">    </span><br><span class=\"line\">    # 可视化训练过程</span><br><span class=\"line\">    plt.figure(figsize=(10, 5))</span><br><span class=\"line\">    plt.plot(train_losses, label=&#x27;Train Loss&#x27;)</span><br><span class=\"line\">    plt.plot(val_losses, label=&#x27;Validation Loss&#x27;)</span><br><span class=\"line\">    plt.xlabel(&#x27;Epochs&#x27;)</span><br><span class=\"line\">    plt.ylabel(&#x27;Loss&#x27;)</span><br><span class=\"line\">    plt.legend()</span><br><span class=\"line\">    plt.title(&#x27;Training and Validation Loss&#x27;)</span><br><span class=\"line\">    plt.show()</span><br><span class=\"line\">    </span><br><span class=\"line\">    # 可视化注意力机制</span><br><span class=\"line\">    print(&quot;\\nVisualizing attention for sample examples...&quot;)</span><br><span class=\"line\">    model.eval()</span><br><span class=\"line\">    with torch.no_grad():</span><br><span class=\"line\">        # 随机选择一些测试样本</span><br><span class=\"line\">        indices = np.random.choice(len(test_dataset), 4, replace=False)</span><br><span class=\"line\">        for i in indices:</span><br><span class=\"line\">            sample_X, sample_y = test_dataset[i]</span><br><span class=\"line\">            sample_X = sample_X.unsqueeze(0).to(config.device)  # 增加批次维度</span><br><span class=\"line\">            _, attention_weights = model(sample_X)</span><br><span class=\"line\">            </span><br><span class=\"line\">            # 转换回CPU和numpy</span><br><span class=\"line\">            sample_X = sample_X.cpu().numpy().squeeze()</span><br><span class=\"line\">            attention_weights = attention_weights.cpu().numpy().squeeze()</span><br><span class=\"line\">            </span><br><span class=\"line\">            # 绘制</span><br><span class=\"line\">            title = f&quot;Sample &#123;i&#125; - &#123;&#x27;Anomaly&#x27; if sample_y.item() == 1 else &#x27;Normal&#x27;&#125;&quot;</span><br><span class=\"line\">            plot_attention(sample_X, attention_weights, title)</span><br><span class=\"line\"></span><br><span class=\"line\">if __name__ == &quot;__main__&quot;:</span><br><span class=\"line\">    main()</span><br></pre></td></tr></table></figure>","related_posts":["python-script2.html"],"length":10735,"excerpt":"<p>&emsp;&emsp;今天学习注意力机制（<a href=\"https://towardsdatascience.com/hands-on-attention-mechanism-for-time-series-classification-with-python/\">Attention Mechanism</a>）。</p>","more":"<p>&emsp;&emsp;注意力机制的核心思想是让模型能够动态聚焦于输入数据中最相关的部分。在时间序列分类中：<br>工作原理：</p>\n<p>通过计算每个时间步的”重要性分数”（attention score）</p>\n<p>使用softmax函数将这些分数转换为0-1之间的权重</p>\n<p>对时间步特征进行加权求和，生成上下文向量（context vector）<br>数学表示：</p>\n<p>   $e_i &#x3D; f(h_i)$  # 计算每个隐藏状态h_i的能量分数<br>   $α_i &#x3D; exp(e_i) &#x2F; Σ exp(e_j)$  # softmax归一化<br>   $context &#x3D; Σ (α_i * h_i)$  # 加权上下文向量<br>与传统模型的对比：</p>\n<table>\n<thead>\n<tr>\n<th>模型类型</th>\n<th>处理变长异常能力</th>\n<th>可解释性</th>\n<th>计算效率</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>FFN</td>\n<td>❌ 固定位置依赖</td>\n<td>❌ 黑盒</td>\n<td>⭐⭐⭐⭐</td>\n</tr>\n<tr>\n<td>CNN</td>\n<td>△ 局部感受野</td>\n<td>△ 中等</td>\n<td>⭐⭐⭐⭐</td>\n</tr>\n<tr>\n<td>Attention</td>\n<td>✅ 动态聚焦</td>\n<td>✅ 高（权重可视化）</td>\n<td>⭐⭐⭐</td>\n</tr>\n</tbody></table>\n<p>双向LSTM（BiLSTM）<br>作用：作为特征提取器，捕获时间序列的前后依赖关系</p>\n<p>双向性：同时考虑过去和未来信息</p>\n<p>  前向：h_forward &#x3D; LSTM(从t&#x3D;0到t&#x3D;T)<br>  后向：h_backward &#x3D; LSTM(从t&#x3D;T到t&#x3D;0)<br>  最终状态：h &#x3D; [h_forward; h_backward]</p>\n<p>异常检测机制</p>\n<pre class=\"mermaid\">graph LR\n    A[原始正弦波] --> B[随机位置]\n    --> C[插入平坦段]\n    --> D[长度随机]\n    --> E[振幅/频率随机]\n    --> F[形成异常样本]</pre>\n<p>模型架构</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">AttentionModel(</span><br><span class=\"line\">  (lstm): LSTM(<span class=\"number\">1</span>, <span class=\"number\">32</span>, bidirectional=<span class=\"literal\">True</span>)</span><br><span class=\"line\">  (attention): Sequential(</span><br><span class=\"line\">    (<span class=\"number\">0</span>): Linear(in_features=<span class=\"number\">64</span>, out_features=<span class=\"number\">64</span>)</span><br><span class=\"line\">    (<span class=\"number\">1</span>): Tanh()</span><br><span class=\"line\">    (<span class=\"number\">2</span>): Linear(in_features=<span class=\"number\">64</span>, out_features=<span class=\"number\">1</span>)</span><br><span class=\"line\">  )</span><br><span class=\"line\">  (classifier): Sequential(</span><br><span class=\"line\">    (<span class=\"number\">0</span>): Linear(in_features=<span class=\"number\">64</span>, out_features=<span class=\"number\">1</span>)</span><br><span class=\"line\">    (<span class=\"number\">1</span>): Sigmoid()</span><br><span class=\"line\">  )</span><br><span class=\"line\">)</span><br></pre></td></tr></table></figure>\n\n<p>评估指标<br>ROC-AUC：衡量模型区分正负样本的能力</p>\n<p>值域[0,1]，&gt;0.9表示优秀模型<br>F1-Score：精确率和召回率的调和平均</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">F1 = 2  (Precision  Recall) / (Precision + Recall)</span><br></pre></td></tr></table></figure>\n<p>混淆矩阵：</p>\n<table>\n<thead>\n<tr>\n<th></th>\n<th>预测正常</th>\n<th>预测异常</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>实际正常</td>\n<td>TN (真负例)</td>\n<td>FP (假正例)</td>\n</tr>\n<tr>\n<td>实际异常</td>\n<td>FN (假负例)</td>\n<td>TP (真正例)</td>\n</tr>\n</tbody></table>\n<p>“学习注意力机制的最佳途径不是NLP而是时间序列”<br>优势：</p>\n<ol>\n<li>复杂度降低：</li>\n</ol>\n<h3 id=\"NLP需要词嵌入-位置编码等额外层\"><a href=\"#NLP需要词嵌入-位置编码等额外层\" class=\"headerlink\" title=\"NLP需要词嵌入&#x2F;位置编码等额外层\"></a>NLP需要词嵌入&#x2F;位置编码等额外层</h3><h3 id=\"时间序列可直接使用原始数值数据\"><a href=\"#时间序列可直接使用原始数值数据\" class=\"headerlink\" title=\"时间序列可直接使用原始数值数据\"></a>时间序列可直接使用原始数值数据</h3><h3 id=\"示例：NLP处理流程-vs-时间序列处理\"><a href=\"#示例：NLP处理流程-vs-时间序列处理\" class=\"headerlink\" title=\"示例：NLP处理流程 vs 时间序列处理\"></a>示例：NLP处理流程 vs 时间序列处理</h3><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># NLP</span><br><span class=\"line\">文本 → 分词 → 嵌入 → 位置编码 → 注意力</span><br><span class=\"line\"># 时间序列</span><br><span class=\"line\">原始信号 → 注意力</span><br></pre></td></tr></table></figure>\n<ol start=\"2\">\n<li>直观可视化：<br>  时间序列的注意力权重可直接叠加在信号图上<br>  NLP的注意力热力图需要专业知识解释</li>\n<li>计算效率：<br>  时间序列可生成小型合成数据集（文中5000样本）<br>  训练在CPU上仅需几分钟（NLP模型通常需要GPU小时级训练）</li>\n</ol>\n<p>局限性：</p>\n<ol>\n<li>语义理解缺失：<br> NLP任务能更好展示注意力处理语义关系的能力<br> 如：指代消解”The animal didn’t cross the street because it was too tired”</li>\n<li>实际应用偏差：<br>  工业界注意力应用仍以NLP为主（BERT, GPT等）<br>  时间序列注意力研究相对较少</li>\n</ol>\n<p>改进建议:</p>\n<ol>\n<li>混合学习路径（推荐）</li>\n</ol>\n<pre class=\"mermaid\">graph TD\n    A[基础概念] --> B[时间序列示例]\n--> C[可视化理解]\n--> D[NLP进阶]\n--> E[CV扩展]</pre>\n\n<ol start=\"2\">\n<li>增强时间序列实验设计<br>  多类型异常：<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 当前：仅平坦异常</span></span><br><span class=\"line\">wave[loc:end] = wave[loc] </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 建议增加：</span></span><br><span class=\"line\">wave[loc:end] = <span class=\"number\">0</span>  <span class=\"comment\"># 零值异常</span></span><br><span class=\"line\">wave[loc:end] = random_noise()  <span class=\"comment\"># 噪声异常</span></span><br><span class=\"line\">wave = add_spike(loc)  <span class=\"comment\"># 尖峰异常</span></span><br></pre></td></tr></table></figure>\n多变量时间序列：<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">  <span class=\"comment\"># 当前：单变量正弦波</span></span><br><span class=\"line\">X.shape = (<span class=\"number\">5000</span>, <span class=\"number\">500</span>, <span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 改进：多变量</span></span><br><span class=\"line\">X_multi = np.stack([sine_wave, </span><br><span class=\"line\">                    cosine_wave, </span><br><span class=\"line\">                    random_walk], axis=-<span class=\"number\">1</span>)</span><br></pre></td></tr></table></figure></li>\n<li>模型架构优化</li>\n</ol>\n<p>多头注意力（Multi-Head Attention）：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">  <span class=\"comment\"># 当前：单头</span></span><br><span class=\"line\"><span class=\"variable language_\">self</span>.attention = nn.Sequential(...)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 改进：多头</span></span><br><span class=\"line\"><span class=\"variable language_\">self</span>.multihead_attn = nn.MultiheadAttention(</span><br><span class=\"line\">    embed_dim=<span class=\"number\">64</span>, num_heads=<span class=\"number\">4</span></span><br><span class=\"line\">)</span><br></pre></td></tr></table></figure>\n<p>位置编码增强：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">  <span class=\"comment\"># 当前：依赖LSTM的顺序处理</span></span><br><span class=\"line\"><span class=\"comment\"># 改进：显式位置编码</span></span><br><span class=\"line\">position = torch.arange(<span class=\"number\">0</span>, seq_len).unsqueeze(<span class=\"number\">1</span>)</span><br><span class=\"line\">pe = torch.sin(position / <span class=\"number\">10000</span>(<span class=\"number\">2</span>*i/d_model))</span><br></pre></td></tr></table></figure>\n<ol start=\"4\">\n<li>可解释性增强</li>\n</ol>\n<p>定量评估指标：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">attention_accuracy</span>(<span class=\"params\">att_weights, anomaly_loc</span>):</span><br><span class=\"line\">  <span class=\"string\">&quot;&quot;&quot;计算注意力聚焦异常区域的准确度&quot;&quot;&quot;</span></span><br><span class=\"line\">  focus_region = att_weights.argmax()-<span class=\"number\">10</span> : att_weights.argmax()+<span class=\"number\">10</span></span><br><span class=\"line\">  overlap = <span class=\"built_in\">len</span>(<span class=\"built_in\">set</span>(focus_region) &amp; <span class=\"built_in\">set</span>(anomaly_loc))</span><br><span class=\"line\">  <span class=\"keyword\">return</span> overlap / <span class=\"built_in\">len</span>(anomaly_loc)</span><br></pre></td></tr></table></figure>\n<p>对比可视化：</p>\n<table>\n<thead>\n<tr>\n<th>样本类型</th>\n<th>正常样本</th>\n<th>异常样本</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>注意力分布</td>\n<td>均匀分布</td>\n<td>峰值在异常区</td>\n</tr>\n<tr>\n<td>典型模式</td>\n<td></td>\n<td></td>\n</tr>\n</tbody></table>\n<p>时间序列提供了更简洁直观的注意力学习路径。但在工业实践中，建议：</p>\n<ol>\n<li>以时间序列作为入门起点</li>\n<li>通过NLP任务深化语义理解</li>\n<li>最终扩展到多模态应用<br>“注意力机制不是领域特定的工具，而是数据关系的动态透镜——时间序列提供了最干净的镜片来观察其本质。”</li>\n</ol>\n<p>python脚本例子：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br><span class=\"line\">145</span><br><span class=\"line\">146</span><br><span class=\"line\">147</span><br><span class=\"line\">148</span><br><span class=\"line\">149</span><br><span class=\"line\">150</span><br><span class=\"line\">151</span><br><span class=\"line\">152</span><br><span class=\"line\">153</span><br><span class=\"line\">154</span><br><span class=\"line\">155</span><br><span class=\"line\">156</span><br><span class=\"line\">157</span><br><span class=\"line\">158</span><br><span class=\"line\">159</span><br><span class=\"line\">160</span><br><span class=\"line\">161</span><br><span class=\"line\">162</span><br><span class=\"line\">163</span><br><span class=\"line\">164</span><br><span class=\"line\">165</span><br><span class=\"line\">166</span><br><span class=\"line\">167</span><br><span class=\"line\">168</span><br><span class=\"line\">169</span><br><span class=\"line\">170</span><br><span class=\"line\">171</span><br><span class=\"line\">172</span><br><span class=\"line\">173</span><br><span class=\"line\">174</span><br><span class=\"line\">175</span><br><span class=\"line\">176</span><br><span class=\"line\">177</span><br><span class=\"line\">178</span><br><span class=\"line\">179</span><br><span class=\"line\">180</span><br><span class=\"line\">181</span><br><span class=\"line\">182</span><br><span class=\"line\">183</span><br><span class=\"line\">184</span><br><span class=\"line\">185</span><br><span class=\"line\">186</span><br><span class=\"line\">187</span><br><span class=\"line\">188</span><br><span class=\"line\">189</span><br><span class=\"line\">190</span><br><span class=\"line\">191</span><br><span class=\"line\">192</span><br><span class=\"line\">193</span><br><span class=\"line\">194</span><br><span class=\"line\">195</span><br><span class=\"line\">196</span><br><span class=\"line\">197</span><br><span class=\"line\">198</span><br><span class=\"line\">199</span><br><span class=\"line\">200</span><br><span class=\"line\">201</span><br><span class=\"line\">202</span><br><span class=\"line\">203</span><br><span class=\"line\">204</span><br><span class=\"line\">205</span><br><span class=\"line\">206</span><br><span class=\"line\">207</span><br><span class=\"line\">208</span><br><span class=\"line\">209</span><br><span class=\"line\">210</span><br><span class=\"line\">211</span><br><span class=\"line\">212</span><br><span class=\"line\">213</span><br><span class=\"line\">214</span><br><span class=\"line\">215</span><br><span class=\"line\">216</span><br><span class=\"line\">217</span><br><span class=\"line\">218</span><br><span class=\"line\">219</span><br><span class=\"line\">220</span><br><span class=\"line\">221</span><br><span class=\"line\">222</span><br><span class=\"line\">223</span><br><span class=\"line\">224</span><br><span class=\"line\">225</span><br><span class=\"line\">226</span><br><span class=\"line\">227</span><br><span class=\"line\">228</span><br><span class=\"line\">229</span><br><span class=\"line\">230</span><br><span class=\"line\">231</span><br><span class=\"line\">232</span><br><span class=\"line\">233</span><br><span class=\"line\">234</span><br><span class=\"line\">235</span><br><span class=\"line\">236</span><br><span class=\"line\">237</span><br><span class=\"line\">238</span><br><span class=\"line\">239</span><br><span class=\"line\">240</span><br><span class=\"line\">241</span><br><span class=\"line\">242</span><br><span class=\"line\">243</span><br><span class=\"line\">244</span><br><span class=\"line\">245</span><br><span class=\"line\">246</span><br><span class=\"line\">247</span><br><span class=\"line\">248</span><br><span class=\"line\">249</span><br><span class=\"line\">250</span><br><span class=\"line\">251</span><br><span class=\"line\">252</span><br><span class=\"line\">253</span><br><span class=\"line\">254</span><br><span class=\"line\">255</span><br><span class=\"line\">256</span><br><span class=\"line\">257</span><br><span class=\"line\">258</span><br><span class=\"line\">259</span><br><span class=\"line\">260</span><br><span class=\"line\">261</span><br><span class=\"line\">262</span><br><span class=\"line\">263</span><br><span class=\"line\">264</span><br><span class=\"line\">265</span><br><span class=\"line\">266</span><br><span class=\"line\">267</span><br><span class=\"line\">268</span><br><span class=\"line\">269</span><br><span class=\"line\">270</span><br><span class=\"line\">271</span><br><span class=\"line\">272</span><br><span class=\"line\">273</span><br><span class=\"line\">274</span><br><span class=\"line\">275</span><br><span class=\"line\">276</span><br><span class=\"line\">277</span><br><span class=\"line\">278</span><br><span class=\"line\">279</span><br><span class=\"line\">280</span><br><span class=\"line\">281</span><br><span class=\"line\">282</span><br><span class=\"line\">283</span><br><span class=\"line\">284</span><br><span class=\"line\">285</span><br><span class=\"line\">286</span><br><span class=\"line\">287</span><br><span class=\"line\">288</span><br><span class=\"line\">289</span><br><span class=\"line\">290</span><br><span class=\"line\">291</span><br><span class=\"line\">292</span><br><span class=\"line\">293</span><br><span class=\"line\">294</span><br><span class=\"line\">295</span><br><span class=\"line\">296</span><br><span class=\"line\">297</span><br><span class=\"line\">298</span><br><span class=\"line\">299</span><br><span class=\"line\">300</span><br><span class=\"line\">301</span><br><span class=\"line\">302</span><br><span class=\"line\">303</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">import numpy as np</span><br><span class=\"line\">import matplotlib.pyplot as plt</span><br><span class=\"line\">import torch</span><br><span class=\"line\">import torch.nn as nn</span><br><span class=\"line\">import torch.optim as optim</span><br><span class=\"line\">from torch.utils.data import Dataset, DataLoader, TensorDataset</span><br><span class=\"line\">from sklearn.model_selection import train_test_split</span><br><span class=\"line\">from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score</span><br><span class=\"line\"></span><br><span class=\"line\"># 配置参数</span><br><span class=\"line\">class Config:</span><br><span class=\"line\">    num_points = 500        # 时间序列长度</span><br><span class=\"line\">    dataset_size = 5000     # 数据集大小</span><br><span class=\"line\">    normal_ratio = 0.5      # 正常样本比例</span><br><span class=\"line\">    min_freq = 1            # 最小频率</span><br><span class=\"line\">    max_freq = 4            # 最大频率</span><br><span class=\"line\">    min_amp = 1             # 最小振幅</span><br><span class=\"line\">    max_amp = 10            # 最大振幅</span><br><span class=\"line\">    min_loc_ratio = 0.0     # 异常位置最小比例</span><br><span class=\"line\">    max_loc_ratio = 0.9     # 异常位置最大比例</span><br><span class=\"line\">    min_length_ratio = 0.1  # 异常长度最小比例</span><br><span class=\"line\">    max_length_ratio = 0.5  # 异常长度最大比例</span><br><span class=\"line\">    batch_size = 32         # 批大小</span><br><span class=\"line\">    lr = 0.001              # 学习率</span><br><span class=\"line\">    num_epochs = 15         # 训练轮数</span><br><span class=\"line\">    hidden_dim = 32         # LSTM隐藏层维度</span><br><span class=\"line\">    device = torch.device(&#x27;cuda&#x27; if torch.cuda.is_available() else &#x27;cpu&#x27;)</span><br><span class=\"line\">    patience = 5            # 早停耐心值</span><br><span class=\"line\"></span><br><span class=\"line\">config = Config()</span><br><span class=\"line\"></span><br><span class=\"line\"># 1. 数据生成</span><br><span class=\"line\">def generate_sine_wave(length, freq, amp):</span><br><span class=\"line\">    &quot;&quot;&quot;生成正弦波&quot;&quot;&quot;</span><br><span class=\"line\">    t = np.linspace(0, 2*np.pi, length)</span><br><span class=\"line\">    return amp * np.sin(freq * t)</span><br><span class=\"line\"></span><br><span class=\"line\">def generate_dataset(config):</span><br><span class=\"line\">    &quot;&quot;&quot;生成数据集&quot;&quot;&quot;</span><br><span class=\"line\">    X = []</span><br><span class=\"line\">    y = []</span><br><span class=\"line\">    </span><br><span class=\"line\">    for _ in range(config.dataset_size):</span><br><span class=\"line\">        # 随机生成频率和振幅</span><br><span class=\"line\">        freq = np.random.uniform(config.min_freq, config.max_freq)</span><br><span class=\"line\">        amp = np.random.uniform(config.min_amp, config.max_amp)</span><br><span class=\"line\">        </span><br><span class=\"line\">        # 生成正常或异常样本</span><br><span class=\"line\">        if np.random.rand() &lt; config.normal_ratio:</span><br><span class=\"line\">            # 正常样本</span><br><span class=\"line\">            wave = generate_sine_wave(config.num_points, freq, amp)</span><br><span class=\"line\">            label = 0</span><br><span class=\"line\">        else:</span><br><span class=\"line\">            # 异常样本：生成正弦波并在随机位置插入平坦段</span><br><span class=\"line\">            wave = generate_sine_wave(config.num_points, freq, amp)</span><br><span class=\"line\">            # 随机选择异常位置和长度（按比例）</span><br><span class=\"line\">            loc_ratio = np.random.uniform(config.min_loc_ratio, config.max_loc_ratio)</span><br><span class=\"line\">            length_ratio = np.random.uniform(config.min_length_ratio, config.max_length_ratio)</span><br><span class=\"line\">            loc = int(loc_ratio * config.num_points)</span><br><span class=\"line\">            length = int(length_ratio * config.num_points)</span><br><span class=\"line\">            end = min(loc + length, config.num_points)</span><br><span class=\"line\">            # 将选定区域替换为常数值（取开始点的值）</span><br><span class=\"line\">            wave[loc:end] = wave[loc]</span><br><span class=\"line\">            label = 1</span><br><span class=\"line\">        </span><br><span class=\"line\">        X.append(wave)</span><br><span class=\"line\">        y.append(label)</span><br><span class=\"line\">    </span><br><span class=\"line\">    # 转换为numpy数组</span><br><span class=\"line\">    X = np.array(X)</span><br><span class=\"line\">    y = np.array(y)</span><br><span class=\"line\">    </span><br><span class=\"line\">    # 转换为PyTorch张量</span><br><span class=\"line\">    X_tensor = torch.tensor(X, dtype=torch.float32).unsqueeze(-1)  # (N, T, 1)</span><br><span class=\"line\">    y_tensor = torch.tensor(y, dtype=torch.float32)  # (N,)</span><br><span class=\"line\">    </span><br><span class=\"line\">    return X_tensor, y_tensor</span><br><span class=\"line\"></span><br><span class=\"line\"># 2. 模型定义</span><br><span class=\"line\">class AttentionModel(nn.Module):</span><br><span class=\"line\">    def __init__(self, input_dim=1, hidden_dim=32):</span><br><span class=\"line\">        super(AttentionModel, self).__init__()</span><br><span class=\"line\">        # 双向LSTM</span><br><span class=\"line\">        self.lstm = nn.LSTM(</span><br><span class=\"line\">            input_size=input_dim,</span><br><span class=\"line\">            hidden_size=hidden_dim,</span><br><span class=\"line\">            batch_first=True,</span><br><span class=\"line\">            bidirectional=True</span><br><span class=\"line\">        )</span><br><span class=\"line\">        # 注意力权重计算</span><br><span class=\"line\">        self.attention = nn.Sequential(</span><br><span class=\"line\">            nn.Linear(2 * hidden_dim, 64),</span><br><span class=\"line\">            nn.Tanh(),</span><br><span class=\"line\">            nn.Linear(64, 1)</span><br><span class=\"line\">        )</span><br><span class=\"line\">        # 分类器</span><br><span class=\"line\">        self.classifier = nn.Sequential(</span><br><span class=\"line\">            nn.Linear(2 * hidden_dim, 1),</span><br><span class=\"line\">            nn.Sigmoid()</span><br><span class=\"line\">        )</span><br><span class=\"line\">    </span><br><span class=\"line\">    def forward(self, x):</span><br><span class=\"line\">        # LSTM处理</span><br><span class=\"line\">        lstm_out, _ = self.lstm(x)  # (batch_size, seq_len, 2*hidden_dim)</span><br><span class=\"line\">        </span><br><span class=\"line\">        # 计算注意力权重</span><br><span class=\"line\">        e = self.attention(lstm_out).squeeze(-1)  # (batch_size, seq_len)</span><br><span class=\"line\">        alpha = torch.softmax(e, dim=1)  # 归一化权重</span><br><span class=\"line\">        alpha_expanded = alpha.unsqueeze(-1)  # (batch_size, seq_len, 1)</span><br><span class=\"line\">        </span><br><span class=\"line\">        # 加权得到上下文向量</span><br><span class=\"line\">        context = torch.sum(alpha_expanded * lstm_out, dim=1)  # (batch_size, 2*hidden_dim)</span><br><span class=\"line\">        </span><br><span class=\"line\">        # 分类</span><br><span class=\"line\">        out = self.classifier(context).squeeze(-1)  # (batch_size,)</span><br><span class=\"line\">        return out, alpha</span><br><span class=\"line\"></span><br><span class=\"line\"># 3. 训练函数</span><br><span class=\"line\">def train_model(model, train_loader, val_loader, config):</span><br><span class=\"line\">    model.to(config.device)</span><br><span class=\"line\">    criterion = nn.BCELoss()</span><br><span class=\"line\">    optimizer = optim.Adam(model.parameters(), lr=config.lr)</span><br><span class=\"line\">    </span><br><span class=\"line\">    best_val_loss = float(&#x27;inf&#x27;)</span><br><span class=\"line\">    patience_counter = 0</span><br><span class=\"line\">    </span><br><span class=\"line\">    train_losses = []</span><br><span class=\"line\">    val_losses = []</span><br><span class=\"line\">    </span><br><span class=\"line\">    for epoch in range(config.num_epochs):</span><br><span class=\"line\">        # 训练阶段</span><br><span class=\"line\">        model.train()</span><br><span class=\"line\">        train_loss = 0.0</span><br><span class=\"line\">        for batch_X, batch_y in train_loader:</span><br><span class=\"line\">            batch_X, batch_y = batch_X.to(config.device), batch_y.to(config.device)</span><br><span class=\"line\">            </span><br><span class=\"line\">            optimizer.zero_grad()</span><br><span class=\"line\">            outputs, _ = model(batch_X)</span><br><span class=\"line\">            loss = criterion(outputs, batch_y)</span><br><span class=\"line\">            loss.backward()</span><br><span class=\"line\">            optimizer.step()</span><br><span class=\"line\">            </span><br><span class=\"line\">            train_loss += loss.item() * batch_X.size(0)</span><br><span class=\"line\">        </span><br><span class=\"line\">        # 计算平均训练损失</span><br><span class=\"line\">        train_loss = train_loss / len(train_loader.dataset)</span><br><span class=\"line\">        train_losses.append(train_loss)</span><br><span class=\"line\">        </span><br><span class=\"line\">        # 验证阶段</span><br><span class=\"line\">        model.eval()</span><br><span class=\"line\">        val_loss = 0.0</span><br><span class=\"line\">        with torch.no_grad():</span><br><span class=\"line\">            for batch_X, batch_y in val_loader:</span><br><span class=\"line\">                batch_X, batch_y = batch_X.to(config.device), batch_y.to(config.device)</span><br><span class=\"line\">                outputs, _ = model(batch_X)</span><br><span class=\"line\">                loss = criterion(outputs, batch_y)</span><br><span class=\"line\">                val_loss += loss.item() * batch_X.size(0)</span><br><span class=\"line\">        </span><br><span class=\"line\">        val_loss = val_loss / len(val_loader.dataset)</span><br><span class=\"line\">        val_losses.append(val_loss)</span><br><span class=\"line\">        </span><br><span class=\"line\">        print(f&#x27;Epoch &#123;epoch+1&#125;/&#123;config.num_epochs&#125; | Train Loss: &#123;train_loss:.4f&#125; | Val Loss: &#123;val_loss:.4f&#125;&#x27;)</span><br><span class=\"line\">        </span><br><span class=\"line\">        # 早停检查</span><br><span class=\"line\">        if val_loss &lt; best_val_loss:</span><br><span class=\"line\">            best_val_loss = val_loss</span><br><span class=\"line\">            patience_counter = 0</span><br><span class=\"line\">            torch.save(model.state_dict(), &#x27;best_model.pth&#x27;)</span><br><span class=\"line\">        else:</span><br><span class=\"line\">            patience_counter += 1</span><br><span class=\"line\">            if patience_counter &gt;= config.patience:</span><br><span class=\"line\">                print(f&#x27;Early stopping at epoch &#123;epoch+1&#125;&#x27;)</span><br><span class=\"line\">                break</span><br><span class=\"line\">    </span><br><span class=\"line\">    # 加载最佳模型</span><br><span class=\"line\">    model.load_state_dict(torch.load(&#x27;best_model.pth&#x27;))</span><br><span class=\"line\">    return model, train_losses, val_losses</span><br><span class=\"line\"></span><br><span class=\"line\"># 4. 评估函数</span><br><span class=\"line\">def evaluate_model(model, test_loader, config):</span><br><span class=\"line\">    model.eval()</span><br><span class=\"line\">    y_true = []</span><br><span class=\"line\">    y_pred = []</span><br><span class=\"line\">    y_score = []</span><br><span class=\"line\">    </span><br><span class=\"line\">    with torch.no_grad():</span><br><span class=\"line\">        for batch_X, batch_y in test_loader:</span><br><span class=\"line\">            batch_X, batch_y = batch_X.to(config.device), batch_y.to(config.device)</span><br><span class=\"line\">            outputs, _ = model(batch_X)</span><br><span class=\"line\">            </span><br><span class=\"line\">            # 收集真实标签和预测概率</span><br><span class=\"line\">            y_true.extend(batch_y.cpu().numpy())</span><br><span class=\"line\">            y_score.extend(outputs.cpu().numpy())</span><br><span class=\"line\">            y_pred.extend((outputs &gt; 0.5).float().cpu().numpy())</span><br><span class=\"line\">    </span><br><span class=\"line\">    # 计算指标</span><br><span class=\"line\">    acc = accuracy_score(y_true, y_pred)</span><br><span class=\"line\">    prec = precision_score(y_true, y_pred)</span><br><span class=\"line\">    rec = recall_score(y_true, y_pred)</span><br><span class=\"line\">    f1 = f1_score(y_true, y_pred)</span><br><span class=\"line\">    auc = roc_auc_score(y_true, y_score)</span><br><span class=\"line\">    cm = confusion_matrix(y_true, y_pred)</span><br><span class=\"line\">    </span><br><span class=\"line\">    print(f&#x27;Accuracy: &#123;acc:.4f&#125;&#x27;)</span><br><span class=\"line\">    print(f&#x27;Precision: &#123;prec:.4f&#125;&#x27;)</span><br><span class=\"line\">    print(f&#x27;Recall: &#123;rec:.4f&#125;&#x27;)</span><br><span class=\"line\">    print(f&#x27;F1 Score: &#123;f1:.4f&#125;&#x27;)</span><br><span class=\"line\">    print(f&#x27;ROC AUC: &#123;auc:.4f&#125;&#x27;)</span><br><span class=\"line\">    print(&#x27;Confusion Matrix:&#x27;)</span><br><span class=\"line\">    print(cm)</span><br><span class=\"line\">    </span><br><span class=\"line\">    return acc, prec, rec, f1, auc, cm</span><br><span class=\"line\"></span><br><span class=\"line\"># 5. 可视化注意力</span><br><span class=\"line\">def plot_attention(wave, attention_weights, title=&#x27;Attention Visualization&#x27;):</span><br><span class=\"line\">    &quot;&quot;&quot;可视化注意力权重&quot;&quot;&quot;</span><br><span class=\"line\">    wave = wave.squeeze()</span><br><span class=\"line\">    attention_weights = attention_weights.squeeze()</span><br><span class=\"line\">    </span><br><span class=\"line\">    fig, ax1 = plt.subplots(figsize=(12, 4))</span><br><span class=\"line\">    </span><br><span class=\"line\">    # 绘制原始波形</span><br><span class=\"line\">    ax1.plot(wave, &#x27;b-&#x27;, label=&#x27;Signal&#x27;)</span><br><span class=\"line\">    ax1.set_xlabel(&#x27;Time Step&#x27;)</span><br><span class=\"line\">    ax1.set_ylabel(&#x27;Amplitude&#x27;, color=&#x27;b&#x27;)</span><br><span class=\"line\">    ax1.tick_params(&#x27;y&#x27;, colors=&#x27;b&#x27;)</span><br><span class=\"line\">    </span><br><span class=\"line\">    # 绘制注意力权重（红色虚线）</span><br><span class=\"line\">    ax2 = ax1.twinx()</span><br><span class=\"line\">    ax2.plot(attention_weights, &#x27;r--&#x27;, alpha=0.7, label=&#x27;Attention&#x27;)</span><br><span class=\"line\">    ax2.set_ylabel(&#x27;Attention Weight&#x27;, color=&#x27;r&#x27;)</span><br><span class=\"line\">    ax2.tick_params(&#x27;y&#x27;, colors=&#x27;r&#x27;)</span><br><span class=\"line\">    ax2.set_ylim(0, 1.0)</span><br><span class=\"line\">    </span><br><span class=\"line\">    plt.title(title)</span><br><span class=\"line\">    fig.tight_layout()</span><br><span class=\"line\">    plt.show()</span><br><span class=\"line\"></span><br><span class=\"line\"># 主函数</span><br><span class=\"line\">def main():</span><br><span class=\"line\">    # 生成数据</span><br><span class=\"line\">    print(&quot;Generating dataset...&quot;)</span><br><span class=\"line\">    X, y = generate_dataset(config)</span><br><span class=\"line\">    </span><br><span class=\"line\">    # 划分训练集、验证集、测试集</span><br><span class=\"line\">    X_train, X_temp, y_train, y_temp = train_test_split(</span><br><span class=\"line\">        X, y, test_size=0.3, random_state=42</span><br><span class=\"line\">    )</span><br><span class=\"line\">    X_val, X_test, y_val, y_test = train_test_split(</span><br><span class=\"line\">        X_temp, y_temp, test_size=0.5, random_state=42</span><br><span class=\"line\">    )</span><br><span class=\"line\">    </span><br><span class=\"line\">    # 创建数据加载器</span><br><span class=\"line\">    train_dataset = TensorDataset(X_train, y_train)</span><br><span class=\"line\">    val_dataset = TensorDataset(X_val, y_val)</span><br><span class=\"line\">    test_dataset = TensorDataset(X_test, y_test)</span><br><span class=\"line\">    </span><br><span class=\"line\">    train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True)</span><br><span class=\"line\">    val_loader = DataLoader(val_dataset, batch_size=config.batch_size)</span><br><span class=\"line\">    test_loader = DataLoader(test_dataset, batch_size=config.batch_size)</span><br><span class=\"line\">    </span><br><span class=\"line\">    # 初始化模型</span><br><span class=\"line\">    model = AttentionModel(input_dim=1, hidden_dim=config.hidden_dim)</span><br><span class=\"line\">    </span><br><span class=\"line\">    # 训练模型</span><br><span class=\"line\">    print(&quot;Training model...&quot;)</span><br><span class=\"line\">    model, train_losses, val_losses = train_model(model, train_loader, val_loader, config)</span><br><span class=\"line\">    </span><br><span class=\"line\">    # 评估模型</span><br><span class=\"line\">    print(&quot;\\nEvaluating model on test set...&quot;)</span><br><span class=\"line\">    evaluate_model(model, test_loader, config)</span><br><span class=\"line\">    </span><br><span class=\"line\">    # 可视化训练过程</span><br><span class=\"line\">    plt.figure(figsize=(10, 5))</span><br><span class=\"line\">    plt.plot(train_losses, label=&#x27;Train Loss&#x27;)</span><br><span class=\"line\">    plt.plot(val_losses, label=&#x27;Validation Loss&#x27;)</span><br><span class=\"line\">    plt.xlabel(&#x27;Epochs&#x27;)</span><br><span class=\"line\">    plt.ylabel(&#x27;Loss&#x27;)</span><br><span class=\"line\">    plt.legend()</span><br><span class=\"line\">    plt.title(&#x27;Training and Validation Loss&#x27;)</span><br><span class=\"line\">    plt.show()</span><br><span class=\"line\">    </span><br><span class=\"line\">    # 可视化注意力机制</span><br><span class=\"line\">    print(&quot;\\nVisualizing attention for sample examples...&quot;)</span><br><span class=\"line\">    model.eval()</span><br><span class=\"line\">    with torch.no_grad():</span><br><span class=\"line\">        # 随机选择一些测试样本</span><br><span class=\"line\">        indices = np.random.choice(len(test_dataset), 4, replace=False)</span><br><span class=\"line\">        for i in indices:</span><br><span class=\"line\">            sample_X, sample_y = test_dataset[i]</span><br><span class=\"line\">            sample_X = sample_X.unsqueeze(0).to(config.device)  # 增加批次维度</span><br><span class=\"line\">            _, attention_weights = model(sample_X)</span><br><span class=\"line\">            </span><br><span class=\"line\">            # 转换回CPU和numpy</span><br><span class=\"line\">            sample_X = sample_X.cpu().numpy().squeeze()</span><br><span class=\"line\">            attention_weights = attention_weights.cpu().numpy().squeeze()</span><br><span class=\"line\">            </span><br><span class=\"line\">            # 绘制</span><br><span class=\"line\">            title = f&quot;Sample &#123;i&#125; - &#123;&#x27;Anomaly&#x27; if sample_y.item() == 1 else &#x27;Normal&#x27;&#125;&quot;</span><br><span class=\"line\">            plot_attention(sample_X, attention_weights, title)</span><br><span class=\"line\"></span><br><span class=\"line\">if __name__ == &quot;__main__&quot;:</span><br><span class=\"line\">    main()</span><br></pre></td></tr></table></figure>"},{"title":"python脚本下载连续波形数据","abbrlink":"b4ccc3e7","date":"2025-06-07T09:09:37.000Z","_content":"&emsp;&emsp;这是连续波形数据下载python脚本更新。\n<!--less-->\n```python\nimport os\nimport time\nimport socket\nimport numpy as np\nfrom obspy import UTCDateTime, Stream\nfrom obspy.clients.fdsn import Client\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\nfrom requests.exceptions import ConnectionError, Timeout\n\n# 参数设置\nclient = Client(\"IRIS\")\noutput_dir = \"global_data\"\nos.makedirs(output_dir, exist_ok=True)\nsta_file = \"station.lst\"\nstart_date = UTCDateTime(\"2013-01-01\")\nend_date = UTCDateTime(\"2024-01-01\")  # 包括该天\nthread_workers = 20\nexception_log = \"exceptions.txt\"\ntiming_log = \"download_time.txt\"\nmax_retries = 5  # 最大重试次数\nprint(f\"📁 当前工作目录: {os.getcwd()}\")\nprint(f\"📁 波形保存路径: {os.path.abspath(output_dir)}\")\n\n# 读取台站列表\nsta_list = []\nwith open(sta_file, \"r\") as sf:\n    for line in sf:\n        if line.strip() and not line.strip().startswith(\"#\"):\n            parts = line.strip().split()\n            if len(parts) >= 2:\n                net, sta = parts[0], parts[1]\n                sta_list.append((net, sta))\n\ndef download_station(net, sta, day):\n    \"\"\"\n    下载单个台站某天波形数据，去仪器响应，返回Stream\n    \"\"\"\n    start = UTCDateTime(day)\n    end = start + 86400\n    st = client.get_waveforms(net, sta, \"*\", \"LH?\", start, end, attach_response=True)\n\n    st.remove_response(output=\"VEL\", pre_filt=(0.008, 0.01, 0.3, 0.4),\n                       taper=True, zero_mean=True, taper_fraction=0.05)\n    return st\ndef download_day(day):\n    \"\"\"\n    下载某天所有台站数据，返回合并Stream和日志信息\n    \"\"\"\n    stream_day = Stream()\n    daily_log = []\n    log_lines = []\n\n    with ThreadPoolExecutor(max_workers=thread_workers) as executor:\n        futures = {executor.submit(download_station, net, sta, day): (net, sta) for net, sta in sta_list}\n\n        for future in as_completed(futures):\n            net, sta = futures[future]\n            try:\n                st = future.result()\n                stream_day += st\n                print(f\"✅ {net}.{sta} 下载成功（{len(st)} traces）\")\n                daily_log.append((net, sta, 1))\n            except Exception as e:\n                print(f\"❌ {net}.{sta} 下载失败: {e}\")\n                daily_log.append((net, sta, 0))\n                log_lines.append(f\"{day.date} {net}.{sta} ❌ {e}\")\n\n    return stream_day, daily_log, log_lines\n\ndef is_network_error(e):\n    \"\"\"\n    判断异常是否为网络相关异常\n    \"\"\"\n    network_error_types = (ConnectionError, Timeout, socket.timeout, socket.error)\n    return isinstance(e, network_error_types) or \"timed out\" in str(e).lower() or \"connection\" in str(e).lower()\n\n# 主循环\ncurrent_day = start_date\nwhile current_day <= end_date:\n    filename = f\"{current_day.strftime('%Y%m%d')}.mseed\"\n    filepath = os.path.join(output_dir, filename)\n\n    # 先判断文件是否存在且非空\n    if os.path.exists(filepath) and os.path.getsize(filepath) > 0:\n        print(f\"\\n📆 {current_day.date} 文件已存在且非空，跳过下载。\")\n        current_day += 86400\n        continue\n\n    print(f\"\\n📆 正在处理日期: {current_day.date}\")\n\n    attempt = 0\n    success = False\n    day_start_time = time.time()\n\n    while attempt < max_retries and not success:\n        attempt += 1\n        print(f\"🔄 尝试第 {attempt} 次下载 {current_day.date} ...\")\n\n        try:\n            stream_day, daily_log, log_lines = download_day(current_day)\n\n            if len(stream_day) == 0:\n                print(f\"⚠️ {current_day.date} 没有下载到数据，准备重试...\")\n                raise ValueError(\"下载数据为空\")\n\n            # 保存合并后的波形\n            stream_day.write(filepath, format=\"MSEED\")\n            print(f\"💾 {filename} 保存成功（共 {len(stream_day)} traces）\")\n            success = True\n\n            # 写入异常日志\n            if log_lines:\n                with open(exception_log, \"a\") as elog:\n                    elog.write(\"\\n\".join(log_lines) + \"\\n\")\n\n        except Exception as e:\n            print(f\"❌ 下载异常: {e}\")\n\n            # 判断是否为网络错误\n            if is_network_error(e):\n                print(\"🌐 网络异常，等待5秒后重试...\")\n                time.sleep(5)\n            else:\n                print(\"⚠️ 非网络异常，仍将重试...\")\n                time.sleep(3)\n\n    # 下载耗时记录\n    day_duration = time.time() - day_start_time\n    with open(timing_log, \"a\") as tlog:\n        tlog.write(f\"{current_day.date}: {day_duration:.2f} seconds\\n\")\n\n    if not success:\n        print(f\"❌ {current_day.date} 下载失败，超过最大重试次数。请检查网络或日志。\")\n\n    current_day += 86400\n```\n&emsp;&emsp;这个脚本实现的功能包括：\n   * 下载台站列表station.lst的2013-01-01到2024-01-01，LH?数据。\n   * 每天的数据存储为global_data/YYYYMMDD.mseed。\n   * 去仪器响应，保留VEL，滤波频率为0.008, 0.01, 0.3, 0.4。\n   * 记录每天数据下载的耗时，保存在“download_time.txt”中。\n   * 判断是否是网络中断错误，如果是则做5次尝试重新下载，每次间隔5秒。\n   * 判断当天数据是否已经被下载，如果没有或者大小是0则开始下载。\n   * 将错误输出到exceptions.txt中。\n   * 每天数据下载时，启用20个进程进行下载。\n","source":"_posts/2025-06-07-download-continuous-seis.md","raw":"---\ntitle: python脚本下载连续波形数据\ntags:\n  - python\ncategories:\n  - work\nabbrlink: b4ccc3e7\ndate: 2025-06-07 17:09:37\n---\n&emsp;&emsp;这是连续波形数据下载python脚本更新。\n<!--less-->\n```python\nimport os\nimport time\nimport socket\nimport numpy as np\nfrom obspy import UTCDateTime, Stream\nfrom obspy.clients.fdsn import Client\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\nfrom requests.exceptions import ConnectionError, Timeout\n\n# 参数设置\nclient = Client(\"IRIS\")\noutput_dir = \"global_data\"\nos.makedirs(output_dir, exist_ok=True)\nsta_file = \"station.lst\"\nstart_date = UTCDateTime(\"2013-01-01\")\nend_date = UTCDateTime(\"2024-01-01\")  # 包括该天\nthread_workers = 20\nexception_log = \"exceptions.txt\"\ntiming_log = \"download_time.txt\"\nmax_retries = 5  # 最大重试次数\nprint(f\"📁 当前工作目录: {os.getcwd()}\")\nprint(f\"📁 波形保存路径: {os.path.abspath(output_dir)}\")\n\n# 读取台站列表\nsta_list = []\nwith open(sta_file, \"r\") as sf:\n    for line in sf:\n        if line.strip() and not line.strip().startswith(\"#\"):\n            parts = line.strip().split()\n            if len(parts) >= 2:\n                net, sta = parts[0], parts[1]\n                sta_list.append((net, sta))\n\ndef download_station(net, sta, day):\n    \"\"\"\n    下载单个台站某天波形数据，去仪器响应，返回Stream\n    \"\"\"\n    start = UTCDateTime(day)\n    end = start + 86400\n    st = client.get_waveforms(net, sta, \"*\", \"LH?\", start, end, attach_response=True)\n\n    st.remove_response(output=\"VEL\", pre_filt=(0.008, 0.01, 0.3, 0.4),\n                       taper=True, zero_mean=True, taper_fraction=0.05)\n    return st\ndef download_day(day):\n    \"\"\"\n    下载某天所有台站数据，返回合并Stream和日志信息\n    \"\"\"\n    stream_day = Stream()\n    daily_log = []\n    log_lines = []\n\n    with ThreadPoolExecutor(max_workers=thread_workers) as executor:\n        futures = {executor.submit(download_station, net, sta, day): (net, sta) for net, sta in sta_list}\n\n        for future in as_completed(futures):\n            net, sta = futures[future]\n            try:\n                st = future.result()\n                stream_day += st\n                print(f\"✅ {net}.{sta} 下载成功（{len(st)} traces）\")\n                daily_log.append((net, sta, 1))\n            except Exception as e:\n                print(f\"❌ {net}.{sta} 下载失败: {e}\")\n                daily_log.append((net, sta, 0))\n                log_lines.append(f\"{day.date} {net}.{sta} ❌ {e}\")\n\n    return stream_day, daily_log, log_lines\n\ndef is_network_error(e):\n    \"\"\"\n    判断异常是否为网络相关异常\n    \"\"\"\n    network_error_types = (ConnectionError, Timeout, socket.timeout, socket.error)\n    return isinstance(e, network_error_types) or \"timed out\" in str(e).lower() or \"connection\" in str(e).lower()\n\n# 主循环\ncurrent_day = start_date\nwhile current_day <= end_date:\n    filename = f\"{current_day.strftime('%Y%m%d')}.mseed\"\n    filepath = os.path.join(output_dir, filename)\n\n    # 先判断文件是否存在且非空\n    if os.path.exists(filepath) and os.path.getsize(filepath) > 0:\n        print(f\"\\n📆 {current_day.date} 文件已存在且非空，跳过下载。\")\n        current_day += 86400\n        continue\n\n    print(f\"\\n📆 正在处理日期: {current_day.date}\")\n\n    attempt = 0\n    success = False\n    day_start_time = time.time()\n\n    while attempt < max_retries and not success:\n        attempt += 1\n        print(f\"🔄 尝试第 {attempt} 次下载 {current_day.date} ...\")\n\n        try:\n            stream_day, daily_log, log_lines = download_day(current_day)\n\n            if len(stream_day) == 0:\n                print(f\"⚠️ {current_day.date} 没有下载到数据，准备重试...\")\n                raise ValueError(\"下载数据为空\")\n\n            # 保存合并后的波形\n            stream_day.write(filepath, format=\"MSEED\")\n            print(f\"💾 {filename} 保存成功（共 {len(stream_day)} traces）\")\n            success = True\n\n            # 写入异常日志\n            if log_lines:\n                with open(exception_log, \"a\") as elog:\n                    elog.write(\"\\n\".join(log_lines) + \"\\n\")\n\n        except Exception as e:\n            print(f\"❌ 下载异常: {e}\")\n\n            # 判断是否为网络错误\n            if is_network_error(e):\n                print(\"🌐 网络异常，等待5秒后重试...\")\n                time.sleep(5)\n            else:\n                print(\"⚠️ 非网络异常，仍将重试...\")\n                time.sleep(3)\n\n    # 下载耗时记录\n    day_duration = time.time() - day_start_time\n    with open(timing_log, \"a\") as tlog:\n        tlog.write(f\"{current_day.date}: {day_duration:.2f} seconds\\n\")\n\n    if not success:\n        print(f\"❌ {current_day.date} 下载失败，超过最大重试次数。请检查网络或日志。\")\n\n    current_day += 86400\n```\n&emsp;&emsp;这个脚本实现的功能包括：\n   * 下载台站列表station.lst的2013-01-01到2024-01-01，LH?数据。\n   * 每天的数据存储为global_data/YYYYMMDD.mseed。\n   * 去仪器响应，保留VEL，滤波频率为0.008, 0.01, 0.3, 0.4。\n   * 记录每天数据下载的耗时，保存在“download_time.txt”中。\n   * 判断是否是网络中断错误，如果是则做5次尝试重新下载，每次间隔5秒。\n   * 判断当天数据是否已经被下载，如果没有或者大小是0则开始下载。\n   * 将错误输出到exceptions.txt中。\n   * 每天数据下载时，启用20个进程进行下载。\n","slug":"download-continuous-seis","published":1,"updated":"2025-06-07T11:51:08.953Z","comments":1,"layout":"post","photos":[],"_id":"cmh498iqg00cowvoufqha4uef","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\"><span class=\"keyword\">import</span> time</span><br><span class=\"line\"><span class=\"keyword\">import</span> socket</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">from</span> obspy <span class=\"keyword\">import</span> UTCDateTime, Stream</span><br><span class=\"line\"><span class=\"keyword\">from</span> obspy.clients.fdsn <span class=\"keyword\">import</span> Client</span><br><span class=\"line\"><span class=\"keyword\">from</span> concurrent.futures <span class=\"keyword\">import</span> ThreadPoolExecutor, as_completed</span><br><span class=\"line\"><span class=\"keyword\">from</span> requests.exceptions <span class=\"keyword\">import</span> ConnectionError, Timeout</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 参数设置</span></span><br><span class=\"line\">client = Client(<span class=\"string\">&quot;IRIS&quot;</span>)</span><br><span class=\"line\">output_dir = <span class=\"string\">&quot;global_data&quot;</span></span><br><span class=\"line\">os.makedirs(output_dir, exist_ok=<span class=\"literal\">True</span>)</span><br><span class=\"line\">sta_file = <span class=\"string\">&quot;station.lst&quot;</span></span><br><span class=\"line\">start_date = UTCDateTime(<span class=\"string\">&quot;2013-01-01&quot;</span>)</span><br><span class=\"line\">end_date = UTCDateTime(<span class=\"string\">&quot;2024-01-01&quot;</span>)  <span class=\"comment\"># 包括该天</span></span><br><span class=\"line\">thread_workers = <span class=\"number\">20</span></span><br><span class=\"line\">exception_log = <span class=\"string\">&quot;exceptions.txt&quot;</span></span><br><span class=\"line\">timing_log = <span class=\"string\">&quot;download_time.txt&quot;</span></span><br><span class=\"line\">max_retries = <span class=\"number\">5</span>  <span class=\"comment\"># 最大重试次数</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">f&quot;📁 当前工作目录: <span class=\"subst\">&#123;os.getcwd()&#125;</span>&quot;</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">f&quot;📁 波形保存路径: <span class=\"subst\">&#123;os.path.abspath(output_dir)&#125;</span>&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 读取台站列表</span></span><br><span class=\"line\">sta_list = []</span><br><span class=\"line\"><span class=\"keyword\">with</span> <span class=\"built_in\">open</span>(sta_file, <span class=\"string\">&quot;r&quot;</span>) <span class=\"keyword\">as</span> sf:</span><br><span class=\"line\">    <span class=\"keyword\">for</span> line <span class=\"keyword\">in</span> sf:</span><br><span class=\"line\">        <span class=\"keyword\">if</span> line.strip() <span class=\"keyword\">and</span> <span class=\"keyword\">not</span> line.strip().startswith(<span class=\"string\">&quot;#&quot;</span>):</span><br><span class=\"line\">            parts = line.strip().split()</span><br><span class=\"line\">            <span class=\"keyword\">if</span> <span class=\"built_in\">len</span>(parts) &gt;= <span class=\"number\">2</span>:</span><br><span class=\"line\">                net, sta = parts[<span class=\"number\">0</span>], parts[<span class=\"number\">1</span>]</span><br><span class=\"line\">                sta_list.append((net, sta))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">download_station</span>(<span class=\"params\">net, sta, day</span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;</span></span><br><span class=\"line\"><span class=\"string\">    下载单个台站某天波形数据，去仪器响应，返回Stream</span></span><br><span class=\"line\"><span class=\"string\">    &quot;&quot;&quot;</span></span><br><span class=\"line\">    start = UTCDateTime(day)</span><br><span class=\"line\">    end = start + <span class=\"number\">86400</span></span><br><span class=\"line\">    st = client.get_waveforms(net, sta, <span class=\"string\">&quot;*&quot;</span>, <span class=\"string\">&quot;LH?&quot;</span>, start, end, attach_response=<span class=\"literal\">True</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    st.remove_response(output=<span class=\"string\">&quot;VEL&quot;</span>, pre_filt=(<span class=\"number\">0.008</span>, <span class=\"number\">0.01</span>, <span class=\"number\">0.3</span>, <span class=\"number\">0.4</span>),</span><br><span class=\"line\">                       taper=<span class=\"literal\">True</span>, zero_mean=<span class=\"literal\">True</span>, taper_fraction=<span class=\"number\">0.05</span>)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> st</span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">download_day</span>(<span class=\"params\">day</span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;</span></span><br><span class=\"line\"><span class=\"string\">    下载某天所有台站数据，返回合并Stream和日志信息</span></span><br><span class=\"line\"><span class=\"string\">    &quot;&quot;&quot;</span></span><br><span class=\"line\">    stream_day = Stream()</span><br><span class=\"line\">    daily_log = []</span><br><span class=\"line\">    log_lines = []</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">with</span> ThreadPoolExecutor(max_workers=thread_workers) <span class=\"keyword\">as</span> executor:</span><br><span class=\"line\">        futures = &#123;executor.submit(download_station, net, sta, day): (net, sta) <span class=\"keyword\">for</span> net, sta <span class=\"keyword\">in</span> sta_list&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">for</span> future <span class=\"keyword\">in</span> as_completed(futures):</span><br><span class=\"line\">            net, sta = futures[future]</span><br><span class=\"line\">            <span class=\"keyword\">try</span>:</span><br><span class=\"line\">                st = future.result()</span><br><span class=\"line\">                stream_day += st</span><br><span class=\"line\">                <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;✅ <span class=\"subst\">&#123;net&#125;</span>.<span class=\"subst\">&#123;sta&#125;</span> 下载成功（<span class=\"subst\">&#123;<span class=\"built_in\">len</span>(st)&#125;</span> traces）&quot;</span>)</span><br><span class=\"line\">                daily_log.append((net, sta, <span class=\"number\">1</span>))</span><br><span class=\"line\">            <span class=\"keyword\">except</span> Exception <span class=\"keyword\">as</span> e:</span><br><span class=\"line\">                <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;❌ <span class=\"subst\">&#123;net&#125;</span>.<span class=\"subst\">&#123;sta&#125;</span> 下载失败: <span class=\"subst\">&#123;e&#125;</span>&quot;</span>)</span><br><span class=\"line\">                daily_log.append((net, sta, <span class=\"number\">0</span>))</span><br><span class=\"line\">                log_lines.append(<span class=\"string\">f&quot;<span class=\"subst\">&#123;day.date&#125;</span> <span class=\"subst\">&#123;net&#125;</span>.<span class=\"subst\">&#123;sta&#125;</span> ❌ <span class=\"subst\">&#123;e&#125;</span>&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> stream_day, daily_log, log_lines</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">is_network_error</span>(<span class=\"params\">e</span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;</span></span><br><span class=\"line\"><span class=\"string\">    判断异常是否为网络相关异常</span></span><br><span class=\"line\"><span class=\"string\">    &quot;&quot;&quot;</span></span><br><span class=\"line\">    network_error_types = (ConnectionError, Timeout, socket.timeout, socket.error)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"built_in\">isinstance</span>(e, network_error_types) <span class=\"keyword\">or</span> <span class=\"string\">&quot;timed out&quot;</span> <span class=\"keyword\">in</span> <span class=\"built_in\">str</span>(e).lower() <span class=\"keyword\">or</span> <span class=\"string\">&quot;connection&quot;</span> <span class=\"keyword\">in</span> <span class=\"built_in\">str</span>(e).lower()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 主循环</span></span><br><span class=\"line\">current_day = start_date</span><br><span class=\"line\"><span class=\"keyword\">while</span> current_day &lt;= end_date:</span><br><span class=\"line\">    filename = <span class=\"string\">f&quot;<span class=\"subst\">&#123;current_day.strftime(<span class=\"string\">&#x27;%Y%m%d&#x27;</span>)&#125;</span>.mseed&quot;</span></span><br><span class=\"line\">    filepath = os.path.join(output_dir, filename)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 先判断文件是否存在且非空</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> os.path.exists(filepath) <span class=\"keyword\">and</span> os.path.getsize(filepath) &gt; <span class=\"number\">0</span>:</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;\\n📆 <span class=\"subst\">&#123;current_day.date&#125;</span> 文件已存在且非空，跳过下载。&quot;</span>)</span><br><span class=\"line\">        current_day += <span class=\"number\">86400</span></span><br><span class=\"line\">        <span class=\"keyword\">continue</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;\\n📆 正在处理日期: <span class=\"subst\">&#123;current_day.date&#125;</span>&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    attempt = <span class=\"number\">0</span></span><br><span class=\"line\">    success = <span class=\"literal\">False</span></span><br><span class=\"line\">    day_start_time = time.time()</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">while</span> attempt &lt; max_retries <span class=\"keyword\">and</span> <span class=\"keyword\">not</span> success:</span><br><span class=\"line\">        attempt += <span class=\"number\">1</span></span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;🔄 尝试第 <span class=\"subst\">&#123;attempt&#125;</span> 次下载 <span class=\"subst\">&#123;current_day.date&#125;</span> ...&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">try</span>:</span><br><span class=\"line\">            stream_day, daily_log, log_lines = download_day(current_day)</span><br><span class=\"line\"></span><br><span class=\"line\">            <span class=\"keyword\">if</span> <span class=\"built_in\">len</span>(stream_day) == <span class=\"number\">0</span>:</span><br><span class=\"line\">                <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;⚠️ <span class=\"subst\">&#123;current_day.date&#125;</span> 没有下载到数据，准备重试...&quot;</span>)</span><br><span class=\"line\">                <span class=\"keyword\">raise</span> ValueError(<span class=\"string\">&quot;下载数据为空&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">            <span class=\"comment\"># 保存合并后的波形</span></span><br><span class=\"line\">            stream_day.write(filepath, <span class=\"built_in\">format</span>=<span class=\"string\">&quot;MSEED&quot;</span>)</span><br><span class=\"line\">            <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;💾 <span class=\"subst\">&#123;filename&#125;</span> 保存成功（共 <span class=\"subst\">&#123;<span class=\"built_in\">len</span>(stream_day)&#125;</span> traces）&quot;</span>)</span><br><span class=\"line\">            success = <span class=\"literal\">True</span></span><br><span class=\"line\"></span><br><span class=\"line\">            <span class=\"comment\"># 写入异常日志</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span> log_lines:</span><br><span class=\"line\">                <span class=\"keyword\">with</span> <span class=\"built_in\">open</span>(exception_log, <span class=\"string\">&quot;a&quot;</span>) <span class=\"keyword\">as</span> elog:</span><br><span class=\"line\">                    elog.write(<span class=\"string\">&quot;\\n&quot;</span>.join(log_lines) + <span class=\"string\">&quot;\\n&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">except</span> Exception <span class=\"keyword\">as</span> e:</span><br><span class=\"line\">            <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;❌ 下载异常: <span class=\"subst\">&#123;e&#125;</span>&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">            <span class=\"comment\"># 判断是否为网络错误</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span> is_network_error(e):</span><br><span class=\"line\">                <span class=\"built_in\">print</span>(<span class=\"string\">&quot;🌐 网络异常，等待5秒后重试...&quot;</span>)</span><br><span class=\"line\">                time.sleep(<span class=\"number\">5</span>)</span><br><span class=\"line\">            <span class=\"keyword\">else</span>:</span><br><span class=\"line\">                <span class=\"built_in\">print</span>(<span class=\"string\">&quot;⚠️ 非网络异常，仍将重试...&quot;</span>)</span><br><span class=\"line\">                time.sleep(<span class=\"number\">3</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 下载耗时记录</span></span><br><span class=\"line\">    day_duration = time.time() - day_start_time</span><br><span class=\"line\">    <span class=\"keyword\">with</span> <span class=\"built_in\">open</span>(timing_log, <span class=\"string\">&quot;a&quot;</span>) <span class=\"keyword\">as</span> tlog:</span><br><span class=\"line\">        tlog.write(<span class=\"string\">f&quot;<span class=\"subst\">&#123;current_day.date&#125;</span>: <span class=\"subst\">&#123;day_duration:<span class=\"number\">.2</span>f&#125;</span> seconds\\n&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">if</span> <span class=\"keyword\">not</span> success:</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;❌ <span class=\"subst\">&#123;current_day.date&#125;</span> 下载失败，超过最大重试次数。请检查网络或日志。&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    current_day += <span class=\"number\">86400</span></span><br></pre></td></tr></table></figure>\n<p>&emsp;&emsp;这个脚本实现的功能包括：</p>\n<ul>\n<li>下载台站列表station.lst的2013-01-01到2024-01-01，LH?数据。</li>\n<li>每天的数据存储为global_data&#x2F;YYYYMMDD.mseed。</li>\n<li>去仪器响应，保留VEL，滤波频率为0.008, 0.01, 0.3, 0.4。</li>\n<li>记录每天数据下载的耗时，保存在“download_time.txt”中。</li>\n<li>判断是否是网络中断错误，如果是则做5次尝试重新下载，每次间隔5秒。</li>\n<li>判断当天数据是否已经被下载，如果没有或者大小是0则开始下载。</li>\n<li>将错误输出到exceptions.txt中。</li>\n<li>每天数据下载时，启用20个进程进行下载。</li>\n</ul>","related_posts":["statistic-data-download.html"],"length":4389,"excerpt":"<p>&emsp;&emsp;这是连续波形数据下载python脚本更新。</p>","more":"<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\"><span class=\"keyword\">import</span> time</span><br><span class=\"line\"><span class=\"keyword\">import</span> socket</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">from</span> obspy <span class=\"keyword\">import</span> UTCDateTime, Stream</span><br><span class=\"line\"><span class=\"keyword\">from</span> obspy.clients.fdsn <span class=\"keyword\">import</span> Client</span><br><span class=\"line\"><span class=\"keyword\">from</span> concurrent.futures <span class=\"keyword\">import</span> ThreadPoolExecutor, as_completed</span><br><span class=\"line\"><span class=\"keyword\">from</span> requests.exceptions <span class=\"keyword\">import</span> ConnectionError, Timeout</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 参数设置</span></span><br><span class=\"line\">client = Client(<span class=\"string\">&quot;IRIS&quot;</span>)</span><br><span class=\"line\">output_dir = <span class=\"string\">&quot;global_data&quot;</span></span><br><span class=\"line\">os.makedirs(output_dir, exist_ok=<span class=\"literal\">True</span>)</span><br><span class=\"line\">sta_file = <span class=\"string\">&quot;station.lst&quot;</span></span><br><span class=\"line\">start_date = UTCDateTime(<span class=\"string\">&quot;2013-01-01&quot;</span>)</span><br><span class=\"line\">end_date = UTCDateTime(<span class=\"string\">&quot;2024-01-01&quot;</span>)  <span class=\"comment\"># 包括该天</span></span><br><span class=\"line\">thread_workers = <span class=\"number\">20</span></span><br><span class=\"line\">exception_log = <span class=\"string\">&quot;exceptions.txt&quot;</span></span><br><span class=\"line\">timing_log = <span class=\"string\">&quot;download_time.txt&quot;</span></span><br><span class=\"line\">max_retries = <span class=\"number\">5</span>  <span class=\"comment\"># 最大重试次数</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">f&quot;📁 当前工作目录: <span class=\"subst\">&#123;os.getcwd()&#125;</span>&quot;</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">f&quot;📁 波形保存路径: <span class=\"subst\">&#123;os.path.abspath(output_dir)&#125;</span>&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 读取台站列表</span></span><br><span class=\"line\">sta_list = []</span><br><span class=\"line\"><span class=\"keyword\">with</span> <span class=\"built_in\">open</span>(sta_file, <span class=\"string\">&quot;r&quot;</span>) <span class=\"keyword\">as</span> sf:</span><br><span class=\"line\">    <span class=\"keyword\">for</span> line <span class=\"keyword\">in</span> sf:</span><br><span class=\"line\">        <span class=\"keyword\">if</span> line.strip() <span class=\"keyword\">and</span> <span class=\"keyword\">not</span> line.strip().startswith(<span class=\"string\">&quot;#&quot;</span>):</span><br><span class=\"line\">            parts = line.strip().split()</span><br><span class=\"line\">            <span class=\"keyword\">if</span> <span class=\"built_in\">len</span>(parts) &gt;= <span class=\"number\">2</span>:</span><br><span class=\"line\">                net, sta = parts[<span class=\"number\">0</span>], parts[<span class=\"number\">1</span>]</span><br><span class=\"line\">                sta_list.append((net, sta))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">download_station</span>(<span class=\"params\">net, sta, day</span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;</span></span><br><span class=\"line\"><span class=\"string\">    下载单个台站某天波形数据，去仪器响应，返回Stream</span></span><br><span class=\"line\"><span class=\"string\">    &quot;&quot;&quot;</span></span><br><span class=\"line\">    start = UTCDateTime(day)</span><br><span class=\"line\">    end = start + <span class=\"number\">86400</span></span><br><span class=\"line\">    st = client.get_waveforms(net, sta, <span class=\"string\">&quot;*&quot;</span>, <span class=\"string\">&quot;LH?&quot;</span>, start, end, attach_response=<span class=\"literal\">True</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    st.remove_response(output=<span class=\"string\">&quot;VEL&quot;</span>, pre_filt=(<span class=\"number\">0.008</span>, <span class=\"number\">0.01</span>, <span class=\"number\">0.3</span>, <span class=\"number\">0.4</span>),</span><br><span class=\"line\">                       taper=<span class=\"literal\">True</span>, zero_mean=<span class=\"literal\">True</span>, taper_fraction=<span class=\"number\">0.05</span>)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> st</span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">download_day</span>(<span class=\"params\">day</span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;</span></span><br><span class=\"line\"><span class=\"string\">    下载某天所有台站数据，返回合并Stream和日志信息</span></span><br><span class=\"line\"><span class=\"string\">    &quot;&quot;&quot;</span></span><br><span class=\"line\">    stream_day = Stream()</span><br><span class=\"line\">    daily_log = []</span><br><span class=\"line\">    log_lines = []</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">with</span> ThreadPoolExecutor(max_workers=thread_workers) <span class=\"keyword\">as</span> executor:</span><br><span class=\"line\">        futures = &#123;executor.submit(download_station, net, sta, day): (net, sta) <span class=\"keyword\">for</span> net, sta <span class=\"keyword\">in</span> sta_list&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">for</span> future <span class=\"keyword\">in</span> as_completed(futures):</span><br><span class=\"line\">            net, sta = futures[future]</span><br><span class=\"line\">            <span class=\"keyword\">try</span>:</span><br><span class=\"line\">                st = future.result()</span><br><span class=\"line\">                stream_day += st</span><br><span class=\"line\">                <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;✅ <span class=\"subst\">&#123;net&#125;</span>.<span class=\"subst\">&#123;sta&#125;</span> 下载成功（<span class=\"subst\">&#123;<span class=\"built_in\">len</span>(st)&#125;</span> traces）&quot;</span>)</span><br><span class=\"line\">                daily_log.append((net, sta, <span class=\"number\">1</span>))</span><br><span class=\"line\">            <span class=\"keyword\">except</span> Exception <span class=\"keyword\">as</span> e:</span><br><span class=\"line\">                <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;❌ <span class=\"subst\">&#123;net&#125;</span>.<span class=\"subst\">&#123;sta&#125;</span> 下载失败: <span class=\"subst\">&#123;e&#125;</span>&quot;</span>)</span><br><span class=\"line\">                daily_log.append((net, sta, <span class=\"number\">0</span>))</span><br><span class=\"line\">                log_lines.append(<span class=\"string\">f&quot;<span class=\"subst\">&#123;day.date&#125;</span> <span class=\"subst\">&#123;net&#125;</span>.<span class=\"subst\">&#123;sta&#125;</span> ❌ <span class=\"subst\">&#123;e&#125;</span>&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> stream_day, daily_log, log_lines</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">is_network_error</span>(<span class=\"params\">e</span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;</span></span><br><span class=\"line\"><span class=\"string\">    判断异常是否为网络相关异常</span></span><br><span class=\"line\"><span class=\"string\">    &quot;&quot;&quot;</span></span><br><span class=\"line\">    network_error_types = (ConnectionError, Timeout, socket.timeout, socket.error)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"built_in\">isinstance</span>(e, network_error_types) <span class=\"keyword\">or</span> <span class=\"string\">&quot;timed out&quot;</span> <span class=\"keyword\">in</span> <span class=\"built_in\">str</span>(e).lower() <span class=\"keyword\">or</span> <span class=\"string\">&quot;connection&quot;</span> <span class=\"keyword\">in</span> <span class=\"built_in\">str</span>(e).lower()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 主循环</span></span><br><span class=\"line\">current_day = start_date</span><br><span class=\"line\"><span class=\"keyword\">while</span> current_day &lt;= end_date:</span><br><span class=\"line\">    filename = <span class=\"string\">f&quot;<span class=\"subst\">&#123;current_day.strftime(<span class=\"string\">&#x27;%Y%m%d&#x27;</span>)&#125;</span>.mseed&quot;</span></span><br><span class=\"line\">    filepath = os.path.join(output_dir, filename)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 先判断文件是否存在且非空</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> os.path.exists(filepath) <span class=\"keyword\">and</span> os.path.getsize(filepath) &gt; <span class=\"number\">0</span>:</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;\\n📆 <span class=\"subst\">&#123;current_day.date&#125;</span> 文件已存在且非空，跳过下载。&quot;</span>)</span><br><span class=\"line\">        current_day += <span class=\"number\">86400</span></span><br><span class=\"line\">        <span class=\"keyword\">continue</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;\\n📆 正在处理日期: <span class=\"subst\">&#123;current_day.date&#125;</span>&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    attempt = <span class=\"number\">0</span></span><br><span class=\"line\">    success = <span class=\"literal\">False</span></span><br><span class=\"line\">    day_start_time = time.time()</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">while</span> attempt &lt; max_retries <span class=\"keyword\">and</span> <span class=\"keyword\">not</span> success:</span><br><span class=\"line\">        attempt += <span class=\"number\">1</span></span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;🔄 尝试第 <span class=\"subst\">&#123;attempt&#125;</span> 次下载 <span class=\"subst\">&#123;current_day.date&#125;</span> ...&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">try</span>:</span><br><span class=\"line\">            stream_day, daily_log, log_lines = download_day(current_day)</span><br><span class=\"line\"></span><br><span class=\"line\">            <span class=\"keyword\">if</span> <span class=\"built_in\">len</span>(stream_day) == <span class=\"number\">0</span>:</span><br><span class=\"line\">                <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;⚠️ <span class=\"subst\">&#123;current_day.date&#125;</span> 没有下载到数据，准备重试...&quot;</span>)</span><br><span class=\"line\">                <span class=\"keyword\">raise</span> ValueError(<span class=\"string\">&quot;下载数据为空&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">            <span class=\"comment\"># 保存合并后的波形</span></span><br><span class=\"line\">            stream_day.write(filepath, <span class=\"built_in\">format</span>=<span class=\"string\">&quot;MSEED&quot;</span>)</span><br><span class=\"line\">            <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;💾 <span class=\"subst\">&#123;filename&#125;</span> 保存成功（共 <span class=\"subst\">&#123;<span class=\"built_in\">len</span>(stream_day)&#125;</span> traces）&quot;</span>)</span><br><span class=\"line\">            success = <span class=\"literal\">True</span></span><br><span class=\"line\"></span><br><span class=\"line\">            <span class=\"comment\"># 写入异常日志</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span> log_lines:</span><br><span class=\"line\">                <span class=\"keyword\">with</span> <span class=\"built_in\">open</span>(exception_log, <span class=\"string\">&quot;a&quot;</span>) <span class=\"keyword\">as</span> elog:</span><br><span class=\"line\">                    elog.write(<span class=\"string\">&quot;\\n&quot;</span>.join(log_lines) + <span class=\"string\">&quot;\\n&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">except</span> Exception <span class=\"keyword\">as</span> e:</span><br><span class=\"line\">            <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;❌ 下载异常: <span class=\"subst\">&#123;e&#125;</span>&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">            <span class=\"comment\"># 判断是否为网络错误</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span> is_network_error(e):</span><br><span class=\"line\">                <span class=\"built_in\">print</span>(<span class=\"string\">&quot;🌐 网络异常，等待5秒后重试...&quot;</span>)</span><br><span class=\"line\">                time.sleep(<span class=\"number\">5</span>)</span><br><span class=\"line\">            <span class=\"keyword\">else</span>:</span><br><span class=\"line\">                <span class=\"built_in\">print</span>(<span class=\"string\">&quot;⚠️ 非网络异常，仍将重试...&quot;</span>)</span><br><span class=\"line\">                time.sleep(<span class=\"number\">3</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 下载耗时记录</span></span><br><span class=\"line\">    day_duration = time.time() - day_start_time</span><br><span class=\"line\">    <span class=\"keyword\">with</span> <span class=\"built_in\">open</span>(timing_log, <span class=\"string\">&quot;a&quot;</span>) <span class=\"keyword\">as</span> tlog:</span><br><span class=\"line\">        tlog.write(<span class=\"string\">f&quot;<span class=\"subst\">&#123;current_day.date&#125;</span>: <span class=\"subst\">&#123;day_duration:<span class=\"number\">.2</span>f&#125;</span> seconds\\n&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">if</span> <span class=\"keyword\">not</span> success:</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;❌ <span class=\"subst\">&#123;current_day.date&#125;</span> 下载失败，超过最大重试次数。请检查网络或日志。&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    current_day += <span class=\"number\">86400</span></span><br></pre></td></tr></table></figure>\n<p>&emsp;&emsp;这个脚本实现的功能包括：</p>\n<ul>\n<li>下载台站列表station.lst的2013-01-01到2024-01-01，LH?数据。</li>\n<li>每天的数据存储为global_data&#x2F;YYYYMMDD.mseed。</li>\n<li>去仪器响应，保留VEL，滤波频率为0.008, 0.01, 0.3, 0.4。</li>\n<li>记录每天数据下载的耗时，保存在“download_time.txt”中。</li>\n<li>判断是否是网络中断错误，如果是则做5次尝试重新下载，每次间隔5秒。</li>\n<li>判断当天数据是否已经被下载，如果没有或者大小是0则开始下载。</li>\n<li>将错误输出到exceptions.txt中。</li>\n<li>每天数据下载时，启用20个进程进行下载。</li>\n</ul>"},{"title":"统计数据下载情况","abbrlink":"dc8bc93b","date":"2025-06-07T11:48:45.000Z","_content":"&emsp;&emsp;数据下载好后需要统计下载的情况，这是python脚本。\n```python\nimport os\nfrom obspy import read\nfrom datetime import datetime as dt\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.cm as cm\nimport matplotlib.dates as mdates\nfrom collections import defaultdict\nfrom matplotlib.transforms import blended_transform_factory\n\n# ===== 配置 =====\ndata_dir = \"daily_waveforms\"  # 存放YYYYMMDD.mseed文件目录\nstation_file = \"station.list\"  # 台站列表，格式：NET STA（两列）\ncomponents = [\"LHZ\", \"LHN\", \"LHE\"]\nstart_year = 2020\nend_year = 2020\n\n# ===== 读取台站列表 =====\nstations = []\nwith open(station_file, \"r\") as f:\n    for line in f:\n        if line.strip():\n            net, sta = line.strip().split()[:2]\n            stations.append((net, sta))\n\nstation_set = set(f\"{net}.{sta}\" for net, sta in stations)\n\n# ===== 初始化 =====\nstation_dates = {comp: defaultdict(set) for comp in components}  # comp -> {net.sta -> set(date)}\nstation_file_sizes = defaultdict(int)  # 台站对应所有文件大小\ntotal_files = 0\ntotal_file_size = 0\n\n# ===== 遍历所有mseed文件 =====\nall_files = sorted(f for f in os.listdir(data_dir) if f.endswith(\".mseed\"))\nfor filename in all_files:\n    filepath = os.path.join(data_dir, filename)\n\n    size = os.path.getsize(filepath)\n    total_files += 1\n    total_file_size += size\n\n    try:\n        st = read(filepath)\n    except Exception as e:\n        print(f\"读取文件失败 {filename}: {e}\")\n        continue\n\n    # 解析文件日期 YYYYMMDD\n    try:\n        file_date = dt.strptime(filename[:8], \"%Y%m%d\").date()\n    except Exception as e:\n        print(f\"无法解析日期 {filename}: {e}\")\n        continue\n\n    for tr in st:\n        net = tr.stats.network\n        sta = tr.stats.station\n        comp = tr.stats.channel[-3:]\n\n        key = f\"{net}.{sta}\"\n        if key not in station_set:\n            continue\n        if comp not in components:\n            continue\n\n        station_dates[comp][key].add(file_date)\n        station_file_sizes[key] += size\n\nprint(f\"共计读取文件数: {total_files}\")\nprint(f\"所有文件总大小: {total_file_size / (1024**2):.2f} MB\")\n\n# ===== 删除无有效数据台站 =====\nfor comp in components:\n    keys_to_remove = [k for k, dates in station_dates[comp].items() if len(dates) == 0]\n    for k in keys_to_remove:\n        del station_dates[comp][k]\n\n# ===== 输出有效天数统计文本 =====\nfor comp in components:\n    with open(f\"station_day_count_{comp}.txt\", \"w\") as f:\n        for key in sorted(station_dates[comp].keys()):\n            f.write(f\"{key} {len(station_dates[comp][key])}\\n\")\n\n# ===== 台网颜色映射 =====\nall_nets = sorted(set(net for net, sta in stations))\nnet_color_map = {net: cm.get_cmap(\"tab20\")(i / max(len(all_nets)-1,1)) for i, net in enumerate(all_nets)}\n\n# ===== 绘图函数 =====\ndef plot_component_availability(comp, station_dates_comp):\n    valid_stations = sorted(station_dates_comp.keys(), key=lambda x: (x.split(\".\")[0], x.split(\".\")[1]))\n    fig, ax = plt.subplots(figsize=(14, max(6, 0.3 * len(valid_stations))))\n\n    def to_datetime(d):\n        return dt(d.year, d.month, d.day)\n\n    for idx, key in enumerate(valid_stations):\n        net = key.split(\".\")[0]\n        dates = sorted(station_dates_comp[key])\n        x_vals = [to_datetime(d) for d in dates]\n        ax.plot(x_vals, [idx]*len(dates), \".\", color=net_color_map[net], markersize=2)\n\n    ax.set_xlabel(\"时间\")\n    ax.set_ylabel(\"台站\")\n    ax.set_yticks(range(len(valid_stations)))\n    ax.set_yticklabels(valid_stations, fontsize=5)\n\n    ax.grid(True, linestyle=\":\", alpha=0.5)\n\n    x_start = dt(start_year, 1, 1)\n    x_end = dt(end_year, 12, 31)\n    ax.set_xlim(x_start, x_end)\n\n    ax.xaxis.set_major_locator(mdates.YearLocator())\n    ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%Y\"))\n\n    plt.tight_layout(rect=[0, 0, 0.85, 1])\n\n    # 右侧外部标注台网名\n    trans = blended_transform_factory(ax.transAxes, ax.transData)\n    net_indices = defaultdict(list)\n    for idx, key in enumerate(valid_stations):\n        net = key.split(\".\")[0]\n        net_indices[net].append(idx)\n\n    for net, indices in net_indices.items():\n        mid_idx = indices[len(indices)//2]\n        color = net_color_map[net]\n        ax.text(1.02, mid_idx, net, color=color, fontsize=8, fontweight='bold',\n                verticalalignment='center', horizontalalignment='left',\n                transform=trans)\n\n    plt.savefig(f\"{comp}_availability_2013_2022.png\", dpi=300, bbox_inches='tight')\n    plt.close()\n    print(f\"已保存图像: {comp}_availability_2013_2022.png\")\n\n# ===== 画三分量图 =====\nfor comp in components:\n    plot_component_availability(comp, station_dates[comp])\n\n# ===== 台网统计 =====\nnetwork_stats = defaultdict(lambda: {\"total\": 0, \"valid\": 0, \"day_counts\": []})\n\nfor net, sta in stations:\n    network_stats[net][\"total\"] += 1\n\nall_valid_keys = set()\nfor comp in components:\n    all_valid_keys.update(station_dates[comp].keys())\n\nfor key in all_valid_keys:\n    net = key.split(\".\")[0]\n    days_list = [len(station_dates[comp].get(key, [])) for comp in components]\n    valid_days = max(days_list)\n    network_stats[net][\"valid\"] += 1\n    network_stats[net][\"day_counts\"].append(valid_days)\n\nprint(\"\\n台网统计汇总：\")\nprint(f\"{'Net':<6} {'Total':>6} {'Valid':>6} {'AvgDays':>10}\")\nprint(\"-\" * 32)\nwith open(\"network_summary_all_components.txt\", \"w\") as f:\n    f.write(f\"{'Net':<6} {'Total':>6} {'Valid':>6} {'AvgDays':>10}\\n\")\n    for net in sorted(network_stats.keys()):\n        total = network_stats[net][\"total\"]\n        valid = network_stats[net][\"valid\"]\n        avg_days = np.mean(network_stats[net][\"day_counts\"]) if network_stats[net][\"day_counts\"] else 0\n        line = f\"{net:<6} {total:>6} {valid:>6} {avg_days:>10.1f}\"\n        print(line)\n        f.write(line + \"\\n\")\n\n# ===== 总结 =====\nprint(f\"\\n文件总数: {total_files}\")\nprint(f\"文件总大小: {total_file_size/(1024**2):.2f} MB ({total_file_size/(1024**3):.2f} GB)\")\n```\n&emsp;&emsp;这个脚本实现的功能包括：\n   * 统计开始时间start_year到结束时间end_year的数据下载情况\n   * 对LHZ、LHN和LHE分别进行统计。\n   * 对统计结果进行可视化输出。\n   * 横轴是时间，纵轴是台站名。不同台网用不同颜色标出。在图右侧标出台网名。\n   * 输出文件network_summary_all_components.txt，给出台网包含台站数目，有效台站数目和各自平均天数。\n   * 输出文件station_day_count_{comp}.txt，给出台站名和有效天数。\n   * 输出文件总数，文件总大小。\n","source":"_posts/2025-06-07-statistic-data-download.md","raw":"---\ntitle: 统计数据下载情况\ntags:\n  - python\ncategories:\n  - work\nabbrlink: dc8bc93b\ndate: 2025-06-07 19:48:45\n---\n&emsp;&emsp;数据下载好后需要统计下载的情况，这是python脚本。\n```python\nimport os\nfrom obspy import read\nfrom datetime import datetime as dt\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.cm as cm\nimport matplotlib.dates as mdates\nfrom collections import defaultdict\nfrom matplotlib.transforms import blended_transform_factory\n\n# ===== 配置 =====\ndata_dir = \"daily_waveforms\"  # 存放YYYYMMDD.mseed文件目录\nstation_file = \"station.list\"  # 台站列表，格式：NET STA（两列）\ncomponents = [\"LHZ\", \"LHN\", \"LHE\"]\nstart_year = 2020\nend_year = 2020\n\n# ===== 读取台站列表 =====\nstations = []\nwith open(station_file, \"r\") as f:\n    for line in f:\n        if line.strip():\n            net, sta = line.strip().split()[:2]\n            stations.append((net, sta))\n\nstation_set = set(f\"{net}.{sta}\" for net, sta in stations)\n\n# ===== 初始化 =====\nstation_dates = {comp: defaultdict(set) for comp in components}  # comp -> {net.sta -> set(date)}\nstation_file_sizes = defaultdict(int)  # 台站对应所有文件大小\ntotal_files = 0\ntotal_file_size = 0\n\n# ===== 遍历所有mseed文件 =====\nall_files = sorted(f for f in os.listdir(data_dir) if f.endswith(\".mseed\"))\nfor filename in all_files:\n    filepath = os.path.join(data_dir, filename)\n\n    size = os.path.getsize(filepath)\n    total_files += 1\n    total_file_size += size\n\n    try:\n        st = read(filepath)\n    except Exception as e:\n        print(f\"读取文件失败 {filename}: {e}\")\n        continue\n\n    # 解析文件日期 YYYYMMDD\n    try:\n        file_date = dt.strptime(filename[:8], \"%Y%m%d\").date()\n    except Exception as e:\n        print(f\"无法解析日期 {filename}: {e}\")\n        continue\n\n    for tr in st:\n        net = tr.stats.network\n        sta = tr.stats.station\n        comp = tr.stats.channel[-3:]\n\n        key = f\"{net}.{sta}\"\n        if key not in station_set:\n            continue\n        if comp not in components:\n            continue\n\n        station_dates[comp][key].add(file_date)\n        station_file_sizes[key] += size\n\nprint(f\"共计读取文件数: {total_files}\")\nprint(f\"所有文件总大小: {total_file_size / (1024**2):.2f} MB\")\n\n# ===== 删除无有效数据台站 =====\nfor comp in components:\n    keys_to_remove = [k for k, dates in station_dates[comp].items() if len(dates) == 0]\n    for k in keys_to_remove:\n        del station_dates[comp][k]\n\n# ===== 输出有效天数统计文本 =====\nfor comp in components:\n    with open(f\"station_day_count_{comp}.txt\", \"w\") as f:\n        for key in sorted(station_dates[comp].keys()):\n            f.write(f\"{key} {len(station_dates[comp][key])}\\n\")\n\n# ===== 台网颜色映射 =====\nall_nets = sorted(set(net for net, sta in stations))\nnet_color_map = {net: cm.get_cmap(\"tab20\")(i / max(len(all_nets)-1,1)) for i, net in enumerate(all_nets)}\n\n# ===== 绘图函数 =====\ndef plot_component_availability(comp, station_dates_comp):\n    valid_stations = sorted(station_dates_comp.keys(), key=lambda x: (x.split(\".\")[0], x.split(\".\")[1]))\n    fig, ax = plt.subplots(figsize=(14, max(6, 0.3 * len(valid_stations))))\n\n    def to_datetime(d):\n        return dt(d.year, d.month, d.day)\n\n    for idx, key in enumerate(valid_stations):\n        net = key.split(\".\")[0]\n        dates = sorted(station_dates_comp[key])\n        x_vals = [to_datetime(d) for d in dates]\n        ax.plot(x_vals, [idx]*len(dates), \".\", color=net_color_map[net], markersize=2)\n\n    ax.set_xlabel(\"时间\")\n    ax.set_ylabel(\"台站\")\n    ax.set_yticks(range(len(valid_stations)))\n    ax.set_yticklabels(valid_stations, fontsize=5)\n\n    ax.grid(True, linestyle=\":\", alpha=0.5)\n\n    x_start = dt(start_year, 1, 1)\n    x_end = dt(end_year, 12, 31)\n    ax.set_xlim(x_start, x_end)\n\n    ax.xaxis.set_major_locator(mdates.YearLocator())\n    ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%Y\"))\n\n    plt.tight_layout(rect=[0, 0, 0.85, 1])\n\n    # 右侧外部标注台网名\n    trans = blended_transform_factory(ax.transAxes, ax.transData)\n    net_indices = defaultdict(list)\n    for idx, key in enumerate(valid_stations):\n        net = key.split(\".\")[0]\n        net_indices[net].append(idx)\n\n    for net, indices in net_indices.items():\n        mid_idx = indices[len(indices)//2]\n        color = net_color_map[net]\n        ax.text(1.02, mid_idx, net, color=color, fontsize=8, fontweight='bold',\n                verticalalignment='center', horizontalalignment='left',\n                transform=trans)\n\n    plt.savefig(f\"{comp}_availability_2013_2022.png\", dpi=300, bbox_inches='tight')\n    plt.close()\n    print(f\"已保存图像: {comp}_availability_2013_2022.png\")\n\n# ===== 画三分量图 =====\nfor comp in components:\n    plot_component_availability(comp, station_dates[comp])\n\n# ===== 台网统计 =====\nnetwork_stats = defaultdict(lambda: {\"total\": 0, \"valid\": 0, \"day_counts\": []})\n\nfor net, sta in stations:\n    network_stats[net][\"total\"] += 1\n\nall_valid_keys = set()\nfor comp in components:\n    all_valid_keys.update(station_dates[comp].keys())\n\nfor key in all_valid_keys:\n    net = key.split(\".\")[0]\n    days_list = [len(station_dates[comp].get(key, [])) for comp in components]\n    valid_days = max(days_list)\n    network_stats[net][\"valid\"] += 1\n    network_stats[net][\"day_counts\"].append(valid_days)\n\nprint(\"\\n台网统计汇总：\")\nprint(f\"{'Net':<6} {'Total':>6} {'Valid':>6} {'AvgDays':>10}\")\nprint(\"-\" * 32)\nwith open(\"network_summary_all_components.txt\", \"w\") as f:\n    f.write(f\"{'Net':<6} {'Total':>6} {'Valid':>6} {'AvgDays':>10}\\n\")\n    for net in sorted(network_stats.keys()):\n        total = network_stats[net][\"total\"]\n        valid = network_stats[net][\"valid\"]\n        avg_days = np.mean(network_stats[net][\"day_counts\"]) if network_stats[net][\"day_counts\"] else 0\n        line = f\"{net:<6} {total:>6} {valid:>6} {avg_days:>10.1f}\"\n        print(line)\n        f.write(line + \"\\n\")\n\n# ===== 总结 =====\nprint(f\"\\n文件总数: {total_files}\")\nprint(f\"文件总大小: {total_file_size/(1024**2):.2f} MB ({total_file_size/(1024**3):.2f} GB)\")\n```\n&emsp;&emsp;这个脚本实现的功能包括：\n   * 统计开始时间start_year到结束时间end_year的数据下载情况\n   * 对LHZ、LHN和LHE分别进行统计。\n   * 对统计结果进行可视化输出。\n   * 横轴是时间，纵轴是台站名。不同台网用不同颜色标出。在图右侧标出台网名。\n   * 输出文件network_summary_all_components.txt，给出台网包含台站数目，有效台站数目和各自平均天数。\n   * 输出文件station_day_count_{comp}.txt，给出台站名和有效天数。\n   * 输出文件总数，文件总大小。\n","slug":"statistic-data-download","published":1,"updated":"2025-06-07T11:58:11.040Z","comments":1,"layout":"post","photos":[],"_id":"cmh498iqh00cswvoudssp2rfy","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>&emsp;&emsp;数据下载好后需要统计下载的情况，这是python脚本。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br><span class=\"line\">145</span><br><span class=\"line\">146</span><br><span class=\"line\">147</span><br><span class=\"line\">148</span><br><span class=\"line\">149</span><br><span class=\"line\">150</span><br><span class=\"line\">151</span><br><span class=\"line\">152</span><br><span class=\"line\">153</span><br><span class=\"line\">154</span><br><span class=\"line\">155</span><br><span class=\"line\">156</span><br><span class=\"line\">157</span><br><span class=\"line\">158</span><br><span class=\"line\">159</span><br><span class=\"line\">160</span><br><span class=\"line\">161</span><br><span class=\"line\">162</span><br><span class=\"line\">163</span><br><span class=\"line\">164</span><br><span class=\"line\">165</span><br><span class=\"line\">166</span><br><span class=\"line\">167</span><br><span class=\"line\">168</span><br><span class=\"line\">169</span><br><span class=\"line\">170</span><br><span class=\"line\">171</span><br><span class=\"line\">172</span><br><span class=\"line\">173</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\"><span class=\"keyword\">from</span> obspy <span class=\"keyword\">import</span> read</span><br><span class=\"line\"><span class=\"keyword\">from</span> datetime <span class=\"keyword\">import</span> datetime <span class=\"keyword\">as</span> dt</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.cm <span class=\"keyword\">as</span> cm</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.dates <span class=\"keyword\">as</span> mdates</span><br><span class=\"line\"><span class=\"keyword\">from</span> collections <span class=\"keyword\">import</span> defaultdict</span><br><span class=\"line\"><span class=\"keyword\">from</span> matplotlib.transforms <span class=\"keyword\">import</span> blended_transform_factory</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># ===== 配置 =====</span></span><br><span class=\"line\">data_dir = <span class=\"string\">&quot;daily_waveforms&quot;</span>  <span class=\"comment\"># 存放YYYYMMDD.mseed文件目录</span></span><br><span class=\"line\">station_file = <span class=\"string\">&quot;station.list&quot;</span>  <span class=\"comment\"># 台站列表，格式：NET STA（两列）</span></span><br><span class=\"line\">components = [<span class=\"string\">&quot;LHZ&quot;</span>, <span class=\"string\">&quot;LHN&quot;</span>, <span class=\"string\">&quot;LHE&quot;</span>]</span><br><span class=\"line\">start_year = <span class=\"number\">2020</span></span><br><span class=\"line\">end_year = <span class=\"number\">2020</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># ===== 读取台站列表 =====</span></span><br><span class=\"line\">stations = []</span><br><span class=\"line\"><span class=\"keyword\">with</span> <span class=\"built_in\">open</span>(station_file, <span class=\"string\">&quot;r&quot;</span>) <span class=\"keyword\">as</span> f:</span><br><span class=\"line\">    <span class=\"keyword\">for</span> line <span class=\"keyword\">in</span> f:</span><br><span class=\"line\">        <span class=\"keyword\">if</span> line.strip():</span><br><span class=\"line\">            net, sta = line.strip().split()[:<span class=\"number\">2</span>]</span><br><span class=\"line\">            stations.append((net, sta))</span><br><span class=\"line\"></span><br><span class=\"line\">station_set = <span class=\"built_in\">set</span>(<span class=\"string\">f&quot;<span class=\"subst\">&#123;net&#125;</span>.<span class=\"subst\">&#123;sta&#125;</span>&quot;</span> <span class=\"keyword\">for</span> net, sta <span class=\"keyword\">in</span> stations)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># ===== 初始化 =====</span></span><br><span class=\"line\">station_dates = &#123;comp: defaultdict(<span class=\"built_in\">set</span>) <span class=\"keyword\">for</span> comp <span class=\"keyword\">in</span> components&#125;  <span class=\"comment\"># comp -&gt; &#123;net.sta -&gt; set(date)&#125;</span></span><br><span class=\"line\">station_file_sizes = defaultdict(<span class=\"built_in\">int</span>)  <span class=\"comment\"># 台站对应所有文件大小</span></span><br><span class=\"line\">total_files = <span class=\"number\">0</span></span><br><span class=\"line\">total_file_size = <span class=\"number\">0</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># ===== 遍历所有mseed文件 =====</span></span><br><span class=\"line\">all_files = <span class=\"built_in\">sorted</span>(f <span class=\"keyword\">for</span> f <span class=\"keyword\">in</span> os.listdir(data_dir) <span class=\"keyword\">if</span> f.endswith(<span class=\"string\">&quot;.mseed&quot;</span>))</span><br><span class=\"line\"><span class=\"keyword\">for</span> filename <span class=\"keyword\">in</span> all_files:</span><br><span class=\"line\">    filepath = os.path.join(data_dir, filename)</span><br><span class=\"line\"></span><br><span class=\"line\">    size = os.path.getsize(filepath)</span><br><span class=\"line\">    total_files += <span class=\"number\">1</span></span><br><span class=\"line\">    total_file_size += size</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">try</span>:</span><br><span class=\"line\">        st = read(filepath)</span><br><span class=\"line\">    <span class=\"keyword\">except</span> Exception <span class=\"keyword\">as</span> e:</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;读取文件失败 <span class=\"subst\">&#123;filename&#125;</span>: <span class=\"subst\">&#123;e&#125;</span>&quot;</span>)</span><br><span class=\"line\">        <span class=\"keyword\">continue</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 解析文件日期 YYYYMMDD</span></span><br><span class=\"line\">    <span class=\"keyword\">try</span>:</span><br><span class=\"line\">        file_date = dt.strptime(filename[:<span class=\"number\">8</span>], <span class=\"string\">&quot;%Y%m%d&quot;</span>).date()</span><br><span class=\"line\">    <span class=\"keyword\">except</span> Exception <span class=\"keyword\">as</span> e:</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;无法解析日期 <span class=\"subst\">&#123;filename&#125;</span>: <span class=\"subst\">&#123;e&#125;</span>&quot;</span>)</span><br><span class=\"line\">        <span class=\"keyword\">continue</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">for</span> tr <span class=\"keyword\">in</span> st:</span><br><span class=\"line\">        net = tr.stats.network</span><br><span class=\"line\">        sta = tr.stats.station</span><br><span class=\"line\">        comp = tr.stats.channel[-<span class=\"number\">3</span>:]</span><br><span class=\"line\"></span><br><span class=\"line\">        key = <span class=\"string\">f&quot;<span class=\"subst\">&#123;net&#125;</span>.<span class=\"subst\">&#123;sta&#125;</span>&quot;</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> key <span class=\"keyword\">not</span> <span class=\"keyword\">in</span> station_set:</span><br><span class=\"line\">            <span class=\"keyword\">continue</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> comp <span class=\"keyword\">not</span> <span class=\"keyword\">in</span> components:</span><br><span class=\"line\">            <span class=\"keyword\">continue</span></span><br><span class=\"line\"></span><br><span class=\"line\">        station_dates[comp][key].add(file_date)</span><br><span class=\"line\">        station_file_sizes[key] += size</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">f&quot;共计读取文件数: <span class=\"subst\">&#123;total_files&#125;</span>&quot;</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">f&quot;所有文件总大小: <span class=\"subst\">&#123;total_file_size / (<span class=\"number\">1024</span>**<span class=\"number\">2</span>):<span class=\"number\">.2</span>f&#125;</span> MB&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># ===== 删除无有效数据台站 =====</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> comp <span class=\"keyword\">in</span> components:</span><br><span class=\"line\">    keys_to_remove = [k <span class=\"keyword\">for</span> k, dates <span class=\"keyword\">in</span> station_dates[comp].items() <span class=\"keyword\">if</span> <span class=\"built_in\">len</span>(dates) == <span class=\"number\">0</span>]</span><br><span class=\"line\">    <span class=\"keyword\">for</span> k <span class=\"keyword\">in</span> keys_to_remove:</span><br><span class=\"line\">        <span class=\"keyword\">del</span> station_dates[comp][k]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># ===== 输出有效天数统计文本 =====</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> comp <span class=\"keyword\">in</span> components:</span><br><span class=\"line\">    <span class=\"keyword\">with</span> <span class=\"built_in\">open</span>(<span class=\"string\">f&quot;station_day_count_<span class=\"subst\">&#123;comp&#125;</span>.txt&quot;</span>, <span class=\"string\">&quot;w&quot;</span>) <span class=\"keyword\">as</span> f:</span><br><span class=\"line\">        <span class=\"keyword\">for</span> key <span class=\"keyword\">in</span> <span class=\"built_in\">sorted</span>(station_dates[comp].keys()):</span><br><span class=\"line\">            f.write(<span class=\"string\">f&quot;<span class=\"subst\">&#123;key&#125;</span> <span class=\"subst\">&#123;<span class=\"built_in\">len</span>(station_dates[comp][key])&#125;</span>\\n&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># ===== 台网颜色映射 =====</span></span><br><span class=\"line\">all_nets = <span class=\"built_in\">sorted</span>(<span class=\"built_in\">set</span>(net <span class=\"keyword\">for</span> net, sta <span class=\"keyword\">in</span> stations))</span><br><span class=\"line\">net_color_map = &#123;net: cm.get_cmap(<span class=\"string\">&quot;tab20&quot;</span>)(i / <span class=\"built_in\">max</span>(<span class=\"built_in\">len</span>(all_nets)-<span class=\"number\">1</span>,<span class=\"number\">1</span>)) <span class=\"keyword\">for</span> i, net <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(all_nets)&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># ===== 绘图函数 =====</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">plot_component_availability</span>(<span class=\"params\">comp, station_dates_comp</span>):</span><br><span class=\"line\">    valid_stations = <span class=\"built_in\">sorted</span>(station_dates_comp.keys(), key=<span class=\"keyword\">lambda</span> x: (x.split(<span class=\"string\">&quot;.&quot;</span>)[<span class=\"number\">0</span>], x.split(<span class=\"string\">&quot;.&quot;</span>)[<span class=\"number\">1</span>]))</span><br><span class=\"line\">    fig, ax = plt.subplots(figsize=(<span class=\"number\">14</span>, <span class=\"built_in\">max</span>(<span class=\"number\">6</span>, <span class=\"number\">0.3</span> * <span class=\"built_in\">len</span>(valid_stations))))</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">to_datetime</span>(<span class=\"params\">d</span>):</span><br><span class=\"line\">        <span class=\"keyword\">return</span> dt(d.year, d.month, d.day)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">for</span> idx, key <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(valid_stations):</span><br><span class=\"line\">        net = key.split(<span class=\"string\">&quot;.&quot;</span>)[<span class=\"number\">0</span>]</span><br><span class=\"line\">        dates = <span class=\"built_in\">sorted</span>(station_dates_comp[key])</span><br><span class=\"line\">        x_vals = [to_datetime(d) <span class=\"keyword\">for</span> d <span class=\"keyword\">in</span> dates]</span><br><span class=\"line\">        ax.plot(x_vals, [idx]*<span class=\"built_in\">len</span>(dates), <span class=\"string\">&quot;.&quot;</span>, color=net_color_map[net], markersize=<span class=\"number\">2</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    ax.set_xlabel(<span class=\"string\">&quot;时间&quot;</span>)</span><br><span class=\"line\">    ax.set_ylabel(<span class=\"string\">&quot;台站&quot;</span>)</span><br><span class=\"line\">    ax.set_yticks(<span class=\"built_in\">range</span>(<span class=\"built_in\">len</span>(valid_stations)))</span><br><span class=\"line\">    ax.set_yticklabels(valid_stations, fontsize=<span class=\"number\">5</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    ax.grid(<span class=\"literal\">True</span>, linestyle=<span class=\"string\">&quot;:&quot;</span>, alpha=<span class=\"number\">0.5</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    x_start = dt(start_year, <span class=\"number\">1</span>, <span class=\"number\">1</span>)</span><br><span class=\"line\">    x_end = dt(end_year, <span class=\"number\">12</span>, <span class=\"number\">31</span>)</span><br><span class=\"line\">    ax.set_xlim(x_start, x_end)</span><br><span class=\"line\"></span><br><span class=\"line\">    ax.xaxis.set_major_locator(mdates.YearLocator())</span><br><span class=\"line\">    ax.xaxis.set_major_formatter(mdates.DateFormatter(<span class=\"string\">&quot;%Y&quot;</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">    plt.tight_layout(rect=[<span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">0.85</span>, <span class=\"number\">1</span>])</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 右侧外部标注台网名</span></span><br><span class=\"line\">    trans = blended_transform_factory(ax.transAxes, ax.transData)</span><br><span class=\"line\">    net_indices = defaultdict(<span class=\"built_in\">list</span>)</span><br><span class=\"line\">    <span class=\"keyword\">for</span> idx, key <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(valid_stations):</span><br><span class=\"line\">        net = key.split(<span class=\"string\">&quot;.&quot;</span>)[<span class=\"number\">0</span>]</span><br><span class=\"line\">        net_indices[net].append(idx)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">for</span> net, indices <span class=\"keyword\">in</span> net_indices.items():</span><br><span class=\"line\">        mid_idx = indices[<span class=\"built_in\">len</span>(indices)//<span class=\"number\">2</span>]</span><br><span class=\"line\">        color = net_color_map[net]</span><br><span class=\"line\">        ax.text(<span class=\"number\">1.02</span>, mid_idx, net, color=color, fontsize=<span class=\"number\">8</span>, fontweight=<span class=\"string\">&#x27;bold&#x27;</span>,</span><br><span class=\"line\">                verticalalignment=<span class=\"string\">&#x27;center&#x27;</span>, horizontalalignment=<span class=\"string\">&#x27;left&#x27;</span>,</span><br><span class=\"line\">                transform=trans)</span><br><span class=\"line\"></span><br><span class=\"line\">    plt.savefig(<span class=\"string\">f&quot;<span class=\"subst\">&#123;comp&#125;</span>_availability_2013_2022.png&quot;</span>, dpi=<span class=\"number\">300</span>, bbox_inches=<span class=\"string\">&#x27;tight&#x27;</span>)</span><br><span class=\"line\">    plt.close()</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;已保存图像: <span class=\"subst\">&#123;comp&#125;</span>_availability_2013_2022.png&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># ===== 画三分量图 =====</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> comp <span class=\"keyword\">in</span> components:</span><br><span class=\"line\">    plot_component_availability(comp, station_dates[comp])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># ===== 台网统计 =====</span></span><br><span class=\"line\">network_stats = defaultdict(<span class=\"keyword\">lambda</span>: &#123;<span class=\"string\">&quot;total&quot;</span>: <span class=\"number\">0</span>, <span class=\"string\">&quot;valid&quot;</span>: <span class=\"number\">0</span>, <span class=\"string\">&quot;day_counts&quot;</span>: []&#125;)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> net, sta <span class=\"keyword\">in</span> stations:</span><br><span class=\"line\">    network_stats[net][<span class=\"string\">&quot;total&quot;</span>] += <span class=\"number\">1</span></span><br><span class=\"line\"></span><br><span class=\"line\">all_valid_keys = <span class=\"built_in\">set</span>()</span><br><span class=\"line\"><span class=\"keyword\">for</span> comp <span class=\"keyword\">in</span> components:</span><br><span class=\"line\">    all_valid_keys.update(station_dates[comp].keys())</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> key <span class=\"keyword\">in</span> all_valid_keys:</span><br><span class=\"line\">    net = key.split(<span class=\"string\">&quot;.&quot;</span>)[<span class=\"number\">0</span>]</span><br><span class=\"line\">    days_list = [<span class=\"built_in\">len</span>(station_dates[comp].get(key, [])) <span class=\"keyword\">for</span> comp <span class=\"keyword\">in</span> components]</span><br><span class=\"line\">    valid_days = <span class=\"built_in\">max</span>(days_list)</span><br><span class=\"line\">    network_stats[net][<span class=\"string\">&quot;valid&quot;</span>] += <span class=\"number\">1</span></span><br><span class=\"line\">    network_stats[net][<span class=\"string\">&quot;day_counts&quot;</span>].append(valid_days)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&quot;\\n台网统计汇总：&quot;</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">f&quot;<span class=\"subst\">&#123;<span class=\"string\">&#x27;Net&#x27;</span>:&lt;<span class=\"number\">6</span>&#125;</span> <span class=\"subst\">&#123;<span class=\"string\">&#x27;Total&#x27;</span>:&gt;<span class=\"number\">6</span>&#125;</span> <span class=\"subst\">&#123;<span class=\"string\">&#x27;Valid&#x27;</span>:&gt;<span class=\"number\">6</span>&#125;</span> <span class=\"subst\">&#123;<span class=\"string\">&#x27;AvgDays&#x27;</span>:&gt;<span class=\"number\">10</span>&#125;</span>&quot;</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&quot;-&quot;</span> * <span class=\"number\">32</span>)</span><br><span class=\"line\"><span class=\"keyword\">with</span> <span class=\"built_in\">open</span>(<span class=\"string\">&quot;network_summary_all_components.txt&quot;</span>, <span class=\"string\">&quot;w&quot;</span>) <span class=\"keyword\">as</span> f:</span><br><span class=\"line\">    f.write(<span class=\"string\">f&quot;<span class=\"subst\">&#123;<span class=\"string\">&#x27;Net&#x27;</span>:&lt;<span class=\"number\">6</span>&#125;</span> <span class=\"subst\">&#123;<span class=\"string\">&#x27;Total&#x27;</span>:&gt;<span class=\"number\">6</span>&#125;</span> <span class=\"subst\">&#123;<span class=\"string\">&#x27;Valid&#x27;</span>:&gt;<span class=\"number\">6</span>&#125;</span> <span class=\"subst\">&#123;<span class=\"string\">&#x27;AvgDays&#x27;</span>:&gt;<span class=\"number\">10</span>&#125;</span>\\n&quot;</span>)</span><br><span class=\"line\">    <span class=\"keyword\">for</span> net <span class=\"keyword\">in</span> <span class=\"built_in\">sorted</span>(network_stats.keys()):</span><br><span class=\"line\">        total = network_stats[net][<span class=\"string\">&quot;total&quot;</span>]</span><br><span class=\"line\">        valid = network_stats[net][<span class=\"string\">&quot;valid&quot;</span>]</span><br><span class=\"line\">        avg_days = np.mean(network_stats[net][<span class=\"string\">&quot;day_counts&quot;</span>]) <span class=\"keyword\">if</span> network_stats[net][<span class=\"string\">&quot;day_counts&quot;</span>] <span class=\"keyword\">else</span> <span class=\"number\">0</span></span><br><span class=\"line\">        line = <span class=\"string\">f&quot;<span class=\"subst\">&#123;net:&lt;<span class=\"number\">6</span>&#125;</span> <span class=\"subst\">&#123;total:&gt;<span class=\"number\">6</span>&#125;</span> <span class=\"subst\">&#123;valid:&gt;<span class=\"number\">6</span>&#125;</span> <span class=\"subst\">&#123;avg_days:&gt;<span class=\"number\">10.1</span>f&#125;</span>&quot;</span></span><br><span class=\"line\">        <span class=\"built_in\">print</span>(line)</span><br><span class=\"line\">        f.write(line + <span class=\"string\">&quot;\\n&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># ===== 总结 =====</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">f&quot;\\n文件总数: <span class=\"subst\">&#123;total_files&#125;</span>&quot;</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">f&quot;文件总大小: <span class=\"subst\">&#123;total_file_size/(<span class=\"number\">1024</span>**<span class=\"number\">2</span>):<span class=\"number\">.2</span>f&#125;</span> MB (<span class=\"subst\">&#123;total_file_size/(<span class=\"number\">1024</span>**<span class=\"number\">3</span>):<span class=\"number\">.2</span>f&#125;</span> GB)&quot;</span>)</span><br></pre></td></tr></table></figure>\n<p>&emsp;&emsp;这个脚本实现的功能包括：</p>\n<ul>\n<li>统计开始时间start_year到结束时间end_year的数据下载情况</li>\n<li>对LHZ、LHN和LHE分别进行统计。</li>\n<li>对统计结果进行可视化输出。</li>\n<li>横轴是时间，纵轴是台站名。不同台网用不同颜色标出。在图右侧标出台网名。</li>\n<li>输出文件network_summary_all_components.txt，给出台网包含台站数目，有效台站数目和各自平均天数。</li>\n<li>输出文件station_day_count_{comp}.txt，给出台站名和有效天数。</li>\n<li>输出文件总数，文件总大小。</li>\n</ul>\n","related_posts":["how-to-add-frame.html","add_counter.html","download-continuous-seis.html"],"length":6241,"excerpt":"","more":"<p>&emsp;&emsp;数据下载好后需要统计下载的情况，这是python脚本。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br><span class=\"line\">145</span><br><span class=\"line\">146</span><br><span class=\"line\">147</span><br><span class=\"line\">148</span><br><span class=\"line\">149</span><br><span class=\"line\">150</span><br><span class=\"line\">151</span><br><span class=\"line\">152</span><br><span class=\"line\">153</span><br><span class=\"line\">154</span><br><span class=\"line\">155</span><br><span class=\"line\">156</span><br><span class=\"line\">157</span><br><span class=\"line\">158</span><br><span class=\"line\">159</span><br><span class=\"line\">160</span><br><span class=\"line\">161</span><br><span class=\"line\">162</span><br><span class=\"line\">163</span><br><span class=\"line\">164</span><br><span class=\"line\">165</span><br><span class=\"line\">166</span><br><span class=\"line\">167</span><br><span class=\"line\">168</span><br><span class=\"line\">169</span><br><span class=\"line\">170</span><br><span class=\"line\">171</span><br><span class=\"line\">172</span><br><span class=\"line\">173</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\"><span class=\"keyword\">from</span> obspy <span class=\"keyword\">import</span> read</span><br><span class=\"line\"><span class=\"keyword\">from</span> datetime <span class=\"keyword\">import</span> datetime <span class=\"keyword\">as</span> dt</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.cm <span class=\"keyword\">as</span> cm</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.dates <span class=\"keyword\">as</span> mdates</span><br><span class=\"line\"><span class=\"keyword\">from</span> collections <span class=\"keyword\">import</span> defaultdict</span><br><span class=\"line\"><span class=\"keyword\">from</span> matplotlib.transforms <span class=\"keyword\">import</span> blended_transform_factory</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># ===== 配置 =====</span></span><br><span class=\"line\">data_dir = <span class=\"string\">&quot;daily_waveforms&quot;</span>  <span class=\"comment\"># 存放YYYYMMDD.mseed文件目录</span></span><br><span class=\"line\">station_file = <span class=\"string\">&quot;station.list&quot;</span>  <span class=\"comment\"># 台站列表，格式：NET STA（两列）</span></span><br><span class=\"line\">components = [<span class=\"string\">&quot;LHZ&quot;</span>, <span class=\"string\">&quot;LHN&quot;</span>, <span class=\"string\">&quot;LHE&quot;</span>]</span><br><span class=\"line\">start_year = <span class=\"number\">2020</span></span><br><span class=\"line\">end_year = <span class=\"number\">2020</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># ===== 读取台站列表 =====</span></span><br><span class=\"line\">stations = []</span><br><span class=\"line\"><span class=\"keyword\">with</span> <span class=\"built_in\">open</span>(station_file, <span class=\"string\">&quot;r&quot;</span>) <span class=\"keyword\">as</span> f:</span><br><span class=\"line\">    <span class=\"keyword\">for</span> line <span class=\"keyword\">in</span> f:</span><br><span class=\"line\">        <span class=\"keyword\">if</span> line.strip():</span><br><span class=\"line\">            net, sta = line.strip().split()[:<span class=\"number\">2</span>]</span><br><span class=\"line\">            stations.append((net, sta))</span><br><span class=\"line\"></span><br><span class=\"line\">station_set = <span class=\"built_in\">set</span>(<span class=\"string\">f&quot;<span class=\"subst\">&#123;net&#125;</span>.<span class=\"subst\">&#123;sta&#125;</span>&quot;</span> <span class=\"keyword\">for</span> net, sta <span class=\"keyword\">in</span> stations)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># ===== 初始化 =====</span></span><br><span class=\"line\">station_dates = &#123;comp: defaultdict(<span class=\"built_in\">set</span>) <span class=\"keyword\">for</span> comp <span class=\"keyword\">in</span> components&#125;  <span class=\"comment\"># comp -&gt; &#123;net.sta -&gt; set(date)&#125;</span></span><br><span class=\"line\">station_file_sizes = defaultdict(<span class=\"built_in\">int</span>)  <span class=\"comment\"># 台站对应所有文件大小</span></span><br><span class=\"line\">total_files = <span class=\"number\">0</span></span><br><span class=\"line\">total_file_size = <span class=\"number\">0</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># ===== 遍历所有mseed文件 =====</span></span><br><span class=\"line\">all_files = <span class=\"built_in\">sorted</span>(f <span class=\"keyword\">for</span> f <span class=\"keyword\">in</span> os.listdir(data_dir) <span class=\"keyword\">if</span> f.endswith(<span class=\"string\">&quot;.mseed&quot;</span>))</span><br><span class=\"line\"><span class=\"keyword\">for</span> filename <span class=\"keyword\">in</span> all_files:</span><br><span class=\"line\">    filepath = os.path.join(data_dir, filename)</span><br><span class=\"line\"></span><br><span class=\"line\">    size = os.path.getsize(filepath)</span><br><span class=\"line\">    total_files += <span class=\"number\">1</span></span><br><span class=\"line\">    total_file_size += size</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">try</span>:</span><br><span class=\"line\">        st = read(filepath)</span><br><span class=\"line\">    <span class=\"keyword\">except</span> Exception <span class=\"keyword\">as</span> e:</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;读取文件失败 <span class=\"subst\">&#123;filename&#125;</span>: <span class=\"subst\">&#123;e&#125;</span>&quot;</span>)</span><br><span class=\"line\">        <span class=\"keyword\">continue</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 解析文件日期 YYYYMMDD</span></span><br><span class=\"line\">    <span class=\"keyword\">try</span>:</span><br><span class=\"line\">        file_date = dt.strptime(filename[:<span class=\"number\">8</span>], <span class=\"string\">&quot;%Y%m%d&quot;</span>).date()</span><br><span class=\"line\">    <span class=\"keyword\">except</span> Exception <span class=\"keyword\">as</span> e:</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;无法解析日期 <span class=\"subst\">&#123;filename&#125;</span>: <span class=\"subst\">&#123;e&#125;</span>&quot;</span>)</span><br><span class=\"line\">        <span class=\"keyword\">continue</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">for</span> tr <span class=\"keyword\">in</span> st:</span><br><span class=\"line\">        net = tr.stats.network</span><br><span class=\"line\">        sta = tr.stats.station</span><br><span class=\"line\">        comp = tr.stats.channel[-<span class=\"number\">3</span>:]</span><br><span class=\"line\"></span><br><span class=\"line\">        key = <span class=\"string\">f&quot;<span class=\"subst\">&#123;net&#125;</span>.<span class=\"subst\">&#123;sta&#125;</span>&quot;</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> key <span class=\"keyword\">not</span> <span class=\"keyword\">in</span> station_set:</span><br><span class=\"line\">            <span class=\"keyword\">continue</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> comp <span class=\"keyword\">not</span> <span class=\"keyword\">in</span> components:</span><br><span class=\"line\">            <span class=\"keyword\">continue</span></span><br><span class=\"line\"></span><br><span class=\"line\">        station_dates[comp][key].add(file_date)</span><br><span class=\"line\">        station_file_sizes[key] += size</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">f&quot;共计读取文件数: <span class=\"subst\">&#123;total_files&#125;</span>&quot;</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">f&quot;所有文件总大小: <span class=\"subst\">&#123;total_file_size / (<span class=\"number\">1024</span>**<span class=\"number\">2</span>):<span class=\"number\">.2</span>f&#125;</span> MB&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># ===== 删除无有效数据台站 =====</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> comp <span class=\"keyword\">in</span> components:</span><br><span class=\"line\">    keys_to_remove = [k <span class=\"keyword\">for</span> k, dates <span class=\"keyword\">in</span> station_dates[comp].items() <span class=\"keyword\">if</span> <span class=\"built_in\">len</span>(dates) == <span class=\"number\">0</span>]</span><br><span class=\"line\">    <span class=\"keyword\">for</span> k <span class=\"keyword\">in</span> keys_to_remove:</span><br><span class=\"line\">        <span class=\"keyword\">del</span> station_dates[comp][k]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># ===== 输出有效天数统计文本 =====</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> comp <span class=\"keyword\">in</span> components:</span><br><span class=\"line\">    <span class=\"keyword\">with</span> <span class=\"built_in\">open</span>(<span class=\"string\">f&quot;station_day_count_<span class=\"subst\">&#123;comp&#125;</span>.txt&quot;</span>, <span class=\"string\">&quot;w&quot;</span>) <span class=\"keyword\">as</span> f:</span><br><span class=\"line\">        <span class=\"keyword\">for</span> key <span class=\"keyword\">in</span> <span class=\"built_in\">sorted</span>(station_dates[comp].keys()):</span><br><span class=\"line\">            f.write(<span class=\"string\">f&quot;<span class=\"subst\">&#123;key&#125;</span> <span class=\"subst\">&#123;<span class=\"built_in\">len</span>(station_dates[comp][key])&#125;</span>\\n&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># ===== 台网颜色映射 =====</span></span><br><span class=\"line\">all_nets = <span class=\"built_in\">sorted</span>(<span class=\"built_in\">set</span>(net <span class=\"keyword\">for</span> net, sta <span class=\"keyword\">in</span> stations))</span><br><span class=\"line\">net_color_map = &#123;net: cm.get_cmap(<span class=\"string\">&quot;tab20&quot;</span>)(i / <span class=\"built_in\">max</span>(<span class=\"built_in\">len</span>(all_nets)-<span class=\"number\">1</span>,<span class=\"number\">1</span>)) <span class=\"keyword\">for</span> i, net <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(all_nets)&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># ===== 绘图函数 =====</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">plot_component_availability</span>(<span class=\"params\">comp, station_dates_comp</span>):</span><br><span class=\"line\">    valid_stations = <span class=\"built_in\">sorted</span>(station_dates_comp.keys(), key=<span class=\"keyword\">lambda</span> x: (x.split(<span class=\"string\">&quot;.&quot;</span>)[<span class=\"number\">0</span>], x.split(<span class=\"string\">&quot;.&quot;</span>)[<span class=\"number\">1</span>]))</span><br><span class=\"line\">    fig, ax = plt.subplots(figsize=(<span class=\"number\">14</span>, <span class=\"built_in\">max</span>(<span class=\"number\">6</span>, <span class=\"number\">0.3</span> * <span class=\"built_in\">len</span>(valid_stations))))</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">to_datetime</span>(<span class=\"params\">d</span>):</span><br><span class=\"line\">        <span class=\"keyword\">return</span> dt(d.year, d.month, d.day)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">for</span> idx, key <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(valid_stations):</span><br><span class=\"line\">        net = key.split(<span class=\"string\">&quot;.&quot;</span>)[<span class=\"number\">0</span>]</span><br><span class=\"line\">        dates = <span class=\"built_in\">sorted</span>(station_dates_comp[key])</span><br><span class=\"line\">        x_vals = [to_datetime(d) <span class=\"keyword\">for</span> d <span class=\"keyword\">in</span> dates]</span><br><span class=\"line\">        ax.plot(x_vals, [idx]*<span class=\"built_in\">len</span>(dates), <span class=\"string\">&quot;.&quot;</span>, color=net_color_map[net], markersize=<span class=\"number\">2</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    ax.set_xlabel(<span class=\"string\">&quot;时间&quot;</span>)</span><br><span class=\"line\">    ax.set_ylabel(<span class=\"string\">&quot;台站&quot;</span>)</span><br><span class=\"line\">    ax.set_yticks(<span class=\"built_in\">range</span>(<span class=\"built_in\">len</span>(valid_stations)))</span><br><span class=\"line\">    ax.set_yticklabels(valid_stations, fontsize=<span class=\"number\">5</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    ax.grid(<span class=\"literal\">True</span>, linestyle=<span class=\"string\">&quot;:&quot;</span>, alpha=<span class=\"number\">0.5</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    x_start = dt(start_year, <span class=\"number\">1</span>, <span class=\"number\">1</span>)</span><br><span class=\"line\">    x_end = dt(end_year, <span class=\"number\">12</span>, <span class=\"number\">31</span>)</span><br><span class=\"line\">    ax.set_xlim(x_start, x_end)</span><br><span class=\"line\"></span><br><span class=\"line\">    ax.xaxis.set_major_locator(mdates.YearLocator())</span><br><span class=\"line\">    ax.xaxis.set_major_formatter(mdates.DateFormatter(<span class=\"string\">&quot;%Y&quot;</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">    plt.tight_layout(rect=[<span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">0.85</span>, <span class=\"number\">1</span>])</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 右侧外部标注台网名</span></span><br><span class=\"line\">    trans = blended_transform_factory(ax.transAxes, ax.transData)</span><br><span class=\"line\">    net_indices = defaultdict(<span class=\"built_in\">list</span>)</span><br><span class=\"line\">    <span class=\"keyword\">for</span> idx, key <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(valid_stations):</span><br><span class=\"line\">        net = key.split(<span class=\"string\">&quot;.&quot;</span>)[<span class=\"number\">0</span>]</span><br><span class=\"line\">        net_indices[net].append(idx)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">for</span> net, indices <span class=\"keyword\">in</span> net_indices.items():</span><br><span class=\"line\">        mid_idx = indices[<span class=\"built_in\">len</span>(indices)//<span class=\"number\">2</span>]</span><br><span class=\"line\">        color = net_color_map[net]</span><br><span class=\"line\">        ax.text(<span class=\"number\">1.02</span>, mid_idx, net, color=color, fontsize=<span class=\"number\">8</span>, fontweight=<span class=\"string\">&#x27;bold&#x27;</span>,</span><br><span class=\"line\">                verticalalignment=<span class=\"string\">&#x27;center&#x27;</span>, horizontalalignment=<span class=\"string\">&#x27;left&#x27;</span>,</span><br><span class=\"line\">                transform=trans)</span><br><span class=\"line\"></span><br><span class=\"line\">    plt.savefig(<span class=\"string\">f&quot;<span class=\"subst\">&#123;comp&#125;</span>_availability_2013_2022.png&quot;</span>, dpi=<span class=\"number\">300</span>, bbox_inches=<span class=\"string\">&#x27;tight&#x27;</span>)</span><br><span class=\"line\">    plt.close()</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;已保存图像: <span class=\"subst\">&#123;comp&#125;</span>_availability_2013_2022.png&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># ===== 画三分量图 =====</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> comp <span class=\"keyword\">in</span> components:</span><br><span class=\"line\">    plot_component_availability(comp, station_dates[comp])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># ===== 台网统计 =====</span></span><br><span class=\"line\">network_stats = defaultdict(<span class=\"keyword\">lambda</span>: &#123;<span class=\"string\">&quot;total&quot;</span>: <span class=\"number\">0</span>, <span class=\"string\">&quot;valid&quot;</span>: <span class=\"number\">0</span>, <span class=\"string\">&quot;day_counts&quot;</span>: []&#125;)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> net, sta <span class=\"keyword\">in</span> stations:</span><br><span class=\"line\">    network_stats[net][<span class=\"string\">&quot;total&quot;</span>] += <span class=\"number\">1</span></span><br><span class=\"line\"></span><br><span class=\"line\">all_valid_keys = <span class=\"built_in\">set</span>()</span><br><span class=\"line\"><span class=\"keyword\">for</span> comp <span class=\"keyword\">in</span> components:</span><br><span class=\"line\">    all_valid_keys.update(station_dates[comp].keys())</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> key <span class=\"keyword\">in</span> all_valid_keys:</span><br><span class=\"line\">    net = key.split(<span class=\"string\">&quot;.&quot;</span>)[<span class=\"number\">0</span>]</span><br><span class=\"line\">    days_list = [<span class=\"built_in\">len</span>(station_dates[comp].get(key, [])) <span class=\"keyword\">for</span> comp <span class=\"keyword\">in</span> components]</span><br><span class=\"line\">    valid_days = <span class=\"built_in\">max</span>(days_list)</span><br><span class=\"line\">    network_stats[net][<span class=\"string\">&quot;valid&quot;</span>] += <span class=\"number\">1</span></span><br><span class=\"line\">    network_stats[net][<span class=\"string\">&quot;day_counts&quot;</span>].append(valid_days)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&quot;\\n台网统计汇总：&quot;</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">f&quot;<span class=\"subst\">&#123;<span class=\"string\">&#x27;Net&#x27;</span>:&lt;<span class=\"number\">6</span>&#125;</span> <span class=\"subst\">&#123;<span class=\"string\">&#x27;Total&#x27;</span>:&gt;<span class=\"number\">6</span>&#125;</span> <span class=\"subst\">&#123;<span class=\"string\">&#x27;Valid&#x27;</span>:&gt;<span class=\"number\">6</span>&#125;</span> <span class=\"subst\">&#123;<span class=\"string\">&#x27;AvgDays&#x27;</span>:&gt;<span class=\"number\">10</span>&#125;</span>&quot;</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&quot;-&quot;</span> * <span class=\"number\">32</span>)</span><br><span class=\"line\"><span class=\"keyword\">with</span> <span class=\"built_in\">open</span>(<span class=\"string\">&quot;network_summary_all_components.txt&quot;</span>, <span class=\"string\">&quot;w&quot;</span>) <span class=\"keyword\">as</span> f:</span><br><span class=\"line\">    f.write(<span class=\"string\">f&quot;<span class=\"subst\">&#123;<span class=\"string\">&#x27;Net&#x27;</span>:&lt;<span class=\"number\">6</span>&#125;</span> <span class=\"subst\">&#123;<span class=\"string\">&#x27;Total&#x27;</span>:&gt;<span class=\"number\">6</span>&#125;</span> <span class=\"subst\">&#123;<span class=\"string\">&#x27;Valid&#x27;</span>:&gt;<span class=\"number\">6</span>&#125;</span> <span class=\"subst\">&#123;<span class=\"string\">&#x27;AvgDays&#x27;</span>:&gt;<span class=\"number\">10</span>&#125;</span>\\n&quot;</span>)</span><br><span class=\"line\">    <span class=\"keyword\">for</span> net <span class=\"keyword\">in</span> <span class=\"built_in\">sorted</span>(network_stats.keys()):</span><br><span class=\"line\">        total = network_stats[net][<span class=\"string\">&quot;total&quot;</span>]</span><br><span class=\"line\">        valid = network_stats[net][<span class=\"string\">&quot;valid&quot;</span>]</span><br><span class=\"line\">        avg_days = np.mean(network_stats[net][<span class=\"string\">&quot;day_counts&quot;</span>]) <span class=\"keyword\">if</span> network_stats[net][<span class=\"string\">&quot;day_counts&quot;</span>] <span class=\"keyword\">else</span> <span class=\"number\">0</span></span><br><span class=\"line\">        line = <span class=\"string\">f&quot;<span class=\"subst\">&#123;net:&lt;<span class=\"number\">6</span>&#125;</span> <span class=\"subst\">&#123;total:&gt;<span class=\"number\">6</span>&#125;</span> <span class=\"subst\">&#123;valid:&gt;<span class=\"number\">6</span>&#125;</span> <span class=\"subst\">&#123;avg_days:&gt;<span class=\"number\">10.1</span>f&#125;</span>&quot;</span></span><br><span class=\"line\">        <span class=\"built_in\">print</span>(line)</span><br><span class=\"line\">        f.write(line + <span class=\"string\">&quot;\\n&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># ===== 总结 =====</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">f&quot;\\n文件总数: <span class=\"subst\">&#123;total_files&#125;</span>&quot;</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">f&quot;文件总大小: <span class=\"subst\">&#123;total_file_size/(<span class=\"number\">1024</span>**<span class=\"number\">2</span>):<span class=\"number\">.2</span>f&#125;</span> MB (<span class=\"subst\">&#123;total_file_size/(<span class=\"number\">1024</span>**<span class=\"number\">3</span>):<span class=\"number\">.2</span>f&#125;</span> GB)&quot;</span>)</span><br></pre></td></tr></table></figure>\n<p>&emsp;&emsp;这个脚本实现的功能包括：</p>\n<ul>\n<li>统计开始时间start_year到结束时间end_year的数据下载情况</li>\n<li>对LHZ、LHN和LHE分别进行统计。</li>\n<li>对统计结果进行可视化输出。</li>\n<li>横轴是时间，纵轴是台站名。不同台网用不同颜色标出。在图右侧标出台网名。</li>\n<li>输出文件network_summary_all_components.txt，给出台网包含台站数目，有效台站数目和各自平均天数。</li>\n<li>输出文件station_day_count_{comp}.txt，给出台站名和有效天数。</li>\n<li>输出文件总数，文件总大小。</li>\n</ul>\n"},{"title":"urllib3的问题","abbrlink":"4cf90829","date":"2025-06-08T06:12:26.000Z","_content":"&emsp;&emsp;安装了seisman的[HinetPy](https://github.com/seisman/HinetPy)，运行脚本数据下载脚本的时候就遇到这个问题：\n```\nfrom HinetPy import Client, win32\n  File \"/home/junxie/work/Snet/HinetPy-main/HinetPy/__init__.py\", line 23, in <module>\n    from .client import Client\n  File \"/home/junxie/work/Snet/HinetPy-main/HinetPy/client.py\", line 22, in <module>\n    from urllib3.util import create_urllib3_context\nImportError: cannot import name 'create_urllib3_context' from 'urllib3.util' (/home/junxie/.conda/envs/py3/lib/python3.9/site-packages/urllib3/util/__init__.py)\n```\n怎么整？\n<!--less-->\n&emsp;&emsp;遇到问题不要歪，凡事都来找AI。\n&emsp;&emsp;于是我把问题贴给了chatGPT，它说：\n   * 方法1 给urllib3降级，降到1.26.x，可我的就是1.26.16，pass\n   * 方法2 更新HinetPy到最新版本，可人家都就是最新版本啊，pass\n   * 方法3 手动patch，具体是将client.py中的\n```\nfrom urllib3.util import create_urllib3_context\n```\n&emsp;&emsp;替换为\n```\nfrom ssl import create_default_context as create_urllib3_context\n```\n&emsp;&emsp;看起来挺靠谱的。于是出现了这个问题\n```\n  File \"/home/junxie/work/Snet/HinetPy-main/HinetPy/client.py\", line 139, in __init__\n    self.login(user, password)\n  File \"/home/junxie/work/Snet/HinetPy-main/HinetPy/client.py\", line 188, in login\n    self.session.mount(self._HINET, AddedCipherAdapter())\n  File \"/home/junxie/.conda/envs/py3/lib/python3.9/site-packages/requests/adapters.py\", line 155, in __init__\n    self.init_poolmanager(pool_connections, pool_maxsize, block=pool_block)\n  File \"/home/junxie/work/Snet/HinetPy-main/HinetPy/client.py\", line 47, in init_poolmanager\n    ctx = create_urllib3_context(ciphers=\":HIGH:!DH:!aNULL\")\nTypeError: create_default_context() got an unexpected keyword argument 'ciphers'\n```\n&emsp;&emsp;然后，各种折腾一翻，删除，重装还是不行，看看模块create_urllib3_context\n```\ngrep create_urllib3_context /home/junxie/.conda/envs/py3/lib/python3.9/site-packages/urllib3/util/*.py\n```\n&emsp;&emsp;长这样：\n```\n/home/junxie/.conda/envs/py3/lib/python3.9/site-packages/urllib3/util/proxy.py:from .ssl_ import create_urllib3_context, resolve_cert_reqs, resolve_ssl_version\n/home/junxie/.conda/envs/py3/lib/python3.9/site-packages/urllib3/util/proxy.py:    ssl_context = create_urllib3_context(\n/home/junxie/.conda/envs/py3/lib/python3.9/site-packages/urllib3/util/ssl_.py:def create_urllib3_context(\n/home/junxie/.conda/envs/py3/lib/python3.9/site-packages/urllib3/util/ssl_.py:        context = ssl_.create_urllib3_context()\n/home/junxie/.conda/envs/py3/lib/python3.9/site-packages/urllib3/util/ssl_.py:        be created using :func:create_urllib3_context.\n/home/junxie/.conda/envs/py3/lib/python3.9/site-packages/urllib3/util/ssl_.py:        context = create_urllib3_context(ssl_version, cert_reqs, ciphers=ciphers)\n```\n&emsp;&emsp;表明urllib3安装是正确的。所以在client.py中，将这一句：\n```\nfrom urllib3.util import create_urllib3_context\n```\n&emsp;&emsp;改为：\n```\nfrom urllib3.util.ssl_ import create_urllib3_context\n```\n&emsp;&emsp;然后就万事大吉了。总结：不懂就问AI吧，但不好好学习和思考，到头来还是不懂。然而这又有什么关系，只要有AI在，会问AI问题就行了。没AI的话，那就拜拜了。\n","source":"_posts/2025-06-08-problem-of-urllib3.md","raw":"---\ntitle: urllib3的问题\ntags:\n  - python\ncategories:\n  - work\nabbrlink: 4cf90829\ndate: 2025-06-08 14:12:26\n---\n&emsp;&emsp;安装了seisman的[HinetPy](https://github.com/seisman/HinetPy)，运行脚本数据下载脚本的时候就遇到这个问题：\n```\nfrom HinetPy import Client, win32\n  File \"/home/junxie/work/Snet/HinetPy-main/HinetPy/__init__.py\", line 23, in <module>\n    from .client import Client\n  File \"/home/junxie/work/Snet/HinetPy-main/HinetPy/client.py\", line 22, in <module>\n    from urllib3.util import create_urllib3_context\nImportError: cannot import name 'create_urllib3_context' from 'urllib3.util' (/home/junxie/.conda/envs/py3/lib/python3.9/site-packages/urllib3/util/__init__.py)\n```\n怎么整？\n<!--less-->\n&emsp;&emsp;遇到问题不要歪，凡事都来找AI。\n&emsp;&emsp;于是我把问题贴给了chatGPT，它说：\n   * 方法1 给urllib3降级，降到1.26.x，可我的就是1.26.16，pass\n   * 方法2 更新HinetPy到最新版本，可人家都就是最新版本啊，pass\n   * 方法3 手动patch，具体是将client.py中的\n```\nfrom urllib3.util import create_urllib3_context\n```\n&emsp;&emsp;替换为\n```\nfrom ssl import create_default_context as create_urllib3_context\n```\n&emsp;&emsp;看起来挺靠谱的。于是出现了这个问题\n```\n  File \"/home/junxie/work/Snet/HinetPy-main/HinetPy/client.py\", line 139, in __init__\n    self.login(user, password)\n  File \"/home/junxie/work/Snet/HinetPy-main/HinetPy/client.py\", line 188, in login\n    self.session.mount(self._HINET, AddedCipherAdapter())\n  File \"/home/junxie/.conda/envs/py3/lib/python3.9/site-packages/requests/adapters.py\", line 155, in __init__\n    self.init_poolmanager(pool_connections, pool_maxsize, block=pool_block)\n  File \"/home/junxie/work/Snet/HinetPy-main/HinetPy/client.py\", line 47, in init_poolmanager\n    ctx = create_urllib3_context(ciphers=\":HIGH:!DH:!aNULL\")\nTypeError: create_default_context() got an unexpected keyword argument 'ciphers'\n```\n&emsp;&emsp;然后，各种折腾一翻，删除，重装还是不行，看看模块create_urllib3_context\n```\ngrep create_urllib3_context /home/junxie/.conda/envs/py3/lib/python3.9/site-packages/urllib3/util/*.py\n```\n&emsp;&emsp;长这样：\n```\n/home/junxie/.conda/envs/py3/lib/python3.9/site-packages/urllib3/util/proxy.py:from .ssl_ import create_urllib3_context, resolve_cert_reqs, resolve_ssl_version\n/home/junxie/.conda/envs/py3/lib/python3.9/site-packages/urllib3/util/proxy.py:    ssl_context = create_urllib3_context(\n/home/junxie/.conda/envs/py3/lib/python3.9/site-packages/urllib3/util/ssl_.py:def create_urllib3_context(\n/home/junxie/.conda/envs/py3/lib/python3.9/site-packages/urllib3/util/ssl_.py:        context = ssl_.create_urllib3_context()\n/home/junxie/.conda/envs/py3/lib/python3.9/site-packages/urllib3/util/ssl_.py:        be created using :func:create_urllib3_context.\n/home/junxie/.conda/envs/py3/lib/python3.9/site-packages/urllib3/util/ssl_.py:        context = create_urllib3_context(ssl_version, cert_reqs, ciphers=ciphers)\n```\n&emsp;&emsp;表明urllib3安装是正确的。所以在client.py中，将这一句：\n```\nfrom urllib3.util import create_urllib3_context\n```\n&emsp;&emsp;改为：\n```\nfrom urllib3.util.ssl_ import create_urllib3_context\n```\n&emsp;&emsp;然后就万事大吉了。总结：不懂就问AI吧，但不好好学习和思考，到头来还是不懂。然而这又有什么关系，只要有AI在，会问AI问题就行了。没AI的话，那就拜拜了。\n","slug":"problem-of-urllib3","published":1,"updated":"2025-06-08T06:29:45.887Z","comments":1,"layout":"post","photos":[],"_id":"cmh498iqh00cvwvou3hrt4mm4","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>&emsp;&emsp;遇到问题不要歪，凡事都来找AI。<br>&emsp;&emsp;于是我把问题贴给了chatGPT，它说：</p>\n<ul>\n<li>方法1 给urllib3降级，降到1.26.x，可我的就是1.26.16，pass</li>\n<li>方法2 更新HinetPy到最新版本，可人家都就是最新版本啊，pass</li>\n<li>方法3 手动patch，具体是将client.py中的<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">from urllib3.util import create_urllib3_context</span><br></pre></td></tr></table></figure>\n&emsp;&emsp;替换为<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">from ssl import create_default_context as create_urllib3_context</span><br></pre></td></tr></table></figure>\n&emsp;&emsp;看起来挺靠谱的。于是出现了这个问题<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">  File &quot;/home/junxie/work/Snet/HinetPy-main/HinetPy/client.py&quot;, line 139, in __init__</span><br><span class=\"line\">    self.login(user, password)</span><br><span class=\"line\">  File &quot;/home/junxie/work/Snet/HinetPy-main/HinetPy/client.py&quot;, line 188, in login</span><br><span class=\"line\">    self.session.mount(self._HINET, AddedCipherAdapter())</span><br><span class=\"line\">  File &quot;/home/junxie/.conda/envs/py3/lib/python3.9/site-packages/requests/adapters.py&quot;, line 155, in __init__</span><br><span class=\"line\">    self.init_poolmanager(pool_connections, pool_maxsize, block=pool_block)</span><br><span class=\"line\">  File &quot;/home/junxie/work/Snet/HinetPy-main/HinetPy/client.py&quot;, line 47, in init_poolmanager</span><br><span class=\"line\">    ctx = create_urllib3_context(ciphers=&quot;:HIGH:!DH:!aNULL&quot;)</span><br><span class=\"line\">TypeError: create_default_context() got an unexpected keyword argument &#x27;ciphers&#x27;</span><br></pre></td></tr></table></figure>\n&emsp;&emsp;然后，各种折腾一翻，删除，重装还是不行，看看模块create_urllib3_context<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">grep create_urllib3_context /home/junxie/.conda/envs/py3/lib/python3.9/site-packages/urllib3/util/*.py</span><br></pre></td></tr></table></figure>\n&emsp;&emsp;长这样：<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">/home/junxie/.conda/envs/py3/lib/python3.9/site-packages/urllib3/util/proxy.py:from .ssl_ import create_urllib3_context, resolve_cert_reqs, resolve_ssl_version</span><br><span class=\"line\">/home/junxie/.conda/envs/py3/lib/python3.9/site-packages/urllib3/util/proxy.py:    ssl_context = create_urllib3_context(</span><br><span class=\"line\">/home/junxie/.conda/envs/py3/lib/python3.9/site-packages/urllib3/util/ssl_.py:def create_urllib3_context(</span><br><span class=\"line\">/home/junxie/.conda/envs/py3/lib/python3.9/site-packages/urllib3/util/ssl_.py:        context = ssl_.create_urllib3_context()</span><br><span class=\"line\">/home/junxie/.conda/envs/py3/lib/python3.9/site-packages/urllib3/util/ssl_.py:        be created using :func:create_urllib3_context.</span><br><span class=\"line\">/home/junxie/.conda/envs/py3/lib/python3.9/site-packages/urllib3/util/ssl_.py:        context = create_urllib3_context(ssl_version, cert_reqs, ciphers=ciphers)</span><br></pre></td></tr></table></figure>\n&emsp;&emsp;表明urllib3安装是正确的。所以在client.py中，将这一句：<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">from urllib3.util import create_urllib3_context</span><br></pre></td></tr></table></figure>\n&emsp;&emsp;改为：<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">from urllib3.util.ssl_ import create_urllib3_context</span><br></pre></td></tr></table></figure>\n&emsp;&emsp;然后就万事大吉了。总结：不懂就问AI吧，但不好好学习和思考，到头来还是不懂。然而这又有什么关系，只要有AI在，会问AI问题就行了。没AI的话，那就拜拜了。</li>\n</ul>","related_posts":["how-to-download-Snet-data.html"],"length":2692,"excerpt":"<p>&emsp;&emsp;安装了seisman的<a href=\"https://github.com/seisman/HinetPy\">HinetPy</a>，运行脚本数据下载脚本的时候就遇到这个问题：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">from HinetPy import Client, win32</span><br><span class=\"line\">  File &quot;/home/junxie/work/Snet/HinetPy-main/HinetPy/__init__.py&quot;, line 23, in &lt;module&gt;</span><br><span class=\"line\">    from .client import Client</span><br><span class=\"line\">  File &quot;/home/junxie/work/Snet/HinetPy-main/HinetPy/client.py&quot;, line 22, in &lt;module&gt;</span><br><span class=\"line\">    from urllib3.util import create_urllib3_context</span><br><span class=\"line\">ImportError: cannot import name &#x27;create_urllib3_context&#x27; from &#x27;urllib3.util&#x27; (/home/junxie/.conda/envs/py3/lib/python3.9/site-packages/urllib3/util/__init__.py)</span><br></pre></td></tr></table></figure>\n<p>怎么整？</p>","more":"<p>&emsp;&emsp;遇到问题不要歪，凡事都来找AI。<br>&emsp;&emsp;于是我把问题贴给了chatGPT，它说：</p>\n<ul>\n<li>方法1 给urllib3降级，降到1.26.x，可我的就是1.26.16，pass</li>\n<li>方法2 更新HinetPy到最新版本，可人家都就是最新版本啊，pass</li>\n<li>方法3 手动patch，具体是将client.py中的<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">from urllib3.util import create_urllib3_context</span><br></pre></td></tr></table></figure>\n&emsp;&emsp;替换为<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">from ssl import create_default_context as create_urllib3_context</span><br></pre></td></tr></table></figure>\n&emsp;&emsp;看起来挺靠谱的。于是出现了这个问题<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">  File &quot;/home/junxie/work/Snet/HinetPy-main/HinetPy/client.py&quot;, line 139, in __init__</span><br><span class=\"line\">    self.login(user, password)</span><br><span class=\"line\">  File &quot;/home/junxie/work/Snet/HinetPy-main/HinetPy/client.py&quot;, line 188, in login</span><br><span class=\"line\">    self.session.mount(self._HINET, AddedCipherAdapter())</span><br><span class=\"line\">  File &quot;/home/junxie/.conda/envs/py3/lib/python3.9/site-packages/requests/adapters.py&quot;, line 155, in __init__</span><br><span class=\"line\">    self.init_poolmanager(pool_connections, pool_maxsize, block=pool_block)</span><br><span class=\"line\">  File &quot;/home/junxie/work/Snet/HinetPy-main/HinetPy/client.py&quot;, line 47, in init_poolmanager</span><br><span class=\"line\">    ctx = create_urllib3_context(ciphers=&quot;:HIGH:!DH:!aNULL&quot;)</span><br><span class=\"line\">TypeError: create_default_context() got an unexpected keyword argument &#x27;ciphers&#x27;</span><br></pre></td></tr></table></figure>\n&emsp;&emsp;然后，各种折腾一翻，删除，重装还是不行，看看模块create_urllib3_context<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">grep create_urllib3_context /home/junxie/.conda/envs/py3/lib/python3.9/site-packages/urllib3/util/*.py</span><br></pre></td></tr></table></figure>\n&emsp;&emsp;长这样：<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">/home/junxie/.conda/envs/py3/lib/python3.9/site-packages/urllib3/util/proxy.py:from .ssl_ import create_urllib3_context, resolve_cert_reqs, resolve_ssl_version</span><br><span class=\"line\">/home/junxie/.conda/envs/py3/lib/python3.9/site-packages/urllib3/util/proxy.py:    ssl_context = create_urllib3_context(</span><br><span class=\"line\">/home/junxie/.conda/envs/py3/lib/python3.9/site-packages/urllib3/util/ssl_.py:def create_urllib3_context(</span><br><span class=\"line\">/home/junxie/.conda/envs/py3/lib/python3.9/site-packages/urllib3/util/ssl_.py:        context = ssl_.create_urllib3_context()</span><br><span class=\"line\">/home/junxie/.conda/envs/py3/lib/python3.9/site-packages/urllib3/util/ssl_.py:        be created using :func:create_urllib3_context.</span><br><span class=\"line\">/home/junxie/.conda/envs/py3/lib/python3.9/site-packages/urllib3/util/ssl_.py:        context = create_urllib3_context(ssl_version, cert_reqs, ciphers=ciphers)</span><br></pre></td></tr></table></figure>\n&emsp;&emsp;表明urllib3安装是正确的。所以在client.py中，将这一句：<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">from urllib3.util import create_urllib3_context</span><br></pre></td></tr></table></figure>\n&emsp;&emsp;改为：<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">from urllib3.util.ssl_ import create_urllib3_context</span><br></pre></td></tr></table></figure>\n&emsp;&emsp;然后就万事大吉了。总结：不懂就问AI吧，但不好好学习和思考，到头来还是不懂。然而这又有什么关系，只要有AI在，会问AI问题就行了。没AI的话，那就拜拜了。</li>\n</ul>"},{"title":"Fedora 40如何安装腾讯会议","abbrlink":"91c0c63d","date":"2025-06-17T05:20:08.000Z","_content":"&emsp;&emsp;没想到腾讯开发了Linux版本下的腾讯会议。\n<!--less-->\n&emsp;&emsp;那怎么安装呢？\n&emsp;&emsp;我用了老办法，就是google咯，呃不是，我用的bing。搜索出来的第一条是知乎答案。于是按照说明开始安装了。首先在[腾讯主页](https://meeting.tencent.com/download)下载deb安装包。只有deb安装包，看样子还是ubuntu比较流行啊。\n&emsp;&emsp;接下来按照说明安装alien。\n```\nsudo dnf install alien\n```\n&emsp;&emsp;alien可以将deb格式和rpm格式进行转换。还挺不错。转换命令是：\n```\nsudo alien -r deb包\n```\n&emsp;&emsp;然后就生成了一个rpm包，就可以安装了。。。吧。。。\n&emsp;&emsp;不好意思，有依赖问题，怎么都搞不定。\n&emsp;&emsp;事实上我犯了个错误啊，现在搜索引擎已经落伍了啊。我立马把问题输给了豆包啊。它说可以这么安装：\n * 安装Flatpak\n```\nsudo dnf install flatpak\n```\n嗯，我已经安装了。什么时候安装的呢。\n * 添加Flathub仓库：\n```\nsudo flatpak remote-add --if-not-exists flathub https://flathub.org/repo/flathub.flatpakrepo\n```\n * 按转腾讯会议：\n```\nflatpak install flathub com.tencent.wemeet\n```\n * 运行\n```\nflatpak run com.tencent.wemeet\n```\n\n&emsp;&emsp;然后。。。安装速度慢的可以啊。我直接Ctrl+C掐了。\n&emsp;&emsp;然后我在应用中心直接搜wemeet，就出现了WemeetApp，点击就安装了。好用的很。\n&emsp;&emsp;Linux也变成了点击就运行的玩意儿了啊。\n","source":"_posts/2025-06-17-how-to-install-wemeet.md","raw":"---\ntitle: Fedora 40如何安装腾讯会议\ntags:\n  - Linux\ncategories:\n  - Linux\nabbrlink: 91c0c63d\ndate: 2025-06-17 13:20:08\n---\n&emsp;&emsp;没想到腾讯开发了Linux版本下的腾讯会议。\n<!--less-->\n&emsp;&emsp;那怎么安装呢？\n&emsp;&emsp;我用了老办法，就是google咯，呃不是，我用的bing。搜索出来的第一条是知乎答案。于是按照说明开始安装了。首先在[腾讯主页](https://meeting.tencent.com/download)下载deb安装包。只有deb安装包，看样子还是ubuntu比较流行啊。\n&emsp;&emsp;接下来按照说明安装alien。\n```\nsudo dnf install alien\n```\n&emsp;&emsp;alien可以将deb格式和rpm格式进行转换。还挺不错。转换命令是：\n```\nsudo alien -r deb包\n```\n&emsp;&emsp;然后就生成了一个rpm包，就可以安装了。。。吧。。。\n&emsp;&emsp;不好意思，有依赖问题，怎么都搞不定。\n&emsp;&emsp;事实上我犯了个错误啊，现在搜索引擎已经落伍了啊。我立马把问题输给了豆包啊。它说可以这么安装：\n * 安装Flatpak\n```\nsudo dnf install flatpak\n```\n嗯，我已经安装了。什么时候安装的呢。\n * 添加Flathub仓库：\n```\nsudo flatpak remote-add --if-not-exists flathub https://flathub.org/repo/flathub.flatpakrepo\n```\n * 按转腾讯会议：\n```\nflatpak install flathub com.tencent.wemeet\n```\n * 运行\n```\nflatpak run com.tencent.wemeet\n```\n\n&emsp;&emsp;然后。。。安装速度慢的可以啊。我直接Ctrl+C掐了。\n&emsp;&emsp;然后我在应用中心直接搜wemeet，就出现了WemeetApp，点击就安装了。好用的很。\n&emsp;&emsp;Linux也变成了点击就运行的玩意儿了啊。\n","slug":"how-to-install-wemeet","published":1,"updated":"2025-06-17T05:36:03.503Z","comments":1,"layout":"post","photos":[],"_id":"cmh498iqi00czwvou4jqfaify","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>&emsp;&emsp;那怎么安装呢？<br>&emsp;&emsp;我用了老办法，就是google咯，呃不是，我用的bing。搜索出来的第一条是知乎答案。于是按照说明开始安装了。首先在<a href=\"https://meeting.tencent.com/download\">腾讯主页</a>下载deb安装包。只有deb安装包，看样子还是ubuntu比较流行啊。<br>&emsp;&emsp;接下来按照说明安装alien。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo dnf install alien</span><br></pre></td></tr></table></figure>\n<p>&emsp;&emsp;alien可以将deb格式和rpm格式进行转换。还挺不错。转换命令是：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo alien -r deb包</span><br></pre></td></tr></table></figure>\n<p>&emsp;&emsp;然后就生成了一个rpm包，就可以安装了。。。吧。。。<br>&emsp;&emsp;不好意思，有依赖问题，怎么都搞不定。<br>&emsp;&emsp;事实上我犯了个错误啊，现在搜索引擎已经落伍了啊。我立马把问题输给了豆包啊。它说可以这么安装：</p>\n<ul>\n<li>安装Flatpak<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo dnf install flatpak</span><br></pre></td></tr></table></figure>\n嗯，我已经安装了。什么时候安装的呢。</li>\n<li>添加Flathub仓库：<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo flatpak remote-add --if-not-exists flathub https://flathub.org/repo/flathub.flatpakrepo</span><br></pre></td></tr></table></figure></li>\n<li>按转腾讯会议：<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">flatpak install flathub com.tencent.wemeet</span><br></pre></td></tr></table></figure></li>\n<li>运行<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">flatpak run com.tencent.wemeet</span><br></pre></td></tr></table></figure></li>\n</ul>\n<p>&emsp;&emsp;然后。。。安装速度慢的可以啊。我直接Ctrl+C掐了。<br>&emsp;&emsp;然后我在应用中心直接搜wemeet，就出现了WemeetApp，点击就安装了。好用的很。<br>&emsp;&emsp;Linux也变成了点击就运行的玩意儿了啊。</p>","related_posts":[],"length":753,"excerpt":"<p>&emsp;&emsp;没想到腾讯开发了Linux版本下的腾讯会议。</p>","more":"<p>&emsp;&emsp;那怎么安装呢？<br>&emsp;&emsp;我用了老办法，就是google咯，呃不是，我用的bing。搜索出来的第一条是知乎答案。于是按照说明开始安装了。首先在<a href=\"https://meeting.tencent.com/download\">腾讯主页</a>下载deb安装包。只有deb安装包，看样子还是ubuntu比较流行啊。<br>&emsp;&emsp;接下来按照说明安装alien。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo dnf install alien</span><br></pre></td></tr></table></figure>\n<p>&emsp;&emsp;alien可以将deb格式和rpm格式进行转换。还挺不错。转换命令是：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo alien -r deb包</span><br></pre></td></tr></table></figure>\n<p>&emsp;&emsp;然后就生成了一个rpm包，就可以安装了。。。吧。。。<br>&emsp;&emsp;不好意思，有依赖问题，怎么都搞不定。<br>&emsp;&emsp;事实上我犯了个错误啊，现在搜索引擎已经落伍了啊。我立马把问题输给了豆包啊。它说可以这么安装：</p>\n<ul>\n<li>安装Flatpak<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo dnf install flatpak</span><br></pre></td></tr></table></figure>\n嗯，我已经安装了。什么时候安装的呢。</li>\n<li>添加Flathub仓库：<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo flatpak remote-add --if-not-exists flathub https://flathub.org/repo/flathub.flatpakrepo</span><br></pre></td></tr></table></figure></li>\n<li>按转腾讯会议：<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">flatpak install flathub com.tencent.wemeet</span><br></pre></td></tr></table></figure></li>\n<li>运行<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">flatpak run com.tencent.wemeet</span><br></pre></td></tr></table></figure></li>\n</ul>\n<p>&emsp;&emsp;然后。。。安装速度慢的可以啊。我直接Ctrl+C掐了。<br>&emsp;&emsp;然后我在应用中心直接搜wemeet，就出现了WemeetApp，点击就安装了。好用的很。<br>&emsp;&emsp;Linux也变成了点击就运行的玩意儿了啊。</p>"},{"title":"python脚本下载连续波形数据更新","abbrlink":"5f341ab1","date":"2025-06-08T12:42:13.000Z","_content":"&emsp;&emsp;python脚本下载连续波形数据更新。\n<!--less-->\n```python\nimport os\nimport numpy as np\nfrom obspy import UTCDateTime, Stream, Trace\nfrom obspy.io.sac import SACTrace\nfrom obspy.clients.fdsn import Client\nfrom obspy.signal.rotate import rotate_ne_rt\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\nimport traceback\nfrom collections import defaultdict\n\n# 参数设置\nclient = Client(\"IRIS\")\noutput_dir = \"daily_waveforms\"\nos.makedirs(output_dir, exist_ok=True)\nsta_file = \"station.list\"\nstart_date = UTCDateTime(\"2023-09-16\")\nend_date = UTCDateTime(\"2023-09-27\")  # 包括该天\nthread_workers = 6\nexception_log = \"exceptions.txt\"\nsampling_rate = 1.0  # LH通道的采样率 (1 Hz)\nexpected_npts = 86400  # 86400秒 * 1Hz采样率\n\n# 打印工作目录与输出目录\nprint(f\"📁📁📁📁 当前工作目录: {os.getcwd()}\")\nprint(f\"📁📁📁📁 保存路径: {os.path.abspath(output_dir)}\")\n\n# 读取台站列表\nsta_list = []\nwith open(sta_file, \"r\") as sf:\n    for line in sf:\n        if line.strip() and not line.strip().startswith(\"#\"):\n            parts = line.strip().split()\n            if len(parts) >= 2:\n                net, sta = parts[0], parts[1]\n                sta_list.append((net, sta))\n\n# 记录异常到文件\ndef log_exception(msg):\n    with open(exception_log, \"a\") as f:\n        f.write(f\"{UTCDateTime.now().isoformat()} - {msg}\\n\")\n\n# 保存为SAC文件（每个通道一个文件）\ndef save_channel_sac(tr, day_dir, net, sta, station_coords):\n    try:\n        # 确保目录存在\n        os.makedirs(day_dir, exist_ok=True)\n        \n        # 文件名格式: NET_STA_CHAN.SAC\n        chan = tr.stats.channel\n        filename = f\"{net}_{sta}_{chan}.SAC\"\n        filepath = os.path.join(day_dir, filename)\n        \n        # 创建SACTrace对象\n        sac = SACTrace.from_obspy_trace(tr)\n        \n        # 设置台站信息\n        sac.kstnm = sta\n        sac.knetwk = net\n        \n        # 设置坐标信息\n        if station_coords is not None:\n            sac.stla = station_coords[\"latitude\"]\n            sac.stlo = station_coords[\"longitude\"]\n            sac.stel = station_coords[\"elevation\"]\n            sac.stdp = station_coords.get(\"local_depth\", 0.0)\n            print(f\"    ✅ 添加坐标: {sac.stla:.4f}, {sac.stlo:.4f}\")\n        else:\n            sac.stla = 0.0\n            sac.stlo = 0.0\n            sac.stel = 0.0\n            sac.stdp = 0.0\n            print(f\"    ⚠⚠⚠️ 无坐标信息\")\n        \n        # 保存文件\n        sac.write(filepath)\n        \n        print(f\"  保存: {filename}\")\n        return filepath\n    except Exception as e:\n        log_exception(f\"保存SAC文件失败 {net}.{sta}.{chan}: {str(e)}\")\n        traceback.print_exc()\n        return None\n\n# 数据补零处理\ndef fill_gaps(tr, start_time):\n    \"\"\"\n    确保数据有完整的86400个点，缺失部分补零\n    \"\"\"\n    try:\n        # 创建新的头信息\n        new_header = tr.stats.copy()\n        new_header.starttime = start_time  # 确保从当天00:00:00开始\n        new_header.npts = expected_npts\n        new_header.sampling_rate = sampling_rate\n        \n        # 创建全零数据数组\n        new_data = np.zeros(expected_npts, dtype=tr.data.dtype)\n        \n        # 计算数据偏移量（当前数据在当天中的起始位置）\n        start_diff = int((tr.stats.starttime - start_time))\n        \n        # 确保偏移量在合理范围内\n        if 0 <= start_diff < expected_npts:\n            end_index = min(start_diff + tr.stats.npts, expected_npts)\n            valid_length = end_index - start_diff\n            \n            # 将实际数据复制到全零数组的相应位置\n            if valid_length > 0:\n                new_data[start_diff:end_index] = tr.data[:valid_length]\n        \n        # 创建新的Trace\n        return Trace(data=new_data, header=new_header)\n    except Exception as e:\n        log_exception(f\"数据补零失败: {str(e)}\")\n        return tr\n\n# 旋转LH1/LH2分量到LHE/LHN\ndef rotate_to_EN(tr1, tr2):\n    \"\"\"将两个水平分量(LH1/LH2)旋转到地理坐标系(LHE/LHN)\"\"\"\n    try:\n        # 假设LH1是北分量，LH2是东分量\n        north = tr1.data\n        east = tr2.data\n        \n        # 旋转分量\n        n, e = rotate_ne_rt(north, east, 0)\n        \n        # 创建新的Trace对象\n        trN = Trace(data=n)\n        trN.stats = tr1.stats.copy()\n        trN.stats.channel = \"LHN\"\n        \n        trE = Trace(data=e)\n        trE.stats = tr2.stats.copy()\n        trE.stats.channel = \"LHE\"\n        \n        return trN, trE\n    except Exception as e:\n        log_exception(f\"旋转分量失败: {e}\")\n        return tr1, tr2\n\n# 处理水平分量\ndef process_horizontal_components(st):\n    \"\"\"\n    处理水平分量：\n    1. 如果只有LH1和LH2，旋转为LHE和LHN，并删除原始的极LH1/LH2\n    2. 如果存在LHN和LHE，优先使用它们，并删除任何LH1/LH2分量\n    \"\"\"\n    try:\n        # 按通道类型分组\n        comp_groups = defaultdict(list)\n        for tr in st:\n            comp_groups[tr.stats.channel].append(tr)\n        \n        # 处理水平分量\n        horizontal_stream = Stream()\n        \n        # 优先选择LHN和LHE分量\n        en_comps = [\"LHE\", \"LHN\"]\n        has_EN = any(comp in comp_groups for comp in en_comps)\n        \n        if has_EN:\n            # 使用已有的LHN/LHE分量（只取第一个）\n            for comp in en_comps:\n                if comp in comp_groups:\n                    horizontal_stream.append(comp_groups[comp][0])\n            print(\"  使用现有的LHN/LHE分量\")\n            \n            # 删除任何存在的LH1/LH2分量\n            if \"LH1\" in comp_groups or \"LH2\" in comp_groups:\n                print(\"  删除原始的LH1/LH2分量\")\n        else:\n            # 检查是否有LH1和LH2\n            rt_comps = [\"LH1\", \"LH2\"]\n            if all(comp in comp_groups for comp in rt_comps):\n                # 获取LH1和LH2分量（只取第一个）\n                lh1 = comp_groups[\"LH1\"][0]\n                lh2 = comp_groups[\"LH2\"][0]\n                \n                # 旋转到EN分量\n                trN, trE = rotate_to_EN(lh1, lh2)\n                horizontal_stream.append(trN)\n                horizontal_stream.append(trE)\n                print(\"  旋转LH1/LH2为LHN/LHE\")\n                \n                # 删除原始的LH1/LH2分量\n                print(\"  删除原始的LH1/LH2分量\")\n        \n        return horizontal_stream\n    except Exception as e:\n        log_exception(f\"处理水平分量失败: {e}\")\n        return Stream()\n\n# 下载并处理单个台站某天的数据\ndef download_station(net, sta, day):\n    station_coords = None  # 存储台站坐标\n    try:\n        start = UTCDateTime(day)\n        end = start + 86400\n        day_str = start.strftime(\"%Y%m%d\")\n        \n        # 获取台站元数据\n        print(f\"  获取 {net}.{sta} 元数据...\")\n        try:\n            inv = client.get_stations(\n                network=net, \n                station=sta, \n                starttime=start, \n                endtime=end, \n                level=\"channel\"\n            )\n            \n            # 尝试获取台站坐标（使用LHZ通道）\n            try:\n                station_coords = inv.get_coordinates(f\"{net}.{sta}.00.LHZ\", start)\n                print(f\"    ✅ 获取坐标: {station_coords['latitude']:.4f}, {station_coords['longitude']:.4f}\")\n            except:\n                # 如果LHZ失败，尝试其他LH通道\n                for chan in [\"LHN\", \"LHE\", \"LH1\", \"LH2\"]:\n                    try:\n                        station_coords = inv.get_coordinates(f\"{net}.{sta}.00.{chan}\", start)\n                        print(f\"    ✅ 获取坐标: {station_coords['latitude']:.4f}, {station_coords['longitude']:.4f}\")\n                        break\n                    except:\n                        continue\n                if station_coords is None:\n                    print(\"    ⚠⚠⚠️ 无法获取坐标\")\n        except Exception as e:\n            print(f\"  ⚠⚠⚠️ 元数据获取失败: {str(e)}\")\n        \n        # 下载波形数据\n        print(f\"  下载 {net}.{sta} 波形数据...\")\n        st = client.get_waveforms(net, sta, \"*\", \"LH?\", start, end, attach_response=True)\n        \n        # 如果没数据，直接返回\n        if len(st) == 0:\n            return (net, sta, False, \"无数据\")\n        \n        # 检查是否有LHZ分量（只取第一个）\n        vertical_st = st.select(channel=\"LHZ\")\n        if len(vertical_st) == 0:\n            print(f\"  ⚠⚠⚠️ 跳过 {net}.{sta} - 无LHZ分量\")\n            return (net, sta, False, \"无LHZ分量\")\n        else:\n            # 只保留第一个LHZ分量\n            vertical_tr = vertical_st[0]\n        \n        # 去除仪器响应\n        print(\"  去除仪器响应...\")\n        st.remove_response(output=\"VEL\", pre_filt=(0.008, 0.01, 0.3, 0.4),\n                           taper=True, zero_mean=True, taper_fraction=0.05)\n        \n        # 处理水平分量\n        print(\"  处理水平分量...\")\n        horizontal_st = process_horizontal_components(st)\n        \n        # 合并垂直和水平分量\n        processed_st = Stream([vertical_tr]) + horizontal_st\n        \n        # 确保只有三个分量：LHZ, LHN, LHE\n        final_st = Stream()\n        channels = set()\n        for tr in processed_st:\n            # 只添加LHZ、LHN和LHE分量\n            if tr.stats.channel in [\"LHZ\", \"LHN\", \"LHE\"]:\n                if tr.stats.channel not in channels:\n                    final_st.append(tr)\n                    channels.add(tr.stats.channel)\n                else:\n                    print(f\"  ⚠⚠⚠️ 跳过重复通道: {tr.stats.channel}\")\n        \n        # 数据补零处理\n        print(\"  数据补零处理...\")\n        filled_st = Stream()\n        for tr in final_st:\n            filled_tr = fill_gaps(tr, start)\n            filled_st.append(filled_tr)\n        \n        # 创建日期目录\n        day_dir = os.path.join(output_dir, day_str)\n        \n        # 保存每个通道的数据\n        saved_files = []\n        for tr in filled_st:\n            filepath = save_channel_sac(tr, day_dir, net, sta, station_coords)\n            if filepath:\n                saved_files.append(filepath)\n        \n        return (net, sta, True, saved_files)\n    except Exception as e:\n        error_msg = f\"{str(e)}\"\n        if hasattr(e, 'response') and e.response is not None:\n            error_msg += f\" (Status: {e.response.status_code})\"\n        return (net, sta, False, error_msg)\n\n# 遍历日期，按天下载并保存\ncurrent_day = start_date\nwhile current_day <= end_date:\n    day_str = current_day.strftime(\"%Y%m%d\")\n    day_dir = os.path.join(output_dir, day_str)\n    \n    # 检查是否已下载\n    if os.path.exists(day_dir) and os.path.isdir(day_dir):\n        print(f\"\\n📆📆📆📆 日期 {current_day.date} 已存在，跳过处理\")\n        # 进入下一天\n        current_day += 86400\n        continue\n    \n    print(f\"\\n📆📆📆📆 正在处理日期: {current_day.date}\")\n    \n    # 创建日期目录\n    os.makedirs(day_dir, exist_ok=True)\n\n    # 异常记录每天追加\n    log_lines = []\n    success_count = 0\n    fail_count = 0\n\n    # 启动多线程下载当天所有台站数据\n    with ThreadPoolExecutor(max_workers=thread_workers) as executor:\n        futures = {executor.submit(download_station, net, sta, current_day): (net, sta) for net, sta in sta_list}\n\n        for future in as_completed(futures):\n            net, sta = futures[future]\n            try:\n                net, sta, ok, result = future.result()\n                if ok:\n                    success_count += 1\n                    file_count = len(result)\n                    print(f\"✅ {net}.{sta} 处理成功 - 保存了 {file_count} 个SAC文件\")\n                    for filepath in result:\n                        print(f\"   ↳↳ {os.path.basename(filepath)}\")\n                else:\n                    fail_count += 1\n                    print(f\"❌❌❌❌ {net}.{sta} 处理失败: {result}\")\n                    log_lines.append(f\"{current_day.date} {net}.{sta} ❌❌❌❌ {result}\")\n            except Exception as e:\n                fail_count += 1\n                error_msg = f\"{str(e)}\"\n                print(f\"❌❌❌❌ {net}.{sta} 异常: {error_msg}\")\n                log_lines.append(f\"{current_day.date} {net}.{sta} ❌❌❌❌ {error_msg}\")\n                traceback.print_exc()\n\n    print(f\"\\n📊📊 本日统计: {success_count} 个台站成功, {fail_count} 个台站失败\")\n\n    # 写入异常日志\n    if log_lines:\n        with open(exception_log, \"a\") as elog:\n            elog.write(\"\\n\".join(log_lines) + \"\\n\")\n\n    # 进入下一天\n    current_day += 86400\n\nprint(\"\\n🎉🎉 所有日期处理完成!\")\n```\n&emsp;&emsp;此脚本完成以下操作:\n   * 多线程下载指定定时间段的LH分量数据。\n   * 按天保存到同一个文件夹，检查当天的文件是否已经建立，如果已建立则跳过（防止重复下载）。\n   * 检查是否有LHZ分量，如果没有则跳过此台。\n   * 去除仪器响应，保存为速度记录，滤波到0.008-0.4Hz。\n   * 仅保存第一个location（空，00，01）的LHZ，LHE，LHN。\n   * 如果同时有LH1,LH2,LHE,LHN则删除LH1,LH2分量。\n   * 如果仅有LH1,LH2,则旋转到LHE，LHN，删除LH1,LH2。\n   * 如果不足86400则补零，对齐到当天的00:00:00。\n   * 保存为SAC格式，文件名为NET_STA_COM.SAC。\n","source":"_posts/2025-06-08-download-continous-data-update.md","raw":"---\ntitle: python脚本下载连续波形数据更新\ntags:\n  - python\ncategories:\n  - work\nabbrlink: 5f341ab1\ndate: 2025-06-08 20:42:13\n---\n&emsp;&emsp;python脚本下载连续波形数据更新。\n<!--less-->\n```python\nimport os\nimport numpy as np\nfrom obspy import UTCDateTime, Stream, Trace\nfrom obspy.io.sac import SACTrace\nfrom obspy.clients.fdsn import Client\nfrom obspy.signal.rotate import rotate_ne_rt\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\nimport traceback\nfrom collections import defaultdict\n\n# 参数设置\nclient = Client(\"IRIS\")\noutput_dir = \"daily_waveforms\"\nos.makedirs(output_dir, exist_ok=True)\nsta_file = \"station.list\"\nstart_date = UTCDateTime(\"2023-09-16\")\nend_date = UTCDateTime(\"2023-09-27\")  # 包括该天\nthread_workers = 6\nexception_log = \"exceptions.txt\"\nsampling_rate = 1.0  # LH通道的采样率 (1 Hz)\nexpected_npts = 86400  # 86400秒 * 1Hz采样率\n\n# 打印工作目录与输出目录\nprint(f\"📁📁📁📁 当前工作目录: {os.getcwd()}\")\nprint(f\"📁📁📁📁 保存路径: {os.path.abspath(output_dir)}\")\n\n# 读取台站列表\nsta_list = []\nwith open(sta_file, \"r\") as sf:\n    for line in sf:\n        if line.strip() and not line.strip().startswith(\"#\"):\n            parts = line.strip().split()\n            if len(parts) >= 2:\n                net, sta = parts[0], parts[1]\n                sta_list.append((net, sta))\n\n# 记录异常到文件\ndef log_exception(msg):\n    with open(exception_log, \"a\") as f:\n        f.write(f\"{UTCDateTime.now().isoformat()} - {msg}\\n\")\n\n# 保存为SAC文件（每个通道一个文件）\ndef save_channel_sac(tr, day_dir, net, sta, station_coords):\n    try:\n        # 确保目录存在\n        os.makedirs(day_dir, exist_ok=True)\n        \n        # 文件名格式: NET_STA_CHAN.SAC\n        chan = tr.stats.channel\n        filename = f\"{net}_{sta}_{chan}.SAC\"\n        filepath = os.path.join(day_dir, filename)\n        \n        # 创建SACTrace对象\n        sac = SACTrace.from_obspy_trace(tr)\n        \n        # 设置台站信息\n        sac.kstnm = sta\n        sac.knetwk = net\n        \n        # 设置坐标信息\n        if station_coords is not None:\n            sac.stla = station_coords[\"latitude\"]\n            sac.stlo = station_coords[\"longitude\"]\n            sac.stel = station_coords[\"elevation\"]\n            sac.stdp = station_coords.get(\"local_depth\", 0.0)\n            print(f\"    ✅ 添加坐标: {sac.stla:.4f}, {sac.stlo:.4f}\")\n        else:\n            sac.stla = 0.0\n            sac.stlo = 0.0\n            sac.stel = 0.0\n            sac.stdp = 0.0\n            print(f\"    ⚠⚠⚠️ 无坐标信息\")\n        \n        # 保存文件\n        sac.write(filepath)\n        \n        print(f\"  保存: {filename}\")\n        return filepath\n    except Exception as e:\n        log_exception(f\"保存SAC文件失败 {net}.{sta}.{chan}: {str(e)}\")\n        traceback.print_exc()\n        return None\n\n# 数据补零处理\ndef fill_gaps(tr, start_time):\n    \"\"\"\n    确保数据有完整的86400个点，缺失部分补零\n    \"\"\"\n    try:\n        # 创建新的头信息\n        new_header = tr.stats.copy()\n        new_header.starttime = start_time  # 确保从当天00:00:00开始\n        new_header.npts = expected_npts\n        new_header.sampling_rate = sampling_rate\n        \n        # 创建全零数据数组\n        new_data = np.zeros(expected_npts, dtype=tr.data.dtype)\n        \n        # 计算数据偏移量（当前数据在当天中的起始位置）\n        start_diff = int((tr.stats.starttime - start_time))\n        \n        # 确保偏移量在合理范围内\n        if 0 <= start_diff < expected_npts:\n            end_index = min(start_diff + tr.stats.npts, expected_npts)\n            valid_length = end_index - start_diff\n            \n            # 将实际数据复制到全零数组的相应位置\n            if valid_length > 0:\n                new_data[start_diff:end_index] = tr.data[:valid_length]\n        \n        # 创建新的Trace\n        return Trace(data=new_data, header=new_header)\n    except Exception as e:\n        log_exception(f\"数据补零失败: {str(e)}\")\n        return tr\n\n# 旋转LH1/LH2分量到LHE/LHN\ndef rotate_to_EN(tr1, tr2):\n    \"\"\"将两个水平分量(LH1/LH2)旋转到地理坐标系(LHE/LHN)\"\"\"\n    try:\n        # 假设LH1是北分量，LH2是东分量\n        north = tr1.data\n        east = tr2.data\n        \n        # 旋转分量\n        n, e = rotate_ne_rt(north, east, 0)\n        \n        # 创建新的Trace对象\n        trN = Trace(data=n)\n        trN.stats = tr1.stats.copy()\n        trN.stats.channel = \"LHN\"\n        \n        trE = Trace(data=e)\n        trE.stats = tr2.stats.copy()\n        trE.stats.channel = \"LHE\"\n        \n        return trN, trE\n    except Exception as e:\n        log_exception(f\"旋转分量失败: {e}\")\n        return tr1, tr2\n\n# 处理水平分量\ndef process_horizontal_components(st):\n    \"\"\"\n    处理水平分量：\n    1. 如果只有LH1和LH2，旋转为LHE和LHN，并删除原始的极LH1/LH2\n    2. 如果存在LHN和LHE，优先使用它们，并删除任何LH1/LH2分量\n    \"\"\"\n    try:\n        # 按通道类型分组\n        comp_groups = defaultdict(list)\n        for tr in st:\n            comp_groups[tr.stats.channel].append(tr)\n        \n        # 处理水平分量\n        horizontal_stream = Stream()\n        \n        # 优先选择LHN和LHE分量\n        en_comps = [\"LHE\", \"LHN\"]\n        has_EN = any(comp in comp_groups for comp in en_comps)\n        \n        if has_EN:\n            # 使用已有的LHN/LHE分量（只取第一个）\n            for comp in en_comps:\n                if comp in comp_groups:\n                    horizontal_stream.append(comp_groups[comp][0])\n            print(\"  使用现有的LHN/LHE分量\")\n            \n            # 删除任何存在的LH1/LH2分量\n            if \"LH1\" in comp_groups or \"LH2\" in comp_groups:\n                print(\"  删除原始的LH1/LH2分量\")\n        else:\n            # 检查是否有LH1和LH2\n            rt_comps = [\"LH1\", \"LH2\"]\n            if all(comp in comp_groups for comp in rt_comps):\n                # 获取LH1和LH2分量（只取第一个）\n                lh1 = comp_groups[\"LH1\"][0]\n                lh2 = comp_groups[\"LH2\"][0]\n                \n                # 旋转到EN分量\n                trN, trE = rotate_to_EN(lh1, lh2)\n                horizontal_stream.append(trN)\n                horizontal_stream.append(trE)\n                print(\"  旋转LH1/LH2为LHN/LHE\")\n                \n                # 删除原始的LH1/LH2分量\n                print(\"  删除原始的LH1/LH2分量\")\n        \n        return horizontal_stream\n    except Exception as e:\n        log_exception(f\"处理水平分量失败: {e}\")\n        return Stream()\n\n# 下载并处理单个台站某天的数据\ndef download_station(net, sta, day):\n    station_coords = None  # 存储台站坐标\n    try:\n        start = UTCDateTime(day)\n        end = start + 86400\n        day_str = start.strftime(\"%Y%m%d\")\n        \n        # 获取台站元数据\n        print(f\"  获取 {net}.{sta} 元数据...\")\n        try:\n            inv = client.get_stations(\n                network=net, \n                station=sta, \n                starttime=start, \n                endtime=end, \n                level=\"channel\"\n            )\n            \n            # 尝试获取台站坐标（使用LHZ通道）\n            try:\n                station_coords = inv.get_coordinates(f\"{net}.{sta}.00.LHZ\", start)\n                print(f\"    ✅ 获取坐标: {station_coords['latitude']:.4f}, {station_coords['longitude']:.4f}\")\n            except:\n                # 如果LHZ失败，尝试其他LH通道\n                for chan in [\"LHN\", \"LHE\", \"LH1\", \"LH2\"]:\n                    try:\n                        station_coords = inv.get_coordinates(f\"{net}.{sta}.00.{chan}\", start)\n                        print(f\"    ✅ 获取坐标: {station_coords['latitude']:.4f}, {station_coords['longitude']:.4f}\")\n                        break\n                    except:\n                        continue\n                if station_coords is None:\n                    print(\"    ⚠⚠⚠️ 无法获取坐标\")\n        except Exception as e:\n            print(f\"  ⚠⚠⚠️ 元数据获取失败: {str(e)}\")\n        \n        # 下载波形数据\n        print(f\"  下载 {net}.{sta} 波形数据...\")\n        st = client.get_waveforms(net, sta, \"*\", \"LH?\", start, end, attach_response=True)\n        \n        # 如果没数据，直接返回\n        if len(st) == 0:\n            return (net, sta, False, \"无数据\")\n        \n        # 检查是否有LHZ分量（只取第一个）\n        vertical_st = st.select(channel=\"LHZ\")\n        if len(vertical_st) == 0:\n            print(f\"  ⚠⚠⚠️ 跳过 {net}.{sta} - 无LHZ分量\")\n            return (net, sta, False, \"无LHZ分量\")\n        else:\n            # 只保留第一个LHZ分量\n            vertical_tr = vertical_st[0]\n        \n        # 去除仪器响应\n        print(\"  去除仪器响应...\")\n        st.remove_response(output=\"VEL\", pre_filt=(0.008, 0.01, 0.3, 0.4),\n                           taper=True, zero_mean=True, taper_fraction=0.05)\n        \n        # 处理水平分量\n        print(\"  处理水平分量...\")\n        horizontal_st = process_horizontal_components(st)\n        \n        # 合并垂直和水平分量\n        processed_st = Stream([vertical_tr]) + horizontal_st\n        \n        # 确保只有三个分量：LHZ, LHN, LHE\n        final_st = Stream()\n        channels = set()\n        for tr in processed_st:\n            # 只添加LHZ、LHN和LHE分量\n            if tr.stats.channel in [\"LHZ\", \"LHN\", \"LHE\"]:\n                if tr.stats.channel not in channels:\n                    final_st.append(tr)\n                    channels.add(tr.stats.channel)\n                else:\n                    print(f\"  ⚠⚠⚠️ 跳过重复通道: {tr.stats.channel}\")\n        \n        # 数据补零处理\n        print(\"  数据补零处理...\")\n        filled_st = Stream()\n        for tr in final_st:\n            filled_tr = fill_gaps(tr, start)\n            filled_st.append(filled_tr)\n        \n        # 创建日期目录\n        day_dir = os.path.join(output_dir, day_str)\n        \n        # 保存每个通道的数据\n        saved_files = []\n        for tr in filled_st:\n            filepath = save_channel_sac(tr, day_dir, net, sta, station_coords)\n            if filepath:\n                saved_files.append(filepath)\n        \n        return (net, sta, True, saved_files)\n    except Exception as e:\n        error_msg = f\"{str(e)}\"\n        if hasattr(e, 'response') and e.response is not None:\n            error_msg += f\" (Status: {e.response.status_code})\"\n        return (net, sta, False, error_msg)\n\n# 遍历日期，按天下载并保存\ncurrent_day = start_date\nwhile current_day <= end_date:\n    day_str = current_day.strftime(\"%Y%m%d\")\n    day_dir = os.path.join(output_dir, day_str)\n    \n    # 检查是否已下载\n    if os.path.exists(day_dir) and os.path.isdir(day_dir):\n        print(f\"\\n📆📆📆📆 日期 {current_day.date} 已存在，跳过处理\")\n        # 进入下一天\n        current_day += 86400\n        continue\n    \n    print(f\"\\n📆📆📆📆 正在处理日期: {current_day.date}\")\n    \n    # 创建日期目录\n    os.makedirs(day_dir, exist_ok=True)\n\n    # 异常记录每天追加\n    log_lines = []\n    success_count = 0\n    fail_count = 0\n\n    # 启动多线程下载当天所有台站数据\n    with ThreadPoolExecutor(max_workers=thread_workers) as executor:\n        futures = {executor.submit(download_station, net, sta, current_day): (net, sta) for net, sta in sta_list}\n\n        for future in as_completed(futures):\n            net, sta = futures[future]\n            try:\n                net, sta, ok, result = future.result()\n                if ok:\n                    success_count += 1\n                    file_count = len(result)\n                    print(f\"✅ {net}.{sta} 处理成功 - 保存了 {file_count} 个SAC文件\")\n                    for filepath in result:\n                        print(f\"   ↳↳ {os.path.basename(filepath)}\")\n                else:\n                    fail_count += 1\n                    print(f\"❌❌❌❌ {net}.{sta} 处理失败: {result}\")\n                    log_lines.append(f\"{current_day.date} {net}.{sta} ❌❌❌❌ {result}\")\n            except Exception as e:\n                fail_count += 1\n                error_msg = f\"{str(e)}\"\n                print(f\"❌❌❌❌ {net}.{sta} 异常: {error_msg}\")\n                log_lines.append(f\"{current_day.date} {net}.{sta} ❌❌❌❌ {error_msg}\")\n                traceback.print_exc()\n\n    print(f\"\\n📊📊 本日统计: {success_count} 个台站成功, {fail_count} 个台站失败\")\n\n    # 写入异常日志\n    if log_lines:\n        with open(exception_log, \"a\") as elog:\n            elog.write(\"\\n\".join(log_lines) + \"\\n\")\n\n    # 进入下一天\n    current_day += 86400\n\nprint(\"\\n🎉🎉 所有日期处理完成!\")\n```\n&emsp;&emsp;此脚本完成以下操作:\n   * 多线程下载指定定时间段的LH分量数据。\n   * 按天保存到同一个文件夹，检查当天的文件是否已经建立，如果已建立则跳过（防止重复下载）。\n   * 检查是否有LHZ分量，如果没有则跳过此台。\n   * 去除仪器响应，保存为速度记录，滤波到0.008-0.4Hz。\n   * 仅保存第一个location（空，00，01）的LHZ，LHE，LHN。\n   * 如果同时有LH1,LH2,LHE,LHN则删除LH1,LH2分量。\n   * 如果仅有LH1,LH2,则旋转到LHE，LHN，删除LH1,LH2。\n   * 如果不足86400则补零，对齐到当天的00:00:00。\n   * 保存为SAC格式，文件名为NET_STA_COM.SAC。\n","slug":"download-continous-data-update","published":1,"updated":"2025-06-08T14:02:03.497Z","comments":1,"layout":"post","photos":[],"_id":"cmh498iqi00d2wvouct9ubg2x","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br><span class=\"line\">145</span><br><span class=\"line\">146</span><br><span class=\"line\">147</span><br><span class=\"line\">148</span><br><span class=\"line\">149</span><br><span class=\"line\">150</span><br><span class=\"line\">151</span><br><span class=\"line\">152</span><br><span class=\"line\">153</span><br><span class=\"line\">154</span><br><span class=\"line\">155</span><br><span class=\"line\">156</span><br><span class=\"line\">157</span><br><span class=\"line\">158</span><br><span class=\"line\">159</span><br><span class=\"line\">160</span><br><span class=\"line\">161</span><br><span class=\"line\">162</span><br><span class=\"line\">163</span><br><span class=\"line\">164</span><br><span class=\"line\">165</span><br><span class=\"line\">166</span><br><span class=\"line\">167</span><br><span class=\"line\">168</span><br><span class=\"line\">169</span><br><span class=\"line\">170</span><br><span class=\"line\">171</span><br><span class=\"line\">172</span><br><span class=\"line\">173</span><br><span class=\"line\">174</span><br><span class=\"line\">175</span><br><span class=\"line\">176</span><br><span class=\"line\">177</span><br><span class=\"line\">178</span><br><span class=\"line\">179</span><br><span class=\"line\">180</span><br><span class=\"line\">181</span><br><span class=\"line\">182</span><br><span class=\"line\">183</span><br><span class=\"line\">184</span><br><span class=\"line\">185</span><br><span class=\"line\">186</span><br><span class=\"line\">187</span><br><span class=\"line\">188</span><br><span class=\"line\">189</span><br><span class=\"line\">190</span><br><span class=\"line\">191</span><br><span class=\"line\">192</span><br><span class=\"line\">193</span><br><span class=\"line\">194</span><br><span class=\"line\">195</span><br><span class=\"line\">196</span><br><span class=\"line\">197</span><br><span class=\"line\">198</span><br><span class=\"line\">199</span><br><span class=\"line\">200</span><br><span class=\"line\">201</span><br><span class=\"line\">202</span><br><span class=\"line\">203</span><br><span class=\"line\">204</span><br><span class=\"line\">205</span><br><span class=\"line\">206</span><br><span class=\"line\">207</span><br><span class=\"line\">208</span><br><span class=\"line\">209</span><br><span class=\"line\">210</span><br><span class=\"line\">211</span><br><span class=\"line\">212</span><br><span class=\"line\">213</span><br><span class=\"line\">214</span><br><span class=\"line\">215</span><br><span class=\"line\">216</span><br><span class=\"line\">217</span><br><span class=\"line\">218</span><br><span class=\"line\">219</span><br><span class=\"line\">220</span><br><span class=\"line\">221</span><br><span class=\"line\">222</span><br><span class=\"line\">223</span><br><span class=\"line\">224</span><br><span class=\"line\">225</span><br><span class=\"line\">226</span><br><span class=\"line\">227</span><br><span class=\"line\">228</span><br><span class=\"line\">229</span><br><span class=\"line\">230</span><br><span class=\"line\">231</span><br><span class=\"line\">232</span><br><span class=\"line\">233</span><br><span class=\"line\">234</span><br><span class=\"line\">235</span><br><span class=\"line\">236</span><br><span class=\"line\">237</span><br><span class=\"line\">238</span><br><span class=\"line\">239</span><br><span class=\"line\">240</span><br><span class=\"line\">241</span><br><span class=\"line\">242</span><br><span class=\"line\">243</span><br><span class=\"line\">244</span><br><span class=\"line\">245</span><br><span class=\"line\">246</span><br><span class=\"line\">247</span><br><span class=\"line\">248</span><br><span class=\"line\">249</span><br><span class=\"line\">250</span><br><span class=\"line\">251</span><br><span class=\"line\">252</span><br><span class=\"line\">253</span><br><span class=\"line\">254</span><br><span class=\"line\">255</span><br><span class=\"line\">256</span><br><span class=\"line\">257</span><br><span class=\"line\">258</span><br><span class=\"line\">259</span><br><span class=\"line\">260</span><br><span class=\"line\">261</span><br><span class=\"line\">262</span><br><span class=\"line\">263</span><br><span class=\"line\">264</span><br><span class=\"line\">265</span><br><span class=\"line\">266</span><br><span class=\"line\">267</span><br><span class=\"line\">268</span><br><span class=\"line\">269</span><br><span class=\"line\">270</span><br><span class=\"line\">271</span><br><span class=\"line\">272</span><br><span class=\"line\">273</span><br><span class=\"line\">274</span><br><span class=\"line\">275</span><br><span class=\"line\">276</span><br><span class=\"line\">277</span><br><span class=\"line\">278</span><br><span class=\"line\">279</span><br><span class=\"line\">280</span><br><span class=\"line\">281</span><br><span class=\"line\">282</span><br><span class=\"line\">283</span><br><span class=\"line\">284</span><br><span class=\"line\">285</span><br><span class=\"line\">286</span><br><span class=\"line\">287</span><br><span class=\"line\">288</span><br><span class=\"line\">289</span><br><span class=\"line\">290</span><br><span class=\"line\">291</span><br><span class=\"line\">292</span><br><span class=\"line\">293</span><br><span class=\"line\">294</span><br><span class=\"line\">295</span><br><span class=\"line\">296</span><br><span class=\"line\">297</span><br><span class=\"line\">298</span><br><span class=\"line\">299</span><br><span class=\"line\">300</span><br><span class=\"line\">301</span><br><span class=\"line\">302</span><br><span class=\"line\">303</span><br><span class=\"line\">304</span><br><span class=\"line\">305</span><br><span class=\"line\">306</span><br><span class=\"line\">307</span><br><span class=\"line\">308</span><br><span class=\"line\">309</span><br><span class=\"line\">310</span><br><span class=\"line\">311</span><br><span class=\"line\">312</span><br><span class=\"line\">313</span><br><span class=\"line\">314</span><br><span class=\"line\">315</span><br><span class=\"line\">316</span><br><span class=\"line\">317</span><br><span class=\"line\">318</span><br><span class=\"line\">319</span><br><span class=\"line\">320</span><br><span class=\"line\">321</span><br><span class=\"line\">322</span><br><span class=\"line\">323</span><br><span class=\"line\">324</span><br><span class=\"line\">325</span><br><span class=\"line\">326</span><br><span class=\"line\">327</span><br><span class=\"line\">328</span><br><span class=\"line\">329</span><br><span class=\"line\">330</span><br><span class=\"line\">331</span><br><span class=\"line\">332</span><br><span class=\"line\">333</span><br><span class=\"line\">334</span><br><span class=\"line\">335</span><br><span class=\"line\">336</span><br><span class=\"line\">337</span><br><span class=\"line\">338</span><br><span class=\"line\">339</span><br><span class=\"line\">340</span><br><span class=\"line\">341</span><br><span class=\"line\">342</span><br><span class=\"line\">343</span><br><span class=\"line\">344</span><br><span class=\"line\">345</span><br><span class=\"line\">346</span><br><span class=\"line\">347</span><br><span class=\"line\">348</span><br><span class=\"line\">349</span><br><span class=\"line\">350</span><br><span class=\"line\">351</span><br><span class=\"line\">352</span><br><span class=\"line\">353</span><br><span class=\"line\">354</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">from</span> obspy <span class=\"keyword\">import</span> UTCDateTime, Stream, Trace</span><br><span class=\"line\"><span class=\"keyword\">from</span> obspy.io.sac <span class=\"keyword\">import</span> SACTrace</span><br><span class=\"line\"><span class=\"keyword\">from</span> obspy.clients.fdsn <span class=\"keyword\">import</span> Client</span><br><span class=\"line\"><span class=\"keyword\">from</span> obspy.signal.rotate <span class=\"keyword\">import</span> rotate_ne_rt</span><br><span class=\"line\"><span class=\"keyword\">from</span> concurrent.futures <span class=\"keyword\">import</span> ThreadPoolExecutor, as_completed</span><br><span class=\"line\"><span class=\"keyword\">import</span> traceback</span><br><span class=\"line\"><span class=\"keyword\">from</span> collections <span class=\"keyword\">import</span> defaultdict</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 参数设置</span></span><br><span class=\"line\">client = Client(<span class=\"string\">&quot;IRIS&quot;</span>)</span><br><span class=\"line\">output_dir = <span class=\"string\">&quot;daily_waveforms&quot;</span></span><br><span class=\"line\">os.makedirs(output_dir, exist_ok=<span class=\"literal\">True</span>)</span><br><span class=\"line\">sta_file = <span class=\"string\">&quot;station.list&quot;</span></span><br><span class=\"line\">start_date = UTCDateTime(<span class=\"string\">&quot;2023-09-16&quot;</span>)</span><br><span class=\"line\">end_date = UTCDateTime(<span class=\"string\">&quot;2023-09-27&quot;</span>)  <span class=\"comment\"># 包括该天</span></span><br><span class=\"line\">thread_workers = <span class=\"number\">6</span></span><br><span class=\"line\">exception_log = <span class=\"string\">&quot;exceptions.txt&quot;</span></span><br><span class=\"line\">sampling_rate = <span class=\"number\">1.0</span>  <span class=\"comment\"># LH通道的采样率 (1 Hz)</span></span><br><span class=\"line\">expected_npts = <span class=\"number\">86400</span>  <span class=\"comment\"># 86400秒 * 1Hz采样率</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 打印工作目录与输出目录</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">f&quot;📁📁📁📁 当前工作目录: <span class=\"subst\">&#123;os.getcwd()&#125;</span>&quot;</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">f&quot;📁📁📁📁 保存路径: <span class=\"subst\">&#123;os.path.abspath(output_dir)&#125;</span>&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 读取台站列表</span></span><br><span class=\"line\">sta_list = []</span><br><span class=\"line\"><span class=\"keyword\">with</span> <span class=\"built_in\">open</span>(sta_file, <span class=\"string\">&quot;r&quot;</span>) <span class=\"keyword\">as</span> sf:</span><br><span class=\"line\">    <span class=\"keyword\">for</span> line <span class=\"keyword\">in</span> sf:</span><br><span class=\"line\">        <span class=\"keyword\">if</span> line.strip() <span class=\"keyword\">and</span> <span class=\"keyword\">not</span> line.strip().startswith(<span class=\"string\">&quot;#&quot;</span>):</span><br><span class=\"line\">            parts = line.strip().split()</span><br><span class=\"line\">            <span class=\"keyword\">if</span> <span class=\"built_in\">len</span>(parts) &gt;= <span class=\"number\">2</span>:</span><br><span class=\"line\">                net, sta = parts[<span class=\"number\">0</span>], parts[<span class=\"number\">1</span>]</span><br><span class=\"line\">                sta_list.append((net, sta))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 记录异常到文件</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">log_exception</span>(<span class=\"params\">msg</span>):</span><br><span class=\"line\">    <span class=\"keyword\">with</span> <span class=\"built_in\">open</span>(exception_log, <span class=\"string\">&quot;a&quot;</span>) <span class=\"keyword\">as</span> f:</span><br><span class=\"line\">        f.write(<span class=\"string\">f&quot;<span class=\"subst\">&#123;UTCDateTime.now().isoformat()&#125;</span> - <span class=\"subst\">&#123;msg&#125;</span>\\n&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 保存为SAC文件（每个通道一个文件）</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">save_channel_sac</span>(<span class=\"params\">tr, day_dir, net, sta, station_coords</span>):</span><br><span class=\"line\">    <span class=\"keyword\">try</span>:</span><br><span class=\"line\">        <span class=\"comment\"># 确保目录存在</span></span><br><span class=\"line\">        os.makedirs(day_dir, exist_ok=<span class=\"literal\">True</span>)</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"comment\"># 文件名格式: NET_STA_CHAN.SAC</span></span><br><span class=\"line\">        chan = tr.stats.channel</span><br><span class=\"line\">        filename = <span class=\"string\">f&quot;<span class=\"subst\">&#123;net&#125;</span>_<span class=\"subst\">&#123;sta&#125;</span>_<span class=\"subst\">&#123;chan&#125;</span>.SAC&quot;</span></span><br><span class=\"line\">        filepath = os.path.join(day_dir, filename)</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"comment\"># 创建SACTrace对象</span></span><br><span class=\"line\">        sac = SACTrace.from_obspy_trace(tr)</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"comment\"># 设置台站信息</span></span><br><span class=\"line\">        sac.kstnm = sta</span><br><span class=\"line\">        sac.knetwk = net</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"comment\"># 设置坐标信息</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> station_coords <span class=\"keyword\">is</span> <span class=\"keyword\">not</span> <span class=\"literal\">None</span>:</span><br><span class=\"line\">            sac.stla = station_coords[<span class=\"string\">&quot;latitude&quot;</span>]</span><br><span class=\"line\">            sac.stlo = station_coords[<span class=\"string\">&quot;longitude&quot;</span>]</span><br><span class=\"line\">            sac.stel = station_coords[<span class=\"string\">&quot;elevation&quot;</span>]</span><br><span class=\"line\">            sac.stdp = station_coords.get(<span class=\"string\">&quot;local_depth&quot;</span>, <span class=\"number\">0.0</span>)</span><br><span class=\"line\">            <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;    ✅ 添加坐标: <span class=\"subst\">&#123;sac.stla:<span class=\"number\">.4</span>f&#125;</span>, <span class=\"subst\">&#123;sac.stlo:<span class=\"number\">.4</span>f&#125;</span>&quot;</span>)</span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            sac.stla = <span class=\"number\">0.0</span></span><br><span class=\"line\">            sac.stlo = <span class=\"number\">0.0</span></span><br><span class=\"line\">            sac.stel = <span class=\"number\">0.0</span></span><br><span class=\"line\">            sac.stdp = <span class=\"number\">0.0</span></span><br><span class=\"line\">            <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;    ⚠⚠⚠️ 无坐标信息&quot;</span>)</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"comment\"># 保存文件</span></span><br><span class=\"line\">        sac.write(filepath)</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;  保存: <span class=\"subst\">&#123;filename&#125;</span>&quot;</span>)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> filepath</span><br><span class=\"line\">    <span class=\"keyword\">except</span> Exception <span class=\"keyword\">as</span> e:</span><br><span class=\"line\">        log_exception(<span class=\"string\">f&quot;保存SAC文件失败 <span class=\"subst\">&#123;net&#125;</span>.<span class=\"subst\">&#123;sta&#125;</span>.<span class=\"subst\">&#123;chan&#125;</span>: <span class=\"subst\">&#123;<span class=\"built_in\">str</span>(e)&#125;</span>&quot;</span>)</span><br><span class=\"line\">        traceback.print_exc()</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">None</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 数据补零处理</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">fill_gaps</span>(<span class=\"params\">tr, start_time</span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;</span></span><br><span class=\"line\"><span class=\"string\">    确保数据有完整的86400个点，缺失部分补零</span></span><br><span class=\"line\"><span class=\"string\">    &quot;&quot;&quot;</span></span><br><span class=\"line\">    <span class=\"keyword\">try</span>:</span><br><span class=\"line\">        <span class=\"comment\"># 创建新的头信息</span></span><br><span class=\"line\">        new_header = tr.stats.copy()</span><br><span class=\"line\">        new_header.starttime = start_time  <span class=\"comment\"># 确保从当天00:00:00开始</span></span><br><span class=\"line\">        new_header.npts = expected_npts</span><br><span class=\"line\">        new_header.sampling_rate = sampling_rate</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"comment\"># 创建全零数据数组</span></span><br><span class=\"line\">        new_data = np.zeros(expected_npts, dtype=tr.data.dtype)</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"comment\"># 计算数据偏移量（当前数据在当天中的起始位置）</span></span><br><span class=\"line\">        start_diff = <span class=\"built_in\">int</span>((tr.stats.starttime - start_time))</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"comment\"># 确保偏移量在合理范围内</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> <span class=\"number\">0</span> &lt;= start_diff &lt; expected_npts:</span><br><span class=\"line\">            end_index = <span class=\"built_in\">min</span>(start_diff + tr.stats.npts, expected_npts)</span><br><span class=\"line\">            valid_length = end_index - start_diff</span><br><span class=\"line\">            </span><br><span class=\"line\">            <span class=\"comment\"># 将实际数据复制到全零数组的相应位置</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span> valid_length &gt; <span class=\"number\">0</span>:</span><br><span class=\"line\">                new_data[start_diff:end_index] = tr.data[:valid_length]</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"comment\"># 创建新的Trace</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> Trace(data=new_data, header=new_header)</span><br><span class=\"line\">    <span class=\"keyword\">except</span> Exception <span class=\"keyword\">as</span> e:</span><br><span class=\"line\">        log_exception(<span class=\"string\">f&quot;数据补零失败: <span class=\"subst\">&#123;<span class=\"built_in\">str</span>(e)&#125;</span>&quot;</span>)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> tr</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 旋转LH1/LH2分量到LHE/LHN</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">rotate_to_EN</span>(<span class=\"params\">tr1, tr2</span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;将两个水平分量(LH1/LH2)旋转到地理坐标系(LHE/LHN)&quot;&quot;&quot;</span></span><br><span class=\"line\">    <span class=\"keyword\">try</span>:</span><br><span class=\"line\">        <span class=\"comment\"># 假设LH1是北分量，LH2是东分量</span></span><br><span class=\"line\">        north = tr1.data</span><br><span class=\"line\">        east = tr2.data</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"comment\"># 旋转分量</span></span><br><span class=\"line\">        n, e = rotate_ne_rt(north, east, <span class=\"number\">0</span>)</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"comment\"># 创建新的Trace对象</span></span><br><span class=\"line\">        trN = Trace(data=n)</span><br><span class=\"line\">        trN.stats = tr1.stats.copy()</span><br><span class=\"line\">        trN.stats.channel = <span class=\"string\">&quot;LHN&quot;</span></span><br><span class=\"line\">        </span><br><span class=\"line\">        trE = Trace(data=e)</span><br><span class=\"line\">        trE.stats = tr2.stats.copy()</span><br><span class=\"line\">        trE.stats.channel = <span class=\"string\">&quot;LHE&quot;</span></span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"keyword\">return</span> trN, trE</span><br><span class=\"line\">    <span class=\"keyword\">except</span> Exception <span class=\"keyword\">as</span> e:</span><br><span class=\"line\">        log_exception(<span class=\"string\">f&quot;旋转分量失败: <span class=\"subst\">&#123;e&#125;</span>&quot;</span>)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> tr1, tr2</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 处理水平分量</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">process_horizontal_components</span>(<span class=\"params\">st</span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;</span></span><br><span class=\"line\"><span class=\"string\">    处理水平分量：</span></span><br><span class=\"line\"><span class=\"string\">    1. 如果只有LH1和LH2，旋转为LHE和LHN，并删除原始的极LH1/LH2</span></span><br><span class=\"line\"><span class=\"string\">    2. 如果存在LHN和LHE，优先使用它们，并删除任何LH1/LH2分量</span></span><br><span class=\"line\"><span class=\"string\">    &quot;&quot;&quot;</span></span><br><span class=\"line\">    <span class=\"keyword\">try</span>:</span><br><span class=\"line\">        <span class=\"comment\"># 按通道类型分组</span></span><br><span class=\"line\">        comp_groups = defaultdict(<span class=\"built_in\">list</span>)</span><br><span class=\"line\">        <span class=\"keyword\">for</span> tr <span class=\"keyword\">in</span> st:</span><br><span class=\"line\">            comp_groups[tr.stats.channel].append(tr)</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"comment\"># 处理水平分量</span></span><br><span class=\"line\">        horizontal_stream = Stream()</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"comment\"># 优先选择LHN和LHE分量</span></span><br><span class=\"line\">        en_comps = [<span class=\"string\">&quot;LHE&quot;</span>, <span class=\"string\">&quot;LHN&quot;</span>]</span><br><span class=\"line\">        has_EN = <span class=\"built_in\">any</span>(comp <span class=\"keyword\">in</span> comp_groups <span class=\"keyword\">for</span> comp <span class=\"keyword\">in</span> en_comps)</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"keyword\">if</span> has_EN:</span><br><span class=\"line\">            <span class=\"comment\"># 使用已有的LHN/LHE分量（只取第一个）</span></span><br><span class=\"line\">            <span class=\"keyword\">for</span> comp <span class=\"keyword\">in</span> en_comps:</span><br><span class=\"line\">                <span class=\"keyword\">if</span> comp <span class=\"keyword\">in</span> comp_groups:</span><br><span class=\"line\">                    horizontal_stream.append(comp_groups[comp][<span class=\"number\">0</span>])</span><br><span class=\"line\">            <span class=\"built_in\">print</span>(<span class=\"string\">&quot;  使用现有的LHN/LHE分量&quot;</span>)</span><br><span class=\"line\">            </span><br><span class=\"line\">            <span class=\"comment\"># 删除任何存在的LH1/LH2分量</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span> <span class=\"string\">&quot;LH1&quot;</span> <span class=\"keyword\">in</span> comp_groups <span class=\"keyword\">or</span> <span class=\"string\">&quot;LH2&quot;</span> <span class=\"keyword\">in</span> comp_groups:</span><br><span class=\"line\">                <span class=\"built_in\">print</span>(<span class=\"string\">&quot;  删除原始的LH1/LH2分量&quot;</span>)</span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            <span class=\"comment\"># 检查是否有LH1和LH2</span></span><br><span class=\"line\">            rt_comps = [<span class=\"string\">&quot;LH1&quot;</span>, <span class=\"string\">&quot;LH2&quot;</span>]</span><br><span class=\"line\">            <span class=\"keyword\">if</span> <span class=\"built_in\">all</span>(comp <span class=\"keyword\">in</span> comp_groups <span class=\"keyword\">for</span> comp <span class=\"keyword\">in</span> rt_comps):</span><br><span class=\"line\">                <span class=\"comment\"># 获取LH1和LH2分量（只取第一个）</span></span><br><span class=\"line\">                lh1 = comp_groups[<span class=\"string\">&quot;LH1&quot;</span>][<span class=\"number\">0</span>]</span><br><span class=\"line\">                lh2 = comp_groups[<span class=\"string\">&quot;LH2&quot;</span>][<span class=\"number\">0</span>]</span><br><span class=\"line\">                </span><br><span class=\"line\">                <span class=\"comment\"># 旋转到EN分量</span></span><br><span class=\"line\">                trN, trE = rotate_to_EN(lh1, lh2)</span><br><span class=\"line\">                horizontal_stream.append(trN)</span><br><span class=\"line\">                horizontal_stream.append(trE)</span><br><span class=\"line\">                <span class=\"built_in\">print</span>(<span class=\"string\">&quot;  旋转LH1/LH2为LHN/LHE&quot;</span>)</span><br><span class=\"line\">                </span><br><span class=\"line\">                <span class=\"comment\"># 删除原始的LH1/LH2分量</span></span><br><span class=\"line\">                <span class=\"built_in\">print</span>(<span class=\"string\">&quot;  删除原始的LH1/LH2分量&quot;</span>)</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"keyword\">return</span> horizontal_stream</span><br><span class=\"line\">    <span class=\"keyword\">except</span> Exception <span class=\"keyword\">as</span> e:</span><br><span class=\"line\">        log_exception(<span class=\"string\">f&quot;处理水平分量失败: <span class=\"subst\">&#123;e&#125;</span>&quot;</span>)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> Stream()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 下载并处理单个台站某天的数据</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">download_station</span>(<span class=\"params\">net, sta, day</span>):</span><br><span class=\"line\">    station_coords = <span class=\"literal\">None</span>  <span class=\"comment\"># 存储台站坐标</span></span><br><span class=\"line\">    <span class=\"keyword\">try</span>:</span><br><span class=\"line\">        start = UTCDateTime(day)</span><br><span class=\"line\">        end = start + <span class=\"number\">86400</span></span><br><span class=\"line\">        day_str = start.strftime(<span class=\"string\">&quot;%Y%m%d&quot;</span>)</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"comment\"># 获取台站元数据</span></span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;  获取 <span class=\"subst\">&#123;net&#125;</span>.<span class=\"subst\">&#123;sta&#125;</span> 元数据...&quot;</span>)</span><br><span class=\"line\">        <span class=\"keyword\">try</span>:</span><br><span class=\"line\">            inv = client.get_stations(</span><br><span class=\"line\">                network=net, </span><br><span class=\"line\">                station=sta, </span><br><span class=\"line\">                starttime=start, </span><br><span class=\"line\">                endtime=end, </span><br><span class=\"line\">                level=<span class=\"string\">&quot;channel&quot;</span></span><br><span class=\"line\">            )</span><br><span class=\"line\">            </span><br><span class=\"line\">            <span class=\"comment\"># 尝试获取台站坐标（使用LHZ通道）</span></span><br><span class=\"line\">            <span class=\"keyword\">try</span>:</span><br><span class=\"line\">                station_coords = inv.get_coordinates(<span class=\"string\">f&quot;<span class=\"subst\">&#123;net&#125;</span>.<span class=\"subst\">&#123;sta&#125;</span>.00.LHZ&quot;</span>, start)</span><br><span class=\"line\">                <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;    ✅ 获取坐标: <span class=\"subst\">&#123;station_coords[<span class=\"string\">&#x27;latitude&#x27;</span>]:<span class=\"number\">.4</span>f&#125;</span>, <span class=\"subst\">&#123;station_coords[<span class=\"string\">&#x27;longitude&#x27;</span>]:<span class=\"number\">.4</span>f&#125;</span>&quot;</span>)</span><br><span class=\"line\">            <span class=\"keyword\">except</span>:</span><br><span class=\"line\">                <span class=\"comment\"># 如果LHZ失败，尝试其他LH通道</span></span><br><span class=\"line\">                <span class=\"keyword\">for</span> chan <span class=\"keyword\">in</span> [<span class=\"string\">&quot;LHN&quot;</span>, <span class=\"string\">&quot;LHE&quot;</span>, <span class=\"string\">&quot;LH1&quot;</span>, <span class=\"string\">&quot;LH2&quot;</span>]:</span><br><span class=\"line\">                    <span class=\"keyword\">try</span>:</span><br><span class=\"line\">                        station_coords = inv.get_coordinates(<span class=\"string\">f&quot;<span class=\"subst\">&#123;net&#125;</span>.<span class=\"subst\">&#123;sta&#125;</span>.00.<span class=\"subst\">&#123;chan&#125;</span>&quot;</span>, start)</span><br><span class=\"line\">                        <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;    ✅ 获取坐标: <span class=\"subst\">&#123;station_coords[<span class=\"string\">&#x27;latitude&#x27;</span>]:<span class=\"number\">.4</span>f&#125;</span>, <span class=\"subst\">&#123;station_coords[<span class=\"string\">&#x27;longitude&#x27;</span>]:<span class=\"number\">.4</span>f&#125;</span>&quot;</span>)</span><br><span class=\"line\">                        <span class=\"keyword\">break</span></span><br><span class=\"line\">                    <span class=\"keyword\">except</span>:</span><br><span class=\"line\">                        <span class=\"keyword\">continue</span></span><br><span class=\"line\">                <span class=\"keyword\">if</span> station_coords <span class=\"keyword\">is</span> <span class=\"literal\">None</span>:</span><br><span class=\"line\">                    <span class=\"built_in\">print</span>(<span class=\"string\">&quot;    ⚠⚠⚠️ 无法获取坐标&quot;</span>)</span><br><span class=\"line\">        <span class=\"keyword\">except</span> Exception <span class=\"keyword\">as</span> e:</span><br><span class=\"line\">            <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;  ⚠⚠⚠️ 元数据获取失败: <span class=\"subst\">&#123;<span class=\"built_in\">str</span>(e)&#125;</span>&quot;</span>)</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"comment\"># 下载波形数据</span></span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;  下载 <span class=\"subst\">&#123;net&#125;</span>.<span class=\"subst\">&#123;sta&#125;</span> 波形数据...&quot;</span>)</span><br><span class=\"line\">        st = client.get_waveforms(net, sta, <span class=\"string\">&quot;*&quot;</span>, <span class=\"string\">&quot;LH?&quot;</span>, start, end, attach_response=<span class=\"literal\">True</span>)</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"comment\"># 如果没数据，直接返回</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> <span class=\"built_in\">len</span>(st) == <span class=\"number\">0</span>:</span><br><span class=\"line\">            <span class=\"keyword\">return</span> (net, sta, <span class=\"literal\">False</span>, <span class=\"string\">&quot;无数据&quot;</span>)</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"comment\"># 检查是否有LHZ分量（只取第一个）</span></span><br><span class=\"line\">        vertical_st = st.select(channel=<span class=\"string\">&quot;LHZ&quot;</span>)</span><br><span class=\"line\">        <span class=\"keyword\">if</span> <span class=\"built_in\">len</span>(vertical_st) == <span class=\"number\">0</span>:</span><br><span class=\"line\">            <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;  ⚠⚠⚠️ 跳过 <span class=\"subst\">&#123;net&#125;</span>.<span class=\"subst\">&#123;sta&#125;</span> - 无LHZ分量&quot;</span>)</span><br><span class=\"line\">            <span class=\"keyword\">return</span> (net, sta, <span class=\"literal\">False</span>, <span class=\"string\">&quot;无LHZ分量&quot;</span>)</span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            <span class=\"comment\"># 只保留第一个LHZ分量</span></span><br><span class=\"line\">            vertical_tr = vertical_st[<span class=\"number\">0</span>]</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"comment\"># 去除仪器响应</span></span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">&quot;  去除仪器响应...&quot;</span>)</span><br><span class=\"line\">        st.remove_response(output=<span class=\"string\">&quot;VEL&quot;</span>, pre_filt=(<span class=\"number\">0.008</span>, <span class=\"number\">0.01</span>, <span class=\"number\">0.3</span>, <span class=\"number\">0.4</span>),</span><br><span class=\"line\">                           taper=<span class=\"literal\">True</span>, zero_mean=<span class=\"literal\">True</span>, taper_fraction=<span class=\"number\">0.05</span>)</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"comment\"># 处理水平分量</span></span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">&quot;  处理水平分量...&quot;</span>)</span><br><span class=\"line\">        horizontal_st = process_horizontal_components(st)</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"comment\"># 合并垂直和水平分量</span></span><br><span class=\"line\">        processed_st = Stream([vertical_tr]) + horizontal_st</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"comment\"># 确保只有三个分量：LHZ, LHN, LHE</span></span><br><span class=\"line\">        final_st = Stream()</span><br><span class=\"line\">        channels = <span class=\"built_in\">set</span>()</span><br><span class=\"line\">        <span class=\"keyword\">for</span> tr <span class=\"keyword\">in</span> processed_st:</span><br><span class=\"line\">            <span class=\"comment\"># 只添加LHZ、LHN和LHE分量</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span> tr.stats.channel <span class=\"keyword\">in</span> [<span class=\"string\">&quot;LHZ&quot;</span>, <span class=\"string\">&quot;LHN&quot;</span>, <span class=\"string\">&quot;LHE&quot;</span>]:</span><br><span class=\"line\">                <span class=\"keyword\">if</span> tr.stats.channel <span class=\"keyword\">not</span> <span class=\"keyword\">in</span> channels:</span><br><span class=\"line\">                    final_st.append(tr)</span><br><span class=\"line\">                    channels.add(tr.stats.channel)</span><br><span class=\"line\">                <span class=\"keyword\">else</span>:</span><br><span class=\"line\">                    <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;  ⚠⚠⚠️ 跳过重复通道: <span class=\"subst\">&#123;tr.stats.channel&#125;</span>&quot;</span>)</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"comment\"># 数据补零处理</span></span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">&quot;  数据补零处理...&quot;</span>)</span><br><span class=\"line\">        filled_st = Stream()</span><br><span class=\"line\">        <span class=\"keyword\">for</span> tr <span class=\"keyword\">in</span> final_st:</span><br><span class=\"line\">            filled_tr = fill_gaps(tr, start)</span><br><span class=\"line\">            filled_st.append(filled_tr)</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"comment\"># 创建日期目录</span></span><br><span class=\"line\">        day_dir = os.path.join(output_dir, day_str)</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"comment\"># 保存每个通道的数据</span></span><br><span class=\"line\">        saved_files = []</span><br><span class=\"line\">        <span class=\"keyword\">for</span> tr <span class=\"keyword\">in</span> filled_st:</span><br><span class=\"line\">            filepath = save_channel_sac(tr, day_dir, net, sta, station_coords)</span><br><span class=\"line\">            <span class=\"keyword\">if</span> filepath:</span><br><span class=\"line\">                saved_files.append(filepath)</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"keyword\">return</span> (net, sta, <span class=\"literal\">True</span>, saved_files)</span><br><span class=\"line\">    <span class=\"keyword\">except</span> Exception <span class=\"keyword\">as</span> e:</span><br><span class=\"line\">        error_msg = <span class=\"string\">f&quot;<span class=\"subst\">&#123;<span class=\"built_in\">str</span>(e)&#125;</span>&quot;</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> <span class=\"built_in\">hasattr</span>(e, <span class=\"string\">&#x27;response&#x27;</span>) <span class=\"keyword\">and</span> e.response <span class=\"keyword\">is</span> <span class=\"keyword\">not</span> <span class=\"literal\">None</span>:</span><br><span class=\"line\">            error_msg += <span class=\"string\">f&quot; (Status: <span class=\"subst\">&#123;e.response.status_code&#125;</span>)&quot;</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> (net, sta, <span class=\"literal\">False</span>, error_msg)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 遍历日期，按天下载并保存</span></span><br><span class=\"line\">current_day = start_date</span><br><span class=\"line\"><span class=\"keyword\">while</span> current_day &lt;= end_date:</span><br><span class=\"line\">    day_str = current_day.strftime(<span class=\"string\">&quot;%Y%m%d&quot;</span>)</span><br><span class=\"line\">    day_dir = os.path.join(output_dir, day_str)</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\"># 检查是否已下载</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> os.path.exists(day_dir) <span class=\"keyword\">and</span> os.path.isdir(day_dir):</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;\\n📆📆📆📆 日期 <span class=\"subst\">&#123;current_day.date&#125;</span> 已存在，跳过处理&quot;</span>)</span><br><span class=\"line\">        <span class=\"comment\"># 进入下一天</span></span><br><span class=\"line\">        current_day += <span class=\"number\">86400</span></span><br><span class=\"line\">        <span class=\"keyword\">continue</span></span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;\\n📆📆📆📆 正在处理日期: <span class=\"subst\">&#123;current_day.date&#125;</span>&quot;</span>)</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\"># 创建日期目录</span></span><br><span class=\"line\">    os.makedirs(day_dir, exist_ok=<span class=\"literal\">True</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 异常记录每天追加</span></span><br><span class=\"line\">    log_lines = []</span><br><span class=\"line\">    success_count = <span class=\"number\">0</span></span><br><span class=\"line\">    fail_count = <span class=\"number\">0</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 启动多线程下载当天所有台站数据</span></span><br><span class=\"line\">    <span class=\"keyword\">with</span> ThreadPoolExecutor(max_workers=thread_workers) <span class=\"keyword\">as</span> executor:</span><br><span class=\"line\">        futures = &#123;executor.submit(download_station, net, sta, current_day): (net, sta) <span class=\"keyword\">for</span> net, sta <span class=\"keyword\">in</span> sta_list&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">for</span> future <span class=\"keyword\">in</span> as_completed(futures):</span><br><span class=\"line\">            net, sta = futures[future]</span><br><span class=\"line\">            <span class=\"keyword\">try</span>:</span><br><span class=\"line\">                net, sta, ok, result = future.result()</span><br><span class=\"line\">                <span class=\"keyword\">if</span> ok:</span><br><span class=\"line\">                    success_count += <span class=\"number\">1</span></span><br><span class=\"line\">                    file_count = <span class=\"built_in\">len</span>(result)</span><br><span class=\"line\">                    <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;✅ <span class=\"subst\">&#123;net&#125;</span>.<span class=\"subst\">&#123;sta&#125;</span> 处理成功 - 保存了 <span class=\"subst\">&#123;file_count&#125;</span> 个SAC文件&quot;</span>)</span><br><span class=\"line\">                    <span class=\"keyword\">for</span> filepath <span class=\"keyword\">in</span> result:</span><br><span class=\"line\">                        <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;   ↳↳ <span class=\"subst\">&#123;os.path.basename(filepath)&#125;</span>&quot;</span>)</span><br><span class=\"line\">                <span class=\"keyword\">else</span>:</span><br><span class=\"line\">                    fail_count += <span class=\"number\">1</span></span><br><span class=\"line\">                    <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;❌❌❌❌ <span class=\"subst\">&#123;net&#125;</span>.<span class=\"subst\">&#123;sta&#125;</span> 处理失败: <span class=\"subst\">&#123;result&#125;</span>&quot;</span>)</span><br><span class=\"line\">                    log_lines.append(<span class=\"string\">f&quot;<span class=\"subst\">&#123;current_day.date&#125;</span> <span class=\"subst\">&#123;net&#125;</span>.<span class=\"subst\">&#123;sta&#125;</span> ❌❌❌❌ <span class=\"subst\">&#123;result&#125;</span>&quot;</span>)</span><br><span class=\"line\">            <span class=\"keyword\">except</span> Exception <span class=\"keyword\">as</span> e:</span><br><span class=\"line\">                fail_count += <span class=\"number\">1</span></span><br><span class=\"line\">                error_msg = <span class=\"string\">f&quot;<span class=\"subst\">&#123;<span class=\"built_in\">str</span>(e)&#125;</span>&quot;</span></span><br><span class=\"line\">                <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;❌❌❌❌ <span class=\"subst\">&#123;net&#125;</span>.<span class=\"subst\">&#123;sta&#125;</span> 异常: <span class=\"subst\">&#123;error_msg&#125;</span>&quot;</span>)</span><br><span class=\"line\">                log_lines.append(<span class=\"string\">f&quot;<span class=\"subst\">&#123;current_day.date&#125;</span> <span class=\"subst\">&#123;net&#125;</span>.<span class=\"subst\">&#123;sta&#125;</span> ❌❌❌❌ <span class=\"subst\">&#123;error_msg&#125;</span>&quot;</span>)</span><br><span class=\"line\">                traceback.print_exc()</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;\\n📊📊 本日统计: <span class=\"subst\">&#123;success_count&#125;</span> 个台站成功, <span class=\"subst\">&#123;fail_count&#125;</span> 个台站失败&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 写入异常日志</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> log_lines:</span><br><span class=\"line\">        <span class=\"keyword\">with</span> <span class=\"built_in\">open</span>(exception_log, <span class=\"string\">&quot;a&quot;</span>) <span class=\"keyword\">as</span> elog:</span><br><span class=\"line\">            elog.write(<span class=\"string\">&quot;\\n&quot;</span>.join(log_lines) + <span class=\"string\">&quot;\\n&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 进入下一天</span></span><br><span class=\"line\">    current_day += <span class=\"number\">86400</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&quot;\\n🎉🎉 所有日期处理完成!&quot;</span>)</span><br></pre></td></tr></table></figure>\n<p>&emsp;&emsp;此脚本完成以下操作:</p>\n<ul>\n<li>多线程下载指定定时间段的LH分量数据。</li>\n<li>按天保存到同一个文件夹，检查当天的文件是否已经建立，如果已建立则跳过（防止重复下载）。</li>\n<li>检查是否有LHZ分量，如果没有则跳过此台。</li>\n<li>去除仪器响应，保存为速度记录，滤波到0.008-0.4Hz。</li>\n<li>仅保存第一个location（空，00，01）的LHZ，LHE，LHN。</li>\n<li>如果同时有LH1,LH2,LHE,LHN则删除LH1,LH2分量。</li>\n<li>如果仅有LH1,LH2,则旋转到LHE，LHN，删除LH1,LH2。</li>\n<li>如果不足86400则补零，对齐到当天的00:00:00。</li>\n<li>保存为SAC格式，文件名为NET_STA_COM.SAC。</li>\n</ul>","related_posts":["download-earthquake-py.html"],"length":10095,"excerpt":"<p>&emsp;&emsp;python脚本下载连续波形数据更新。</p>","more":"<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br><span class=\"line\">145</span><br><span class=\"line\">146</span><br><span class=\"line\">147</span><br><span class=\"line\">148</span><br><span class=\"line\">149</span><br><span class=\"line\">150</span><br><span class=\"line\">151</span><br><span class=\"line\">152</span><br><span class=\"line\">153</span><br><span class=\"line\">154</span><br><span class=\"line\">155</span><br><span class=\"line\">156</span><br><span class=\"line\">157</span><br><span class=\"line\">158</span><br><span class=\"line\">159</span><br><span class=\"line\">160</span><br><span class=\"line\">161</span><br><span class=\"line\">162</span><br><span class=\"line\">163</span><br><span class=\"line\">164</span><br><span class=\"line\">165</span><br><span class=\"line\">166</span><br><span class=\"line\">167</span><br><span class=\"line\">168</span><br><span class=\"line\">169</span><br><span class=\"line\">170</span><br><span class=\"line\">171</span><br><span class=\"line\">172</span><br><span class=\"line\">173</span><br><span class=\"line\">174</span><br><span class=\"line\">175</span><br><span class=\"line\">176</span><br><span class=\"line\">177</span><br><span class=\"line\">178</span><br><span class=\"line\">179</span><br><span class=\"line\">180</span><br><span class=\"line\">181</span><br><span class=\"line\">182</span><br><span class=\"line\">183</span><br><span class=\"line\">184</span><br><span class=\"line\">185</span><br><span class=\"line\">186</span><br><span class=\"line\">187</span><br><span class=\"line\">188</span><br><span class=\"line\">189</span><br><span class=\"line\">190</span><br><span class=\"line\">191</span><br><span class=\"line\">192</span><br><span class=\"line\">193</span><br><span class=\"line\">194</span><br><span class=\"line\">195</span><br><span class=\"line\">196</span><br><span class=\"line\">197</span><br><span class=\"line\">198</span><br><span class=\"line\">199</span><br><span class=\"line\">200</span><br><span class=\"line\">201</span><br><span class=\"line\">202</span><br><span class=\"line\">203</span><br><span class=\"line\">204</span><br><span class=\"line\">205</span><br><span class=\"line\">206</span><br><span class=\"line\">207</span><br><span class=\"line\">208</span><br><span class=\"line\">209</span><br><span class=\"line\">210</span><br><span class=\"line\">211</span><br><span class=\"line\">212</span><br><span class=\"line\">213</span><br><span class=\"line\">214</span><br><span class=\"line\">215</span><br><span class=\"line\">216</span><br><span class=\"line\">217</span><br><span class=\"line\">218</span><br><span class=\"line\">219</span><br><span class=\"line\">220</span><br><span class=\"line\">221</span><br><span class=\"line\">222</span><br><span class=\"line\">223</span><br><span class=\"line\">224</span><br><span class=\"line\">225</span><br><span class=\"line\">226</span><br><span class=\"line\">227</span><br><span class=\"line\">228</span><br><span class=\"line\">229</span><br><span class=\"line\">230</span><br><span class=\"line\">231</span><br><span class=\"line\">232</span><br><span class=\"line\">233</span><br><span class=\"line\">234</span><br><span class=\"line\">235</span><br><span class=\"line\">236</span><br><span class=\"line\">237</span><br><span class=\"line\">238</span><br><span class=\"line\">239</span><br><span class=\"line\">240</span><br><span class=\"line\">241</span><br><span class=\"line\">242</span><br><span class=\"line\">243</span><br><span class=\"line\">244</span><br><span class=\"line\">245</span><br><span class=\"line\">246</span><br><span class=\"line\">247</span><br><span class=\"line\">248</span><br><span class=\"line\">249</span><br><span class=\"line\">250</span><br><span class=\"line\">251</span><br><span class=\"line\">252</span><br><span class=\"line\">253</span><br><span class=\"line\">254</span><br><span class=\"line\">255</span><br><span class=\"line\">256</span><br><span class=\"line\">257</span><br><span class=\"line\">258</span><br><span class=\"line\">259</span><br><span class=\"line\">260</span><br><span class=\"line\">261</span><br><span class=\"line\">262</span><br><span class=\"line\">263</span><br><span class=\"line\">264</span><br><span class=\"line\">265</span><br><span class=\"line\">266</span><br><span class=\"line\">267</span><br><span class=\"line\">268</span><br><span class=\"line\">269</span><br><span class=\"line\">270</span><br><span class=\"line\">271</span><br><span class=\"line\">272</span><br><span class=\"line\">273</span><br><span class=\"line\">274</span><br><span class=\"line\">275</span><br><span class=\"line\">276</span><br><span class=\"line\">277</span><br><span class=\"line\">278</span><br><span class=\"line\">279</span><br><span class=\"line\">280</span><br><span class=\"line\">281</span><br><span class=\"line\">282</span><br><span class=\"line\">283</span><br><span class=\"line\">284</span><br><span class=\"line\">285</span><br><span class=\"line\">286</span><br><span class=\"line\">287</span><br><span class=\"line\">288</span><br><span class=\"line\">289</span><br><span class=\"line\">290</span><br><span class=\"line\">291</span><br><span class=\"line\">292</span><br><span class=\"line\">293</span><br><span class=\"line\">294</span><br><span class=\"line\">295</span><br><span class=\"line\">296</span><br><span class=\"line\">297</span><br><span class=\"line\">298</span><br><span class=\"line\">299</span><br><span class=\"line\">300</span><br><span class=\"line\">301</span><br><span class=\"line\">302</span><br><span class=\"line\">303</span><br><span class=\"line\">304</span><br><span class=\"line\">305</span><br><span class=\"line\">306</span><br><span class=\"line\">307</span><br><span class=\"line\">308</span><br><span class=\"line\">309</span><br><span class=\"line\">310</span><br><span class=\"line\">311</span><br><span class=\"line\">312</span><br><span class=\"line\">313</span><br><span class=\"line\">314</span><br><span class=\"line\">315</span><br><span class=\"line\">316</span><br><span class=\"line\">317</span><br><span class=\"line\">318</span><br><span class=\"line\">319</span><br><span class=\"line\">320</span><br><span class=\"line\">321</span><br><span class=\"line\">322</span><br><span class=\"line\">323</span><br><span class=\"line\">324</span><br><span class=\"line\">325</span><br><span class=\"line\">326</span><br><span class=\"line\">327</span><br><span class=\"line\">328</span><br><span class=\"line\">329</span><br><span class=\"line\">330</span><br><span class=\"line\">331</span><br><span class=\"line\">332</span><br><span class=\"line\">333</span><br><span class=\"line\">334</span><br><span class=\"line\">335</span><br><span class=\"line\">336</span><br><span class=\"line\">337</span><br><span class=\"line\">338</span><br><span class=\"line\">339</span><br><span class=\"line\">340</span><br><span class=\"line\">341</span><br><span class=\"line\">342</span><br><span class=\"line\">343</span><br><span class=\"line\">344</span><br><span class=\"line\">345</span><br><span class=\"line\">346</span><br><span class=\"line\">347</span><br><span class=\"line\">348</span><br><span class=\"line\">349</span><br><span class=\"line\">350</span><br><span class=\"line\">351</span><br><span class=\"line\">352</span><br><span class=\"line\">353</span><br><span class=\"line\">354</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">from</span> obspy <span class=\"keyword\">import</span> UTCDateTime, Stream, Trace</span><br><span class=\"line\"><span class=\"keyword\">from</span> obspy.io.sac <span class=\"keyword\">import</span> SACTrace</span><br><span class=\"line\"><span class=\"keyword\">from</span> obspy.clients.fdsn <span class=\"keyword\">import</span> Client</span><br><span class=\"line\"><span class=\"keyword\">from</span> obspy.signal.rotate <span class=\"keyword\">import</span> rotate_ne_rt</span><br><span class=\"line\"><span class=\"keyword\">from</span> concurrent.futures <span class=\"keyword\">import</span> ThreadPoolExecutor, as_completed</span><br><span class=\"line\"><span class=\"keyword\">import</span> traceback</span><br><span class=\"line\"><span class=\"keyword\">from</span> collections <span class=\"keyword\">import</span> defaultdict</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 参数设置</span></span><br><span class=\"line\">client = Client(<span class=\"string\">&quot;IRIS&quot;</span>)</span><br><span class=\"line\">output_dir = <span class=\"string\">&quot;daily_waveforms&quot;</span></span><br><span class=\"line\">os.makedirs(output_dir, exist_ok=<span class=\"literal\">True</span>)</span><br><span class=\"line\">sta_file = <span class=\"string\">&quot;station.list&quot;</span></span><br><span class=\"line\">start_date = UTCDateTime(<span class=\"string\">&quot;2023-09-16&quot;</span>)</span><br><span class=\"line\">end_date = UTCDateTime(<span class=\"string\">&quot;2023-09-27&quot;</span>)  <span class=\"comment\"># 包括该天</span></span><br><span class=\"line\">thread_workers = <span class=\"number\">6</span></span><br><span class=\"line\">exception_log = <span class=\"string\">&quot;exceptions.txt&quot;</span></span><br><span class=\"line\">sampling_rate = <span class=\"number\">1.0</span>  <span class=\"comment\"># LH通道的采样率 (1 Hz)</span></span><br><span class=\"line\">expected_npts = <span class=\"number\">86400</span>  <span class=\"comment\"># 86400秒 * 1Hz采样率</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 打印工作目录与输出目录</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">f&quot;📁📁📁📁 当前工作目录: <span class=\"subst\">&#123;os.getcwd()&#125;</span>&quot;</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">f&quot;📁📁📁📁 保存路径: <span class=\"subst\">&#123;os.path.abspath(output_dir)&#125;</span>&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 读取台站列表</span></span><br><span class=\"line\">sta_list = []</span><br><span class=\"line\"><span class=\"keyword\">with</span> <span class=\"built_in\">open</span>(sta_file, <span class=\"string\">&quot;r&quot;</span>) <span class=\"keyword\">as</span> sf:</span><br><span class=\"line\">    <span class=\"keyword\">for</span> line <span class=\"keyword\">in</span> sf:</span><br><span class=\"line\">        <span class=\"keyword\">if</span> line.strip() <span class=\"keyword\">and</span> <span class=\"keyword\">not</span> line.strip().startswith(<span class=\"string\">&quot;#&quot;</span>):</span><br><span class=\"line\">            parts = line.strip().split()</span><br><span class=\"line\">            <span class=\"keyword\">if</span> <span class=\"built_in\">len</span>(parts) &gt;= <span class=\"number\">2</span>:</span><br><span class=\"line\">                net, sta = parts[<span class=\"number\">0</span>], parts[<span class=\"number\">1</span>]</span><br><span class=\"line\">                sta_list.append((net, sta))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 记录异常到文件</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">log_exception</span>(<span class=\"params\">msg</span>):</span><br><span class=\"line\">    <span class=\"keyword\">with</span> <span class=\"built_in\">open</span>(exception_log, <span class=\"string\">&quot;a&quot;</span>) <span class=\"keyword\">as</span> f:</span><br><span class=\"line\">        f.write(<span class=\"string\">f&quot;<span class=\"subst\">&#123;UTCDateTime.now().isoformat()&#125;</span> - <span class=\"subst\">&#123;msg&#125;</span>\\n&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 保存为SAC文件（每个通道一个文件）</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">save_channel_sac</span>(<span class=\"params\">tr, day_dir, net, sta, station_coords</span>):</span><br><span class=\"line\">    <span class=\"keyword\">try</span>:</span><br><span class=\"line\">        <span class=\"comment\"># 确保目录存在</span></span><br><span class=\"line\">        os.makedirs(day_dir, exist_ok=<span class=\"literal\">True</span>)</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"comment\"># 文件名格式: NET_STA_CHAN.SAC</span></span><br><span class=\"line\">        chan = tr.stats.channel</span><br><span class=\"line\">        filename = <span class=\"string\">f&quot;<span class=\"subst\">&#123;net&#125;</span>_<span class=\"subst\">&#123;sta&#125;</span>_<span class=\"subst\">&#123;chan&#125;</span>.SAC&quot;</span></span><br><span class=\"line\">        filepath = os.path.join(day_dir, filename)</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"comment\"># 创建SACTrace对象</span></span><br><span class=\"line\">        sac = SACTrace.from_obspy_trace(tr)</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"comment\"># 设置台站信息</span></span><br><span class=\"line\">        sac.kstnm = sta</span><br><span class=\"line\">        sac.knetwk = net</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"comment\"># 设置坐标信息</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> station_coords <span class=\"keyword\">is</span> <span class=\"keyword\">not</span> <span class=\"literal\">None</span>:</span><br><span class=\"line\">            sac.stla = station_coords[<span class=\"string\">&quot;latitude&quot;</span>]</span><br><span class=\"line\">            sac.stlo = station_coords[<span class=\"string\">&quot;longitude&quot;</span>]</span><br><span class=\"line\">            sac.stel = station_coords[<span class=\"string\">&quot;elevation&quot;</span>]</span><br><span class=\"line\">            sac.stdp = station_coords.get(<span class=\"string\">&quot;local_depth&quot;</span>, <span class=\"number\">0.0</span>)</span><br><span class=\"line\">            <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;    ✅ 添加坐标: <span class=\"subst\">&#123;sac.stla:<span class=\"number\">.4</span>f&#125;</span>, <span class=\"subst\">&#123;sac.stlo:<span class=\"number\">.4</span>f&#125;</span>&quot;</span>)</span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            sac.stla = <span class=\"number\">0.0</span></span><br><span class=\"line\">            sac.stlo = <span class=\"number\">0.0</span></span><br><span class=\"line\">            sac.stel = <span class=\"number\">0.0</span></span><br><span class=\"line\">            sac.stdp = <span class=\"number\">0.0</span></span><br><span class=\"line\">            <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;    ⚠⚠⚠️ 无坐标信息&quot;</span>)</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"comment\"># 保存文件</span></span><br><span class=\"line\">        sac.write(filepath)</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;  保存: <span class=\"subst\">&#123;filename&#125;</span>&quot;</span>)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> filepath</span><br><span class=\"line\">    <span class=\"keyword\">except</span> Exception <span class=\"keyword\">as</span> e:</span><br><span class=\"line\">        log_exception(<span class=\"string\">f&quot;保存SAC文件失败 <span class=\"subst\">&#123;net&#125;</span>.<span class=\"subst\">&#123;sta&#125;</span>.<span class=\"subst\">&#123;chan&#125;</span>: <span class=\"subst\">&#123;<span class=\"built_in\">str</span>(e)&#125;</span>&quot;</span>)</span><br><span class=\"line\">        traceback.print_exc()</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">None</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 数据补零处理</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">fill_gaps</span>(<span class=\"params\">tr, start_time</span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;</span></span><br><span class=\"line\"><span class=\"string\">    确保数据有完整的86400个点，缺失部分补零</span></span><br><span class=\"line\"><span class=\"string\">    &quot;&quot;&quot;</span></span><br><span class=\"line\">    <span class=\"keyword\">try</span>:</span><br><span class=\"line\">        <span class=\"comment\"># 创建新的头信息</span></span><br><span class=\"line\">        new_header = tr.stats.copy()</span><br><span class=\"line\">        new_header.starttime = start_time  <span class=\"comment\"># 确保从当天00:00:00开始</span></span><br><span class=\"line\">        new_header.npts = expected_npts</span><br><span class=\"line\">        new_header.sampling_rate = sampling_rate</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"comment\"># 创建全零数据数组</span></span><br><span class=\"line\">        new_data = np.zeros(expected_npts, dtype=tr.data.dtype)</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"comment\"># 计算数据偏移量（当前数据在当天中的起始位置）</span></span><br><span class=\"line\">        start_diff = <span class=\"built_in\">int</span>((tr.stats.starttime - start_time))</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"comment\"># 确保偏移量在合理范围内</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> <span class=\"number\">0</span> &lt;= start_diff &lt; expected_npts:</span><br><span class=\"line\">            end_index = <span class=\"built_in\">min</span>(start_diff + tr.stats.npts, expected_npts)</span><br><span class=\"line\">            valid_length = end_index - start_diff</span><br><span class=\"line\">            </span><br><span class=\"line\">            <span class=\"comment\"># 将实际数据复制到全零数组的相应位置</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span> valid_length &gt; <span class=\"number\">0</span>:</span><br><span class=\"line\">                new_data[start_diff:end_index] = tr.data[:valid_length]</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"comment\"># 创建新的Trace</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> Trace(data=new_data, header=new_header)</span><br><span class=\"line\">    <span class=\"keyword\">except</span> Exception <span class=\"keyword\">as</span> e:</span><br><span class=\"line\">        log_exception(<span class=\"string\">f&quot;数据补零失败: <span class=\"subst\">&#123;<span class=\"built_in\">str</span>(e)&#125;</span>&quot;</span>)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> tr</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 旋转LH1/LH2分量到LHE/LHN</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">rotate_to_EN</span>(<span class=\"params\">tr1, tr2</span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;将两个水平分量(LH1/LH2)旋转到地理坐标系(LHE/LHN)&quot;&quot;&quot;</span></span><br><span class=\"line\">    <span class=\"keyword\">try</span>:</span><br><span class=\"line\">        <span class=\"comment\"># 假设LH1是北分量，LH2是东分量</span></span><br><span class=\"line\">        north = tr1.data</span><br><span class=\"line\">        east = tr2.data</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"comment\"># 旋转分量</span></span><br><span class=\"line\">        n, e = rotate_ne_rt(north, east, <span class=\"number\">0</span>)</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"comment\"># 创建新的Trace对象</span></span><br><span class=\"line\">        trN = Trace(data=n)</span><br><span class=\"line\">        trN.stats = tr1.stats.copy()</span><br><span class=\"line\">        trN.stats.channel = <span class=\"string\">&quot;LHN&quot;</span></span><br><span class=\"line\">        </span><br><span class=\"line\">        trE = Trace(data=e)</span><br><span class=\"line\">        trE.stats = tr2.stats.copy()</span><br><span class=\"line\">        trE.stats.channel = <span class=\"string\">&quot;LHE&quot;</span></span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"keyword\">return</span> trN, trE</span><br><span class=\"line\">    <span class=\"keyword\">except</span> Exception <span class=\"keyword\">as</span> e:</span><br><span class=\"line\">        log_exception(<span class=\"string\">f&quot;旋转分量失败: <span class=\"subst\">&#123;e&#125;</span>&quot;</span>)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> tr1, tr2</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 处理水平分量</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">process_horizontal_components</span>(<span class=\"params\">st</span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;</span></span><br><span class=\"line\"><span class=\"string\">    处理水平分量：</span></span><br><span class=\"line\"><span class=\"string\">    1. 如果只有LH1和LH2，旋转为LHE和LHN，并删除原始的极LH1/LH2</span></span><br><span class=\"line\"><span class=\"string\">    2. 如果存在LHN和LHE，优先使用它们，并删除任何LH1/LH2分量</span></span><br><span class=\"line\"><span class=\"string\">    &quot;&quot;&quot;</span></span><br><span class=\"line\">    <span class=\"keyword\">try</span>:</span><br><span class=\"line\">        <span class=\"comment\"># 按通道类型分组</span></span><br><span class=\"line\">        comp_groups = defaultdict(<span class=\"built_in\">list</span>)</span><br><span class=\"line\">        <span class=\"keyword\">for</span> tr <span class=\"keyword\">in</span> st:</span><br><span class=\"line\">            comp_groups[tr.stats.channel].append(tr)</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"comment\"># 处理水平分量</span></span><br><span class=\"line\">        horizontal_stream = Stream()</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"comment\"># 优先选择LHN和LHE分量</span></span><br><span class=\"line\">        en_comps = [<span class=\"string\">&quot;LHE&quot;</span>, <span class=\"string\">&quot;LHN&quot;</span>]</span><br><span class=\"line\">        has_EN = <span class=\"built_in\">any</span>(comp <span class=\"keyword\">in</span> comp_groups <span class=\"keyword\">for</span> comp <span class=\"keyword\">in</span> en_comps)</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"keyword\">if</span> has_EN:</span><br><span class=\"line\">            <span class=\"comment\"># 使用已有的LHN/LHE分量（只取第一个）</span></span><br><span class=\"line\">            <span class=\"keyword\">for</span> comp <span class=\"keyword\">in</span> en_comps:</span><br><span class=\"line\">                <span class=\"keyword\">if</span> comp <span class=\"keyword\">in</span> comp_groups:</span><br><span class=\"line\">                    horizontal_stream.append(comp_groups[comp][<span class=\"number\">0</span>])</span><br><span class=\"line\">            <span class=\"built_in\">print</span>(<span class=\"string\">&quot;  使用现有的LHN/LHE分量&quot;</span>)</span><br><span class=\"line\">            </span><br><span class=\"line\">            <span class=\"comment\"># 删除任何存在的LH1/LH2分量</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span> <span class=\"string\">&quot;LH1&quot;</span> <span class=\"keyword\">in</span> comp_groups <span class=\"keyword\">or</span> <span class=\"string\">&quot;LH2&quot;</span> <span class=\"keyword\">in</span> comp_groups:</span><br><span class=\"line\">                <span class=\"built_in\">print</span>(<span class=\"string\">&quot;  删除原始的LH1/LH2分量&quot;</span>)</span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            <span class=\"comment\"># 检查是否有LH1和LH2</span></span><br><span class=\"line\">            rt_comps = [<span class=\"string\">&quot;LH1&quot;</span>, <span class=\"string\">&quot;LH2&quot;</span>]</span><br><span class=\"line\">            <span class=\"keyword\">if</span> <span class=\"built_in\">all</span>(comp <span class=\"keyword\">in</span> comp_groups <span class=\"keyword\">for</span> comp <span class=\"keyword\">in</span> rt_comps):</span><br><span class=\"line\">                <span class=\"comment\"># 获取LH1和LH2分量（只取第一个）</span></span><br><span class=\"line\">                lh1 = comp_groups[<span class=\"string\">&quot;LH1&quot;</span>][<span class=\"number\">0</span>]</span><br><span class=\"line\">                lh2 = comp_groups[<span class=\"string\">&quot;LH2&quot;</span>][<span class=\"number\">0</span>]</span><br><span class=\"line\">                </span><br><span class=\"line\">                <span class=\"comment\"># 旋转到EN分量</span></span><br><span class=\"line\">                trN, trE = rotate_to_EN(lh1, lh2)</span><br><span class=\"line\">                horizontal_stream.append(trN)</span><br><span class=\"line\">                horizontal_stream.append(trE)</span><br><span class=\"line\">                <span class=\"built_in\">print</span>(<span class=\"string\">&quot;  旋转LH1/LH2为LHN/LHE&quot;</span>)</span><br><span class=\"line\">                </span><br><span class=\"line\">                <span class=\"comment\"># 删除原始的LH1/LH2分量</span></span><br><span class=\"line\">                <span class=\"built_in\">print</span>(<span class=\"string\">&quot;  删除原始的LH1/LH2分量&quot;</span>)</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"keyword\">return</span> horizontal_stream</span><br><span class=\"line\">    <span class=\"keyword\">except</span> Exception <span class=\"keyword\">as</span> e:</span><br><span class=\"line\">        log_exception(<span class=\"string\">f&quot;处理水平分量失败: <span class=\"subst\">&#123;e&#125;</span>&quot;</span>)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> Stream()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 下载并处理单个台站某天的数据</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">download_station</span>(<span class=\"params\">net, sta, day</span>):</span><br><span class=\"line\">    station_coords = <span class=\"literal\">None</span>  <span class=\"comment\"># 存储台站坐标</span></span><br><span class=\"line\">    <span class=\"keyword\">try</span>:</span><br><span class=\"line\">        start = UTCDateTime(day)</span><br><span class=\"line\">        end = start + <span class=\"number\">86400</span></span><br><span class=\"line\">        day_str = start.strftime(<span class=\"string\">&quot;%Y%m%d&quot;</span>)</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"comment\"># 获取台站元数据</span></span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;  获取 <span class=\"subst\">&#123;net&#125;</span>.<span class=\"subst\">&#123;sta&#125;</span> 元数据...&quot;</span>)</span><br><span class=\"line\">        <span class=\"keyword\">try</span>:</span><br><span class=\"line\">            inv = client.get_stations(</span><br><span class=\"line\">                network=net, </span><br><span class=\"line\">                station=sta, </span><br><span class=\"line\">                starttime=start, </span><br><span class=\"line\">                endtime=end, </span><br><span class=\"line\">                level=<span class=\"string\">&quot;channel&quot;</span></span><br><span class=\"line\">            )</span><br><span class=\"line\">            </span><br><span class=\"line\">            <span class=\"comment\"># 尝试获取台站坐标（使用LHZ通道）</span></span><br><span class=\"line\">            <span class=\"keyword\">try</span>:</span><br><span class=\"line\">                station_coords = inv.get_coordinates(<span class=\"string\">f&quot;<span class=\"subst\">&#123;net&#125;</span>.<span class=\"subst\">&#123;sta&#125;</span>.00.LHZ&quot;</span>, start)</span><br><span class=\"line\">                <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;    ✅ 获取坐标: <span class=\"subst\">&#123;station_coords[<span class=\"string\">&#x27;latitude&#x27;</span>]:<span class=\"number\">.4</span>f&#125;</span>, <span class=\"subst\">&#123;station_coords[<span class=\"string\">&#x27;longitude&#x27;</span>]:<span class=\"number\">.4</span>f&#125;</span>&quot;</span>)</span><br><span class=\"line\">            <span class=\"keyword\">except</span>:</span><br><span class=\"line\">                <span class=\"comment\"># 如果LHZ失败，尝试其他LH通道</span></span><br><span class=\"line\">                <span class=\"keyword\">for</span> chan <span class=\"keyword\">in</span> [<span class=\"string\">&quot;LHN&quot;</span>, <span class=\"string\">&quot;LHE&quot;</span>, <span class=\"string\">&quot;LH1&quot;</span>, <span class=\"string\">&quot;LH2&quot;</span>]:</span><br><span class=\"line\">                    <span class=\"keyword\">try</span>:</span><br><span class=\"line\">                        station_coords = inv.get_coordinates(<span class=\"string\">f&quot;<span class=\"subst\">&#123;net&#125;</span>.<span class=\"subst\">&#123;sta&#125;</span>.00.<span class=\"subst\">&#123;chan&#125;</span>&quot;</span>, start)</span><br><span class=\"line\">                        <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;    ✅ 获取坐标: <span class=\"subst\">&#123;station_coords[<span class=\"string\">&#x27;latitude&#x27;</span>]:<span class=\"number\">.4</span>f&#125;</span>, <span class=\"subst\">&#123;station_coords[<span class=\"string\">&#x27;longitude&#x27;</span>]:<span class=\"number\">.4</span>f&#125;</span>&quot;</span>)</span><br><span class=\"line\">                        <span class=\"keyword\">break</span></span><br><span class=\"line\">                    <span class=\"keyword\">except</span>:</span><br><span class=\"line\">                        <span class=\"keyword\">continue</span></span><br><span class=\"line\">                <span class=\"keyword\">if</span> station_coords <span class=\"keyword\">is</span> <span class=\"literal\">None</span>:</span><br><span class=\"line\">                    <span class=\"built_in\">print</span>(<span class=\"string\">&quot;    ⚠⚠⚠️ 无法获取坐标&quot;</span>)</span><br><span class=\"line\">        <span class=\"keyword\">except</span> Exception <span class=\"keyword\">as</span> e:</span><br><span class=\"line\">            <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;  ⚠⚠⚠️ 元数据获取失败: <span class=\"subst\">&#123;<span class=\"built_in\">str</span>(e)&#125;</span>&quot;</span>)</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"comment\"># 下载波形数据</span></span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;  下载 <span class=\"subst\">&#123;net&#125;</span>.<span class=\"subst\">&#123;sta&#125;</span> 波形数据...&quot;</span>)</span><br><span class=\"line\">        st = client.get_waveforms(net, sta, <span class=\"string\">&quot;*&quot;</span>, <span class=\"string\">&quot;LH?&quot;</span>, start, end, attach_response=<span class=\"literal\">True</span>)</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"comment\"># 如果没数据，直接返回</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> <span class=\"built_in\">len</span>(st) == <span class=\"number\">0</span>:</span><br><span class=\"line\">            <span class=\"keyword\">return</span> (net, sta, <span class=\"literal\">False</span>, <span class=\"string\">&quot;无数据&quot;</span>)</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"comment\"># 检查是否有LHZ分量（只取第一个）</span></span><br><span class=\"line\">        vertical_st = st.select(channel=<span class=\"string\">&quot;LHZ&quot;</span>)</span><br><span class=\"line\">        <span class=\"keyword\">if</span> <span class=\"built_in\">len</span>(vertical_st) == <span class=\"number\">0</span>:</span><br><span class=\"line\">            <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;  ⚠⚠⚠️ 跳过 <span class=\"subst\">&#123;net&#125;</span>.<span class=\"subst\">&#123;sta&#125;</span> - 无LHZ分量&quot;</span>)</span><br><span class=\"line\">            <span class=\"keyword\">return</span> (net, sta, <span class=\"literal\">False</span>, <span class=\"string\">&quot;无LHZ分量&quot;</span>)</span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            <span class=\"comment\"># 只保留第一个LHZ分量</span></span><br><span class=\"line\">            vertical_tr = vertical_st[<span class=\"number\">0</span>]</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"comment\"># 去除仪器响应</span></span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">&quot;  去除仪器响应...&quot;</span>)</span><br><span class=\"line\">        st.remove_response(output=<span class=\"string\">&quot;VEL&quot;</span>, pre_filt=(<span class=\"number\">0.008</span>, <span class=\"number\">0.01</span>, <span class=\"number\">0.3</span>, <span class=\"number\">0.4</span>),</span><br><span class=\"line\">                           taper=<span class=\"literal\">True</span>, zero_mean=<span class=\"literal\">True</span>, taper_fraction=<span class=\"number\">0.05</span>)</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"comment\"># 处理水平分量</span></span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">&quot;  处理水平分量...&quot;</span>)</span><br><span class=\"line\">        horizontal_st = process_horizontal_components(st)</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"comment\"># 合并垂直和水平分量</span></span><br><span class=\"line\">        processed_st = Stream([vertical_tr]) + horizontal_st</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"comment\"># 确保只有三个分量：LHZ, LHN, LHE</span></span><br><span class=\"line\">        final_st = Stream()</span><br><span class=\"line\">        channels = <span class=\"built_in\">set</span>()</span><br><span class=\"line\">        <span class=\"keyword\">for</span> tr <span class=\"keyword\">in</span> processed_st:</span><br><span class=\"line\">            <span class=\"comment\"># 只添加LHZ、LHN和LHE分量</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span> tr.stats.channel <span class=\"keyword\">in</span> [<span class=\"string\">&quot;LHZ&quot;</span>, <span class=\"string\">&quot;LHN&quot;</span>, <span class=\"string\">&quot;LHE&quot;</span>]:</span><br><span class=\"line\">                <span class=\"keyword\">if</span> tr.stats.channel <span class=\"keyword\">not</span> <span class=\"keyword\">in</span> channels:</span><br><span class=\"line\">                    final_st.append(tr)</span><br><span class=\"line\">                    channels.add(tr.stats.channel)</span><br><span class=\"line\">                <span class=\"keyword\">else</span>:</span><br><span class=\"line\">                    <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;  ⚠⚠⚠️ 跳过重复通道: <span class=\"subst\">&#123;tr.stats.channel&#125;</span>&quot;</span>)</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"comment\"># 数据补零处理</span></span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">&quot;  数据补零处理...&quot;</span>)</span><br><span class=\"line\">        filled_st = Stream()</span><br><span class=\"line\">        <span class=\"keyword\">for</span> tr <span class=\"keyword\">in</span> final_st:</span><br><span class=\"line\">            filled_tr = fill_gaps(tr, start)</span><br><span class=\"line\">            filled_st.append(filled_tr)</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"comment\"># 创建日期目录</span></span><br><span class=\"line\">        day_dir = os.path.join(output_dir, day_str)</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"comment\"># 保存每个通道的数据</span></span><br><span class=\"line\">        saved_files = []</span><br><span class=\"line\">        <span class=\"keyword\">for</span> tr <span class=\"keyword\">in</span> filled_st:</span><br><span class=\"line\">            filepath = save_channel_sac(tr, day_dir, net, sta, station_coords)</span><br><span class=\"line\">            <span class=\"keyword\">if</span> filepath:</span><br><span class=\"line\">                saved_files.append(filepath)</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"keyword\">return</span> (net, sta, <span class=\"literal\">True</span>, saved_files)</span><br><span class=\"line\">    <span class=\"keyword\">except</span> Exception <span class=\"keyword\">as</span> e:</span><br><span class=\"line\">        error_msg = <span class=\"string\">f&quot;<span class=\"subst\">&#123;<span class=\"built_in\">str</span>(e)&#125;</span>&quot;</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> <span class=\"built_in\">hasattr</span>(e, <span class=\"string\">&#x27;response&#x27;</span>) <span class=\"keyword\">and</span> e.response <span class=\"keyword\">is</span> <span class=\"keyword\">not</span> <span class=\"literal\">None</span>:</span><br><span class=\"line\">            error_msg += <span class=\"string\">f&quot; (Status: <span class=\"subst\">&#123;e.response.status_code&#125;</span>)&quot;</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> (net, sta, <span class=\"literal\">False</span>, error_msg)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 遍历日期，按天下载并保存</span></span><br><span class=\"line\">current_day = start_date</span><br><span class=\"line\"><span class=\"keyword\">while</span> current_day &lt;= end_date:</span><br><span class=\"line\">    day_str = current_day.strftime(<span class=\"string\">&quot;%Y%m%d&quot;</span>)</span><br><span class=\"line\">    day_dir = os.path.join(output_dir, day_str)</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\"># 检查是否已下载</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> os.path.exists(day_dir) <span class=\"keyword\">and</span> os.path.isdir(day_dir):</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;\\n📆📆📆📆 日期 <span class=\"subst\">&#123;current_day.date&#125;</span> 已存在，跳过处理&quot;</span>)</span><br><span class=\"line\">        <span class=\"comment\"># 进入下一天</span></span><br><span class=\"line\">        current_day += <span class=\"number\">86400</span></span><br><span class=\"line\">        <span class=\"keyword\">continue</span></span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;\\n📆📆📆📆 正在处理日期: <span class=\"subst\">&#123;current_day.date&#125;</span>&quot;</span>)</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\"># 创建日期目录</span></span><br><span class=\"line\">    os.makedirs(day_dir, exist_ok=<span class=\"literal\">True</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 异常记录每天追加</span></span><br><span class=\"line\">    log_lines = []</span><br><span class=\"line\">    success_count = <span class=\"number\">0</span></span><br><span class=\"line\">    fail_count = <span class=\"number\">0</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 启动多线程下载当天所有台站数据</span></span><br><span class=\"line\">    <span class=\"keyword\">with</span> ThreadPoolExecutor(max_workers=thread_workers) <span class=\"keyword\">as</span> executor:</span><br><span class=\"line\">        futures = &#123;executor.submit(download_station, net, sta, current_day): (net, sta) <span class=\"keyword\">for</span> net, sta <span class=\"keyword\">in</span> sta_list&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">for</span> future <span class=\"keyword\">in</span> as_completed(futures):</span><br><span class=\"line\">            net, sta = futures[future]</span><br><span class=\"line\">            <span class=\"keyword\">try</span>:</span><br><span class=\"line\">                net, sta, ok, result = future.result()</span><br><span class=\"line\">                <span class=\"keyword\">if</span> ok:</span><br><span class=\"line\">                    success_count += <span class=\"number\">1</span></span><br><span class=\"line\">                    file_count = <span class=\"built_in\">len</span>(result)</span><br><span class=\"line\">                    <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;✅ <span class=\"subst\">&#123;net&#125;</span>.<span class=\"subst\">&#123;sta&#125;</span> 处理成功 - 保存了 <span class=\"subst\">&#123;file_count&#125;</span> 个SAC文件&quot;</span>)</span><br><span class=\"line\">                    <span class=\"keyword\">for</span> filepath <span class=\"keyword\">in</span> result:</span><br><span class=\"line\">                        <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;   ↳↳ <span class=\"subst\">&#123;os.path.basename(filepath)&#125;</span>&quot;</span>)</span><br><span class=\"line\">                <span class=\"keyword\">else</span>:</span><br><span class=\"line\">                    fail_count += <span class=\"number\">1</span></span><br><span class=\"line\">                    <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;❌❌❌❌ <span class=\"subst\">&#123;net&#125;</span>.<span class=\"subst\">&#123;sta&#125;</span> 处理失败: <span class=\"subst\">&#123;result&#125;</span>&quot;</span>)</span><br><span class=\"line\">                    log_lines.append(<span class=\"string\">f&quot;<span class=\"subst\">&#123;current_day.date&#125;</span> <span class=\"subst\">&#123;net&#125;</span>.<span class=\"subst\">&#123;sta&#125;</span> ❌❌❌❌ <span class=\"subst\">&#123;result&#125;</span>&quot;</span>)</span><br><span class=\"line\">            <span class=\"keyword\">except</span> Exception <span class=\"keyword\">as</span> e:</span><br><span class=\"line\">                fail_count += <span class=\"number\">1</span></span><br><span class=\"line\">                error_msg = <span class=\"string\">f&quot;<span class=\"subst\">&#123;<span class=\"built_in\">str</span>(e)&#125;</span>&quot;</span></span><br><span class=\"line\">                <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;❌❌❌❌ <span class=\"subst\">&#123;net&#125;</span>.<span class=\"subst\">&#123;sta&#125;</span> 异常: <span class=\"subst\">&#123;error_msg&#125;</span>&quot;</span>)</span><br><span class=\"line\">                log_lines.append(<span class=\"string\">f&quot;<span class=\"subst\">&#123;current_day.date&#125;</span> <span class=\"subst\">&#123;net&#125;</span>.<span class=\"subst\">&#123;sta&#125;</span> ❌❌❌❌ <span class=\"subst\">&#123;error_msg&#125;</span>&quot;</span>)</span><br><span class=\"line\">                traceback.print_exc()</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;\\n📊📊 本日统计: <span class=\"subst\">&#123;success_count&#125;</span> 个台站成功, <span class=\"subst\">&#123;fail_count&#125;</span> 个台站失败&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 写入异常日志</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> log_lines:</span><br><span class=\"line\">        <span class=\"keyword\">with</span> <span class=\"built_in\">open</span>(exception_log, <span class=\"string\">&quot;a&quot;</span>) <span class=\"keyword\">as</span> elog:</span><br><span class=\"line\">            elog.write(<span class=\"string\">&quot;\\n&quot;</span>.join(log_lines) + <span class=\"string\">&quot;\\n&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 进入下一天</span></span><br><span class=\"line\">    current_day += <span class=\"number\">86400</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&quot;\\n🎉🎉 所有日期处理完成!&quot;</span>)</span><br></pre></td></tr></table></figure>\n<p>&emsp;&emsp;此脚本完成以下操作:</p>\n<ul>\n<li>多线程下载指定定时间段的LH分量数据。</li>\n<li>按天保存到同一个文件夹，检查当天的文件是否已经建立，如果已建立则跳过（防止重复下载）。</li>\n<li>检查是否有LHZ分量，如果没有则跳过此台。</li>\n<li>去除仪器响应，保存为速度记录，滤波到0.008-0.4Hz。</li>\n<li>仅保存第一个location（空，00，01）的LHZ，LHE，LHN。</li>\n<li>如果同时有LH1,LH2,LHE,LHN则删除LH1,LH2分量。</li>\n<li>如果仅有LH1,LH2,则旋转到LHE，LHN，删除LH1,LH2。</li>\n<li>如果不足86400则补零，对齐到当天的00:00:00。</li>\n<li>保存为SAC格式，文件名为NET_STA_COM.SAC。</li>\n</ul>"},{"title":"Hexo下如何画流程图","abbrlink":"46bb6583","date":"2025-06-17T13:13:32.000Z","_content":"&emsp;&emsp;那么Hexo下如何画流程图呢？\n<!--less-->\n&emsp;&emsp;因为Hexo是用的Markdown的语法，所以是指Markdown的语法。这里我用的是mermaid。用之前需要安装啊。\n\n```\nnpm install hexo-filter-mermaid-diagrams --save\n```\n\n然后\n在三个反引号+mermaid和三个反引号之间输入:\n\ngraph TD\nA[开始] --> B{条件判断}\nB -->|是| C[操作1]\nB -->|否| D[操作2]\nC --> E[结束]\nD --> E\n\n就会生成:\n\n```mermaid\ngraph TD\nA[开始] --> B{条件判断}\nB -->|是| C[操作1]\nB -->|否| D[操作2]\nC --> E[结束]\nD --> E\n```\n大功告成。\n","source":"_posts/2025-06-17-plot-work-flow.md","raw":"---\ntitle: Hexo下如何画流程图\ntags:\n  - Linux\ncategories:\n  - web\nabbrlink: 46bb6583\ndate: 2025-06-17 21:13:32\n---\n&emsp;&emsp;那么Hexo下如何画流程图呢？\n<!--less-->\n&emsp;&emsp;因为Hexo是用的Markdown的语法，所以是指Markdown的语法。这里我用的是mermaid。用之前需要安装啊。\n\n```\nnpm install hexo-filter-mermaid-diagrams --save\n```\n\n然后\n在三个反引号+mermaid和三个反引号之间输入:\n\ngraph TD\nA[开始] --> B{条件判断}\nB -->|是| C[操作1]\nB -->|否| D[操作2]\nC --> E[结束]\nD --> E\n\n就会生成:\n\n```mermaid\ngraph TD\nA[开始] --> B{条件判断}\nB -->|是| C[操作1]\nB -->|否| D[操作2]\nC --> E[结束]\nD --> E\n```\n大功告成。\n","slug":"plot-work-flow","published":1,"updated":"2025-06-18T01:12:47.774Z","comments":1,"layout":"post","photos":[],"_id":"cmh498iqj00d6wvou535teuqd","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>&emsp;&emsp;因为Hexo是用的Markdown的语法，所以是指Markdown的语法。这里我用的是mermaid。用之前需要安装啊。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">npm install hexo-filter-mermaid-diagrams --save</span><br></pre></td></tr></table></figure>\n\n<p>然后<br>在三个反引号+mermaid和三个反引号之间输入:</p>\n<p>graph TD<br>A[开始] –&gt; B{条件判断}<br>B –&gt;|是| C[操作1]<br>B –&gt;|否| D[操作2]<br>C –&gt; E[结束]<br>D –&gt; E</p>\n<p>就会生成:</p>\n<pre class=\"mermaid\">graph TD\nA[开始] --> B{条件判断}\nB -->|是| C[操作1]\nB -->|否| D[操作2]\nC --> E[结束]\nD --> E</pre>\n<p>大功告成。</p>","related_posts":[],"length":315,"excerpt":"<p>&emsp;&emsp;那么Hexo下如何画流程图呢？</p>","more":"<p>&emsp;&emsp;因为Hexo是用的Markdown的语法，所以是指Markdown的语法。这里我用的是mermaid。用之前需要安装啊。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">npm install hexo-filter-mermaid-diagrams --save</span><br></pre></td></tr></table></figure>\n\n<p>然后<br>在三个反引号+mermaid和三个反引号之间输入:</p>\n<p>graph TD<br>A[开始] –&gt; B{条件判断}<br>B –&gt;|是| C[操作1]<br>B –&gt;|否| D[操作2]<br>C –&gt; E[结束]<br>D –&gt; E</p>\n<p>就会生成:</p>\n<pre class=\"mermaid\">graph TD\nA[开始] --> B{条件判断}\nB -->|是| C[操作1]\nB -->|否| D[操作2]\nC --> E[结束]\nD --> E</pre>\n<p>大功告成。</p>"},{"title":"学习Sequencer","abbrlink":"c0e33a2d","date":"2025-06-17T11:17:21.000Z","mathjax":true,"_content":"&emsp;&emsp;今天学习Sequencer。\n<!--less-->\n&emsp;&emsp;什么是Sequencer？具体请参见[这篇文章](https://github.com/dalya/Sequencer/blob/master/Sequencer_paper.pdf)。脚本在[这里](https://github.com/dalya/Sequencer)。不想看？那就看我得了。\n\n# Sequencer是什么？\n\nSequencer是一种无监督算法，旨在从复杂数据中自动识别主要的一维连续趋势。它通过分析数据对象之间的相似性图结构，无需预定义特征、参数调整或领域知识，直接处理原始数据（如像素、光谱值）来发现隐藏的全局序列。其核心创新在于：\n\n * 通用性：适用于任意一维数据（光谱、时间序列、图像行等）。\n * 自动化：自动选择最优的相似性度量和分析尺度。\n * 可解释性：输出物理意义明确的序列（如温度梯度、红移序列）。\n\n# 工作原理\n  * 核心思想：最小生成树（MST）的几何特征\n  * 关键假设：连续趋势会生成细长的MST，随机数据则产生紧凑的MST。\n  * 量化指标：伸长率（Elongation）,$\\eta=a/b$\n  a：MST平均高度（从最不连通节点到其他节点的最短路径均值）\n  b：MST平均宽度（按层级分组的节点数均值）\n  * 物理意义：$\\eta$ 越大，数据越接近一维序列。\n# 算法流程\n\n```mermaid\ngraph TD\nA[输入数据] --> B[多尺度分割]\nB --> C[多度量计算]\nC --> D[构建MST]\nD --> E[计算η值]\nE --> F[加权聚合]\nF --> G[全局MST]\nG --> H[BFS序列提取]\n```\n&emsp;&emsp;步骤详解如下：\n\n 1. 多尺度分割\n   将每个数据对象（如400像素光谱）分割为不同尺度的片段（例：从完整对象到20像素小段）。\n目的：捕获局部和全局趋势。\n 2. 多度量计算\n   对每个（尺度, 片段）组合，用4种度量计算距离矩阵：\n   * 欧氏距离（整体形状）\n   * KL散度（概率分布差异）\n   * 地球移动距离（EMD）（位移敏感）\n   * 能量距离（分布差异）\n   为什么多度量？ 不同度量揭示不同特征（如EMD检测谱线位移，欧氏距离捕捉整体形态）。\n 3. MST构建与η计算\n   对每个（度量, 尺度, 片段）生成距离矩阵$\\rightarrow$构建MST$\\rightarrow$计算伸长率$ \\eta_{klm} $。例（文章图3）：窄脉冲数据在小尺度（l=4,5）的欧氏距离获得高$\\eta$，指示局部趋势。\n 4. 信息聚合\n   * 片段聚合：对固定（度量,尺度），用$\\eta$加权平均各片段距离矩阵：$ D_{kl}=\\langle \\eta_{klm} \\cdot D_{klm}\\rangle_{m} $\n   * 全局聚合：用$\\eta$加权合并所有MST的边，构建全局邻近矩阵：\n$$ P_{combined}=\\langle \\eta_{kl}\\cdot edges(MST_{kl})\\rangle_{kl} $$\n 5. 序列提取\n   构建全局MST$\\rightarrow$从最不连通节点开始广度优先搜索（BFS），生成最终序列顺序。\n\n# 输出数据的理解\n  1. 序列顺序：输出为数据对象的有序索引列表，相邻对象在主导度量和尺度下最相似。\n  2. 物理意义：\n  * 恒星光谱（图4a）：序列对应温度梯度（顶部高温恒星→底部低温恒星）。\n  * 类星体光谱（图4b）：序列反映红移变化（谱线系统性位移）。\n  * 地震波数据（图5）：序列揭示地理结构差异（沉积盆地→火成岩区）。\n  3. 可视化建议：将重排后的数据矩阵按序列索引显示，观察连续变化模式（如移动的谱线、渐变纹理）。\n\n# 使用注意事项\n  1. 数据预处理\n    * 归一化：算法内部对每个数据段执行总和归一化（sum=1），无需额外操作。\n    * 高动态范围数据：建议对数缩放（如亮度值）避免少数像素主导。\n    * 缺失值：需插值或剔除，否则距离度量失效。\n  2. 计算优化\n    * 大数据集（$ N>10^4 $）：\n     ** 启用子采样模式（见7.3节）：\n       1. 在小样本（$N_{s}<< N$ ）构建初始序列。\n       2. 按锚点（$f_{A}N_{s}$）逐步插入剩余点。\n     ** 复杂度：从O($N^2$)降至O($N\\logN$)。\n    * 并行化：各（度量,尺度,片段）计算相互独立，可并行加速。\n  3. 结果验证\n    * 检查高$\\eta$度量：分析主导趋势的度量（如EMD指示位移，KL散度捕获分布变化）。\n    * 残差分析（见5.1节）：\n      ** 沿序列方向平滑数据$\\rightarrow$比较原始值与平滑值的残差。大残差可能指示异常点或次级趋势。\n      ** 对比降维方法：用归一化伸长率$ \\eta\\prime=\\eta/N $评估t-SNE/UMAP结果（图7,8）。\n  4. 局限性\n    * 噪声敏感：信噪比<5时趋势可能被掩盖（建议先筛选高信噪比子集）。\n    * 多维数据：算法设计为一维输入，需展平多维数据（如将图像转为行向量）。\n    * 序列唯一性：复杂数据可能存在多个有效序列（需领域知识判断主导趋势）。\n\n\n```python\nimport os\nimport glob\nimport numpy as np\nfrom obspy import read\nfrom obspy.signal.cross_correlation import correlate\nimport matplotlib.pyplot as plt\n\n# 设定文件夹路径和文件匹配模式\nfolder_path = './processed_sac/'\nfile_pattern = os.path.join(folder_path, '20111122T184816*BHZ*.sac')\nfile_list = sorted(glob.glob(file_pattern))\n\n# 设定滤波参数\nlowcut = 0.05\nhighcut = 2.0\nfilter_params = {'lowcut': lowcut, 'highcut': highcut, 'corners': 4, 'method': 'bandpass'}\n\n# 用于存储最终数据的列表\ndata_list = []\n\ndef calculate_time_shift(signal1, signal2, dt, max_shift_seconds=10):\n    \"\"\"\n    计算两个信号之间的时移，返回时移（秒）。\n    参数 max_shift_seconds 控制最大允许的滞后量。\n    \"\"\"\n    max_shift_samples = int(max_shift_seconds / dt)  # 最大允许滞后对应的样本数\n    correlation = correlate(signal1, signal2, max_shift_samples, demean=True, normalize=True)\n    lag = np.argmax(correlation) - max_shift_samples\n    lag_time = lag * dt  # 使用采样间隔转换索引为时间\n    return lag_time\n\n# 读取 SAC 文件并进行处理\nfor file in file_list:\n    # 读取 SAC 文件\n    st = read(file)\n    tr = st[0]  # 假设每个文件只有一个 Trace\n    # 获取数据和采样间隔\n    data = tr.data\n    dt = tr.stats.delta  # 采样间隔\n    # 判断是否全为零，如果是，跳过\n    if np.all(data == 0):\n        print(f\"{file} 数据全为零，跳过。\")\n        continue\n    # 滤波处理（使用 `obspy` 内建的滤波方法）\n    tr.filter(type='bandpass', freqmin=lowcut, freqmax=highcut, corners=filter_params['corners'])\n    filtered_data = tr.data  \n    # 归一化\n    depmin = np.min(filtered_data)\n    depmax = np.max(filtered_data)\n    if depmax != depmin:\n        normalized_data = (filtered_data) / (depmax - depmin)\n    else:\n        normalized_data = filtered_data  # 如果最大值等于最小值，直接使用原数据  \n    data_list.append(normalized_data)\n# 假设我们想要对第一个信号进行时移校正，将所有其他信号与第一个信号对齐\ndata=data_list\nbase_signal = data_list[0]\ntime_shifts = []\n# 对每个信号与基准信号计算时移\nfor i, signal in enumerate(data_list[1:], start=1):\n    time_shift = calculate_time_shift(base_signal, signal, dt)\n    time_shifts.append(time_shift)\n    print(f\"信号 {i+1} 与基准信号的时移: {time_shift:.4f} 秒\")\n    # 平移信号\n    shift_samples = int(round(time_shift / dt))  # 转换为样本数，并取整\n    if shift_samples > 0:\n        shifted_signal = np.concatenate((np.zeros(shift_samples), signal[:-shift_samples]))\n    elif shift_samples < 0:\n        shifted_signal = np.concatenate((signal[-shift_samples:], np.zeros(-shift_samples)))\n    else:\n        shifted_signal = signal\n    # 更新信号为平移后的信号\n    data_list[i] = shifted_signal\n# 转换成一个二维数组，方便作为 sequencer 的输入\ndata_array = np.array(data_list)\n# 打印一下结果，检查是否符合要求\nprint(data_array.shape)\nimport matplotlib.pyplot as plt\nimport sequencer\nobjects_list_simulated = np.vstack(data_array)\nnum_rows = objects_list_simulated.shape[0]\nprint(num_rows)\nshuffled_indices = np.random.permutation(num_rows)\n#shuffled_indices = np.arange(23)\nprint(shuffled_indices)\nobjects_list_shuffled = objects_list_simulated[shuffled_indices, :]\n# 确保没有零值或负值\n#objects_list_shuffled = np.maximum(objects_list_shuffled, 1e-16)  # 或者加上偏移量\n#objects_list_shuffled = np.maximum(objects_list_shuffled, 1e-16)  # 或者加上偏移量\nobjects_list_shuffled = objects_list_shuffled+1.0\n\nplt.figure(1, figsize=(10, 5))\nplt.subplot(1,2,1)\nplt.title(\"input dataset [lines]\")\nfor j, object_data in enumerate(data):\n    grid = np.arange(len(object_data))  # 创建与 object_data 长度相同的 x 轴\n    object_data_scaled_y = object_data + (j-1) *1.0  # 缩放以避免重叠\n    plt.plot(grid, object_data_scaled_y)\nplt.xlabel(\"x\")\nplt.ylabel(\"scaled intensity\")\n\nplt.subplot(1,2,2)\nplt.title(\"input dataset [heat]\")\nplt.pcolormesh(objects_list_shuffled,cmap='inferno')\nplt.colorbar()\nplt.xlabel(\"x\")\nplt.ylabel(\"original index\")\nplt.tight_layout()\n\n\n# 跑sequencer\noutput_path = \"sequencer_output_directory\"\nif not os.path.exists(output_path):\n    os.makedirs(output_path)\n# 初始化 sequencer 对象\nestimator_list = ['EMD', 'energy', 'L2']\nseq = sequencer.Sequencer(grid, objects_list_shuffled, estimator_list)\n# 执行 sequencer\nfinal_elongation, final_sequence = seq.execute(output_path)\n\n# first example\nestimator_name = 'EMD'\nscale = 1\nprint(\"Intermediate elongation for metric=%s and scale=%s: %s\" % (estimator_name, scale, \n                                                                  seq.return_elongation_of_weighted_products(estimator_name, scale)))\n# second example\nestimator_list, scale_list, elongation_list = seq.return_elongation_of_weighted_products_all_metrics_and_scales()\nfor i in range(len(estimator_list)):\n    print(\"metric=%s, scale=%s, elongation: %s\" % (estimator_list[i], \n                                                   scale_list[i], \n                                                   elongation_list[i]))\n\n# 画图\nestimator_list, scale_list, sequence_list = seq.return_sequence_of_weighted_products_all_metrics_and_scales()\n\n#fig, axs = plt.subplots(2, 2, figsize=(12, 10))\nplt.figure(1, figsize=(16, 16))\nplt.subplot(2, 2, 1)\n#plt.title(\"input dataset\")\n#plt.pcolormesh(objects_list_shuffled)\n#plt.colorbar()\n#plt.xlabel(\"x\")\n#plt.ylabel(\"original index\")\n\nfor j, object_data in enumerate(objects_list_shuffled):\n    grid = np.arange(len(object_data))  # 创建与 object_data 长度相同的 x 轴\n    object_data_scaled_y = object_data + (j-1) * 1  # 缩放以避免重叠\n    plt.plot(grid, object_data_scaled_y)\nplt.xlabel(\"x\")\nplt.ylabel(\"Original\")\n\nplt.subplot(2, 2, 2)\nplt.title(\"ordered according to\\n intermediate sequence using: \\n metric=%s, scale=%s\" % (estimator_list[0], scale_list[0]))\nsequnce = sequence_list[0]\n#plt.pcolormesh(objects_list_shuffled[sequnce])\n#plt.colorbar()\n#plt.xlabel(\"x\")\n#plt.ylabel(\"original index\")\nfor j, object_data in enumerate(objects_list_shuffled[sequnce]):\n    grid = np.arange(len(object_data))  # 创建与 object_data 长度相同的 x 轴\n    object_data_scaled_y = object_data + (j-1) * 1  # 缩放以避免重叠\n    plt.plot(grid, object_data_scaled_y)\nplt.xlabel(\"x\")\nplt.ylabel(\"Original\")\n\nplt.subplot(2, 2, 3)\nplt.title(\"ordered according to\\n intermediate sequence using: \\n metric=%s, scale=%s\" % (estimator_list[1], scale_list[1]))\nsequnce = sequence_list[1]\n#plt.pcolormesh(objects_list_shuffled[sequnce])\n#plt.colorbar()\n#plt.xlabel(\"x\")\n#plt.ylabel(\"original index\")\nfor j, object_data in enumerate(objects_list_shuffled[sequnce]):\n    grid = np.arange(len(object_data))  # 创建与 object_data 长度相同的 x 轴\n    object_data_scaled_y = object_data + (j-1) * 1  # 缩放以避免重叠\n    plt.plot(grid, object_data_scaled_y)\nplt.xlabel(\"x\")\nplt.ylabel(\"Original\")\n\nplt.subplot(2, 2, 4)\nplt.title(\"ordered according to\\n intermediate sequence using: \\n metric=%s, scale=%s\" % (estimator_list[2], scale_list[2]))\nsequnce = sequence_list[2]\n#plt.pcolormesh(objects_list_shuffled[sequnce])\n#plt.colorbar()\n#plt.xlabel(\"x\")\n#plt.ylabel(\"original index\")\nfor j, object_data in enumerate(objects_list_shuffled[sequnce]):\n    grid = np.arange(len(object_data))  # 创建与 object_data 长度相同的 x 轴\n    object_data_scaled_y = object_data + (j-1) * 1  # 缩放以避免重叠\n    plt.plot(grid, object_data_scaled_y)\nplt.xlabel(\"x\")\nplt.ylabel(\"Original\")\n\nplt.tight_layout()\n```\n","source":"_posts/2025-06-17-run-sequencer.md","raw":"---\ntitle: 学习Sequencer\ntags:\n  - python\ncategories:\n  - work\nabbrlink: c0e33a2d\ndate: 2025-06-17 19:17:21\nmathjax: true\n---\n&emsp;&emsp;今天学习Sequencer。\n<!--less-->\n&emsp;&emsp;什么是Sequencer？具体请参见[这篇文章](https://github.com/dalya/Sequencer/blob/master/Sequencer_paper.pdf)。脚本在[这里](https://github.com/dalya/Sequencer)。不想看？那就看我得了。\n\n# Sequencer是什么？\n\nSequencer是一种无监督算法，旨在从复杂数据中自动识别主要的一维连续趋势。它通过分析数据对象之间的相似性图结构，无需预定义特征、参数调整或领域知识，直接处理原始数据（如像素、光谱值）来发现隐藏的全局序列。其核心创新在于：\n\n * 通用性：适用于任意一维数据（光谱、时间序列、图像行等）。\n * 自动化：自动选择最优的相似性度量和分析尺度。\n * 可解释性：输出物理意义明确的序列（如温度梯度、红移序列）。\n\n# 工作原理\n  * 核心思想：最小生成树（MST）的几何特征\n  * 关键假设：连续趋势会生成细长的MST，随机数据则产生紧凑的MST。\n  * 量化指标：伸长率（Elongation）,$\\eta=a/b$\n  a：MST平均高度（从最不连通节点到其他节点的最短路径均值）\n  b：MST平均宽度（按层级分组的节点数均值）\n  * 物理意义：$\\eta$ 越大，数据越接近一维序列。\n# 算法流程\n\n```mermaid\ngraph TD\nA[输入数据] --> B[多尺度分割]\nB --> C[多度量计算]\nC --> D[构建MST]\nD --> E[计算η值]\nE --> F[加权聚合]\nF --> G[全局MST]\nG --> H[BFS序列提取]\n```\n&emsp;&emsp;步骤详解如下：\n\n 1. 多尺度分割\n   将每个数据对象（如400像素光谱）分割为不同尺度的片段（例：从完整对象到20像素小段）。\n目的：捕获局部和全局趋势。\n 2. 多度量计算\n   对每个（尺度, 片段）组合，用4种度量计算距离矩阵：\n   * 欧氏距离（整体形状）\n   * KL散度（概率分布差异）\n   * 地球移动距离（EMD）（位移敏感）\n   * 能量距离（分布差异）\n   为什么多度量？ 不同度量揭示不同特征（如EMD检测谱线位移，欧氏距离捕捉整体形态）。\n 3. MST构建与η计算\n   对每个（度量, 尺度, 片段）生成距离矩阵$\\rightarrow$构建MST$\\rightarrow$计算伸长率$ \\eta_{klm} $。例（文章图3）：窄脉冲数据在小尺度（l=4,5）的欧氏距离获得高$\\eta$，指示局部趋势。\n 4. 信息聚合\n   * 片段聚合：对固定（度量,尺度），用$\\eta$加权平均各片段距离矩阵：$ D_{kl}=\\langle \\eta_{klm} \\cdot D_{klm}\\rangle_{m} $\n   * 全局聚合：用$\\eta$加权合并所有MST的边，构建全局邻近矩阵：\n$$ P_{combined}=\\langle \\eta_{kl}\\cdot edges(MST_{kl})\\rangle_{kl} $$\n 5. 序列提取\n   构建全局MST$\\rightarrow$从最不连通节点开始广度优先搜索（BFS），生成最终序列顺序。\n\n# 输出数据的理解\n  1. 序列顺序：输出为数据对象的有序索引列表，相邻对象在主导度量和尺度下最相似。\n  2. 物理意义：\n  * 恒星光谱（图4a）：序列对应温度梯度（顶部高温恒星→底部低温恒星）。\n  * 类星体光谱（图4b）：序列反映红移变化（谱线系统性位移）。\n  * 地震波数据（图5）：序列揭示地理结构差异（沉积盆地→火成岩区）。\n  3. 可视化建议：将重排后的数据矩阵按序列索引显示，观察连续变化模式（如移动的谱线、渐变纹理）。\n\n# 使用注意事项\n  1. 数据预处理\n    * 归一化：算法内部对每个数据段执行总和归一化（sum=1），无需额外操作。\n    * 高动态范围数据：建议对数缩放（如亮度值）避免少数像素主导。\n    * 缺失值：需插值或剔除，否则距离度量失效。\n  2. 计算优化\n    * 大数据集（$ N>10^4 $）：\n     ** 启用子采样模式（见7.3节）：\n       1. 在小样本（$N_{s}<< N$ ）构建初始序列。\n       2. 按锚点（$f_{A}N_{s}$）逐步插入剩余点。\n     ** 复杂度：从O($N^2$)降至O($N\\logN$)。\n    * 并行化：各（度量,尺度,片段）计算相互独立，可并行加速。\n  3. 结果验证\n    * 检查高$\\eta$度量：分析主导趋势的度量（如EMD指示位移，KL散度捕获分布变化）。\n    * 残差分析（见5.1节）：\n      ** 沿序列方向平滑数据$\\rightarrow$比较原始值与平滑值的残差。大残差可能指示异常点或次级趋势。\n      ** 对比降维方法：用归一化伸长率$ \\eta\\prime=\\eta/N $评估t-SNE/UMAP结果（图7,8）。\n  4. 局限性\n    * 噪声敏感：信噪比<5时趋势可能被掩盖（建议先筛选高信噪比子集）。\n    * 多维数据：算法设计为一维输入，需展平多维数据（如将图像转为行向量）。\n    * 序列唯一性：复杂数据可能存在多个有效序列（需领域知识判断主导趋势）。\n\n\n```python\nimport os\nimport glob\nimport numpy as np\nfrom obspy import read\nfrom obspy.signal.cross_correlation import correlate\nimport matplotlib.pyplot as plt\n\n# 设定文件夹路径和文件匹配模式\nfolder_path = './processed_sac/'\nfile_pattern = os.path.join(folder_path, '20111122T184816*BHZ*.sac')\nfile_list = sorted(glob.glob(file_pattern))\n\n# 设定滤波参数\nlowcut = 0.05\nhighcut = 2.0\nfilter_params = {'lowcut': lowcut, 'highcut': highcut, 'corners': 4, 'method': 'bandpass'}\n\n# 用于存储最终数据的列表\ndata_list = []\n\ndef calculate_time_shift(signal1, signal2, dt, max_shift_seconds=10):\n    \"\"\"\n    计算两个信号之间的时移，返回时移（秒）。\n    参数 max_shift_seconds 控制最大允许的滞后量。\n    \"\"\"\n    max_shift_samples = int(max_shift_seconds / dt)  # 最大允许滞后对应的样本数\n    correlation = correlate(signal1, signal2, max_shift_samples, demean=True, normalize=True)\n    lag = np.argmax(correlation) - max_shift_samples\n    lag_time = lag * dt  # 使用采样间隔转换索引为时间\n    return lag_time\n\n# 读取 SAC 文件并进行处理\nfor file in file_list:\n    # 读取 SAC 文件\n    st = read(file)\n    tr = st[0]  # 假设每个文件只有一个 Trace\n    # 获取数据和采样间隔\n    data = tr.data\n    dt = tr.stats.delta  # 采样间隔\n    # 判断是否全为零，如果是，跳过\n    if np.all(data == 0):\n        print(f\"{file} 数据全为零，跳过。\")\n        continue\n    # 滤波处理（使用 `obspy` 内建的滤波方法）\n    tr.filter(type='bandpass', freqmin=lowcut, freqmax=highcut, corners=filter_params['corners'])\n    filtered_data = tr.data  \n    # 归一化\n    depmin = np.min(filtered_data)\n    depmax = np.max(filtered_data)\n    if depmax != depmin:\n        normalized_data = (filtered_data) / (depmax - depmin)\n    else:\n        normalized_data = filtered_data  # 如果最大值等于最小值，直接使用原数据  \n    data_list.append(normalized_data)\n# 假设我们想要对第一个信号进行时移校正，将所有其他信号与第一个信号对齐\ndata=data_list\nbase_signal = data_list[0]\ntime_shifts = []\n# 对每个信号与基准信号计算时移\nfor i, signal in enumerate(data_list[1:], start=1):\n    time_shift = calculate_time_shift(base_signal, signal, dt)\n    time_shifts.append(time_shift)\n    print(f\"信号 {i+1} 与基准信号的时移: {time_shift:.4f} 秒\")\n    # 平移信号\n    shift_samples = int(round(time_shift / dt))  # 转换为样本数，并取整\n    if shift_samples > 0:\n        shifted_signal = np.concatenate((np.zeros(shift_samples), signal[:-shift_samples]))\n    elif shift_samples < 0:\n        shifted_signal = np.concatenate((signal[-shift_samples:], np.zeros(-shift_samples)))\n    else:\n        shifted_signal = signal\n    # 更新信号为平移后的信号\n    data_list[i] = shifted_signal\n# 转换成一个二维数组，方便作为 sequencer 的输入\ndata_array = np.array(data_list)\n# 打印一下结果，检查是否符合要求\nprint(data_array.shape)\nimport matplotlib.pyplot as plt\nimport sequencer\nobjects_list_simulated = np.vstack(data_array)\nnum_rows = objects_list_simulated.shape[0]\nprint(num_rows)\nshuffled_indices = np.random.permutation(num_rows)\n#shuffled_indices = np.arange(23)\nprint(shuffled_indices)\nobjects_list_shuffled = objects_list_simulated[shuffled_indices, :]\n# 确保没有零值或负值\n#objects_list_shuffled = np.maximum(objects_list_shuffled, 1e-16)  # 或者加上偏移量\n#objects_list_shuffled = np.maximum(objects_list_shuffled, 1e-16)  # 或者加上偏移量\nobjects_list_shuffled = objects_list_shuffled+1.0\n\nplt.figure(1, figsize=(10, 5))\nplt.subplot(1,2,1)\nplt.title(\"input dataset [lines]\")\nfor j, object_data in enumerate(data):\n    grid = np.arange(len(object_data))  # 创建与 object_data 长度相同的 x 轴\n    object_data_scaled_y = object_data + (j-1) *1.0  # 缩放以避免重叠\n    plt.plot(grid, object_data_scaled_y)\nplt.xlabel(\"x\")\nplt.ylabel(\"scaled intensity\")\n\nplt.subplot(1,2,2)\nplt.title(\"input dataset [heat]\")\nplt.pcolormesh(objects_list_shuffled,cmap='inferno')\nplt.colorbar()\nplt.xlabel(\"x\")\nplt.ylabel(\"original index\")\nplt.tight_layout()\n\n\n# 跑sequencer\noutput_path = \"sequencer_output_directory\"\nif not os.path.exists(output_path):\n    os.makedirs(output_path)\n# 初始化 sequencer 对象\nestimator_list = ['EMD', 'energy', 'L2']\nseq = sequencer.Sequencer(grid, objects_list_shuffled, estimator_list)\n# 执行 sequencer\nfinal_elongation, final_sequence = seq.execute(output_path)\n\n# first example\nestimator_name = 'EMD'\nscale = 1\nprint(\"Intermediate elongation for metric=%s and scale=%s: %s\" % (estimator_name, scale, \n                                                                  seq.return_elongation_of_weighted_products(estimator_name, scale)))\n# second example\nestimator_list, scale_list, elongation_list = seq.return_elongation_of_weighted_products_all_metrics_and_scales()\nfor i in range(len(estimator_list)):\n    print(\"metric=%s, scale=%s, elongation: %s\" % (estimator_list[i], \n                                                   scale_list[i], \n                                                   elongation_list[i]))\n\n# 画图\nestimator_list, scale_list, sequence_list = seq.return_sequence_of_weighted_products_all_metrics_and_scales()\n\n#fig, axs = plt.subplots(2, 2, figsize=(12, 10))\nplt.figure(1, figsize=(16, 16))\nplt.subplot(2, 2, 1)\n#plt.title(\"input dataset\")\n#plt.pcolormesh(objects_list_shuffled)\n#plt.colorbar()\n#plt.xlabel(\"x\")\n#plt.ylabel(\"original index\")\n\nfor j, object_data in enumerate(objects_list_shuffled):\n    grid = np.arange(len(object_data))  # 创建与 object_data 长度相同的 x 轴\n    object_data_scaled_y = object_data + (j-1) * 1  # 缩放以避免重叠\n    plt.plot(grid, object_data_scaled_y)\nplt.xlabel(\"x\")\nplt.ylabel(\"Original\")\n\nplt.subplot(2, 2, 2)\nplt.title(\"ordered according to\\n intermediate sequence using: \\n metric=%s, scale=%s\" % (estimator_list[0], scale_list[0]))\nsequnce = sequence_list[0]\n#plt.pcolormesh(objects_list_shuffled[sequnce])\n#plt.colorbar()\n#plt.xlabel(\"x\")\n#plt.ylabel(\"original index\")\nfor j, object_data in enumerate(objects_list_shuffled[sequnce]):\n    grid = np.arange(len(object_data))  # 创建与 object_data 长度相同的 x 轴\n    object_data_scaled_y = object_data + (j-1) * 1  # 缩放以避免重叠\n    plt.plot(grid, object_data_scaled_y)\nplt.xlabel(\"x\")\nplt.ylabel(\"Original\")\n\nplt.subplot(2, 2, 3)\nplt.title(\"ordered according to\\n intermediate sequence using: \\n metric=%s, scale=%s\" % (estimator_list[1], scale_list[1]))\nsequnce = sequence_list[1]\n#plt.pcolormesh(objects_list_shuffled[sequnce])\n#plt.colorbar()\n#plt.xlabel(\"x\")\n#plt.ylabel(\"original index\")\nfor j, object_data in enumerate(objects_list_shuffled[sequnce]):\n    grid = np.arange(len(object_data))  # 创建与 object_data 长度相同的 x 轴\n    object_data_scaled_y = object_data + (j-1) * 1  # 缩放以避免重叠\n    plt.plot(grid, object_data_scaled_y)\nplt.xlabel(\"x\")\nplt.ylabel(\"Original\")\n\nplt.subplot(2, 2, 4)\nplt.title(\"ordered according to\\n intermediate sequence using: \\n metric=%s, scale=%s\" % (estimator_list[2], scale_list[2]))\nsequnce = sequence_list[2]\n#plt.pcolormesh(objects_list_shuffled[sequnce])\n#plt.colorbar()\n#plt.xlabel(\"x\")\n#plt.ylabel(\"original index\")\nfor j, object_data in enumerate(objects_list_shuffled[sequnce]):\n    grid = np.arange(len(object_data))  # 创建与 object_data 长度相同的 x 轴\n    object_data_scaled_y = object_data + (j-1) * 1  # 缩放以避免重叠\n    plt.plot(grid, object_data_scaled_y)\nplt.xlabel(\"x\")\nplt.ylabel(\"Original\")\n\nplt.tight_layout()\n```\n","slug":"run-sequencer","published":1,"updated":"2025-06-18T03:19:47.359Z","comments":1,"layout":"post","photos":[],"_id":"cmh498iqj00d9wvougkgu3pxh","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>&emsp;&emsp;什么是Sequencer？具体请参见<a href=\"https://github.com/dalya/Sequencer/blob/master/Sequencer_paper.pdf\">这篇文章</a>。脚本在<a href=\"https://github.com/dalya/Sequencer\">这里</a>。不想看？那就看我得了。</p>\n<h1 id=\"Sequencer是什么？\"><a href=\"#Sequencer是什么？\" class=\"headerlink\" title=\"Sequencer是什么？\"></a>Sequencer是什么？</h1><p>Sequencer是一种无监督算法，旨在从复杂数据中自动识别主要的一维连续趋势。它通过分析数据对象之间的相似性图结构，无需预定义特征、参数调整或领域知识，直接处理原始数据（如像素、光谱值）来发现隐藏的全局序列。其核心创新在于：</p>\n<ul>\n<li>通用性：适用于任意一维数据（光谱、时间序列、图像行等）。</li>\n<li>自动化：自动选择最优的相似性度量和分析尺度。</li>\n<li>可解释性：输出物理意义明确的序列（如温度梯度、红移序列）。</li>\n</ul>\n<h1 id=\"工作原理\"><a href=\"#工作原理\" class=\"headerlink\" title=\"工作原理\"></a>工作原理</h1><ul>\n<li>核心思想：最小生成树（MST）的几何特征</li>\n<li>关键假设：连续趋势会生成细长的MST，随机数据则产生紧凑的MST。</li>\n<li>量化指标：伸长率（Elongation）,$\\eta&#x3D;a&#x2F;b$<br>  a：MST平均高度（从最不连通节点到其他节点的最短路径均值）<br>  b：MST平均宽度（按层级分组的节点数均值）</li>\n<li>物理意义：$\\eta$ 越大，数据越接近一维序列。</li>\n</ul>\n<h1 id=\"算法流程\"><a href=\"#算法流程\" class=\"headerlink\" title=\"算法流程\"></a>算法流程</h1><pre class=\"mermaid\">graph TD\nA[输入数据] --> B[多尺度分割]\nB --> C[多度量计算]\nC --> D[构建MST]\nD --> E[计算η值]\nE --> F[加权聚合]\nF --> G[全局MST]\nG --> H[BFS序列提取]</pre>\n<p>&emsp;&emsp;步骤详解如下：</p>\n<ol>\n<li>多尺度分割<br>   将每个数据对象（如400像素光谱）分割为不同尺度的片段（例：从完整对象到20像素小段）。<br>目的：捕获局部和全局趋势。</li>\n<li>多度量计算<br>   对每个（尺度, 片段）组合，用4种度量计算距离矩阵：</li>\n</ol>\n<ul>\n<li>欧氏距离（整体形状）</li>\n<li>KL散度（概率分布差异）</li>\n<li>地球移动距离（EMD）（位移敏感）</li>\n<li>能量距离（分布差异）<br>   为什么多度量？ 不同度量揭示不同特征（如EMD检测谱线位移，欧氏距离捕捉整体形态）。</li>\n</ul>\n<ol start=\"3\">\n<li>MST构建与η计算<br>   对每个（度量, 尺度, 片段）生成距离矩阵$\\rightarrow$构建MST$\\rightarrow$计算伸长率$ \\eta_{klm} $。例（文章图3）：窄脉冲数据在小尺度（l&#x3D;4,5）的欧氏距离获得高$\\eta$，指示局部趋势。</li>\n<li>信息聚合</li>\n</ol>\n<ul>\n<li>片段聚合：对固定（度量,尺度），用$\\eta$加权平均各片段距离矩阵：$ D_{kl}&#x3D;\\langle \\eta_{klm} \\cdot D_{klm}\\rangle_{m} $</li>\n<li>全局聚合：用$\\eta$加权合并所有MST的边，构建全局邻近矩阵：<br>$$ P_{combined}&#x3D;\\langle \\eta_{kl}\\cdot edges(MST_{kl})\\rangle_{kl} $$</li>\n</ul>\n<ol start=\"5\">\n<li>序列提取<br>   构建全局MST$\\rightarrow$从最不连通节点开始广度优先搜索（BFS），生成最终序列顺序。</li>\n</ol>\n<h1 id=\"输出数据的理解\"><a href=\"#输出数据的理解\" class=\"headerlink\" title=\"输出数据的理解\"></a>输出数据的理解</h1><ol>\n<li>序列顺序：输出为数据对象的有序索引列表，相邻对象在主导度量和尺度下最相似。</li>\n<li>物理意义：</li>\n</ol>\n<ul>\n<li>恒星光谱（图4a）：序列对应温度梯度（顶部高温恒星→底部低温恒星）。</li>\n<li>类星体光谱（图4b）：序列反映红移变化（谱线系统性位移）。</li>\n<li>地震波数据（图5）：序列揭示地理结构差异（沉积盆地→火成岩区）。</li>\n</ul>\n<ol start=\"3\">\n<li>可视化建议：将重排后的数据矩阵按序列索引显示，观察连续变化模式（如移动的谱线、渐变纹理）。</li>\n</ol>\n<h1 id=\"使用注意事项\"><a href=\"#使用注意事项\" class=\"headerlink\" title=\"使用注意事项\"></a>使用注意事项</h1><ol>\n<li>数据预处理<br>* 归一化：算法内部对每个数据段执行总和归一化（sum&#x3D;1），无需额外操作。<br>* 高动态范围数据：建议对数缩放（如亮度值）避免少数像素主导。<br>* 缺失值：需插值或剔除，否则距离度量失效。</li>\n<li>计算优化<br>* 大数据集（$ N&gt;10^4 $）：<br>** 启用子采样模式（见7.3节）：<ol>\n<li>在小样本（$N_{s}&lt;&lt; N$ ）构建初始序列。</li>\n<li>按锚点（$f_{A}N_{s}$）逐步插入剩余点。<br>** 复杂度：从O($N^2$)降至O($N\\logN$)。<br>* 并行化：各（度量,尺度,片段）计算相互独立，可并行加速。</li>\n</ol>\n</li>\n<li>结果验证<br>* 检查高$\\eta$度量：分析主导趋势的度量（如EMD指示位移，KL散度捕获分布变化）。<br>* 残差分析（见5.1节）：<br> ** 沿序列方向平滑数据$\\rightarrow$比较原始值与平滑值的残差。大残差可能指示异常点或次级趋势。<br> ** 对比降维方法：用归一化伸长率$ \\eta\\prime&#x3D;\\eta&#x2F;N $评估t-SNE&#x2F;UMAP结果（图7,8）。</li>\n<li>局限性<br>* 噪声敏感：信噪比&lt;5时趋势可能被掩盖（建议先筛选高信噪比子集）。<br>* 多维数据：算法设计为一维输入，需展平多维数据（如将图像转为行向量）。<br>* 序列唯一性：复杂数据可能存在多个有效序列（需领域知识判断主导趋势）。</li>\n</ol>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br><span class=\"line\">145</span><br><span class=\"line\">146</span><br><span class=\"line\">147</span><br><span class=\"line\">148</span><br><span class=\"line\">149</span><br><span class=\"line\">150</span><br><span class=\"line\">151</span><br><span class=\"line\">152</span><br><span class=\"line\">153</span><br><span class=\"line\">154</span><br><span class=\"line\">155</span><br><span class=\"line\">156</span><br><span class=\"line\">157</span><br><span class=\"line\">158</span><br><span class=\"line\">159</span><br><span class=\"line\">160</span><br><span class=\"line\">161</span><br><span class=\"line\">162</span><br><span class=\"line\">163</span><br><span class=\"line\">164</span><br><span class=\"line\">165</span><br><span class=\"line\">166</span><br><span class=\"line\">167</span><br><span class=\"line\">168</span><br><span class=\"line\">169</span><br><span class=\"line\">170</span><br><span class=\"line\">171</span><br><span class=\"line\">172</span><br><span class=\"line\">173</span><br><span class=\"line\">174</span><br><span class=\"line\">175</span><br><span class=\"line\">176</span><br><span class=\"line\">177</span><br><span class=\"line\">178</span><br><span class=\"line\">179</span><br><span class=\"line\">180</span><br><span class=\"line\">181</span><br><span class=\"line\">182</span><br><span class=\"line\">183</span><br><span class=\"line\">184</span><br><span class=\"line\">185</span><br><span class=\"line\">186</span><br><span class=\"line\">187</span><br><span class=\"line\">188</span><br><span class=\"line\">189</span><br><span class=\"line\">190</span><br><span class=\"line\">191</span><br><span class=\"line\">192</span><br><span class=\"line\">193</span><br><span class=\"line\">194</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\"><span class=\"keyword\">import</span> glob</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">from</span> obspy <span class=\"keyword\">import</span> read</span><br><span class=\"line\"><span class=\"keyword\">from</span> obspy.signal.cross_correlation <span class=\"keyword\">import</span> correlate</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 设定文件夹路径和文件匹配模式</span></span><br><span class=\"line\">folder_path = <span class=\"string\">&#x27;./processed_sac/&#x27;</span></span><br><span class=\"line\">file_pattern = os.path.join(folder_path, <span class=\"string\">&#x27;20111122T184816*BHZ*.sac&#x27;</span>)</span><br><span class=\"line\">file_list = <span class=\"built_in\">sorted</span>(glob.glob(file_pattern))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 设定滤波参数</span></span><br><span class=\"line\">lowcut = <span class=\"number\">0.05</span></span><br><span class=\"line\">highcut = <span class=\"number\">2.0</span></span><br><span class=\"line\">filter_params = &#123;<span class=\"string\">&#x27;lowcut&#x27;</span>: lowcut, <span class=\"string\">&#x27;highcut&#x27;</span>: highcut, <span class=\"string\">&#x27;corners&#x27;</span>: <span class=\"number\">4</span>, <span class=\"string\">&#x27;method&#x27;</span>: <span class=\"string\">&#x27;bandpass&#x27;</span>&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 用于存储最终数据的列表</span></span><br><span class=\"line\">data_list = []</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">calculate_time_shift</span>(<span class=\"params\">signal1, signal2, dt, max_shift_seconds=<span class=\"number\">10</span></span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;</span></span><br><span class=\"line\"><span class=\"string\">    计算两个信号之间的时移，返回时移（秒）。</span></span><br><span class=\"line\"><span class=\"string\">    参数 max_shift_seconds 控制最大允许的滞后量。</span></span><br><span class=\"line\"><span class=\"string\">    &quot;&quot;&quot;</span></span><br><span class=\"line\">    max_shift_samples = <span class=\"built_in\">int</span>(max_shift_seconds / dt)  <span class=\"comment\"># 最大允许滞后对应的样本数</span></span><br><span class=\"line\">    correlation = correlate(signal1, signal2, max_shift_samples, demean=<span class=\"literal\">True</span>, normalize=<span class=\"literal\">True</span>)</span><br><span class=\"line\">    lag = np.argmax(correlation) - max_shift_samples</span><br><span class=\"line\">    lag_time = lag * dt  <span class=\"comment\"># 使用采样间隔转换索引为时间</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> lag_time</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 读取 SAC 文件并进行处理</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> file <span class=\"keyword\">in</span> file_list:</span><br><span class=\"line\">    <span class=\"comment\"># 读取 SAC 文件</span></span><br><span class=\"line\">    st = read(file)</span><br><span class=\"line\">    tr = st[<span class=\"number\">0</span>]  <span class=\"comment\"># 假设每个文件只有一个 Trace</span></span><br><span class=\"line\">    <span class=\"comment\"># 获取数据和采样间隔</span></span><br><span class=\"line\">    data = tr.data</span><br><span class=\"line\">    dt = tr.stats.delta  <span class=\"comment\"># 采样间隔</span></span><br><span class=\"line\">    <span class=\"comment\"># 判断是否全为零，如果是，跳过</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> np.<span class=\"built_in\">all</span>(data == <span class=\"number\">0</span>):</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;<span class=\"subst\">&#123;file&#125;</span> 数据全为零，跳过。&quot;</span>)</span><br><span class=\"line\">        <span class=\"keyword\">continue</span></span><br><span class=\"line\">    <span class=\"comment\"># 滤波处理（使用 `obspy` 内建的滤波方法）</span></span><br><span class=\"line\">    tr.<span class=\"built_in\">filter</span>(<span class=\"built_in\">type</span>=<span class=\"string\">&#x27;bandpass&#x27;</span>, freqmin=lowcut, freqmax=highcut, corners=filter_params[<span class=\"string\">&#x27;corners&#x27;</span>])</span><br><span class=\"line\">    filtered_data = tr.data  </span><br><span class=\"line\">    <span class=\"comment\"># 归一化</span></span><br><span class=\"line\">    depmin = np.<span class=\"built_in\">min</span>(filtered_data)</span><br><span class=\"line\">    depmax = np.<span class=\"built_in\">max</span>(filtered_data)</span><br><span class=\"line\">    <span class=\"keyword\">if</span> depmax != depmin:</span><br><span class=\"line\">        normalized_data = (filtered_data) / (depmax - depmin)</span><br><span class=\"line\">    <span class=\"keyword\">else</span>:</span><br><span class=\"line\">        normalized_data = filtered_data  <span class=\"comment\"># 如果最大值等于最小值，直接使用原数据  </span></span><br><span class=\"line\">    data_list.append(normalized_data)</span><br><span class=\"line\"><span class=\"comment\"># 假设我们想要对第一个信号进行时移校正，将所有其他信号与第一个信号对齐</span></span><br><span class=\"line\">data=data_list</span><br><span class=\"line\">base_signal = data_list[<span class=\"number\">0</span>]</span><br><span class=\"line\">time_shifts = []</span><br><span class=\"line\"><span class=\"comment\"># 对每个信号与基准信号计算时移</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> i, signal <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(data_list[<span class=\"number\">1</span>:], start=<span class=\"number\">1</span>):</span><br><span class=\"line\">    time_shift = calculate_time_shift(base_signal, signal, dt)</span><br><span class=\"line\">    time_shifts.append(time_shift)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;信号 <span class=\"subst\">&#123;i+<span class=\"number\">1</span>&#125;</span> 与基准信号的时移: <span class=\"subst\">&#123;time_shift:<span class=\"number\">.4</span>f&#125;</span> 秒&quot;</span>)</span><br><span class=\"line\">    <span class=\"comment\"># 平移信号</span></span><br><span class=\"line\">    shift_samples = <span class=\"built_in\">int</span>(<span class=\"built_in\">round</span>(time_shift / dt))  <span class=\"comment\"># 转换为样本数，并取整</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> shift_samples &gt; <span class=\"number\">0</span>:</span><br><span class=\"line\">        shifted_signal = np.concatenate((np.zeros(shift_samples), signal[:-shift_samples]))</span><br><span class=\"line\">    <span class=\"keyword\">elif</span> shift_samples &lt; <span class=\"number\">0</span>:</span><br><span class=\"line\">        shifted_signal = np.concatenate((signal[-shift_samples:], np.zeros(-shift_samples)))</span><br><span class=\"line\">    <span class=\"keyword\">else</span>:</span><br><span class=\"line\">        shifted_signal = signal</span><br><span class=\"line\">    <span class=\"comment\"># 更新信号为平移后的信号</span></span><br><span class=\"line\">    data_list[i] = shifted_signal</span><br><span class=\"line\"><span class=\"comment\"># 转换成一个二维数组，方便作为 sequencer 的输入</span></span><br><span class=\"line\">data_array = np.array(data_list)</span><br><span class=\"line\"><span class=\"comment\"># 打印一下结果，检查是否符合要求</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(data_array.shape)</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">import</span> sequencer</span><br><span class=\"line\">objects_list_simulated = np.vstack(data_array)</span><br><span class=\"line\">num_rows = objects_list_simulated.shape[<span class=\"number\">0</span>]</span><br><span class=\"line\"><span class=\"built_in\">print</span>(num_rows)</span><br><span class=\"line\">shuffled_indices = np.random.permutation(num_rows)</span><br><span class=\"line\"><span class=\"comment\">#shuffled_indices = np.arange(23)</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(shuffled_indices)</span><br><span class=\"line\">objects_list_shuffled = objects_list_simulated[shuffled_indices, :]</span><br><span class=\"line\"><span class=\"comment\"># 确保没有零值或负值</span></span><br><span class=\"line\"><span class=\"comment\">#objects_list_shuffled = np.maximum(objects_list_shuffled, 1e-16)  # 或者加上偏移量</span></span><br><span class=\"line\"><span class=\"comment\">#objects_list_shuffled = np.maximum(objects_list_shuffled, 1e-16)  # 或者加上偏移量</span></span><br><span class=\"line\">objects_list_shuffled = objects_list_shuffled+<span class=\"number\">1.0</span></span><br><span class=\"line\"></span><br><span class=\"line\">plt.figure(<span class=\"number\">1</span>, figsize=(<span class=\"number\">10</span>, <span class=\"number\">5</span>))</span><br><span class=\"line\">plt.subplot(<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">1</span>)</span><br><span class=\"line\">plt.title(<span class=\"string\">&quot;input dataset [lines]&quot;</span>)</span><br><span class=\"line\"><span class=\"keyword\">for</span> j, object_data <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(data):</span><br><span class=\"line\">    grid = np.arange(<span class=\"built_in\">len</span>(object_data))  <span class=\"comment\"># 创建与 object_data 长度相同的 x 轴</span></span><br><span class=\"line\">    object_data_scaled_y = object_data + (j-<span class=\"number\">1</span>) *<span class=\"number\">1.0</span>  <span class=\"comment\"># 缩放以避免重叠</span></span><br><span class=\"line\">    plt.plot(grid, object_data_scaled_y)</span><br><span class=\"line\">plt.xlabel(<span class=\"string\">&quot;x&quot;</span>)</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">&quot;scaled intensity&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">plt.subplot(<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">2</span>)</span><br><span class=\"line\">plt.title(<span class=\"string\">&quot;input dataset [heat]&quot;</span>)</span><br><span class=\"line\">plt.pcolormesh(objects_list_shuffled,cmap=<span class=\"string\">&#x27;inferno&#x27;</span>)</span><br><span class=\"line\">plt.colorbar()</span><br><span class=\"line\">plt.xlabel(<span class=\"string\">&quot;x&quot;</span>)</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">&quot;original index&quot;</span>)</span><br><span class=\"line\">plt.tight_layout()</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 跑sequencer</span></span><br><span class=\"line\">output_path = <span class=\"string\">&quot;sequencer_output_directory&quot;</span></span><br><span class=\"line\"><span class=\"keyword\">if</span> <span class=\"keyword\">not</span> os.path.exists(output_path):</span><br><span class=\"line\">    os.makedirs(output_path)</span><br><span class=\"line\"><span class=\"comment\"># 初始化 sequencer 对象</span></span><br><span class=\"line\">estimator_list = [<span class=\"string\">&#x27;EMD&#x27;</span>, <span class=\"string\">&#x27;energy&#x27;</span>, <span class=\"string\">&#x27;L2&#x27;</span>]</span><br><span class=\"line\">seq = sequencer.Sequencer(grid, objects_list_shuffled, estimator_list)</span><br><span class=\"line\"><span class=\"comment\"># 执行 sequencer</span></span><br><span class=\"line\">final_elongation, final_sequence = seq.execute(output_path)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># first example</span></span><br><span class=\"line\">estimator_name = <span class=\"string\">&#x27;EMD&#x27;</span></span><br><span class=\"line\">scale = <span class=\"number\">1</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&quot;Intermediate elongation for metric=%s and scale=%s: %s&quot;</span> % (estimator_name, scale, </span><br><span class=\"line\">                                                                  seq.return_elongation_of_weighted_products(estimator_name, scale)))</span><br><span class=\"line\"><span class=\"comment\"># second example</span></span><br><span class=\"line\">estimator_list, scale_list, elongation_list = seq.return_elongation_of_weighted_products_all_metrics_and_scales()</span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"built_in\">len</span>(estimator_list)):</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&quot;metric=%s, scale=%s, elongation: %s&quot;</span> % (estimator_list[i], </span><br><span class=\"line\">                                                   scale_list[i], </span><br><span class=\"line\">                                                   elongation_list[i]))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 画图</span></span><br><span class=\"line\">estimator_list, scale_list, sequence_list = seq.return_sequence_of_weighted_products_all_metrics_and_scales()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#fig, axs = plt.subplots(2, 2, figsize=(12, 10))</span></span><br><span class=\"line\">plt.figure(<span class=\"number\">1</span>, figsize=(<span class=\"number\">16</span>, <span class=\"number\">16</span>))</span><br><span class=\"line\">plt.subplot(<span class=\"number\">2</span>, <span class=\"number\">2</span>, <span class=\"number\">1</span>)</span><br><span class=\"line\"><span class=\"comment\">#plt.title(&quot;input dataset&quot;)</span></span><br><span class=\"line\"><span class=\"comment\">#plt.pcolormesh(objects_list_shuffled)</span></span><br><span class=\"line\"><span class=\"comment\">#plt.colorbar()</span></span><br><span class=\"line\"><span class=\"comment\">#plt.xlabel(&quot;x&quot;)</span></span><br><span class=\"line\"><span class=\"comment\">#plt.ylabel(&quot;original index&quot;)</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> j, object_data <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(objects_list_shuffled):</span><br><span class=\"line\">    grid = np.arange(<span class=\"built_in\">len</span>(object_data))  <span class=\"comment\"># 创建与 object_data 长度相同的 x 轴</span></span><br><span class=\"line\">    object_data_scaled_y = object_data + (j-<span class=\"number\">1</span>) * <span class=\"number\">1</span>  <span class=\"comment\"># 缩放以避免重叠</span></span><br><span class=\"line\">    plt.plot(grid, object_data_scaled_y)</span><br><span class=\"line\">plt.xlabel(<span class=\"string\">&quot;x&quot;</span>)</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">&quot;Original&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">plt.subplot(<span class=\"number\">2</span>, <span class=\"number\">2</span>, <span class=\"number\">2</span>)</span><br><span class=\"line\">plt.title(<span class=\"string\">&quot;ordered according to\\n intermediate sequence using: \\n metric=%s, scale=%s&quot;</span> % (estimator_list[<span class=\"number\">0</span>], scale_list[<span class=\"number\">0</span>]))</span><br><span class=\"line\">sequnce = sequence_list[<span class=\"number\">0</span>]</span><br><span class=\"line\"><span class=\"comment\">#plt.pcolormesh(objects_list_shuffled[sequnce])</span></span><br><span class=\"line\"><span class=\"comment\">#plt.colorbar()</span></span><br><span class=\"line\"><span class=\"comment\">#plt.xlabel(&quot;x&quot;)</span></span><br><span class=\"line\"><span class=\"comment\">#plt.ylabel(&quot;original index&quot;)</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> j, object_data <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(objects_list_shuffled[sequnce]):</span><br><span class=\"line\">    grid = np.arange(<span class=\"built_in\">len</span>(object_data))  <span class=\"comment\"># 创建与 object_data 长度相同的 x 轴</span></span><br><span class=\"line\">    object_data_scaled_y = object_data + (j-<span class=\"number\">1</span>) * <span class=\"number\">1</span>  <span class=\"comment\"># 缩放以避免重叠</span></span><br><span class=\"line\">    plt.plot(grid, object_data_scaled_y)</span><br><span class=\"line\">plt.xlabel(<span class=\"string\">&quot;x&quot;</span>)</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">&quot;Original&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">plt.subplot(<span class=\"number\">2</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>)</span><br><span class=\"line\">plt.title(<span class=\"string\">&quot;ordered according to\\n intermediate sequence using: \\n metric=%s, scale=%s&quot;</span> % (estimator_list[<span class=\"number\">1</span>], scale_list[<span class=\"number\">1</span>]))</span><br><span class=\"line\">sequnce = sequence_list[<span class=\"number\">1</span>]</span><br><span class=\"line\"><span class=\"comment\">#plt.pcolormesh(objects_list_shuffled[sequnce])</span></span><br><span class=\"line\"><span class=\"comment\">#plt.colorbar()</span></span><br><span class=\"line\"><span class=\"comment\">#plt.xlabel(&quot;x&quot;)</span></span><br><span class=\"line\"><span class=\"comment\">#plt.ylabel(&quot;original index&quot;)</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> j, object_data <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(objects_list_shuffled[sequnce]):</span><br><span class=\"line\">    grid = np.arange(<span class=\"built_in\">len</span>(object_data))  <span class=\"comment\"># 创建与 object_data 长度相同的 x 轴</span></span><br><span class=\"line\">    object_data_scaled_y = object_data + (j-<span class=\"number\">1</span>) * <span class=\"number\">1</span>  <span class=\"comment\"># 缩放以避免重叠</span></span><br><span class=\"line\">    plt.plot(grid, object_data_scaled_y)</span><br><span class=\"line\">plt.xlabel(<span class=\"string\">&quot;x&quot;</span>)</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">&quot;Original&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">plt.subplot(<span class=\"number\">2</span>, <span class=\"number\">2</span>, <span class=\"number\">4</span>)</span><br><span class=\"line\">plt.title(<span class=\"string\">&quot;ordered according to\\n intermediate sequence using: \\n metric=%s, scale=%s&quot;</span> % (estimator_list[<span class=\"number\">2</span>], scale_list[<span class=\"number\">2</span>]))</span><br><span class=\"line\">sequnce = sequence_list[<span class=\"number\">2</span>]</span><br><span class=\"line\"><span class=\"comment\">#plt.pcolormesh(objects_list_shuffled[sequnce])</span></span><br><span class=\"line\"><span class=\"comment\">#plt.colorbar()</span></span><br><span class=\"line\"><span class=\"comment\">#plt.xlabel(&quot;x&quot;)</span></span><br><span class=\"line\"><span class=\"comment\">#plt.ylabel(&quot;original index&quot;)</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> j, object_data <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(objects_list_shuffled[sequnce]):</span><br><span class=\"line\">    grid = np.arange(<span class=\"built_in\">len</span>(object_data))  <span class=\"comment\"># 创建与 object_data 长度相同的 x 轴</span></span><br><span class=\"line\">    object_data_scaled_y = object_data + (j-<span class=\"number\">1</span>) * <span class=\"number\">1</span>  <span class=\"comment\"># 缩放以避免重叠</span></span><br><span class=\"line\">    plt.plot(grid, object_data_scaled_y)</span><br><span class=\"line\">plt.xlabel(<span class=\"string\">&quot;x&quot;</span>)</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">&quot;Original&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">plt.tight_layout()</span><br></pre></td></tr></table></figure>","related_posts":["latex-math-express.html"],"length":8609,"excerpt":"<p>&emsp;&emsp;今天学习Sequencer。</p>","more":"<p>&emsp;&emsp;什么是Sequencer？具体请参见<a href=\"https://github.com/dalya/Sequencer/blob/master/Sequencer_paper.pdf\">这篇文章</a>。脚本在<a href=\"https://github.com/dalya/Sequencer\">这里</a>。不想看？那就看我得了。</p>\n<h1 id=\"Sequencer是什么？\"><a href=\"#Sequencer是什么？\" class=\"headerlink\" title=\"Sequencer是什么？\"></a>Sequencer是什么？</h1><p>Sequencer是一种无监督算法，旨在从复杂数据中自动识别主要的一维连续趋势。它通过分析数据对象之间的相似性图结构，无需预定义特征、参数调整或领域知识，直接处理原始数据（如像素、光谱值）来发现隐藏的全局序列。其核心创新在于：</p>\n<ul>\n<li>通用性：适用于任意一维数据（光谱、时间序列、图像行等）。</li>\n<li>自动化：自动选择最优的相似性度量和分析尺度。</li>\n<li>可解释性：输出物理意义明确的序列（如温度梯度、红移序列）。</li>\n</ul>\n<h1 id=\"工作原理\"><a href=\"#工作原理\" class=\"headerlink\" title=\"工作原理\"></a>工作原理</h1><ul>\n<li>核心思想：最小生成树（MST）的几何特征</li>\n<li>关键假设：连续趋势会生成细长的MST，随机数据则产生紧凑的MST。</li>\n<li>量化指标：伸长率（Elongation）,$\\eta&#x3D;a&#x2F;b$<br>  a：MST平均高度（从最不连通节点到其他节点的最短路径均值）<br>  b：MST平均宽度（按层级分组的节点数均值）</li>\n<li>物理意义：$\\eta$ 越大，数据越接近一维序列。</li>\n</ul>\n<h1 id=\"算法流程\"><a href=\"#算法流程\" class=\"headerlink\" title=\"算法流程\"></a>算法流程</h1><pre class=\"mermaid\">graph TD\nA[输入数据] --> B[多尺度分割]\nB --> C[多度量计算]\nC --> D[构建MST]\nD --> E[计算η值]\nE --> F[加权聚合]\nF --> G[全局MST]\nG --> H[BFS序列提取]</pre>\n<p>&emsp;&emsp;步骤详解如下：</p>\n<ol>\n<li>多尺度分割<br>   将每个数据对象（如400像素光谱）分割为不同尺度的片段（例：从完整对象到20像素小段）。<br>目的：捕获局部和全局趋势。</li>\n<li>多度量计算<br>   对每个（尺度, 片段）组合，用4种度量计算距离矩阵：</li>\n</ol>\n<ul>\n<li>欧氏距离（整体形状）</li>\n<li>KL散度（概率分布差异）</li>\n<li>地球移动距离（EMD）（位移敏感）</li>\n<li>能量距离（分布差异）<br>   为什么多度量？ 不同度量揭示不同特征（如EMD检测谱线位移，欧氏距离捕捉整体形态）。</li>\n</ul>\n<ol start=\"3\">\n<li>MST构建与η计算<br>   对每个（度量, 尺度, 片段）生成距离矩阵$\\rightarrow$构建MST$\\rightarrow$计算伸长率$ \\eta_{klm} $。例（文章图3）：窄脉冲数据在小尺度（l&#x3D;4,5）的欧氏距离获得高$\\eta$，指示局部趋势。</li>\n<li>信息聚合</li>\n</ol>\n<ul>\n<li>片段聚合：对固定（度量,尺度），用$\\eta$加权平均各片段距离矩阵：$ D_{kl}&#x3D;\\langle \\eta_{klm} \\cdot D_{klm}\\rangle_{m} $</li>\n<li>全局聚合：用$\\eta$加权合并所有MST的边，构建全局邻近矩阵：<br>$$ P_{combined}&#x3D;\\langle \\eta_{kl}\\cdot edges(MST_{kl})\\rangle_{kl} $$</li>\n</ul>\n<ol start=\"5\">\n<li>序列提取<br>   构建全局MST$\\rightarrow$从最不连通节点开始广度优先搜索（BFS），生成最终序列顺序。</li>\n</ol>\n<h1 id=\"输出数据的理解\"><a href=\"#输出数据的理解\" class=\"headerlink\" title=\"输出数据的理解\"></a>输出数据的理解</h1><ol>\n<li>序列顺序：输出为数据对象的有序索引列表，相邻对象在主导度量和尺度下最相似。</li>\n<li>物理意义：</li>\n</ol>\n<ul>\n<li>恒星光谱（图4a）：序列对应温度梯度（顶部高温恒星→底部低温恒星）。</li>\n<li>类星体光谱（图4b）：序列反映红移变化（谱线系统性位移）。</li>\n<li>地震波数据（图5）：序列揭示地理结构差异（沉积盆地→火成岩区）。</li>\n</ul>\n<ol start=\"3\">\n<li>可视化建议：将重排后的数据矩阵按序列索引显示，观察连续变化模式（如移动的谱线、渐变纹理）。</li>\n</ol>\n<h1 id=\"使用注意事项\"><a href=\"#使用注意事项\" class=\"headerlink\" title=\"使用注意事项\"></a>使用注意事项</h1><ol>\n<li>数据预处理<br>* 归一化：算法内部对每个数据段执行总和归一化（sum&#x3D;1），无需额外操作。<br>* 高动态范围数据：建议对数缩放（如亮度值）避免少数像素主导。<br>* 缺失值：需插值或剔除，否则距离度量失效。</li>\n<li>计算优化<br>* 大数据集（$ N&gt;10^4 $）：<br>** 启用子采样模式（见7.3节）：<ol>\n<li>在小样本（$N_{s}&lt;&lt; N$ ）构建初始序列。</li>\n<li>按锚点（$f_{A}N_{s}$）逐步插入剩余点。<br>** 复杂度：从O($N^2$)降至O($N\\logN$)。<br>* 并行化：各（度量,尺度,片段）计算相互独立，可并行加速。</li>\n</ol>\n</li>\n<li>结果验证<br>* 检查高$\\eta$度量：分析主导趋势的度量（如EMD指示位移，KL散度捕获分布变化）。<br>* 残差分析（见5.1节）：<br> ** 沿序列方向平滑数据$\\rightarrow$比较原始值与平滑值的残差。大残差可能指示异常点或次级趋势。<br> ** 对比降维方法：用归一化伸长率$ \\eta\\prime&#x3D;\\eta&#x2F;N $评估t-SNE&#x2F;UMAP结果（图7,8）。</li>\n<li>局限性<br>* 噪声敏感：信噪比&lt;5时趋势可能被掩盖（建议先筛选高信噪比子集）。<br>* 多维数据：算法设计为一维输入，需展平多维数据（如将图像转为行向量）。<br>* 序列唯一性：复杂数据可能存在多个有效序列（需领域知识判断主导趋势）。</li>\n</ol>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br><span class=\"line\">145</span><br><span class=\"line\">146</span><br><span class=\"line\">147</span><br><span class=\"line\">148</span><br><span class=\"line\">149</span><br><span class=\"line\">150</span><br><span class=\"line\">151</span><br><span class=\"line\">152</span><br><span class=\"line\">153</span><br><span class=\"line\">154</span><br><span class=\"line\">155</span><br><span class=\"line\">156</span><br><span class=\"line\">157</span><br><span class=\"line\">158</span><br><span class=\"line\">159</span><br><span class=\"line\">160</span><br><span class=\"line\">161</span><br><span class=\"line\">162</span><br><span class=\"line\">163</span><br><span class=\"line\">164</span><br><span class=\"line\">165</span><br><span class=\"line\">166</span><br><span class=\"line\">167</span><br><span class=\"line\">168</span><br><span class=\"line\">169</span><br><span class=\"line\">170</span><br><span class=\"line\">171</span><br><span class=\"line\">172</span><br><span class=\"line\">173</span><br><span class=\"line\">174</span><br><span class=\"line\">175</span><br><span class=\"line\">176</span><br><span class=\"line\">177</span><br><span class=\"line\">178</span><br><span class=\"line\">179</span><br><span class=\"line\">180</span><br><span class=\"line\">181</span><br><span class=\"line\">182</span><br><span class=\"line\">183</span><br><span class=\"line\">184</span><br><span class=\"line\">185</span><br><span class=\"line\">186</span><br><span class=\"line\">187</span><br><span class=\"line\">188</span><br><span class=\"line\">189</span><br><span class=\"line\">190</span><br><span class=\"line\">191</span><br><span class=\"line\">192</span><br><span class=\"line\">193</span><br><span class=\"line\">194</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\"><span class=\"keyword\">import</span> glob</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">from</span> obspy <span class=\"keyword\">import</span> read</span><br><span class=\"line\"><span class=\"keyword\">from</span> obspy.signal.cross_correlation <span class=\"keyword\">import</span> correlate</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 设定文件夹路径和文件匹配模式</span></span><br><span class=\"line\">folder_path = <span class=\"string\">&#x27;./processed_sac/&#x27;</span></span><br><span class=\"line\">file_pattern = os.path.join(folder_path, <span class=\"string\">&#x27;20111122T184816*BHZ*.sac&#x27;</span>)</span><br><span class=\"line\">file_list = <span class=\"built_in\">sorted</span>(glob.glob(file_pattern))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 设定滤波参数</span></span><br><span class=\"line\">lowcut = <span class=\"number\">0.05</span></span><br><span class=\"line\">highcut = <span class=\"number\">2.0</span></span><br><span class=\"line\">filter_params = &#123;<span class=\"string\">&#x27;lowcut&#x27;</span>: lowcut, <span class=\"string\">&#x27;highcut&#x27;</span>: highcut, <span class=\"string\">&#x27;corners&#x27;</span>: <span class=\"number\">4</span>, <span class=\"string\">&#x27;method&#x27;</span>: <span class=\"string\">&#x27;bandpass&#x27;</span>&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 用于存储最终数据的列表</span></span><br><span class=\"line\">data_list = []</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">calculate_time_shift</span>(<span class=\"params\">signal1, signal2, dt, max_shift_seconds=<span class=\"number\">10</span></span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;</span></span><br><span class=\"line\"><span class=\"string\">    计算两个信号之间的时移，返回时移（秒）。</span></span><br><span class=\"line\"><span class=\"string\">    参数 max_shift_seconds 控制最大允许的滞后量。</span></span><br><span class=\"line\"><span class=\"string\">    &quot;&quot;&quot;</span></span><br><span class=\"line\">    max_shift_samples = <span class=\"built_in\">int</span>(max_shift_seconds / dt)  <span class=\"comment\"># 最大允许滞后对应的样本数</span></span><br><span class=\"line\">    correlation = correlate(signal1, signal2, max_shift_samples, demean=<span class=\"literal\">True</span>, normalize=<span class=\"literal\">True</span>)</span><br><span class=\"line\">    lag = np.argmax(correlation) - max_shift_samples</span><br><span class=\"line\">    lag_time = lag * dt  <span class=\"comment\"># 使用采样间隔转换索引为时间</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> lag_time</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 读取 SAC 文件并进行处理</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> file <span class=\"keyword\">in</span> file_list:</span><br><span class=\"line\">    <span class=\"comment\"># 读取 SAC 文件</span></span><br><span class=\"line\">    st = read(file)</span><br><span class=\"line\">    tr = st[<span class=\"number\">0</span>]  <span class=\"comment\"># 假设每个文件只有一个 Trace</span></span><br><span class=\"line\">    <span class=\"comment\"># 获取数据和采样间隔</span></span><br><span class=\"line\">    data = tr.data</span><br><span class=\"line\">    dt = tr.stats.delta  <span class=\"comment\"># 采样间隔</span></span><br><span class=\"line\">    <span class=\"comment\"># 判断是否全为零，如果是，跳过</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> np.<span class=\"built_in\">all</span>(data == <span class=\"number\">0</span>):</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;<span class=\"subst\">&#123;file&#125;</span> 数据全为零，跳过。&quot;</span>)</span><br><span class=\"line\">        <span class=\"keyword\">continue</span></span><br><span class=\"line\">    <span class=\"comment\"># 滤波处理（使用 `obspy` 内建的滤波方法）</span></span><br><span class=\"line\">    tr.<span class=\"built_in\">filter</span>(<span class=\"built_in\">type</span>=<span class=\"string\">&#x27;bandpass&#x27;</span>, freqmin=lowcut, freqmax=highcut, corners=filter_params[<span class=\"string\">&#x27;corners&#x27;</span>])</span><br><span class=\"line\">    filtered_data = tr.data  </span><br><span class=\"line\">    <span class=\"comment\"># 归一化</span></span><br><span class=\"line\">    depmin = np.<span class=\"built_in\">min</span>(filtered_data)</span><br><span class=\"line\">    depmax = np.<span class=\"built_in\">max</span>(filtered_data)</span><br><span class=\"line\">    <span class=\"keyword\">if</span> depmax != depmin:</span><br><span class=\"line\">        normalized_data = (filtered_data) / (depmax - depmin)</span><br><span class=\"line\">    <span class=\"keyword\">else</span>:</span><br><span class=\"line\">        normalized_data = filtered_data  <span class=\"comment\"># 如果最大值等于最小值，直接使用原数据  </span></span><br><span class=\"line\">    data_list.append(normalized_data)</span><br><span class=\"line\"><span class=\"comment\"># 假设我们想要对第一个信号进行时移校正，将所有其他信号与第一个信号对齐</span></span><br><span class=\"line\">data=data_list</span><br><span class=\"line\">base_signal = data_list[<span class=\"number\">0</span>]</span><br><span class=\"line\">time_shifts = []</span><br><span class=\"line\"><span class=\"comment\"># 对每个信号与基准信号计算时移</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> i, signal <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(data_list[<span class=\"number\">1</span>:], start=<span class=\"number\">1</span>):</span><br><span class=\"line\">    time_shift = calculate_time_shift(base_signal, signal, dt)</span><br><span class=\"line\">    time_shifts.append(time_shift)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;信号 <span class=\"subst\">&#123;i+<span class=\"number\">1</span>&#125;</span> 与基准信号的时移: <span class=\"subst\">&#123;time_shift:<span class=\"number\">.4</span>f&#125;</span> 秒&quot;</span>)</span><br><span class=\"line\">    <span class=\"comment\"># 平移信号</span></span><br><span class=\"line\">    shift_samples = <span class=\"built_in\">int</span>(<span class=\"built_in\">round</span>(time_shift / dt))  <span class=\"comment\"># 转换为样本数，并取整</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> shift_samples &gt; <span class=\"number\">0</span>:</span><br><span class=\"line\">        shifted_signal = np.concatenate((np.zeros(shift_samples), signal[:-shift_samples]))</span><br><span class=\"line\">    <span class=\"keyword\">elif</span> shift_samples &lt; <span class=\"number\">0</span>:</span><br><span class=\"line\">        shifted_signal = np.concatenate((signal[-shift_samples:], np.zeros(-shift_samples)))</span><br><span class=\"line\">    <span class=\"keyword\">else</span>:</span><br><span class=\"line\">        shifted_signal = signal</span><br><span class=\"line\">    <span class=\"comment\"># 更新信号为平移后的信号</span></span><br><span class=\"line\">    data_list[i] = shifted_signal</span><br><span class=\"line\"><span class=\"comment\"># 转换成一个二维数组，方便作为 sequencer 的输入</span></span><br><span class=\"line\">data_array = np.array(data_list)</span><br><span class=\"line\"><span class=\"comment\"># 打印一下结果，检查是否符合要求</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(data_array.shape)</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">import</span> sequencer</span><br><span class=\"line\">objects_list_simulated = np.vstack(data_array)</span><br><span class=\"line\">num_rows = objects_list_simulated.shape[<span class=\"number\">0</span>]</span><br><span class=\"line\"><span class=\"built_in\">print</span>(num_rows)</span><br><span class=\"line\">shuffled_indices = np.random.permutation(num_rows)</span><br><span class=\"line\"><span class=\"comment\">#shuffled_indices = np.arange(23)</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(shuffled_indices)</span><br><span class=\"line\">objects_list_shuffled = objects_list_simulated[shuffled_indices, :]</span><br><span class=\"line\"><span class=\"comment\"># 确保没有零值或负值</span></span><br><span class=\"line\"><span class=\"comment\">#objects_list_shuffled = np.maximum(objects_list_shuffled, 1e-16)  # 或者加上偏移量</span></span><br><span class=\"line\"><span class=\"comment\">#objects_list_shuffled = np.maximum(objects_list_shuffled, 1e-16)  # 或者加上偏移量</span></span><br><span class=\"line\">objects_list_shuffled = objects_list_shuffled+<span class=\"number\">1.0</span></span><br><span class=\"line\"></span><br><span class=\"line\">plt.figure(<span class=\"number\">1</span>, figsize=(<span class=\"number\">10</span>, <span class=\"number\">5</span>))</span><br><span class=\"line\">plt.subplot(<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">1</span>)</span><br><span class=\"line\">plt.title(<span class=\"string\">&quot;input dataset [lines]&quot;</span>)</span><br><span class=\"line\"><span class=\"keyword\">for</span> j, object_data <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(data):</span><br><span class=\"line\">    grid = np.arange(<span class=\"built_in\">len</span>(object_data))  <span class=\"comment\"># 创建与 object_data 长度相同的 x 轴</span></span><br><span class=\"line\">    object_data_scaled_y = object_data + (j-<span class=\"number\">1</span>) *<span class=\"number\">1.0</span>  <span class=\"comment\"># 缩放以避免重叠</span></span><br><span class=\"line\">    plt.plot(grid, object_data_scaled_y)</span><br><span class=\"line\">plt.xlabel(<span class=\"string\">&quot;x&quot;</span>)</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">&quot;scaled intensity&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">plt.subplot(<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">2</span>)</span><br><span class=\"line\">plt.title(<span class=\"string\">&quot;input dataset [heat]&quot;</span>)</span><br><span class=\"line\">plt.pcolormesh(objects_list_shuffled,cmap=<span class=\"string\">&#x27;inferno&#x27;</span>)</span><br><span class=\"line\">plt.colorbar()</span><br><span class=\"line\">plt.xlabel(<span class=\"string\">&quot;x&quot;</span>)</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">&quot;original index&quot;</span>)</span><br><span class=\"line\">plt.tight_layout()</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 跑sequencer</span></span><br><span class=\"line\">output_path = <span class=\"string\">&quot;sequencer_output_directory&quot;</span></span><br><span class=\"line\"><span class=\"keyword\">if</span> <span class=\"keyword\">not</span> os.path.exists(output_path):</span><br><span class=\"line\">    os.makedirs(output_path)</span><br><span class=\"line\"><span class=\"comment\"># 初始化 sequencer 对象</span></span><br><span class=\"line\">estimator_list = [<span class=\"string\">&#x27;EMD&#x27;</span>, <span class=\"string\">&#x27;energy&#x27;</span>, <span class=\"string\">&#x27;L2&#x27;</span>]</span><br><span class=\"line\">seq = sequencer.Sequencer(grid, objects_list_shuffled, estimator_list)</span><br><span class=\"line\"><span class=\"comment\"># 执行 sequencer</span></span><br><span class=\"line\">final_elongation, final_sequence = seq.execute(output_path)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># first example</span></span><br><span class=\"line\">estimator_name = <span class=\"string\">&#x27;EMD&#x27;</span></span><br><span class=\"line\">scale = <span class=\"number\">1</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&quot;Intermediate elongation for metric=%s and scale=%s: %s&quot;</span> % (estimator_name, scale, </span><br><span class=\"line\">                                                                  seq.return_elongation_of_weighted_products(estimator_name, scale)))</span><br><span class=\"line\"><span class=\"comment\"># second example</span></span><br><span class=\"line\">estimator_list, scale_list, elongation_list = seq.return_elongation_of_weighted_products_all_metrics_and_scales()</span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"built_in\">len</span>(estimator_list)):</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&quot;metric=%s, scale=%s, elongation: %s&quot;</span> % (estimator_list[i], </span><br><span class=\"line\">                                                   scale_list[i], </span><br><span class=\"line\">                                                   elongation_list[i]))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 画图</span></span><br><span class=\"line\">estimator_list, scale_list, sequence_list = seq.return_sequence_of_weighted_products_all_metrics_and_scales()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#fig, axs = plt.subplots(2, 2, figsize=(12, 10))</span></span><br><span class=\"line\">plt.figure(<span class=\"number\">1</span>, figsize=(<span class=\"number\">16</span>, <span class=\"number\">16</span>))</span><br><span class=\"line\">plt.subplot(<span class=\"number\">2</span>, <span class=\"number\">2</span>, <span class=\"number\">1</span>)</span><br><span class=\"line\"><span class=\"comment\">#plt.title(&quot;input dataset&quot;)</span></span><br><span class=\"line\"><span class=\"comment\">#plt.pcolormesh(objects_list_shuffled)</span></span><br><span class=\"line\"><span class=\"comment\">#plt.colorbar()</span></span><br><span class=\"line\"><span class=\"comment\">#plt.xlabel(&quot;x&quot;)</span></span><br><span class=\"line\"><span class=\"comment\">#plt.ylabel(&quot;original index&quot;)</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> j, object_data <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(objects_list_shuffled):</span><br><span class=\"line\">    grid = np.arange(<span class=\"built_in\">len</span>(object_data))  <span class=\"comment\"># 创建与 object_data 长度相同的 x 轴</span></span><br><span class=\"line\">    object_data_scaled_y = object_data + (j-<span class=\"number\">1</span>) * <span class=\"number\">1</span>  <span class=\"comment\"># 缩放以避免重叠</span></span><br><span class=\"line\">    plt.plot(grid, object_data_scaled_y)</span><br><span class=\"line\">plt.xlabel(<span class=\"string\">&quot;x&quot;</span>)</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">&quot;Original&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">plt.subplot(<span class=\"number\">2</span>, <span class=\"number\">2</span>, <span class=\"number\">2</span>)</span><br><span class=\"line\">plt.title(<span class=\"string\">&quot;ordered according to\\n intermediate sequence using: \\n metric=%s, scale=%s&quot;</span> % (estimator_list[<span class=\"number\">0</span>], scale_list[<span class=\"number\">0</span>]))</span><br><span class=\"line\">sequnce = sequence_list[<span class=\"number\">0</span>]</span><br><span class=\"line\"><span class=\"comment\">#plt.pcolormesh(objects_list_shuffled[sequnce])</span></span><br><span class=\"line\"><span class=\"comment\">#plt.colorbar()</span></span><br><span class=\"line\"><span class=\"comment\">#plt.xlabel(&quot;x&quot;)</span></span><br><span class=\"line\"><span class=\"comment\">#plt.ylabel(&quot;original index&quot;)</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> j, object_data <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(objects_list_shuffled[sequnce]):</span><br><span class=\"line\">    grid = np.arange(<span class=\"built_in\">len</span>(object_data))  <span class=\"comment\"># 创建与 object_data 长度相同的 x 轴</span></span><br><span class=\"line\">    object_data_scaled_y = object_data + (j-<span class=\"number\">1</span>) * <span class=\"number\">1</span>  <span class=\"comment\"># 缩放以避免重叠</span></span><br><span class=\"line\">    plt.plot(grid, object_data_scaled_y)</span><br><span class=\"line\">plt.xlabel(<span class=\"string\">&quot;x&quot;</span>)</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">&quot;Original&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">plt.subplot(<span class=\"number\">2</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>)</span><br><span class=\"line\">plt.title(<span class=\"string\">&quot;ordered according to\\n intermediate sequence using: \\n metric=%s, scale=%s&quot;</span> % (estimator_list[<span class=\"number\">1</span>], scale_list[<span class=\"number\">1</span>]))</span><br><span class=\"line\">sequnce = sequence_list[<span class=\"number\">1</span>]</span><br><span class=\"line\"><span class=\"comment\">#plt.pcolormesh(objects_list_shuffled[sequnce])</span></span><br><span class=\"line\"><span class=\"comment\">#plt.colorbar()</span></span><br><span class=\"line\"><span class=\"comment\">#plt.xlabel(&quot;x&quot;)</span></span><br><span class=\"line\"><span class=\"comment\">#plt.ylabel(&quot;original index&quot;)</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> j, object_data <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(objects_list_shuffled[sequnce]):</span><br><span class=\"line\">    grid = np.arange(<span class=\"built_in\">len</span>(object_data))  <span class=\"comment\"># 创建与 object_data 长度相同的 x 轴</span></span><br><span class=\"line\">    object_data_scaled_y = object_data + (j-<span class=\"number\">1</span>) * <span class=\"number\">1</span>  <span class=\"comment\"># 缩放以避免重叠</span></span><br><span class=\"line\">    plt.plot(grid, object_data_scaled_y)</span><br><span class=\"line\">plt.xlabel(<span class=\"string\">&quot;x&quot;</span>)</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">&quot;Original&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">plt.subplot(<span class=\"number\">2</span>, <span class=\"number\">2</span>, <span class=\"number\">4</span>)</span><br><span class=\"line\">plt.title(<span class=\"string\">&quot;ordered according to\\n intermediate sequence using: \\n metric=%s, scale=%s&quot;</span> % (estimator_list[<span class=\"number\">2</span>], scale_list[<span class=\"number\">2</span>]))</span><br><span class=\"line\">sequnce = sequence_list[<span class=\"number\">2</span>]</span><br><span class=\"line\"><span class=\"comment\">#plt.pcolormesh(objects_list_shuffled[sequnce])</span></span><br><span class=\"line\"><span class=\"comment\">#plt.colorbar()</span></span><br><span class=\"line\"><span class=\"comment\">#plt.xlabel(&quot;x&quot;)</span></span><br><span class=\"line\"><span class=\"comment\">#plt.ylabel(&quot;original index&quot;)</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> j, object_data <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(objects_list_shuffled[sequnce]):</span><br><span class=\"line\">    grid = np.arange(<span class=\"built_in\">len</span>(object_data))  <span class=\"comment\"># 创建与 object_data 长度相同的 x 轴</span></span><br><span class=\"line\">    object_data_scaled_y = object_data + (j-<span class=\"number\">1</span>) * <span class=\"number\">1</span>  <span class=\"comment\"># 缩放以避免重叠</span></span><br><span class=\"line\">    plt.plot(grid, object_data_scaled_y)</span><br><span class=\"line\">plt.xlabel(<span class=\"string\">&quot;x&quot;</span>)</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">&quot;Original&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">plt.tight_layout()</span><br></pre></td></tr></table></figure>"},{"title":"有趣的jupyter-notebook插件","abbrlink":"69c8d283","date":"2025-06-21T11:45:32.000Z","_content":"\n有趣的jupyter notebook插件:\n\n| **插件名称**               | **简介**                                                                 | **官方链接**                                                                 |\n|----------------------------|--------------------------------------------------------------------------|----------------------------------------------------------------------------|\n| **Jupyter Contrib NBe**    | 核心扩展包，集成50+插件（代码补全、变量监控、执行时间显示等）             | [GitHub](https://github.com/ipython-contrib/jupyter_contrib_nbextensions)  |\n| **Hinterland**             | 实时代码补全工具，支持 Python/R/Julia，减少拼写错误                      | [文档](https://jupyter-contrib-nbextensions.readthedocs.io/en/latest/nbextensions/hinterland/README.html) |\n| **Table of Contents (2)** | 动态生成目录，支持标题跳转，适合长文档导航                               | [配置页](https://jupyter-contrib-nbextensions.readthedocs.io/en/latest/nbextensions/toc2/README.html) |\n| **Variable Inspector**    | 侧边栏实时显示变量类型/大小/值，替代频繁 `print(type)` 操作              | [说明](https://jupyter-contrib-nbextensions.readthedocs.io/en/latest/nbextensions/varInspector/README.html) |\n| **ExecuteTime**            | 记录每个 Cell 的执行时间和完成时间，优化性能分析                         | [详情](https://jupyter-contrib-nbextensions.readthedocs.io/en/latest/nbextensions/execute_time/README.html) |\n| **Autopep8**               | 一键格式化代码为 PEP8 标准，提升可读性                                   | [PyPI](https://pypi.org/project/autopep8/)                                |\n| **jupyterthemes**          | 界面主题美化，支持暗黑模式/护眼配色（如 `monokai`, `solarized`）          | [GitHub](https://github.com/dunovank/jupyter-themes)                      |\n| **Notify**                 | 内核空闲时发送浏览器通知，适合长时间任务（如模型训练）                   | [文档](https://jupyter-contrib-nbextensions.readthedocs.io/en/latest/nbextensions/notify/README.html) |\n| **jupyter Widgets**        | 创建交互控件（滑块/下拉菜单），将静态图表转为动态仪表盘                  | [官网](https://ipywidgets.readthedocs.io/en/latest/)                      |\n| **Voilà**                  | 将 Notebook 转为独立 Web 应用，隐藏代码仅保留交互结果                    | [文档](https://voila.readthedocs.io/en/stable/)                           |\n| **RISE**                   | 实时代码幻灯片工具，用 Markdown 标题分页，支持演示中修改参数             | [GitHub](https://github.com/damianavila/RISE)                            |\n\n安装：\n```\npip install jupyter_contrib_nbextensions jupyterthemes voila rise\njupyter contrib nbextension install\njupyter nbextension enable [插件名]  # 启用具体插件\n```\n","source":"_posts/2025-06-21-jupyter-notebook-extensions.md","raw":"---\ntitle: 有趣的jupyter-notebook插件\ntags:\n  - python\ncategories:\n  - python\nabbrlink: 69c8d283\ndate: 2025-06-21 19:45:32\n---\n\n有趣的jupyter notebook插件:\n\n| **插件名称**               | **简介**                                                                 | **官方链接**                                                                 |\n|----------------------------|--------------------------------------------------------------------------|----------------------------------------------------------------------------|\n| **Jupyter Contrib NBe**    | 核心扩展包，集成50+插件（代码补全、变量监控、执行时间显示等）             | [GitHub](https://github.com/ipython-contrib/jupyter_contrib_nbextensions)  |\n| **Hinterland**             | 实时代码补全工具，支持 Python/R/Julia，减少拼写错误                      | [文档](https://jupyter-contrib-nbextensions.readthedocs.io/en/latest/nbextensions/hinterland/README.html) |\n| **Table of Contents (2)** | 动态生成目录，支持标题跳转，适合长文档导航                               | [配置页](https://jupyter-contrib-nbextensions.readthedocs.io/en/latest/nbextensions/toc2/README.html) |\n| **Variable Inspector**    | 侧边栏实时显示变量类型/大小/值，替代频繁 `print(type)` 操作              | [说明](https://jupyter-contrib-nbextensions.readthedocs.io/en/latest/nbextensions/varInspector/README.html) |\n| **ExecuteTime**            | 记录每个 Cell 的执行时间和完成时间，优化性能分析                         | [详情](https://jupyter-contrib-nbextensions.readthedocs.io/en/latest/nbextensions/execute_time/README.html) |\n| **Autopep8**               | 一键格式化代码为 PEP8 标准，提升可读性                                   | [PyPI](https://pypi.org/project/autopep8/)                                |\n| **jupyterthemes**          | 界面主题美化，支持暗黑模式/护眼配色（如 `monokai`, `solarized`）          | [GitHub](https://github.com/dunovank/jupyter-themes)                      |\n| **Notify**                 | 内核空闲时发送浏览器通知，适合长时间任务（如模型训练）                   | [文档](https://jupyter-contrib-nbextensions.readthedocs.io/en/latest/nbextensions/notify/README.html) |\n| **jupyter Widgets**        | 创建交互控件（滑块/下拉菜单），将静态图表转为动态仪表盘                  | [官网](https://ipywidgets.readthedocs.io/en/latest/)                      |\n| **Voilà**                  | 将 Notebook 转为独立 Web 应用，隐藏代码仅保留交互结果                    | [文档](https://voila.readthedocs.io/en/stable/)                           |\n| **RISE**                   | 实时代码幻灯片工具，用 Markdown 标题分页，支持演示中修改参数             | [GitHub](https://github.com/damianavila/RISE)                            |\n\n安装：\n```\npip install jupyter_contrib_nbextensions jupyterthemes voila rise\njupyter contrib nbextension install\njupyter nbextension enable [插件名]  # 启用具体插件\n```\n","slug":"jupyter-notebook-extensions","published":1,"updated":"2025-06-21T12:30:04.873Z","comments":1,"layout":"post","photos":[],"_id":"cmh498iqk00ddwvou80ac70wq","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>有趣的jupyter notebook插件:</p>\n<table>\n<thead>\n<tr>\n<th><strong>插件名称</strong></th>\n<th><strong>简介</strong></th>\n<th><strong>官方链接</strong></th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Jupyter Contrib NBe</strong></td>\n<td>核心扩展包，集成50+插件（代码补全、变量监控、执行时间显示等）</td>\n<td><a href=\"https://github.com/ipython-contrib/jupyter_contrib_nbextensions\">GitHub</a></td>\n</tr>\n<tr>\n<td><strong>Hinterland</strong></td>\n<td>实时代码补全工具，支持 Python&#x2F;R&#x2F;Julia，减少拼写错误</td>\n<td><a href=\"https://jupyter-contrib-nbextensions.readthedocs.io/en/latest/nbextensions/hinterland/README.html\">文档</a></td>\n</tr>\n<tr>\n<td><strong>Table of Contents (2)</strong></td>\n<td>动态生成目录，支持标题跳转，适合长文档导航</td>\n<td><a href=\"https://jupyter-contrib-nbextensions.readthedocs.io/en/latest/nbextensions/toc2/README.html\">配置页</a></td>\n</tr>\n<tr>\n<td><strong>Variable Inspector</strong></td>\n<td>侧边栏实时显示变量类型&#x2F;大小&#x2F;值，替代频繁 <code>print(type)</code> 操作</td>\n<td><a href=\"https://jupyter-contrib-nbextensions.readthedocs.io/en/latest/nbextensions/varInspector/README.html\">说明</a></td>\n</tr>\n<tr>\n<td><strong>ExecuteTime</strong></td>\n<td>记录每个 Cell 的执行时间和完成时间，优化性能分析</td>\n<td><a href=\"https://jupyter-contrib-nbextensions.readthedocs.io/en/latest/nbextensions/execute_time/README.html\">详情</a></td>\n</tr>\n<tr>\n<td><strong>Autopep8</strong></td>\n<td>一键格式化代码为 PEP8 标准，提升可读性</td>\n<td><a href=\"https://pypi.org/project/autopep8/\">PyPI</a></td>\n</tr>\n<tr>\n<td><strong>jupyterthemes</strong></td>\n<td>界面主题美化，支持暗黑模式&#x2F;护眼配色（如 <code>monokai</code>, <code>solarized</code>）</td>\n<td><a href=\"https://github.com/dunovank/jupyter-themes\">GitHub</a></td>\n</tr>\n<tr>\n<td><strong>Notify</strong></td>\n<td>内核空闲时发送浏览器通知，适合长时间任务（如模型训练）</td>\n<td><a href=\"https://jupyter-contrib-nbextensions.readthedocs.io/en/latest/nbextensions/notify/README.html\">文档</a></td>\n</tr>\n<tr>\n<td><strong>jupyter Widgets</strong></td>\n<td>创建交互控件（滑块&#x2F;下拉菜单），将静态图表转为动态仪表盘</td>\n<td><a href=\"https://ipywidgets.readthedocs.io/en/latest/\">官网</a></td>\n</tr>\n<tr>\n<td><strong>Voilà</strong></td>\n<td>将 Notebook 转为独立 Web 应用，隐藏代码仅保留交互结果</td>\n<td><a href=\"https://voila.readthedocs.io/en/stable/\">文档</a></td>\n</tr>\n<tr>\n<td><strong>RISE</strong></td>\n<td>实时代码幻灯片工具，用 Markdown 标题分页，支持演示中修改参数</td>\n<td><a href=\"https://github.com/damianavila/RISE\">GitHub</a></td>\n</tr>\n</tbody></table>\n<p>安装：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pip install jupyter_contrib_nbextensions jupyterthemes voila rise</span><br><span class=\"line\">jupyter contrib nbextension install</span><br><span class=\"line\">jupyter nbextension enable [插件名]  # 启用具体插件</span><br></pre></td></tr></table></figure>\n","related_posts":["object-detection.html","how-I-build-this-web.html","passwd-free-for-deployment.html"],"length":675,"excerpt":"","more":"<p>有趣的jupyter notebook插件:</p>\n<table>\n<thead>\n<tr>\n<th><strong>插件名称</strong></th>\n<th><strong>简介</strong></th>\n<th><strong>官方链接</strong></th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Jupyter Contrib NBe</strong></td>\n<td>核心扩展包，集成50+插件（代码补全、变量监控、执行时间显示等）</td>\n<td><a href=\"https://github.com/ipython-contrib/jupyter_contrib_nbextensions\">GitHub</a></td>\n</tr>\n<tr>\n<td><strong>Hinterland</strong></td>\n<td>实时代码补全工具，支持 Python&#x2F;R&#x2F;Julia，减少拼写错误</td>\n<td><a href=\"https://jupyter-contrib-nbextensions.readthedocs.io/en/latest/nbextensions/hinterland/README.html\">文档</a></td>\n</tr>\n<tr>\n<td><strong>Table of Contents (2)</strong></td>\n<td>动态生成目录，支持标题跳转，适合长文档导航</td>\n<td><a href=\"https://jupyter-contrib-nbextensions.readthedocs.io/en/latest/nbextensions/toc2/README.html\">配置页</a></td>\n</tr>\n<tr>\n<td><strong>Variable Inspector</strong></td>\n<td>侧边栏实时显示变量类型&#x2F;大小&#x2F;值，替代频繁 <code>print(type)</code> 操作</td>\n<td><a href=\"https://jupyter-contrib-nbextensions.readthedocs.io/en/latest/nbextensions/varInspector/README.html\">说明</a></td>\n</tr>\n<tr>\n<td><strong>ExecuteTime</strong></td>\n<td>记录每个 Cell 的执行时间和完成时间，优化性能分析</td>\n<td><a href=\"https://jupyter-contrib-nbextensions.readthedocs.io/en/latest/nbextensions/execute_time/README.html\">详情</a></td>\n</tr>\n<tr>\n<td><strong>Autopep8</strong></td>\n<td>一键格式化代码为 PEP8 标准，提升可读性</td>\n<td><a href=\"https://pypi.org/project/autopep8/\">PyPI</a></td>\n</tr>\n<tr>\n<td><strong>jupyterthemes</strong></td>\n<td>界面主题美化，支持暗黑模式&#x2F;护眼配色（如 <code>monokai</code>, <code>solarized</code>）</td>\n<td><a href=\"https://github.com/dunovank/jupyter-themes\">GitHub</a></td>\n</tr>\n<tr>\n<td><strong>Notify</strong></td>\n<td>内核空闲时发送浏览器通知，适合长时间任务（如模型训练）</td>\n<td><a href=\"https://jupyter-contrib-nbextensions.readthedocs.io/en/latest/nbextensions/notify/README.html\">文档</a></td>\n</tr>\n<tr>\n<td><strong>jupyter Widgets</strong></td>\n<td>创建交互控件（滑块&#x2F;下拉菜单），将静态图表转为动态仪表盘</td>\n<td><a href=\"https://ipywidgets.readthedocs.io/en/latest/\">官网</a></td>\n</tr>\n<tr>\n<td><strong>Voilà</strong></td>\n<td>将 Notebook 转为独立 Web 应用，隐藏代码仅保留交互结果</td>\n<td><a href=\"https://voila.readthedocs.io/en/stable/\">文档</a></td>\n</tr>\n<tr>\n<td><strong>RISE</strong></td>\n<td>实时代码幻灯片工具，用 Markdown 标题分页，支持演示中修改参数</td>\n<td><a href=\"https://github.com/damianavila/RISE\">GitHub</a></td>\n</tr>\n</tbody></table>\n<p>安装：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pip install jupyter_contrib_nbextensions jupyterthemes voila rise</span><br><span class=\"line\">jupyter contrib nbextension install</span><br><span class=\"line\">jupyter nbextension enable [插件名]  # 启用具体插件</span><br></pre></td></tr></table></figure>\n"},{"title":"$\\LaTeX$的数学公式表达","abbrlink":"d78cae06","date":"2025-06-21T07:03:50.000Z","_content":"&emsp;&emsp;以下是$\\LaTeX$的数学算符\n\n> **说明**：公式需包裹在 `$...$`（行内公式）或 `$$...$$`（块级公式）中，以下表格中的 **渲染效果** 需在支持 LaTeX 的 Markdown 环境中显示（如 Typora、Obsidian 等）。\n\n---\n\n## 一、基础运算符号\n| 符号名称       | $\\LaTeX$ 命令      | 渲染效果         |\n|----------------|----------------|------------------|\n| 加号           | `a + b`        | $a + b$          |\n| 减号           | `a - b`        | $a - b$          |\n| 乘号（叉乘）   | `a \\times b`   | $a \\times b$     |\n| 乘号（点乘）   | `a \\cdot b`    | $a \\cdot b$      |\n| 除号           | `a \\div b`     | $a \\div b$       |\n| 加减号         | `a \\pm b`      | $a \\pm b$        |\n| 减加号         | `a \\mp b`      | $a \\mp b$        |\n\n---\n\n## 二、关系运算符\n| 符号名称       | $\\LaTeX$ 命令      | 渲染效果         |\n|----------------|----------------|------------------|\n| 等于           | `a = b`        | $a = b$          |\n| 不等于         | `a \\neq b`     | $a \\neq b$       |\n| 约等于         | `a \\approx b`  | $a \\approx b$    |\n| 大于等于       | `a \\geq b`     | $a \\geq b$       |\n| 小于等于       | `a \\leq b`     | $a \\leq b$       |\n| 远大于         | `a \\gg b`      | $a \\gg b$        |\n| 远小于         | `a \\ll b`      | $a \\ll b$        |\n| 正比于         | `a \\propto b`  | $a \\propto b$    |\n\n---\n\n## 三、集合运算符\n| 符号名称       | $\\LaTeX$ 命令          | 渲染效果             |\n|----------------|--------------------|----------------------|\n| 并集           | `A \\cup B`         | $A \\cup B$          |\n| 交集           | `A \\cap B`         | $A \\cap B$          |\n| 属于           | `x \\in A`          | $x \\in A$           |\n| 不属于         | `x \\notin B`       | $x \\notin B$        |\n| 子集           | `A \\subset B`      | $A \\subset B$       |\n| 真子集         | `A \\subseteq B`    | $A \\subseteq B$     |\n| 空集           | `\\emptyset`        | $\\emptyset$         |\n| 实数集         | `\\mathbb{R}`       | $\\mathbb{R}$        |\n| 自然数集       | `\\mathbb{N}`       | $\\mathbb{N}$        |\n\n---\n\n## 四、微积分符号\n| 符号名称         | $\\LaTeX$ 命令                 | 渲染效果                  |\n|------------------|---------------------------|---------------------------|\n| 积分             | `\\int_{a}^{b} f(x) dx`    | $\\int_{a}^{b} f(x) dx$    |\n| 偏导数           | `\\frac{\\partial f}{\\partial x}` | $\\frac{\\partial f}{\\partial x}$ |\n| 极限             | `\\lim_{x \\to 0} \\frac{\\sin x}{x}` | $\\lim_{x \\to 0} \\frac{\\sin x}{x}$ |\n| 求和             | `\\sum_{i=1}^{n} i^2`      | $\\sum_{i=1}^{n} i^2$      |\n| 导数（撇号形式） | `f'(x)`                   | $f'(x)$                   |\n| 梯度             | `\\nabla f`                | $\\nabla f$                |\n| 二阶导数         | `\\frac{d^2 y}{dx^2}`      | $\\frac{d^2 y}{dx^2}$      |\n\n---\n\n## 五、希腊字母\n| 小写字母 | $\\LaTeX$ 命令 | 渲染效果 | 大写字母 | LaTeX 命令 | 渲染效果 |\n|----------|------------|----------|----------|------------|----------|\n| α (alpha) | `\\alpha`   | $\\alpha$ | Γ (Gamma) | `\\Gamma`   | $\\Gamma$ |\n| β (beta)  | `\\beta`    | $\\beta$  | Δ (Delta) | `\\Delta`   | $\\Delta$ |\n| θ (theta) | `\\theta`   | $\\theta$ | Θ (Theta) | `\\Theta`   | $\\Theta$ |\n| π (pi)    | `\\pi`      | $\\pi$    | Π (Pi)    | `\\Pi`      | $\\Pi$    |\n| σ (sigma) | `\\sigma`   | $\\sigma$ | Σ (Sigma) | `\\Sigma`   | $\\Sigma$ |\n\n---\n\n## 六、箭头符号\n| 符号名称   | $\\LaTeX$ 命令         | 渲染效果            |\n|------------|-------------------|---------------------|\n| 右箭头     | `\\rightarrow`    | $\\rightarrow$       |\n| 左箭头     | `\\leftarrow`     | $\\leftarrow$        |\n| 双向箭头   | `\\leftrightarrow`| $\\leftrightarrow$   |\n| 蕴含符号   | `\\Rightarrow`    | $\\Rightarrow$       |\n| 等价符号   | `\\Leftrightarrow`| $\\Leftrightarrow$   |\n| 映射箭头   | `\\mapsto`        | $\\mapsto$           |\n\n---\n\n## 七、括号与定界符\n| 符号名称       | $\\LaTeX$ 命令                     | 渲染效果                     |\n|----------------|--------------------------------|------------------------------|\n| 圆括号（自适应）| `\\left( \\frac{a}{b} \\right)`   | $\\left( \\frac{a}{b} \\right)$  |\n| 方括号         | `\\left[ x \\right]`             | $\\left[ x \\right]$            |\n| 花括号         | `\\left\\{ x \\right\\}`           | $\\{ x \\}$          |\n| 绝对值         | `\\lvert x \\rvert`              | $\\lvert x \\rvert$             |\n| 范数           | `\\lVert \\mathbf{v} \\rVert`     | $\\lVert \\mathbf{v} \\rVert$    |\n\n---\n\n## 八、矩阵环境\n```latex\n$$ \n\\begin{pmatrix}  % 圆括号矩阵\na & b \\\\\nc & d \n\\end{pmatrix}\n\\quad\n\\begin{bmatrix}  % 方括号矩阵\na & b \\\\\nc & d \n\\end{bmatrix}\n\\quad\n\\begin{vmatrix}  % 行列式\na & b \\\\\nc & d \n\\end{vmatrix}\n$$\n```\n渲染效果：\n$$ \n\\begin{pmatrix}  % 圆括号矩阵\na & b \\\\\nc & d \n\\end{pmatrix}\n\\quad\n\\begin{bmatrix}  % 方括号矩阵\na & b \\\\\nc & d \n\\end{bmatrix}\n\\quad\n\\begin{vmatrix}  % 行列式\na & b \\\\\nc & d \n\\end{vmatrix}\n$$\n\n看样子花括号和矩阵都不太行啊。\n","source":"_posts/2025-06-21-latex-math-express.md","raw":"---\ntitle: $\\LaTeX$的数学公式表达\ntags:\n  - LaTeX\ncategories:\n  - web\nabbrlink: d78cae06\ndate: 2025-06-21 15:03:50\n---\n&emsp;&emsp;以下是$\\LaTeX$的数学算符\n\n> **说明**：公式需包裹在 `$...$`（行内公式）或 `$$...$$`（块级公式）中，以下表格中的 **渲染效果** 需在支持 LaTeX 的 Markdown 环境中显示（如 Typora、Obsidian 等）。\n\n---\n\n## 一、基础运算符号\n| 符号名称       | $\\LaTeX$ 命令      | 渲染效果         |\n|----------------|----------------|------------------|\n| 加号           | `a + b`        | $a + b$          |\n| 减号           | `a - b`        | $a - b$          |\n| 乘号（叉乘）   | `a \\times b`   | $a \\times b$     |\n| 乘号（点乘）   | `a \\cdot b`    | $a \\cdot b$      |\n| 除号           | `a \\div b`     | $a \\div b$       |\n| 加减号         | `a \\pm b`      | $a \\pm b$        |\n| 减加号         | `a \\mp b`      | $a \\mp b$        |\n\n---\n\n## 二、关系运算符\n| 符号名称       | $\\LaTeX$ 命令      | 渲染效果         |\n|----------------|----------------|------------------|\n| 等于           | `a = b`        | $a = b$          |\n| 不等于         | `a \\neq b`     | $a \\neq b$       |\n| 约等于         | `a \\approx b`  | $a \\approx b$    |\n| 大于等于       | `a \\geq b`     | $a \\geq b$       |\n| 小于等于       | `a \\leq b`     | $a \\leq b$       |\n| 远大于         | `a \\gg b`      | $a \\gg b$        |\n| 远小于         | `a \\ll b`      | $a \\ll b$        |\n| 正比于         | `a \\propto b`  | $a \\propto b$    |\n\n---\n\n## 三、集合运算符\n| 符号名称       | $\\LaTeX$ 命令          | 渲染效果             |\n|----------------|--------------------|----------------------|\n| 并集           | `A \\cup B`         | $A \\cup B$          |\n| 交集           | `A \\cap B`         | $A \\cap B$          |\n| 属于           | `x \\in A`          | $x \\in A$           |\n| 不属于         | `x \\notin B`       | $x \\notin B$        |\n| 子集           | `A \\subset B`      | $A \\subset B$       |\n| 真子集         | `A \\subseteq B`    | $A \\subseteq B$     |\n| 空集           | `\\emptyset`        | $\\emptyset$         |\n| 实数集         | `\\mathbb{R}`       | $\\mathbb{R}$        |\n| 自然数集       | `\\mathbb{N}`       | $\\mathbb{N}$        |\n\n---\n\n## 四、微积分符号\n| 符号名称         | $\\LaTeX$ 命令                 | 渲染效果                  |\n|------------------|---------------------------|---------------------------|\n| 积分             | `\\int_{a}^{b} f(x) dx`    | $\\int_{a}^{b} f(x) dx$    |\n| 偏导数           | `\\frac{\\partial f}{\\partial x}` | $\\frac{\\partial f}{\\partial x}$ |\n| 极限             | `\\lim_{x \\to 0} \\frac{\\sin x}{x}` | $\\lim_{x \\to 0} \\frac{\\sin x}{x}$ |\n| 求和             | `\\sum_{i=1}^{n} i^2`      | $\\sum_{i=1}^{n} i^2$      |\n| 导数（撇号形式） | `f'(x)`                   | $f'(x)$                   |\n| 梯度             | `\\nabla f`                | $\\nabla f$                |\n| 二阶导数         | `\\frac{d^2 y}{dx^2}`      | $\\frac{d^2 y}{dx^2}$      |\n\n---\n\n## 五、希腊字母\n| 小写字母 | $\\LaTeX$ 命令 | 渲染效果 | 大写字母 | LaTeX 命令 | 渲染效果 |\n|----------|------------|----------|----------|------------|----------|\n| α (alpha) | `\\alpha`   | $\\alpha$ | Γ (Gamma) | `\\Gamma`   | $\\Gamma$ |\n| β (beta)  | `\\beta`    | $\\beta$  | Δ (Delta) | `\\Delta`   | $\\Delta$ |\n| θ (theta) | `\\theta`   | $\\theta$ | Θ (Theta) | `\\Theta`   | $\\Theta$ |\n| π (pi)    | `\\pi`      | $\\pi$    | Π (Pi)    | `\\Pi`      | $\\Pi$    |\n| σ (sigma) | `\\sigma`   | $\\sigma$ | Σ (Sigma) | `\\Sigma`   | $\\Sigma$ |\n\n---\n\n## 六、箭头符号\n| 符号名称   | $\\LaTeX$ 命令         | 渲染效果            |\n|------------|-------------------|---------------------|\n| 右箭头     | `\\rightarrow`    | $\\rightarrow$       |\n| 左箭头     | `\\leftarrow`     | $\\leftarrow$        |\n| 双向箭头   | `\\leftrightarrow`| $\\leftrightarrow$   |\n| 蕴含符号   | `\\Rightarrow`    | $\\Rightarrow$       |\n| 等价符号   | `\\Leftrightarrow`| $\\Leftrightarrow$   |\n| 映射箭头   | `\\mapsto`        | $\\mapsto$           |\n\n---\n\n## 七、括号与定界符\n| 符号名称       | $\\LaTeX$ 命令                     | 渲染效果                     |\n|----------------|--------------------------------|------------------------------|\n| 圆括号（自适应）| `\\left( \\frac{a}{b} \\right)`   | $\\left( \\frac{a}{b} \\right)$  |\n| 方括号         | `\\left[ x \\right]`             | $\\left[ x \\right]$            |\n| 花括号         | `\\left\\{ x \\right\\}`           | $\\{ x \\}$          |\n| 绝对值         | `\\lvert x \\rvert`              | $\\lvert x \\rvert$             |\n| 范数           | `\\lVert \\mathbf{v} \\rVert`     | $\\lVert \\mathbf{v} \\rVert$    |\n\n---\n\n## 八、矩阵环境\n```latex\n$$ \n\\begin{pmatrix}  % 圆括号矩阵\na & b \\\\\nc & d \n\\end{pmatrix}\n\\quad\n\\begin{bmatrix}  % 方括号矩阵\na & b \\\\\nc & d \n\\end{bmatrix}\n\\quad\n\\begin{vmatrix}  % 行列式\na & b \\\\\nc & d \n\\end{vmatrix}\n$$\n```\n渲染效果：\n$$ \n\\begin{pmatrix}  % 圆括号矩阵\na & b \\\\\nc & d \n\\end{pmatrix}\n\\quad\n\\begin{bmatrix}  % 方括号矩阵\na & b \\\\\nc & d \n\\end{bmatrix}\n\\quad\n\\begin{vmatrix}  % 行列式\na & b \\\\\nc & d \n\\end{vmatrix}\n$$\n\n看样子花括号和矩阵都不太行啊。\n","slug":"latex-math-express","published":1,"updated":"2025-06-21T09:25:53.424Z","comments":1,"layout":"post","photos":[],"_id":"cmh498iqk00dgwvou1244bccq","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>&emsp;&emsp;以下是$\\LaTeX$的数学算符</p>\n<blockquote>\n<p><strong>说明</strong>：公式需包裹在 <code>$...$</code>（行内公式）或 <code>$$...$$</code>（块级公式）中，以下表格中的 <strong>渲染效果</strong> 需在支持 LaTeX 的 Markdown 环境中显示（如 Typora、Obsidian 等）。</p>\n</blockquote>\n<hr>\n<h2 id=\"一、基础运算符号\"><a href=\"#一、基础运算符号\" class=\"headerlink\" title=\"一、基础运算符号\"></a>一、基础运算符号</h2><table>\n<thead>\n<tr>\n<th>符号名称</th>\n<th>$\\LaTeX$ 命令</th>\n<th>渲染效果</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>加号</td>\n<td><code>a + b</code></td>\n<td>$a + b$</td>\n</tr>\n<tr>\n<td>减号</td>\n<td><code>a - b</code></td>\n<td>$a - b$</td>\n</tr>\n<tr>\n<td>乘号（叉乘）</td>\n<td><code>a \\times b</code></td>\n<td>$a \\times b$</td>\n</tr>\n<tr>\n<td>乘号（点乘）</td>\n<td><code>a \\cdot b</code></td>\n<td>$a \\cdot b$</td>\n</tr>\n<tr>\n<td>除号</td>\n<td><code>a \\div b</code></td>\n<td>$a \\div b$</td>\n</tr>\n<tr>\n<td>加减号</td>\n<td><code>a \\pm b</code></td>\n<td>$a \\pm b$</td>\n</tr>\n<tr>\n<td>减加号</td>\n<td><code>a \\mp b</code></td>\n<td>$a \\mp b$</td>\n</tr>\n</tbody></table>\n<hr>\n<h2 id=\"二、关系运算符\"><a href=\"#二、关系运算符\" class=\"headerlink\" title=\"二、关系运算符\"></a>二、关系运算符</h2><table>\n<thead>\n<tr>\n<th>符号名称</th>\n<th>$\\LaTeX$ 命令</th>\n<th>渲染效果</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>等于</td>\n<td><code>a = b</code></td>\n<td>$a &#x3D; b$</td>\n</tr>\n<tr>\n<td>不等于</td>\n<td><code>a \\neq b</code></td>\n<td>$a \\neq b$</td>\n</tr>\n<tr>\n<td>约等于</td>\n<td><code>a \\approx b</code></td>\n<td>$a \\approx b$</td>\n</tr>\n<tr>\n<td>大于等于</td>\n<td><code>a \\geq b</code></td>\n<td>$a \\geq b$</td>\n</tr>\n<tr>\n<td>小于等于</td>\n<td><code>a \\leq b</code></td>\n<td>$a \\leq b$</td>\n</tr>\n<tr>\n<td>远大于</td>\n<td><code>a \\gg b</code></td>\n<td>$a \\gg b$</td>\n</tr>\n<tr>\n<td>远小于</td>\n<td><code>a \\ll b</code></td>\n<td>$a \\ll b$</td>\n</tr>\n<tr>\n<td>正比于</td>\n<td><code>a \\propto b</code></td>\n<td>$a \\propto b$</td>\n</tr>\n</tbody></table>\n<hr>\n<h2 id=\"三、集合运算符\"><a href=\"#三、集合运算符\" class=\"headerlink\" title=\"三、集合运算符\"></a>三、集合运算符</h2><table>\n<thead>\n<tr>\n<th>符号名称</th>\n<th>$\\LaTeX$ 命令</th>\n<th>渲染效果</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>并集</td>\n<td><code>A \\cup B</code></td>\n<td>$A \\cup B$</td>\n</tr>\n<tr>\n<td>交集</td>\n<td><code>A \\cap B</code></td>\n<td>$A \\cap B$</td>\n</tr>\n<tr>\n<td>属于</td>\n<td><code>x \\in A</code></td>\n<td>$x \\in A$</td>\n</tr>\n<tr>\n<td>不属于</td>\n<td><code>x \\notin B</code></td>\n<td>$x \\notin B$</td>\n</tr>\n<tr>\n<td>子集</td>\n<td><code>A \\subset B</code></td>\n<td>$A \\subset B$</td>\n</tr>\n<tr>\n<td>真子集</td>\n<td><code>A \\subseteq B</code></td>\n<td>$A \\subseteq B$</td>\n</tr>\n<tr>\n<td>空集</td>\n<td><code>\\emptyset</code></td>\n<td>$\\emptyset$</td>\n</tr>\n<tr>\n<td>实数集</td>\n<td><code>\\mathbb&#123;R&#125;</code></td>\n<td>$\\mathbb{R}$</td>\n</tr>\n<tr>\n<td>自然数集</td>\n<td><code>\\mathbb&#123;N&#125;</code></td>\n<td>$\\mathbb{N}$</td>\n</tr>\n</tbody></table>\n<hr>\n<h2 id=\"四、微积分符号\"><a href=\"#四、微积分符号\" class=\"headerlink\" title=\"四、微积分符号\"></a>四、微积分符号</h2><table>\n<thead>\n<tr>\n<th>符号名称</th>\n<th>$\\LaTeX$ 命令</th>\n<th>渲染效果</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>积分</td>\n<td><code>\\int_&#123;a&#125;^&#123;b&#125; f(x) dx</code></td>\n<td>$\\int_{a}^{b} f(x) dx$</td>\n</tr>\n<tr>\n<td>偏导数</td>\n<td><code>\\frac&#123;\\partial f&#125;&#123;\\partial x&#125;</code></td>\n<td>$\\frac{\\partial f}{\\partial x}$</td>\n</tr>\n<tr>\n<td>极限</td>\n<td><code>\\lim_&#123;x \\to 0&#125; \\frac&#123;\\sin x&#125;&#123;x&#125;</code></td>\n<td>$\\lim_{x \\to 0} \\frac{\\sin x}{x}$</td>\n</tr>\n<tr>\n<td>求和</td>\n<td><code>\\sum_&#123;i=1&#125;^&#123;n&#125; i^2</code></td>\n<td>$\\sum_{i&#x3D;1}^{n} i^2$</td>\n</tr>\n<tr>\n<td>导数（撇号形式）</td>\n<td><code>f&#39;(x)</code></td>\n<td>$f’(x)$</td>\n</tr>\n<tr>\n<td>梯度</td>\n<td><code>\\nabla f</code></td>\n<td>$\\nabla f$</td>\n</tr>\n<tr>\n<td>二阶导数</td>\n<td><code>\\frac&#123;d^2 y&#125;&#123;dx^2&#125;</code></td>\n<td>$\\frac{d^2 y}{dx^2}$</td>\n</tr>\n</tbody></table>\n<hr>\n<h2 id=\"五、希腊字母\"><a href=\"#五、希腊字母\" class=\"headerlink\" title=\"五、希腊字母\"></a>五、希腊字母</h2><table>\n<thead>\n<tr>\n<th>小写字母</th>\n<th>$\\LaTeX$ 命令</th>\n<th>渲染效果</th>\n<th>大写字母</th>\n<th>LaTeX 命令</th>\n<th>渲染效果</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>α (alpha)</td>\n<td><code>\\alpha</code></td>\n<td>$\\alpha$</td>\n<td>Γ (Gamma)</td>\n<td><code>\\Gamma</code></td>\n<td>$\\Gamma$</td>\n</tr>\n<tr>\n<td>β (beta)</td>\n<td><code>\\beta</code></td>\n<td>$\\beta$</td>\n<td>Δ (Delta)</td>\n<td><code>\\Delta</code></td>\n<td>$\\Delta$</td>\n</tr>\n<tr>\n<td>θ (theta)</td>\n<td><code>\\theta</code></td>\n<td>$\\theta$</td>\n<td>Θ (Theta)</td>\n<td><code>\\Theta</code></td>\n<td>$\\Theta$</td>\n</tr>\n<tr>\n<td>π (pi)</td>\n<td><code>\\pi</code></td>\n<td>$\\pi$</td>\n<td>Π (Pi)</td>\n<td><code>\\Pi</code></td>\n<td>$\\Pi$</td>\n</tr>\n<tr>\n<td>σ (sigma)</td>\n<td><code>\\sigma</code></td>\n<td>$\\sigma$</td>\n<td>Σ (Sigma)</td>\n<td><code>\\Sigma</code></td>\n<td>$\\Sigma$</td>\n</tr>\n</tbody></table>\n<hr>\n<h2 id=\"六、箭头符号\"><a href=\"#六、箭头符号\" class=\"headerlink\" title=\"六、箭头符号\"></a>六、箭头符号</h2><table>\n<thead>\n<tr>\n<th>符号名称</th>\n<th>$\\LaTeX$ 命令</th>\n<th>渲染效果</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>右箭头</td>\n<td><code>\\rightarrow</code></td>\n<td>$\\rightarrow$</td>\n</tr>\n<tr>\n<td>左箭头</td>\n<td><code>\\leftarrow</code></td>\n<td>$\\leftarrow$</td>\n</tr>\n<tr>\n<td>双向箭头</td>\n<td><code>\\leftrightarrow</code></td>\n<td>$\\leftrightarrow$</td>\n</tr>\n<tr>\n<td>蕴含符号</td>\n<td><code>\\Rightarrow</code></td>\n<td>$\\Rightarrow$</td>\n</tr>\n<tr>\n<td>等价符号</td>\n<td><code>\\Leftrightarrow</code></td>\n<td>$\\Leftrightarrow$</td>\n</tr>\n<tr>\n<td>映射箭头</td>\n<td><code>\\mapsto</code></td>\n<td>$\\mapsto$</td>\n</tr>\n</tbody></table>\n<hr>\n<h2 id=\"七、括号与定界符\"><a href=\"#七、括号与定界符\" class=\"headerlink\" title=\"七、括号与定界符\"></a>七、括号与定界符</h2><table>\n<thead>\n<tr>\n<th>符号名称</th>\n<th>$\\LaTeX$ 命令</th>\n<th>渲染效果</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>圆括号（自适应）</td>\n<td><code>\\left( \\frac&#123;a&#125;&#123;b&#125; \\right)</code></td>\n<td>$\\left( \\frac{a}{b} \\right)$</td>\n</tr>\n<tr>\n<td>方括号</td>\n<td><code>\\left[ x \\right]</code></td>\n<td>$\\left[ x \\right]$</td>\n</tr>\n<tr>\n<td>花括号</td>\n<td><code>\\left\\&#123; x \\right\\&#125;</code></td>\n<td>${ x }$</td>\n</tr>\n<tr>\n<td>绝对值</td>\n<td><code>\\lvert x \\rvert</code></td>\n<td>$\\lvert x \\rvert$</td>\n</tr>\n<tr>\n<td>范数</td>\n<td><code>\\lVert \\mathbf&#123;v&#125; \\rVert</code></td>\n<td>$\\lVert \\mathbf{v} \\rVert$</td>\n</tr>\n</tbody></table>\n<hr>\n<h2 id=\"八、矩阵环境\"><a href=\"#八、矩阵环境\" class=\"headerlink\" title=\"八、矩阵环境\"></a>八、矩阵环境</h2><figure class=\"highlight latex\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">$</span><span class=\"built_in\">$</span> </span><br><span class=\"line\"><span class=\"keyword\">\\begin</span>&#123;pmatrix&#125;  <span class=\"comment\">% 圆括号矩阵</span></span><br><span class=\"line\">a <span class=\"built_in\">&amp;</span> b <span class=\"keyword\">\\\\</span></span><br><span class=\"line\">c <span class=\"built_in\">&amp;</span> d </span><br><span class=\"line\"><span class=\"keyword\">\\end</span>&#123;pmatrix&#125;</span><br><span class=\"line\"><span class=\"keyword\">\\quad</span></span><br><span class=\"line\"><span class=\"keyword\">\\begin</span>&#123;bmatrix&#125;  <span class=\"comment\">% 方括号矩阵</span></span><br><span class=\"line\">a <span class=\"built_in\">&amp;</span> b <span class=\"keyword\">\\\\</span></span><br><span class=\"line\">c <span class=\"built_in\">&amp;</span> d </span><br><span class=\"line\"><span class=\"keyword\">\\end</span>&#123;bmatrix&#125;</span><br><span class=\"line\"><span class=\"keyword\">\\quad</span></span><br><span class=\"line\"><span class=\"keyword\">\\begin</span>&#123;vmatrix&#125;  <span class=\"comment\">% 行列式</span></span><br><span class=\"line\">a <span class=\"built_in\">&amp;</span> b <span class=\"keyword\">\\\\</span></span><br><span class=\"line\">c <span class=\"built_in\">&amp;</span> d </span><br><span class=\"line\"><span class=\"keyword\">\\end</span>&#123;vmatrix&#125;</span><br><span class=\"line\"><span class=\"built_in\">$</span><span class=\"built_in\">$</span></span><br></pre></td></tr></table></figure>\n<p>渲染效果：<br>$$<br>\\begin{pmatrix}  % 圆括号矩阵<br>a &amp; b \\<br>c &amp; d<br>\\end{pmatrix}<br>\\quad<br>\\begin{bmatrix}  % 方括号矩阵<br>a &amp; b \\<br>c &amp; d<br>\\end{bmatrix}<br>\\quad<br>\\begin{vmatrix}  % 行列式<br>a &amp; b \\<br>c &amp; d<br>\\end{vmatrix}<br>$$</p>\n<p>看样子花括号和矩阵都不太行啊。</p>\n","related_posts":["no-file-found-in-LaTeX.html","add_counter.html","music.html","avatar-to-homepage.html","run-sequencer.html"],"length":2199,"excerpt":"","more":"<p>&emsp;&emsp;以下是$\\LaTeX$的数学算符</p>\n<blockquote>\n<p><strong>说明</strong>：公式需包裹在 <code>$...$</code>（行内公式）或 <code>$$...$$</code>（块级公式）中，以下表格中的 <strong>渲染效果</strong> 需在支持 LaTeX 的 Markdown 环境中显示（如 Typora、Obsidian 等）。</p>\n</blockquote>\n<hr>\n<h2 id=\"一、基础运算符号\"><a href=\"#一、基础运算符号\" class=\"headerlink\" title=\"一、基础运算符号\"></a>一、基础运算符号</h2><table>\n<thead>\n<tr>\n<th>符号名称</th>\n<th>$\\LaTeX$ 命令</th>\n<th>渲染效果</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>加号</td>\n<td><code>a + b</code></td>\n<td>$a + b$</td>\n</tr>\n<tr>\n<td>减号</td>\n<td><code>a - b</code></td>\n<td>$a - b$</td>\n</tr>\n<tr>\n<td>乘号（叉乘）</td>\n<td><code>a \\times b</code></td>\n<td>$a \\times b$</td>\n</tr>\n<tr>\n<td>乘号（点乘）</td>\n<td><code>a \\cdot b</code></td>\n<td>$a \\cdot b$</td>\n</tr>\n<tr>\n<td>除号</td>\n<td><code>a \\div b</code></td>\n<td>$a \\div b$</td>\n</tr>\n<tr>\n<td>加减号</td>\n<td><code>a \\pm b</code></td>\n<td>$a \\pm b$</td>\n</tr>\n<tr>\n<td>减加号</td>\n<td><code>a \\mp b</code></td>\n<td>$a \\mp b$</td>\n</tr>\n</tbody></table>\n<hr>\n<h2 id=\"二、关系运算符\"><a href=\"#二、关系运算符\" class=\"headerlink\" title=\"二、关系运算符\"></a>二、关系运算符</h2><table>\n<thead>\n<tr>\n<th>符号名称</th>\n<th>$\\LaTeX$ 命令</th>\n<th>渲染效果</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>等于</td>\n<td><code>a = b</code></td>\n<td>$a &#x3D; b$</td>\n</tr>\n<tr>\n<td>不等于</td>\n<td><code>a \\neq b</code></td>\n<td>$a \\neq b$</td>\n</tr>\n<tr>\n<td>约等于</td>\n<td><code>a \\approx b</code></td>\n<td>$a \\approx b$</td>\n</tr>\n<tr>\n<td>大于等于</td>\n<td><code>a \\geq b</code></td>\n<td>$a \\geq b$</td>\n</tr>\n<tr>\n<td>小于等于</td>\n<td><code>a \\leq b</code></td>\n<td>$a \\leq b$</td>\n</tr>\n<tr>\n<td>远大于</td>\n<td><code>a \\gg b</code></td>\n<td>$a \\gg b$</td>\n</tr>\n<tr>\n<td>远小于</td>\n<td><code>a \\ll b</code></td>\n<td>$a \\ll b$</td>\n</tr>\n<tr>\n<td>正比于</td>\n<td><code>a \\propto b</code></td>\n<td>$a \\propto b$</td>\n</tr>\n</tbody></table>\n<hr>\n<h2 id=\"三、集合运算符\"><a href=\"#三、集合运算符\" class=\"headerlink\" title=\"三、集合运算符\"></a>三、集合运算符</h2><table>\n<thead>\n<tr>\n<th>符号名称</th>\n<th>$\\LaTeX$ 命令</th>\n<th>渲染效果</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>并集</td>\n<td><code>A \\cup B</code></td>\n<td>$A \\cup B$</td>\n</tr>\n<tr>\n<td>交集</td>\n<td><code>A \\cap B</code></td>\n<td>$A \\cap B$</td>\n</tr>\n<tr>\n<td>属于</td>\n<td><code>x \\in A</code></td>\n<td>$x \\in A$</td>\n</tr>\n<tr>\n<td>不属于</td>\n<td><code>x \\notin B</code></td>\n<td>$x \\notin B$</td>\n</tr>\n<tr>\n<td>子集</td>\n<td><code>A \\subset B</code></td>\n<td>$A \\subset B$</td>\n</tr>\n<tr>\n<td>真子集</td>\n<td><code>A \\subseteq B</code></td>\n<td>$A \\subseteq B$</td>\n</tr>\n<tr>\n<td>空集</td>\n<td><code>\\emptyset</code></td>\n<td>$\\emptyset$</td>\n</tr>\n<tr>\n<td>实数集</td>\n<td><code>\\mathbb&#123;R&#125;</code></td>\n<td>$\\mathbb{R}$</td>\n</tr>\n<tr>\n<td>自然数集</td>\n<td><code>\\mathbb&#123;N&#125;</code></td>\n<td>$\\mathbb{N}$</td>\n</tr>\n</tbody></table>\n<hr>\n<h2 id=\"四、微积分符号\"><a href=\"#四、微积分符号\" class=\"headerlink\" title=\"四、微积分符号\"></a>四、微积分符号</h2><table>\n<thead>\n<tr>\n<th>符号名称</th>\n<th>$\\LaTeX$ 命令</th>\n<th>渲染效果</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>积分</td>\n<td><code>\\int_&#123;a&#125;^&#123;b&#125; f(x) dx</code></td>\n<td>$\\int_{a}^{b} f(x) dx$</td>\n</tr>\n<tr>\n<td>偏导数</td>\n<td><code>\\frac&#123;\\partial f&#125;&#123;\\partial x&#125;</code></td>\n<td>$\\frac{\\partial f}{\\partial x}$</td>\n</tr>\n<tr>\n<td>极限</td>\n<td><code>\\lim_&#123;x \\to 0&#125; \\frac&#123;\\sin x&#125;&#123;x&#125;</code></td>\n<td>$\\lim_{x \\to 0} \\frac{\\sin x}{x}$</td>\n</tr>\n<tr>\n<td>求和</td>\n<td><code>\\sum_&#123;i=1&#125;^&#123;n&#125; i^2</code></td>\n<td>$\\sum_{i&#x3D;1}^{n} i^2$</td>\n</tr>\n<tr>\n<td>导数（撇号形式）</td>\n<td><code>f&#39;(x)</code></td>\n<td>$f’(x)$</td>\n</tr>\n<tr>\n<td>梯度</td>\n<td><code>\\nabla f</code></td>\n<td>$\\nabla f$</td>\n</tr>\n<tr>\n<td>二阶导数</td>\n<td><code>\\frac&#123;d^2 y&#125;&#123;dx^2&#125;</code></td>\n<td>$\\frac{d^2 y}{dx^2}$</td>\n</tr>\n</tbody></table>\n<hr>\n<h2 id=\"五、希腊字母\"><a href=\"#五、希腊字母\" class=\"headerlink\" title=\"五、希腊字母\"></a>五、希腊字母</h2><table>\n<thead>\n<tr>\n<th>小写字母</th>\n<th>$\\LaTeX$ 命令</th>\n<th>渲染效果</th>\n<th>大写字母</th>\n<th>LaTeX 命令</th>\n<th>渲染效果</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>α (alpha)</td>\n<td><code>\\alpha</code></td>\n<td>$\\alpha$</td>\n<td>Γ (Gamma)</td>\n<td><code>\\Gamma</code></td>\n<td>$\\Gamma$</td>\n</tr>\n<tr>\n<td>β (beta)</td>\n<td><code>\\beta</code></td>\n<td>$\\beta$</td>\n<td>Δ (Delta)</td>\n<td><code>\\Delta</code></td>\n<td>$\\Delta$</td>\n</tr>\n<tr>\n<td>θ (theta)</td>\n<td><code>\\theta</code></td>\n<td>$\\theta$</td>\n<td>Θ (Theta)</td>\n<td><code>\\Theta</code></td>\n<td>$\\Theta$</td>\n</tr>\n<tr>\n<td>π (pi)</td>\n<td><code>\\pi</code></td>\n<td>$\\pi$</td>\n<td>Π (Pi)</td>\n<td><code>\\Pi</code></td>\n<td>$\\Pi$</td>\n</tr>\n<tr>\n<td>σ (sigma)</td>\n<td><code>\\sigma</code></td>\n<td>$\\sigma$</td>\n<td>Σ (Sigma)</td>\n<td><code>\\Sigma</code></td>\n<td>$\\Sigma$</td>\n</tr>\n</tbody></table>\n<hr>\n<h2 id=\"六、箭头符号\"><a href=\"#六、箭头符号\" class=\"headerlink\" title=\"六、箭头符号\"></a>六、箭头符号</h2><table>\n<thead>\n<tr>\n<th>符号名称</th>\n<th>$\\LaTeX$ 命令</th>\n<th>渲染效果</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>右箭头</td>\n<td><code>\\rightarrow</code></td>\n<td>$\\rightarrow$</td>\n</tr>\n<tr>\n<td>左箭头</td>\n<td><code>\\leftarrow</code></td>\n<td>$\\leftarrow$</td>\n</tr>\n<tr>\n<td>双向箭头</td>\n<td><code>\\leftrightarrow</code></td>\n<td>$\\leftrightarrow$</td>\n</tr>\n<tr>\n<td>蕴含符号</td>\n<td><code>\\Rightarrow</code></td>\n<td>$\\Rightarrow$</td>\n</tr>\n<tr>\n<td>等价符号</td>\n<td><code>\\Leftrightarrow</code></td>\n<td>$\\Leftrightarrow$</td>\n</tr>\n<tr>\n<td>映射箭头</td>\n<td><code>\\mapsto</code></td>\n<td>$\\mapsto$</td>\n</tr>\n</tbody></table>\n<hr>\n<h2 id=\"七、括号与定界符\"><a href=\"#七、括号与定界符\" class=\"headerlink\" title=\"七、括号与定界符\"></a>七、括号与定界符</h2><table>\n<thead>\n<tr>\n<th>符号名称</th>\n<th>$\\LaTeX$ 命令</th>\n<th>渲染效果</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>圆括号（自适应）</td>\n<td><code>\\left( \\frac&#123;a&#125;&#123;b&#125; \\right)</code></td>\n<td>$\\left( \\frac{a}{b} \\right)$</td>\n</tr>\n<tr>\n<td>方括号</td>\n<td><code>\\left[ x \\right]</code></td>\n<td>$\\left[ x \\right]$</td>\n</tr>\n<tr>\n<td>花括号</td>\n<td><code>\\left\\&#123; x \\right\\&#125;</code></td>\n<td>${ x }$</td>\n</tr>\n<tr>\n<td>绝对值</td>\n<td><code>\\lvert x \\rvert</code></td>\n<td>$\\lvert x \\rvert$</td>\n</tr>\n<tr>\n<td>范数</td>\n<td><code>\\lVert \\mathbf&#123;v&#125; \\rVert</code></td>\n<td>$\\lVert \\mathbf{v} \\rVert$</td>\n</tr>\n</tbody></table>\n<hr>\n<h2 id=\"八、矩阵环境\"><a href=\"#八、矩阵环境\" class=\"headerlink\" title=\"八、矩阵环境\"></a>八、矩阵环境</h2><figure class=\"highlight latex\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">$</span><span class=\"built_in\">$</span> </span><br><span class=\"line\"><span class=\"keyword\">\\begin</span>&#123;pmatrix&#125;  <span class=\"comment\">% 圆括号矩阵</span></span><br><span class=\"line\">a <span class=\"built_in\">&amp;</span> b <span class=\"keyword\">\\\\</span></span><br><span class=\"line\">c <span class=\"built_in\">&amp;</span> d </span><br><span class=\"line\"><span class=\"keyword\">\\end</span>&#123;pmatrix&#125;</span><br><span class=\"line\"><span class=\"keyword\">\\quad</span></span><br><span class=\"line\"><span class=\"keyword\">\\begin</span>&#123;bmatrix&#125;  <span class=\"comment\">% 方括号矩阵</span></span><br><span class=\"line\">a <span class=\"built_in\">&amp;</span> b <span class=\"keyword\">\\\\</span></span><br><span class=\"line\">c <span class=\"built_in\">&amp;</span> d </span><br><span class=\"line\"><span class=\"keyword\">\\end</span>&#123;bmatrix&#125;</span><br><span class=\"line\"><span class=\"keyword\">\\quad</span></span><br><span class=\"line\"><span class=\"keyword\">\\begin</span>&#123;vmatrix&#125;  <span class=\"comment\">% 行列式</span></span><br><span class=\"line\">a <span class=\"built_in\">&amp;</span> b <span class=\"keyword\">\\\\</span></span><br><span class=\"line\">c <span class=\"built_in\">&amp;</span> d </span><br><span class=\"line\"><span class=\"keyword\">\\end</span>&#123;vmatrix&#125;</span><br><span class=\"line\"><span class=\"built_in\">$</span><span class=\"built_in\">$</span></span><br></pre></td></tr></table></figure>\n<p>渲染效果：<br>$$<br>\\begin{pmatrix}  % 圆括号矩阵<br>a &amp; b \\<br>c &amp; d<br>\\end{pmatrix}<br>\\quad<br>\\begin{bmatrix}  % 方括号矩阵<br>a &amp; b \\<br>c &amp; d<br>\\end{bmatrix}<br>\\quad<br>\\begin{vmatrix}  % 行列式<br>a &amp; b \\<br>c &amp; d<br>\\end{vmatrix}<br>$$</p>\n<p>看样子花括号和矩阵都不太行啊。</p>\n"},{"title":"有趣的新闻网站","abbrlink":"25e54122","date":"2025-06-21T09:38:07.000Z","_content":"&emsp;&emsp;以下是有趣的新闻网站：\n  * [AllYouCanRead](https://www.allyoucanread.com/)是一个综合性资讯导航平台，按地域聚合全球六大洲新闻站点，同时以艺术、商业、科技等超 30 个主题精细分类各类网站资源，杂志专区更细分动物、时尚、育儿等数十个品类，通过清晰的结构化导航，为用户提供一站式全球新闻媒体与实用网站的定向检索服务。\n  * [Apple News](https://www.apple.com/apple-news)是苹果公司为iOS和macOS设备打造的官方新闻应用，它不仅整合主流新闻媒体的免费内容，还通过订阅服务 Apple News+ 提供大量杂志和深度报道。该平台以用户界面友好、内容精选优质而著称，尤其适合苹果生态中的用户日常阅读使用。借助苹果的算法推荐和编辑精选，用户可以在一个界面中阅读来自多家出版商的新闻、专题和评论。对于追求高品质阅读体验的用户，Apple News 提供了一种简洁但内容丰富的获取方式。\n  * [BBC News](https://www.bbc.com/news)是英国广播公司旗下的新闻平台，长期以客观、权威的报道风格受到全球用户信赖。它提供来自全球各地的实时新闻、深度分析、专题报道以及视频广播内容，尤其擅长以多语种进行国际传播，包括提供中文页面服务。BBC News 无需订阅即可访问，内容涵盖政治、科技、文化、健康等广泛领域，适合希望获取权威信息、提升英文阅读能力或关注全球动态的广大读者。\n  * [CNN](https://edition.cnn.com/)作为国际知名新闻平台，以实时追踪全球突发新闻为核心特色，24 小时不间断更新政治、经济、科技、文化及娱乐等领域资讯。其报道兼具速度与深度，既提供俄乌冲突、美国大选等热点事件的现场直击，也通过专家分析、纪录片等形式挖掘新闻背后的背景逻辑。\n  * [Flipboard](https://flipboard.com)是一个以“杂志式排版”为特色的新闻聚合与社交内容平台，用户可以根据自己的兴趣订阅特定主题、媒体或用户发布的内容源，并将喜欢的内容整理成属于自己的“杂志”。它强调视觉体验和内容个性化，非常适合喜欢图文并茂、轻松滑阅的移动端用户。Flipboard 支持离线阅读和多平台同步，并通过滑动式界面增强交互感，使其成为许多用户在通勤、碎片时间中快速获取资讯的理想选择。\n  * [Google News](https://news.google.com)是谷歌推出的一项新闻聚合服务，它通过智能算法从全球各大新闻网站实时抓取内容，为用户推送个性化、主题化的新闻报道。平台聚合同一事件来自不同媒体的视角，帮助读者全面了解事件全貌。其界面简洁、使用免费，同时支持桌面和移动端，是获取国际主流新闻、快速了解时事动态的便捷工具。用户还可以设置感兴趣的主题或地区，实现高度定制化的阅读体验，非常适合需要快速掌握新闻全局的用户。\n  * [Newsnow](https://www.newsnow.co.uk/h/)作为一个英国的多元新闻聚合平台，具备诸多显著优势。其新闻内容丰富多元，广泛涵盖英国、世界、商业、娱乐、体育及科技等各个领域，能够满足不同用户的多样化阅读需求。网站的界面设计简洁直观，分类清晰，便于用户快速定位感兴趣的新闻板块。其个性化推荐功能有助于用户发现更多符合个人喜好的内容。\n  * [NewsBrief](https://emm.newsbrief.eu/NewsBrief/clusteredition/en/latest.html)核心优势在于以分钟级速度聚合全球60+语言信源，通过AI驱动的动态聚类技术，将碎片化新闻提炼为可视化事件脉络，其独家\"EU Focus\"模块深度追踪28个欧盟机构政策动向，并支持跨事件对比分析，为政策研究者、商业机构提供学术级舆情洞察。\n  * [Newspaper Map](https://newspapermap.com/)通过地图可视化交互，直观聚合全球报纸资源，支持按地理位置一键直达各地新闻源，突破传统新闻检索的国界与语言限制。\n  * [Paperboy](https://www.thepaperboy.com/)在算法推荐新闻泛滥的时代，反其道而行，成为\"数字报亭式\"的古典新闻聚合平台，满足用户对传统报纸阅读体验的怀旧需求，同时解决地方性信息获取痛点。\n  * [PressReader](http://www.pressreader.com/)是一个汇集全球报纸和杂志的数字阅读平台，提供来自120多个国家、70多种语言的7000多份出版物原版内容。其最大优势在于内容全面、更新及时，涵盖新闻、财经、科技、时尚等多个领域。平台呈现与实体刊物一致的排版，支持全文搜索、多语种翻译、音频朗读与剪藏分享，提升了阅读的互动性和便捷性。\n  * [The New York Times](https://www.nytimes.com)是全球最具影响力的新闻机构之一，提供高质量的新闻报道、评论、深度专题和调查类文章。作为一个付费订阅平台，它以专业记者团队、深入独家的调查报道和精准的国际视角闻名，尤其在政治、经济、国际关系等领域具有广泛权威性。无论是通过网页还是手机 App，纽约时报为读者提供一种深入理解世界的方式，是重度新闻使用者、研究者和政策关注者的重要信息来源。\n  * [World News](https://wn.com/)提供全球新闻资讯，整合大量知名媒体的报道，涵盖政治、经济、社会、文化及自然灾害等丰富多样的新闻内容，更新及时，能够快速反映世界各地的最新动态。该网站界面简洁直观，以图文列表形式展示新闻，每条新闻都明确标注了来源媒体和发布时间，增强了新闻的可信度与透明度。\n  * [环球网国际新闻](https://world.huanqiu.com/)以 “全球视野、中国视角” 为核心，兼具时效性、权威性与多元覆盖，既关注国际政治经济格局的宏观变化，也聚焦与中国及华人相关的具体议题，通过结构化板块和图文结合的方式，为读者提供全面、及时的国际资讯。 \n  * [央视网](https://news.cctv.com/)作为国家级新媒体旗舰平台，既保持主流媒体的权威性，又通过技术创新实现“新闻+政务+服务”深度融合，是媒体融合发展的标杆案例。其核心优势在于依托总台内容资源库构建的全媒体传播体系，以及在无障碍访问等社会责任领域的先行实践。\n","source":"_posts/2025-06-21-news-website.md","raw":"---\ntitle: 有趣的新闻网站\ntags:\n  - Fun\ncategories:\n  - 杂\nabbrlink: '25e54122'\ndate: 2025-06-21 17:38:07\n---\n&emsp;&emsp;以下是有趣的新闻网站：\n  * [AllYouCanRead](https://www.allyoucanread.com/)是一个综合性资讯导航平台，按地域聚合全球六大洲新闻站点，同时以艺术、商业、科技等超 30 个主题精细分类各类网站资源，杂志专区更细分动物、时尚、育儿等数十个品类，通过清晰的结构化导航，为用户提供一站式全球新闻媒体与实用网站的定向检索服务。\n  * [Apple News](https://www.apple.com/apple-news)是苹果公司为iOS和macOS设备打造的官方新闻应用，它不仅整合主流新闻媒体的免费内容，还通过订阅服务 Apple News+ 提供大量杂志和深度报道。该平台以用户界面友好、内容精选优质而著称，尤其适合苹果生态中的用户日常阅读使用。借助苹果的算法推荐和编辑精选，用户可以在一个界面中阅读来自多家出版商的新闻、专题和评论。对于追求高品质阅读体验的用户，Apple News 提供了一种简洁但内容丰富的获取方式。\n  * [BBC News](https://www.bbc.com/news)是英国广播公司旗下的新闻平台，长期以客观、权威的报道风格受到全球用户信赖。它提供来自全球各地的实时新闻、深度分析、专题报道以及视频广播内容，尤其擅长以多语种进行国际传播，包括提供中文页面服务。BBC News 无需订阅即可访问，内容涵盖政治、科技、文化、健康等广泛领域，适合希望获取权威信息、提升英文阅读能力或关注全球动态的广大读者。\n  * [CNN](https://edition.cnn.com/)作为国际知名新闻平台，以实时追踪全球突发新闻为核心特色，24 小时不间断更新政治、经济、科技、文化及娱乐等领域资讯。其报道兼具速度与深度，既提供俄乌冲突、美国大选等热点事件的现场直击，也通过专家分析、纪录片等形式挖掘新闻背后的背景逻辑。\n  * [Flipboard](https://flipboard.com)是一个以“杂志式排版”为特色的新闻聚合与社交内容平台，用户可以根据自己的兴趣订阅特定主题、媒体或用户发布的内容源，并将喜欢的内容整理成属于自己的“杂志”。它强调视觉体验和内容个性化，非常适合喜欢图文并茂、轻松滑阅的移动端用户。Flipboard 支持离线阅读和多平台同步，并通过滑动式界面增强交互感，使其成为许多用户在通勤、碎片时间中快速获取资讯的理想选择。\n  * [Google News](https://news.google.com)是谷歌推出的一项新闻聚合服务，它通过智能算法从全球各大新闻网站实时抓取内容，为用户推送个性化、主题化的新闻报道。平台聚合同一事件来自不同媒体的视角，帮助读者全面了解事件全貌。其界面简洁、使用免费，同时支持桌面和移动端，是获取国际主流新闻、快速了解时事动态的便捷工具。用户还可以设置感兴趣的主题或地区，实现高度定制化的阅读体验，非常适合需要快速掌握新闻全局的用户。\n  * [Newsnow](https://www.newsnow.co.uk/h/)作为一个英国的多元新闻聚合平台，具备诸多显著优势。其新闻内容丰富多元，广泛涵盖英国、世界、商业、娱乐、体育及科技等各个领域，能够满足不同用户的多样化阅读需求。网站的界面设计简洁直观，分类清晰，便于用户快速定位感兴趣的新闻板块。其个性化推荐功能有助于用户发现更多符合个人喜好的内容。\n  * [NewsBrief](https://emm.newsbrief.eu/NewsBrief/clusteredition/en/latest.html)核心优势在于以分钟级速度聚合全球60+语言信源，通过AI驱动的动态聚类技术，将碎片化新闻提炼为可视化事件脉络，其独家\"EU Focus\"模块深度追踪28个欧盟机构政策动向，并支持跨事件对比分析，为政策研究者、商业机构提供学术级舆情洞察。\n  * [Newspaper Map](https://newspapermap.com/)通过地图可视化交互，直观聚合全球报纸资源，支持按地理位置一键直达各地新闻源，突破传统新闻检索的国界与语言限制。\n  * [Paperboy](https://www.thepaperboy.com/)在算法推荐新闻泛滥的时代，反其道而行，成为\"数字报亭式\"的古典新闻聚合平台，满足用户对传统报纸阅读体验的怀旧需求，同时解决地方性信息获取痛点。\n  * [PressReader](http://www.pressreader.com/)是一个汇集全球报纸和杂志的数字阅读平台，提供来自120多个国家、70多种语言的7000多份出版物原版内容。其最大优势在于内容全面、更新及时，涵盖新闻、财经、科技、时尚等多个领域。平台呈现与实体刊物一致的排版，支持全文搜索、多语种翻译、音频朗读与剪藏分享，提升了阅读的互动性和便捷性。\n  * [The New York Times](https://www.nytimes.com)是全球最具影响力的新闻机构之一，提供高质量的新闻报道、评论、深度专题和调查类文章。作为一个付费订阅平台，它以专业记者团队、深入独家的调查报道和精准的国际视角闻名，尤其在政治、经济、国际关系等领域具有广泛权威性。无论是通过网页还是手机 App，纽约时报为读者提供一种深入理解世界的方式，是重度新闻使用者、研究者和政策关注者的重要信息来源。\n  * [World News](https://wn.com/)提供全球新闻资讯，整合大量知名媒体的报道，涵盖政治、经济、社会、文化及自然灾害等丰富多样的新闻内容，更新及时，能够快速反映世界各地的最新动态。该网站界面简洁直观，以图文列表形式展示新闻，每条新闻都明确标注了来源媒体和发布时间，增强了新闻的可信度与透明度。\n  * [环球网国际新闻](https://world.huanqiu.com/)以 “全球视野、中国视角” 为核心，兼具时效性、权威性与多元覆盖，既关注国际政治经济格局的宏观变化，也聚焦与中国及华人相关的具体议题，通过结构化板块和图文结合的方式，为读者提供全面、及时的国际资讯。 \n  * [央视网](https://news.cctv.com/)作为国家级新媒体旗舰平台，既保持主流媒体的权威性，又通过技术创新实现“新闻+政务+服务”深度融合，是媒体融合发展的标杆案例。其核心优势在于依托总台内容资源库构建的全媒体传播体系，以及在无障碍访问等社会责任领域的先行实践。\n","slug":"news-website","published":1,"updated":"2025-06-21T11:23:03.220Z","comments":1,"layout":"post","photos":[],"_id":"cmh498iqk00dlwvou9815gcyr","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>&emsp;&emsp;以下是有趣的新闻网站：</p>\n<ul>\n<li><a href=\"https://www.allyoucanread.com/\">AllYouCanRead</a>是一个综合性资讯导航平台，按地域聚合全球六大洲新闻站点，同时以艺术、商业、科技等超 30 个主题精细分类各类网站资源，杂志专区更细分动物、时尚、育儿等数十个品类，通过清晰的结构化导航，为用户提供一站式全球新闻媒体与实用网站的定向检索服务。</li>\n<li><a href=\"https://www.apple.com/apple-news\">Apple News</a>是苹果公司为iOS和macOS设备打造的官方新闻应用，它不仅整合主流新闻媒体的免费内容，还通过订阅服务 Apple News+ 提供大量杂志和深度报道。该平台以用户界面友好、内容精选优质而著称，尤其适合苹果生态中的用户日常阅读使用。借助苹果的算法推荐和编辑精选，用户可以在一个界面中阅读来自多家出版商的新闻、专题和评论。对于追求高品质阅读体验的用户，Apple News 提供了一种简洁但内容丰富的获取方式。</li>\n<li><a href=\"https://www.bbc.com/news\">BBC News</a>是英国广播公司旗下的新闻平台，长期以客观、权威的报道风格受到全球用户信赖。它提供来自全球各地的实时新闻、深度分析、专题报道以及视频广播内容，尤其擅长以多语种进行国际传播，包括提供中文页面服务。BBC News 无需订阅即可访问，内容涵盖政治、科技、文化、健康等广泛领域，适合希望获取权威信息、提升英文阅读能力或关注全球动态的广大读者。</li>\n<li><a href=\"https://edition.cnn.com/\">CNN</a>作为国际知名新闻平台，以实时追踪全球突发新闻为核心特色，24 小时不间断更新政治、经济、科技、文化及娱乐等领域资讯。其报道兼具速度与深度，既提供俄乌冲突、美国大选等热点事件的现场直击，也通过专家分析、纪录片等形式挖掘新闻背后的背景逻辑。</li>\n<li><a href=\"https://flipboard.com/\">Flipboard</a>是一个以“杂志式排版”为特色的新闻聚合与社交内容平台，用户可以根据自己的兴趣订阅特定主题、媒体或用户发布的内容源，并将喜欢的内容整理成属于自己的“杂志”。它强调视觉体验和内容个性化，非常适合喜欢图文并茂、轻松滑阅的移动端用户。Flipboard 支持离线阅读和多平台同步，并通过滑动式界面增强交互感，使其成为许多用户在通勤、碎片时间中快速获取资讯的理想选择。</li>\n<li><a href=\"https://news.google.com/\">Google News</a>是谷歌推出的一项新闻聚合服务，它通过智能算法从全球各大新闻网站实时抓取内容，为用户推送个性化、主题化的新闻报道。平台聚合同一事件来自不同媒体的视角，帮助读者全面了解事件全貌。其界面简洁、使用免费，同时支持桌面和移动端，是获取国际主流新闻、快速了解时事动态的便捷工具。用户还可以设置感兴趣的主题或地区，实现高度定制化的阅读体验，非常适合需要快速掌握新闻全局的用户。</li>\n<li><a href=\"https://www.newsnow.co.uk/h/\">Newsnow</a>作为一个英国的多元新闻聚合平台，具备诸多显著优势。其新闻内容丰富多元，广泛涵盖英国、世界、商业、娱乐、体育及科技等各个领域，能够满足不同用户的多样化阅读需求。网站的界面设计简洁直观，分类清晰，便于用户快速定位感兴趣的新闻板块。其个性化推荐功能有助于用户发现更多符合个人喜好的内容。</li>\n<li><a href=\"https://emm.newsbrief.eu/NewsBrief/clusteredition/en/latest.html\">NewsBrief</a>核心优势在于以分钟级速度聚合全球60+语言信源，通过AI驱动的动态聚类技术，将碎片化新闻提炼为可视化事件脉络，其独家”EU Focus”模块深度追踪28个欧盟机构政策动向，并支持跨事件对比分析，为政策研究者、商业机构提供学术级舆情洞察。</li>\n<li><a href=\"https://newspapermap.com/\">Newspaper Map</a>通过地图可视化交互，直观聚合全球报纸资源，支持按地理位置一键直达各地新闻源，突破传统新闻检索的国界与语言限制。</li>\n<li><a href=\"https://www.thepaperboy.com/\">Paperboy</a>在算法推荐新闻泛滥的时代，反其道而行，成为”数字报亭式”的古典新闻聚合平台，满足用户对传统报纸阅读体验的怀旧需求，同时解决地方性信息获取痛点。</li>\n<li><a href=\"http://www.pressreader.com/\">PressReader</a>是一个汇集全球报纸和杂志的数字阅读平台，提供来自120多个国家、70多种语言的7000多份出版物原版内容。其最大优势在于内容全面、更新及时，涵盖新闻、财经、科技、时尚等多个领域。平台呈现与实体刊物一致的排版，支持全文搜索、多语种翻译、音频朗读与剪藏分享，提升了阅读的互动性和便捷性。</li>\n<li><a href=\"https://www.nytimes.com/\">The New York Times</a>是全球最具影响力的新闻机构之一，提供高质量的新闻报道、评论、深度专题和调查类文章。作为一个付费订阅平台，它以专业记者团队、深入独家的调查报道和精准的国际视角闻名，尤其在政治、经济、国际关系等领域具有广泛权威性。无论是通过网页还是手机 App，纽约时报为读者提供一种深入理解世界的方式，是重度新闻使用者、研究者和政策关注者的重要信息来源。</li>\n<li><a href=\"https://wn.com/\">World News</a>提供全球新闻资讯，整合大量知名媒体的报道，涵盖政治、经济、社会、文化及自然灾害等丰富多样的新闻内容，更新及时，能够快速反映世界各地的最新动态。该网站界面简洁直观，以图文列表形式展示新闻，每条新闻都明确标注了来源媒体和发布时间，增强了新闻的可信度与透明度。</li>\n<li><a href=\"https://world.huanqiu.com/\">环球网国际新闻</a>以 “全球视野、中国视角” 为核心，兼具时效性、权威性与多元覆盖，既关注国际政治经济格局的宏观变化，也聚焦与中国及华人相关的具体议题，通过结构化板块和图文结合的方式，为读者提供全面、及时的国际资讯。 </li>\n<li><a href=\"https://news.cctv.com/\">央视网</a>作为国家级新媒体旗舰平台，既保持主流媒体的权威性，又通过技术创新实现“新闻+政务+服务”深度融合，是媒体融合发展的标杆案例。其核心优势在于依托总台内容资源库构建的全媒体传播体系，以及在无障碍访问等社会责任领域的先行实践。</li>\n</ul>\n","related_posts":[],"length":2137,"excerpt":"","more":"<p>&emsp;&emsp;以下是有趣的新闻网站：</p>\n<ul>\n<li><a href=\"https://www.allyoucanread.com/\">AllYouCanRead</a>是一个综合性资讯导航平台，按地域聚合全球六大洲新闻站点，同时以艺术、商业、科技等超 30 个主题精细分类各类网站资源，杂志专区更细分动物、时尚、育儿等数十个品类，通过清晰的结构化导航，为用户提供一站式全球新闻媒体与实用网站的定向检索服务。</li>\n<li><a href=\"https://www.apple.com/apple-news\">Apple News</a>是苹果公司为iOS和macOS设备打造的官方新闻应用，它不仅整合主流新闻媒体的免费内容，还通过订阅服务 Apple News+ 提供大量杂志和深度报道。该平台以用户界面友好、内容精选优质而著称，尤其适合苹果生态中的用户日常阅读使用。借助苹果的算法推荐和编辑精选，用户可以在一个界面中阅读来自多家出版商的新闻、专题和评论。对于追求高品质阅读体验的用户，Apple News 提供了一种简洁但内容丰富的获取方式。</li>\n<li><a href=\"https://www.bbc.com/news\">BBC News</a>是英国广播公司旗下的新闻平台，长期以客观、权威的报道风格受到全球用户信赖。它提供来自全球各地的实时新闻、深度分析、专题报道以及视频广播内容，尤其擅长以多语种进行国际传播，包括提供中文页面服务。BBC News 无需订阅即可访问，内容涵盖政治、科技、文化、健康等广泛领域，适合希望获取权威信息、提升英文阅读能力或关注全球动态的广大读者。</li>\n<li><a href=\"https://edition.cnn.com/\">CNN</a>作为国际知名新闻平台，以实时追踪全球突发新闻为核心特色，24 小时不间断更新政治、经济、科技、文化及娱乐等领域资讯。其报道兼具速度与深度，既提供俄乌冲突、美国大选等热点事件的现场直击，也通过专家分析、纪录片等形式挖掘新闻背后的背景逻辑。</li>\n<li><a href=\"https://flipboard.com/\">Flipboard</a>是一个以“杂志式排版”为特色的新闻聚合与社交内容平台，用户可以根据自己的兴趣订阅特定主题、媒体或用户发布的内容源，并将喜欢的内容整理成属于自己的“杂志”。它强调视觉体验和内容个性化，非常适合喜欢图文并茂、轻松滑阅的移动端用户。Flipboard 支持离线阅读和多平台同步，并通过滑动式界面增强交互感，使其成为许多用户在通勤、碎片时间中快速获取资讯的理想选择。</li>\n<li><a href=\"https://news.google.com/\">Google News</a>是谷歌推出的一项新闻聚合服务，它通过智能算法从全球各大新闻网站实时抓取内容，为用户推送个性化、主题化的新闻报道。平台聚合同一事件来自不同媒体的视角，帮助读者全面了解事件全貌。其界面简洁、使用免费，同时支持桌面和移动端，是获取国际主流新闻、快速了解时事动态的便捷工具。用户还可以设置感兴趣的主题或地区，实现高度定制化的阅读体验，非常适合需要快速掌握新闻全局的用户。</li>\n<li><a href=\"https://www.newsnow.co.uk/h/\">Newsnow</a>作为一个英国的多元新闻聚合平台，具备诸多显著优势。其新闻内容丰富多元，广泛涵盖英国、世界、商业、娱乐、体育及科技等各个领域，能够满足不同用户的多样化阅读需求。网站的界面设计简洁直观，分类清晰，便于用户快速定位感兴趣的新闻板块。其个性化推荐功能有助于用户发现更多符合个人喜好的内容。</li>\n<li><a href=\"https://emm.newsbrief.eu/NewsBrief/clusteredition/en/latest.html\">NewsBrief</a>核心优势在于以分钟级速度聚合全球60+语言信源，通过AI驱动的动态聚类技术，将碎片化新闻提炼为可视化事件脉络，其独家”EU Focus”模块深度追踪28个欧盟机构政策动向，并支持跨事件对比分析，为政策研究者、商业机构提供学术级舆情洞察。</li>\n<li><a href=\"https://newspapermap.com/\">Newspaper Map</a>通过地图可视化交互，直观聚合全球报纸资源，支持按地理位置一键直达各地新闻源，突破传统新闻检索的国界与语言限制。</li>\n<li><a href=\"https://www.thepaperboy.com/\">Paperboy</a>在算法推荐新闻泛滥的时代，反其道而行，成为”数字报亭式”的古典新闻聚合平台，满足用户对传统报纸阅读体验的怀旧需求，同时解决地方性信息获取痛点。</li>\n<li><a href=\"http://www.pressreader.com/\">PressReader</a>是一个汇集全球报纸和杂志的数字阅读平台，提供来自120多个国家、70多种语言的7000多份出版物原版内容。其最大优势在于内容全面、更新及时，涵盖新闻、财经、科技、时尚等多个领域。平台呈现与实体刊物一致的排版，支持全文搜索、多语种翻译、音频朗读与剪藏分享，提升了阅读的互动性和便捷性。</li>\n<li><a href=\"https://www.nytimes.com/\">The New York Times</a>是全球最具影响力的新闻机构之一，提供高质量的新闻报道、评论、深度专题和调查类文章。作为一个付费订阅平台，它以专业记者团队、深入独家的调查报道和精准的国际视角闻名，尤其在政治、经济、国际关系等领域具有广泛权威性。无论是通过网页还是手机 App，纽约时报为读者提供一种深入理解世界的方式，是重度新闻使用者、研究者和政策关注者的重要信息来源。</li>\n<li><a href=\"https://wn.com/\">World News</a>提供全球新闻资讯，整合大量知名媒体的报道，涵盖政治、经济、社会、文化及自然灾害等丰富多样的新闻内容，更新及时，能够快速反映世界各地的最新动态。该网站界面简洁直观，以图文列表形式展示新闻，每条新闻都明确标注了来源媒体和发布时间，增强了新闻的可信度与透明度。</li>\n<li><a href=\"https://world.huanqiu.com/\">环球网国际新闻</a>以 “全球视野、中国视角” 为核心，兼具时效性、权威性与多元覆盖，既关注国际政治经济格局的宏观变化，也聚焦与中国及华人相关的具体议题，通过结构化板块和图文结合的方式，为读者提供全面、及时的国际资讯。 </li>\n<li><a href=\"https://news.cctv.com/\">央视网</a>作为国家级新媒体旗舰平台，既保持主流媒体的权威性，又通过技术创新实现“新闻+政务+服务”深度融合，是媒体融合发展的标杆案例。其核心优势在于依托总台内容资源库构建的全媒体传播体系，以及在无障碍访问等社会责任领域的先行实践。</li>\n</ul>\n"},{"title":"PYTHON脚本练习（一）","abbrlink":"588cd39d","date":"2025-06-21T06:29:56.000Z","_content":"&emsp;&emsp;以下是python脚本练习1，功能包括：\n  * 遍历目录events_20250619下所有子目录中以bhz.SAC_rm结尾的SAC文件；\n  * 对这些数据进行窄带滤波，宽度为中心频率（周期分之一）的$\\pm$5mHz，滤波器为4个极点0相位的Butterworth，滤波周期为arange(25,145,10)；\n  * 计算窄带滤波后的每个周期的信噪比。信噪比定义为信号窗口内，波形包络的最大值比上噪声窗口的均方根。信号窗口定义为2.5-5km/s的到时。噪声窗定义为信号末端之后1000秒开始的1000秒长度的窗口。计算的信噪比写入到user0；\n  * 将处理后的数据写到新的文件夹bp_sac中，文件名命名为z.year.jday.00.STA.bhz.period，仅保留信噪比大于3的数据。\n  * 采用并行处理(8个cpu)。\n  * 统计每个周期信噪比大于3的波形数据。\n  * 统计每个周期信噪比大于3的波形的平均信噪比。\n  * 将统计结构写入csv，并画出统计结果。\n```\nimport os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom obspy import read\nfrom obspy.signal.filter import envelope\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\nfrom collections import defaultdict\n\n# 参数设置 \ninput_root = \"events_20250619\"\noutput_root = \"bp_sac\"\ncenter_periods = np.arange(25, 150, 10)\nbandwidth = 0.010\nvmin, vmax = 2.5, 5.0\nnoise_offset, noise_len = 1000, 1000\nsnr_threshold = 3.0\nmax_workers = 8  # 根据 CPU 核心数调整\n\n# 存储每个周期的 SNR 值\nperiod_snr_map = defaultdict(list)\n\ndef process_file(filepath, root):\n    results = []\n    try:\n        st = read(filepath)\n        tr = st[0]\n        sac = tr.stats.sac\n    except Exception as e:\n        print(f\"跳过 {filepath}: {e}\")\n        return results\n\n    if not hasattr(sac, \"o\") or not hasattr(sac, \"dist\"):\n        return results\n\n    dist = sac.dist\n    starttime = tr.stats.starttime\n    win_start = starttime + dist / vmax\n    win_end = starttime + dist / vmin\n    t = tr.times()\n    abs_time = np.array([starttime + float(tt) for tt in t])\n\n    for period in center_periods:\n        fc = 1.0 / period\n        fmin, fmax = fc - bandwidth / 2, fc + bandwidth / 2\n        if fmin <= 0:\n            continue\n        tr_filt = tr.copy()\n        tr_filt.detrend(\"demean\")\n        tr_filt.taper(0.05)\n        tr_filt.filter(\"bandpass\", freqmin=fmin, freqmax=fmax, corners=4, zerophase=True)\n        env = envelope(tr_filt.data)\n        idx_sig = np.where((abs_time >= win_start) & (abs_time <= win_end))[0]\n        if len(idx_sig) == 0:\n            continue\n        signal_max = np.max(env[idx_sig])\n        noise_start = win_end + noise_offset\n        noise_end = noise_start + noise_len\n        idx_noise = np.where((abs_time >= noise_start) & (abs_time <= noise_end))[0]\n        if len(idx_noise) == 0:\n            continue\n        noise_rms = np.sqrt(np.mean(env[idx_noise] ** 2))\n        snr = signal_max / noise_rms if noise_rms > 0 else 0\n\n        if snr >= snr_threshold:\n            tr_filt.stats.sac.user0 = snr\n            year = tr.stats.starttime.year\n            jday = tr.stats.starttime.julday\n            station = tr.stats.station.lower()\n            channel = tr.stats.channel.lower()\n            outname = f\"z.{year}.{jday:03d}.00.{station}.{channel}.{period:03d}\"\n\n            rel_dir = os.path.relpath(root, input_root)\n            out_dir = os.path.join(output_root, rel_dir)\n            os.makedirs(out_dir, exist_ok=True)\n            outpath = os.path.join(out_dir, outname)\n            tr_filt.write(outpath, format=\"SAC\")\n\n            results.append((period, snr))\n            print(f\"✔ 保存: {outname}, SNR={snr:.2f}\")\n\n    return results\n# ===== 收集所有文件路径 =====\nall_files = []\nfor root, dirs, files in os.walk(input_root):\n    for file in files:\n        if file.endswith(\"bhz.SAC_rm\"):\n            all_files.append((os.path.join(root, file), root))\n\nprint(f\"📁 待处理文件数: {len(all_files)}\")\n\n# ===== 并行处理 =====\nwith ThreadPoolExecutor(max_workers=max_workers) as executor:\n    future_to_file = {executor.submit(process_file, fpath, root): (fpath, root) for fpath, root in all_files}\n    for future in as_completed(future_to_file):\n        try:\n            result = future.result()\n            for period, snr in result:\n                period_snr_map[period].append(snr)\n        except Exception as e:\n            fpath, _ = future_to_file[future]\n            print(f\"❌ 文件出错 {fpath}: {e}\")\n\n# ===== 统计与可视化 =====\nperiods = sorted(period_snr_map.keys())\ncounts = [len(period_snr_map[p]) for p in periods]\nmeans = [np.mean(period_snr_map[p]) if len(period_snr_map[p]) > 0 else 0 for p in periods]\n\ndf = pd.DataFrame({\n    \"Period(s)\": periods,\n    \"Count(SNR>3)\": counts,\n    \"Mean_SNR(SNR>3)\": means\n})\ndf.to_csv(\"snr_stats.csv\", index=False)\n\n# === 可视化 ===\nplt.figure(figsize=(10, 6))\nplt.bar(periods, counts, width=4, color='skyblue', edgecolor='black')\nplt.xlabel(\"Period (s)\")\nplt.ylabel(\"Count of SNR > 3\")\nplt.title(\"Number of Traces with SNR > 3 per Period\")\nplt.grid(True, linestyle=\"--\", alpha=0.5)\nplt.tight_layout()\nplt.savefig(\"snr_count_bar.png\", dpi=150)\n\nplt.figure(figsize=(10, 6))\nplt.plot(periods, means, marker='o', linestyle='-', color='orange')\nplt.xlabel(\"Period (s)\")\nplt.ylabel(\"Mean SNR (SNR > 3)\")\nplt.title(\"Mean SNR of Traces with SNR > 3 per Period\")\nplt.grid(True, linestyle=\"--\", alpha=0.5)\nplt.tight_layout()\nplt.savefig(\"snr_mean_line.png\", dpi=150)\n\nprint(\"🎉 并行处理完成，统计结果写入 snr_stats.csv\")\n```\n","source":"_posts/2025-06-21-python-script1.md","raw":"---\ntitle: PYTHON脚本练习（一）\ntags:\n  - python\ncategories:\n  - work\nabbrlink: 588cd39d\ndate: 2025-06-21 14:29:56\n---\n&emsp;&emsp;以下是python脚本练习1，功能包括：\n  * 遍历目录events_20250619下所有子目录中以bhz.SAC_rm结尾的SAC文件；\n  * 对这些数据进行窄带滤波，宽度为中心频率（周期分之一）的$\\pm$5mHz，滤波器为4个极点0相位的Butterworth，滤波周期为arange(25,145,10)；\n  * 计算窄带滤波后的每个周期的信噪比。信噪比定义为信号窗口内，波形包络的最大值比上噪声窗口的均方根。信号窗口定义为2.5-5km/s的到时。噪声窗定义为信号末端之后1000秒开始的1000秒长度的窗口。计算的信噪比写入到user0；\n  * 将处理后的数据写到新的文件夹bp_sac中，文件名命名为z.year.jday.00.STA.bhz.period，仅保留信噪比大于3的数据。\n  * 采用并行处理(8个cpu)。\n  * 统计每个周期信噪比大于3的波形数据。\n  * 统计每个周期信噪比大于3的波形的平均信噪比。\n  * 将统计结构写入csv，并画出统计结果。\n```\nimport os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom obspy import read\nfrom obspy.signal.filter import envelope\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\nfrom collections import defaultdict\n\n# 参数设置 \ninput_root = \"events_20250619\"\noutput_root = \"bp_sac\"\ncenter_periods = np.arange(25, 150, 10)\nbandwidth = 0.010\nvmin, vmax = 2.5, 5.0\nnoise_offset, noise_len = 1000, 1000\nsnr_threshold = 3.0\nmax_workers = 8  # 根据 CPU 核心数调整\n\n# 存储每个周期的 SNR 值\nperiod_snr_map = defaultdict(list)\n\ndef process_file(filepath, root):\n    results = []\n    try:\n        st = read(filepath)\n        tr = st[0]\n        sac = tr.stats.sac\n    except Exception as e:\n        print(f\"跳过 {filepath}: {e}\")\n        return results\n\n    if not hasattr(sac, \"o\") or not hasattr(sac, \"dist\"):\n        return results\n\n    dist = sac.dist\n    starttime = tr.stats.starttime\n    win_start = starttime + dist / vmax\n    win_end = starttime + dist / vmin\n    t = tr.times()\n    abs_time = np.array([starttime + float(tt) for tt in t])\n\n    for period in center_periods:\n        fc = 1.0 / period\n        fmin, fmax = fc - bandwidth / 2, fc + bandwidth / 2\n        if fmin <= 0:\n            continue\n        tr_filt = tr.copy()\n        tr_filt.detrend(\"demean\")\n        tr_filt.taper(0.05)\n        tr_filt.filter(\"bandpass\", freqmin=fmin, freqmax=fmax, corners=4, zerophase=True)\n        env = envelope(tr_filt.data)\n        idx_sig = np.where((abs_time >= win_start) & (abs_time <= win_end))[0]\n        if len(idx_sig) == 0:\n            continue\n        signal_max = np.max(env[idx_sig])\n        noise_start = win_end + noise_offset\n        noise_end = noise_start + noise_len\n        idx_noise = np.where((abs_time >= noise_start) & (abs_time <= noise_end))[0]\n        if len(idx_noise) == 0:\n            continue\n        noise_rms = np.sqrt(np.mean(env[idx_noise] ** 2))\n        snr = signal_max / noise_rms if noise_rms > 0 else 0\n\n        if snr >= snr_threshold:\n            tr_filt.stats.sac.user0 = snr\n            year = tr.stats.starttime.year\n            jday = tr.stats.starttime.julday\n            station = tr.stats.station.lower()\n            channel = tr.stats.channel.lower()\n            outname = f\"z.{year}.{jday:03d}.00.{station}.{channel}.{period:03d}\"\n\n            rel_dir = os.path.relpath(root, input_root)\n            out_dir = os.path.join(output_root, rel_dir)\n            os.makedirs(out_dir, exist_ok=True)\n            outpath = os.path.join(out_dir, outname)\n            tr_filt.write(outpath, format=\"SAC\")\n\n            results.append((period, snr))\n            print(f\"✔ 保存: {outname}, SNR={snr:.2f}\")\n\n    return results\n# ===== 收集所有文件路径 =====\nall_files = []\nfor root, dirs, files in os.walk(input_root):\n    for file in files:\n        if file.endswith(\"bhz.SAC_rm\"):\n            all_files.append((os.path.join(root, file), root))\n\nprint(f\"📁 待处理文件数: {len(all_files)}\")\n\n# ===== 并行处理 =====\nwith ThreadPoolExecutor(max_workers=max_workers) as executor:\n    future_to_file = {executor.submit(process_file, fpath, root): (fpath, root) for fpath, root in all_files}\n    for future in as_completed(future_to_file):\n        try:\n            result = future.result()\n            for period, snr in result:\n                period_snr_map[period].append(snr)\n        except Exception as e:\n            fpath, _ = future_to_file[future]\n            print(f\"❌ 文件出错 {fpath}: {e}\")\n\n# ===== 统计与可视化 =====\nperiods = sorted(period_snr_map.keys())\ncounts = [len(period_snr_map[p]) for p in periods]\nmeans = [np.mean(period_snr_map[p]) if len(period_snr_map[p]) > 0 else 0 for p in periods]\n\ndf = pd.DataFrame({\n    \"Period(s)\": periods,\n    \"Count(SNR>3)\": counts,\n    \"Mean_SNR(SNR>3)\": means\n})\ndf.to_csv(\"snr_stats.csv\", index=False)\n\n# === 可视化 ===\nplt.figure(figsize=(10, 6))\nplt.bar(periods, counts, width=4, color='skyblue', edgecolor='black')\nplt.xlabel(\"Period (s)\")\nplt.ylabel(\"Count of SNR > 3\")\nplt.title(\"Number of Traces with SNR > 3 per Period\")\nplt.grid(True, linestyle=\"--\", alpha=0.5)\nplt.tight_layout()\nplt.savefig(\"snr_count_bar.png\", dpi=150)\n\nplt.figure(figsize=(10, 6))\nplt.plot(periods, means, marker='o', linestyle='-', color='orange')\nplt.xlabel(\"Period (s)\")\nplt.ylabel(\"Mean SNR (SNR > 3)\")\nplt.title(\"Mean SNR of Traces with SNR > 3 per Period\")\nplt.grid(True, linestyle=\"--\", alpha=0.5)\nplt.tight_layout()\nplt.savefig(\"snr_mean_line.png\", dpi=150)\n\nprint(\"🎉 并行处理完成，统计结果写入 snr_stats.csv\")\n```\n","slug":"python-script1","published":1,"updated":"2025-06-30T13:31:09.319Z","comments":1,"layout":"post","photos":[],"_id":"cmh498iql00dowvou3cfygoar","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>&emsp;&emsp;以下是python脚本练习1，功能包括：</p>\n<ul>\n<li>遍历目录events_20250619下所有子目录中以bhz.SAC_rm结尾的SAC文件；</li>\n<li>对这些数据进行窄带滤波，宽度为中心频率（周期分之一）的$\\pm$5mHz，滤波器为4个极点0相位的Butterworth，滤波周期为arange(25,145,10)；</li>\n<li>计算窄带滤波后的每个周期的信噪比。信噪比定义为信号窗口内，波形包络的最大值比上噪声窗口的均方根。信号窗口定义为2.5-5km&#x2F;s的到时。噪声窗定义为信号末端之后1000秒开始的1000秒长度的窗口。计算的信噪比写入到user0；</li>\n<li>将处理后的数据写到新的文件夹bp_sac中，文件名命名为z.year.jday.00.STA.bhz.period，仅保留信噪比大于3的数据。</li>\n<li>采用并行处理(8个cpu)。</li>\n<li>统计每个周期信噪比大于3的波形数据。</li>\n<li>统计每个周期信噪比大于3的波形的平均信噪比。</li>\n<li>将统计结构写入csv，并画出统计结果。<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">import os</span><br><span class=\"line\">import numpy as np</span><br><span class=\"line\">import pandas as pd</span><br><span class=\"line\">import matplotlib.pyplot as plt</span><br><span class=\"line\">from obspy import read</span><br><span class=\"line\">from obspy.signal.filter import envelope</span><br><span class=\"line\">from concurrent.futures import ThreadPoolExecutor, as_completed</span><br><span class=\"line\">from collections import defaultdict</span><br><span class=\"line\"></span><br><span class=\"line\"># 参数设置 </span><br><span class=\"line\">input_root = &quot;events_20250619&quot;</span><br><span class=\"line\">output_root = &quot;bp_sac&quot;</span><br><span class=\"line\">center_periods = np.arange(25, 150, 10)</span><br><span class=\"line\">bandwidth = 0.010</span><br><span class=\"line\">vmin, vmax = 2.5, 5.0</span><br><span class=\"line\">noise_offset, noise_len = 1000, 1000</span><br><span class=\"line\">snr_threshold = 3.0</span><br><span class=\"line\">max_workers = 8  # 根据 CPU 核心数调整</span><br><span class=\"line\"></span><br><span class=\"line\"># 存储每个周期的 SNR 值</span><br><span class=\"line\">period_snr_map = defaultdict(list)</span><br><span class=\"line\"></span><br><span class=\"line\">def process_file(filepath, root):</span><br><span class=\"line\">    results = []</span><br><span class=\"line\">    try:</span><br><span class=\"line\">        st = read(filepath)</span><br><span class=\"line\">        tr = st[0]</span><br><span class=\"line\">        sac = tr.stats.sac</span><br><span class=\"line\">    except Exception as e:</span><br><span class=\"line\">        print(f&quot;跳过 &#123;filepath&#125;: &#123;e&#125;&quot;)</span><br><span class=\"line\">        return results</span><br><span class=\"line\"></span><br><span class=\"line\">    if not hasattr(sac, &quot;o&quot;) or not hasattr(sac, &quot;dist&quot;):</span><br><span class=\"line\">        return results</span><br><span class=\"line\"></span><br><span class=\"line\">    dist = sac.dist</span><br><span class=\"line\">    starttime = tr.stats.starttime</span><br><span class=\"line\">    win_start = starttime + dist / vmax</span><br><span class=\"line\">    win_end = starttime + dist / vmin</span><br><span class=\"line\">    t = tr.times()</span><br><span class=\"line\">    abs_time = np.array([starttime + float(tt) for tt in t])</span><br><span class=\"line\"></span><br><span class=\"line\">    for period in center_periods:</span><br><span class=\"line\">        fc = 1.0 / period</span><br><span class=\"line\">        fmin, fmax = fc - bandwidth / 2, fc + bandwidth / 2</span><br><span class=\"line\">        if fmin &lt;= 0:</span><br><span class=\"line\">            continue</span><br><span class=\"line\">        tr_filt = tr.copy()</span><br><span class=\"line\">        tr_filt.detrend(&quot;demean&quot;)</span><br><span class=\"line\">        tr_filt.taper(0.05)</span><br><span class=\"line\">        tr_filt.filter(&quot;bandpass&quot;, freqmin=fmin, freqmax=fmax, corners=4, zerophase=True)</span><br><span class=\"line\">        env = envelope(tr_filt.data)</span><br><span class=\"line\">        idx_sig = np.where((abs_time &gt;= win_start) &amp; (abs_time &lt;= win_end))[0]</span><br><span class=\"line\">        if len(idx_sig) == 0:</span><br><span class=\"line\">            continue</span><br><span class=\"line\">        signal_max = np.max(env[idx_sig])</span><br><span class=\"line\">        noise_start = win_end + noise_offset</span><br><span class=\"line\">        noise_end = noise_start + noise_len</span><br><span class=\"line\">        idx_noise = np.where((abs_time &gt;= noise_start) &amp; (abs_time &lt;= noise_end))[0]</span><br><span class=\"line\">        if len(idx_noise) == 0:</span><br><span class=\"line\">            continue</span><br><span class=\"line\">        noise_rms = np.sqrt(np.mean(env[idx_noise] ** 2))</span><br><span class=\"line\">        snr = signal_max / noise_rms if noise_rms &gt; 0 else 0</span><br><span class=\"line\"></span><br><span class=\"line\">        if snr &gt;= snr_threshold:</span><br><span class=\"line\">            tr_filt.stats.sac.user0 = snr</span><br><span class=\"line\">            year = tr.stats.starttime.year</span><br><span class=\"line\">            jday = tr.stats.starttime.julday</span><br><span class=\"line\">            station = tr.stats.station.lower()</span><br><span class=\"line\">            channel = tr.stats.channel.lower()</span><br><span class=\"line\">            outname = f&quot;z.&#123;year&#125;.&#123;jday:03d&#125;.00.&#123;station&#125;.&#123;channel&#125;.&#123;period:03d&#125;&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">            rel_dir = os.path.relpath(root, input_root)</span><br><span class=\"line\">            out_dir = os.path.join(output_root, rel_dir)</span><br><span class=\"line\">            os.makedirs(out_dir, exist_ok=True)</span><br><span class=\"line\">            outpath = os.path.join(out_dir, outname)</span><br><span class=\"line\">            tr_filt.write(outpath, format=&quot;SAC&quot;)</span><br><span class=\"line\"></span><br><span class=\"line\">            results.append((period, snr))</span><br><span class=\"line\">            print(f&quot;✔ 保存: &#123;outname&#125;, SNR=&#123;snr:.2f&#125;&quot;)</span><br><span class=\"line\"></span><br><span class=\"line\">    return results</span><br><span class=\"line\"># ===== 收集所有文件路径 =====</span><br><span class=\"line\">all_files = []</span><br><span class=\"line\">for root, dirs, files in os.walk(input_root):</span><br><span class=\"line\">    for file in files:</span><br><span class=\"line\">        if file.endswith(&quot;bhz.SAC_rm&quot;):</span><br><span class=\"line\">            all_files.append((os.path.join(root, file), root))</span><br><span class=\"line\"></span><br><span class=\"line\">print(f&quot;📁 待处理文件数: &#123;len(all_files)&#125;&quot;)</span><br><span class=\"line\"></span><br><span class=\"line\"># ===== 并行处理 =====</span><br><span class=\"line\">with ThreadPoolExecutor(max_workers=max_workers) as executor:</span><br><span class=\"line\">    future_to_file = &#123;executor.submit(process_file, fpath, root): (fpath, root) for fpath, root in all_files&#125;</span><br><span class=\"line\">    for future in as_completed(future_to_file):</span><br><span class=\"line\">        try:</span><br><span class=\"line\">            result = future.result()</span><br><span class=\"line\">            for period, snr in result:</span><br><span class=\"line\">                period_snr_map[period].append(snr)</span><br><span class=\"line\">        except Exception as e:</span><br><span class=\"line\">            fpath, _ = future_to_file[future]</span><br><span class=\"line\">            print(f&quot;❌ 文件出错 &#123;fpath&#125;: &#123;e&#125;&quot;)</span><br><span class=\"line\"></span><br><span class=\"line\"># ===== 统计与可视化 =====</span><br><span class=\"line\">periods = sorted(period_snr_map.keys())</span><br><span class=\"line\">counts = [len(period_snr_map[p]) for p in periods]</span><br><span class=\"line\">means = [np.mean(period_snr_map[p]) if len(period_snr_map[p]) &gt; 0 else 0 for p in periods]</span><br><span class=\"line\"></span><br><span class=\"line\">df = pd.DataFrame(&#123;</span><br><span class=\"line\">    &quot;Period(s)&quot;: periods,</span><br><span class=\"line\">    &quot;Count(SNR&gt;3)&quot;: counts,</span><br><span class=\"line\">    &quot;Mean_SNR(SNR&gt;3)&quot;: means</span><br><span class=\"line\">&#125;)</span><br><span class=\"line\">df.to_csv(&quot;snr_stats.csv&quot;, index=False)</span><br><span class=\"line\"></span><br><span class=\"line\"># === 可视化 ===</span><br><span class=\"line\">plt.figure(figsize=(10, 6))</span><br><span class=\"line\">plt.bar(periods, counts, width=4, color=&#x27;skyblue&#x27;, edgecolor=&#x27;black&#x27;)</span><br><span class=\"line\">plt.xlabel(&quot;Period (s)&quot;)</span><br><span class=\"line\">plt.ylabel(&quot;Count of SNR &gt; 3&quot;)</span><br><span class=\"line\">plt.title(&quot;Number of Traces with SNR &gt; 3 per Period&quot;)</span><br><span class=\"line\">plt.grid(True, linestyle=&quot;--&quot;, alpha=0.5)</span><br><span class=\"line\">plt.tight_layout()</span><br><span class=\"line\">plt.savefig(&quot;snr_count_bar.png&quot;, dpi=150)</span><br><span class=\"line\"></span><br><span class=\"line\">plt.figure(figsize=(10, 6))</span><br><span class=\"line\">plt.plot(periods, means, marker=&#x27;o&#x27;, linestyle=&#x27;-&#x27;, color=&#x27;orange&#x27;)</span><br><span class=\"line\">plt.xlabel(&quot;Period (s)&quot;)</span><br><span class=\"line\">plt.ylabel(&quot;Mean SNR (SNR &gt; 3)&quot;)</span><br><span class=\"line\">plt.title(&quot;Mean SNR of Traces with SNR &gt; 3 per Period&quot;)</span><br><span class=\"line\">plt.grid(True, linestyle=&quot;--&quot;, alpha=0.5)</span><br><span class=\"line\">plt.tight_layout()</span><br><span class=\"line\">plt.savefig(&quot;snr_mean_line.png&quot;, dpi=150)</span><br><span class=\"line\"></span><br><span class=\"line\">print(&quot;🎉 并行处理完成，统计结果写入 snr_stats.csv&quot;)</span><br></pre></td></tr></table></figure></li>\n</ul>\n","related_posts":[],"length":4652,"excerpt":"","more":"<p>&emsp;&emsp;以下是python脚本练习1，功能包括：</p>\n<ul>\n<li>遍历目录events_20250619下所有子目录中以bhz.SAC_rm结尾的SAC文件；</li>\n<li>对这些数据进行窄带滤波，宽度为中心频率（周期分之一）的$\\pm$5mHz，滤波器为4个极点0相位的Butterworth，滤波周期为arange(25,145,10)；</li>\n<li>计算窄带滤波后的每个周期的信噪比。信噪比定义为信号窗口内，波形包络的最大值比上噪声窗口的均方根。信号窗口定义为2.5-5km&#x2F;s的到时。噪声窗定义为信号末端之后1000秒开始的1000秒长度的窗口。计算的信噪比写入到user0；</li>\n<li>将处理后的数据写到新的文件夹bp_sac中，文件名命名为z.year.jday.00.STA.bhz.period，仅保留信噪比大于3的数据。</li>\n<li>采用并行处理(8个cpu)。</li>\n<li>统计每个周期信噪比大于3的波形数据。</li>\n<li>统计每个周期信噪比大于3的波形的平均信噪比。</li>\n<li>将统计结构写入csv，并画出统计结果。<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">import os</span><br><span class=\"line\">import numpy as np</span><br><span class=\"line\">import pandas as pd</span><br><span class=\"line\">import matplotlib.pyplot as plt</span><br><span class=\"line\">from obspy import read</span><br><span class=\"line\">from obspy.signal.filter import envelope</span><br><span class=\"line\">from concurrent.futures import ThreadPoolExecutor, as_completed</span><br><span class=\"line\">from collections import defaultdict</span><br><span class=\"line\"></span><br><span class=\"line\"># 参数设置 </span><br><span class=\"line\">input_root = &quot;events_20250619&quot;</span><br><span class=\"line\">output_root = &quot;bp_sac&quot;</span><br><span class=\"line\">center_periods = np.arange(25, 150, 10)</span><br><span class=\"line\">bandwidth = 0.010</span><br><span class=\"line\">vmin, vmax = 2.5, 5.0</span><br><span class=\"line\">noise_offset, noise_len = 1000, 1000</span><br><span class=\"line\">snr_threshold = 3.0</span><br><span class=\"line\">max_workers = 8  # 根据 CPU 核心数调整</span><br><span class=\"line\"></span><br><span class=\"line\"># 存储每个周期的 SNR 值</span><br><span class=\"line\">period_snr_map = defaultdict(list)</span><br><span class=\"line\"></span><br><span class=\"line\">def process_file(filepath, root):</span><br><span class=\"line\">    results = []</span><br><span class=\"line\">    try:</span><br><span class=\"line\">        st = read(filepath)</span><br><span class=\"line\">        tr = st[0]</span><br><span class=\"line\">        sac = tr.stats.sac</span><br><span class=\"line\">    except Exception as e:</span><br><span class=\"line\">        print(f&quot;跳过 &#123;filepath&#125;: &#123;e&#125;&quot;)</span><br><span class=\"line\">        return results</span><br><span class=\"line\"></span><br><span class=\"line\">    if not hasattr(sac, &quot;o&quot;) or not hasattr(sac, &quot;dist&quot;):</span><br><span class=\"line\">        return results</span><br><span class=\"line\"></span><br><span class=\"line\">    dist = sac.dist</span><br><span class=\"line\">    starttime = tr.stats.starttime</span><br><span class=\"line\">    win_start = starttime + dist / vmax</span><br><span class=\"line\">    win_end = starttime + dist / vmin</span><br><span class=\"line\">    t = tr.times()</span><br><span class=\"line\">    abs_time = np.array([starttime + float(tt) for tt in t])</span><br><span class=\"line\"></span><br><span class=\"line\">    for period in center_periods:</span><br><span class=\"line\">        fc = 1.0 / period</span><br><span class=\"line\">        fmin, fmax = fc - bandwidth / 2, fc + bandwidth / 2</span><br><span class=\"line\">        if fmin &lt;= 0:</span><br><span class=\"line\">            continue</span><br><span class=\"line\">        tr_filt = tr.copy()</span><br><span class=\"line\">        tr_filt.detrend(&quot;demean&quot;)</span><br><span class=\"line\">        tr_filt.taper(0.05)</span><br><span class=\"line\">        tr_filt.filter(&quot;bandpass&quot;, freqmin=fmin, freqmax=fmax, corners=4, zerophase=True)</span><br><span class=\"line\">        env = envelope(tr_filt.data)</span><br><span class=\"line\">        idx_sig = np.where((abs_time &gt;= win_start) &amp; (abs_time &lt;= win_end))[0]</span><br><span class=\"line\">        if len(idx_sig) == 0:</span><br><span class=\"line\">            continue</span><br><span class=\"line\">        signal_max = np.max(env[idx_sig])</span><br><span class=\"line\">        noise_start = win_end + noise_offset</span><br><span class=\"line\">        noise_end = noise_start + noise_len</span><br><span class=\"line\">        idx_noise = np.where((abs_time &gt;= noise_start) &amp; (abs_time &lt;= noise_end))[0]</span><br><span class=\"line\">        if len(idx_noise) == 0:</span><br><span class=\"line\">            continue</span><br><span class=\"line\">        noise_rms = np.sqrt(np.mean(env[idx_noise] ** 2))</span><br><span class=\"line\">        snr = signal_max / noise_rms if noise_rms &gt; 0 else 0</span><br><span class=\"line\"></span><br><span class=\"line\">        if snr &gt;= snr_threshold:</span><br><span class=\"line\">            tr_filt.stats.sac.user0 = snr</span><br><span class=\"line\">            year = tr.stats.starttime.year</span><br><span class=\"line\">            jday = tr.stats.starttime.julday</span><br><span class=\"line\">            station = tr.stats.station.lower()</span><br><span class=\"line\">            channel = tr.stats.channel.lower()</span><br><span class=\"line\">            outname = f&quot;z.&#123;year&#125;.&#123;jday:03d&#125;.00.&#123;station&#125;.&#123;channel&#125;.&#123;period:03d&#125;&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">            rel_dir = os.path.relpath(root, input_root)</span><br><span class=\"line\">            out_dir = os.path.join(output_root, rel_dir)</span><br><span class=\"line\">            os.makedirs(out_dir, exist_ok=True)</span><br><span class=\"line\">            outpath = os.path.join(out_dir, outname)</span><br><span class=\"line\">            tr_filt.write(outpath, format=&quot;SAC&quot;)</span><br><span class=\"line\"></span><br><span class=\"line\">            results.append((period, snr))</span><br><span class=\"line\">            print(f&quot;✔ 保存: &#123;outname&#125;, SNR=&#123;snr:.2f&#125;&quot;)</span><br><span class=\"line\"></span><br><span class=\"line\">    return results</span><br><span class=\"line\"># ===== 收集所有文件路径 =====</span><br><span class=\"line\">all_files = []</span><br><span class=\"line\">for root, dirs, files in os.walk(input_root):</span><br><span class=\"line\">    for file in files:</span><br><span class=\"line\">        if file.endswith(&quot;bhz.SAC_rm&quot;):</span><br><span class=\"line\">            all_files.append((os.path.join(root, file), root))</span><br><span class=\"line\"></span><br><span class=\"line\">print(f&quot;📁 待处理文件数: &#123;len(all_files)&#125;&quot;)</span><br><span class=\"line\"></span><br><span class=\"line\"># ===== 并行处理 =====</span><br><span class=\"line\">with ThreadPoolExecutor(max_workers=max_workers) as executor:</span><br><span class=\"line\">    future_to_file = &#123;executor.submit(process_file, fpath, root): (fpath, root) for fpath, root in all_files&#125;</span><br><span class=\"line\">    for future in as_completed(future_to_file):</span><br><span class=\"line\">        try:</span><br><span class=\"line\">            result = future.result()</span><br><span class=\"line\">            for period, snr in result:</span><br><span class=\"line\">                period_snr_map[period].append(snr)</span><br><span class=\"line\">        except Exception as e:</span><br><span class=\"line\">            fpath, _ = future_to_file[future]</span><br><span class=\"line\">            print(f&quot;❌ 文件出错 &#123;fpath&#125;: &#123;e&#125;&quot;)</span><br><span class=\"line\"></span><br><span class=\"line\"># ===== 统计与可视化 =====</span><br><span class=\"line\">periods = sorted(period_snr_map.keys())</span><br><span class=\"line\">counts = [len(period_snr_map[p]) for p in periods]</span><br><span class=\"line\">means = [np.mean(period_snr_map[p]) if len(period_snr_map[p]) &gt; 0 else 0 for p in periods]</span><br><span class=\"line\"></span><br><span class=\"line\">df = pd.DataFrame(&#123;</span><br><span class=\"line\">    &quot;Period(s)&quot;: periods,</span><br><span class=\"line\">    &quot;Count(SNR&gt;3)&quot;: counts,</span><br><span class=\"line\">    &quot;Mean_SNR(SNR&gt;3)&quot;: means</span><br><span class=\"line\">&#125;)</span><br><span class=\"line\">df.to_csv(&quot;snr_stats.csv&quot;, index=False)</span><br><span class=\"line\"></span><br><span class=\"line\"># === 可视化 ===</span><br><span class=\"line\">plt.figure(figsize=(10, 6))</span><br><span class=\"line\">plt.bar(periods, counts, width=4, color=&#x27;skyblue&#x27;, edgecolor=&#x27;black&#x27;)</span><br><span class=\"line\">plt.xlabel(&quot;Period (s)&quot;)</span><br><span class=\"line\">plt.ylabel(&quot;Count of SNR &gt; 3&quot;)</span><br><span class=\"line\">plt.title(&quot;Number of Traces with SNR &gt; 3 per Period&quot;)</span><br><span class=\"line\">plt.grid(True, linestyle=&quot;--&quot;, alpha=0.5)</span><br><span class=\"line\">plt.tight_layout()</span><br><span class=\"line\">plt.savefig(&quot;snr_count_bar.png&quot;, dpi=150)</span><br><span class=\"line\"></span><br><span class=\"line\">plt.figure(figsize=(10, 6))</span><br><span class=\"line\">plt.plot(periods, means, marker=&#x27;o&#x27;, linestyle=&#x27;-&#x27;, color=&#x27;orange&#x27;)</span><br><span class=\"line\">plt.xlabel(&quot;Period (s)&quot;)</span><br><span class=\"line\">plt.ylabel(&quot;Mean SNR (SNR &gt; 3)&quot;)</span><br><span class=\"line\">plt.title(&quot;Mean SNR of Traces with SNR &gt; 3 per Period&quot;)</span><br><span class=\"line\">plt.grid(True, linestyle=&quot;--&quot;, alpha=0.5)</span><br><span class=\"line\">plt.tight_layout()</span><br><span class=\"line\">plt.savefig(&quot;snr_mean_line.png&quot;, dpi=150)</span><br><span class=\"line\"></span><br><span class=\"line\">print(&quot;🎉 并行处理完成，统计结果写入 snr_stats.csv&quot;)</span><br></pre></td></tr></table></figure></li>\n</ul>\n"},{"title":"学习匹配场","abbrlink":"dcec3c7c","date":"2025-06-27T00:34:58.000Z","_content":"\n&emsp;&emsp;今天学习匹配场处理（Matched Field Processing, MFP），见[这里](https://geophydog.cool/post/matched_field_processing/#__1-basic-descriptions__)。\n<!--less-->\n&emsp;&emsp;MFP是一种定位算法，最早应用于海洋声学领域（Baggeroer & Kuperman，1988），目前在地震学中已广泛用于地震或微震定位（如 Cros et al.，2011；Gal et al.，2018）。以下为 MFP 的简要原理：\n\n## MFP 功率计算\n\n首先计算频率域的谱向量：\n\n$$\n\\boldsymbol{u}(\\omega) = [u_1(\\omega), u_2(\\omega), \\cdots, u_N(\\omega)]^T \\tag{1}\n$$\n\n其中，$N$ 表示接收器的总数，$T$ 表示转置操作，$u_i(\\omega)$ 是第 $i$ 个接收器的傅里叶谱，$\\omega$ 是角频率。\n\n然后计算协方差矩阵：\n\n$$\n\\boldsymbol{C}(\\omega) = \\boldsymbol{u}(\\omega) \\boldsymbol{u}^H(\\omega) \\tag{2}\n$$\n\n其中 $H$ 表示厄米共轭（复转置）操作。\n\n通常我们仅保留相位信息，因此对协方差矩阵进行归一化处理：\n\n$$\n\\tilde{C}_{mn}(\\omega) = \\frac{C_{mn}(\\omega)}{|C_{mn}(\\omega)|} \\tag{3}\n$$\n\n接着构造导向矢量（steering vector）：\n\n$$\n\\boldsymbol{a}(\\omega, v, \\boldsymbol{r}) = [e^{-i\\omega |\\boldsymbol{r}-\\boldsymbol{r}_1|/v}, \\cdots, e^{-i\\omega |\\boldsymbol{r}-\\boldsymbol{r}_N|/v}]^T \\tag{4}\n$$\n\n其中，$v$ 为波速，$\\boldsymbol{r}$ 表示候选源位置，$\\boldsymbol{r}_i$ 为第 $i$ 个接收器的位置。\n\n最终，MFP 相干性定义为：\n\n$$\nP(\\omega, v, \\boldsymbol{r}) = \\frac{1}{N^2} \\boldsymbol{a}^H(\\omega, v, \\boldsymbol{r}) \\tilde{\\boldsymbol{C}}(\\omega) \\boldsymbol{a}(\\omega, v, \\boldsymbol{r}) \\tag{5}\n$$\n\n当 $P(\\omega, v, \\boldsymbol{r})$ 达到最大值时，对应的 $\\boldsymbol{r}$ 即为可能的震源位置。\n\n不过，由于地球介质的非均匀性会影响地震波的传播速度，因此 MFP 在地震学中也存在局限。有研究者提出在三维速度模型中引入射线追踪（ray tracing）来计算旅行时间（Gal 等，2018）。\n\n## MFP阵列响应函数\n\n类似于 F-K 波束形成（beamforming）方法，我们可以指定信号的震源位置、传播速度和频率，用以评估阵列几何结构的分辨能力。\n\n已知信号的波速 $v$、震源位置 $\\boldsymbol{r}_0$ 和频率 $\\omega$，构造其复频谱向量如下：\n\n$$\n\\boldsymbol{u}(\\omega, v, \\boldsymbol{r}_0) = [e^{-i\\omega|\\boldsymbol{r}_0-\\boldsymbol{r}_1|/v}, \\cdots, e^{-i\\omega|\\boldsymbol{r}_0-\\boldsymbol{r}_N|/v}]^T \\tag{6}\n$$\n\n对应的协方差矩阵为：\n\n$$\n\\boldsymbol{C}(\\omega) = \\boldsymbol{u}(\\omega, v, \\boldsymbol{r}_0) \\boldsymbol{u}^H(\\omega, v, \\boldsymbol{r}_0) \\tag{7}\n$$\n\n提取协方差矩阵的相位信息：\n\n$$\n\\tilde{C}_{mn}(\\omega) = \\frac{C_{mn}(\\omega)}{|C_{mn}(\\omega)|} \\tag{8}\n$$\n\n然后再次生成导向矢量：\n\n$$\n\\boldsymbol{a}(\\omega, v, \\boldsymbol{r}) = [e^{-i\\omega|\\boldsymbol{r}-\\boldsymbol{r}_1|/v}, \\cdots, e^{-i\\omega|\\boldsymbol{r}-\\boldsymbol{r}_N|/v}]^T \\tag{9}\n$$\n\n计算 MFP 相干性：\n\n$$\nP(\\omega, v, \\boldsymbol{r}) = \\frac{1}{N^2} \\boldsymbol{a}^H(\\omega, v, \\boldsymbol{r}) \\tilde{\\boldsymbol{C}}(\\omega) \\boldsymbol{a}(\\omega, v, \\boldsymbol{r}) \\tag{10}\n$$\n\n为了简化处理，可以对多个频率下的相干性进行平均，得到最终的 MFP 相干性值：\n\n$$\nP_0(v, \\boldsymbol{r}) = \\frac{1}{K} \\sum_{k}P(\\omega_k, v, \\boldsymbol{r}) \\tag{11}\n$$\n\n参考文献：\nBaggeroer, A. B., Kuperman, W. A., & Schmidt, H. (1988). Matched field processing: Source localization in correlated noise as an optimum parameter estimation problem. The Journal of the Acoustical Society of America, 83(2), 571-587.\n\nCros, E., Roux, P., Vandemeulebrouck, J., & Kedar, S. (2011). Locating hydrothermal acoustic sources at Old Faithful Geyser using matched field processing. Geophysical Journal International, 187(1), 385-393.\n\nGal, M., Reading, A. M., Rawlinson, N., & Schulte‐Pelkum, V. (2018). Matched field processing of three‐component seismic array data applied to Rayleigh and Love microseisms. Journal of Geophysical Research: Solid Earth, 123(8), 6871-6889.\n","source":"_posts/2025-06-27-mfp.md","raw":"---\ntitle: 学习匹配场 \nabbrlink: dcec3c7c\ndate: 2025-06-27 08:34:58\ntags:\n---\n\n&emsp;&emsp;今天学习匹配场处理（Matched Field Processing, MFP），见[这里](https://geophydog.cool/post/matched_field_processing/#__1-basic-descriptions__)。\n<!--less-->\n&emsp;&emsp;MFP是一种定位算法，最早应用于海洋声学领域（Baggeroer & Kuperman，1988），目前在地震学中已广泛用于地震或微震定位（如 Cros et al.，2011；Gal et al.，2018）。以下为 MFP 的简要原理：\n\n## MFP 功率计算\n\n首先计算频率域的谱向量：\n\n$$\n\\boldsymbol{u}(\\omega) = [u_1(\\omega), u_2(\\omega), \\cdots, u_N(\\omega)]^T \\tag{1}\n$$\n\n其中，$N$ 表示接收器的总数，$T$ 表示转置操作，$u_i(\\omega)$ 是第 $i$ 个接收器的傅里叶谱，$\\omega$ 是角频率。\n\n然后计算协方差矩阵：\n\n$$\n\\boldsymbol{C}(\\omega) = \\boldsymbol{u}(\\omega) \\boldsymbol{u}^H(\\omega) \\tag{2}\n$$\n\n其中 $H$ 表示厄米共轭（复转置）操作。\n\n通常我们仅保留相位信息，因此对协方差矩阵进行归一化处理：\n\n$$\n\\tilde{C}_{mn}(\\omega) = \\frac{C_{mn}(\\omega)}{|C_{mn}(\\omega)|} \\tag{3}\n$$\n\n接着构造导向矢量（steering vector）：\n\n$$\n\\boldsymbol{a}(\\omega, v, \\boldsymbol{r}) = [e^{-i\\omega |\\boldsymbol{r}-\\boldsymbol{r}_1|/v}, \\cdots, e^{-i\\omega |\\boldsymbol{r}-\\boldsymbol{r}_N|/v}]^T \\tag{4}\n$$\n\n其中，$v$ 为波速，$\\boldsymbol{r}$ 表示候选源位置，$\\boldsymbol{r}_i$ 为第 $i$ 个接收器的位置。\n\n最终，MFP 相干性定义为：\n\n$$\nP(\\omega, v, \\boldsymbol{r}) = \\frac{1}{N^2} \\boldsymbol{a}^H(\\omega, v, \\boldsymbol{r}) \\tilde{\\boldsymbol{C}}(\\omega) \\boldsymbol{a}(\\omega, v, \\boldsymbol{r}) \\tag{5}\n$$\n\n当 $P(\\omega, v, \\boldsymbol{r})$ 达到最大值时，对应的 $\\boldsymbol{r}$ 即为可能的震源位置。\n\n不过，由于地球介质的非均匀性会影响地震波的传播速度，因此 MFP 在地震学中也存在局限。有研究者提出在三维速度模型中引入射线追踪（ray tracing）来计算旅行时间（Gal 等，2018）。\n\n## MFP阵列响应函数\n\n类似于 F-K 波束形成（beamforming）方法，我们可以指定信号的震源位置、传播速度和频率，用以评估阵列几何结构的分辨能力。\n\n已知信号的波速 $v$、震源位置 $\\boldsymbol{r}_0$ 和频率 $\\omega$，构造其复频谱向量如下：\n\n$$\n\\boldsymbol{u}(\\omega, v, \\boldsymbol{r}_0) = [e^{-i\\omega|\\boldsymbol{r}_0-\\boldsymbol{r}_1|/v}, \\cdots, e^{-i\\omega|\\boldsymbol{r}_0-\\boldsymbol{r}_N|/v}]^T \\tag{6}\n$$\n\n对应的协方差矩阵为：\n\n$$\n\\boldsymbol{C}(\\omega) = \\boldsymbol{u}(\\omega, v, \\boldsymbol{r}_0) \\boldsymbol{u}^H(\\omega, v, \\boldsymbol{r}_0) \\tag{7}\n$$\n\n提取协方差矩阵的相位信息：\n\n$$\n\\tilde{C}_{mn}(\\omega) = \\frac{C_{mn}(\\omega)}{|C_{mn}(\\omega)|} \\tag{8}\n$$\n\n然后再次生成导向矢量：\n\n$$\n\\boldsymbol{a}(\\omega, v, \\boldsymbol{r}) = [e^{-i\\omega|\\boldsymbol{r}-\\boldsymbol{r}_1|/v}, \\cdots, e^{-i\\omega|\\boldsymbol{r}-\\boldsymbol{r}_N|/v}]^T \\tag{9}\n$$\n\n计算 MFP 相干性：\n\n$$\nP(\\omega, v, \\boldsymbol{r}) = \\frac{1}{N^2} \\boldsymbol{a}^H(\\omega, v, \\boldsymbol{r}) \\tilde{\\boldsymbol{C}}(\\omega) \\boldsymbol{a}(\\omega, v, \\boldsymbol{r}) \\tag{10}\n$$\n\n为了简化处理，可以对多个频率下的相干性进行平均，得到最终的 MFP 相干性值：\n\n$$\nP_0(v, \\boldsymbol{r}) = \\frac{1}{K} \\sum_{k}P(\\omega_k, v, \\boldsymbol{r}) \\tag{11}\n$$\n\n参考文献：\nBaggeroer, A. B., Kuperman, W. A., & Schmidt, H. (1988). Matched field processing: Source localization in correlated noise as an optimum parameter estimation problem. The Journal of the Acoustical Society of America, 83(2), 571-587.\n\nCros, E., Roux, P., Vandemeulebrouck, J., & Kedar, S. (2011). Locating hydrothermal acoustic sources at Old Faithful Geyser using matched field processing. Geophysical Journal International, 187(1), 385-393.\n\nGal, M., Reading, A. M., Rawlinson, N., & Schulte‐Pelkum, V. (2018). Matched field processing of three‐component seismic array data applied to Rayleigh and Love microseisms. Journal of Geophysical Research: Solid Earth, 123(8), 6871-6889.\n","slug":"mfp","published":1,"updated":"2025-06-27T01:07:14.517Z","comments":1,"layout":"post","photos":[],"_id":"cmh498iql00drwvou1d8u58bv","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>&emsp;&emsp;MFP是一种定位算法，最早应用于海洋声学领域（Baggeroer &amp; Kuperman，1988），目前在地震学中已广泛用于地震或微震定位（如 Cros et al.，2011；Gal et al.，2018）。以下为 MFP 的简要原理：</p>\n<h2 id=\"MFP-功率计算\"><a href=\"#MFP-功率计算\" class=\"headerlink\" title=\"MFP 功率计算\"></a>MFP 功率计算</h2><p>首先计算频率域的谱向量：</p>\n<p>$$<br>\\boldsymbol{u}(\\omega) &#x3D; [u_1(\\omega), u_2(\\omega), \\cdots, u_N(\\omega)]^T \\tag{1}<br>$$</p>\n<p>其中，$N$ 表示接收器的总数，$T$ 表示转置操作，$u_i(\\omega)$ 是第 $i$ 个接收器的傅里叶谱，$\\omega$ 是角频率。</p>\n<p>然后计算协方差矩阵：</p>\n<p>$$<br>\\boldsymbol{C}(\\omega) &#x3D; \\boldsymbol{u}(\\omega) \\boldsymbol{u}^H(\\omega) \\tag{2}<br>$$</p>\n<p>其中 $H$ 表示厄米共轭（复转置）操作。</p>\n<p>通常我们仅保留相位信息，因此对协方差矩阵进行归一化处理：</p>\n<p>$$<br>\\tilde{C}<em>{mn}(\\omega) &#x3D; \\frac{C</em>{mn}(\\omega)}{|C_{mn}(\\omega)|} \\tag{3}<br>$$</p>\n<p>接着构造导向矢量（steering vector）：</p>\n<p>$$<br>\\boldsymbol{a}(\\omega, v, \\boldsymbol{r}) &#x3D; [e^{-i\\omega |\\boldsymbol{r}-\\boldsymbol{r}_1|&#x2F;v}, \\cdots, e^{-i\\omega |\\boldsymbol{r}-\\boldsymbol{r}_N|&#x2F;v}]^T \\tag{4}<br>$$</p>\n<p>其中，$v$ 为波速，$\\boldsymbol{r}$ 表示候选源位置，$\\boldsymbol{r}_i$ 为第 $i$ 个接收器的位置。</p>\n<p>最终，MFP 相干性定义为：</p>\n<p>$$<br>P(\\omega, v, \\boldsymbol{r}) &#x3D; \\frac{1}{N^2} \\boldsymbol{a}^H(\\omega, v, \\boldsymbol{r}) \\tilde{\\boldsymbol{C}}(\\omega) \\boldsymbol{a}(\\omega, v, \\boldsymbol{r}) \\tag{5}<br>$$</p>\n<p>当 $P(\\omega, v, \\boldsymbol{r})$ 达到最大值时，对应的 $\\boldsymbol{r}$ 即为可能的震源位置。</p>\n<p>不过，由于地球介质的非均匀性会影响地震波的传播速度，因此 MFP 在地震学中也存在局限。有研究者提出在三维速度模型中引入射线追踪（ray tracing）来计算旅行时间（Gal 等，2018）。</p>\n<h2 id=\"MFP阵列响应函数\"><a href=\"#MFP阵列响应函数\" class=\"headerlink\" title=\"MFP阵列响应函数\"></a>MFP阵列响应函数</h2><p>类似于 F-K 波束形成（beamforming）方法，我们可以指定信号的震源位置、传播速度和频率，用以评估阵列几何结构的分辨能力。</p>\n<p>已知信号的波速 $v$、震源位置 $\\boldsymbol{r}_0$ 和频率 $\\omega$，构造其复频谱向量如下：</p>\n<p>$$<br>\\boldsymbol{u}(\\omega, v, \\boldsymbol{r}_0) &#x3D; [e^{-i\\omega|\\boldsymbol{r}_0-\\boldsymbol{r}_1|&#x2F;v}, \\cdots, e^{-i\\omega|\\boldsymbol{r}_0-\\boldsymbol{r}_N|&#x2F;v}]^T \\tag{6}<br>$$</p>\n<p>对应的协方差矩阵为：</p>\n<p>$$<br>\\boldsymbol{C}(\\omega) &#x3D; \\boldsymbol{u}(\\omega, v, \\boldsymbol{r}_0) \\boldsymbol{u}^H(\\omega, v, \\boldsymbol{r}_0) \\tag{7}<br>$$</p>\n<p>提取协方差矩阵的相位信息：</p>\n<p>$$<br>\\tilde{C}<em>{mn}(\\omega) &#x3D; \\frac{C</em>{mn}(\\omega)}{|C_{mn}(\\omega)|} \\tag{8}<br>$$</p>\n<p>然后再次生成导向矢量：</p>\n<p>$$<br>\\boldsymbol{a}(\\omega, v, \\boldsymbol{r}) &#x3D; [e^{-i\\omega|\\boldsymbol{r}-\\boldsymbol{r}_1|&#x2F;v}, \\cdots, e^{-i\\omega|\\boldsymbol{r}-\\boldsymbol{r}_N|&#x2F;v}]^T \\tag{9}<br>$$</p>\n<p>计算 MFP 相干性：</p>\n<p>$$<br>P(\\omega, v, \\boldsymbol{r}) &#x3D; \\frac{1}{N^2} \\boldsymbol{a}^H(\\omega, v, \\boldsymbol{r}) \\tilde{\\boldsymbol{C}}(\\omega) \\boldsymbol{a}(\\omega, v, \\boldsymbol{r}) \\tag{10}<br>$$</p>\n<p>为了简化处理，可以对多个频率下的相干性进行平均，得到最终的 MFP 相干性值：</p>\n<p>$$<br>P_0(v, \\boldsymbol{r}) &#x3D; \\frac{1}{K} \\sum_{k}P(\\omega_k, v, \\boldsymbol{r}) \\tag{11}<br>$$</p>\n<p>参考文献：<br>Baggeroer, A. B., Kuperman, W. A., &amp; Schmidt, H. (1988). Matched field processing: Source localization in correlated noise as an optimum parameter estimation problem. The Journal of the Acoustical Society of America, 83(2), 571-587.</p>\n<p>Cros, E., Roux, P., Vandemeulebrouck, J., &amp; Kedar, S. (2011). Locating hydrothermal acoustic sources at Old Faithful Geyser using matched field processing. Geophysical Journal International, 187(1), 385-393.</p>\n<p>Gal, M., Reading, A. M., Rawlinson, N., &amp; Schulte‐Pelkum, V. (2018). Matched field processing of three‐component seismic array data applied to Rayleigh and Love microseisms. Journal of Geophysical Research: Solid Earth, 123(8), 6871-6889.</p>","related_posts":["music.html","how-to-add-frame.html","code-and-project2.html"],"length":2782,"excerpt":"<p>&emsp;&emsp;今天学习匹配场处理（Matched Field Processing, MFP），见<a href=\"https://geophydog.cool/post/matched_field_processing/#__1-basic-descriptions__\">这里</a>。</p>","more":"<p>&emsp;&emsp;MFP是一种定位算法，最早应用于海洋声学领域（Baggeroer &amp; Kuperman，1988），目前在地震学中已广泛用于地震或微震定位（如 Cros et al.，2011；Gal et al.，2018）。以下为 MFP 的简要原理：</p>\n<h2 id=\"MFP-功率计算\"><a href=\"#MFP-功率计算\" class=\"headerlink\" title=\"MFP 功率计算\"></a>MFP 功率计算</h2><p>首先计算频率域的谱向量：</p>\n<p>$$<br>\\boldsymbol{u}(\\omega) &#x3D; [u_1(\\omega), u_2(\\omega), \\cdots, u_N(\\omega)]^T \\tag{1}<br>$$</p>\n<p>其中，$N$ 表示接收器的总数，$T$ 表示转置操作，$u_i(\\omega)$ 是第 $i$ 个接收器的傅里叶谱，$\\omega$ 是角频率。</p>\n<p>然后计算协方差矩阵：</p>\n<p>$$<br>\\boldsymbol{C}(\\omega) &#x3D; \\boldsymbol{u}(\\omega) \\boldsymbol{u}^H(\\omega) \\tag{2}<br>$$</p>\n<p>其中 $H$ 表示厄米共轭（复转置）操作。</p>\n<p>通常我们仅保留相位信息，因此对协方差矩阵进行归一化处理：</p>\n<p>$$<br>\\tilde{C}<em>{mn}(\\omega) &#x3D; \\frac{C</em>{mn}(\\omega)}{|C_{mn}(\\omega)|} \\tag{3}<br>$$</p>\n<p>接着构造导向矢量（steering vector）：</p>\n<p>$$<br>\\boldsymbol{a}(\\omega, v, \\boldsymbol{r}) &#x3D; [e^{-i\\omega |\\boldsymbol{r}-\\boldsymbol{r}_1|&#x2F;v}, \\cdots, e^{-i\\omega |\\boldsymbol{r}-\\boldsymbol{r}_N|&#x2F;v}]^T \\tag{4}<br>$$</p>\n<p>其中，$v$ 为波速，$\\boldsymbol{r}$ 表示候选源位置，$\\boldsymbol{r}_i$ 为第 $i$ 个接收器的位置。</p>\n<p>最终，MFP 相干性定义为：</p>\n<p>$$<br>P(\\omega, v, \\boldsymbol{r}) &#x3D; \\frac{1}{N^2} \\boldsymbol{a}^H(\\omega, v, \\boldsymbol{r}) \\tilde{\\boldsymbol{C}}(\\omega) \\boldsymbol{a}(\\omega, v, \\boldsymbol{r}) \\tag{5}<br>$$</p>\n<p>当 $P(\\omega, v, \\boldsymbol{r})$ 达到最大值时，对应的 $\\boldsymbol{r}$ 即为可能的震源位置。</p>\n<p>不过，由于地球介质的非均匀性会影响地震波的传播速度，因此 MFP 在地震学中也存在局限。有研究者提出在三维速度模型中引入射线追踪（ray tracing）来计算旅行时间（Gal 等，2018）。</p>\n<h2 id=\"MFP阵列响应函数\"><a href=\"#MFP阵列响应函数\" class=\"headerlink\" title=\"MFP阵列响应函数\"></a>MFP阵列响应函数</h2><p>类似于 F-K 波束形成（beamforming）方法，我们可以指定信号的震源位置、传播速度和频率，用以评估阵列几何结构的分辨能力。</p>\n<p>已知信号的波速 $v$、震源位置 $\\boldsymbol{r}_0$ 和频率 $\\omega$，构造其复频谱向量如下：</p>\n<p>$$<br>\\boldsymbol{u}(\\omega, v, \\boldsymbol{r}_0) &#x3D; [e^{-i\\omega|\\boldsymbol{r}_0-\\boldsymbol{r}_1|&#x2F;v}, \\cdots, e^{-i\\omega|\\boldsymbol{r}_0-\\boldsymbol{r}_N|&#x2F;v}]^T \\tag{6}<br>$$</p>\n<p>对应的协方差矩阵为：</p>\n<p>$$<br>\\boldsymbol{C}(\\omega) &#x3D; \\boldsymbol{u}(\\omega, v, \\boldsymbol{r}_0) \\boldsymbol{u}^H(\\omega, v, \\boldsymbol{r}_0) \\tag{7}<br>$$</p>\n<p>提取协方差矩阵的相位信息：</p>\n<p>$$<br>\\tilde{C}<em>{mn}(\\omega) &#x3D; \\frac{C</em>{mn}(\\omega)}{|C_{mn}(\\omega)|} \\tag{8}<br>$$</p>\n<p>然后再次生成导向矢量：</p>\n<p>$$<br>\\boldsymbol{a}(\\omega, v, \\boldsymbol{r}) &#x3D; [e^{-i\\omega|\\boldsymbol{r}-\\boldsymbol{r}_1|&#x2F;v}, \\cdots, e^{-i\\omega|\\boldsymbol{r}-\\boldsymbol{r}_N|&#x2F;v}]^T \\tag{9}<br>$$</p>\n<p>计算 MFP 相干性：</p>\n<p>$$<br>P(\\omega, v, \\boldsymbol{r}) &#x3D; \\frac{1}{N^2} \\boldsymbol{a}^H(\\omega, v, \\boldsymbol{r}) \\tilde{\\boldsymbol{C}}(\\omega) \\boldsymbol{a}(\\omega, v, \\boldsymbol{r}) \\tag{10}<br>$$</p>\n<p>为了简化处理，可以对多个频率下的相干性进行平均，得到最终的 MFP 相干性值：</p>\n<p>$$<br>P_0(v, \\boldsymbol{r}) &#x3D; \\frac{1}{K} \\sum_{k}P(\\omega_k, v, \\boldsymbol{r}) \\tag{11}<br>$$</p>\n<p>参考文献：<br>Baggeroer, A. B., Kuperman, W. A., &amp; Schmidt, H. (1988). Matched field processing: Source localization in correlated noise as an optimum parameter estimation problem. The Journal of the Acoustical Society of America, 83(2), 571-587.</p>\n<p>Cros, E., Roux, P., Vandemeulebrouck, J., &amp; Kedar, S. (2011). Locating hydrothermal acoustic sources at Old Faithful Geyser using matched field processing. Geophysical Journal International, 187(1), 385-393.</p>\n<p>Gal, M., Reading, A. M., Rawlinson, N., &amp; Schulte‐Pelkum, V. (2018). Matched field processing of three‐component seismic array data applied to Rayleigh and Love microseisms. Journal of Geophysical Research: Solid Earth, 123(8), 6871-6889.</p>"},{"title":"PYTHON脚本练习（二）","abbrlink":"689a3f45","date":"2025-06-30T13:27:28.000Z","_content":"&emsp;&emsp;以下是python脚本练习2，功能为读取选定时间段内的hdf5文件，文件名形如20130512_cross_spec.hdf5。该文件总共有24段，每一段是一个小时某台阵平均互相关谱。然后画出这个互相关谱，保存为png格式图片。\n```python\nimport os\nimport h5py\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.dates as mdates\nfrom datetime import datetime, timedelta\nfrom matplotlib.dates import DateFormatter\n\n\ndef parse_filename_to_start_time(filename):\n    \"\"\"从文件名推断数据起始时间\"\"\"\n    date_str = filename.split('_')[0]  # 提取\"20130512\"\n    return datetime.strptime(date_str, \"%Y%m%d\")  # 转为 datetime\n\n\ndef load_cross_spec_from_files(hdf5_dir, start_date, end_date):\n    \"\"\"读取目录下所有落在给定时间范围的互相关谱\"\"\"\n    files = sorted([f for f in os.listdir(hdf5_dir) if f.endswith(\"_cross_spec.hdf5\")])\n    #files = sorted([f for f in os.listdir(hdf5_dir) if f.endswith(\"_power_spec.hdf5\")])\n    time_list = []\n    spec_list = []\n    for file in files:\n        try:\n            base_time = parse_filename_to_start_time(file)\n        except Exception as e:\n            print(f\"跳过无法解析时间的文件：{file}\")\n            continue\n\n        if not (start_date <= base_time <= end_date):\n            continue\n\n        file_path = os.path.join(hdf5_dir, file)\n        with h5py.File(file_path, 'r') as f:\n            for i in range(1,24):\n                ds_name = f'window_{i}'\n                if ds_name in f:\n                    data = f[ds_name][:]\n                    current_time = base_time + timedelta(hours=i)\n                    time_list.append(current_time)\n                    spec_list.append(data)\n    return time_list, spec_list\n\n\ndef plot_spectrogram(time_list, spec_list, freqs=None, title=\"Cross Spectrogram\", save_path=None):\n    \"\"\"绘制时间-频率图像\"\"\"\n    if not time_list or not spec_list:\n        print(\"没有数据可供绘图。\")\n        return\n\n    spec_array = np.array(spec_list).T  # shape: freq x time\n    #spec_array = spec_array - np.mean(spec_array, axis=1, keepdims=True)\n    n_freq = spec_array.shape[0]\n\n    if freqs is None:\n        freqs = np.linspace(0.005, 0.1, n_freq)\n\n    fig, ax = plt.subplots(figsize=(14, 6))\n    time_nums = mdates.date2num(time_list)\n\n    cax = ax.pcolormesh(time_nums, freqs, spec_array, shading='auto', cmap='inferno')\n    #cax = ax.pcolormesh(time_nums, freqs, spec_array, shading='auto' )\n    fig.colorbar(cax, label='Cross Spectral Amplitude')\n    ax.set_title(title)\n    ax.set_yscale('log')  # 设置纵轴为对数刻度\n    ax.set_xlabel(\"Time (UTC)\")\n    ax.set_ylabel(\"Frequency (Hz)\")\n    ax.xaxis.set_major_formatter(DateFormatter(\"%Y-%m-%d\\n%H:%M\"))\n    plt.xticks(rotation=30)\n    plt.tight_layout()\n\n    if save_path:\n        plt.savefig(save_path, dpi=300)\n        print(f\"图像已保存到：{save_path}\")\n\n    plt.show()\n\n# 设置参数\nhdf5_dir = \"output_1_0\"  # HDF5 文件夹路径\nstart_date = datetime(2006, 5, 1)\nend_date = datetime(2006, 5,31)\n# 加载数据\ntime_list, spec_list = load_cross_spec_from_files(hdf5_dir, start_date, end_date)\n# 绘图并保存为 PNG（可选）\nplot_spectrogram(time_list, spec_list,\n                 title=f\"Cross Spectral Density ({start_date.date()} ~ {end_date.date()})\",\n                 save_path=\"cross_spectrogram_2006_1_0.png\")\n```\n","source":"_posts/2025-06-30-python-script2.md","raw":"---\ntitle: PYTHON脚本练习（二）\ntags:\n  - python\ncategories:\n  - work\nabbrlink: 689a3f45\ndate: 2025-06-30 21:27:28\n---\n&emsp;&emsp;以下是python脚本练习2，功能为读取选定时间段内的hdf5文件，文件名形如20130512_cross_spec.hdf5。该文件总共有24段，每一段是一个小时某台阵平均互相关谱。然后画出这个互相关谱，保存为png格式图片。\n```python\nimport os\nimport h5py\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.dates as mdates\nfrom datetime import datetime, timedelta\nfrom matplotlib.dates import DateFormatter\n\n\ndef parse_filename_to_start_time(filename):\n    \"\"\"从文件名推断数据起始时间\"\"\"\n    date_str = filename.split('_')[0]  # 提取\"20130512\"\n    return datetime.strptime(date_str, \"%Y%m%d\")  # 转为 datetime\n\n\ndef load_cross_spec_from_files(hdf5_dir, start_date, end_date):\n    \"\"\"读取目录下所有落在给定时间范围的互相关谱\"\"\"\n    files = sorted([f for f in os.listdir(hdf5_dir) if f.endswith(\"_cross_spec.hdf5\")])\n    #files = sorted([f for f in os.listdir(hdf5_dir) if f.endswith(\"_power_spec.hdf5\")])\n    time_list = []\n    spec_list = []\n    for file in files:\n        try:\n            base_time = parse_filename_to_start_time(file)\n        except Exception as e:\n            print(f\"跳过无法解析时间的文件：{file}\")\n            continue\n\n        if not (start_date <= base_time <= end_date):\n            continue\n\n        file_path = os.path.join(hdf5_dir, file)\n        with h5py.File(file_path, 'r') as f:\n            for i in range(1,24):\n                ds_name = f'window_{i}'\n                if ds_name in f:\n                    data = f[ds_name][:]\n                    current_time = base_time + timedelta(hours=i)\n                    time_list.append(current_time)\n                    spec_list.append(data)\n    return time_list, spec_list\n\n\ndef plot_spectrogram(time_list, spec_list, freqs=None, title=\"Cross Spectrogram\", save_path=None):\n    \"\"\"绘制时间-频率图像\"\"\"\n    if not time_list or not spec_list:\n        print(\"没有数据可供绘图。\")\n        return\n\n    spec_array = np.array(spec_list).T  # shape: freq x time\n    #spec_array = spec_array - np.mean(spec_array, axis=1, keepdims=True)\n    n_freq = spec_array.shape[0]\n\n    if freqs is None:\n        freqs = np.linspace(0.005, 0.1, n_freq)\n\n    fig, ax = plt.subplots(figsize=(14, 6))\n    time_nums = mdates.date2num(time_list)\n\n    cax = ax.pcolormesh(time_nums, freqs, spec_array, shading='auto', cmap='inferno')\n    #cax = ax.pcolormesh(time_nums, freqs, spec_array, shading='auto' )\n    fig.colorbar(cax, label='Cross Spectral Amplitude')\n    ax.set_title(title)\n    ax.set_yscale('log')  # 设置纵轴为对数刻度\n    ax.set_xlabel(\"Time (UTC)\")\n    ax.set_ylabel(\"Frequency (Hz)\")\n    ax.xaxis.set_major_formatter(DateFormatter(\"%Y-%m-%d\\n%H:%M\"))\n    plt.xticks(rotation=30)\n    plt.tight_layout()\n\n    if save_path:\n        plt.savefig(save_path, dpi=300)\n        print(f\"图像已保存到：{save_path}\")\n\n    plt.show()\n\n# 设置参数\nhdf5_dir = \"output_1_0\"  # HDF5 文件夹路径\nstart_date = datetime(2006, 5, 1)\nend_date = datetime(2006, 5,31)\n# 加载数据\ntime_list, spec_list = load_cross_spec_from_files(hdf5_dir, start_date, end_date)\n# 绘图并保存为 PNG（可选）\nplot_spectrogram(time_list, spec_list,\n                 title=f\"Cross Spectral Density ({start_date.date()} ~ {end_date.date()})\",\n                 save_path=\"cross_spectrogram_2006_1_0.png\")\n```\n","slug":"python-script2","published":1,"updated":"2025-06-30T13:43:30.793Z","comments":1,"layout":"post","photos":[],"_id":"cmh498iqm00dvwvoufw3ua8ri","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>&emsp;&emsp;以下是python脚本练习2，功能为读取选定时间段内的hdf5文件，文件名形如20130512_cross_spec.hdf5。该文件总共有24段，每一段是一个小时某台阵平均互相关谱。然后画出这个互相关谱，保存为png格式图片。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\"><span class=\"keyword\">import</span> h5py</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.dates <span class=\"keyword\">as</span> mdates</span><br><span class=\"line\"><span class=\"keyword\">from</span> datetime <span class=\"keyword\">import</span> datetime, timedelta</span><br><span class=\"line\"><span class=\"keyword\">from</span> matplotlib.dates <span class=\"keyword\">import</span> DateFormatter</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">parse_filename_to_start_time</span>(<span class=\"params\">filename</span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;从文件名推断数据起始时间&quot;&quot;&quot;</span></span><br><span class=\"line\">    date_str = filename.split(<span class=\"string\">&#x27;_&#x27;</span>)[<span class=\"number\">0</span>]  <span class=\"comment\"># 提取&quot;20130512&quot;</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> datetime.strptime(date_str, <span class=\"string\">&quot;%Y%m%d&quot;</span>)  <span class=\"comment\"># 转为 datetime</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">load_cross_spec_from_files</span>(<span class=\"params\">hdf5_dir, start_date, end_date</span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;读取目录下所有落在给定时间范围的互相关谱&quot;&quot;&quot;</span></span><br><span class=\"line\">    files = <span class=\"built_in\">sorted</span>([f <span class=\"keyword\">for</span> f <span class=\"keyword\">in</span> os.listdir(hdf5_dir) <span class=\"keyword\">if</span> f.endswith(<span class=\"string\">&quot;_cross_spec.hdf5&quot;</span>)])</span><br><span class=\"line\">    <span class=\"comment\">#files = sorted([f for f in os.listdir(hdf5_dir) if f.endswith(&quot;_power_spec.hdf5&quot;)])</span></span><br><span class=\"line\">    time_list = []</span><br><span class=\"line\">    spec_list = []</span><br><span class=\"line\">    <span class=\"keyword\">for</span> file <span class=\"keyword\">in</span> files:</span><br><span class=\"line\">        <span class=\"keyword\">try</span>:</span><br><span class=\"line\">            base_time = parse_filename_to_start_time(file)</span><br><span class=\"line\">        <span class=\"keyword\">except</span> Exception <span class=\"keyword\">as</span> e:</span><br><span class=\"line\">            <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;跳过无法解析时间的文件：<span class=\"subst\">&#123;file&#125;</span>&quot;</span>)</span><br><span class=\"line\">            <span class=\"keyword\">continue</span></span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">if</span> <span class=\"keyword\">not</span> (start_date &lt;= base_time &lt;= end_date):</span><br><span class=\"line\">            <span class=\"keyword\">continue</span></span><br><span class=\"line\"></span><br><span class=\"line\">        file_path = os.path.join(hdf5_dir, file)</span><br><span class=\"line\">        <span class=\"keyword\">with</span> h5py.File(file_path, <span class=\"string\">&#x27;r&#x27;</span>) <span class=\"keyword\">as</span> f:</span><br><span class=\"line\">            <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">1</span>,<span class=\"number\">24</span>):</span><br><span class=\"line\">                ds_name = <span class=\"string\">f&#x27;window_<span class=\"subst\">&#123;i&#125;</span>&#x27;</span></span><br><span class=\"line\">                <span class=\"keyword\">if</span> ds_name <span class=\"keyword\">in</span> f:</span><br><span class=\"line\">                    data = f[ds_name][:]</span><br><span class=\"line\">                    current_time = base_time + timedelta(hours=i)</span><br><span class=\"line\">                    time_list.append(current_time)</span><br><span class=\"line\">                    spec_list.append(data)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> time_list, spec_list</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">plot_spectrogram</span>(<span class=\"params\">time_list, spec_list, freqs=<span class=\"literal\">None</span>, title=<span class=\"string\">&quot;Cross Spectrogram&quot;</span>, save_path=<span class=\"literal\">None</span></span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;绘制时间-频率图像&quot;&quot;&quot;</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> <span class=\"keyword\">not</span> time_list <span class=\"keyword\">or</span> <span class=\"keyword\">not</span> spec_list:</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">&quot;没有数据可供绘图。&quot;</span>)</span><br><span class=\"line\">        <span class=\"keyword\">return</span></span><br><span class=\"line\"></span><br><span class=\"line\">    spec_array = np.array(spec_list).T  <span class=\"comment\"># shape: freq x time</span></span><br><span class=\"line\">    <span class=\"comment\">#spec_array = spec_array - np.mean(spec_array, axis=1, keepdims=True)</span></span><br><span class=\"line\">    n_freq = spec_array.shape[<span class=\"number\">0</span>]</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">if</span> freqs <span class=\"keyword\">is</span> <span class=\"literal\">None</span>:</span><br><span class=\"line\">        freqs = np.linspace(<span class=\"number\">0.005</span>, <span class=\"number\">0.1</span>, n_freq)</span><br><span class=\"line\"></span><br><span class=\"line\">    fig, ax = plt.subplots(figsize=(<span class=\"number\">14</span>, <span class=\"number\">6</span>))</span><br><span class=\"line\">    time_nums = mdates.date2num(time_list)</span><br><span class=\"line\"></span><br><span class=\"line\">    cax = ax.pcolormesh(time_nums, freqs, spec_array, shading=<span class=\"string\">&#x27;auto&#x27;</span>, cmap=<span class=\"string\">&#x27;inferno&#x27;</span>)</span><br><span class=\"line\">    <span class=\"comment\">#cax = ax.pcolormesh(time_nums, freqs, spec_array, shading=&#x27;auto&#x27; )</span></span><br><span class=\"line\">    fig.colorbar(cax, label=<span class=\"string\">&#x27;Cross Spectral Amplitude&#x27;</span>)</span><br><span class=\"line\">    ax.set_title(title)</span><br><span class=\"line\">    ax.set_yscale(<span class=\"string\">&#x27;log&#x27;</span>)  <span class=\"comment\"># 设置纵轴为对数刻度</span></span><br><span class=\"line\">    ax.set_xlabel(<span class=\"string\">&quot;Time (UTC)&quot;</span>)</span><br><span class=\"line\">    ax.set_ylabel(<span class=\"string\">&quot;Frequency (Hz)&quot;</span>)</span><br><span class=\"line\">    ax.xaxis.set_major_formatter(DateFormatter(<span class=\"string\">&quot;%Y-%m-%d\\n%H:%M&quot;</span>))</span><br><span class=\"line\">    plt.xticks(rotation=<span class=\"number\">30</span>)</span><br><span class=\"line\">    plt.tight_layout()</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">if</span> save_path:</span><br><span class=\"line\">        plt.savefig(save_path, dpi=<span class=\"number\">300</span>)</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;图像已保存到：<span class=\"subst\">&#123;save_path&#125;</span>&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    plt.show()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 设置参数</span></span><br><span class=\"line\">hdf5_dir = <span class=\"string\">&quot;output_1_0&quot;</span>  <span class=\"comment\"># HDF5 文件夹路径</span></span><br><span class=\"line\">start_date = datetime(<span class=\"number\">2006</span>, <span class=\"number\">5</span>, <span class=\"number\">1</span>)</span><br><span class=\"line\">end_date = datetime(<span class=\"number\">2006</span>, <span class=\"number\">5</span>,<span class=\"number\">31</span>)</span><br><span class=\"line\"><span class=\"comment\"># 加载数据</span></span><br><span class=\"line\">time_list, spec_list = load_cross_spec_from_files(hdf5_dir, start_date, end_date)</span><br><span class=\"line\"><span class=\"comment\"># 绘图并保存为 PNG（可选）</span></span><br><span class=\"line\">plot_spectrogram(time_list, spec_list,</span><br><span class=\"line\">                 title=<span class=\"string\">f&quot;Cross Spectral Density (<span class=\"subst\">&#123;start_date.date()&#125;</span> ~ <span class=\"subst\">&#123;end_date.date()&#125;</span>)&quot;</span>,</span><br><span class=\"line\">                 save_path=<span class=\"string\">&quot;cross_spectrogram_2006_1_0.png&quot;</span>)</span><br></pre></td></tr></table></figure>\n","related_posts":["attention-mechanism.html","how-to-calculate-synthetic-NCF.html"],"length":2887,"excerpt":"","more":"<p>&emsp;&emsp;以下是python脚本练习2，功能为读取选定时间段内的hdf5文件，文件名形如20130512_cross_spec.hdf5。该文件总共有24段，每一段是一个小时某台阵平均互相关谱。然后画出这个互相关谱，保存为png格式图片。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\"><span class=\"keyword\">import</span> h5py</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.dates <span class=\"keyword\">as</span> mdates</span><br><span class=\"line\"><span class=\"keyword\">from</span> datetime <span class=\"keyword\">import</span> datetime, timedelta</span><br><span class=\"line\"><span class=\"keyword\">from</span> matplotlib.dates <span class=\"keyword\">import</span> DateFormatter</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">parse_filename_to_start_time</span>(<span class=\"params\">filename</span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;从文件名推断数据起始时间&quot;&quot;&quot;</span></span><br><span class=\"line\">    date_str = filename.split(<span class=\"string\">&#x27;_&#x27;</span>)[<span class=\"number\">0</span>]  <span class=\"comment\"># 提取&quot;20130512&quot;</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> datetime.strptime(date_str, <span class=\"string\">&quot;%Y%m%d&quot;</span>)  <span class=\"comment\"># 转为 datetime</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">load_cross_spec_from_files</span>(<span class=\"params\">hdf5_dir, start_date, end_date</span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;读取目录下所有落在给定时间范围的互相关谱&quot;&quot;&quot;</span></span><br><span class=\"line\">    files = <span class=\"built_in\">sorted</span>([f <span class=\"keyword\">for</span> f <span class=\"keyword\">in</span> os.listdir(hdf5_dir) <span class=\"keyword\">if</span> f.endswith(<span class=\"string\">&quot;_cross_spec.hdf5&quot;</span>)])</span><br><span class=\"line\">    <span class=\"comment\">#files = sorted([f for f in os.listdir(hdf5_dir) if f.endswith(&quot;_power_spec.hdf5&quot;)])</span></span><br><span class=\"line\">    time_list = []</span><br><span class=\"line\">    spec_list = []</span><br><span class=\"line\">    <span class=\"keyword\">for</span> file <span class=\"keyword\">in</span> files:</span><br><span class=\"line\">        <span class=\"keyword\">try</span>:</span><br><span class=\"line\">            base_time = parse_filename_to_start_time(file)</span><br><span class=\"line\">        <span class=\"keyword\">except</span> Exception <span class=\"keyword\">as</span> e:</span><br><span class=\"line\">            <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;跳过无法解析时间的文件：<span class=\"subst\">&#123;file&#125;</span>&quot;</span>)</span><br><span class=\"line\">            <span class=\"keyword\">continue</span></span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">if</span> <span class=\"keyword\">not</span> (start_date &lt;= base_time &lt;= end_date):</span><br><span class=\"line\">            <span class=\"keyword\">continue</span></span><br><span class=\"line\"></span><br><span class=\"line\">        file_path = os.path.join(hdf5_dir, file)</span><br><span class=\"line\">        <span class=\"keyword\">with</span> h5py.File(file_path, <span class=\"string\">&#x27;r&#x27;</span>) <span class=\"keyword\">as</span> f:</span><br><span class=\"line\">            <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">1</span>,<span class=\"number\">24</span>):</span><br><span class=\"line\">                ds_name = <span class=\"string\">f&#x27;window_<span class=\"subst\">&#123;i&#125;</span>&#x27;</span></span><br><span class=\"line\">                <span class=\"keyword\">if</span> ds_name <span class=\"keyword\">in</span> f:</span><br><span class=\"line\">                    data = f[ds_name][:]</span><br><span class=\"line\">                    current_time = base_time + timedelta(hours=i)</span><br><span class=\"line\">                    time_list.append(current_time)</span><br><span class=\"line\">                    spec_list.append(data)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> time_list, spec_list</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">plot_spectrogram</span>(<span class=\"params\">time_list, spec_list, freqs=<span class=\"literal\">None</span>, title=<span class=\"string\">&quot;Cross Spectrogram&quot;</span>, save_path=<span class=\"literal\">None</span></span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;绘制时间-频率图像&quot;&quot;&quot;</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> <span class=\"keyword\">not</span> time_list <span class=\"keyword\">or</span> <span class=\"keyword\">not</span> spec_list:</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">&quot;没有数据可供绘图。&quot;</span>)</span><br><span class=\"line\">        <span class=\"keyword\">return</span></span><br><span class=\"line\"></span><br><span class=\"line\">    spec_array = np.array(spec_list).T  <span class=\"comment\"># shape: freq x time</span></span><br><span class=\"line\">    <span class=\"comment\">#spec_array = spec_array - np.mean(spec_array, axis=1, keepdims=True)</span></span><br><span class=\"line\">    n_freq = spec_array.shape[<span class=\"number\">0</span>]</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">if</span> freqs <span class=\"keyword\">is</span> <span class=\"literal\">None</span>:</span><br><span class=\"line\">        freqs = np.linspace(<span class=\"number\">0.005</span>, <span class=\"number\">0.1</span>, n_freq)</span><br><span class=\"line\"></span><br><span class=\"line\">    fig, ax = plt.subplots(figsize=(<span class=\"number\">14</span>, <span class=\"number\">6</span>))</span><br><span class=\"line\">    time_nums = mdates.date2num(time_list)</span><br><span class=\"line\"></span><br><span class=\"line\">    cax = ax.pcolormesh(time_nums, freqs, spec_array, shading=<span class=\"string\">&#x27;auto&#x27;</span>, cmap=<span class=\"string\">&#x27;inferno&#x27;</span>)</span><br><span class=\"line\">    <span class=\"comment\">#cax = ax.pcolormesh(time_nums, freqs, spec_array, shading=&#x27;auto&#x27; )</span></span><br><span class=\"line\">    fig.colorbar(cax, label=<span class=\"string\">&#x27;Cross Spectral Amplitude&#x27;</span>)</span><br><span class=\"line\">    ax.set_title(title)</span><br><span class=\"line\">    ax.set_yscale(<span class=\"string\">&#x27;log&#x27;</span>)  <span class=\"comment\"># 设置纵轴为对数刻度</span></span><br><span class=\"line\">    ax.set_xlabel(<span class=\"string\">&quot;Time (UTC)&quot;</span>)</span><br><span class=\"line\">    ax.set_ylabel(<span class=\"string\">&quot;Frequency (Hz)&quot;</span>)</span><br><span class=\"line\">    ax.xaxis.set_major_formatter(DateFormatter(<span class=\"string\">&quot;%Y-%m-%d\\n%H:%M&quot;</span>))</span><br><span class=\"line\">    plt.xticks(rotation=<span class=\"number\">30</span>)</span><br><span class=\"line\">    plt.tight_layout()</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">if</span> save_path:</span><br><span class=\"line\">        plt.savefig(save_path, dpi=<span class=\"number\">300</span>)</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;图像已保存到：<span class=\"subst\">&#123;save_path&#125;</span>&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    plt.show()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 设置参数</span></span><br><span class=\"line\">hdf5_dir = <span class=\"string\">&quot;output_1_0&quot;</span>  <span class=\"comment\"># HDF5 文件夹路径</span></span><br><span class=\"line\">start_date = datetime(<span class=\"number\">2006</span>, <span class=\"number\">5</span>, <span class=\"number\">1</span>)</span><br><span class=\"line\">end_date = datetime(<span class=\"number\">2006</span>, <span class=\"number\">5</span>,<span class=\"number\">31</span>)</span><br><span class=\"line\"><span class=\"comment\"># 加载数据</span></span><br><span class=\"line\">time_list, spec_list = load_cross_spec_from_files(hdf5_dir, start_date, end_date)</span><br><span class=\"line\"><span class=\"comment\"># 绘图并保存为 PNG（可选）</span></span><br><span class=\"line\">plot_spectrogram(time_list, spec_list,</span><br><span class=\"line\">                 title=<span class=\"string\">f&quot;Cross Spectral Density (<span class=\"subst\">&#123;start_date.date()&#125;</span> ~ <span class=\"subst\">&#123;end_date.date()&#125;</span>)&quot;</span>,</span><br><span class=\"line\">                 save_path=<span class=\"string\">&quot;cross_spectrogram_2006_1_0.png&quot;</span>)</span><br></pre></td></tr></table></figure>\n"},{"title":"如何发布你自己的脚本","abbrlink":"c743ea3e","date":"2025-07-01T03:07:47.000Z","_content":"&emsp;&emsp;你是不是也想让自己的程序像obspy一样，叫全世界的人pip install就可以用？\n<!--less-->\n&emsp;&emsp;这里以一个简单的例子来说明如何创建自己的程序、打包并发布到PyPI。\n# 创建自己的项目\n首先创建一个目录mypkg_project，结构如下：\n```\nmypkg_project/\n├── mypkg/\n│   ├── __init__.py\n│   └── utils.py\n├── README.md\n├── setup.py\n├── pyproject.toml\n```\n# 编写包的内容\n在mypkg/utils.py内写入：\n```\ndef add(a, b):\n    return a + b\n```\n在mypkg/__init__.py内写入：\n```\nfrom .utils import add\n```\n# 添加元数据文件README.md\n在README.md中写入：\n```\n# mypkg\nA simple Python package with an add function.\n```\n在setup.py中写入：\n```\nfrom setuptools import setup, find_packages\nsetup(\n    name='mypkg',\n    version='0.1',\n    author='Your Name',\n    description='A simple example package',\n    long_description=open('README.md').read(),\n    long_description_content_type='text/markdown',\n    packages=find_packages(),\n    classifiers=[\n        'Programming Language :: Python :: 3',\n    ],\n    python_requires='>=3.6',\n)\n```\n在pyproject.toml中写入：\n```\n[build-system]\nrequires = [\"setuptools\", \"wheel\"]\nbuild-backend = \"setuptools.build_meta\"\n```\n# 项目打包\n在根目录mypkg_project/中运行：\n```\npython3 -m pip install --upgrade build\npython3 -m build\n```\n会生成：\n```\ndist/\n├── mypkg-0.1-py3-none-any.whl\n└── mypkg-0.1.tar.gz\n```\n# 本地安装\n用pip就可以本地安装：\n```\npip install dist/mypkg-0.1-py3-none-any.whl\n```\n利用python就可以调用：\n```\nfrom mypkg import add\nadd(2, 3)\n```\n# 上传到PyPI（公开发布）\n首先安装twine：\n```\npip install twine\n```\n发布：\n```\ntwine upload dist/*\n```\n这里会提示你输入PyPI的用户名和密码。这一步需要首先到[PyPI](https://pypi.org/account/register/)注册账号，发布的时候需要用token\n```\ntwine upload --repository pypi dist/* -u __token__ -p pypi-<your_token>\n```\n上传成功之后可以在https://pypi.org/project/mypkg/访问。\n然后任何人都可以安装你的脚本了：\n```\npip install mypkg\n```\n\n","source":"_posts/2025-07-01-distribute-package.md","raw":"---\ntitle: 如何发布你自己的脚本\ntags:\n  - python\ncategories:\n  - python\nabbrlink: c743ea3e\ndate: 2025-07-01 11:07:47\n---\n&emsp;&emsp;你是不是也想让自己的程序像obspy一样，叫全世界的人pip install就可以用？\n<!--less-->\n&emsp;&emsp;这里以一个简单的例子来说明如何创建自己的程序、打包并发布到PyPI。\n# 创建自己的项目\n首先创建一个目录mypkg_project，结构如下：\n```\nmypkg_project/\n├── mypkg/\n│   ├── __init__.py\n│   └── utils.py\n├── README.md\n├── setup.py\n├── pyproject.toml\n```\n# 编写包的内容\n在mypkg/utils.py内写入：\n```\ndef add(a, b):\n    return a + b\n```\n在mypkg/__init__.py内写入：\n```\nfrom .utils import add\n```\n# 添加元数据文件README.md\n在README.md中写入：\n```\n# mypkg\nA simple Python package with an add function.\n```\n在setup.py中写入：\n```\nfrom setuptools import setup, find_packages\nsetup(\n    name='mypkg',\n    version='0.1',\n    author='Your Name',\n    description='A simple example package',\n    long_description=open('README.md').read(),\n    long_description_content_type='text/markdown',\n    packages=find_packages(),\n    classifiers=[\n        'Programming Language :: Python :: 3',\n    ],\n    python_requires='>=3.6',\n)\n```\n在pyproject.toml中写入：\n```\n[build-system]\nrequires = [\"setuptools\", \"wheel\"]\nbuild-backend = \"setuptools.build_meta\"\n```\n# 项目打包\n在根目录mypkg_project/中运行：\n```\npython3 -m pip install --upgrade build\npython3 -m build\n```\n会生成：\n```\ndist/\n├── mypkg-0.1-py3-none-any.whl\n└── mypkg-0.1.tar.gz\n```\n# 本地安装\n用pip就可以本地安装：\n```\npip install dist/mypkg-0.1-py3-none-any.whl\n```\n利用python就可以调用：\n```\nfrom mypkg import add\nadd(2, 3)\n```\n# 上传到PyPI（公开发布）\n首先安装twine：\n```\npip install twine\n```\n发布：\n```\ntwine upload dist/*\n```\n这里会提示你输入PyPI的用户名和密码。这一步需要首先到[PyPI](https://pypi.org/account/register/)注册账号，发布的时候需要用token\n```\ntwine upload --repository pypi dist/* -u __token__ -p pypi-<your_token>\n```\n上传成功之后可以在https://pypi.org/project/mypkg/访问。\n然后任何人都可以安装你的脚本了：\n```\npip install mypkg\n```\n\n","slug":"distribute-package","published":1,"updated":"2025-07-01T03:56:37.835Z","comments":1,"layout":"post","photos":[],"_id":"cmh498iqm00dywvou4iw3dngc","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>&emsp;&emsp;这里以一个简单的例子来说明如何创建自己的程序、打包并发布到PyPI。</p>\n<h1 id=\"创建自己的项目\"><a href=\"#创建自己的项目\" class=\"headerlink\" title=\"创建自己的项目\"></a>创建自己的项目</h1><p>首先创建一个目录mypkg_project，结构如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mypkg_project/</span><br><span class=\"line\">├── mypkg/</span><br><span class=\"line\">│   ├── __init__.py</span><br><span class=\"line\">│   └── utils.py</span><br><span class=\"line\">├── README.md</span><br><span class=\"line\">├── setup.py</span><br><span class=\"line\">├── pyproject.toml</span><br></pre></td></tr></table></figure>\n<h1 id=\"编写包的内容\"><a href=\"#编写包的内容\" class=\"headerlink\" title=\"编写包的内容\"></a>编写包的内容</h1><p>在mypkg&#x2F;utils.py内写入：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">def add(a, b):</span><br><span class=\"line\">    return a + b</span><br></pre></td></tr></table></figure>\n<p>在mypkg&#x2F;<strong>init</strong>.py内写入：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">from .utils import add</span><br></pre></td></tr></table></figure>\n<h1 id=\"添加元数据文件README-md\"><a href=\"#添加元数据文件README-md\" class=\"headerlink\" title=\"添加元数据文件README.md\"></a>添加元数据文件README.md</h1><p>在README.md中写入：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># mypkg</span><br><span class=\"line\">A simple Python package with an add function.</span><br></pre></td></tr></table></figure>\n<p>在setup.py中写入：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">from setuptools import setup, find_packages</span><br><span class=\"line\">setup(</span><br><span class=\"line\">    name=&#x27;mypkg&#x27;,</span><br><span class=\"line\">    version=&#x27;0.1&#x27;,</span><br><span class=\"line\">    author=&#x27;Your Name&#x27;,</span><br><span class=\"line\">    description=&#x27;A simple example package&#x27;,</span><br><span class=\"line\">    long_description=open(&#x27;README.md&#x27;).read(),</span><br><span class=\"line\">    long_description_content_type=&#x27;text/markdown&#x27;,</span><br><span class=\"line\">    packages=find_packages(),</span><br><span class=\"line\">    classifiers=[</span><br><span class=\"line\">        &#x27;Programming Language :: Python :: 3&#x27;,</span><br><span class=\"line\">    ],</span><br><span class=\"line\">    python_requires=&#x27;&gt;=3.6&#x27;,</span><br><span class=\"line\">)</span><br></pre></td></tr></table></figure>\n<p>在pyproject.toml中写入：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[build-system]</span><br><span class=\"line\">requires = [&quot;setuptools&quot;, &quot;wheel&quot;]</span><br><span class=\"line\">build-backend = &quot;setuptools.build_meta&quot;</span><br></pre></td></tr></table></figure>\n<h1 id=\"项目打包\"><a href=\"#项目打包\" class=\"headerlink\" title=\"项目打包\"></a>项目打包</h1><p>在根目录mypkg_project&#x2F;中运行：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">python3 -m pip install --upgrade build</span><br><span class=\"line\">python3 -m build</span><br></pre></td></tr></table></figure>\n<p>会生成：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">dist/</span><br><span class=\"line\">├── mypkg-0.1-py3-none-any.whl</span><br><span class=\"line\">└── mypkg-0.1.tar.gz</span><br></pre></td></tr></table></figure>\n<h1 id=\"本地安装\"><a href=\"#本地安装\" class=\"headerlink\" title=\"本地安装\"></a>本地安装</h1><p>用pip就可以本地安装：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pip install dist/mypkg-0.1-py3-none-any.whl</span><br></pre></td></tr></table></figure>\n<p>利用python就可以调用：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">from mypkg import add</span><br><span class=\"line\">add(2, 3)</span><br></pre></td></tr></table></figure>\n<h1 id=\"上传到PyPI（公开发布）\"><a href=\"#上传到PyPI（公开发布）\" class=\"headerlink\" title=\"上传到PyPI（公开发布）\"></a>上传到PyPI（公开发布）</h1><p>首先安装twine：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pip install twine</span><br></pre></td></tr></table></figure>\n<p>发布：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">twine upload dist/*</span><br></pre></td></tr></table></figure>\n<p>这里会提示你输入PyPI的用户名和密码。这一步需要首先到<a href=\"https://pypi.org/account/register/\">PyPI</a>注册账号，发布的时候需要用token</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">twine upload --repository pypi dist/* -u __token__ -p pypi-&lt;your_token&gt;</span><br></pre></td></tr></table></figure>\n<p>上传成功之后可以在<a href=\"https://pypi.org/project/mypkg/%E8%AE%BF%E9%97%AE%E3%80%82\">https://pypi.org/project/mypkg/访问。</a><br>然后任何人都可以安装你的脚本了：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pip install mypkg</span><br></pre></td></tr></table></figure>","related_posts":["code-and-project2.html"],"length":1459,"excerpt":"<p>&emsp;&emsp;你是不是也想让自己的程序像obspy一样，叫全世界的人pip install就可以用？</p>","more":"<p>&emsp;&emsp;这里以一个简单的例子来说明如何创建自己的程序、打包并发布到PyPI。</p>\n<h1 id=\"创建自己的项目\"><a href=\"#创建自己的项目\" class=\"headerlink\" title=\"创建自己的项目\"></a>创建自己的项目</h1><p>首先创建一个目录mypkg_project，结构如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mypkg_project/</span><br><span class=\"line\">├── mypkg/</span><br><span class=\"line\">│   ├── __init__.py</span><br><span class=\"line\">│   └── utils.py</span><br><span class=\"line\">├── README.md</span><br><span class=\"line\">├── setup.py</span><br><span class=\"line\">├── pyproject.toml</span><br></pre></td></tr></table></figure>\n<h1 id=\"编写包的内容\"><a href=\"#编写包的内容\" class=\"headerlink\" title=\"编写包的内容\"></a>编写包的内容</h1><p>在mypkg&#x2F;utils.py内写入：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">def add(a, b):</span><br><span class=\"line\">    return a + b</span><br></pre></td></tr></table></figure>\n<p>在mypkg&#x2F;<strong>init</strong>.py内写入：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">from .utils import add</span><br></pre></td></tr></table></figure>\n<h1 id=\"添加元数据文件README-md\"><a href=\"#添加元数据文件README-md\" class=\"headerlink\" title=\"添加元数据文件README.md\"></a>添加元数据文件README.md</h1><p>在README.md中写入：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># mypkg</span><br><span class=\"line\">A simple Python package with an add function.</span><br></pre></td></tr></table></figure>\n<p>在setup.py中写入：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">from setuptools import setup, find_packages</span><br><span class=\"line\">setup(</span><br><span class=\"line\">    name=&#x27;mypkg&#x27;,</span><br><span class=\"line\">    version=&#x27;0.1&#x27;,</span><br><span class=\"line\">    author=&#x27;Your Name&#x27;,</span><br><span class=\"line\">    description=&#x27;A simple example package&#x27;,</span><br><span class=\"line\">    long_description=open(&#x27;README.md&#x27;).read(),</span><br><span class=\"line\">    long_description_content_type=&#x27;text/markdown&#x27;,</span><br><span class=\"line\">    packages=find_packages(),</span><br><span class=\"line\">    classifiers=[</span><br><span class=\"line\">        &#x27;Programming Language :: Python :: 3&#x27;,</span><br><span class=\"line\">    ],</span><br><span class=\"line\">    python_requires=&#x27;&gt;=3.6&#x27;,</span><br><span class=\"line\">)</span><br></pre></td></tr></table></figure>\n<p>在pyproject.toml中写入：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[build-system]</span><br><span class=\"line\">requires = [&quot;setuptools&quot;, &quot;wheel&quot;]</span><br><span class=\"line\">build-backend = &quot;setuptools.build_meta&quot;</span><br></pre></td></tr></table></figure>\n<h1 id=\"项目打包\"><a href=\"#项目打包\" class=\"headerlink\" title=\"项目打包\"></a>项目打包</h1><p>在根目录mypkg_project&#x2F;中运行：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">python3 -m pip install --upgrade build</span><br><span class=\"line\">python3 -m build</span><br></pre></td></tr></table></figure>\n<p>会生成：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">dist/</span><br><span class=\"line\">├── mypkg-0.1-py3-none-any.whl</span><br><span class=\"line\">└── mypkg-0.1.tar.gz</span><br></pre></td></tr></table></figure>\n<h1 id=\"本地安装\"><a href=\"#本地安装\" class=\"headerlink\" title=\"本地安装\"></a>本地安装</h1><p>用pip就可以本地安装：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pip install dist/mypkg-0.1-py3-none-any.whl</span><br></pre></td></tr></table></figure>\n<p>利用python就可以调用：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">from mypkg import add</span><br><span class=\"line\">add(2, 3)</span><br></pre></td></tr></table></figure>\n<h1 id=\"上传到PyPI（公开发布）\"><a href=\"#上传到PyPI（公开发布）\" class=\"headerlink\" title=\"上传到PyPI（公开发布）\"></a>上传到PyPI（公开发布）</h1><p>首先安装twine：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pip install twine</span><br></pre></td></tr></table></figure>\n<p>发布：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">twine upload dist/*</span><br></pre></td></tr></table></figure>\n<p>这里会提示你输入PyPI的用户名和密码。这一步需要首先到<a href=\"https://pypi.org/account/register/\">PyPI</a>注册账号，发布的时候需要用token</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">twine upload --repository pypi dist/* -u __token__ -p pypi-&lt;your_token&gt;</span><br></pre></td></tr></table></figure>\n<p>上传成功之后可以在<a href=\"https://pypi.org/project/mypkg/%E8%AE%BF%E9%97%AE%E3%80%82\">https://pypi.org/project/mypkg/访问。</a><br>然后任何人都可以安装你的脚本了：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pip install mypkg</span><br></pre></td></tr></table></figure>"},{"title":"PYTHON脚本练习（三）聚束分析","abbrlink":"2a2cdaad","date":"2025-08-24T03:19:23.000Z","_content":"&emsp;&emsp;python脚本练习-fk。\n<!--less-->\n&emsp;&emsp;以下脚本可完成功能：\n## 1.数据预处理与筛选\n  * 台站管理：从station.lst读取台站信息（网络名、台站名、经纬度）。\n  * 数据加载：按日期遍历数据目录，加载每个台站的LHZ分量SAC文件。\n  * 有效性检查：仅使用具有有效数据且台站数≥3天的数据。\n## 2.时间窗口分割\n  * 将每天数据分割为1800秒长、50%重叠的窗口（步长900秒）。\n  * 对每个窗口提取对应时间段的数据。\n## 3. 频域分析\n  * 滤波与窗函数：对每个台站数据加汉宁窗，去均值。\n  * FFT计算：使用下一个2的幂次长度进行FFT，提取[fmin, fmax]频段的频谱。\n## 4. 聚束分析（FK分析）\n  * 参数网格：\n  方位角（az\\_grid）：0°\\~360°，步长5°。\n  速度（speed\\_grid）：1\\~5 km/s，步长0.05 km/s（通过慢度1/v参与计算）。\n  * 波束功率计算：\n  1. 坐标转换：将台站经纬度转换为以平均位置为中心的直角坐标系（单位：公里）。\n  2. 相位延迟计算：\n    对每个方位角，计算台站投影位置proj = x*sin(az) + y*cos(az)。\n    对每个速度，计算时延delays = proj * 慢度（s=1/v）。\n  3. 导向向量：生成复相位因子exp(-j*2π*f*delays)。\n  4. 波束频谱：将各台站频谱与导向向量加权求和，得到波束频谱。\n  5. 功率归一化：计算波束功率并除以总功率（各台站功率之和）。\n## 5.结果可视化\n  * 雷达图绘制：\n  极坐标下，横轴为方位角，纵轴为速度，颜色表示归一化功率。\n  标注最大能量点，显示其方位角和速度。\n  * 输出：每天生成一张PNG图片，保存至arr_figures目录。\n## 脚本\n```\n#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\"\"\"\nCustom FK / beamforming array analysis (no obspy.array_processing)\n改进：使用速度 (km/s) 替代慢度，每天输出雷达图，并标注最大能量点\n\"\"\"\nimport os\nimport glob\nimport math\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom obspy import read, UTCDateTime\nfrom datetime import timedelta\n\n# ---------------- User parameters ----------------\nstation_file = \"station.lst\"\ndata_dir = \"data\"                 # structure: data/YYYYMMDD/NET_STA_LH?.SAC\noutput_dir = \"arr_figures\"\nos.makedirs(output_dir, exist_ok=True)\n\n# frequency band of interest\nfmin, fmax = 0.028, 0.032  # Hz\n\n# window settings\nwin_len = 1800             # seconds\nwin_frac = 0.5             # 50% overlap\nwin_step = int(win_len * (1 - win_frac))\n\n# FK grid\naz_step = 5.0\naz_grid = np.arange(0, 360, az_step)\n\n# speed search (instead of slowness)\nvmin, vmax, vstep = 1, 5.0, 0.05  # km/s\n#s_grid = 1.0 / np.arange(vmax, vmin, -vstep)  # convert to slowness s/km\nspeed_grid = np.arange(vmin, vmax, vstep)  # convert to slowness s/km\n\n#speed_grid = 1.0 / s_grid  # for plotting\ns_grid = 1.0 / speed_grid  # for plotting\n\n# day range\nstart_date = UTCDateTime(\"2013-01-01\")\nend_date   = UTCDateTime(\"2025-01-01\")\n\n# minimal number of stations\nmin_stations = 3\n\n# ---------------- helper functions ----------------\ndef read_stations(station_file):\n    stations = []\n    with open(station_file, \"r\") as f:\n        for line in f:\n            line = line.strip()\n            if not line or line.startswith(\"#\"):\n                continue\n            parts = line.split(\"|\")\n            if len(parts) < 4:\n                continue\n            net, sta = parts[0].strip(), parts[1].strip()\n            try:\n                lat = float(parts[2]); lon = float(parts[3])\n            except Exception:\n                continue\n            stations.append((net, sta, lat, lon))\n    return stations\n\ndef geo_to_xy_km(lats, lons):\n    lat0 = np.mean(lats)\n    lon0 = np.mean(lons)\n    deg2km_lat = 110.574\n    deg2km_lon = 111.320 * math.cos(math.radians(lat0))\n    xs = (np.array(lons) - lon0) * deg2km_lon\n    ys = (np.array(lats) - lat0) * deg2km_lat\n    return xs, ys, lat0, lon0\n\ndef window_slices(day_start, win_len, win_step):\n    t0 = int(day_start.timestamp)\n    t_end = int((day_start + 86400).timestamp)\n    slices = []\n    t = t0\n    while t + win_len <= t_end:\n        slices.append((t, t + win_len))\n        t += win_step\n    return slices\n\ndef next_pow2(n):\n    return 1 << (n - 1).bit_length()\n\n# ---------------- main pipeline ----------------\nstations = read_stations(station_file)\nif len(stations) == 0:\n    raise SystemExit(\"No stations read from station.lst\")\n\nprint(f\"[INFO] Read {len(stations)} stations\")\n\ncurrent = start_date\nwhile current <= end_date:\n    day_str = current.strftime(\"%Y%m%d\")\n    day_path = os.path.join(data_dir, day_str)\n    print(f\"\\n[INFO] Processing {day_str} ...\")\n    if not os.path.isdir(day_path):\n        print(f\"[WARN] {day_path} not found. skip.\")\n        current += timedelta(days=1)\n        continue\n\n    # read one trace per station\n    traces = {}\n    lat_list = []; lon_list = []; net_sta_list = []\n    for net, sta, lat, lon in stations:\n        pattern = os.path.join(day_path, f\"{net}_{sta}_LHZ.SAC\")\n        files = sorted(glob.glob(pattern))\n        if not files: continue\n        try:\n            tr = read(files[0])[0]\n            traces[(net,sta)] = tr\n            lat_list.append(lat); lon_list.append(lon); net_sta_list.append((net,sta))\n        except Exception as e:\n            print(f\"[WARN] read {files[0]} failed: {e}\")\n            continue\n\n    nsta = len(traces)\n    if nsta < min_stations:\n        print(f\"[WARN] Only {nsta} stations available, skip.\")\n        current += timedelta(days=1)\n        continue\n\n    # sampling rate\n    sr_target = min([tr.stats.sampling_rate for tr in traces.values()])\n    xs, ys, lat0, lon0 = geo_to_xy_km(lat_list, lon_list)\n\n    # reorder traces\n    traces_ordered = [traces[k] for k in net_sta_list]\n\n    # window slices\n    day_start = UTCDateTime(current.strftime(\"%Y-%m-%dT00:00:00\"))\n    slices = window_slices(day_start, win_len, win_step)\n    print(f\"[INFO] {len(slices)} windows\")\n\n    # accumulate daily power grid\n    daily_power = np.zeros((len(az_grid), len(s_grid)))\n    nwin_used = 0\n\n    for (t0, t1) in slices:\n        specs = []\n        valid = True\n        nfft = None\n        for tr in traces_ordered:\n            try:\n                seg = tr.slice(UTCDateTime(t0), UTCDateTime(t1), nearest_sample=False)\n            except:\n                valid = False; break\n            expected_npts = int(round((t1 - t0) * sr_target))\n            data = seg.data.astype(np.float64)\n            if len(data) < expected_npts:\n                if len(data) == 0: valid = False; break\n                data = np.pad(data, (0, expected_npts-len(data)))\n            elif len(data) > expected_npts:\n                data = data[:expected_npts]\n            data -= np.mean(data)\n            data *= np.hanning(len(data))\n            if nfft is None:\n                nfft = next_pow2(len(data))\n            spec = np.fft.rfft(data, n=nfft)\n            freqs = np.fft.rfftfreq(nfft, d=1.0/sr_target)\n            specs.append(spec)\n        if not valid or nfft is None: continue\n\n        specs = np.array(specs)\n        freq_mask = (freqs>=fmin)&(freqs<=fmax)\n        if not np.any(freq_mask): continue\n        freqs_sel = freqs[freq_mask]\n        specs_sel = specs[:, freq_mask]\n\n        xs_arr = np.array(xs); ys_arr = np.array(ys)\n        spec_power = np.sum(np.abs(specs_sel)**2)\n        if spec_power<=0: continue\n\n        two_pi = 2*np.pi\n        power_grid = np.zeros((len(az_grid), len(s_grid)))\n        for ia, az_deg in enumerate(az_grid):\n            az_rad = math.radians(az_deg)\n            proj = xs_arr*np.sin(az_rad) + ys_arr*np.cos(az_rad)\n            for is_idx, s in enumerate(s_grid):\n                delays = proj*s\n                steering = np.exp(-1j*two_pi*np.outer(delays,freqs_sel))\n                beam_spectrum = np.sum(steering*specs_sel, axis=0)\n                power = np.sum(np.abs(beam_spectrum)**2)\n                power_grid[ia,is_idx] = power/spec_power\n        daily_power += power_grid\n        nwin_used += 1\n\n    if nwin_used==0:\n        print(f\"[WARN] no valid windows {day_str}\")\n        current += timedelta(days=1)\n        continue\n\n    daily_power /= nwin_used\n    print(f\"[INFO] averaged over {nwin_used} windows\")\n\n    # ---------------- plot daily radar ----------------\n    theta, r = np.meshgrid(np.deg2rad(az_grid), speed_grid)\n    Z = daily_power.T  # shape (len(s_grid), len(az_grid))\n\n    # locate max power\n    max_idx = np.unravel_index(np.argmax(Z), Z.shape)\n    max_az_deg = az_grid[max_idx[1]]\n    max_speed = r[max_idx]  # km/s\n\n    fig = plt.figure(figsize=(7,7))\n    ax = fig.add_subplot(111, polar=True)\n    pcm = ax.pcolormesh(theta, r, Z, shading=\"auto\", cmap=\"viridis\")\n    ax.set_theta_zero_location(\"N\")\n    ax.set_theta_direction(-1)\n    ax.set_rmax(vmax)\n    #fig.colorbar(pcm, ax=ax, orientation=\"vertical\", label=\"Normalized Power\")\n    ax.set_title(f\"FK Radar {day_str}\\nBand {fmin}-{fmax} Hz\", fontsize=12)\n\n    # mark max point\n    ax.plot(np.deg2rad(max_az_deg), max_speed, 'ro', markersize=8, label=f\"Max Power\\nAz={max_az_deg:.1f}°, v={max_speed:.2f} km/s\")\n    ax.legend(loc='upper right', bbox_to_anchor=(1.3,1.1), fontsize=8)\n\n    out_png = os.path.join(output_dir, f\"fk_radar_{day_str}.png\")\n    plt.savefig(out_png, dpi=200, bbox_inches=\"tight\")\n    plt.close()\n    print(f\"[INFO] saved {out_png}\")\n    current += timedelta(days=1)\n```\n","source":"_posts/2025-08-24-fk.md","raw":"---\ntitle: PYTHON脚本练习（三）聚束分析\ntags:\n  - python\ncategories:\n  - python\nabbrlink: 2a2cdaad\ndate: 2025-08-24 11:19:23\n---\n&emsp;&emsp;python脚本练习-fk。\n<!--less-->\n&emsp;&emsp;以下脚本可完成功能：\n## 1.数据预处理与筛选\n  * 台站管理：从station.lst读取台站信息（网络名、台站名、经纬度）。\n  * 数据加载：按日期遍历数据目录，加载每个台站的LHZ分量SAC文件。\n  * 有效性检查：仅使用具有有效数据且台站数≥3天的数据。\n## 2.时间窗口分割\n  * 将每天数据分割为1800秒长、50%重叠的窗口（步长900秒）。\n  * 对每个窗口提取对应时间段的数据。\n## 3. 频域分析\n  * 滤波与窗函数：对每个台站数据加汉宁窗，去均值。\n  * FFT计算：使用下一个2的幂次长度进行FFT，提取[fmin, fmax]频段的频谱。\n## 4. 聚束分析（FK分析）\n  * 参数网格：\n  方位角（az\\_grid）：0°\\~360°，步长5°。\n  速度（speed\\_grid）：1\\~5 km/s，步长0.05 km/s（通过慢度1/v参与计算）。\n  * 波束功率计算：\n  1. 坐标转换：将台站经纬度转换为以平均位置为中心的直角坐标系（单位：公里）。\n  2. 相位延迟计算：\n    对每个方位角，计算台站投影位置proj = x*sin(az) + y*cos(az)。\n    对每个速度，计算时延delays = proj * 慢度（s=1/v）。\n  3. 导向向量：生成复相位因子exp(-j*2π*f*delays)。\n  4. 波束频谱：将各台站频谱与导向向量加权求和，得到波束频谱。\n  5. 功率归一化：计算波束功率并除以总功率（各台站功率之和）。\n## 5.结果可视化\n  * 雷达图绘制：\n  极坐标下，横轴为方位角，纵轴为速度，颜色表示归一化功率。\n  标注最大能量点，显示其方位角和速度。\n  * 输出：每天生成一张PNG图片，保存至arr_figures目录。\n## 脚本\n```\n#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\"\"\"\nCustom FK / beamforming array analysis (no obspy.array_processing)\n改进：使用速度 (km/s) 替代慢度，每天输出雷达图，并标注最大能量点\n\"\"\"\nimport os\nimport glob\nimport math\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom obspy import read, UTCDateTime\nfrom datetime import timedelta\n\n# ---------------- User parameters ----------------\nstation_file = \"station.lst\"\ndata_dir = \"data\"                 # structure: data/YYYYMMDD/NET_STA_LH?.SAC\noutput_dir = \"arr_figures\"\nos.makedirs(output_dir, exist_ok=True)\n\n# frequency band of interest\nfmin, fmax = 0.028, 0.032  # Hz\n\n# window settings\nwin_len = 1800             # seconds\nwin_frac = 0.5             # 50% overlap\nwin_step = int(win_len * (1 - win_frac))\n\n# FK grid\naz_step = 5.0\naz_grid = np.arange(0, 360, az_step)\n\n# speed search (instead of slowness)\nvmin, vmax, vstep = 1, 5.0, 0.05  # km/s\n#s_grid = 1.0 / np.arange(vmax, vmin, -vstep)  # convert to slowness s/km\nspeed_grid = np.arange(vmin, vmax, vstep)  # convert to slowness s/km\n\n#speed_grid = 1.0 / s_grid  # for plotting\ns_grid = 1.0 / speed_grid  # for plotting\n\n# day range\nstart_date = UTCDateTime(\"2013-01-01\")\nend_date   = UTCDateTime(\"2025-01-01\")\n\n# minimal number of stations\nmin_stations = 3\n\n# ---------------- helper functions ----------------\ndef read_stations(station_file):\n    stations = []\n    with open(station_file, \"r\") as f:\n        for line in f:\n            line = line.strip()\n            if not line or line.startswith(\"#\"):\n                continue\n            parts = line.split(\"|\")\n            if len(parts) < 4:\n                continue\n            net, sta = parts[0].strip(), parts[1].strip()\n            try:\n                lat = float(parts[2]); lon = float(parts[3])\n            except Exception:\n                continue\n            stations.append((net, sta, lat, lon))\n    return stations\n\ndef geo_to_xy_km(lats, lons):\n    lat0 = np.mean(lats)\n    lon0 = np.mean(lons)\n    deg2km_lat = 110.574\n    deg2km_lon = 111.320 * math.cos(math.radians(lat0))\n    xs = (np.array(lons) - lon0) * deg2km_lon\n    ys = (np.array(lats) - lat0) * deg2km_lat\n    return xs, ys, lat0, lon0\n\ndef window_slices(day_start, win_len, win_step):\n    t0 = int(day_start.timestamp)\n    t_end = int((day_start + 86400).timestamp)\n    slices = []\n    t = t0\n    while t + win_len <= t_end:\n        slices.append((t, t + win_len))\n        t += win_step\n    return slices\n\ndef next_pow2(n):\n    return 1 << (n - 1).bit_length()\n\n# ---------------- main pipeline ----------------\nstations = read_stations(station_file)\nif len(stations) == 0:\n    raise SystemExit(\"No stations read from station.lst\")\n\nprint(f\"[INFO] Read {len(stations)} stations\")\n\ncurrent = start_date\nwhile current <= end_date:\n    day_str = current.strftime(\"%Y%m%d\")\n    day_path = os.path.join(data_dir, day_str)\n    print(f\"\\n[INFO] Processing {day_str} ...\")\n    if not os.path.isdir(day_path):\n        print(f\"[WARN] {day_path} not found. skip.\")\n        current += timedelta(days=1)\n        continue\n\n    # read one trace per station\n    traces = {}\n    lat_list = []; lon_list = []; net_sta_list = []\n    for net, sta, lat, lon in stations:\n        pattern = os.path.join(day_path, f\"{net}_{sta}_LHZ.SAC\")\n        files = sorted(glob.glob(pattern))\n        if not files: continue\n        try:\n            tr = read(files[0])[0]\n            traces[(net,sta)] = tr\n            lat_list.append(lat); lon_list.append(lon); net_sta_list.append((net,sta))\n        except Exception as e:\n            print(f\"[WARN] read {files[0]} failed: {e}\")\n            continue\n\n    nsta = len(traces)\n    if nsta < min_stations:\n        print(f\"[WARN] Only {nsta} stations available, skip.\")\n        current += timedelta(days=1)\n        continue\n\n    # sampling rate\n    sr_target = min([tr.stats.sampling_rate for tr in traces.values()])\n    xs, ys, lat0, lon0 = geo_to_xy_km(lat_list, lon_list)\n\n    # reorder traces\n    traces_ordered = [traces[k] for k in net_sta_list]\n\n    # window slices\n    day_start = UTCDateTime(current.strftime(\"%Y-%m-%dT00:00:00\"))\n    slices = window_slices(day_start, win_len, win_step)\n    print(f\"[INFO] {len(slices)} windows\")\n\n    # accumulate daily power grid\n    daily_power = np.zeros((len(az_grid), len(s_grid)))\n    nwin_used = 0\n\n    for (t0, t1) in slices:\n        specs = []\n        valid = True\n        nfft = None\n        for tr in traces_ordered:\n            try:\n                seg = tr.slice(UTCDateTime(t0), UTCDateTime(t1), nearest_sample=False)\n            except:\n                valid = False; break\n            expected_npts = int(round((t1 - t0) * sr_target))\n            data = seg.data.astype(np.float64)\n            if len(data) < expected_npts:\n                if len(data) == 0: valid = False; break\n                data = np.pad(data, (0, expected_npts-len(data)))\n            elif len(data) > expected_npts:\n                data = data[:expected_npts]\n            data -= np.mean(data)\n            data *= np.hanning(len(data))\n            if nfft is None:\n                nfft = next_pow2(len(data))\n            spec = np.fft.rfft(data, n=nfft)\n            freqs = np.fft.rfftfreq(nfft, d=1.0/sr_target)\n            specs.append(spec)\n        if not valid or nfft is None: continue\n\n        specs = np.array(specs)\n        freq_mask = (freqs>=fmin)&(freqs<=fmax)\n        if not np.any(freq_mask): continue\n        freqs_sel = freqs[freq_mask]\n        specs_sel = specs[:, freq_mask]\n\n        xs_arr = np.array(xs); ys_arr = np.array(ys)\n        spec_power = np.sum(np.abs(specs_sel)**2)\n        if spec_power<=0: continue\n\n        two_pi = 2*np.pi\n        power_grid = np.zeros((len(az_grid), len(s_grid)))\n        for ia, az_deg in enumerate(az_grid):\n            az_rad = math.radians(az_deg)\n            proj = xs_arr*np.sin(az_rad) + ys_arr*np.cos(az_rad)\n            for is_idx, s in enumerate(s_grid):\n                delays = proj*s\n                steering = np.exp(-1j*two_pi*np.outer(delays,freqs_sel))\n                beam_spectrum = np.sum(steering*specs_sel, axis=0)\n                power = np.sum(np.abs(beam_spectrum)**2)\n                power_grid[ia,is_idx] = power/spec_power\n        daily_power += power_grid\n        nwin_used += 1\n\n    if nwin_used==0:\n        print(f\"[WARN] no valid windows {day_str}\")\n        current += timedelta(days=1)\n        continue\n\n    daily_power /= nwin_used\n    print(f\"[INFO] averaged over {nwin_used} windows\")\n\n    # ---------------- plot daily radar ----------------\n    theta, r = np.meshgrid(np.deg2rad(az_grid), speed_grid)\n    Z = daily_power.T  # shape (len(s_grid), len(az_grid))\n\n    # locate max power\n    max_idx = np.unravel_index(np.argmax(Z), Z.shape)\n    max_az_deg = az_grid[max_idx[1]]\n    max_speed = r[max_idx]  # km/s\n\n    fig = plt.figure(figsize=(7,7))\n    ax = fig.add_subplot(111, polar=True)\n    pcm = ax.pcolormesh(theta, r, Z, shading=\"auto\", cmap=\"viridis\")\n    ax.set_theta_zero_location(\"N\")\n    ax.set_theta_direction(-1)\n    ax.set_rmax(vmax)\n    #fig.colorbar(pcm, ax=ax, orientation=\"vertical\", label=\"Normalized Power\")\n    ax.set_title(f\"FK Radar {day_str}\\nBand {fmin}-{fmax} Hz\", fontsize=12)\n\n    # mark max point\n    ax.plot(np.deg2rad(max_az_deg), max_speed, 'ro', markersize=8, label=f\"Max Power\\nAz={max_az_deg:.1f}°, v={max_speed:.2f} km/s\")\n    ax.legend(loc='upper right', bbox_to_anchor=(1.3,1.1), fontsize=8)\n\n    out_png = os.path.join(output_dir, f\"fk_radar_{day_str}.png\")\n    plt.savefig(out_png, dpi=200, bbox_inches=\"tight\")\n    plt.close()\n    print(f\"[INFO] saved {out_png}\")\n    current += timedelta(days=1)\n```\n","slug":"fk","published":1,"updated":"2025-08-25T14:03:41.362Z","comments":1,"layout":"post","photos":[],"_id":"cmh498iqn00e2wvou6i2v0pnc","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>&emsp;&emsp;以下脚本可完成功能：</p>\n<h2 id=\"1-数据预处理与筛选\"><a href=\"#1-数据预处理与筛选\" class=\"headerlink\" title=\"1.数据预处理与筛选\"></a>1.数据预处理与筛选</h2><ul>\n<li>台站管理：从station.lst读取台站信息（网络名、台站名、经纬度）。</li>\n<li>数据加载：按日期遍历数据目录，加载每个台站的LHZ分量SAC文件。</li>\n<li>有效性检查：仅使用具有有效数据且台站数≥3天的数据。</li>\n</ul>\n<h2 id=\"2-时间窗口分割\"><a href=\"#2-时间窗口分割\" class=\"headerlink\" title=\"2.时间窗口分割\"></a>2.时间窗口分割</h2><ul>\n<li>将每天数据分割为1800秒长、50%重叠的窗口（步长900秒）。</li>\n<li>对每个窗口提取对应时间段的数据。</li>\n</ul>\n<h2 id=\"3-频域分析\"><a href=\"#3-频域分析\" class=\"headerlink\" title=\"3. 频域分析\"></a>3. 频域分析</h2><ul>\n<li>滤波与窗函数：对每个台站数据加汉宁窗，去均值。</li>\n<li>FFT计算：使用下一个2的幂次长度进行FFT，提取[fmin, fmax]频段的频谱。</li>\n</ul>\n<h2 id=\"4-聚束分析（FK分析）\"><a href=\"#4-聚束分析（FK分析）\" class=\"headerlink\" title=\"4. 聚束分析（FK分析）\"></a>4. 聚束分析（FK分析）</h2><ul>\n<li>参数网格：<br>  方位角（az_grid）：0°~360°，步长5°。<br>  速度（speed_grid）：1~5 km&#x2F;s，步长0.05 km&#x2F;s（通过慢度1&#x2F;v参与计算）。</li>\n<li>波束功率计算：</li>\n</ul>\n<ol>\n<li>坐标转换：将台站经纬度转换为以平均位置为中心的直角坐标系（单位：公里）。</li>\n<li>相位延迟计算：<br>对每个方位角，计算台站投影位置proj &#x3D; x<em>sin(az) + y</em>cos(az)。<br>对每个速度，计算时延delays &#x3D; proj * 慢度（s&#x3D;1&#x2F;v）。</li>\n<li>导向向量：生成复相位因子exp(-j<em>2π</em>f*delays)。</li>\n<li>波束频谱：将各台站频谱与导向向量加权求和，得到波束频谱。</li>\n<li>功率归一化：计算波束功率并除以总功率（各台站功率之和）。</li>\n</ol>\n<h2 id=\"5-结果可视化\"><a href=\"#5-结果可视化\" class=\"headerlink\" title=\"5.结果可视化\"></a>5.结果可视化</h2><ul>\n<li>雷达图绘制：<br>  极坐标下，横轴为方位角，纵轴为速度，颜色表示归一化功率。<br>  标注最大能量点，显示其方位角和速度。</li>\n<li>输出：每天生成一张PNG图片，保存至arr_figures目录。</li>\n</ul>\n<h2 id=\"脚本\"><a href=\"#脚本\" class=\"headerlink\" title=\"脚本\"></a>脚本</h2><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br><span class=\"line\">145</span><br><span class=\"line\">146</span><br><span class=\"line\">147</span><br><span class=\"line\">148</span><br><span class=\"line\">149</span><br><span class=\"line\">150</span><br><span class=\"line\">151</span><br><span class=\"line\">152</span><br><span class=\"line\">153</span><br><span class=\"line\">154</span><br><span class=\"line\">155</span><br><span class=\"line\">156</span><br><span class=\"line\">157</span><br><span class=\"line\">158</span><br><span class=\"line\">159</span><br><span class=\"line\">160</span><br><span class=\"line\">161</span><br><span class=\"line\">162</span><br><span class=\"line\">163</span><br><span class=\"line\">164</span><br><span class=\"line\">165</span><br><span class=\"line\">166</span><br><span class=\"line\">167</span><br><span class=\"line\">168</span><br><span class=\"line\">169</span><br><span class=\"line\">170</span><br><span class=\"line\">171</span><br><span class=\"line\">172</span><br><span class=\"line\">173</span><br><span class=\"line\">174</span><br><span class=\"line\">175</span><br><span class=\"line\">176</span><br><span class=\"line\">177</span><br><span class=\"line\">178</span><br><span class=\"line\">179</span><br><span class=\"line\">180</span><br><span class=\"line\">181</span><br><span class=\"line\">182</span><br><span class=\"line\">183</span><br><span class=\"line\">184</span><br><span class=\"line\">185</span><br><span class=\"line\">186</span><br><span class=\"line\">187</span><br><span class=\"line\">188</span><br><span class=\"line\">189</span><br><span class=\"line\">190</span><br><span class=\"line\">191</span><br><span class=\"line\">192</span><br><span class=\"line\">193</span><br><span class=\"line\">194</span><br><span class=\"line\">195</span><br><span class=\"line\">196</span><br><span class=\"line\">197</span><br><span class=\"line\">198</span><br><span class=\"line\">199</span><br><span class=\"line\">200</span><br><span class=\"line\">201</span><br><span class=\"line\">202</span><br><span class=\"line\">203</span><br><span class=\"line\">204</span><br><span class=\"line\">205</span><br><span class=\"line\">206</span><br><span class=\"line\">207</span><br><span class=\"line\">208</span><br><span class=\"line\">209</span><br><span class=\"line\">210</span><br><span class=\"line\">211</span><br><span class=\"line\">212</span><br><span class=\"line\">213</span><br><span class=\"line\">214</span><br><span class=\"line\">215</span><br><span class=\"line\">216</span><br><span class=\"line\">217</span><br><span class=\"line\">218</span><br><span class=\"line\">219</span><br><span class=\"line\">220</span><br><span class=\"line\">221</span><br><span class=\"line\">222</span><br><span class=\"line\">223</span><br><span class=\"line\">224</span><br><span class=\"line\">225</span><br><span class=\"line\">226</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#!/usr/bin/env python3</span><br><span class=\"line\"># -*- coding: utf-8 -*-</span><br><span class=\"line\">&quot;&quot;&quot;</span><br><span class=\"line\">Custom FK / beamforming array analysis (no obspy.array_processing)</span><br><span class=\"line\">改进：使用速度 (km/s) 替代慢度，每天输出雷达图，并标注最大能量点</span><br><span class=\"line\">&quot;&quot;&quot;</span><br><span class=\"line\">import os</span><br><span class=\"line\">import glob</span><br><span class=\"line\">import math</span><br><span class=\"line\">import numpy as np</span><br><span class=\"line\">import matplotlib.pyplot as plt</span><br><span class=\"line\">from obspy import read, UTCDateTime</span><br><span class=\"line\">from datetime import timedelta</span><br><span class=\"line\"></span><br><span class=\"line\"># ---------------- User parameters ----------------</span><br><span class=\"line\">station_file = &quot;station.lst&quot;</span><br><span class=\"line\">data_dir = &quot;data&quot;                 # structure: data/YYYYMMDD/NET_STA_LH?.SAC</span><br><span class=\"line\">output_dir = &quot;arr_figures&quot;</span><br><span class=\"line\">os.makedirs(output_dir, exist_ok=True)</span><br><span class=\"line\"></span><br><span class=\"line\"># frequency band of interest</span><br><span class=\"line\">fmin, fmax = 0.028, 0.032  # Hz</span><br><span class=\"line\"></span><br><span class=\"line\"># window settings</span><br><span class=\"line\">win_len = 1800             # seconds</span><br><span class=\"line\">win_frac = 0.5             # 50% overlap</span><br><span class=\"line\">win_step = int(win_len * (1 - win_frac))</span><br><span class=\"line\"></span><br><span class=\"line\"># FK grid</span><br><span class=\"line\">az_step = 5.0</span><br><span class=\"line\">az_grid = np.arange(0, 360, az_step)</span><br><span class=\"line\"></span><br><span class=\"line\"># speed search (instead of slowness)</span><br><span class=\"line\">vmin, vmax, vstep = 1, 5.0, 0.05  # km/s</span><br><span class=\"line\">#s_grid = 1.0 / np.arange(vmax, vmin, -vstep)  # convert to slowness s/km</span><br><span class=\"line\">speed_grid = np.arange(vmin, vmax, vstep)  # convert to slowness s/km</span><br><span class=\"line\"></span><br><span class=\"line\">#speed_grid = 1.0 / s_grid  # for plotting</span><br><span class=\"line\">s_grid = 1.0 / speed_grid  # for plotting</span><br><span class=\"line\"></span><br><span class=\"line\"># day range</span><br><span class=\"line\">start_date = UTCDateTime(&quot;2013-01-01&quot;)</span><br><span class=\"line\">end_date   = UTCDateTime(&quot;2025-01-01&quot;)</span><br><span class=\"line\"></span><br><span class=\"line\"># minimal number of stations</span><br><span class=\"line\">min_stations = 3</span><br><span class=\"line\"></span><br><span class=\"line\"># ---------------- helper functions ----------------</span><br><span class=\"line\">def read_stations(station_file):</span><br><span class=\"line\">    stations = []</span><br><span class=\"line\">    with open(station_file, &quot;r&quot;) as f:</span><br><span class=\"line\">        for line in f:</span><br><span class=\"line\">            line = line.strip()</span><br><span class=\"line\">            if not line or line.startswith(&quot;#&quot;):</span><br><span class=\"line\">                continue</span><br><span class=\"line\">            parts = line.split(&quot;|&quot;)</span><br><span class=\"line\">            if len(parts) &lt; 4:</span><br><span class=\"line\">                continue</span><br><span class=\"line\">            net, sta = parts[0].strip(), parts[1].strip()</span><br><span class=\"line\">            try:</span><br><span class=\"line\">                lat = float(parts[2]); lon = float(parts[3])</span><br><span class=\"line\">            except Exception:</span><br><span class=\"line\">                continue</span><br><span class=\"line\">            stations.append((net, sta, lat, lon))</span><br><span class=\"line\">    return stations</span><br><span class=\"line\"></span><br><span class=\"line\">def geo_to_xy_km(lats, lons):</span><br><span class=\"line\">    lat0 = np.mean(lats)</span><br><span class=\"line\">    lon0 = np.mean(lons)</span><br><span class=\"line\">    deg2km_lat = 110.574</span><br><span class=\"line\">    deg2km_lon = 111.320 * math.cos(math.radians(lat0))</span><br><span class=\"line\">    xs = (np.array(lons) - lon0) * deg2km_lon</span><br><span class=\"line\">    ys = (np.array(lats) - lat0) * deg2km_lat</span><br><span class=\"line\">    return xs, ys, lat0, lon0</span><br><span class=\"line\"></span><br><span class=\"line\">def window_slices(day_start, win_len, win_step):</span><br><span class=\"line\">    t0 = int(day_start.timestamp)</span><br><span class=\"line\">    t_end = int((day_start + 86400).timestamp)</span><br><span class=\"line\">    slices = []</span><br><span class=\"line\">    t = t0</span><br><span class=\"line\">    while t + win_len &lt;= t_end:</span><br><span class=\"line\">        slices.append((t, t + win_len))</span><br><span class=\"line\">        t += win_step</span><br><span class=\"line\">    return slices</span><br><span class=\"line\"></span><br><span class=\"line\">def next_pow2(n):</span><br><span class=\"line\">    return 1 &lt;&lt; (n - 1).bit_length()</span><br><span class=\"line\"></span><br><span class=\"line\"># ---------------- main pipeline ----------------</span><br><span class=\"line\">stations = read_stations(station_file)</span><br><span class=\"line\">if len(stations) == 0:</span><br><span class=\"line\">    raise SystemExit(&quot;No stations read from station.lst&quot;)</span><br><span class=\"line\"></span><br><span class=\"line\">print(f&quot;[INFO] Read &#123;len(stations)&#125; stations&quot;)</span><br><span class=\"line\"></span><br><span class=\"line\">current = start_date</span><br><span class=\"line\">while current &lt;= end_date:</span><br><span class=\"line\">    day_str = current.strftime(&quot;%Y%m%d&quot;)</span><br><span class=\"line\">    day_path = os.path.join(data_dir, day_str)</span><br><span class=\"line\">    print(f&quot;\\n[INFO] Processing &#123;day_str&#125; ...&quot;)</span><br><span class=\"line\">    if not os.path.isdir(day_path):</span><br><span class=\"line\">        print(f&quot;[WARN] &#123;day_path&#125; not found. skip.&quot;)</span><br><span class=\"line\">        current += timedelta(days=1)</span><br><span class=\"line\">        continue</span><br><span class=\"line\"></span><br><span class=\"line\">    # read one trace per station</span><br><span class=\"line\">    traces = &#123;&#125;</span><br><span class=\"line\">    lat_list = []; lon_list = []; net_sta_list = []</span><br><span class=\"line\">    for net, sta, lat, lon in stations:</span><br><span class=\"line\">        pattern = os.path.join(day_path, f&quot;&#123;net&#125;_&#123;sta&#125;_LHZ.SAC&quot;)</span><br><span class=\"line\">        files = sorted(glob.glob(pattern))</span><br><span class=\"line\">        if not files: continue</span><br><span class=\"line\">        try:</span><br><span class=\"line\">            tr = read(files[0])[0]</span><br><span class=\"line\">            traces[(net,sta)] = tr</span><br><span class=\"line\">            lat_list.append(lat); lon_list.append(lon); net_sta_list.append((net,sta))</span><br><span class=\"line\">        except Exception as e:</span><br><span class=\"line\">            print(f&quot;[WARN] read &#123;files[0]&#125; failed: &#123;e&#125;&quot;)</span><br><span class=\"line\">            continue</span><br><span class=\"line\"></span><br><span class=\"line\">    nsta = len(traces)</span><br><span class=\"line\">    if nsta &lt; min_stations:</span><br><span class=\"line\">        print(f&quot;[WARN] Only &#123;nsta&#125; stations available, skip.&quot;)</span><br><span class=\"line\">        current += timedelta(days=1)</span><br><span class=\"line\">        continue</span><br><span class=\"line\"></span><br><span class=\"line\">    # sampling rate</span><br><span class=\"line\">    sr_target = min([tr.stats.sampling_rate for tr in traces.values()])</span><br><span class=\"line\">    xs, ys, lat0, lon0 = geo_to_xy_km(lat_list, lon_list)</span><br><span class=\"line\"></span><br><span class=\"line\">    # reorder traces</span><br><span class=\"line\">    traces_ordered = [traces[k] for k in net_sta_list]</span><br><span class=\"line\"></span><br><span class=\"line\">    # window slices</span><br><span class=\"line\">    day_start = UTCDateTime(current.strftime(&quot;%Y-%m-%dT00:00:00&quot;))</span><br><span class=\"line\">    slices = window_slices(day_start, win_len, win_step)</span><br><span class=\"line\">    print(f&quot;[INFO] &#123;len(slices)&#125; windows&quot;)</span><br><span class=\"line\"></span><br><span class=\"line\">    # accumulate daily power grid</span><br><span class=\"line\">    daily_power = np.zeros((len(az_grid), len(s_grid)))</span><br><span class=\"line\">    nwin_used = 0</span><br><span class=\"line\"></span><br><span class=\"line\">    for (t0, t1) in slices:</span><br><span class=\"line\">        specs = []</span><br><span class=\"line\">        valid = True</span><br><span class=\"line\">        nfft = None</span><br><span class=\"line\">        for tr in traces_ordered:</span><br><span class=\"line\">            try:</span><br><span class=\"line\">                seg = tr.slice(UTCDateTime(t0), UTCDateTime(t1), nearest_sample=False)</span><br><span class=\"line\">            except:</span><br><span class=\"line\">                valid = False; break</span><br><span class=\"line\">            expected_npts = int(round((t1 - t0) * sr_target))</span><br><span class=\"line\">            data = seg.data.astype(np.float64)</span><br><span class=\"line\">            if len(data) &lt; expected_npts:</span><br><span class=\"line\">                if len(data) == 0: valid = False; break</span><br><span class=\"line\">                data = np.pad(data, (0, expected_npts-len(data)))</span><br><span class=\"line\">            elif len(data) &gt; expected_npts:</span><br><span class=\"line\">                data = data[:expected_npts]</span><br><span class=\"line\">            data -= np.mean(data)</span><br><span class=\"line\">            data *= np.hanning(len(data))</span><br><span class=\"line\">            if nfft is None:</span><br><span class=\"line\">                nfft = next_pow2(len(data))</span><br><span class=\"line\">            spec = np.fft.rfft(data, n=nfft)</span><br><span class=\"line\">            freqs = np.fft.rfftfreq(nfft, d=1.0/sr_target)</span><br><span class=\"line\">            specs.append(spec)</span><br><span class=\"line\">        if not valid or nfft is None: continue</span><br><span class=\"line\"></span><br><span class=\"line\">        specs = np.array(specs)</span><br><span class=\"line\">        freq_mask = (freqs&gt;=fmin)&amp;(freqs&lt;=fmax)</span><br><span class=\"line\">        if not np.any(freq_mask): continue</span><br><span class=\"line\">        freqs_sel = freqs[freq_mask]</span><br><span class=\"line\">        specs_sel = specs[:, freq_mask]</span><br><span class=\"line\"></span><br><span class=\"line\">        xs_arr = np.array(xs); ys_arr = np.array(ys)</span><br><span class=\"line\">        spec_power = np.sum(np.abs(specs_sel)**2)</span><br><span class=\"line\">        if spec_power&lt;=0: continue</span><br><span class=\"line\"></span><br><span class=\"line\">        two_pi = 2*np.pi</span><br><span class=\"line\">        power_grid = np.zeros((len(az_grid), len(s_grid)))</span><br><span class=\"line\">        for ia, az_deg in enumerate(az_grid):</span><br><span class=\"line\">            az_rad = math.radians(az_deg)</span><br><span class=\"line\">            proj = xs_arr*np.sin(az_rad) + ys_arr*np.cos(az_rad)</span><br><span class=\"line\">            for is_idx, s in enumerate(s_grid):</span><br><span class=\"line\">                delays = proj*s</span><br><span class=\"line\">                steering = np.exp(-1j*two_pi*np.outer(delays,freqs_sel))</span><br><span class=\"line\">                beam_spectrum = np.sum(steering*specs_sel, axis=0)</span><br><span class=\"line\">                power = np.sum(np.abs(beam_spectrum)**2)</span><br><span class=\"line\">                power_grid[ia,is_idx] = power/spec_power</span><br><span class=\"line\">        daily_power += power_grid</span><br><span class=\"line\">        nwin_used += 1</span><br><span class=\"line\"></span><br><span class=\"line\">    if nwin_used==0:</span><br><span class=\"line\">        print(f&quot;[WARN] no valid windows &#123;day_str&#125;&quot;)</span><br><span class=\"line\">        current += timedelta(days=1)</span><br><span class=\"line\">        continue</span><br><span class=\"line\"></span><br><span class=\"line\">    daily_power /= nwin_used</span><br><span class=\"line\">    print(f&quot;[INFO] averaged over &#123;nwin_used&#125; windows&quot;)</span><br><span class=\"line\"></span><br><span class=\"line\">    # ---------------- plot daily radar ----------------</span><br><span class=\"line\">    theta, r = np.meshgrid(np.deg2rad(az_grid), speed_grid)</span><br><span class=\"line\">    Z = daily_power.T  # shape (len(s_grid), len(az_grid))</span><br><span class=\"line\"></span><br><span class=\"line\">    # locate max power</span><br><span class=\"line\">    max_idx = np.unravel_index(np.argmax(Z), Z.shape)</span><br><span class=\"line\">    max_az_deg = az_grid[max_idx[1]]</span><br><span class=\"line\">    max_speed = r[max_idx]  # km/s</span><br><span class=\"line\"></span><br><span class=\"line\">    fig = plt.figure(figsize=(7,7))</span><br><span class=\"line\">    ax = fig.add_subplot(111, polar=True)</span><br><span class=\"line\">    pcm = ax.pcolormesh(theta, r, Z, shading=&quot;auto&quot;, cmap=&quot;viridis&quot;)</span><br><span class=\"line\">    ax.set_theta_zero_location(&quot;N&quot;)</span><br><span class=\"line\">    ax.set_theta_direction(-1)</span><br><span class=\"line\">    ax.set_rmax(vmax)</span><br><span class=\"line\">    #fig.colorbar(pcm, ax=ax, orientation=&quot;vertical&quot;, label=&quot;Normalized Power&quot;)</span><br><span class=\"line\">    ax.set_title(f&quot;FK Radar &#123;day_str&#125;\\nBand &#123;fmin&#125;-&#123;fmax&#125; Hz&quot;, fontsize=12)</span><br><span class=\"line\"></span><br><span class=\"line\">    # mark max point</span><br><span class=\"line\">    ax.plot(np.deg2rad(max_az_deg), max_speed, &#x27;ro&#x27;, markersize=8, label=f&quot;Max Power\\nAz=&#123;max_az_deg:.1f&#125;°, v=&#123;max_speed:.2f&#125; km/s&quot;)</span><br><span class=\"line\">    ax.legend(loc=&#x27;upper right&#x27;, bbox_to_anchor=(1.3,1.1), fontsize=8)</span><br><span class=\"line\"></span><br><span class=\"line\">    out_png = os.path.join(output_dir, f&quot;fk_radar_&#123;day_str&#125;.png&quot;)</span><br><span class=\"line\">    plt.savefig(out_png, dpi=200, bbox_inches=&quot;tight&quot;)</span><br><span class=\"line\">    plt.close()</span><br><span class=\"line\">    print(f&quot;[INFO] saved &#123;out_png&#125;&quot;)</span><br><span class=\"line\">    current += timedelta(days=1)</span><br></pre></td></tr></table></figure>","related_posts":[],"length":7472,"excerpt":"<p>&emsp;&emsp;python脚本练习-fk。</p>","more":"<p>&emsp;&emsp;以下脚本可完成功能：</p>\n<h2 id=\"1-数据预处理与筛选\"><a href=\"#1-数据预处理与筛选\" class=\"headerlink\" title=\"1.数据预处理与筛选\"></a>1.数据预处理与筛选</h2><ul>\n<li>台站管理：从station.lst读取台站信息（网络名、台站名、经纬度）。</li>\n<li>数据加载：按日期遍历数据目录，加载每个台站的LHZ分量SAC文件。</li>\n<li>有效性检查：仅使用具有有效数据且台站数≥3天的数据。</li>\n</ul>\n<h2 id=\"2-时间窗口分割\"><a href=\"#2-时间窗口分割\" class=\"headerlink\" title=\"2.时间窗口分割\"></a>2.时间窗口分割</h2><ul>\n<li>将每天数据分割为1800秒长、50%重叠的窗口（步长900秒）。</li>\n<li>对每个窗口提取对应时间段的数据。</li>\n</ul>\n<h2 id=\"3-频域分析\"><a href=\"#3-频域分析\" class=\"headerlink\" title=\"3. 频域分析\"></a>3. 频域分析</h2><ul>\n<li>滤波与窗函数：对每个台站数据加汉宁窗，去均值。</li>\n<li>FFT计算：使用下一个2的幂次长度进行FFT，提取[fmin, fmax]频段的频谱。</li>\n</ul>\n<h2 id=\"4-聚束分析（FK分析）\"><a href=\"#4-聚束分析（FK分析）\" class=\"headerlink\" title=\"4. 聚束分析（FK分析）\"></a>4. 聚束分析（FK分析）</h2><ul>\n<li>参数网格：<br>  方位角（az_grid）：0°~360°，步长5°。<br>  速度（speed_grid）：1~5 km&#x2F;s，步长0.05 km&#x2F;s（通过慢度1&#x2F;v参与计算）。</li>\n<li>波束功率计算：</li>\n</ul>\n<ol>\n<li>坐标转换：将台站经纬度转换为以平均位置为中心的直角坐标系（单位：公里）。</li>\n<li>相位延迟计算：<br>对每个方位角，计算台站投影位置proj &#x3D; x<em>sin(az) + y</em>cos(az)。<br>对每个速度，计算时延delays &#x3D; proj * 慢度（s&#x3D;1&#x2F;v）。</li>\n<li>导向向量：生成复相位因子exp(-j<em>2π</em>f*delays)。</li>\n<li>波束频谱：将各台站频谱与导向向量加权求和，得到波束频谱。</li>\n<li>功率归一化：计算波束功率并除以总功率（各台站功率之和）。</li>\n</ol>\n<h2 id=\"5-结果可视化\"><a href=\"#5-结果可视化\" class=\"headerlink\" title=\"5.结果可视化\"></a>5.结果可视化</h2><ul>\n<li>雷达图绘制：<br>  极坐标下，横轴为方位角，纵轴为速度，颜色表示归一化功率。<br>  标注最大能量点，显示其方位角和速度。</li>\n<li>输出：每天生成一张PNG图片，保存至arr_figures目录。</li>\n</ul>\n<h2 id=\"脚本\"><a href=\"#脚本\" class=\"headerlink\" title=\"脚本\"></a>脚本</h2><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br><span class=\"line\">145</span><br><span class=\"line\">146</span><br><span class=\"line\">147</span><br><span class=\"line\">148</span><br><span class=\"line\">149</span><br><span class=\"line\">150</span><br><span class=\"line\">151</span><br><span class=\"line\">152</span><br><span class=\"line\">153</span><br><span class=\"line\">154</span><br><span class=\"line\">155</span><br><span class=\"line\">156</span><br><span class=\"line\">157</span><br><span class=\"line\">158</span><br><span class=\"line\">159</span><br><span class=\"line\">160</span><br><span class=\"line\">161</span><br><span class=\"line\">162</span><br><span class=\"line\">163</span><br><span class=\"line\">164</span><br><span class=\"line\">165</span><br><span class=\"line\">166</span><br><span class=\"line\">167</span><br><span class=\"line\">168</span><br><span class=\"line\">169</span><br><span class=\"line\">170</span><br><span class=\"line\">171</span><br><span class=\"line\">172</span><br><span class=\"line\">173</span><br><span class=\"line\">174</span><br><span class=\"line\">175</span><br><span class=\"line\">176</span><br><span class=\"line\">177</span><br><span class=\"line\">178</span><br><span class=\"line\">179</span><br><span class=\"line\">180</span><br><span class=\"line\">181</span><br><span class=\"line\">182</span><br><span class=\"line\">183</span><br><span class=\"line\">184</span><br><span class=\"line\">185</span><br><span class=\"line\">186</span><br><span class=\"line\">187</span><br><span class=\"line\">188</span><br><span class=\"line\">189</span><br><span class=\"line\">190</span><br><span class=\"line\">191</span><br><span class=\"line\">192</span><br><span class=\"line\">193</span><br><span class=\"line\">194</span><br><span class=\"line\">195</span><br><span class=\"line\">196</span><br><span class=\"line\">197</span><br><span class=\"line\">198</span><br><span class=\"line\">199</span><br><span class=\"line\">200</span><br><span class=\"line\">201</span><br><span class=\"line\">202</span><br><span class=\"line\">203</span><br><span class=\"line\">204</span><br><span class=\"line\">205</span><br><span class=\"line\">206</span><br><span class=\"line\">207</span><br><span class=\"line\">208</span><br><span class=\"line\">209</span><br><span class=\"line\">210</span><br><span class=\"line\">211</span><br><span class=\"line\">212</span><br><span class=\"line\">213</span><br><span class=\"line\">214</span><br><span class=\"line\">215</span><br><span class=\"line\">216</span><br><span class=\"line\">217</span><br><span class=\"line\">218</span><br><span class=\"line\">219</span><br><span class=\"line\">220</span><br><span class=\"line\">221</span><br><span class=\"line\">222</span><br><span class=\"line\">223</span><br><span class=\"line\">224</span><br><span class=\"line\">225</span><br><span class=\"line\">226</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#!/usr/bin/env python3</span><br><span class=\"line\"># -*- coding: utf-8 -*-</span><br><span class=\"line\">&quot;&quot;&quot;</span><br><span class=\"line\">Custom FK / beamforming array analysis (no obspy.array_processing)</span><br><span class=\"line\">改进：使用速度 (km/s) 替代慢度，每天输出雷达图，并标注最大能量点</span><br><span class=\"line\">&quot;&quot;&quot;</span><br><span class=\"line\">import os</span><br><span class=\"line\">import glob</span><br><span class=\"line\">import math</span><br><span class=\"line\">import numpy as np</span><br><span class=\"line\">import matplotlib.pyplot as plt</span><br><span class=\"line\">from obspy import read, UTCDateTime</span><br><span class=\"line\">from datetime import timedelta</span><br><span class=\"line\"></span><br><span class=\"line\"># ---------------- User parameters ----------------</span><br><span class=\"line\">station_file = &quot;station.lst&quot;</span><br><span class=\"line\">data_dir = &quot;data&quot;                 # structure: data/YYYYMMDD/NET_STA_LH?.SAC</span><br><span class=\"line\">output_dir = &quot;arr_figures&quot;</span><br><span class=\"line\">os.makedirs(output_dir, exist_ok=True)</span><br><span class=\"line\"></span><br><span class=\"line\"># frequency band of interest</span><br><span class=\"line\">fmin, fmax = 0.028, 0.032  # Hz</span><br><span class=\"line\"></span><br><span class=\"line\"># window settings</span><br><span class=\"line\">win_len = 1800             # seconds</span><br><span class=\"line\">win_frac = 0.5             # 50% overlap</span><br><span class=\"line\">win_step = int(win_len * (1 - win_frac))</span><br><span class=\"line\"></span><br><span class=\"line\"># FK grid</span><br><span class=\"line\">az_step = 5.0</span><br><span class=\"line\">az_grid = np.arange(0, 360, az_step)</span><br><span class=\"line\"></span><br><span class=\"line\"># speed search (instead of slowness)</span><br><span class=\"line\">vmin, vmax, vstep = 1, 5.0, 0.05  # km/s</span><br><span class=\"line\">#s_grid = 1.0 / np.arange(vmax, vmin, -vstep)  # convert to slowness s/km</span><br><span class=\"line\">speed_grid = np.arange(vmin, vmax, vstep)  # convert to slowness s/km</span><br><span class=\"line\"></span><br><span class=\"line\">#speed_grid = 1.0 / s_grid  # for plotting</span><br><span class=\"line\">s_grid = 1.0 / speed_grid  # for plotting</span><br><span class=\"line\"></span><br><span class=\"line\"># day range</span><br><span class=\"line\">start_date = UTCDateTime(&quot;2013-01-01&quot;)</span><br><span class=\"line\">end_date   = UTCDateTime(&quot;2025-01-01&quot;)</span><br><span class=\"line\"></span><br><span class=\"line\"># minimal number of stations</span><br><span class=\"line\">min_stations = 3</span><br><span class=\"line\"></span><br><span class=\"line\"># ---------------- helper functions ----------------</span><br><span class=\"line\">def read_stations(station_file):</span><br><span class=\"line\">    stations = []</span><br><span class=\"line\">    with open(station_file, &quot;r&quot;) as f:</span><br><span class=\"line\">        for line in f:</span><br><span class=\"line\">            line = line.strip()</span><br><span class=\"line\">            if not line or line.startswith(&quot;#&quot;):</span><br><span class=\"line\">                continue</span><br><span class=\"line\">            parts = line.split(&quot;|&quot;)</span><br><span class=\"line\">            if len(parts) &lt; 4:</span><br><span class=\"line\">                continue</span><br><span class=\"line\">            net, sta = parts[0].strip(), parts[1].strip()</span><br><span class=\"line\">            try:</span><br><span class=\"line\">                lat = float(parts[2]); lon = float(parts[3])</span><br><span class=\"line\">            except Exception:</span><br><span class=\"line\">                continue</span><br><span class=\"line\">            stations.append((net, sta, lat, lon))</span><br><span class=\"line\">    return stations</span><br><span class=\"line\"></span><br><span class=\"line\">def geo_to_xy_km(lats, lons):</span><br><span class=\"line\">    lat0 = np.mean(lats)</span><br><span class=\"line\">    lon0 = np.mean(lons)</span><br><span class=\"line\">    deg2km_lat = 110.574</span><br><span class=\"line\">    deg2km_lon = 111.320 * math.cos(math.radians(lat0))</span><br><span class=\"line\">    xs = (np.array(lons) - lon0) * deg2km_lon</span><br><span class=\"line\">    ys = (np.array(lats) - lat0) * deg2km_lat</span><br><span class=\"line\">    return xs, ys, lat0, lon0</span><br><span class=\"line\"></span><br><span class=\"line\">def window_slices(day_start, win_len, win_step):</span><br><span class=\"line\">    t0 = int(day_start.timestamp)</span><br><span class=\"line\">    t_end = int((day_start + 86400).timestamp)</span><br><span class=\"line\">    slices = []</span><br><span class=\"line\">    t = t0</span><br><span class=\"line\">    while t + win_len &lt;= t_end:</span><br><span class=\"line\">        slices.append((t, t + win_len))</span><br><span class=\"line\">        t += win_step</span><br><span class=\"line\">    return slices</span><br><span class=\"line\"></span><br><span class=\"line\">def next_pow2(n):</span><br><span class=\"line\">    return 1 &lt;&lt; (n - 1).bit_length()</span><br><span class=\"line\"></span><br><span class=\"line\"># ---------------- main pipeline ----------------</span><br><span class=\"line\">stations = read_stations(station_file)</span><br><span class=\"line\">if len(stations) == 0:</span><br><span class=\"line\">    raise SystemExit(&quot;No stations read from station.lst&quot;)</span><br><span class=\"line\"></span><br><span class=\"line\">print(f&quot;[INFO] Read &#123;len(stations)&#125; stations&quot;)</span><br><span class=\"line\"></span><br><span class=\"line\">current = start_date</span><br><span class=\"line\">while current &lt;= end_date:</span><br><span class=\"line\">    day_str = current.strftime(&quot;%Y%m%d&quot;)</span><br><span class=\"line\">    day_path = os.path.join(data_dir, day_str)</span><br><span class=\"line\">    print(f&quot;\\n[INFO] Processing &#123;day_str&#125; ...&quot;)</span><br><span class=\"line\">    if not os.path.isdir(day_path):</span><br><span class=\"line\">        print(f&quot;[WARN] &#123;day_path&#125; not found. skip.&quot;)</span><br><span class=\"line\">        current += timedelta(days=1)</span><br><span class=\"line\">        continue</span><br><span class=\"line\"></span><br><span class=\"line\">    # read one trace per station</span><br><span class=\"line\">    traces = &#123;&#125;</span><br><span class=\"line\">    lat_list = []; lon_list = []; net_sta_list = []</span><br><span class=\"line\">    for net, sta, lat, lon in stations:</span><br><span class=\"line\">        pattern = os.path.join(day_path, f&quot;&#123;net&#125;_&#123;sta&#125;_LHZ.SAC&quot;)</span><br><span class=\"line\">        files = sorted(glob.glob(pattern))</span><br><span class=\"line\">        if not files: continue</span><br><span class=\"line\">        try:</span><br><span class=\"line\">            tr = read(files[0])[0]</span><br><span class=\"line\">            traces[(net,sta)] = tr</span><br><span class=\"line\">            lat_list.append(lat); lon_list.append(lon); net_sta_list.append((net,sta))</span><br><span class=\"line\">        except Exception as e:</span><br><span class=\"line\">            print(f&quot;[WARN] read &#123;files[0]&#125; failed: &#123;e&#125;&quot;)</span><br><span class=\"line\">            continue</span><br><span class=\"line\"></span><br><span class=\"line\">    nsta = len(traces)</span><br><span class=\"line\">    if nsta &lt; min_stations:</span><br><span class=\"line\">        print(f&quot;[WARN] Only &#123;nsta&#125; stations available, skip.&quot;)</span><br><span class=\"line\">        current += timedelta(days=1)</span><br><span class=\"line\">        continue</span><br><span class=\"line\"></span><br><span class=\"line\">    # sampling rate</span><br><span class=\"line\">    sr_target = min([tr.stats.sampling_rate for tr in traces.values()])</span><br><span class=\"line\">    xs, ys, lat0, lon0 = geo_to_xy_km(lat_list, lon_list)</span><br><span class=\"line\"></span><br><span class=\"line\">    # reorder traces</span><br><span class=\"line\">    traces_ordered = [traces[k] for k in net_sta_list]</span><br><span class=\"line\"></span><br><span class=\"line\">    # window slices</span><br><span class=\"line\">    day_start = UTCDateTime(current.strftime(&quot;%Y-%m-%dT00:00:00&quot;))</span><br><span class=\"line\">    slices = window_slices(day_start, win_len, win_step)</span><br><span class=\"line\">    print(f&quot;[INFO] &#123;len(slices)&#125; windows&quot;)</span><br><span class=\"line\"></span><br><span class=\"line\">    # accumulate daily power grid</span><br><span class=\"line\">    daily_power = np.zeros((len(az_grid), len(s_grid)))</span><br><span class=\"line\">    nwin_used = 0</span><br><span class=\"line\"></span><br><span class=\"line\">    for (t0, t1) in slices:</span><br><span class=\"line\">        specs = []</span><br><span class=\"line\">        valid = True</span><br><span class=\"line\">        nfft = None</span><br><span class=\"line\">        for tr in traces_ordered:</span><br><span class=\"line\">            try:</span><br><span class=\"line\">                seg = tr.slice(UTCDateTime(t0), UTCDateTime(t1), nearest_sample=False)</span><br><span class=\"line\">            except:</span><br><span class=\"line\">                valid = False; break</span><br><span class=\"line\">            expected_npts = int(round((t1 - t0) * sr_target))</span><br><span class=\"line\">            data = seg.data.astype(np.float64)</span><br><span class=\"line\">            if len(data) &lt; expected_npts:</span><br><span class=\"line\">                if len(data) == 0: valid = False; break</span><br><span class=\"line\">                data = np.pad(data, (0, expected_npts-len(data)))</span><br><span class=\"line\">            elif len(data) &gt; expected_npts:</span><br><span class=\"line\">                data = data[:expected_npts]</span><br><span class=\"line\">            data -= np.mean(data)</span><br><span class=\"line\">            data *= np.hanning(len(data))</span><br><span class=\"line\">            if nfft is None:</span><br><span class=\"line\">                nfft = next_pow2(len(data))</span><br><span class=\"line\">            spec = np.fft.rfft(data, n=nfft)</span><br><span class=\"line\">            freqs = np.fft.rfftfreq(nfft, d=1.0/sr_target)</span><br><span class=\"line\">            specs.append(spec)</span><br><span class=\"line\">        if not valid or nfft is None: continue</span><br><span class=\"line\"></span><br><span class=\"line\">        specs = np.array(specs)</span><br><span class=\"line\">        freq_mask = (freqs&gt;=fmin)&amp;(freqs&lt;=fmax)</span><br><span class=\"line\">        if not np.any(freq_mask): continue</span><br><span class=\"line\">        freqs_sel = freqs[freq_mask]</span><br><span class=\"line\">        specs_sel = specs[:, freq_mask]</span><br><span class=\"line\"></span><br><span class=\"line\">        xs_arr = np.array(xs); ys_arr = np.array(ys)</span><br><span class=\"line\">        spec_power = np.sum(np.abs(specs_sel)**2)</span><br><span class=\"line\">        if spec_power&lt;=0: continue</span><br><span class=\"line\"></span><br><span class=\"line\">        two_pi = 2*np.pi</span><br><span class=\"line\">        power_grid = np.zeros((len(az_grid), len(s_grid)))</span><br><span class=\"line\">        for ia, az_deg in enumerate(az_grid):</span><br><span class=\"line\">            az_rad = math.radians(az_deg)</span><br><span class=\"line\">            proj = xs_arr*np.sin(az_rad) + ys_arr*np.cos(az_rad)</span><br><span class=\"line\">            for is_idx, s in enumerate(s_grid):</span><br><span class=\"line\">                delays = proj*s</span><br><span class=\"line\">                steering = np.exp(-1j*two_pi*np.outer(delays,freqs_sel))</span><br><span class=\"line\">                beam_spectrum = np.sum(steering*specs_sel, axis=0)</span><br><span class=\"line\">                power = np.sum(np.abs(beam_spectrum)**2)</span><br><span class=\"line\">                power_grid[ia,is_idx] = power/spec_power</span><br><span class=\"line\">        daily_power += power_grid</span><br><span class=\"line\">        nwin_used += 1</span><br><span class=\"line\"></span><br><span class=\"line\">    if nwin_used==0:</span><br><span class=\"line\">        print(f&quot;[WARN] no valid windows &#123;day_str&#125;&quot;)</span><br><span class=\"line\">        current += timedelta(days=1)</span><br><span class=\"line\">        continue</span><br><span class=\"line\"></span><br><span class=\"line\">    daily_power /= nwin_used</span><br><span class=\"line\">    print(f&quot;[INFO] averaged over &#123;nwin_used&#125; windows&quot;)</span><br><span class=\"line\"></span><br><span class=\"line\">    # ---------------- plot daily radar ----------------</span><br><span class=\"line\">    theta, r = np.meshgrid(np.deg2rad(az_grid), speed_grid)</span><br><span class=\"line\">    Z = daily_power.T  # shape (len(s_grid), len(az_grid))</span><br><span class=\"line\"></span><br><span class=\"line\">    # locate max power</span><br><span class=\"line\">    max_idx = np.unravel_index(np.argmax(Z), Z.shape)</span><br><span class=\"line\">    max_az_deg = az_grid[max_idx[1]]</span><br><span class=\"line\">    max_speed = r[max_idx]  # km/s</span><br><span class=\"line\"></span><br><span class=\"line\">    fig = plt.figure(figsize=(7,7))</span><br><span class=\"line\">    ax = fig.add_subplot(111, polar=True)</span><br><span class=\"line\">    pcm = ax.pcolormesh(theta, r, Z, shading=&quot;auto&quot;, cmap=&quot;viridis&quot;)</span><br><span class=\"line\">    ax.set_theta_zero_location(&quot;N&quot;)</span><br><span class=\"line\">    ax.set_theta_direction(-1)</span><br><span class=\"line\">    ax.set_rmax(vmax)</span><br><span class=\"line\">    #fig.colorbar(pcm, ax=ax, orientation=&quot;vertical&quot;, label=&quot;Normalized Power&quot;)</span><br><span class=\"line\">    ax.set_title(f&quot;FK Radar &#123;day_str&#125;\\nBand &#123;fmin&#125;-&#123;fmax&#125; Hz&quot;, fontsize=12)</span><br><span class=\"line\"></span><br><span class=\"line\">    # mark max point</span><br><span class=\"line\">    ax.plot(np.deg2rad(max_az_deg), max_speed, &#x27;ro&#x27;, markersize=8, label=f&quot;Max Power\\nAz=&#123;max_az_deg:.1f&#125;°, v=&#123;max_speed:.2f&#125; km/s&quot;)</span><br><span class=\"line\">    ax.legend(loc=&#x27;upper right&#x27;, bbox_to_anchor=(1.3,1.1), fontsize=8)</span><br><span class=\"line\"></span><br><span class=\"line\">    out_png = os.path.join(output_dir, f&quot;fk_radar_&#123;day_str&#125;.png&quot;)</span><br><span class=\"line\">    plt.savefig(out_png, dpi=200, bbox_inches=&quot;tight&quot;)</span><br><span class=\"line\">    plt.close()</span><br><span class=\"line\">    print(f&quot;[INFO] saved &#123;out_png&#125;&quot;)</span><br><span class=\"line\">    current += timedelta(days=1)</span><br></pre></td></tr></table></figure>"},{"title":"如何将图片转化成视频","abbrlink":"c81d7fc8","date":"2025-08-25T13:48:42.000Z","_content":"&emsp;&emsp;如果我有一堆图片，如何利用他们生成视频呢？\n<!--less-->\n&emsp;&emsp;我的图一般都是在linux下生成，大量的图自然用命令来生成是最好的。这里用到程序ffmpeg，没有的话需要自己先安装了啊。\n接下来用命令:\n```\nffmpeg -pattern_type glob -framerate 24 -i \"2*.png\" -c:v libx264 -pix_fmt yuv420p output.mp4\n```\n* -pattern\\_type glob: 作用是启用通配符模式匹配输入文件名。\n* -framerate 24: 作用是设置输入文件的帧率为24帧/秒，那么如果你有100张图片，你生成的视频长度则为100/25=4.17秒。\n* -i \\\"2*.png\\\":表示指定输入文件为所有以2开头的png文件。\n* -c:v libx264: 视频编码器为H.264\n* -pix_fmt yuv420p: 设置像素格式为YUV420色彩空间。\n* output.mp4: 输出文件。\nffmpeg的参数多得很，用到的时候可以去查。这句命令应该没啥问题，有问题就去问ai。另外，生成了mp4以后为了方便在ppt中演示播放可以将其转化为gif。\n```\nffmpeg -i output.mp4 output.gif\n```\n然后就大功告成了啊。\n","source":"_posts/2025-08-25-png-to-mp4.md","raw":"---\ntitle: 如何将图片转化成视频\ntags:\n  - Linux\ncategories:\n  - Linux\nabbrlink: c81d7fc8\ndate: 2025-08-25 21:48:42\n---\n&emsp;&emsp;如果我有一堆图片，如何利用他们生成视频呢？\n<!--less-->\n&emsp;&emsp;我的图一般都是在linux下生成，大量的图自然用命令来生成是最好的。这里用到程序ffmpeg，没有的话需要自己先安装了啊。\n接下来用命令:\n```\nffmpeg -pattern_type glob -framerate 24 -i \"2*.png\" -c:v libx264 -pix_fmt yuv420p output.mp4\n```\n* -pattern\\_type glob: 作用是启用通配符模式匹配输入文件名。\n* -framerate 24: 作用是设置输入文件的帧率为24帧/秒，那么如果你有100张图片，你生成的视频长度则为100/25=4.17秒。\n* -i \\\"2*.png\\\":表示指定输入文件为所有以2开头的png文件。\n* -c:v libx264: 视频编码器为H.264\n* -pix_fmt yuv420p: 设置像素格式为YUV420色彩空间。\n* output.mp4: 输出文件。\nffmpeg的参数多得很，用到的时候可以去查。这句命令应该没啥问题，有问题就去问ai。另外，生成了mp4以后为了方便在ppt中演示播放可以将其转化为gif。\n```\nffmpeg -i output.mp4 output.gif\n```\n然后就大功告成了啊。\n","slug":"png-to-mp4","published":1,"updated":"2025-08-25T14:00:48.919Z","comments":1,"layout":"post","photos":[],"_id":"cmh498iqn00e5wvoueydygus8","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>&emsp;&emsp;我的图一般都是在linux下生成，大量的图自然用命令来生成是最好的。这里用到程序ffmpeg，没有的话需要自己先安装了啊。<br>接下来用命令:</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ffmpeg -pattern_type glob -framerate 24 -i &quot;2*.png&quot; -c:v libx264 -pix_fmt yuv420p output.mp4</span><br></pre></td></tr></table></figure>\n<ul>\n<li>-pattern_type glob: 作用是启用通配符模式匹配输入文件名。</li>\n<li>-framerate 24: 作用是设置输入文件的帧率为24帧&#x2F;秒，那么如果你有100张图片，你生成的视频长度则为100&#x2F;25&#x3D;4.17秒。</li>\n<li>-i &quot;2*.png&quot;:表示指定输入文件为所有以2开头的png文件。</li>\n<li>-c:v libx264: 视频编码器为H.264</li>\n<li>-pix_fmt yuv420p: 设置像素格式为YUV420色彩空间。</li>\n<li>output.mp4: 输出文件。<br>ffmpeg的参数多得很，用到的时候可以去查。这句命令应该没啥问题，有问题就去问ai。另外，生成了mp4以后为了方便在ppt中演示播放可以将其转化为gif。<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ffmpeg -i output.mp4 output.gif</span><br></pre></td></tr></table></figure>\n然后就大功告成了啊。</li>\n</ul>","related_posts":[],"length":557,"excerpt":"<p>&emsp;&emsp;如果我有一堆图片，如何利用他们生成视频呢？</p>","more":"<p>&emsp;&emsp;我的图一般都是在linux下生成，大量的图自然用命令来生成是最好的。这里用到程序ffmpeg，没有的话需要自己先安装了啊。<br>接下来用命令:</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ffmpeg -pattern_type glob -framerate 24 -i &quot;2*.png&quot; -c:v libx264 -pix_fmt yuv420p output.mp4</span><br></pre></td></tr></table></figure>\n<ul>\n<li>-pattern_type glob: 作用是启用通配符模式匹配输入文件名。</li>\n<li>-framerate 24: 作用是设置输入文件的帧率为24帧&#x2F;秒，那么如果你有100张图片，你生成的视频长度则为100&#x2F;25&#x3D;4.17秒。</li>\n<li>-i &quot;2*.png&quot;:表示指定输入文件为所有以2开头的png文件。</li>\n<li>-c:v libx264: 视频编码器为H.264</li>\n<li>-pix_fmt yuv420p: 设置像素格式为YUV420色彩空间。</li>\n<li>output.mp4: 输出文件。<br>ffmpeg的参数多得很，用到的时候可以去查。这句命令应该没啥问题，有问题就去问ai。另外，生成了mp4以后为了方便在ppt中演示播放可以将其转化为gif。<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ffmpeg -i output.mp4 output.gif</span><br></pre></td></tr></table></figure>\n然后就大功告成了啊。</li>\n</ul>"},{"title":"Fedora中安装FreshRSS","abbrlink":"751a68a","date":"2025-10-06T14:31:32.000Z","_content":"&emsp;&emsp;Fedora中Apache环境下如何安装FreshRSS\n<!--less-->\n&emsp;&emsp;之前总是蹭一个小伙子自己建的[RSS](https://rss.othing.xyz/)，白嫖，怕哪天人家不搞了，还是自己建一个吧。详细脚本安装请查看其[github](https://github.com/FreshRSS/FreshRSS/blob/edge/cli/README.md)。废话不多说，具体如下：\n# 一、安装依赖\nFreshRSS是基于PHP的自建RSS聚合器，需要Apache+PHP环境：\n```\nsudo dnf install httpd php php-cli php-common php-json php-gd php-mbstring php-intl php-xml php-pdo php-mysqlnd unzip git -y\n```\n\n启用并启动 Apache：\n```\nsudo systemctl enable --now httpd\n```\n\n确认端口 80 正在监听：\n```\nsudo ss -tulnp | grep :80\n```\n# 二、下载并安装 FreshRSS\n\n推荐安装到 /usr/share/FreshRSS：\n```\ncd /usr/share\nsudo git clone https://github.com/FreshRSS/FreshRSS.git\ncd FreshRSS\nsudo git checkout stable   # 或 edge 分支（开发版）\n```\n\n设置权限（Fedora 的 Apache 用户是 apache）：\n```\nsudo chown -R apache:apache /usr/share/FreshRSS\nsudo chmod -R 755 /usr/share/FreshRSS\n```\n# 三、配置 Apache\n\n新建配置文件：\n```\nsudo vim /etc/httpd/conf.d/freshrss.conf\n```\n写入以下内容：\n```\nAlias /FreshRSS /usr/share/FreshRSS\n\n<Directory /usr/share/FreshRSS>\n    AllowOverride All\n    Options Indexes FollowSymLinks\n    Require all granted\n</Directory>\n```\n保存退出后，重启 Apache：\n```\nsudo systemctl restart httpd\n```\n# 四、处理 SELinux 限制（Fedora 特有）\nFedora 默认启用了 SELinux，会阻止 Apache 访问 /usr/share 下的应用。\n执行以下命令放行：\n```\nsudo chcon -R -t httpd_sys_rw_content_t /usr/share/FreshRSS\nsudo setsebool -P httpd_can_network_connect on\n```\n（若仍被拒绝，可临时关闭测试：sudo setenforce 0）\n\n# 五、访问 Web 界面\n\n打开浏览器访问：\n```\nhttp://localhost/FreshRSS\n```\n你应看到 FreshRSS 的安装页面。\n根据提示创建管理员账号、数据库配置（SQLite/MySQL 都可）。\n\n如果提示 “You don’t have permission to access this resource”，请确认：\n\nApache 配置文件中包含 Require all granted\n\nSELinux 权限已放行（执行了 chcon）\n\n# 六、命令行工具（可选）\n\nFreshRSS 提供强大的 CLI 管理工具，位于 cli/ 目录。\n例如列出用户：\n```\ncd /usr/share/FreshRSS\nsudo -u apache php cli/list-users.php\n```\nFedora 用的是 apache 用户，而不是 Debian/Ubuntu 的 www-data。\n\n# 七、日志与排错\n\n查看 Apache 错误日志：\n```\nsudo tail -n 30 /var/log/httpd/error_log\n```\n\n查看 SELinux 拒绝记录：\n```\nsudo ausearch -m AVC,USER_AVC -ts recent\n```\n# 八、（可选）设置自动更新任务\n\n添加一个定时任务更新 RSS 源：\n```\nsudo -u apache php /usr/share/FreshRSS/app/actualize_script.php > /dev/null 2>&1\n```\n在 /etc/cron.d/freshrss 中添加：\n```\n*/20 * * * * apache php /usr/share/FreshRSS/app/actualize_script.php > /dev/null 2>&1\n```\n表示每20分钟更新一次。\n","source":"_posts/2025-10-06-fedora-install-freshress.md","raw":"---\ntitle: Fedora中安装FreshRSS\ntags:\n  - Linux\ncategories:\n  - Linux\nabbrlink: 751a68a\ndate: 2025-10-06 22:31:32\n---\n&emsp;&emsp;Fedora中Apache环境下如何安装FreshRSS\n<!--less-->\n&emsp;&emsp;之前总是蹭一个小伙子自己建的[RSS](https://rss.othing.xyz/)，白嫖，怕哪天人家不搞了，还是自己建一个吧。详细脚本安装请查看其[github](https://github.com/FreshRSS/FreshRSS/blob/edge/cli/README.md)。废话不多说，具体如下：\n# 一、安装依赖\nFreshRSS是基于PHP的自建RSS聚合器，需要Apache+PHP环境：\n```\nsudo dnf install httpd php php-cli php-common php-json php-gd php-mbstring php-intl php-xml php-pdo php-mysqlnd unzip git -y\n```\n\n启用并启动 Apache：\n```\nsudo systemctl enable --now httpd\n```\n\n确认端口 80 正在监听：\n```\nsudo ss -tulnp | grep :80\n```\n# 二、下载并安装 FreshRSS\n\n推荐安装到 /usr/share/FreshRSS：\n```\ncd /usr/share\nsudo git clone https://github.com/FreshRSS/FreshRSS.git\ncd FreshRSS\nsudo git checkout stable   # 或 edge 分支（开发版）\n```\n\n设置权限（Fedora 的 Apache 用户是 apache）：\n```\nsudo chown -R apache:apache /usr/share/FreshRSS\nsudo chmod -R 755 /usr/share/FreshRSS\n```\n# 三、配置 Apache\n\n新建配置文件：\n```\nsudo vim /etc/httpd/conf.d/freshrss.conf\n```\n写入以下内容：\n```\nAlias /FreshRSS /usr/share/FreshRSS\n\n<Directory /usr/share/FreshRSS>\n    AllowOverride All\n    Options Indexes FollowSymLinks\n    Require all granted\n</Directory>\n```\n保存退出后，重启 Apache：\n```\nsudo systemctl restart httpd\n```\n# 四、处理 SELinux 限制（Fedora 特有）\nFedora 默认启用了 SELinux，会阻止 Apache 访问 /usr/share 下的应用。\n执行以下命令放行：\n```\nsudo chcon -R -t httpd_sys_rw_content_t /usr/share/FreshRSS\nsudo setsebool -P httpd_can_network_connect on\n```\n（若仍被拒绝，可临时关闭测试：sudo setenforce 0）\n\n# 五、访问 Web 界面\n\n打开浏览器访问：\n```\nhttp://localhost/FreshRSS\n```\n你应看到 FreshRSS 的安装页面。\n根据提示创建管理员账号、数据库配置（SQLite/MySQL 都可）。\n\n如果提示 “You don’t have permission to access this resource”，请确认：\n\nApache 配置文件中包含 Require all granted\n\nSELinux 权限已放行（执行了 chcon）\n\n# 六、命令行工具（可选）\n\nFreshRSS 提供强大的 CLI 管理工具，位于 cli/ 目录。\n例如列出用户：\n```\ncd /usr/share/FreshRSS\nsudo -u apache php cli/list-users.php\n```\nFedora 用的是 apache 用户，而不是 Debian/Ubuntu 的 www-data。\n\n# 七、日志与排错\n\n查看 Apache 错误日志：\n```\nsudo tail -n 30 /var/log/httpd/error_log\n```\n\n查看 SELinux 拒绝记录：\n```\nsudo ausearch -m AVC,USER_AVC -ts recent\n```\n# 八、（可选）设置自动更新任务\n\n添加一个定时任务更新 RSS 源：\n```\nsudo -u apache php /usr/share/FreshRSS/app/actualize_script.php > /dev/null 2>&1\n```\n在 /etc/cron.d/freshrss 中添加：\n```\n*/20 * * * * apache php /usr/share/FreshRSS/app/actualize_script.php > /dev/null 2>&1\n```\n表示每20分钟更新一次。\n","slug":"fedora-install-freshress","published":1,"updated":"2025-10-07T00:22:27.125Z","comments":1,"layout":"post","photos":[],"_id":"cmh498iqo00e8wvou8fvg7htv","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>&emsp;&emsp;之前总是蹭一个小伙子自己建的<a href=\"https://rss.othing.xyz/\">RSS</a>，白嫖，怕哪天人家不搞了，还是自己建一个吧。详细脚本安装请查看其<a href=\"https://github.com/FreshRSS/FreshRSS/blob/edge/cli/README.md\">github</a>。废话不多说，具体如下：</p>\n<h1 id=\"一、安装依赖\"><a href=\"#一、安装依赖\" class=\"headerlink\" title=\"一、安装依赖\"></a>一、安装依赖</h1><p>FreshRSS是基于PHP的自建RSS聚合器，需要Apache+PHP环境：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo dnf install httpd php php-cli php-common php-json php-gd php-mbstring php-intl php-xml php-pdo php-mysqlnd unzip git -y</span><br></pre></td></tr></table></figure>\n\n<p>启用并启动 Apache：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo systemctl enable --now httpd</span><br></pre></td></tr></table></figure>\n\n<p>确认端口 80 正在监听：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo ss -tulnp | grep :80</span><br></pre></td></tr></table></figure>\n<h1 id=\"二、下载并安装-FreshRSS\"><a href=\"#二、下载并安装-FreshRSS\" class=\"headerlink\" title=\"二、下载并安装 FreshRSS\"></a>二、下载并安装 FreshRSS</h1><p>推荐安装到 &#x2F;usr&#x2F;share&#x2F;FreshRSS：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cd /usr/share</span><br><span class=\"line\">sudo git clone https://github.com/FreshRSS/FreshRSS.git</span><br><span class=\"line\">cd FreshRSS</span><br><span class=\"line\">sudo git checkout stable   # 或 edge 分支（开发版）</span><br></pre></td></tr></table></figure>\n\n<p>设置权限（Fedora 的 Apache 用户是 apache）：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo chown -R apache:apache /usr/share/FreshRSS</span><br><span class=\"line\">sudo chmod -R 755 /usr/share/FreshRSS</span><br></pre></td></tr></table></figure>\n<h1 id=\"三、配置-Apache\"><a href=\"#三、配置-Apache\" class=\"headerlink\" title=\"三、配置 Apache\"></a>三、配置 Apache</h1><p>新建配置文件：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo vim /etc/httpd/conf.d/freshrss.conf</span><br></pre></td></tr></table></figure>\n<p>写入以下内容：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Alias /FreshRSS /usr/share/FreshRSS</span><br><span class=\"line\"></span><br><span class=\"line\">&lt;Directory /usr/share/FreshRSS&gt;</span><br><span class=\"line\">    AllowOverride All</span><br><span class=\"line\">    Options Indexes FollowSymLinks</span><br><span class=\"line\">    Require all granted</span><br><span class=\"line\">&lt;/Directory&gt;</span><br></pre></td></tr></table></figure>\n<p>保存退出后，重启 Apache：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo systemctl restart httpd</span><br></pre></td></tr></table></figure>\n<h1 id=\"四、处理-SELinux-限制（Fedora-特有）\"><a href=\"#四、处理-SELinux-限制（Fedora-特有）\" class=\"headerlink\" title=\"四、处理 SELinux 限制（Fedora 特有）\"></a>四、处理 SELinux 限制（Fedora 特有）</h1><p>Fedora 默认启用了 SELinux，会阻止 Apache 访问 &#x2F;usr&#x2F;share 下的应用。<br>执行以下命令放行：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo chcon -R -t httpd_sys_rw_content_t /usr/share/FreshRSS</span><br><span class=\"line\">sudo setsebool -P httpd_can_network_connect on</span><br></pre></td></tr></table></figure>\n<p>（若仍被拒绝，可临时关闭测试：sudo setenforce 0）</p>\n<h1 id=\"五、访问-Web-界面\"><a href=\"#五、访问-Web-界面\" class=\"headerlink\" title=\"五、访问 Web 界面\"></a>五、访问 Web 界面</h1><p>打开浏览器访问：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">http://localhost/FreshRSS</span><br></pre></td></tr></table></figure>\n<p>你应看到 FreshRSS 的安装页面。<br>根据提示创建管理员账号、数据库配置（SQLite&#x2F;MySQL 都可）。</p>\n<p>如果提示 “You don’t have permission to access this resource”，请确认：</p>\n<p>Apache 配置文件中包含 Require all granted</p>\n<p>SELinux 权限已放行（执行了 chcon）</p>\n<h1 id=\"六、命令行工具（可选）\"><a href=\"#六、命令行工具（可选）\" class=\"headerlink\" title=\"六、命令行工具（可选）\"></a>六、命令行工具（可选）</h1><p>FreshRSS 提供强大的 CLI 管理工具，位于 cli&#x2F; 目录。<br>例如列出用户：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cd /usr/share/FreshRSS</span><br><span class=\"line\">sudo -u apache php cli/list-users.php</span><br></pre></td></tr></table></figure>\n<p>Fedora 用的是 apache 用户，而不是 Debian&#x2F;Ubuntu 的 www-data。</p>\n<h1 id=\"七、日志与排错\"><a href=\"#七、日志与排错\" class=\"headerlink\" title=\"七、日志与排错\"></a>七、日志与排错</h1><p>查看 Apache 错误日志：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo tail -n 30 /var/log/httpd/error_log</span><br></pre></td></tr></table></figure>\n\n<p>查看 SELinux 拒绝记录：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo ausearch -m AVC,USER_AVC -ts recent</span><br></pre></td></tr></table></figure>\n<h1 id=\"八、（可选）设置自动更新任务\"><a href=\"#八、（可选）设置自动更新任务\" class=\"headerlink\" title=\"八、（可选）设置自动更新任务\"></a>八、（可选）设置自动更新任务</h1><p>添加一个定时任务更新 RSS 源：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo -u apache php /usr/share/FreshRSS/app/actualize_script.php &gt; /dev/null 2&gt;&amp;1</span><br></pre></td></tr></table></figure>\n<p>在 &#x2F;etc&#x2F;cron.d&#x2F;freshrss 中添加：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">*/20 * * * * apache php /usr/share/FreshRSS/app/actualize_script.php &gt; /dev/null 2&gt;&amp;1</span><br></pre></td></tr></table></figure>\n<p>表示每20分钟更新一次。</p>","related_posts":["to-desk.html","how-to-configure-chinese-for-gmt.html","install-and-backup-mediawiki.html","science-blogs.html","after-fedora32.html"],"length":1817,"excerpt":"<p>&emsp;&emsp;Fedora中Apache环境下如何安装FreshRSS</p>","more":"<p>&emsp;&emsp;之前总是蹭一个小伙子自己建的<a href=\"https://rss.othing.xyz/\">RSS</a>，白嫖，怕哪天人家不搞了，还是自己建一个吧。详细脚本安装请查看其<a href=\"https://github.com/FreshRSS/FreshRSS/blob/edge/cli/README.md\">github</a>。废话不多说，具体如下：</p>\n<h1 id=\"一、安装依赖\"><a href=\"#一、安装依赖\" class=\"headerlink\" title=\"一、安装依赖\"></a>一、安装依赖</h1><p>FreshRSS是基于PHP的自建RSS聚合器，需要Apache+PHP环境：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo dnf install httpd php php-cli php-common php-json php-gd php-mbstring php-intl php-xml php-pdo php-mysqlnd unzip git -y</span><br></pre></td></tr></table></figure>\n\n<p>启用并启动 Apache：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo systemctl enable --now httpd</span><br></pre></td></tr></table></figure>\n\n<p>确认端口 80 正在监听：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo ss -tulnp | grep :80</span><br></pre></td></tr></table></figure>\n<h1 id=\"二、下载并安装-FreshRSS\"><a href=\"#二、下载并安装-FreshRSS\" class=\"headerlink\" title=\"二、下载并安装 FreshRSS\"></a>二、下载并安装 FreshRSS</h1><p>推荐安装到 &#x2F;usr&#x2F;share&#x2F;FreshRSS：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cd /usr/share</span><br><span class=\"line\">sudo git clone https://github.com/FreshRSS/FreshRSS.git</span><br><span class=\"line\">cd FreshRSS</span><br><span class=\"line\">sudo git checkout stable   # 或 edge 分支（开发版）</span><br></pre></td></tr></table></figure>\n\n<p>设置权限（Fedora 的 Apache 用户是 apache）：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo chown -R apache:apache /usr/share/FreshRSS</span><br><span class=\"line\">sudo chmod -R 755 /usr/share/FreshRSS</span><br></pre></td></tr></table></figure>\n<h1 id=\"三、配置-Apache\"><a href=\"#三、配置-Apache\" class=\"headerlink\" title=\"三、配置 Apache\"></a>三、配置 Apache</h1><p>新建配置文件：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo vim /etc/httpd/conf.d/freshrss.conf</span><br></pre></td></tr></table></figure>\n<p>写入以下内容：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Alias /FreshRSS /usr/share/FreshRSS</span><br><span class=\"line\"></span><br><span class=\"line\">&lt;Directory /usr/share/FreshRSS&gt;</span><br><span class=\"line\">    AllowOverride All</span><br><span class=\"line\">    Options Indexes FollowSymLinks</span><br><span class=\"line\">    Require all granted</span><br><span class=\"line\">&lt;/Directory&gt;</span><br></pre></td></tr></table></figure>\n<p>保存退出后，重启 Apache：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo systemctl restart httpd</span><br></pre></td></tr></table></figure>\n<h1 id=\"四、处理-SELinux-限制（Fedora-特有）\"><a href=\"#四、处理-SELinux-限制（Fedora-特有）\" class=\"headerlink\" title=\"四、处理 SELinux 限制（Fedora 特有）\"></a>四、处理 SELinux 限制（Fedora 特有）</h1><p>Fedora 默认启用了 SELinux，会阻止 Apache 访问 &#x2F;usr&#x2F;share 下的应用。<br>执行以下命令放行：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo chcon -R -t httpd_sys_rw_content_t /usr/share/FreshRSS</span><br><span class=\"line\">sudo setsebool -P httpd_can_network_connect on</span><br></pre></td></tr></table></figure>\n<p>（若仍被拒绝，可临时关闭测试：sudo setenforce 0）</p>\n<h1 id=\"五、访问-Web-界面\"><a href=\"#五、访问-Web-界面\" class=\"headerlink\" title=\"五、访问 Web 界面\"></a>五、访问 Web 界面</h1><p>打开浏览器访问：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">http://localhost/FreshRSS</span><br></pre></td></tr></table></figure>\n<p>你应看到 FreshRSS 的安装页面。<br>根据提示创建管理员账号、数据库配置（SQLite&#x2F;MySQL 都可）。</p>\n<p>如果提示 “You don’t have permission to access this resource”，请确认：</p>\n<p>Apache 配置文件中包含 Require all granted</p>\n<p>SELinux 权限已放行（执行了 chcon）</p>\n<h1 id=\"六、命令行工具（可选）\"><a href=\"#六、命令行工具（可选）\" class=\"headerlink\" title=\"六、命令行工具（可选）\"></a>六、命令行工具（可选）</h1><p>FreshRSS 提供强大的 CLI 管理工具，位于 cli&#x2F; 目录。<br>例如列出用户：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cd /usr/share/FreshRSS</span><br><span class=\"line\">sudo -u apache php cli/list-users.php</span><br></pre></td></tr></table></figure>\n<p>Fedora 用的是 apache 用户，而不是 Debian&#x2F;Ubuntu 的 www-data。</p>\n<h1 id=\"七、日志与排错\"><a href=\"#七、日志与排错\" class=\"headerlink\" title=\"七、日志与排错\"></a>七、日志与排错</h1><p>查看 Apache 错误日志：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo tail -n 30 /var/log/httpd/error_log</span><br></pre></td></tr></table></figure>\n\n<p>查看 SELinux 拒绝记录：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo ausearch -m AVC,USER_AVC -ts recent</span><br></pre></td></tr></table></figure>\n<h1 id=\"八、（可选）设置自动更新任务\"><a href=\"#八、（可选）设置自动更新任务\" class=\"headerlink\" title=\"八、（可选）设置自动更新任务\"></a>八、（可选）设置自动更新任务</h1><p>添加一个定时任务更新 RSS 源：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo -u apache php /usr/share/FreshRSS/app/actualize_script.php &gt; /dev/null 2&gt;&amp;1</span><br></pre></td></tr></table></figure>\n<p>在 &#x2F;etc&#x2F;cron.d&#x2F;freshrss 中添加：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">*/20 * * * * apache php /usr/share/FreshRSS/app/actualize_script.php &gt; /dev/null 2&gt;&amp;1</span><br></pre></td></tr></table></figure>\n<p>表示每20分钟更新一次。</p>"},{"title":"文献阅读(28)","abbrlink":"82c5b0d","date":"2025-10-10T05:22:19.000Z","_content":"&emsp;&emsp;[SGLOBE-Q2D: A Global 2-D Model of Fundamental and Higher Mode Rayleigh Wave Attenuation From a Large Amplitude Data Set](https://agupubs.onlinelibrary.wiley.com/doi/10.1029/2024JB030139?af=R)\n<!--less-->\n### 摘要\n作者提出了SGLOBE‐Q2D，一个具有不确定性的全球上地幔频率依赖瑞利波衰减模型。使用了约 1000 万个基阶与高阶（最高至第 4 阶谐波）瑞利波振幅测量，周期范围为T≈38–275 秒。振幅数据已校正震源效应与弹性效应，包括（a）移除靠近震源节面的路径；（b）校正台站下方局部结构效应；（c）利用线性射线理论近似考虑聚焦/散焦效应。通过大量合成反演测试，支持将基阶模型展开至球谐阶数20，高于近期全球衰减研究的阶数。观测到太平洋大部分区域下方存在广泛的高衰减异常，可能与热点、弧后扩张及地幔柱有关；同时，非洲的刚果与卡拉哈里克拉通、东欧与西伯利亚克拉通之间表现出清晰的低衰减异常分隔。将SGLOBE‐Q2D与相应相速度图对比，表明上地幔温度对衰减异常有显著控制作用，但水、部分熔融、氧化还原状态及晶粒尺寸等因素也可能起作用。\n### 相关研究的重要性  \n地震衰减直接反映地球介质的非弹性性质，对上地幔温度变化极为敏感，可独立验证速度异常是否源于热效应；同时对部分熔融、水含量、晶粒尺寸、氧化还原状态等也更灵敏，能区分“热”与“化学”异常。全球高分辨率衰减图可揭示地幔柱、弧后扩张、俯冲带等深部动力学过程，为板块驱动力研究提供关键约束；与速度模型联合解释，可分解弹性与非弹性贡献，减少速度-温度转换的多解性。此外，克拉通岩石圈厚度、热异常边界与金属矿床、油气储层及地震活动性存在耦合，衰减结构对资源评价和灾害评估具有实际意义。\n\n### 前人研究综述与不足  \nDalton & Ekström (2006) 仅用基阶瑞利波振幅和线性射线理论，球谐阶数止步12，空间分辨率约1300 km，未引入高阶模，也未给出不确定度。Ma et al. (2016) 把阶数提到16并考虑有限频率聚焦，但仍限于基阶，且未提供逐点误差。Adenis et al. (2017) 采用波形反演与三维谱元正演，阶数同为16，却使用非PREM初始模型，长周期偏差较大，计算成本极高，高阶模结果未公开。Gung & Romanowicz (2004) 虽在波形中引入第1阶，但数据量小、无聚焦校正、南半球覆盖差。区域海底阵列如NoMelt只给出单点一维曲线，无法全球对比，也缺少高阶模深度约束。总体来看，早期模型阶数低、高阶模缺失、误差未量化、克拉通内部结构模糊，成为本文突破的出发点。\n\n### 本文数据与方法  \n研究收集955万条垂直分量小弧瑞利波振幅比，来自12232次4–9级、深12–700 km的地震，由全球1017个台站记录，周期37–275 s，涵盖基阶至第4阶谐波；路径弧长限定30°–110°以避免近源效应并减少模态混叠。首先剔除靠近震源节面的路径（占1.6%），再用自洽相速度图（阶数20）按线性射线理论计算聚焦/散焦校正，最后基于SGLOBE-rani地幔模型与CRUST2.0地壳模型计算台站下方局部放大效应。反演采用阻尼加权最小二乘，参数化为ln(Q)，按5°聚类路径数赋权；通过L-曲线选取正则强度，并用模型协方差矩阵输出格点标准差。为确定可分辨阶数，作者将阶数40的合成衰减图加噪反演，以相关系数≥0.8为标准，最终确定基阶可扩至阶数20，第1–4阶分别至15、12、10。\n\n### 主要结果  \n周期40–70 s的基阶图显示海洋普遍高衰减，快速扩张的东太平洋海隆最强，慢速扩张的大西洋与印度洋稍弱；青藏高原呈现显著高衰减；所有主要克拉通均表现为清晰低衰减异常。100–150 s图上，太平洋远离海隆区域仍保持高衰减，暗示多股或宽大地幔柱；俯冲带弧后区亦高衰减，部分海隆下方出现线性低衰减带，可能与岩石圈冷却有关。第1阶图在西太平洋俯冲带和欧亚下方与基阶特征相似；第2–4阶因深度振荡敏感核与数据稀疏，空间相关性下降，误差可达±15。基阶不确定度通常≤±6，高阶模±15；东太平洋与南极射线覆盖最差，误差最大。\n\n### 创新点与贡献  \n首次将全球基阶衰减图扩至球谐阶数20，半波长分辨率约1000 km，比DEA06、QMA16提高20–30%。系统构建并公开第1–4阶全球衰减图，增强200–600 km过渡带采样。基于模型协方差给出完整格点误差，可直接用于后续三维反演与热力学解释。明确成像非洲刚果与卡拉哈里、东欧与西伯利亚克拉通之间的低衰减分隔，为先前阶数16模型所未见。振幅数据、绘图脚本及合成测试流程全部开源，为社区提供可复现平台。\n\n### 局限与未来方向  \n理论层面仍采用线性射线聚焦与一维接收者校正，未考虑有限频率效应与三维弹性散射；未来可用谱元-波形联合反演，自动包含完整弹性效应。高阶模数据量仅为基阶十分之一，南半球、非洲、大西洋覆盖不足，误差偏大；需补充海底OBS阵列与长期台网，并发展新的模态分离算法。基阶参数化上限为阶数20，对应约1000 km，更小尺度结构需依赖区域密集阵列；可采用自适应球谐-小波混合基函数。温度-衰减转换仍依赖实验标定，水、熔体、晶粒尺寸等多因素耦合尚未量化；下一步应结合矿物物理实验与贝叶斯热-化学联合反演，输出温度、水、熔体概率。误差估计尚未考虑相速度图误差、CRUST2.0外推误差及震源深度/机制误差；未来可引入震源-结构联合反演，并使用更新全球地壳模型以进一步降低系统误差。\n","source":"_posts/2025-10-10-paper-reading-28.md","raw":"---\ntitle: 文献阅读(28)\ntags:\n  - paper\ncategories:\n  - work\nabbrlink: 82c5b0d\ndate: 2025-10-10 13:22:19\n---\n&emsp;&emsp;[SGLOBE-Q2D: A Global 2-D Model of Fundamental and Higher Mode Rayleigh Wave Attenuation From a Large Amplitude Data Set](https://agupubs.onlinelibrary.wiley.com/doi/10.1029/2024JB030139?af=R)\n<!--less-->\n### 摘要\n作者提出了SGLOBE‐Q2D，一个具有不确定性的全球上地幔频率依赖瑞利波衰减模型。使用了约 1000 万个基阶与高阶（最高至第 4 阶谐波）瑞利波振幅测量，周期范围为T≈38–275 秒。振幅数据已校正震源效应与弹性效应，包括（a）移除靠近震源节面的路径；（b）校正台站下方局部结构效应；（c）利用线性射线理论近似考虑聚焦/散焦效应。通过大量合成反演测试，支持将基阶模型展开至球谐阶数20，高于近期全球衰减研究的阶数。观测到太平洋大部分区域下方存在广泛的高衰减异常，可能与热点、弧后扩张及地幔柱有关；同时，非洲的刚果与卡拉哈里克拉通、东欧与西伯利亚克拉通之间表现出清晰的低衰减异常分隔。将SGLOBE‐Q2D与相应相速度图对比，表明上地幔温度对衰减异常有显著控制作用，但水、部分熔融、氧化还原状态及晶粒尺寸等因素也可能起作用。\n### 相关研究的重要性  \n地震衰减直接反映地球介质的非弹性性质，对上地幔温度变化极为敏感，可独立验证速度异常是否源于热效应；同时对部分熔融、水含量、晶粒尺寸、氧化还原状态等也更灵敏，能区分“热”与“化学”异常。全球高分辨率衰减图可揭示地幔柱、弧后扩张、俯冲带等深部动力学过程，为板块驱动力研究提供关键约束；与速度模型联合解释，可分解弹性与非弹性贡献，减少速度-温度转换的多解性。此外，克拉通岩石圈厚度、热异常边界与金属矿床、油气储层及地震活动性存在耦合，衰减结构对资源评价和灾害评估具有实际意义。\n\n### 前人研究综述与不足  \nDalton & Ekström (2006) 仅用基阶瑞利波振幅和线性射线理论，球谐阶数止步12，空间分辨率约1300 km，未引入高阶模，也未给出不确定度。Ma et al. (2016) 把阶数提到16并考虑有限频率聚焦，但仍限于基阶，且未提供逐点误差。Adenis et al. (2017) 采用波形反演与三维谱元正演，阶数同为16，却使用非PREM初始模型，长周期偏差较大，计算成本极高，高阶模结果未公开。Gung & Romanowicz (2004) 虽在波形中引入第1阶，但数据量小、无聚焦校正、南半球覆盖差。区域海底阵列如NoMelt只给出单点一维曲线，无法全球对比，也缺少高阶模深度约束。总体来看，早期模型阶数低、高阶模缺失、误差未量化、克拉通内部结构模糊，成为本文突破的出发点。\n\n### 本文数据与方法  \n研究收集955万条垂直分量小弧瑞利波振幅比，来自12232次4–9级、深12–700 km的地震，由全球1017个台站记录，周期37–275 s，涵盖基阶至第4阶谐波；路径弧长限定30°–110°以避免近源效应并减少模态混叠。首先剔除靠近震源节面的路径（占1.6%），再用自洽相速度图（阶数20）按线性射线理论计算聚焦/散焦校正，最后基于SGLOBE-rani地幔模型与CRUST2.0地壳模型计算台站下方局部放大效应。反演采用阻尼加权最小二乘，参数化为ln(Q)，按5°聚类路径数赋权；通过L-曲线选取正则强度，并用模型协方差矩阵输出格点标准差。为确定可分辨阶数，作者将阶数40的合成衰减图加噪反演，以相关系数≥0.8为标准，最终确定基阶可扩至阶数20，第1–4阶分别至15、12、10。\n\n### 主要结果  \n周期40–70 s的基阶图显示海洋普遍高衰减，快速扩张的东太平洋海隆最强，慢速扩张的大西洋与印度洋稍弱；青藏高原呈现显著高衰减；所有主要克拉通均表现为清晰低衰减异常。100–150 s图上，太平洋远离海隆区域仍保持高衰减，暗示多股或宽大地幔柱；俯冲带弧后区亦高衰减，部分海隆下方出现线性低衰减带，可能与岩石圈冷却有关。第1阶图在西太平洋俯冲带和欧亚下方与基阶特征相似；第2–4阶因深度振荡敏感核与数据稀疏，空间相关性下降，误差可达±15。基阶不确定度通常≤±6，高阶模±15；东太平洋与南极射线覆盖最差，误差最大。\n\n### 创新点与贡献  \n首次将全球基阶衰减图扩至球谐阶数20，半波长分辨率约1000 km，比DEA06、QMA16提高20–30%。系统构建并公开第1–4阶全球衰减图，增强200–600 km过渡带采样。基于模型协方差给出完整格点误差，可直接用于后续三维反演与热力学解释。明确成像非洲刚果与卡拉哈里、东欧与西伯利亚克拉通之间的低衰减分隔，为先前阶数16模型所未见。振幅数据、绘图脚本及合成测试流程全部开源，为社区提供可复现平台。\n\n### 局限与未来方向  \n理论层面仍采用线性射线聚焦与一维接收者校正，未考虑有限频率效应与三维弹性散射；未来可用谱元-波形联合反演，自动包含完整弹性效应。高阶模数据量仅为基阶十分之一，南半球、非洲、大西洋覆盖不足，误差偏大；需补充海底OBS阵列与长期台网，并发展新的模态分离算法。基阶参数化上限为阶数20，对应约1000 km，更小尺度结构需依赖区域密集阵列；可采用自适应球谐-小波混合基函数。温度-衰减转换仍依赖实验标定，水、熔体、晶粒尺寸等多因素耦合尚未量化；下一步应结合矿物物理实验与贝叶斯热-化学联合反演，输出温度、水、熔体概率。误差估计尚未考虑相速度图误差、CRUST2.0外推误差及震源深度/机制误差；未来可引入震源-结构联合反演，并使用更新全球地壳模型以进一步降低系统误差。\n","slug":"paper-reading-28","published":1,"updated":"2025-10-10T05:27:49.511Z","comments":1,"layout":"post","photos":[],"_id":"cmh498iqo00ebwvou5rgmepmb","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><h3 id=\"摘要\"><a href=\"#摘要\" class=\"headerlink\" title=\"摘要\"></a>摘要</h3><p>作者提出了SGLOBE‐Q2D，一个具有不确定性的全球上地幔频率依赖瑞利波衰减模型。使用了约 1000 万个基阶与高阶（最高至第 4 阶谐波）瑞利波振幅测量，周期范围为T≈38–275 秒。振幅数据已校正震源效应与弹性效应，包括（a）移除靠近震源节面的路径；（b）校正台站下方局部结构效应；（c）利用线性射线理论近似考虑聚焦&#x2F;散焦效应。通过大量合成反演测试，支持将基阶模型展开至球谐阶数20，高于近期全球衰减研究的阶数。观测到太平洋大部分区域下方存在广泛的高衰减异常，可能与热点、弧后扩张及地幔柱有关；同时，非洲的刚果与卡拉哈里克拉通、东欧与西伯利亚克拉通之间表现出清晰的低衰减异常分隔。将SGLOBE‐Q2D与相应相速度图对比，表明上地幔温度对衰减异常有显著控制作用，但水、部分熔融、氧化还原状态及晶粒尺寸等因素也可能起作用。</p>\n<h3 id=\"相关研究的重要性\"><a href=\"#相关研究的重要性\" class=\"headerlink\" title=\"相关研究的重要性\"></a>相关研究的重要性</h3><p>地震衰减直接反映地球介质的非弹性性质，对上地幔温度变化极为敏感，可独立验证速度异常是否源于热效应；同时对部分熔融、水含量、晶粒尺寸、氧化还原状态等也更灵敏，能区分“热”与“化学”异常。全球高分辨率衰减图可揭示地幔柱、弧后扩张、俯冲带等深部动力学过程，为板块驱动力研究提供关键约束；与速度模型联合解释，可分解弹性与非弹性贡献，减少速度-温度转换的多解性。此外，克拉通岩石圈厚度、热异常边界与金属矿床、油气储层及地震活动性存在耦合，衰减结构对资源评价和灾害评估具有实际意义。</p>\n<h3 id=\"前人研究综述与不足\"><a href=\"#前人研究综述与不足\" class=\"headerlink\" title=\"前人研究综述与不足\"></a>前人研究综述与不足</h3><p>Dalton &amp; Ekström (2006) 仅用基阶瑞利波振幅和线性射线理论，球谐阶数止步12，空间分辨率约1300 km，未引入高阶模，也未给出不确定度。Ma et al. (2016) 把阶数提到16并考虑有限频率聚焦，但仍限于基阶，且未提供逐点误差。Adenis et al. (2017) 采用波形反演与三维谱元正演，阶数同为16，却使用非PREM初始模型，长周期偏差较大，计算成本极高，高阶模结果未公开。Gung &amp; Romanowicz (2004) 虽在波形中引入第1阶，但数据量小、无聚焦校正、南半球覆盖差。区域海底阵列如NoMelt只给出单点一维曲线，无法全球对比，也缺少高阶模深度约束。总体来看，早期模型阶数低、高阶模缺失、误差未量化、克拉通内部结构模糊，成为本文突破的出发点。</p>\n<h3 id=\"本文数据与方法\"><a href=\"#本文数据与方法\" class=\"headerlink\" title=\"本文数据与方法\"></a>本文数据与方法</h3><p>研究收集955万条垂直分量小弧瑞利波振幅比，来自12232次4–9级、深12–700 km的地震，由全球1017个台站记录，周期37–275 s，涵盖基阶至第4阶谐波；路径弧长限定30°–110°以避免近源效应并减少模态混叠。首先剔除靠近震源节面的路径（占1.6%），再用自洽相速度图（阶数20）按线性射线理论计算聚焦&#x2F;散焦校正，最后基于SGLOBE-rani地幔模型与CRUST2.0地壳模型计算台站下方局部放大效应。反演采用阻尼加权最小二乘，参数化为ln(Q)，按5°聚类路径数赋权；通过L-曲线选取正则强度，并用模型协方差矩阵输出格点标准差。为确定可分辨阶数，作者将阶数40的合成衰减图加噪反演，以相关系数≥0.8为标准，最终确定基阶可扩至阶数20，第1–4阶分别至15、12、10。</p>\n<h3 id=\"主要结果\"><a href=\"#主要结果\" class=\"headerlink\" title=\"主要结果\"></a>主要结果</h3><p>周期40–70 s的基阶图显示海洋普遍高衰减，快速扩张的东太平洋海隆最强，慢速扩张的大西洋与印度洋稍弱；青藏高原呈现显著高衰减；所有主要克拉通均表现为清晰低衰减异常。100–150 s图上，太平洋远离海隆区域仍保持高衰减，暗示多股或宽大地幔柱；俯冲带弧后区亦高衰减，部分海隆下方出现线性低衰减带，可能与岩石圈冷却有关。第1阶图在西太平洋俯冲带和欧亚下方与基阶特征相似；第2–4阶因深度振荡敏感核与数据稀疏，空间相关性下降，误差可达±15。基阶不确定度通常≤±6，高阶模±15；东太平洋与南极射线覆盖最差，误差最大。</p>\n<h3 id=\"创新点与贡献\"><a href=\"#创新点与贡献\" class=\"headerlink\" title=\"创新点与贡献\"></a>创新点与贡献</h3><p>首次将全球基阶衰减图扩至球谐阶数20，半波长分辨率约1000 km，比DEA06、QMA16提高20–30%。系统构建并公开第1–4阶全球衰减图，增强200–600 km过渡带采样。基于模型协方差给出完整格点误差，可直接用于后续三维反演与热力学解释。明确成像非洲刚果与卡拉哈里、东欧与西伯利亚克拉通之间的低衰减分隔，为先前阶数16模型所未见。振幅数据、绘图脚本及合成测试流程全部开源，为社区提供可复现平台。</p>\n<h3 id=\"局限与未来方向\"><a href=\"#局限与未来方向\" class=\"headerlink\" title=\"局限与未来方向\"></a>局限与未来方向</h3><p>理论层面仍采用线性射线聚焦与一维接收者校正，未考虑有限频率效应与三维弹性散射；未来可用谱元-波形联合反演，自动包含完整弹性效应。高阶模数据量仅为基阶十分之一，南半球、非洲、大西洋覆盖不足，误差偏大；需补充海底OBS阵列与长期台网，并发展新的模态分离算法。基阶参数化上限为阶数20，对应约1000 km，更小尺度结构需依赖区域密集阵列；可采用自适应球谐-小波混合基函数。温度-衰减转换仍依赖实验标定，水、熔体、晶粒尺寸等多因素耦合尚未量化；下一步应结合矿物物理实验与贝叶斯热-化学联合反演，输出温度、水、熔体概率。误差估计尚未考虑相速度图误差、CRUST2.0外推误差及震源深度&#x2F;机制误差；未来可引入震源-结构联合反演，并使用更新全球地壳模型以进一步降低系统误差。</p>","related_posts":[],"length":2236,"excerpt":"<p>&emsp;&emsp;<a href=\"https://agupubs.onlinelibrary.wiley.com/doi/10.1029/2024JB030139?af=R\">SGLOBE-Q2D: A Global 2-D Model of Fundamental and Higher Mode Rayleigh Wave Attenuation From a Large Amplitude Data Set</a></p>","more":"<h3 id=\"摘要\"><a href=\"#摘要\" class=\"headerlink\" title=\"摘要\"></a>摘要</h3><p>作者提出了SGLOBE‐Q2D，一个具有不确定性的全球上地幔频率依赖瑞利波衰减模型。使用了约 1000 万个基阶与高阶（最高至第 4 阶谐波）瑞利波振幅测量，周期范围为T≈38–275 秒。振幅数据已校正震源效应与弹性效应，包括（a）移除靠近震源节面的路径；（b）校正台站下方局部结构效应；（c）利用线性射线理论近似考虑聚焦&#x2F;散焦效应。通过大量合成反演测试，支持将基阶模型展开至球谐阶数20，高于近期全球衰减研究的阶数。观测到太平洋大部分区域下方存在广泛的高衰减异常，可能与热点、弧后扩张及地幔柱有关；同时，非洲的刚果与卡拉哈里克拉通、东欧与西伯利亚克拉通之间表现出清晰的低衰减异常分隔。将SGLOBE‐Q2D与相应相速度图对比，表明上地幔温度对衰减异常有显著控制作用，但水、部分熔融、氧化还原状态及晶粒尺寸等因素也可能起作用。</p>\n<h3 id=\"相关研究的重要性\"><a href=\"#相关研究的重要性\" class=\"headerlink\" title=\"相关研究的重要性\"></a>相关研究的重要性</h3><p>地震衰减直接反映地球介质的非弹性性质，对上地幔温度变化极为敏感，可独立验证速度异常是否源于热效应；同时对部分熔融、水含量、晶粒尺寸、氧化还原状态等也更灵敏，能区分“热”与“化学”异常。全球高分辨率衰减图可揭示地幔柱、弧后扩张、俯冲带等深部动力学过程，为板块驱动力研究提供关键约束；与速度模型联合解释，可分解弹性与非弹性贡献，减少速度-温度转换的多解性。此外，克拉通岩石圈厚度、热异常边界与金属矿床、油气储层及地震活动性存在耦合，衰减结构对资源评价和灾害评估具有实际意义。</p>\n<h3 id=\"前人研究综述与不足\"><a href=\"#前人研究综述与不足\" class=\"headerlink\" title=\"前人研究综述与不足\"></a>前人研究综述与不足</h3><p>Dalton &amp; Ekström (2006) 仅用基阶瑞利波振幅和线性射线理论，球谐阶数止步12，空间分辨率约1300 km，未引入高阶模，也未给出不确定度。Ma et al. (2016) 把阶数提到16并考虑有限频率聚焦，但仍限于基阶，且未提供逐点误差。Adenis et al. (2017) 采用波形反演与三维谱元正演，阶数同为16，却使用非PREM初始模型，长周期偏差较大，计算成本极高，高阶模结果未公开。Gung &amp; Romanowicz (2004) 虽在波形中引入第1阶，但数据量小、无聚焦校正、南半球覆盖差。区域海底阵列如NoMelt只给出单点一维曲线，无法全球对比，也缺少高阶模深度约束。总体来看，早期模型阶数低、高阶模缺失、误差未量化、克拉通内部结构模糊，成为本文突破的出发点。</p>\n<h3 id=\"本文数据与方法\"><a href=\"#本文数据与方法\" class=\"headerlink\" title=\"本文数据与方法\"></a>本文数据与方法</h3><p>研究收集955万条垂直分量小弧瑞利波振幅比，来自12232次4–9级、深12–700 km的地震，由全球1017个台站记录，周期37–275 s，涵盖基阶至第4阶谐波；路径弧长限定30°–110°以避免近源效应并减少模态混叠。首先剔除靠近震源节面的路径（占1.6%），再用自洽相速度图（阶数20）按线性射线理论计算聚焦&#x2F;散焦校正，最后基于SGLOBE-rani地幔模型与CRUST2.0地壳模型计算台站下方局部放大效应。反演采用阻尼加权最小二乘，参数化为ln(Q)，按5°聚类路径数赋权；通过L-曲线选取正则强度，并用模型协方差矩阵输出格点标准差。为确定可分辨阶数，作者将阶数40的合成衰减图加噪反演，以相关系数≥0.8为标准，最终确定基阶可扩至阶数20，第1–4阶分别至15、12、10。</p>\n<h3 id=\"主要结果\"><a href=\"#主要结果\" class=\"headerlink\" title=\"主要结果\"></a>主要结果</h3><p>周期40–70 s的基阶图显示海洋普遍高衰减，快速扩张的东太平洋海隆最强，慢速扩张的大西洋与印度洋稍弱；青藏高原呈现显著高衰减；所有主要克拉通均表现为清晰低衰减异常。100–150 s图上，太平洋远离海隆区域仍保持高衰减，暗示多股或宽大地幔柱；俯冲带弧后区亦高衰减，部分海隆下方出现线性低衰减带，可能与岩石圈冷却有关。第1阶图在西太平洋俯冲带和欧亚下方与基阶特征相似；第2–4阶因深度振荡敏感核与数据稀疏，空间相关性下降，误差可达±15。基阶不确定度通常≤±6，高阶模±15；东太平洋与南极射线覆盖最差，误差最大。</p>\n<h3 id=\"创新点与贡献\"><a href=\"#创新点与贡献\" class=\"headerlink\" title=\"创新点与贡献\"></a>创新点与贡献</h3><p>首次将全球基阶衰减图扩至球谐阶数20，半波长分辨率约1000 km，比DEA06、QMA16提高20–30%。系统构建并公开第1–4阶全球衰减图，增强200–600 km过渡带采样。基于模型协方差给出完整格点误差，可直接用于后续三维反演与热力学解释。明确成像非洲刚果与卡拉哈里、东欧与西伯利亚克拉通之间的低衰减分隔，为先前阶数16模型所未见。振幅数据、绘图脚本及合成测试流程全部开源，为社区提供可复现平台。</p>\n<h3 id=\"局限与未来方向\"><a href=\"#局限与未来方向\" class=\"headerlink\" title=\"局限与未来方向\"></a>局限与未来方向</h3><p>理论层面仍采用线性射线聚焦与一维接收者校正，未考虑有限频率效应与三维弹性散射；未来可用谱元-波形联合反演，自动包含完整弹性效应。高阶模数据量仅为基阶十分之一，南半球、非洲、大西洋覆盖不足，误差偏大；需补充海底OBS阵列与长期台网，并发展新的模态分离算法。基阶参数化上限为阶数20，对应约1000 km，更小尺度结构需依赖区域密集阵列；可采用自适应球谐-小波混合基函数。温度-衰减转换仍依赖实验标定，水、熔体、晶粒尺寸等多因素耦合尚未量化；下一步应结合矿物物理实验与贝叶斯热-化学联合反演，输出温度、水、熔体概率。误差估计尚未考虑相速度图误差、CRUST2.0外推误差及震源深度&#x2F;机制误差；未来可引入震源-结构联合反演，并使用更新全球地壳模型以进一步降低系统误差。</p>"},{"title":"文献阅读(29)","abbrlink":"11376a4c","date":"2025-10-19T12:35:53.000Z","_content":"&emsp;&emsp;[Polarized Earth's ambient microseismic noise](https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2011GC003661)\n<!--less-->\n### 翻译\n本文利用全球分布的地震台网（GEOSCOPE）7 年连续三分量记录，对背景噪声进行了频率相关的量化与表征。地脉动于海浪相互作用，是地球上最强且普遍存在的背景噪声。作者提出一种适用于时频域的新方法，可检测极化信号并用以刻画地脉动噪声。通过定义“椭圆极化度”（Degree of Polarization, DOP）谱，发现地脉动频段比其他频带具有更强的极化性。基于单台站极化分析，可测量噪声的背方位角（BAZ），并揭示其明显的季节变化。所得 BAZ 与海浪模型计算的理论源区方向一致，表明该测量稳健可靠。\n\n---\n\n### 相关研究的重要性\n1. 地脉动虽被视为“干扰”，但已成为新一代地震学信号源：  \n   - 可用于背景噪声面波层析成像，弥补天然地震空间分布不均；  \n   - 可实时追踪海洋风暴路径，为气候与海洋预报提供独立数据；  \n   - 是研究海洋-固体地球能量耦合的重要观测窗口。  \n\n2. 传统源区定位需大规模台阵，通过走时差或相干性实现，布设与维护成本高；若能用单台三分量完成方向估计，将显著降低野外工作量。  \n\n3. 极化分析给出的背方位角可直接指向海浪源区，为验证和改进海浪-海底耦合理论（Longuet-Higgins, 1950）提供定量观测依据。  \n\n4. 极化度指标本身可作为“信噪品质”度量，用于噪声层析中对方向性偏差进行校正，提高地下成像精度。\n\n---\n\n### 前人相关研究及不足\n1. Longuet-Higgins (1950) 提出双频压力机制解释二次微地震，奠定了理论基础，但缺乏全球尺度观测验证。  \n\n2. Hasselmann (1963) 采用统计方法描述海浪与海底耦合，未考虑波动方向与极化信息。  \n\n3. Schulte-Pelkum et al. (2004) 利用美国西部密集台阵发现海洋噪声具有强烈方向性，然而依赖台阵且采用时域协方差，频率分辨率有限。  \n\n4. Tanimoto et al. (2006) 分析南加州台站水平/垂直振幅比的季节变化，仅利用振幅比，未直接测量方向。  \n\n5. Gerstoft et al. (2008) 用台阵反演 P 波微地震源区，依然需要密集台站，且未利用极化属性。  \n\n6. Bromirski & Duennebier (2002) 对比近岸与远海地脉动振幅谱，发现频谱差异，但未给出全球单台极化方向。  \n\n7. Stehly et al. (2006) 利用互相关研究噪声源季节变化，需要双台记录，无法给出瞬时方向。  \n\n8. Chevrot et al. (2007) 用欧洲台阵定位第二类地脉动，台阵覆盖有限，且未与海浪模型系统对比。  \n\n9. Aster et al. (2008) 将地脉动功率与多年气候序列关联，仅用功率谱，无方向与极化信息。  \n\n总体不足：  \n- 多数研究依赖台阵，单台极化研究稀少；  \n- 以功率或互相关为主，缺乏定量极化度指标；  \n- 时域或窄带分析，难以同时处理非平稳性与多源叠加；  \n- 很少与独立海浪模型进行季节对比验证。\n\n---\n\n### 本文数据\n- GEOSCOPE 全球 27 个三分量宽频带台站 2001–2007 年连续波形，采样率 1 sps（长周期通道），共 7 年、约 8000 个台日。  \n- 使用垂直、北-南、东-西三分量地面速度记录。\n\n---\n\n### 本文方法\n1. 预处理：去除仪器响应，得到地面速度时序。  \n2. 时频分解：采用 S 变换（Stockwell et al., 1996），窗宽随周期自动缩放（2σ = 3T）。  \n3. 极化分析：  \n   - 对每个时频点构建 3×3 谱矩阵；  \n   - 特征分解得瞬时椭圆长轴、短轴与面法向量；  \n   - 定义“椭圆极化度”DOP，并用面法向量与垂向夹角加权，突出垂直面内椭圆运动；  \n   - 假定基阶瑞利波为逆行进椭圆，消除 180° 模糊，提取背方位角 BAZ。  \n4. 对比验证：利用 Ifremer WAVEWATCH III 海浪模式（含岸线反射）计算全球第二类地脉动理论源区，与实测 BAZ 按月平均进行季节对比。\n\n---\n\n### 本文结果\n1. 极化谱显示第一类（0.05–0.08 Hz）与第二类（0.09–0.15 Hz）地脉动呈明显双峰，且极化度高于两侧频段。  \n2. 单台 BAZ 存在显著季节变化：北半球夏季主要来自南方，冬季主要来自北方，与海浪气候同步。  \n3. 在 0.09–0.14 Hz 观察到线性“频散条纹”，频率随时间斜升，斜率与深海重力波群速 ug = gT/4π 一致，为首次在单台极化数据中出现。  \n4. 与海浪模型对比：实测 BAZ 指向与理论 SM 源区方向总体吻合，季节变化一致，相关系数视觉高于 0.8。  \n5. 内陆站（如 TAM）季节信号最清晰；沿海站受近岸源影响，BAZ 分布带宽约 90°。\n\n---\n\n### 本文创新点与贡献\n1. 方法创新：首次将“时频椭圆极化度 + DOP 阈值”用于 7 年全球连续噪声，实现单台站方向测量。  \n2. 观测创新：  \n   - 提出“极化谱”概念，量化地脉动极化强度随频率分布；  \n   - 首次在单台极化结果中观察到海浪群速引起的线性频散条纹。  \n3. 验证创新：将地震极化 BAZ 与完全独立的海浪模型（含海岸线反射）进行系统季节对比，证明 BAZ 稳健。  \n4. 应用潜力：为噪声层析提供方向偏差校正；为海洋风暴/气候监测提供新手段；指导海底或岸基临时台站选址。\n\n---\n\n### 本文不足与未来展望\n1. 仅使用 1 sps 长周期数据，未分析 0.5–1.4 Hz 高频体波微地震——可提高采样率，联合 P 波微地震研究。  \n2. DOP 阈值与指数 n 人为选取，可能影响信号数量——未来可采用自适应或机器学习优化阈值。  \n3. 海浪模型为“理论源”，未同步反演源强度与 BAZ——可发展联合反演，实现源区强度-方向同时成像。  \n4. 未考虑地壳各向异性或三维结构对 BAZ 的偏折——可引入三维地壳模型进行射线校正。  \n5. 目前仅针对瑞利波椭圆极化，未系统研究 Love 波极化——可开发 Love-Rayleigh 分离方法，探讨 Love 波源区特征。\n","source":"_posts/2025-10-19-paper-reading-29.md","raw":"---\ntitle: 文献阅读(29)\ntags:\n  - paper\ncategories:\n  - work\nabbrlink: 11376a4c\ndate: 2025-10-19 20:35:53\n---\n&emsp;&emsp;[Polarized Earth's ambient microseismic noise](https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2011GC003661)\n<!--less-->\n### 翻译\n本文利用全球分布的地震台网（GEOSCOPE）7 年连续三分量记录，对背景噪声进行了频率相关的量化与表征。地脉动于海浪相互作用，是地球上最强且普遍存在的背景噪声。作者提出一种适用于时频域的新方法，可检测极化信号并用以刻画地脉动噪声。通过定义“椭圆极化度”（Degree of Polarization, DOP）谱，发现地脉动频段比其他频带具有更强的极化性。基于单台站极化分析，可测量噪声的背方位角（BAZ），并揭示其明显的季节变化。所得 BAZ 与海浪模型计算的理论源区方向一致，表明该测量稳健可靠。\n\n---\n\n### 相关研究的重要性\n1. 地脉动虽被视为“干扰”，但已成为新一代地震学信号源：  \n   - 可用于背景噪声面波层析成像，弥补天然地震空间分布不均；  \n   - 可实时追踪海洋风暴路径，为气候与海洋预报提供独立数据；  \n   - 是研究海洋-固体地球能量耦合的重要观测窗口。  \n\n2. 传统源区定位需大规模台阵，通过走时差或相干性实现，布设与维护成本高；若能用单台三分量完成方向估计，将显著降低野外工作量。  \n\n3. 极化分析给出的背方位角可直接指向海浪源区，为验证和改进海浪-海底耦合理论（Longuet-Higgins, 1950）提供定量观测依据。  \n\n4. 极化度指标本身可作为“信噪品质”度量，用于噪声层析中对方向性偏差进行校正，提高地下成像精度。\n\n---\n\n### 前人相关研究及不足\n1. Longuet-Higgins (1950) 提出双频压力机制解释二次微地震，奠定了理论基础，但缺乏全球尺度观测验证。  \n\n2. Hasselmann (1963) 采用统计方法描述海浪与海底耦合，未考虑波动方向与极化信息。  \n\n3. Schulte-Pelkum et al. (2004) 利用美国西部密集台阵发现海洋噪声具有强烈方向性，然而依赖台阵且采用时域协方差，频率分辨率有限。  \n\n4. Tanimoto et al. (2006) 分析南加州台站水平/垂直振幅比的季节变化，仅利用振幅比，未直接测量方向。  \n\n5. Gerstoft et al. (2008) 用台阵反演 P 波微地震源区，依然需要密集台站，且未利用极化属性。  \n\n6. Bromirski & Duennebier (2002) 对比近岸与远海地脉动振幅谱，发现频谱差异，但未给出全球单台极化方向。  \n\n7. Stehly et al. (2006) 利用互相关研究噪声源季节变化，需要双台记录，无法给出瞬时方向。  \n\n8. Chevrot et al. (2007) 用欧洲台阵定位第二类地脉动，台阵覆盖有限，且未与海浪模型系统对比。  \n\n9. Aster et al. (2008) 将地脉动功率与多年气候序列关联，仅用功率谱，无方向与极化信息。  \n\n总体不足：  \n- 多数研究依赖台阵，单台极化研究稀少；  \n- 以功率或互相关为主，缺乏定量极化度指标；  \n- 时域或窄带分析，难以同时处理非平稳性与多源叠加；  \n- 很少与独立海浪模型进行季节对比验证。\n\n---\n\n### 本文数据\n- GEOSCOPE 全球 27 个三分量宽频带台站 2001–2007 年连续波形，采样率 1 sps（长周期通道），共 7 年、约 8000 个台日。  \n- 使用垂直、北-南、东-西三分量地面速度记录。\n\n---\n\n### 本文方法\n1. 预处理：去除仪器响应，得到地面速度时序。  \n2. 时频分解：采用 S 变换（Stockwell et al., 1996），窗宽随周期自动缩放（2σ = 3T）。  \n3. 极化分析：  \n   - 对每个时频点构建 3×3 谱矩阵；  \n   - 特征分解得瞬时椭圆长轴、短轴与面法向量；  \n   - 定义“椭圆极化度”DOP，并用面法向量与垂向夹角加权，突出垂直面内椭圆运动；  \n   - 假定基阶瑞利波为逆行进椭圆，消除 180° 模糊，提取背方位角 BAZ。  \n4. 对比验证：利用 Ifremer WAVEWATCH III 海浪模式（含岸线反射）计算全球第二类地脉动理论源区，与实测 BAZ 按月平均进行季节对比。\n\n---\n\n### 本文结果\n1. 极化谱显示第一类（0.05–0.08 Hz）与第二类（0.09–0.15 Hz）地脉动呈明显双峰，且极化度高于两侧频段。  \n2. 单台 BAZ 存在显著季节变化：北半球夏季主要来自南方，冬季主要来自北方，与海浪气候同步。  \n3. 在 0.09–0.14 Hz 观察到线性“频散条纹”，频率随时间斜升，斜率与深海重力波群速 ug = gT/4π 一致，为首次在单台极化数据中出现。  \n4. 与海浪模型对比：实测 BAZ 指向与理论 SM 源区方向总体吻合，季节变化一致，相关系数视觉高于 0.8。  \n5. 内陆站（如 TAM）季节信号最清晰；沿海站受近岸源影响，BAZ 分布带宽约 90°。\n\n---\n\n### 本文创新点与贡献\n1. 方法创新：首次将“时频椭圆极化度 + DOP 阈值”用于 7 年全球连续噪声，实现单台站方向测量。  \n2. 观测创新：  \n   - 提出“极化谱”概念，量化地脉动极化强度随频率分布；  \n   - 首次在单台极化结果中观察到海浪群速引起的线性频散条纹。  \n3. 验证创新：将地震极化 BAZ 与完全独立的海浪模型（含海岸线反射）进行系统季节对比，证明 BAZ 稳健。  \n4. 应用潜力：为噪声层析提供方向偏差校正；为海洋风暴/气候监测提供新手段；指导海底或岸基临时台站选址。\n\n---\n\n### 本文不足与未来展望\n1. 仅使用 1 sps 长周期数据，未分析 0.5–1.4 Hz 高频体波微地震——可提高采样率，联合 P 波微地震研究。  \n2. DOP 阈值与指数 n 人为选取，可能影响信号数量——未来可采用自适应或机器学习优化阈值。  \n3. 海浪模型为“理论源”，未同步反演源强度与 BAZ——可发展联合反演，实现源区强度-方向同时成像。  \n4. 未考虑地壳各向异性或三维结构对 BAZ 的偏折——可引入三维地壳模型进行射线校正。  \n5. 目前仅针对瑞利波椭圆极化，未系统研究 Love 波极化——可开发 Love-Rayleigh 分离方法，探讨 Love 波源区特征。\n","slug":"paper-reading-29","published":1,"updated":"2025-10-19T13:35:10.939Z","comments":1,"layout":"post","photos":[],"_id":"cmh498iqp00efwvou1h6rcthc","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><h3 id=\"翻译\"><a href=\"#翻译\" class=\"headerlink\" title=\"翻译\"></a>翻译</h3><p>本文利用全球分布的地震台网（GEOSCOPE）7 年连续三分量记录，对背景噪声进行了频率相关的量化与表征。地脉动于海浪相互作用，是地球上最强且普遍存在的背景噪声。作者提出一种适用于时频域的新方法，可检测极化信号并用以刻画地脉动噪声。通过定义“椭圆极化度”（Degree of Polarization, DOP）谱，发现地脉动频段比其他频带具有更强的极化性。基于单台站极化分析，可测量噪声的背方位角（BAZ），并揭示其明显的季节变化。所得 BAZ 与海浪模型计算的理论源区方向一致，表明该测量稳健可靠。</p>\n<hr>\n<h3 id=\"相关研究的重要性\"><a href=\"#相关研究的重要性\" class=\"headerlink\" title=\"相关研究的重要性\"></a>相关研究的重要性</h3><ol>\n<li><p>地脉动虽被视为“干扰”，但已成为新一代地震学信号源：  </p>\n<ul>\n<li>可用于背景噪声面波层析成像，弥补天然地震空间分布不均；  </li>\n<li>可实时追踪海洋风暴路径，为气候与海洋预报提供独立数据；  </li>\n<li>是研究海洋-固体地球能量耦合的重要观测窗口。</li>\n</ul>\n</li>\n<li><p>传统源区定位需大规模台阵，通过走时差或相干性实现，布设与维护成本高；若能用单台三分量完成方向估计，将显著降低野外工作量。  </p>\n</li>\n<li><p>极化分析给出的背方位角可直接指向海浪源区，为验证和改进海浪-海底耦合理论（Longuet-Higgins, 1950）提供定量观测依据。  </p>\n</li>\n<li><p>极化度指标本身可作为“信噪品质”度量，用于噪声层析中对方向性偏差进行校正，提高地下成像精度。</p>\n</li>\n</ol>\n<hr>\n<h3 id=\"前人相关研究及不足\"><a href=\"#前人相关研究及不足\" class=\"headerlink\" title=\"前人相关研究及不足\"></a>前人相关研究及不足</h3><ol>\n<li><p>Longuet-Higgins (1950) 提出双频压力机制解释二次微地震，奠定了理论基础，但缺乏全球尺度观测验证。  </p>\n</li>\n<li><p>Hasselmann (1963) 采用统计方法描述海浪与海底耦合，未考虑波动方向与极化信息。  </p>\n</li>\n<li><p>Schulte-Pelkum et al. (2004) 利用美国西部密集台阵发现海洋噪声具有强烈方向性，然而依赖台阵且采用时域协方差，频率分辨率有限。  </p>\n</li>\n<li><p>Tanimoto et al. (2006) 分析南加州台站水平&#x2F;垂直振幅比的季节变化，仅利用振幅比，未直接测量方向。  </p>\n</li>\n<li><p>Gerstoft et al. (2008) 用台阵反演 P 波微地震源区，依然需要密集台站，且未利用极化属性。  </p>\n</li>\n<li><p>Bromirski &amp; Duennebier (2002) 对比近岸与远海地脉动振幅谱，发现频谱差异，但未给出全球单台极化方向。  </p>\n</li>\n<li><p>Stehly et al. (2006) 利用互相关研究噪声源季节变化，需要双台记录，无法给出瞬时方向。  </p>\n</li>\n<li><p>Chevrot et al. (2007) 用欧洲台阵定位第二类地脉动，台阵覆盖有限，且未与海浪模型系统对比。  </p>\n</li>\n<li><p>Aster et al. (2008) 将地脉动功率与多年气候序列关联，仅用功率谱，无方向与极化信息。</p>\n</li>\n</ol>\n<p>总体不足：  </p>\n<ul>\n<li>多数研究依赖台阵，单台极化研究稀少；  </li>\n<li>以功率或互相关为主，缺乏定量极化度指标；  </li>\n<li>时域或窄带分析，难以同时处理非平稳性与多源叠加；  </li>\n<li>很少与独立海浪模型进行季节对比验证。</li>\n</ul>\n<hr>\n<h3 id=\"本文数据\"><a href=\"#本文数据\" class=\"headerlink\" title=\"本文数据\"></a>本文数据</h3><ul>\n<li>GEOSCOPE 全球 27 个三分量宽频带台站 2001–2007 年连续波形，采样率 1 sps（长周期通道），共 7 年、约 8000 个台日。  </li>\n<li>使用垂直、北-南、东-西三分量地面速度记录。</li>\n</ul>\n<hr>\n<h3 id=\"本文方法\"><a href=\"#本文方法\" class=\"headerlink\" title=\"本文方法\"></a>本文方法</h3><ol>\n<li>预处理：去除仪器响应，得到地面速度时序。  </li>\n<li>时频分解：采用 S 变换（Stockwell et al., 1996），窗宽随周期自动缩放（2σ &#x3D; 3T）。  </li>\n<li>极化分析：  <ul>\n<li>对每个时频点构建 3×3 谱矩阵；  </li>\n<li>特征分解得瞬时椭圆长轴、短轴与面法向量；  </li>\n<li>定义“椭圆极化度”DOP，并用面法向量与垂向夹角加权，突出垂直面内椭圆运动；  </li>\n<li>假定基阶瑞利波为逆行进椭圆，消除 180° 模糊，提取背方位角 BAZ。</li>\n</ul>\n</li>\n<li>对比验证：利用 Ifremer WAVEWATCH III 海浪模式（含岸线反射）计算全球第二类地脉动理论源区，与实测 BAZ 按月平均进行季节对比。</li>\n</ol>\n<hr>\n<h3 id=\"本文结果\"><a href=\"#本文结果\" class=\"headerlink\" title=\"本文结果\"></a>本文结果</h3><ol>\n<li>极化谱显示第一类（0.05–0.08 Hz）与第二类（0.09–0.15 Hz）地脉动呈明显双峰，且极化度高于两侧频段。  </li>\n<li>单台 BAZ 存在显著季节变化：北半球夏季主要来自南方，冬季主要来自北方，与海浪气候同步。  </li>\n<li>在 0.09–0.14 Hz 观察到线性“频散条纹”，频率随时间斜升，斜率与深海重力波群速 ug &#x3D; gT&#x2F;4π 一致，为首次在单台极化数据中出现。  </li>\n<li>与海浪模型对比：实测 BAZ 指向与理论 SM 源区方向总体吻合，季节变化一致，相关系数视觉高于 0.8。  </li>\n<li>内陆站（如 TAM）季节信号最清晰；沿海站受近岸源影响，BAZ 分布带宽约 90°。</li>\n</ol>\n<hr>\n<h3 id=\"本文创新点与贡献\"><a href=\"#本文创新点与贡献\" class=\"headerlink\" title=\"本文创新点与贡献\"></a>本文创新点与贡献</h3><ol>\n<li>方法创新：首次将“时频椭圆极化度 + DOP 阈值”用于 7 年全球连续噪声，实现单台站方向测量。  </li>\n<li>观测创新：  <ul>\n<li>提出“极化谱”概念，量化地脉动极化强度随频率分布；  </li>\n<li>首次在单台极化结果中观察到海浪群速引起的线性频散条纹。</li>\n</ul>\n</li>\n<li>验证创新：将地震极化 BAZ 与完全独立的海浪模型（含海岸线反射）进行系统季节对比，证明 BAZ 稳健。  </li>\n<li>应用潜力：为噪声层析提供方向偏差校正；为海洋风暴&#x2F;气候监测提供新手段；指导海底或岸基临时台站选址。</li>\n</ol>\n<hr>\n<h3 id=\"本文不足与未来展望\"><a href=\"#本文不足与未来展望\" class=\"headerlink\" title=\"本文不足与未来展望\"></a>本文不足与未来展望</h3><ol>\n<li>仅使用 1 sps 长周期数据，未分析 0.5–1.4 Hz 高频体波微地震——可提高采样率，联合 P 波微地震研究。  </li>\n<li>DOP 阈值与指数 n 人为选取，可能影响信号数量——未来可采用自适应或机器学习优化阈值。  </li>\n<li>海浪模型为“理论源”，未同步反演源强度与 BAZ——可发展联合反演，实现源区强度-方向同时成像。  </li>\n<li>未考虑地壳各向异性或三维结构对 BAZ 的偏折——可引入三维地壳模型进行射线校正。  </li>\n<li>目前仅针对瑞利波椭圆极化，未系统研究 Love 波极化——可开发 Love-Rayleigh 分离方法，探讨 Love 波源区特征。</li>\n</ol>","related_posts":[],"length":2246,"excerpt":"<p>&emsp;&emsp;<a href=\"https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2011GC003661\">Polarized Earth’s ambient microseismic noise</a></p>","more":"<h3 id=\"翻译\"><a href=\"#翻译\" class=\"headerlink\" title=\"翻译\"></a>翻译</h3><p>本文利用全球分布的地震台网（GEOSCOPE）7 年连续三分量记录，对背景噪声进行了频率相关的量化与表征。地脉动于海浪相互作用，是地球上最强且普遍存在的背景噪声。作者提出一种适用于时频域的新方法，可检测极化信号并用以刻画地脉动噪声。通过定义“椭圆极化度”（Degree of Polarization, DOP）谱，发现地脉动频段比其他频带具有更强的极化性。基于单台站极化分析，可测量噪声的背方位角（BAZ），并揭示其明显的季节变化。所得 BAZ 与海浪模型计算的理论源区方向一致，表明该测量稳健可靠。</p>\n<hr>\n<h3 id=\"相关研究的重要性\"><a href=\"#相关研究的重要性\" class=\"headerlink\" title=\"相关研究的重要性\"></a>相关研究的重要性</h3><ol>\n<li><p>地脉动虽被视为“干扰”，但已成为新一代地震学信号源：  </p>\n<ul>\n<li>可用于背景噪声面波层析成像，弥补天然地震空间分布不均；  </li>\n<li>可实时追踪海洋风暴路径，为气候与海洋预报提供独立数据；  </li>\n<li>是研究海洋-固体地球能量耦合的重要观测窗口。</li>\n</ul>\n</li>\n<li><p>传统源区定位需大规模台阵，通过走时差或相干性实现，布设与维护成本高；若能用单台三分量完成方向估计，将显著降低野外工作量。  </p>\n</li>\n<li><p>极化分析给出的背方位角可直接指向海浪源区，为验证和改进海浪-海底耦合理论（Longuet-Higgins, 1950）提供定量观测依据。  </p>\n</li>\n<li><p>极化度指标本身可作为“信噪品质”度量，用于噪声层析中对方向性偏差进行校正，提高地下成像精度。</p>\n</li>\n</ol>\n<hr>\n<h3 id=\"前人相关研究及不足\"><a href=\"#前人相关研究及不足\" class=\"headerlink\" title=\"前人相关研究及不足\"></a>前人相关研究及不足</h3><ol>\n<li><p>Longuet-Higgins (1950) 提出双频压力机制解释二次微地震，奠定了理论基础，但缺乏全球尺度观测验证。  </p>\n</li>\n<li><p>Hasselmann (1963) 采用统计方法描述海浪与海底耦合，未考虑波动方向与极化信息。  </p>\n</li>\n<li><p>Schulte-Pelkum et al. (2004) 利用美国西部密集台阵发现海洋噪声具有强烈方向性，然而依赖台阵且采用时域协方差，频率分辨率有限。  </p>\n</li>\n<li><p>Tanimoto et al. (2006) 分析南加州台站水平&#x2F;垂直振幅比的季节变化，仅利用振幅比，未直接测量方向。  </p>\n</li>\n<li><p>Gerstoft et al. (2008) 用台阵反演 P 波微地震源区，依然需要密集台站，且未利用极化属性。  </p>\n</li>\n<li><p>Bromirski &amp; Duennebier (2002) 对比近岸与远海地脉动振幅谱，发现频谱差异，但未给出全球单台极化方向。  </p>\n</li>\n<li><p>Stehly et al. (2006) 利用互相关研究噪声源季节变化，需要双台记录，无法给出瞬时方向。  </p>\n</li>\n<li><p>Chevrot et al. (2007) 用欧洲台阵定位第二类地脉动，台阵覆盖有限，且未与海浪模型系统对比。  </p>\n</li>\n<li><p>Aster et al. (2008) 将地脉动功率与多年气候序列关联，仅用功率谱，无方向与极化信息。</p>\n</li>\n</ol>\n<p>总体不足：  </p>\n<ul>\n<li>多数研究依赖台阵，单台极化研究稀少；  </li>\n<li>以功率或互相关为主，缺乏定量极化度指标；  </li>\n<li>时域或窄带分析，难以同时处理非平稳性与多源叠加；  </li>\n<li>很少与独立海浪模型进行季节对比验证。</li>\n</ul>\n<hr>\n<h3 id=\"本文数据\"><a href=\"#本文数据\" class=\"headerlink\" title=\"本文数据\"></a>本文数据</h3><ul>\n<li>GEOSCOPE 全球 27 个三分量宽频带台站 2001–2007 年连续波形，采样率 1 sps（长周期通道），共 7 年、约 8000 个台日。  </li>\n<li>使用垂直、北-南、东-西三分量地面速度记录。</li>\n</ul>\n<hr>\n<h3 id=\"本文方法\"><a href=\"#本文方法\" class=\"headerlink\" title=\"本文方法\"></a>本文方法</h3><ol>\n<li>预处理：去除仪器响应，得到地面速度时序。  </li>\n<li>时频分解：采用 S 变换（Stockwell et al., 1996），窗宽随周期自动缩放（2σ &#x3D; 3T）。  </li>\n<li>极化分析：  <ul>\n<li>对每个时频点构建 3×3 谱矩阵；  </li>\n<li>特征分解得瞬时椭圆长轴、短轴与面法向量；  </li>\n<li>定义“椭圆极化度”DOP，并用面法向量与垂向夹角加权，突出垂直面内椭圆运动；  </li>\n<li>假定基阶瑞利波为逆行进椭圆，消除 180° 模糊，提取背方位角 BAZ。</li>\n</ul>\n</li>\n<li>对比验证：利用 Ifremer WAVEWATCH III 海浪模式（含岸线反射）计算全球第二类地脉动理论源区，与实测 BAZ 按月平均进行季节对比。</li>\n</ol>\n<hr>\n<h3 id=\"本文结果\"><a href=\"#本文结果\" class=\"headerlink\" title=\"本文结果\"></a>本文结果</h3><ol>\n<li>极化谱显示第一类（0.05–0.08 Hz）与第二类（0.09–0.15 Hz）地脉动呈明显双峰，且极化度高于两侧频段。  </li>\n<li>单台 BAZ 存在显著季节变化：北半球夏季主要来自南方，冬季主要来自北方，与海浪气候同步。  </li>\n<li>在 0.09–0.14 Hz 观察到线性“频散条纹”，频率随时间斜升，斜率与深海重力波群速 ug &#x3D; gT&#x2F;4π 一致，为首次在单台极化数据中出现。  </li>\n<li>与海浪模型对比：实测 BAZ 指向与理论 SM 源区方向总体吻合，季节变化一致，相关系数视觉高于 0.8。  </li>\n<li>内陆站（如 TAM）季节信号最清晰；沿海站受近岸源影响，BAZ 分布带宽约 90°。</li>\n</ol>\n<hr>\n<h3 id=\"本文创新点与贡献\"><a href=\"#本文创新点与贡献\" class=\"headerlink\" title=\"本文创新点与贡献\"></a>本文创新点与贡献</h3><ol>\n<li>方法创新：首次将“时频椭圆极化度 + DOP 阈值”用于 7 年全球连续噪声，实现单台站方向测量。  </li>\n<li>观测创新：  <ul>\n<li>提出“极化谱”概念，量化地脉动极化强度随频率分布；  </li>\n<li>首次在单台极化结果中观察到海浪群速引起的线性频散条纹。</li>\n</ul>\n</li>\n<li>验证创新：将地震极化 BAZ 与完全独立的海浪模型（含海岸线反射）进行系统季节对比，证明 BAZ 稳健。  </li>\n<li>应用潜力：为噪声层析提供方向偏差校正；为海洋风暴&#x2F;气候监测提供新手段；指导海底或岸基临时台站选址。</li>\n</ol>\n<hr>\n<h3 id=\"本文不足与未来展望\"><a href=\"#本文不足与未来展望\" class=\"headerlink\" title=\"本文不足与未来展望\"></a>本文不足与未来展望</h3><ol>\n<li>仅使用 1 sps 长周期数据，未分析 0.5–1.4 Hz 高频体波微地震——可提高采样率，联合 P 波微地震研究。  </li>\n<li>DOP 阈值与指数 n 人为选取，可能影响信号数量——未来可采用自适应或机器学习优化阈值。  </li>\n<li>海浪模型为“理论源”，未同步反演源强度与 BAZ——可发展联合反演，实现源区强度-方向同时成像。  </li>\n<li>未考虑地壳各向异性或三维结构对 BAZ 的偏折——可引入三维地壳模型进行射线校正。  </li>\n<li>目前仅针对瑞利波椭圆极化，未系统研究 Love 波极化——可开发 Love-Rayleigh 分离方法，探讨 Love 波源区特征。</li>\n</ol>"},{"title":"计算背景噪声中噪声源背方位角","abbrlink":"6c30a2ea","date":"2025-10-24T02:24:39.000Z","_content":"&emsp;&emsp;DOP-E 单站极化与背方位角分析流程  \n<!--less-->\n*(基于论文 Schimmel et al., 2011; Berbellini et al., 2019)*  \n## 一、总体流程概述\n\n1. **数据预处理**（去趋势、去仪器、对齐）  \n2. **S-transform 时频分解**（论文定义）  \n3. **构造谱矩阵与时域平滑**  \n4. **本征分解求极化参数（DOP、planarity、semimajor axis）**  \n5. **筛选高质量段**（DOP > 阈值 & planarity 接近水平）  \n6. **计算背方位角（BAZ）并解除 180° 二义性**  \n7. **输出可视化与统计**（时频图、直方图、极坐标图）  \n8. **验证与质量控制（QA）**  \n9. **批量与性能优化**\n\n---\n\n## 二、数据预处理\n\n### 目标\n确保三分量（Z/N/E）记录在同一时间基线，且仅保留稳定的噪声段。\n\n### 步骤\n1. **去仪器响应**  \n   - 若记录为速度，直接使用；否则用 RESP 文件去响应。  \n   - 理由：相位一致性影响极化矩阵。\n\n2. **去趋势 / 去均值**  \n   - `trace.detrend(\"linear\"); trace.detrend(\"demean\")`  \n   - 理由：低频漂移会污染低频段（0.03 Hz）。\n\n3. **剔除事件或脉冲干扰**  \n   - 可通过短时能量（STA/LTA）检测排除瞬变。\n\n4. **带通滤波**  \n   - 推荐：`0.01–0.06 Hz` （若仅关心 0.03 Hz 区域）。  \n   - 理由：去掉无关频段以提高信噪比。\n\n5. **时间对齐与补零**  \n   - 三分量必须同起止时刻；短 gap 可补零，长 gap 建议跳过。\n\n---\n\n## 三、S-transform（论文规范实现）\n\n### 定义\n$$\nS(t,f)=\\int x(\\tau)\\frac{|f|}{\\sqrt{2\\pi}}e^{-(t-\\tau)^2f^2/2}e^{-i2\\pi f\\tau}d\\tau\n$$\n\n### 参数与理由\n| 参数 | 推荐值 | 理由 |\n|------|--------|------|\n| 频率点数 `n_freqs` | 60 | 覆盖 0.01–0.06 Hz 区间，低频对数分辨率更合理 |\n| 窗宽 σ | 1/(2πf) | 论文定义，时间-频率能量守恒 |\n| 调整系数 k | 1.0–1.5 | 增大可提高时域平滑性 |\n| 下采样步长 step | 5 s | 提高计算效率，仍能解析 0.03 Hz（周期 33 s）信号 |\n\n> **说明**：  \n> σ = 1/(2πf) 表示随频率增加窗宽减小，确保多分辨率特性。  \n> |f|/√(2π) 为归一化系数，维持 Parseval 能量一致性。  \n\n---\n\n## 四、谱矩阵构造与平滑\n\n### 谱矩阵定义\n$$\nS_{ij}(t,f) = \\widetilde{X_i}(t,f)\\widetilde{X_j}^*(t,f)\n$$\n其中 $ \\widetilde{X_i}(t,f) $ 为分量 i 的 S-transform 复系数。\n\n### 平滑\n对时间方向做高斯平滑：\n$$\n\\sigma_{\\text{tf}} = \\text{tf\\_window\\_periods} \\times T \\times f_s\n$$\n\n| 参数 | 推荐值 | 理由 |\n|------|--------|------|\n| `tf_window_periods` | 3.0 | 论文示例值（2s ≈ 3T），平滑噪声但保留相干波 |\n| DOP 窗长度 | `4 × T` | 保证至少 4 周期稳定极化，论文建议值 |\n\n---\n\n## 五、本征分解与极化属性\n\n对每个 (t,f) 做 3×3 复矩阵本征分解：\n$$\nS = V \\Lambda V^H,\\quad \\Lambda = \\operatorname{diag}(\\lambda_1,\\lambda_2,\\lambda_3)\n$$\n\n### DOP（Degree of Polarization）\n$$\n\\mathrm{DOP} = \\frac{\\lambda_1 - \\lambda_2}{\\lambda_1 + \\lambda_2 + \\lambda_3}\n$$\n\n### Planarity\n通过主、次特征向量叉积求平面法线，与竖直方向夹角 α：\n- 若 α ≈ 90° → 水平 planarity（Rayleigh 波特征）  \n- 若 α ≈ 0° → 垂直平面（Love 波或噪声）\n\n| 参数 | 推荐值 | 理由 |\n|------|--------|------|\n| `dop_thresh` | 0.8 | 论文常用 0.75–0.85；取 0.8 折中稳健 |\n| `alpha_min` | 60° | 仅保留水平 planarity |\n\n---\n\n## 六、背方位角（BAZ）计算\n\n### 公式\n$$\n\\mathrm{BAZ} = \\operatorname{atan2}(E, N)\n$$\n以度为单位，0° = 北，顺时针增加。\n\n### 处理细节\n- 使用主特征向量的水平分量 (N,E)。  \n- 实部幅值过小则跳过或使用相位差法。  \n- 输出角度范围 [0, 360°)。\n\n### 二义性处理\n- 单站存在 ±180° 二义性。  \n- **假设 retrograde（瑞利波基模）**，可选反向修正：若竖直与水平分量相位差 ~180°，翻转 BAZ。\n\n---\n\n## 七、筛选与聚合输出\n\n### 筛选规则\n```text\nDOP >= 0.8\nplanarity_angle > 60°\n```\n\n## 八、脚本\n```\n#!/usr/bin/env python3\n\"\"\"\nDOP-E style polarization + BAZ extraction using paper-consistent S-transform\nImplements Schimmel et al. (2011) S-transform definition with speed optimizations (Numba).\n\nUsage:\n    python dop_e_st_paper.py /path/to/sac_dir --target-freq 0.03 --outs out\n\nReferences:\n- Schimmel, Stutzmann, Ardhuin & Gallart (2011), Polarized Earth's ambient microseismic noise, G³\n\"\"\"\nimport os\nimport glob\nimport argparse\nfrom collections import defaultdict\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom obspy import read\nfrom scipy.signal import get_window\nfrom numba import njit, prange\nimport math\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")\n\n# ======================================================\n# S-transform implementation per Schimmel et al. (2011)\n# ======================================================\n\ndef s_transform(x, fs, freqs, pad=True):\n    \"\"\"\n    Paper-consistent S-transform:\n    S(t,f) = ∫ x(τ) * |f|/√(2π) * exp[-(t-τ)^2 f^2 / 2] * exp[-i2π f τ] dτ\n    Implemented via FFT multiplication.\n    \"\"\"\n    n = len(x)\n    dt = 1.0 / fs\n    if pad:\n        Nfft = 1 << ((2 * n - 1).bit_length())\n    else:\n        Nfft = n\n    t = np.arange(n) * dt\n    X = np.fft.fft(x, n=Nfft)\n    freqs_fft = np.fft.fftfreq(Nfft, d=dt)\n\n    S = np.zeros((len(freqs), n), dtype=np.complex128)\n    # time index array\n    for i, f in enumerate(freqs):\n        if f <= 0:\n            continue\n        # build Gaussian window in frequency domain for convolution\n        # Using exact analytical equivalence:\n        # G(f') = exp[-2π^2 (f'-f)^2 / f^2]\n        g_f = np.exp(-2.0 * (np.pi ** 2) * ((freqs_fft - f) ** 2) / (f ** 2))\n        # convolution via inverse FFT\n        s_ifft = np.fft.ifft(X * g_f, n=Nfft)\n        s_ifft = s_ifft[:n]\n        # normalization factor |f|/sqrt(2π)\n        S[i, :] = (abs(f) / np.sqrt(2.0 * np.pi)) * s_ifft * np.exp(1j * 2 * np.pi * f * t)\n    return S\n\n\n# ======================================================\n# Polarization & BAZ analysis (Numba optimized)\n# ======================================================\n\n@njit(parallel=True, fastmath=True)\ndef compute_dop_baz(cz, cn, ce, periods, fs, dop_thresh):\n    nfr, nt = cz.shape\n    DOP = np.zeros((nfr, nt))\n    BAZ = np.full((nfr, nt), np.nan)\n    QUALITY = np.zeros((nfr, nt))\n\n    for ifr in prange(nfr):\n        for it in range(nt):\n            # spectral matrix (3x3)\n            Z = cz[ifr, it]\n            N = cn[ifr, it]\n            E = ce[ifr, it]\n            S00 = (Z * np.conj(Z)).real\n            S01 = (Z * np.conj(N))\n            S02 = (Z * np.conj(E))\n            S11 = (N * np.conj(N)).real\n            S12 = (N * np.conj(E))\n            S22 = (E * np.conj(E)).real\n\n            # Hermitian matrix\n            S = np.array([[S00, S01.real, S02.real],\n                          [S01.real, S11, S12.real],\n                          [S02.real, S12.real, S22]], dtype=np.float64)\n\n            # eigen decomposition\n            w, v = np.linalg.eigh(S)\n            idx = np.argsort(w)[::-1]\n            w = w[idx]\n            v = v[:, idx]\n            # DOP = (λ1 - λ2)/(λ1+λ2+λ3)\n            denom = w.sum()\n            if denom <= 0:\n                dop_val = 0.0\n            else:\n                dop_val = (w[0] - w[1]) / denom\n                if dop_val < 0:\n                    dop_val = 0.0\n                elif dop_val > 1.0:\n                    dop_val = 1.0\n            DOP[ifr, it] = dop_val\n\n            if dop_val < dop_thresh:\n                continue\n\n            # horizontal azimuth from first eigenvector (v[:,0])\n            a = v[:, 0]\n            rn = a[1]\n            re = a[2]\n            az = math.degrees(math.atan2(re, rn))\n            if az < 0:\n                az += 360.0\n            BAZ[ifr, it] = az\n            QUALITY[ifr, it] = 1\n\n    return DOP, BAZ, QUALITY\n\n\n# ======================================================\n# DOPAnalyzer class\n# ======================================================\n\nclass DOPAnalyzer:\n    def __init__(self, fs=1.0, target_freq=None, freq_band=None,\n                 dop_thresh=0.8, n_freqs=80, step=1):\n        \"\"\"\n        Parameters:\n            fs: sampling rate\n            target_freq: center frequency (Hz)\n            freq_band: (fmin,fmax)\n            dop_thresh: threshold\n            n_freqs: number of frequency points\n            step: downsample factor for time (e.g. 5 -> 5 s resolution)\n        \"\"\"\n        self.fs = fs\n        self.dt = 1.0 / fs\n        self.target_freq = target_freq\n        self.freq_band = freq_band\n        self.dop_thresh = dop_thresh\n        self.n_freqs = n_freqs\n        self.step = step\n\n    def _read_triple(self, fz, fn, fe):\n        stz = read(fz)[0]\n        stn = read(fn)[0]\n        ste = read(fe)[0]\n        start = max(stz.stats.starttime, stn.stats.starttime, ste.stats.starttime)\n        end = min(stz.stats.endtime, stn.stats.endtime, ste.stats.endtime)\n        stz.trim(start, end)\n        stn.trim(start, end)\n        ste.trim(start, end)\n        return stz.data.astype(float), stn.data.astype(float), ste.data.astype(float), stz.stats\n\n    def _choose_freqs(self):\n        if self.freq_band:\n            fmin, fmax = self.freq_band\n        elif self.target_freq:\n            fmin = self.target_freq * 0.8\n            fmax = self.target_freq * 1.2\n        else:\n            fmin, fmax = 0.005, 0.25\n        freqs = np.logspace(np.log10(fmin), np.log10(fmax), self.n_freqs)\n        return freqs\n\n    def analyze_triple(self, z, n, e):\n        npts = len(z)\n        tvec = np.arange(0, npts, self.step) / self.fs\n        freqs = self._choose_freqs()\n        periods = 1.0 / freqs\n\n        cz = s_transform(z, self.fs, freqs)\n        cn = s_transform(n, self.fs, freqs)\n        ce = s_transform(e, self.fs, freqs)\n\n        # downsample in time for speed\n        cz = cz[:, ::self.step]\n        cn = cn[:, ::self.step]\n        ce = ce[:, ::self.step]\n\n        DOP, BAZ, QUALITY = compute_dop_baz(cz, cn, ce, periods, self.fs, self.dop_thresh)\n\n        return {\"times\": tvec, \"freqs\": freqs, \"DOP\": DOP, \"BAZ\": BAZ, \"QUALITY\": QUALITY}\n\n    def plot_results(self, res, out_prefix=\"result\", target_freq=None):\n        times = res[\"times\"]\n        freqs = res[\"freqs\"]\n        DOP = res[\"DOP\"]\n        BAZ = res[\"BAZ\"]\n        Q = res[\"QUALITY\"]\n\n        t_hr = times / 3600.0\n\n        plt.figure(figsize=(12, 4))\n        plt.pcolormesh(t_hr, freqs, DOP, shading=\"auto\")\n        plt.colorbar(label=\"DOP\")\n        plt.yscale(\"log\")\n        plt.ylabel(\"Frequency (Hz)\")\n        plt.xlabel(\"Time (hours)\")\n        plt.title(\"DOP (S-transform)\")\n        plt.tight_layout()\n        plt.savefig(out_prefix + \"_DOP.png\", dpi=200)\n\n        plt.figure(figsize=(12, 4))\n        baz_masked = np.where(Q > 0, BAZ, np.nan)\n        plt.pcolormesh(t_hr, freqs, baz_masked, shading=\"auto\", cmap=\"hsv\", vmin=0, vmax=360)\n        plt.colorbar(label=\"Back Azimuth (°)\")\n        plt.yscale(\"log\")\n        plt.ylabel(\"Frequency (Hz)\")\n        plt.xlabel(\"Time (hours)\")\n        plt.title(f\"BAZ (DOP>{self.dop_thresh})\")\n        plt.tight_layout()\n        plt.savefig(out_prefix + \"_BAZ_timefreq.png\", dpi=200)\n\n        if target_freq is not None:\n            idx = np.argmin(np.abs(freqs - target_freq))\n            baz_vals = BAZ[idx, Q[idx, :] > 0]\n        else:\n            baz_vals = BAZ[Q > 0]\n\n        plt.figure(figsize=(6, 4))\n        plt.hist(baz_vals[~np.isnan(baz_vals)], bins=np.arange(0, 361, 10))\n        plt.xlabel(\"Back Azimuth (°)\")\n        plt.ylabel(\"Count\")\n        plt.title(\"BAZ Histogram\")\n        plt.tight_layout()\n        plt.savefig(out_prefix + \"_BAZ_hist.png\", dpi=200)\n        plt.close(\"all\")\n\n\n# ======================================================\n# Utility: find 3-component sets\n# ======================================================\n\ndef find_triples_in_dir(sac_dir):\n    files = glob.glob(os.path.join(sac_dir, \"*.SAC\")) + glob.glob(os.path.join(sac_dir, \"*.sac\"))\n    idx = defaultdict(dict)\n    for f in files:\n        b = os.path.basename(f)\n        up = b.upper()\n        if \"LHZ\" in up or \"HZ\" in up:\n            base = up.replace(\"LHZ\", \"\").replace(\"HZ\", \"\").strip(\"_\")\n            idx[base][\"Z\"] = f\n        elif \"LHN\" in up or \"HN\" in up:\n            base = up.replace(\"LHN\", \"\").replace(\"HN\", \"\").strip(\"_\")\n            idx[base][\"N\"] = f\n        elif \"LHE\" in up or \"HE\" in up:\n            base = up.replace(\"LHE\", \"\").replace(\"HE\", \"\").strip(\"_\")\n            idx[base][\"E\"] = f\n    triples = []\n    for base, d in idx.items():\n        if all(k in d for k in (\"Z\", \"N\", \"E\")):\n            triples.append((base, d[\"Z\"], d[\"N\"], d[\"E\"]))\n    return triples\n\n\n# ======================================================\n# Main\n# ======================================================\n\nif __name__ == \"__main__\":\n    p = argparse.ArgumentParser(description=\"DOP-E S-transform (paper consistent, optimized)\")\n    p.add_argument(\"sacdir\", help=\"Directory with 3-component SAC files\")\n    p.add_argument(\"--target-freq\", type=float, default=0.03, help=\"Center frequency (Hz)\")\n    p.add_argument(\"--fmin\", type=float, default=None, help=\"Min frequency\")\n    p.add_argument(\"--fmax\", type=float, default=None, help=\"Max frequency\")\n    p.add_argument(\"--outs\", default=\"out\", help=\"Output prefix\")\n    p.add_argument(\"--dop-thresh\", type=float, default=0.8, help=\"DOP threshold\")\n    p.add_argument(\"--n-freqs\", type=int, default=60, help=\"Number of frequency points\")\n    p.add_argument(\"--step\", type=int, default=5, help=\"Downsample step for time (1 = full)\")\n    args = p.parse_args()\n\n    triples = find_triples_in_dir(args.sacdir)\n    if not triples:\n        print(\"No 3-component SAC sets found.\")\n        raise SystemExit\n\n    for base, fz, fn, fe in triples:\n        print(\"Processing:\", base)\n        z, n, e, stats = DOPAnalyzer()._read_triple(fz, fn, fe)\n        fs = stats.sampling_rate\n        if args.fmin and args.fmax:\n            freq_band = (args.fmin, args.fmax)\n        else:\n            freq_band = None\n        analyzer = DOPAnalyzer(fs=fs,\n                               target_freq=args.target_freq,\n                               freq_band=freq_band,\n                               dop_thresh=args.dop_thresh,\n                               n_freqs=args.n_freqs,\n                               step=args.step)\n        res = analyzer.analyze_triple(z, n, e)\n        outpref = f\"{args.outs}_{base}\"\n        analyzer.plot_results(res, out_prefix=outpref, target_freq=args.target_freq)\n        print(\"Saved:\", outpref)\n```\n","source":"_posts/2025-10-24-noise-source-back-azimuth.md","raw":"---\ntitle: 计算背景噪声中噪声源背方位角\ntags:\n  - work\ncategories:\n  - work\nabbrlink: 6c30a2ea\ndate: 2025-10-24 10:24:39\n---\n&emsp;&emsp;DOP-E 单站极化与背方位角分析流程  \n<!--less-->\n*(基于论文 Schimmel et al., 2011; Berbellini et al., 2019)*  \n## 一、总体流程概述\n\n1. **数据预处理**（去趋势、去仪器、对齐）  \n2. **S-transform 时频分解**（论文定义）  \n3. **构造谱矩阵与时域平滑**  \n4. **本征分解求极化参数（DOP、planarity、semimajor axis）**  \n5. **筛选高质量段**（DOP > 阈值 & planarity 接近水平）  \n6. **计算背方位角（BAZ）并解除 180° 二义性**  \n7. **输出可视化与统计**（时频图、直方图、极坐标图）  \n8. **验证与质量控制（QA）**  \n9. **批量与性能优化**\n\n---\n\n## 二、数据预处理\n\n### 目标\n确保三分量（Z/N/E）记录在同一时间基线，且仅保留稳定的噪声段。\n\n### 步骤\n1. **去仪器响应**  \n   - 若记录为速度，直接使用；否则用 RESP 文件去响应。  \n   - 理由：相位一致性影响极化矩阵。\n\n2. **去趋势 / 去均值**  \n   - `trace.detrend(\"linear\"); trace.detrend(\"demean\")`  \n   - 理由：低频漂移会污染低频段（0.03 Hz）。\n\n3. **剔除事件或脉冲干扰**  \n   - 可通过短时能量（STA/LTA）检测排除瞬变。\n\n4. **带通滤波**  \n   - 推荐：`0.01–0.06 Hz` （若仅关心 0.03 Hz 区域）。  \n   - 理由：去掉无关频段以提高信噪比。\n\n5. **时间对齐与补零**  \n   - 三分量必须同起止时刻；短 gap 可补零，长 gap 建议跳过。\n\n---\n\n## 三、S-transform（论文规范实现）\n\n### 定义\n$$\nS(t,f)=\\int x(\\tau)\\frac{|f|}{\\sqrt{2\\pi}}e^{-(t-\\tau)^2f^2/2}e^{-i2\\pi f\\tau}d\\tau\n$$\n\n### 参数与理由\n| 参数 | 推荐值 | 理由 |\n|------|--------|------|\n| 频率点数 `n_freqs` | 60 | 覆盖 0.01–0.06 Hz 区间，低频对数分辨率更合理 |\n| 窗宽 σ | 1/(2πf) | 论文定义，时间-频率能量守恒 |\n| 调整系数 k | 1.0–1.5 | 增大可提高时域平滑性 |\n| 下采样步长 step | 5 s | 提高计算效率，仍能解析 0.03 Hz（周期 33 s）信号 |\n\n> **说明**：  \n> σ = 1/(2πf) 表示随频率增加窗宽减小，确保多分辨率特性。  \n> |f|/√(2π) 为归一化系数，维持 Parseval 能量一致性。  \n\n---\n\n## 四、谱矩阵构造与平滑\n\n### 谱矩阵定义\n$$\nS_{ij}(t,f) = \\widetilde{X_i}(t,f)\\widetilde{X_j}^*(t,f)\n$$\n其中 $ \\widetilde{X_i}(t,f) $ 为分量 i 的 S-transform 复系数。\n\n### 平滑\n对时间方向做高斯平滑：\n$$\n\\sigma_{\\text{tf}} = \\text{tf\\_window\\_periods} \\times T \\times f_s\n$$\n\n| 参数 | 推荐值 | 理由 |\n|------|--------|------|\n| `tf_window_periods` | 3.0 | 论文示例值（2s ≈ 3T），平滑噪声但保留相干波 |\n| DOP 窗长度 | `4 × T` | 保证至少 4 周期稳定极化，论文建议值 |\n\n---\n\n## 五、本征分解与极化属性\n\n对每个 (t,f) 做 3×3 复矩阵本征分解：\n$$\nS = V \\Lambda V^H,\\quad \\Lambda = \\operatorname{diag}(\\lambda_1,\\lambda_2,\\lambda_3)\n$$\n\n### DOP（Degree of Polarization）\n$$\n\\mathrm{DOP} = \\frac{\\lambda_1 - \\lambda_2}{\\lambda_1 + \\lambda_2 + \\lambda_3}\n$$\n\n### Planarity\n通过主、次特征向量叉积求平面法线，与竖直方向夹角 α：\n- 若 α ≈ 90° → 水平 planarity（Rayleigh 波特征）  \n- 若 α ≈ 0° → 垂直平面（Love 波或噪声）\n\n| 参数 | 推荐值 | 理由 |\n|------|--------|------|\n| `dop_thresh` | 0.8 | 论文常用 0.75–0.85；取 0.8 折中稳健 |\n| `alpha_min` | 60° | 仅保留水平 planarity |\n\n---\n\n## 六、背方位角（BAZ）计算\n\n### 公式\n$$\n\\mathrm{BAZ} = \\operatorname{atan2}(E, N)\n$$\n以度为单位，0° = 北，顺时针增加。\n\n### 处理细节\n- 使用主特征向量的水平分量 (N,E)。  \n- 实部幅值过小则跳过或使用相位差法。  \n- 输出角度范围 [0, 360°)。\n\n### 二义性处理\n- 单站存在 ±180° 二义性。  \n- **假设 retrograde（瑞利波基模）**，可选反向修正：若竖直与水平分量相位差 ~180°，翻转 BAZ。\n\n---\n\n## 七、筛选与聚合输出\n\n### 筛选规则\n```text\nDOP >= 0.8\nplanarity_angle > 60°\n```\n\n## 八、脚本\n```\n#!/usr/bin/env python3\n\"\"\"\nDOP-E style polarization + BAZ extraction using paper-consistent S-transform\nImplements Schimmel et al. (2011) S-transform definition with speed optimizations (Numba).\n\nUsage:\n    python dop_e_st_paper.py /path/to/sac_dir --target-freq 0.03 --outs out\n\nReferences:\n- Schimmel, Stutzmann, Ardhuin & Gallart (2011), Polarized Earth's ambient microseismic noise, G³\n\"\"\"\nimport os\nimport glob\nimport argparse\nfrom collections import defaultdict\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom obspy import read\nfrom scipy.signal import get_window\nfrom numba import njit, prange\nimport math\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")\n\n# ======================================================\n# S-transform implementation per Schimmel et al. (2011)\n# ======================================================\n\ndef s_transform(x, fs, freqs, pad=True):\n    \"\"\"\n    Paper-consistent S-transform:\n    S(t,f) = ∫ x(τ) * |f|/√(2π) * exp[-(t-τ)^2 f^2 / 2] * exp[-i2π f τ] dτ\n    Implemented via FFT multiplication.\n    \"\"\"\n    n = len(x)\n    dt = 1.0 / fs\n    if pad:\n        Nfft = 1 << ((2 * n - 1).bit_length())\n    else:\n        Nfft = n\n    t = np.arange(n) * dt\n    X = np.fft.fft(x, n=Nfft)\n    freqs_fft = np.fft.fftfreq(Nfft, d=dt)\n\n    S = np.zeros((len(freqs), n), dtype=np.complex128)\n    # time index array\n    for i, f in enumerate(freqs):\n        if f <= 0:\n            continue\n        # build Gaussian window in frequency domain for convolution\n        # Using exact analytical equivalence:\n        # G(f') = exp[-2π^2 (f'-f)^2 / f^2]\n        g_f = np.exp(-2.0 * (np.pi ** 2) * ((freqs_fft - f) ** 2) / (f ** 2))\n        # convolution via inverse FFT\n        s_ifft = np.fft.ifft(X * g_f, n=Nfft)\n        s_ifft = s_ifft[:n]\n        # normalization factor |f|/sqrt(2π)\n        S[i, :] = (abs(f) / np.sqrt(2.0 * np.pi)) * s_ifft * np.exp(1j * 2 * np.pi * f * t)\n    return S\n\n\n# ======================================================\n# Polarization & BAZ analysis (Numba optimized)\n# ======================================================\n\n@njit(parallel=True, fastmath=True)\ndef compute_dop_baz(cz, cn, ce, periods, fs, dop_thresh):\n    nfr, nt = cz.shape\n    DOP = np.zeros((nfr, nt))\n    BAZ = np.full((nfr, nt), np.nan)\n    QUALITY = np.zeros((nfr, nt))\n\n    for ifr in prange(nfr):\n        for it in range(nt):\n            # spectral matrix (3x3)\n            Z = cz[ifr, it]\n            N = cn[ifr, it]\n            E = ce[ifr, it]\n            S00 = (Z * np.conj(Z)).real\n            S01 = (Z * np.conj(N))\n            S02 = (Z * np.conj(E))\n            S11 = (N * np.conj(N)).real\n            S12 = (N * np.conj(E))\n            S22 = (E * np.conj(E)).real\n\n            # Hermitian matrix\n            S = np.array([[S00, S01.real, S02.real],\n                          [S01.real, S11, S12.real],\n                          [S02.real, S12.real, S22]], dtype=np.float64)\n\n            # eigen decomposition\n            w, v = np.linalg.eigh(S)\n            idx = np.argsort(w)[::-1]\n            w = w[idx]\n            v = v[:, idx]\n            # DOP = (λ1 - λ2)/(λ1+λ2+λ3)\n            denom = w.sum()\n            if denom <= 0:\n                dop_val = 0.0\n            else:\n                dop_val = (w[0] - w[1]) / denom\n                if dop_val < 0:\n                    dop_val = 0.0\n                elif dop_val > 1.0:\n                    dop_val = 1.0\n            DOP[ifr, it] = dop_val\n\n            if dop_val < dop_thresh:\n                continue\n\n            # horizontal azimuth from first eigenvector (v[:,0])\n            a = v[:, 0]\n            rn = a[1]\n            re = a[2]\n            az = math.degrees(math.atan2(re, rn))\n            if az < 0:\n                az += 360.0\n            BAZ[ifr, it] = az\n            QUALITY[ifr, it] = 1\n\n    return DOP, BAZ, QUALITY\n\n\n# ======================================================\n# DOPAnalyzer class\n# ======================================================\n\nclass DOPAnalyzer:\n    def __init__(self, fs=1.0, target_freq=None, freq_band=None,\n                 dop_thresh=0.8, n_freqs=80, step=1):\n        \"\"\"\n        Parameters:\n            fs: sampling rate\n            target_freq: center frequency (Hz)\n            freq_band: (fmin,fmax)\n            dop_thresh: threshold\n            n_freqs: number of frequency points\n            step: downsample factor for time (e.g. 5 -> 5 s resolution)\n        \"\"\"\n        self.fs = fs\n        self.dt = 1.0 / fs\n        self.target_freq = target_freq\n        self.freq_band = freq_band\n        self.dop_thresh = dop_thresh\n        self.n_freqs = n_freqs\n        self.step = step\n\n    def _read_triple(self, fz, fn, fe):\n        stz = read(fz)[0]\n        stn = read(fn)[0]\n        ste = read(fe)[0]\n        start = max(stz.stats.starttime, stn.stats.starttime, ste.stats.starttime)\n        end = min(stz.stats.endtime, stn.stats.endtime, ste.stats.endtime)\n        stz.trim(start, end)\n        stn.trim(start, end)\n        ste.trim(start, end)\n        return stz.data.astype(float), stn.data.astype(float), ste.data.astype(float), stz.stats\n\n    def _choose_freqs(self):\n        if self.freq_band:\n            fmin, fmax = self.freq_band\n        elif self.target_freq:\n            fmin = self.target_freq * 0.8\n            fmax = self.target_freq * 1.2\n        else:\n            fmin, fmax = 0.005, 0.25\n        freqs = np.logspace(np.log10(fmin), np.log10(fmax), self.n_freqs)\n        return freqs\n\n    def analyze_triple(self, z, n, e):\n        npts = len(z)\n        tvec = np.arange(0, npts, self.step) / self.fs\n        freqs = self._choose_freqs()\n        periods = 1.0 / freqs\n\n        cz = s_transform(z, self.fs, freqs)\n        cn = s_transform(n, self.fs, freqs)\n        ce = s_transform(e, self.fs, freqs)\n\n        # downsample in time for speed\n        cz = cz[:, ::self.step]\n        cn = cn[:, ::self.step]\n        ce = ce[:, ::self.step]\n\n        DOP, BAZ, QUALITY = compute_dop_baz(cz, cn, ce, periods, self.fs, self.dop_thresh)\n\n        return {\"times\": tvec, \"freqs\": freqs, \"DOP\": DOP, \"BAZ\": BAZ, \"QUALITY\": QUALITY}\n\n    def plot_results(self, res, out_prefix=\"result\", target_freq=None):\n        times = res[\"times\"]\n        freqs = res[\"freqs\"]\n        DOP = res[\"DOP\"]\n        BAZ = res[\"BAZ\"]\n        Q = res[\"QUALITY\"]\n\n        t_hr = times / 3600.0\n\n        plt.figure(figsize=(12, 4))\n        plt.pcolormesh(t_hr, freqs, DOP, shading=\"auto\")\n        plt.colorbar(label=\"DOP\")\n        plt.yscale(\"log\")\n        plt.ylabel(\"Frequency (Hz)\")\n        plt.xlabel(\"Time (hours)\")\n        plt.title(\"DOP (S-transform)\")\n        plt.tight_layout()\n        plt.savefig(out_prefix + \"_DOP.png\", dpi=200)\n\n        plt.figure(figsize=(12, 4))\n        baz_masked = np.where(Q > 0, BAZ, np.nan)\n        plt.pcolormesh(t_hr, freqs, baz_masked, shading=\"auto\", cmap=\"hsv\", vmin=0, vmax=360)\n        plt.colorbar(label=\"Back Azimuth (°)\")\n        plt.yscale(\"log\")\n        plt.ylabel(\"Frequency (Hz)\")\n        plt.xlabel(\"Time (hours)\")\n        plt.title(f\"BAZ (DOP>{self.dop_thresh})\")\n        plt.tight_layout()\n        plt.savefig(out_prefix + \"_BAZ_timefreq.png\", dpi=200)\n\n        if target_freq is not None:\n            idx = np.argmin(np.abs(freqs - target_freq))\n            baz_vals = BAZ[idx, Q[idx, :] > 0]\n        else:\n            baz_vals = BAZ[Q > 0]\n\n        plt.figure(figsize=(6, 4))\n        plt.hist(baz_vals[~np.isnan(baz_vals)], bins=np.arange(0, 361, 10))\n        plt.xlabel(\"Back Azimuth (°)\")\n        plt.ylabel(\"Count\")\n        plt.title(\"BAZ Histogram\")\n        plt.tight_layout()\n        plt.savefig(out_prefix + \"_BAZ_hist.png\", dpi=200)\n        plt.close(\"all\")\n\n\n# ======================================================\n# Utility: find 3-component sets\n# ======================================================\n\ndef find_triples_in_dir(sac_dir):\n    files = glob.glob(os.path.join(sac_dir, \"*.SAC\")) + glob.glob(os.path.join(sac_dir, \"*.sac\"))\n    idx = defaultdict(dict)\n    for f in files:\n        b = os.path.basename(f)\n        up = b.upper()\n        if \"LHZ\" in up or \"HZ\" in up:\n            base = up.replace(\"LHZ\", \"\").replace(\"HZ\", \"\").strip(\"_\")\n            idx[base][\"Z\"] = f\n        elif \"LHN\" in up or \"HN\" in up:\n            base = up.replace(\"LHN\", \"\").replace(\"HN\", \"\").strip(\"_\")\n            idx[base][\"N\"] = f\n        elif \"LHE\" in up or \"HE\" in up:\n            base = up.replace(\"LHE\", \"\").replace(\"HE\", \"\").strip(\"_\")\n            idx[base][\"E\"] = f\n    triples = []\n    for base, d in idx.items():\n        if all(k in d for k in (\"Z\", \"N\", \"E\")):\n            triples.append((base, d[\"Z\"], d[\"N\"], d[\"E\"]))\n    return triples\n\n\n# ======================================================\n# Main\n# ======================================================\n\nif __name__ == \"__main__\":\n    p = argparse.ArgumentParser(description=\"DOP-E S-transform (paper consistent, optimized)\")\n    p.add_argument(\"sacdir\", help=\"Directory with 3-component SAC files\")\n    p.add_argument(\"--target-freq\", type=float, default=0.03, help=\"Center frequency (Hz)\")\n    p.add_argument(\"--fmin\", type=float, default=None, help=\"Min frequency\")\n    p.add_argument(\"--fmax\", type=float, default=None, help=\"Max frequency\")\n    p.add_argument(\"--outs\", default=\"out\", help=\"Output prefix\")\n    p.add_argument(\"--dop-thresh\", type=float, default=0.8, help=\"DOP threshold\")\n    p.add_argument(\"--n-freqs\", type=int, default=60, help=\"Number of frequency points\")\n    p.add_argument(\"--step\", type=int, default=5, help=\"Downsample step for time (1 = full)\")\n    args = p.parse_args()\n\n    triples = find_triples_in_dir(args.sacdir)\n    if not triples:\n        print(\"No 3-component SAC sets found.\")\n        raise SystemExit\n\n    for base, fz, fn, fe in triples:\n        print(\"Processing:\", base)\n        z, n, e, stats = DOPAnalyzer()._read_triple(fz, fn, fe)\n        fs = stats.sampling_rate\n        if args.fmin and args.fmax:\n            freq_band = (args.fmin, args.fmax)\n        else:\n            freq_band = None\n        analyzer = DOPAnalyzer(fs=fs,\n                               target_freq=args.target_freq,\n                               freq_band=freq_band,\n                               dop_thresh=args.dop_thresh,\n                               n_freqs=args.n_freqs,\n                               step=args.step)\n        res = analyzer.analyze_triple(z, n, e)\n        outpref = f\"{args.outs}_{base}\"\n        analyzer.plot_results(res, out_prefix=outpref, target_freq=args.target_freq)\n        print(\"Saved:\", outpref)\n```\n","slug":"noise-source-back-azimuth","published":1,"updated":"2025-10-24T02:51:22.342Z","comments":1,"layout":"post","photos":[],"_id":"cmh498ir200i8wvouac8423u4","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p><em>(基于论文 Schimmel et al., 2011; Berbellini et al., 2019)</em>  </p>\n<h2 id=\"一、总体流程概述\"><a href=\"#一、总体流程概述\" class=\"headerlink\" title=\"一、总体流程概述\"></a>一、总体流程概述</h2><ol>\n<li><strong>数据预处理</strong>（去趋势、去仪器、对齐）  </li>\n<li><strong>S-transform 时频分解</strong>（论文定义）  </li>\n<li><strong>构造谱矩阵与时域平滑</strong>  </li>\n<li><strong>本征分解求极化参数（DOP、planarity、semimajor axis）</strong>  </li>\n<li><strong>筛选高质量段</strong>（DOP &gt; 阈值 &amp; planarity 接近水平）  </li>\n<li><strong>计算背方位角（BAZ）并解除 180° 二义性</strong>  </li>\n<li><strong>输出可视化与统计</strong>（时频图、直方图、极坐标图）  </li>\n<li><strong>验证与质量控制（QA）</strong>  </li>\n<li><strong>批量与性能优化</strong></li>\n</ol>\n<hr>\n<h2 id=\"二、数据预处理\"><a href=\"#二、数据预处理\" class=\"headerlink\" title=\"二、数据预处理\"></a>二、数据预处理</h2><h3 id=\"目标\"><a href=\"#目标\" class=\"headerlink\" title=\"目标\"></a>目标</h3><p>确保三分量（Z&#x2F;N&#x2F;E）记录在同一时间基线，且仅保留稳定的噪声段。</p>\n<h3 id=\"步骤\"><a href=\"#步骤\" class=\"headerlink\" title=\"步骤\"></a>步骤</h3><ol>\n<li><p><strong>去仪器响应</strong>  </p>\n<ul>\n<li>若记录为速度，直接使用；否则用 RESP 文件去响应。  </li>\n<li>理由：相位一致性影响极化矩阵。</li>\n</ul>\n</li>\n<li><p><strong>去趋势 &#x2F; 去均值</strong>  </p>\n<ul>\n<li><code>trace.detrend(&quot;linear&quot;); trace.detrend(&quot;demean&quot;)</code>  </li>\n<li>理由：低频漂移会污染低频段（0.03 Hz）。</li>\n</ul>\n</li>\n<li><p><strong>剔除事件或脉冲干扰</strong>  </p>\n<ul>\n<li>可通过短时能量（STA&#x2F;LTA）检测排除瞬变。</li>\n</ul>\n</li>\n<li><p><strong>带通滤波</strong>  </p>\n<ul>\n<li>推荐：<code>0.01–0.06 Hz</code> （若仅关心 0.03 Hz 区域）。  </li>\n<li>理由：去掉无关频段以提高信噪比。</li>\n</ul>\n</li>\n<li><p><strong>时间对齐与补零</strong>  </p>\n<ul>\n<li>三分量必须同起止时刻；短 gap 可补零，长 gap 建议跳过。</li>\n</ul>\n</li>\n</ol>\n<hr>\n<h2 id=\"三、S-transform（论文规范实现）\"><a href=\"#三、S-transform（论文规范实现）\" class=\"headerlink\" title=\"三、S-transform（论文规范实现）\"></a>三、S-transform（论文规范实现）</h2><h3 id=\"定义\"><a href=\"#定义\" class=\"headerlink\" title=\"定义\"></a>定义</h3><p>$$<br>S(t,f)&#x3D;\\int x(\\tau)\\frac{|f|}{\\sqrt{2\\pi}}e^{-(t-\\tau)^2f^2&#x2F;2}e^{-i2\\pi f\\tau}d\\tau<br>$$</p>\n<h3 id=\"参数与理由\"><a href=\"#参数与理由\" class=\"headerlink\" title=\"参数与理由\"></a>参数与理由</h3><table>\n<thead>\n<tr>\n<th>参数</th>\n<th>推荐值</th>\n<th>理由</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>频率点数 <code>n_freqs</code></td>\n<td>60</td>\n<td>覆盖 0.01–0.06 Hz 区间，低频对数分辨率更合理</td>\n</tr>\n<tr>\n<td>窗宽 σ</td>\n<td>1&#x2F;(2πf)</td>\n<td>论文定义，时间-频率能量守恒</td>\n</tr>\n<tr>\n<td>调整系数 k</td>\n<td>1.0–1.5</td>\n<td>增大可提高时域平滑性</td>\n</tr>\n<tr>\n<td>下采样步长 step</td>\n<td>5 s</td>\n<td>提高计算效率，仍能解析 0.03 Hz（周期 33 s）信号</td>\n</tr>\n</tbody></table>\n<blockquote>\n<p><strong>说明</strong>：<br>σ &#x3D; 1&#x2F;(2πf) 表示随频率增加窗宽减小，确保多分辨率特性。<br>|f|&#x2F;√(2π) 为归一化系数，维持 Parseval 能量一致性。  </p>\n</blockquote>\n<hr>\n<h2 id=\"四、谱矩阵构造与平滑\"><a href=\"#四、谱矩阵构造与平滑\" class=\"headerlink\" title=\"四、谱矩阵构造与平滑\"></a>四、谱矩阵构造与平滑</h2><h3 id=\"谱矩阵定义\"><a href=\"#谱矩阵定义\" class=\"headerlink\" title=\"谱矩阵定义\"></a>谱矩阵定义</h3><p>$$<br>S_{ij}(t,f) &#x3D; \\widetilde{X_i}(t,f)\\widetilde{X_j}^*(t,f)<br>$$<br>其中 $ \\widetilde{X_i}(t,f) $ 为分量 i 的 S-transform 复系数。</p>\n<h3 id=\"平滑\"><a href=\"#平滑\" class=\"headerlink\" title=\"平滑\"></a>平滑</h3><p>对时间方向做高斯平滑：<br>$$<br>\\sigma_{\\text{tf}} &#x3D; \\text{tf_window_periods} \\times T \\times f_s<br>$$</p>\n<table>\n<thead>\n<tr>\n<th>参数</th>\n<th>推荐值</th>\n<th>理由</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>tf_window_periods</code></td>\n<td>3.0</td>\n<td>论文示例值（2s ≈ 3T），平滑噪声但保留相干波</td>\n</tr>\n<tr>\n<td>DOP 窗长度</td>\n<td><code>4 × T</code></td>\n<td>保证至少 4 周期稳定极化，论文建议值</td>\n</tr>\n</tbody></table>\n<hr>\n<h2 id=\"五、本征分解与极化属性\"><a href=\"#五、本征分解与极化属性\" class=\"headerlink\" title=\"五、本征分解与极化属性\"></a>五、本征分解与极化属性</h2><p>对每个 (t,f) 做 3×3 复矩阵本征分解：<br>$$<br>S &#x3D; V \\Lambda V^H,\\quad \\Lambda &#x3D; \\operatorname{diag}(\\lambda_1,\\lambda_2,\\lambda_3)<br>$$</p>\n<h3 id=\"DOP（Degree-of-Polarization）\"><a href=\"#DOP（Degree-of-Polarization）\" class=\"headerlink\" title=\"DOP（Degree of Polarization）\"></a>DOP（Degree of Polarization）</h3><p>$$<br>\\mathrm{DOP} &#x3D; \\frac{\\lambda_1 - \\lambda_2}{\\lambda_1 + \\lambda_2 + \\lambda_3}<br>$$</p>\n<h3 id=\"Planarity\"><a href=\"#Planarity\" class=\"headerlink\" title=\"Planarity\"></a>Planarity</h3><p>通过主、次特征向量叉积求平面法线，与竖直方向夹角 α：</p>\n<ul>\n<li>若 α ≈ 90° → 水平 planarity（Rayleigh 波特征）  </li>\n<li>若 α ≈ 0° → 垂直平面（Love 波或噪声）</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>参数</th>\n<th>推荐值</th>\n<th>理由</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>dop_thresh</code></td>\n<td>0.8</td>\n<td>论文常用 0.75–0.85；取 0.8 折中稳健</td>\n</tr>\n<tr>\n<td><code>alpha_min</code></td>\n<td>60°</td>\n<td>仅保留水平 planarity</td>\n</tr>\n</tbody></table>\n<hr>\n<h2 id=\"六、背方位角（BAZ）计算\"><a href=\"#六、背方位角（BAZ）计算\" class=\"headerlink\" title=\"六、背方位角（BAZ）计算\"></a>六、背方位角（BAZ）计算</h2><h3 id=\"公式\"><a href=\"#公式\" class=\"headerlink\" title=\"公式\"></a>公式</h3><p>$$<br>\\mathrm{BAZ} &#x3D; \\operatorname{atan2}(E, N)<br>$$<br>以度为单位，0° &#x3D; 北，顺时针增加。</p>\n<h3 id=\"处理细节\"><a href=\"#处理细节\" class=\"headerlink\" title=\"处理细节\"></a>处理细节</h3><ul>\n<li>使用主特征向量的水平分量 (N,E)。  </li>\n<li>实部幅值过小则跳过或使用相位差法。  </li>\n<li>输出角度范围 [0, 360°)。</li>\n</ul>\n<h3 id=\"二义性处理\"><a href=\"#二义性处理\" class=\"headerlink\" title=\"二义性处理\"></a>二义性处理</h3><ul>\n<li>单站存在 ±180° 二义性。  </li>\n<li><strong>假设 retrograde（瑞利波基模）</strong>，可选反向修正：若竖直与水平分量相位差 ~180°，翻转 BAZ。</li>\n</ul>\n<hr>\n<h2 id=\"七、筛选与聚合输出\"><a href=\"#七、筛选与聚合输出\" class=\"headerlink\" title=\"七、筛选与聚合输出\"></a>七、筛选与聚合输出</h2><h3 id=\"筛选规则\"><a href=\"#筛选规则\" class=\"headerlink\" title=\"筛选规则\"></a>筛选规则</h3><figure class=\"highlight text\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">DOP &gt;= 0.8</span><br><span class=\"line\">planarity_angle &gt; 60°</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"八、脚本\"><a href=\"#八、脚本\" class=\"headerlink\" title=\"八、脚本\"></a>八、脚本</h2><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br><span class=\"line\">145</span><br><span class=\"line\">146</span><br><span class=\"line\">147</span><br><span class=\"line\">148</span><br><span class=\"line\">149</span><br><span class=\"line\">150</span><br><span class=\"line\">151</span><br><span class=\"line\">152</span><br><span class=\"line\">153</span><br><span class=\"line\">154</span><br><span class=\"line\">155</span><br><span class=\"line\">156</span><br><span class=\"line\">157</span><br><span class=\"line\">158</span><br><span class=\"line\">159</span><br><span class=\"line\">160</span><br><span class=\"line\">161</span><br><span class=\"line\">162</span><br><span class=\"line\">163</span><br><span class=\"line\">164</span><br><span class=\"line\">165</span><br><span class=\"line\">166</span><br><span class=\"line\">167</span><br><span class=\"line\">168</span><br><span class=\"line\">169</span><br><span class=\"line\">170</span><br><span class=\"line\">171</span><br><span class=\"line\">172</span><br><span class=\"line\">173</span><br><span class=\"line\">174</span><br><span class=\"line\">175</span><br><span class=\"line\">176</span><br><span class=\"line\">177</span><br><span class=\"line\">178</span><br><span class=\"line\">179</span><br><span class=\"line\">180</span><br><span class=\"line\">181</span><br><span class=\"line\">182</span><br><span class=\"line\">183</span><br><span class=\"line\">184</span><br><span class=\"line\">185</span><br><span class=\"line\">186</span><br><span class=\"line\">187</span><br><span class=\"line\">188</span><br><span class=\"line\">189</span><br><span class=\"line\">190</span><br><span class=\"line\">191</span><br><span class=\"line\">192</span><br><span class=\"line\">193</span><br><span class=\"line\">194</span><br><span class=\"line\">195</span><br><span class=\"line\">196</span><br><span class=\"line\">197</span><br><span class=\"line\">198</span><br><span class=\"line\">199</span><br><span class=\"line\">200</span><br><span class=\"line\">201</span><br><span class=\"line\">202</span><br><span class=\"line\">203</span><br><span class=\"line\">204</span><br><span class=\"line\">205</span><br><span class=\"line\">206</span><br><span class=\"line\">207</span><br><span class=\"line\">208</span><br><span class=\"line\">209</span><br><span class=\"line\">210</span><br><span class=\"line\">211</span><br><span class=\"line\">212</span><br><span class=\"line\">213</span><br><span class=\"line\">214</span><br><span class=\"line\">215</span><br><span class=\"line\">216</span><br><span class=\"line\">217</span><br><span class=\"line\">218</span><br><span class=\"line\">219</span><br><span class=\"line\">220</span><br><span class=\"line\">221</span><br><span class=\"line\">222</span><br><span class=\"line\">223</span><br><span class=\"line\">224</span><br><span class=\"line\">225</span><br><span class=\"line\">226</span><br><span class=\"line\">227</span><br><span class=\"line\">228</span><br><span class=\"line\">229</span><br><span class=\"line\">230</span><br><span class=\"line\">231</span><br><span class=\"line\">232</span><br><span class=\"line\">233</span><br><span class=\"line\">234</span><br><span class=\"line\">235</span><br><span class=\"line\">236</span><br><span class=\"line\">237</span><br><span class=\"line\">238</span><br><span class=\"line\">239</span><br><span class=\"line\">240</span><br><span class=\"line\">241</span><br><span class=\"line\">242</span><br><span class=\"line\">243</span><br><span class=\"line\">244</span><br><span class=\"line\">245</span><br><span class=\"line\">246</span><br><span class=\"line\">247</span><br><span class=\"line\">248</span><br><span class=\"line\">249</span><br><span class=\"line\">250</span><br><span class=\"line\">251</span><br><span class=\"line\">252</span><br><span class=\"line\">253</span><br><span class=\"line\">254</span><br><span class=\"line\">255</span><br><span class=\"line\">256</span><br><span class=\"line\">257</span><br><span class=\"line\">258</span><br><span class=\"line\">259</span><br><span class=\"line\">260</span><br><span class=\"line\">261</span><br><span class=\"line\">262</span><br><span class=\"line\">263</span><br><span class=\"line\">264</span><br><span class=\"line\">265</span><br><span class=\"line\">266</span><br><span class=\"line\">267</span><br><span class=\"line\">268</span><br><span class=\"line\">269</span><br><span class=\"line\">270</span><br><span class=\"line\">271</span><br><span class=\"line\">272</span><br><span class=\"line\">273</span><br><span class=\"line\">274</span><br><span class=\"line\">275</span><br><span class=\"line\">276</span><br><span class=\"line\">277</span><br><span class=\"line\">278</span><br><span class=\"line\">279</span><br><span class=\"line\">280</span><br><span class=\"line\">281</span><br><span class=\"line\">282</span><br><span class=\"line\">283</span><br><span class=\"line\">284</span><br><span class=\"line\">285</span><br><span class=\"line\">286</span><br><span class=\"line\">287</span><br><span class=\"line\">288</span><br><span class=\"line\">289</span><br><span class=\"line\">290</span><br><span class=\"line\">291</span><br><span class=\"line\">292</span><br><span class=\"line\">293</span><br><span class=\"line\">294</span><br><span class=\"line\">295</span><br><span class=\"line\">296</span><br><span class=\"line\">297</span><br><span class=\"line\">298</span><br><span class=\"line\">299</span><br><span class=\"line\">300</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#!/usr/bin/env python3</span><br><span class=\"line\">&quot;&quot;&quot;</span><br><span class=\"line\">DOP-E style polarization + BAZ extraction using paper-consistent S-transform</span><br><span class=\"line\">Implements Schimmel et al. (2011) S-transform definition with speed optimizations (Numba).</span><br><span class=\"line\"></span><br><span class=\"line\">Usage:</span><br><span class=\"line\">    python dop_e_st_paper.py /path/to/sac_dir --target-freq 0.03 --outs out</span><br><span class=\"line\"></span><br><span class=\"line\">References:</span><br><span class=\"line\">- Schimmel, Stutzmann, Ardhuin &amp; Gallart (2011), Polarized Earth&#x27;s ambient microseismic noise, G³</span><br><span class=\"line\">&quot;&quot;&quot;</span><br><span class=\"line\">import os</span><br><span class=\"line\">import glob</span><br><span class=\"line\">import argparse</span><br><span class=\"line\">from collections import defaultdict</span><br><span class=\"line\">import numpy as np</span><br><span class=\"line\">import matplotlib.pyplot as plt</span><br><span class=\"line\">from obspy import read</span><br><span class=\"line\">from scipy.signal import get_window</span><br><span class=\"line\">from numba import njit, prange</span><br><span class=\"line\">import math</span><br><span class=\"line\">import warnings</span><br><span class=\"line\"></span><br><span class=\"line\">warnings.filterwarnings(&quot;ignore&quot;)</span><br><span class=\"line\"></span><br><span class=\"line\"># ======================================================</span><br><span class=\"line\"># S-transform implementation per Schimmel et al. (2011)</span><br><span class=\"line\"># ======================================================</span><br><span class=\"line\"></span><br><span class=\"line\">def s_transform(x, fs, freqs, pad=True):</span><br><span class=\"line\">    &quot;&quot;&quot;</span><br><span class=\"line\">    Paper-consistent S-transform:</span><br><span class=\"line\">    S(t,f) = ∫ x(τ) * |f|/√(2π) * exp[-(t-τ)^2 f^2 / 2] * exp[-i2π f τ] dτ</span><br><span class=\"line\">    Implemented via FFT multiplication.</span><br><span class=\"line\">    &quot;&quot;&quot;</span><br><span class=\"line\">    n = len(x)</span><br><span class=\"line\">    dt = 1.0 / fs</span><br><span class=\"line\">    if pad:</span><br><span class=\"line\">        Nfft = 1 &lt;&lt; ((2 * n - 1).bit_length())</span><br><span class=\"line\">    else:</span><br><span class=\"line\">        Nfft = n</span><br><span class=\"line\">    t = np.arange(n) * dt</span><br><span class=\"line\">    X = np.fft.fft(x, n=Nfft)</span><br><span class=\"line\">    freqs_fft = np.fft.fftfreq(Nfft, d=dt)</span><br><span class=\"line\"></span><br><span class=\"line\">    S = np.zeros((len(freqs), n), dtype=np.complex128)</span><br><span class=\"line\">    # time index array</span><br><span class=\"line\">    for i, f in enumerate(freqs):</span><br><span class=\"line\">        if f &lt;= 0:</span><br><span class=\"line\">            continue</span><br><span class=\"line\">        # build Gaussian window in frequency domain for convolution</span><br><span class=\"line\">        # Using exact analytical equivalence:</span><br><span class=\"line\">        # G(f&#x27;) = exp[-2π^2 (f&#x27;-f)^2 / f^2]</span><br><span class=\"line\">        g_f = np.exp(-2.0 * (np.pi ** 2) * ((freqs_fft - f) ** 2) / (f ** 2))</span><br><span class=\"line\">        # convolution via inverse FFT</span><br><span class=\"line\">        s_ifft = np.fft.ifft(X * g_f, n=Nfft)</span><br><span class=\"line\">        s_ifft = s_ifft[:n]</span><br><span class=\"line\">        # normalization factor |f|/sqrt(2π)</span><br><span class=\"line\">        S[i, :] = (abs(f) / np.sqrt(2.0 * np.pi)) * s_ifft * np.exp(1j * 2 * np.pi * f * t)</span><br><span class=\"line\">    return S</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"># ======================================================</span><br><span class=\"line\"># Polarization &amp; BAZ analysis (Numba optimized)</span><br><span class=\"line\"># ======================================================</span><br><span class=\"line\"></span><br><span class=\"line\">@njit(parallel=True, fastmath=True)</span><br><span class=\"line\">def compute_dop_baz(cz, cn, ce, periods, fs, dop_thresh):</span><br><span class=\"line\">    nfr, nt = cz.shape</span><br><span class=\"line\">    DOP = np.zeros((nfr, nt))</span><br><span class=\"line\">    BAZ = np.full((nfr, nt), np.nan)</span><br><span class=\"line\">    QUALITY = np.zeros((nfr, nt))</span><br><span class=\"line\"></span><br><span class=\"line\">    for ifr in prange(nfr):</span><br><span class=\"line\">        for it in range(nt):</span><br><span class=\"line\">            # spectral matrix (3x3)</span><br><span class=\"line\">            Z = cz[ifr, it]</span><br><span class=\"line\">            N = cn[ifr, it]</span><br><span class=\"line\">            E = ce[ifr, it]</span><br><span class=\"line\">            S00 = (Z * np.conj(Z)).real</span><br><span class=\"line\">            S01 = (Z * np.conj(N))</span><br><span class=\"line\">            S02 = (Z * np.conj(E))</span><br><span class=\"line\">            S11 = (N * np.conj(N)).real</span><br><span class=\"line\">            S12 = (N * np.conj(E))</span><br><span class=\"line\">            S22 = (E * np.conj(E)).real</span><br><span class=\"line\"></span><br><span class=\"line\">            # Hermitian matrix</span><br><span class=\"line\">            S = np.array([[S00, S01.real, S02.real],</span><br><span class=\"line\">                          [S01.real, S11, S12.real],</span><br><span class=\"line\">                          [S02.real, S12.real, S22]], dtype=np.float64)</span><br><span class=\"line\"></span><br><span class=\"line\">            # eigen decomposition</span><br><span class=\"line\">            w, v = np.linalg.eigh(S)</span><br><span class=\"line\">            idx = np.argsort(w)[::-1]</span><br><span class=\"line\">            w = w[idx]</span><br><span class=\"line\">            v = v[:, idx]</span><br><span class=\"line\">            # DOP = (λ1 - λ2)/(λ1+λ2+λ3)</span><br><span class=\"line\">            denom = w.sum()</span><br><span class=\"line\">            if denom &lt;= 0:</span><br><span class=\"line\">                dop_val = 0.0</span><br><span class=\"line\">            else:</span><br><span class=\"line\">                dop_val = (w[0] - w[1]) / denom</span><br><span class=\"line\">                if dop_val &lt; 0:</span><br><span class=\"line\">                    dop_val = 0.0</span><br><span class=\"line\">                elif dop_val &gt; 1.0:</span><br><span class=\"line\">                    dop_val = 1.0</span><br><span class=\"line\">            DOP[ifr, it] = dop_val</span><br><span class=\"line\"></span><br><span class=\"line\">            if dop_val &lt; dop_thresh:</span><br><span class=\"line\">                continue</span><br><span class=\"line\"></span><br><span class=\"line\">            # horizontal azimuth from first eigenvector (v[:,0])</span><br><span class=\"line\">            a = v[:, 0]</span><br><span class=\"line\">            rn = a[1]</span><br><span class=\"line\">            re = a[2]</span><br><span class=\"line\">            az = math.degrees(math.atan2(re, rn))</span><br><span class=\"line\">            if az &lt; 0:</span><br><span class=\"line\">                az += 360.0</span><br><span class=\"line\">            BAZ[ifr, it] = az</span><br><span class=\"line\">            QUALITY[ifr, it] = 1</span><br><span class=\"line\"></span><br><span class=\"line\">    return DOP, BAZ, QUALITY</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"># ======================================================</span><br><span class=\"line\"># DOPAnalyzer class</span><br><span class=\"line\"># ======================================================</span><br><span class=\"line\"></span><br><span class=\"line\">class DOPAnalyzer:</span><br><span class=\"line\">    def __init__(self, fs=1.0, target_freq=None, freq_band=None,</span><br><span class=\"line\">                 dop_thresh=0.8, n_freqs=80, step=1):</span><br><span class=\"line\">        &quot;&quot;&quot;</span><br><span class=\"line\">        Parameters:</span><br><span class=\"line\">            fs: sampling rate</span><br><span class=\"line\">            target_freq: center frequency (Hz)</span><br><span class=\"line\">            freq_band: (fmin,fmax)</span><br><span class=\"line\">            dop_thresh: threshold</span><br><span class=\"line\">            n_freqs: number of frequency points</span><br><span class=\"line\">            step: downsample factor for time (e.g. 5 -&gt; 5 s resolution)</span><br><span class=\"line\">        &quot;&quot;&quot;</span><br><span class=\"line\">        self.fs = fs</span><br><span class=\"line\">        self.dt = 1.0 / fs</span><br><span class=\"line\">        self.target_freq = target_freq</span><br><span class=\"line\">        self.freq_band = freq_band</span><br><span class=\"line\">        self.dop_thresh = dop_thresh</span><br><span class=\"line\">        self.n_freqs = n_freqs</span><br><span class=\"line\">        self.step = step</span><br><span class=\"line\"></span><br><span class=\"line\">    def _read_triple(self, fz, fn, fe):</span><br><span class=\"line\">        stz = read(fz)[0]</span><br><span class=\"line\">        stn = read(fn)[0]</span><br><span class=\"line\">        ste = read(fe)[0]</span><br><span class=\"line\">        start = max(stz.stats.starttime, stn.stats.starttime, ste.stats.starttime)</span><br><span class=\"line\">        end = min(stz.stats.endtime, stn.stats.endtime, ste.stats.endtime)</span><br><span class=\"line\">        stz.trim(start, end)</span><br><span class=\"line\">        stn.trim(start, end)</span><br><span class=\"line\">        ste.trim(start, end)</span><br><span class=\"line\">        return stz.data.astype(float), stn.data.astype(float), ste.data.astype(float), stz.stats</span><br><span class=\"line\"></span><br><span class=\"line\">    def _choose_freqs(self):</span><br><span class=\"line\">        if self.freq_band:</span><br><span class=\"line\">            fmin, fmax = self.freq_band</span><br><span class=\"line\">        elif self.target_freq:</span><br><span class=\"line\">            fmin = self.target_freq * 0.8</span><br><span class=\"line\">            fmax = self.target_freq * 1.2</span><br><span class=\"line\">        else:</span><br><span class=\"line\">            fmin, fmax = 0.005, 0.25</span><br><span class=\"line\">        freqs = np.logspace(np.log10(fmin), np.log10(fmax), self.n_freqs)</span><br><span class=\"line\">        return freqs</span><br><span class=\"line\"></span><br><span class=\"line\">    def analyze_triple(self, z, n, e):</span><br><span class=\"line\">        npts = len(z)</span><br><span class=\"line\">        tvec = np.arange(0, npts, self.step) / self.fs</span><br><span class=\"line\">        freqs = self._choose_freqs()</span><br><span class=\"line\">        periods = 1.0 / freqs</span><br><span class=\"line\"></span><br><span class=\"line\">        cz = s_transform(z, self.fs, freqs)</span><br><span class=\"line\">        cn = s_transform(n, self.fs, freqs)</span><br><span class=\"line\">        ce = s_transform(e, self.fs, freqs)</span><br><span class=\"line\"></span><br><span class=\"line\">        # downsample in time for speed</span><br><span class=\"line\">        cz = cz[:, ::self.step]</span><br><span class=\"line\">        cn = cn[:, ::self.step]</span><br><span class=\"line\">        ce = ce[:, ::self.step]</span><br><span class=\"line\"></span><br><span class=\"line\">        DOP, BAZ, QUALITY = compute_dop_baz(cz, cn, ce, periods, self.fs, self.dop_thresh)</span><br><span class=\"line\"></span><br><span class=\"line\">        return &#123;&quot;times&quot;: tvec, &quot;freqs&quot;: freqs, &quot;DOP&quot;: DOP, &quot;BAZ&quot;: BAZ, &quot;QUALITY&quot;: QUALITY&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    def plot_results(self, res, out_prefix=&quot;result&quot;, target_freq=None):</span><br><span class=\"line\">        times = res[&quot;times&quot;]</span><br><span class=\"line\">        freqs = res[&quot;freqs&quot;]</span><br><span class=\"line\">        DOP = res[&quot;DOP&quot;]</span><br><span class=\"line\">        BAZ = res[&quot;BAZ&quot;]</span><br><span class=\"line\">        Q = res[&quot;QUALITY&quot;]</span><br><span class=\"line\"></span><br><span class=\"line\">        t_hr = times / 3600.0</span><br><span class=\"line\"></span><br><span class=\"line\">        plt.figure(figsize=(12, 4))</span><br><span class=\"line\">        plt.pcolormesh(t_hr, freqs, DOP, shading=&quot;auto&quot;)</span><br><span class=\"line\">        plt.colorbar(label=&quot;DOP&quot;)</span><br><span class=\"line\">        plt.yscale(&quot;log&quot;)</span><br><span class=\"line\">        plt.ylabel(&quot;Frequency (Hz)&quot;)</span><br><span class=\"line\">        plt.xlabel(&quot;Time (hours)&quot;)</span><br><span class=\"line\">        plt.title(&quot;DOP (S-transform)&quot;)</span><br><span class=\"line\">        plt.tight_layout()</span><br><span class=\"line\">        plt.savefig(out_prefix + &quot;_DOP.png&quot;, dpi=200)</span><br><span class=\"line\"></span><br><span class=\"line\">        plt.figure(figsize=(12, 4))</span><br><span class=\"line\">        baz_masked = np.where(Q &gt; 0, BAZ, np.nan)</span><br><span class=\"line\">        plt.pcolormesh(t_hr, freqs, baz_masked, shading=&quot;auto&quot;, cmap=&quot;hsv&quot;, vmin=0, vmax=360)</span><br><span class=\"line\">        plt.colorbar(label=&quot;Back Azimuth (°)&quot;)</span><br><span class=\"line\">        plt.yscale(&quot;log&quot;)</span><br><span class=\"line\">        plt.ylabel(&quot;Frequency (Hz)&quot;)</span><br><span class=\"line\">        plt.xlabel(&quot;Time (hours)&quot;)</span><br><span class=\"line\">        plt.title(f&quot;BAZ (DOP&gt;&#123;self.dop_thresh&#125;)&quot;)</span><br><span class=\"line\">        plt.tight_layout()</span><br><span class=\"line\">        plt.savefig(out_prefix + &quot;_BAZ_timefreq.png&quot;, dpi=200)</span><br><span class=\"line\"></span><br><span class=\"line\">        if target_freq is not None:</span><br><span class=\"line\">            idx = np.argmin(np.abs(freqs - target_freq))</span><br><span class=\"line\">            baz_vals = BAZ[idx, Q[idx, :] &gt; 0]</span><br><span class=\"line\">        else:</span><br><span class=\"line\">            baz_vals = BAZ[Q &gt; 0]</span><br><span class=\"line\"></span><br><span class=\"line\">        plt.figure(figsize=(6, 4))</span><br><span class=\"line\">        plt.hist(baz_vals[~np.isnan(baz_vals)], bins=np.arange(0, 361, 10))</span><br><span class=\"line\">        plt.xlabel(&quot;Back Azimuth (°)&quot;)</span><br><span class=\"line\">        plt.ylabel(&quot;Count&quot;)</span><br><span class=\"line\">        plt.title(&quot;BAZ Histogram&quot;)</span><br><span class=\"line\">        plt.tight_layout()</span><br><span class=\"line\">        plt.savefig(out_prefix + &quot;_BAZ_hist.png&quot;, dpi=200)</span><br><span class=\"line\">        plt.close(&quot;all&quot;)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"># ======================================================</span><br><span class=\"line\"># Utility: find 3-component sets</span><br><span class=\"line\"># ======================================================</span><br><span class=\"line\"></span><br><span class=\"line\">def find_triples_in_dir(sac_dir):</span><br><span class=\"line\">    files = glob.glob(os.path.join(sac_dir, &quot;*.SAC&quot;)) + glob.glob(os.path.join(sac_dir, &quot;*.sac&quot;))</span><br><span class=\"line\">    idx = defaultdict(dict)</span><br><span class=\"line\">    for f in files:</span><br><span class=\"line\">        b = os.path.basename(f)</span><br><span class=\"line\">        up = b.upper()</span><br><span class=\"line\">        if &quot;LHZ&quot; in up or &quot;HZ&quot; in up:</span><br><span class=\"line\">            base = up.replace(&quot;LHZ&quot;, &quot;&quot;).replace(&quot;HZ&quot;, &quot;&quot;).strip(&quot;_&quot;)</span><br><span class=\"line\">            idx[base][&quot;Z&quot;] = f</span><br><span class=\"line\">        elif &quot;LHN&quot; in up or &quot;HN&quot; in up:</span><br><span class=\"line\">            base = up.replace(&quot;LHN&quot;, &quot;&quot;).replace(&quot;HN&quot;, &quot;&quot;).strip(&quot;_&quot;)</span><br><span class=\"line\">            idx[base][&quot;N&quot;] = f</span><br><span class=\"line\">        elif &quot;LHE&quot; in up or &quot;HE&quot; in up:</span><br><span class=\"line\">            base = up.replace(&quot;LHE&quot;, &quot;&quot;).replace(&quot;HE&quot;, &quot;&quot;).strip(&quot;_&quot;)</span><br><span class=\"line\">            idx[base][&quot;E&quot;] = f</span><br><span class=\"line\">    triples = []</span><br><span class=\"line\">    for base, d in idx.items():</span><br><span class=\"line\">        if all(k in d for k in (&quot;Z&quot;, &quot;N&quot;, &quot;E&quot;)):</span><br><span class=\"line\">            triples.append((base, d[&quot;Z&quot;], d[&quot;N&quot;], d[&quot;E&quot;]))</span><br><span class=\"line\">    return triples</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"># ======================================================</span><br><span class=\"line\"># Main</span><br><span class=\"line\"># ======================================================</span><br><span class=\"line\"></span><br><span class=\"line\">if __name__ == &quot;__main__&quot;:</span><br><span class=\"line\">    p = argparse.ArgumentParser(description=&quot;DOP-E S-transform (paper consistent, optimized)&quot;)</span><br><span class=\"line\">    p.add_argument(&quot;sacdir&quot;, help=&quot;Directory with 3-component SAC files&quot;)</span><br><span class=\"line\">    p.add_argument(&quot;--target-freq&quot;, type=float, default=0.03, help=&quot;Center frequency (Hz)&quot;)</span><br><span class=\"line\">    p.add_argument(&quot;--fmin&quot;, type=float, default=None, help=&quot;Min frequency&quot;)</span><br><span class=\"line\">    p.add_argument(&quot;--fmax&quot;, type=float, default=None, help=&quot;Max frequency&quot;)</span><br><span class=\"line\">    p.add_argument(&quot;--outs&quot;, default=&quot;out&quot;, help=&quot;Output prefix&quot;)</span><br><span class=\"line\">    p.add_argument(&quot;--dop-thresh&quot;, type=float, default=0.8, help=&quot;DOP threshold&quot;)</span><br><span class=\"line\">    p.add_argument(&quot;--n-freqs&quot;, type=int, default=60, help=&quot;Number of frequency points&quot;)</span><br><span class=\"line\">    p.add_argument(&quot;--step&quot;, type=int, default=5, help=&quot;Downsample step for time (1 = full)&quot;)</span><br><span class=\"line\">    args = p.parse_args()</span><br><span class=\"line\"></span><br><span class=\"line\">    triples = find_triples_in_dir(args.sacdir)</span><br><span class=\"line\">    if not triples:</span><br><span class=\"line\">        print(&quot;No 3-component SAC sets found.&quot;)</span><br><span class=\"line\">        raise SystemExit</span><br><span class=\"line\"></span><br><span class=\"line\">    for base, fz, fn, fe in triples:</span><br><span class=\"line\">        print(&quot;Processing:&quot;, base)</span><br><span class=\"line\">        z, n, e, stats = DOPAnalyzer()._read_triple(fz, fn, fe)</span><br><span class=\"line\">        fs = stats.sampling_rate</span><br><span class=\"line\">        if args.fmin and args.fmax:</span><br><span class=\"line\">            freq_band = (args.fmin, args.fmax)</span><br><span class=\"line\">        else:</span><br><span class=\"line\">            freq_band = None</span><br><span class=\"line\">        analyzer = DOPAnalyzer(fs=fs,</span><br><span class=\"line\">                               target_freq=args.target_freq,</span><br><span class=\"line\">                               freq_band=freq_band,</span><br><span class=\"line\">                               dop_thresh=args.dop_thresh,</span><br><span class=\"line\">                               n_freqs=args.n_freqs,</span><br><span class=\"line\">                               step=args.step)</span><br><span class=\"line\">        res = analyzer.analyze_triple(z, n, e)</span><br><span class=\"line\">        outpref = f&quot;&#123;args.outs&#125;_&#123;base&#125;&quot;</span><br><span class=\"line\">        analyzer.plot_results(res, out_prefix=outpref, target_freq=args.target_freq)</span><br><span class=\"line\">        print(&quot;Saved:&quot;, outpref)</span><br></pre></td></tr></table></figure>","related_posts":["music.html","latex-math-express.html"],"length":11106,"excerpt":"<p>&emsp;&emsp;DOP-E 单站极化与背方位角分析流程  </p>","more":"<p><em>(基于论文 Schimmel et al., 2011; Berbellini et al., 2019)</em>  </p>\n<h2 id=\"一、总体流程概述\"><a href=\"#一、总体流程概述\" class=\"headerlink\" title=\"一、总体流程概述\"></a>一、总体流程概述</h2><ol>\n<li><strong>数据预处理</strong>（去趋势、去仪器、对齐）  </li>\n<li><strong>S-transform 时频分解</strong>（论文定义）  </li>\n<li><strong>构造谱矩阵与时域平滑</strong>  </li>\n<li><strong>本征分解求极化参数（DOP、planarity、semimajor axis）</strong>  </li>\n<li><strong>筛选高质量段</strong>（DOP &gt; 阈值 &amp; planarity 接近水平）  </li>\n<li><strong>计算背方位角（BAZ）并解除 180° 二义性</strong>  </li>\n<li><strong>输出可视化与统计</strong>（时频图、直方图、极坐标图）  </li>\n<li><strong>验证与质量控制（QA）</strong>  </li>\n<li><strong>批量与性能优化</strong></li>\n</ol>\n<hr>\n<h2 id=\"二、数据预处理\"><a href=\"#二、数据预处理\" class=\"headerlink\" title=\"二、数据预处理\"></a>二、数据预处理</h2><h3 id=\"目标\"><a href=\"#目标\" class=\"headerlink\" title=\"目标\"></a>目标</h3><p>确保三分量（Z&#x2F;N&#x2F;E）记录在同一时间基线，且仅保留稳定的噪声段。</p>\n<h3 id=\"步骤\"><a href=\"#步骤\" class=\"headerlink\" title=\"步骤\"></a>步骤</h3><ol>\n<li><p><strong>去仪器响应</strong>  </p>\n<ul>\n<li>若记录为速度，直接使用；否则用 RESP 文件去响应。  </li>\n<li>理由：相位一致性影响极化矩阵。</li>\n</ul>\n</li>\n<li><p><strong>去趋势 &#x2F; 去均值</strong>  </p>\n<ul>\n<li><code>trace.detrend(&quot;linear&quot;); trace.detrend(&quot;demean&quot;)</code>  </li>\n<li>理由：低频漂移会污染低频段（0.03 Hz）。</li>\n</ul>\n</li>\n<li><p><strong>剔除事件或脉冲干扰</strong>  </p>\n<ul>\n<li>可通过短时能量（STA&#x2F;LTA）检测排除瞬变。</li>\n</ul>\n</li>\n<li><p><strong>带通滤波</strong>  </p>\n<ul>\n<li>推荐：<code>0.01–0.06 Hz</code> （若仅关心 0.03 Hz 区域）。  </li>\n<li>理由：去掉无关频段以提高信噪比。</li>\n</ul>\n</li>\n<li><p><strong>时间对齐与补零</strong>  </p>\n<ul>\n<li>三分量必须同起止时刻；短 gap 可补零，长 gap 建议跳过。</li>\n</ul>\n</li>\n</ol>\n<hr>\n<h2 id=\"三、S-transform（论文规范实现）\"><a href=\"#三、S-transform（论文规范实现）\" class=\"headerlink\" title=\"三、S-transform（论文规范实现）\"></a>三、S-transform（论文规范实现）</h2><h3 id=\"定义\"><a href=\"#定义\" class=\"headerlink\" title=\"定义\"></a>定义</h3><p>$$<br>S(t,f)&#x3D;\\int x(\\tau)\\frac{|f|}{\\sqrt{2\\pi}}e^{-(t-\\tau)^2f^2&#x2F;2}e^{-i2\\pi f\\tau}d\\tau<br>$$</p>\n<h3 id=\"参数与理由\"><a href=\"#参数与理由\" class=\"headerlink\" title=\"参数与理由\"></a>参数与理由</h3><table>\n<thead>\n<tr>\n<th>参数</th>\n<th>推荐值</th>\n<th>理由</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>频率点数 <code>n_freqs</code></td>\n<td>60</td>\n<td>覆盖 0.01–0.06 Hz 区间，低频对数分辨率更合理</td>\n</tr>\n<tr>\n<td>窗宽 σ</td>\n<td>1&#x2F;(2πf)</td>\n<td>论文定义，时间-频率能量守恒</td>\n</tr>\n<tr>\n<td>调整系数 k</td>\n<td>1.0–1.5</td>\n<td>增大可提高时域平滑性</td>\n</tr>\n<tr>\n<td>下采样步长 step</td>\n<td>5 s</td>\n<td>提高计算效率，仍能解析 0.03 Hz（周期 33 s）信号</td>\n</tr>\n</tbody></table>\n<blockquote>\n<p><strong>说明</strong>：<br>σ &#x3D; 1&#x2F;(2πf) 表示随频率增加窗宽减小，确保多分辨率特性。<br>|f|&#x2F;√(2π) 为归一化系数，维持 Parseval 能量一致性。  </p>\n</blockquote>\n<hr>\n<h2 id=\"四、谱矩阵构造与平滑\"><a href=\"#四、谱矩阵构造与平滑\" class=\"headerlink\" title=\"四、谱矩阵构造与平滑\"></a>四、谱矩阵构造与平滑</h2><h3 id=\"谱矩阵定义\"><a href=\"#谱矩阵定义\" class=\"headerlink\" title=\"谱矩阵定义\"></a>谱矩阵定义</h3><p>$$<br>S_{ij}(t,f) &#x3D; \\widetilde{X_i}(t,f)\\widetilde{X_j}^*(t,f)<br>$$<br>其中 $ \\widetilde{X_i}(t,f) $ 为分量 i 的 S-transform 复系数。</p>\n<h3 id=\"平滑\"><a href=\"#平滑\" class=\"headerlink\" title=\"平滑\"></a>平滑</h3><p>对时间方向做高斯平滑：<br>$$<br>\\sigma_{\\text{tf}} &#x3D; \\text{tf_window_periods} \\times T \\times f_s<br>$$</p>\n<table>\n<thead>\n<tr>\n<th>参数</th>\n<th>推荐值</th>\n<th>理由</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>tf_window_periods</code></td>\n<td>3.0</td>\n<td>论文示例值（2s ≈ 3T），平滑噪声但保留相干波</td>\n</tr>\n<tr>\n<td>DOP 窗长度</td>\n<td><code>4 × T</code></td>\n<td>保证至少 4 周期稳定极化，论文建议值</td>\n</tr>\n</tbody></table>\n<hr>\n<h2 id=\"五、本征分解与极化属性\"><a href=\"#五、本征分解与极化属性\" class=\"headerlink\" title=\"五、本征分解与极化属性\"></a>五、本征分解与极化属性</h2><p>对每个 (t,f) 做 3×3 复矩阵本征分解：<br>$$<br>S &#x3D; V \\Lambda V^H,\\quad \\Lambda &#x3D; \\operatorname{diag}(\\lambda_1,\\lambda_2,\\lambda_3)<br>$$</p>\n<h3 id=\"DOP（Degree-of-Polarization）\"><a href=\"#DOP（Degree-of-Polarization）\" class=\"headerlink\" title=\"DOP（Degree of Polarization）\"></a>DOP（Degree of Polarization）</h3><p>$$<br>\\mathrm{DOP} &#x3D; \\frac{\\lambda_1 - \\lambda_2}{\\lambda_1 + \\lambda_2 + \\lambda_3}<br>$$</p>\n<h3 id=\"Planarity\"><a href=\"#Planarity\" class=\"headerlink\" title=\"Planarity\"></a>Planarity</h3><p>通过主、次特征向量叉积求平面法线，与竖直方向夹角 α：</p>\n<ul>\n<li>若 α ≈ 90° → 水平 planarity（Rayleigh 波特征）  </li>\n<li>若 α ≈ 0° → 垂直平面（Love 波或噪声）</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>参数</th>\n<th>推荐值</th>\n<th>理由</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>dop_thresh</code></td>\n<td>0.8</td>\n<td>论文常用 0.75–0.85；取 0.8 折中稳健</td>\n</tr>\n<tr>\n<td><code>alpha_min</code></td>\n<td>60°</td>\n<td>仅保留水平 planarity</td>\n</tr>\n</tbody></table>\n<hr>\n<h2 id=\"六、背方位角（BAZ）计算\"><a href=\"#六、背方位角（BAZ）计算\" class=\"headerlink\" title=\"六、背方位角（BAZ）计算\"></a>六、背方位角（BAZ）计算</h2><h3 id=\"公式\"><a href=\"#公式\" class=\"headerlink\" title=\"公式\"></a>公式</h3><p>$$<br>\\mathrm{BAZ} &#x3D; \\operatorname{atan2}(E, N)<br>$$<br>以度为单位，0° &#x3D; 北，顺时针增加。</p>\n<h3 id=\"处理细节\"><a href=\"#处理细节\" class=\"headerlink\" title=\"处理细节\"></a>处理细节</h3><ul>\n<li>使用主特征向量的水平分量 (N,E)。  </li>\n<li>实部幅值过小则跳过或使用相位差法。  </li>\n<li>输出角度范围 [0, 360°)。</li>\n</ul>\n<h3 id=\"二义性处理\"><a href=\"#二义性处理\" class=\"headerlink\" title=\"二义性处理\"></a>二义性处理</h3><ul>\n<li>单站存在 ±180° 二义性。  </li>\n<li><strong>假设 retrograde（瑞利波基模）</strong>，可选反向修正：若竖直与水平分量相位差 ~180°，翻转 BAZ。</li>\n</ul>\n<hr>\n<h2 id=\"七、筛选与聚合输出\"><a href=\"#七、筛选与聚合输出\" class=\"headerlink\" title=\"七、筛选与聚合输出\"></a>七、筛选与聚合输出</h2><h3 id=\"筛选规则\"><a href=\"#筛选规则\" class=\"headerlink\" title=\"筛选规则\"></a>筛选规则</h3><figure class=\"highlight text\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">DOP &gt;= 0.8</span><br><span class=\"line\">planarity_angle &gt; 60°</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"八、脚本\"><a href=\"#八、脚本\" class=\"headerlink\" title=\"八、脚本\"></a>八、脚本</h2><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br><span class=\"line\">145</span><br><span class=\"line\">146</span><br><span class=\"line\">147</span><br><span class=\"line\">148</span><br><span class=\"line\">149</span><br><span class=\"line\">150</span><br><span class=\"line\">151</span><br><span class=\"line\">152</span><br><span class=\"line\">153</span><br><span class=\"line\">154</span><br><span class=\"line\">155</span><br><span class=\"line\">156</span><br><span class=\"line\">157</span><br><span class=\"line\">158</span><br><span class=\"line\">159</span><br><span class=\"line\">160</span><br><span class=\"line\">161</span><br><span class=\"line\">162</span><br><span class=\"line\">163</span><br><span class=\"line\">164</span><br><span class=\"line\">165</span><br><span class=\"line\">166</span><br><span class=\"line\">167</span><br><span class=\"line\">168</span><br><span class=\"line\">169</span><br><span class=\"line\">170</span><br><span class=\"line\">171</span><br><span class=\"line\">172</span><br><span class=\"line\">173</span><br><span class=\"line\">174</span><br><span class=\"line\">175</span><br><span class=\"line\">176</span><br><span class=\"line\">177</span><br><span class=\"line\">178</span><br><span class=\"line\">179</span><br><span class=\"line\">180</span><br><span class=\"line\">181</span><br><span class=\"line\">182</span><br><span class=\"line\">183</span><br><span class=\"line\">184</span><br><span class=\"line\">185</span><br><span class=\"line\">186</span><br><span class=\"line\">187</span><br><span class=\"line\">188</span><br><span class=\"line\">189</span><br><span class=\"line\">190</span><br><span class=\"line\">191</span><br><span class=\"line\">192</span><br><span class=\"line\">193</span><br><span class=\"line\">194</span><br><span class=\"line\">195</span><br><span class=\"line\">196</span><br><span class=\"line\">197</span><br><span class=\"line\">198</span><br><span class=\"line\">199</span><br><span class=\"line\">200</span><br><span class=\"line\">201</span><br><span class=\"line\">202</span><br><span class=\"line\">203</span><br><span class=\"line\">204</span><br><span class=\"line\">205</span><br><span class=\"line\">206</span><br><span class=\"line\">207</span><br><span class=\"line\">208</span><br><span class=\"line\">209</span><br><span class=\"line\">210</span><br><span class=\"line\">211</span><br><span class=\"line\">212</span><br><span class=\"line\">213</span><br><span class=\"line\">214</span><br><span class=\"line\">215</span><br><span class=\"line\">216</span><br><span class=\"line\">217</span><br><span class=\"line\">218</span><br><span class=\"line\">219</span><br><span class=\"line\">220</span><br><span class=\"line\">221</span><br><span class=\"line\">222</span><br><span class=\"line\">223</span><br><span class=\"line\">224</span><br><span class=\"line\">225</span><br><span class=\"line\">226</span><br><span class=\"line\">227</span><br><span class=\"line\">228</span><br><span class=\"line\">229</span><br><span class=\"line\">230</span><br><span class=\"line\">231</span><br><span class=\"line\">232</span><br><span class=\"line\">233</span><br><span class=\"line\">234</span><br><span class=\"line\">235</span><br><span class=\"line\">236</span><br><span class=\"line\">237</span><br><span class=\"line\">238</span><br><span class=\"line\">239</span><br><span class=\"line\">240</span><br><span class=\"line\">241</span><br><span class=\"line\">242</span><br><span class=\"line\">243</span><br><span class=\"line\">244</span><br><span class=\"line\">245</span><br><span class=\"line\">246</span><br><span class=\"line\">247</span><br><span class=\"line\">248</span><br><span class=\"line\">249</span><br><span class=\"line\">250</span><br><span class=\"line\">251</span><br><span class=\"line\">252</span><br><span class=\"line\">253</span><br><span class=\"line\">254</span><br><span class=\"line\">255</span><br><span class=\"line\">256</span><br><span class=\"line\">257</span><br><span class=\"line\">258</span><br><span class=\"line\">259</span><br><span class=\"line\">260</span><br><span class=\"line\">261</span><br><span class=\"line\">262</span><br><span class=\"line\">263</span><br><span class=\"line\">264</span><br><span class=\"line\">265</span><br><span class=\"line\">266</span><br><span class=\"line\">267</span><br><span class=\"line\">268</span><br><span class=\"line\">269</span><br><span class=\"line\">270</span><br><span class=\"line\">271</span><br><span class=\"line\">272</span><br><span class=\"line\">273</span><br><span class=\"line\">274</span><br><span class=\"line\">275</span><br><span class=\"line\">276</span><br><span class=\"line\">277</span><br><span class=\"line\">278</span><br><span class=\"line\">279</span><br><span class=\"line\">280</span><br><span class=\"line\">281</span><br><span class=\"line\">282</span><br><span class=\"line\">283</span><br><span class=\"line\">284</span><br><span class=\"line\">285</span><br><span class=\"line\">286</span><br><span class=\"line\">287</span><br><span class=\"line\">288</span><br><span class=\"line\">289</span><br><span class=\"line\">290</span><br><span class=\"line\">291</span><br><span class=\"line\">292</span><br><span class=\"line\">293</span><br><span class=\"line\">294</span><br><span class=\"line\">295</span><br><span class=\"line\">296</span><br><span class=\"line\">297</span><br><span class=\"line\">298</span><br><span class=\"line\">299</span><br><span class=\"line\">300</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#!/usr/bin/env python3</span><br><span class=\"line\">&quot;&quot;&quot;</span><br><span class=\"line\">DOP-E style polarization + BAZ extraction using paper-consistent S-transform</span><br><span class=\"line\">Implements Schimmel et al. (2011) S-transform definition with speed optimizations (Numba).</span><br><span class=\"line\"></span><br><span class=\"line\">Usage:</span><br><span class=\"line\">    python dop_e_st_paper.py /path/to/sac_dir --target-freq 0.03 --outs out</span><br><span class=\"line\"></span><br><span class=\"line\">References:</span><br><span class=\"line\">- Schimmel, Stutzmann, Ardhuin &amp; Gallart (2011), Polarized Earth&#x27;s ambient microseismic noise, G³</span><br><span class=\"line\">&quot;&quot;&quot;</span><br><span class=\"line\">import os</span><br><span class=\"line\">import glob</span><br><span class=\"line\">import argparse</span><br><span class=\"line\">from collections import defaultdict</span><br><span class=\"line\">import numpy as np</span><br><span class=\"line\">import matplotlib.pyplot as plt</span><br><span class=\"line\">from obspy import read</span><br><span class=\"line\">from scipy.signal import get_window</span><br><span class=\"line\">from numba import njit, prange</span><br><span class=\"line\">import math</span><br><span class=\"line\">import warnings</span><br><span class=\"line\"></span><br><span class=\"line\">warnings.filterwarnings(&quot;ignore&quot;)</span><br><span class=\"line\"></span><br><span class=\"line\"># ======================================================</span><br><span class=\"line\"># S-transform implementation per Schimmel et al. (2011)</span><br><span class=\"line\"># ======================================================</span><br><span class=\"line\"></span><br><span class=\"line\">def s_transform(x, fs, freqs, pad=True):</span><br><span class=\"line\">    &quot;&quot;&quot;</span><br><span class=\"line\">    Paper-consistent S-transform:</span><br><span class=\"line\">    S(t,f) = ∫ x(τ) * |f|/√(2π) * exp[-(t-τ)^2 f^2 / 2] * exp[-i2π f τ] dτ</span><br><span class=\"line\">    Implemented via FFT multiplication.</span><br><span class=\"line\">    &quot;&quot;&quot;</span><br><span class=\"line\">    n = len(x)</span><br><span class=\"line\">    dt = 1.0 / fs</span><br><span class=\"line\">    if pad:</span><br><span class=\"line\">        Nfft = 1 &lt;&lt; ((2 * n - 1).bit_length())</span><br><span class=\"line\">    else:</span><br><span class=\"line\">        Nfft = n</span><br><span class=\"line\">    t = np.arange(n) * dt</span><br><span class=\"line\">    X = np.fft.fft(x, n=Nfft)</span><br><span class=\"line\">    freqs_fft = np.fft.fftfreq(Nfft, d=dt)</span><br><span class=\"line\"></span><br><span class=\"line\">    S = np.zeros((len(freqs), n), dtype=np.complex128)</span><br><span class=\"line\">    # time index array</span><br><span class=\"line\">    for i, f in enumerate(freqs):</span><br><span class=\"line\">        if f &lt;= 0:</span><br><span class=\"line\">            continue</span><br><span class=\"line\">        # build Gaussian window in frequency domain for convolution</span><br><span class=\"line\">        # Using exact analytical equivalence:</span><br><span class=\"line\">        # G(f&#x27;) = exp[-2π^2 (f&#x27;-f)^2 / f^2]</span><br><span class=\"line\">        g_f = np.exp(-2.0 * (np.pi ** 2) * ((freqs_fft - f) ** 2) / (f ** 2))</span><br><span class=\"line\">        # convolution via inverse FFT</span><br><span class=\"line\">        s_ifft = np.fft.ifft(X * g_f, n=Nfft)</span><br><span class=\"line\">        s_ifft = s_ifft[:n]</span><br><span class=\"line\">        # normalization factor |f|/sqrt(2π)</span><br><span class=\"line\">        S[i, :] = (abs(f) / np.sqrt(2.0 * np.pi)) * s_ifft * np.exp(1j * 2 * np.pi * f * t)</span><br><span class=\"line\">    return S</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"># ======================================================</span><br><span class=\"line\"># Polarization &amp; BAZ analysis (Numba optimized)</span><br><span class=\"line\"># ======================================================</span><br><span class=\"line\"></span><br><span class=\"line\">@njit(parallel=True, fastmath=True)</span><br><span class=\"line\">def compute_dop_baz(cz, cn, ce, periods, fs, dop_thresh):</span><br><span class=\"line\">    nfr, nt = cz.shape</span><br><span class=\"line\">    DOP = np.zeros((nfr, nt))</span><br><span class=\"line\">    BAZ = np.full((nfr, nt), np.nan)</span><br><span class=\"line\">    QUALITY = np.zeros((nfr, nt))</span><br><span class=\"line\"></span><br><span class=\"line\">    for ifr in prange(nfr):</span><br><span class=\"line\">        for it in range(nt):</span><br><span class=\"line\">            # spectral matrix (3x3)</span><br><span class=\"line\">            Z = cz[ifr, it]</span><br><span class=\"line\">            N = cn[ifr, it]</span><br><span class=\"line\">            E = ce[ifr, it]</span><br><span class=\"line\">            S00 = (Z * np.conj(Z)).real</span><br><span class=\"line\">            S01 = (Z * np.conj(N))</span><br><span class=\"line\">            S02 = (Z * np.conj(E))</span><br><span class=\"line\">            S11 = (N * np.conj(N)).real</span><br><span class=\"line\">            S12 = (N * np.conj(E))</span><br><span class=\"line\">            S22 = (E * np.conj(E)).real</span><br><span class=\"line\"></span><br><span class=\"line\">            # Hermitian matrix</span><br><span class=\"line\">            S = np.array([[S00, S01.real, S02.real],</span><br><span class=\"line\">                          [S01.real, S11, S12.real],</span><br><span class=\"line\">                          [S02.real, S12.real, S22]], dtype=np.float64)</span><br><span class=\"line\"></span><br><span class=\"line\">            # eigen decomposition</span><br><span class=\"line\">            w, v = np.linalg.eigh(S)</span><br><span class=\"line\">            idx = np.argsort(w)[::-1]</span><br><span class=\"line\">            w = w[idx]</span><br><span class=\"line\">            v = v[:, idx]</span><br><span class=\"line\">            # DOP = (λ1 - λ2)/(λ1+λ2+λ3)</span><br><span class=\"line\">            denom = w.sum()</span><br><span class=\"line\">            if denom &lt;= 0:</span><br><span class=\"line\">                dop_val = 0.0</span><br><span class=\"line\">            else:</span><br><span class=\"line\">                dop_val = (w[0] - w[1]) / denom</span><br><span class=\"line\">                if dop_val &lt; 0:</span><br><span class=\"line\">                    dop_val = 0.0</span><br><span class=\"line\">                elif dop_val &gt; 1.0:</span><br><span class=\"line\">                    dop_val = 1.0</span><br><span class=\"line\">            DOP[ifr, it] = dop_val</span><br><span class=\"line\"></span><br><span class=\"line\">            if dop_val &lt; dop_thresh:</span><br><span class=\"line\">                continue</span><br><span class=\"line\"></span><br><span class=\"line\">            # horizontal azimuth from first eigenvector (v[:,0])</span><br><span class=\"line\">            a = v[:, 0]</span><br><span class=\"line\">            rn = a[1]</span><br><span class=\"line\">            re = a[2]</span><br><span class=\"line\">            az = math.degrees(math.atan2(re, rn))</span><br><span class=\"line\">            if az &lt; 0:</span><br><span class=\"line\">                az += 360.0</span><br><span class=\"line\">            BAZ[ifr, it] = az</span><br><span class=\"line\">            QUALITY[ifr, it] = 1</span><br><span class=\"line\"></span><br><span class=\"line\">    return DOP, BAZ, QUALITY</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"># ======================================================</span><br><span class=\"line\"># DOPAnalyzer class</span><br><span class=\"line\"># ======================================================</span><br><span class=\"line\"></span><br><span class=\"line\">class DOPAnalyzer:</span><br><span class=\"line\">    def __init__(self, fs=1.0, target_freq=None, freq_band=None,</span><br><span class=\"line\">                 dop_thresh=0.8, n_freqs=80, step=1):</span><br><span class=\"line\">        &quot;&quot;&quot;</span><br><span class=\"line\">        Parameters:</span><br><span class=\"line\">            fs: sampling rate</span><br><span class=\"line\">            target_freq: center frequency (Hz)</span><br><span class=\"line\">            freq_band: (fmin,fmax)</span><br><span class=\"line\">            dop_thresh: threshold</span><br><span class=\"line\">            n_freqs: number of frequency points</span><br><span class=\"line\">            step: downsample factor for time (e.g. 5 -&gt; 5 s resolution)</span><br><span class=\"line\">        &quot;&quot;&quot;</span><br><span class=\"line\">        self.fs = fs</span><br><span class=\"line\">        self.dt = 1.0 / fs</span><br><span class=\"line\">        self.target_freq = target_freq</span><br><span class=\"line\">        self.freq_band = freq_band</span><br><span class=\"line\">        self.dop_thresh = dop_thresh</span><br><span class=\"line\">        self.n_freqs = n_freqs</span><br><span class=\"line\">        self.step = step</span><br><span class=\"line\"></span><br><span class=\"line\">    def _read_triple(self, fz, fn, fe):</span><br><span class=\"line\">        stz = read(fz)[0]</span><br><span class=\"line\">        stn = read(fn)[0]</span><br><span class=\"line\">        ste = read(fe)[0]</span><br><span class=\"line\">        start = max(stz.stats.starttime, stn.stats.starttime, ste.stats.starttime)</span><br><span class=\"line\">        end = min(stz.stats.endtime, stn.stats.endtime, ste.stats.endtime)</span><br><span class=\"line\">        stz.trim(start, end)</span><br><span class=\"line\">        stn.trim(start, end)</span><br><span class=\"line\">        ste.trim(start, end)</span><br><span class=\"line\">        return stz.data.astype(float), stn.data.astype(float), ste.data.astype(float), stz.stats</span><br><span class=\"line\"></span><br><span class=\"line\">    def _choose_freqs(self):</span><br><span class=\"line\">        if self.freq_band:</span><br><span class=\"line\">            fmin, fmax = self.freq_band</span><br><span class=\"line\">        elif self.target_freq:</span><br><span class=\"line\">            fmin = self.target_freq * 0.8</span><br><span class=\"line\">            fmax = self.target_freq * 1.2</span><br><span class=\"line\">        else:</span><br><span class=\"line\">            fmin, fmax = 0.005, 0.25</span><br><span class=\"line\">        freqs = np.logspace(np.log10(fmin), np.log10(fmax), self.n_freqs)</span><br><span class=\"line\">        return freqs</span><br><span class=\"line\"></span><br><span class=\"line\">    def analyze_triple(self, z, n, e):</span><br><span class=\"line\">        npts = len(z)</span><br><span class=\"line\">        tvec = np.arange(0, npts, self.step) / self.fs</span><br><span class=\"line\">        freqs = self._choose_freqs()</span><br><span class=\"line\">        periods = 1.0 / freqs</span><br><span class=\"line\"></span><br><span class=\"line\">        cz = s_transform(z, self.fs, freqs)</span><br><span class=\"line\">        cn = s_transform(n, self.fs, freqs)</span><br><span class=\"line\">        ce = s_transform(e, self.fs, freqs)</span><br><span class=\"line\"></span><br><span class=\"line\">        # downsample in time for speed</span><br><span class=\"line\">        cz = cz[:, ::self.step]</span><br><span class=\"line\">        cn = cn[:, ::self.step]</span><br><span class=\"line\">        ce = ce[:, ::self.step]</span><br><span class=\"line\"></span><br><span class=\"line\">        DOP, BAZ, QUALITY = compute_dop_baz(cz, cn, ce, periods, self.fs, self.dop_thresh)</span><br><span class=\"line\"></span><br><span class=\"line\">        return &#123;&quot;times&quot;: tvec, &quot;freqs&quot;: freqs, &quot;DOP&quot;: DOP, &quot;BAZ&quot;: BAZ, &quot;QUALITY&quot;: QUALITY&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    def plot_results(self, res, out_prefix=&quot;result&quot;, target_freq=None):</span><br><span class=\"line\">        times = res[&quot;times&quot;]</span><br><span class=\"line\">        freqs = res[&quot;freqs&quot;]</span><br><span class=\"line\">        DOP = res[&quot;DOP&quot;]</span><br><span class=\"line\">        BAZ = res[&quot;BAZ&quot;]</span><br><span class=\"line\">        Q = res[&quot;QUALITY&quot;]</span><br><span class=\"line\"></span><br><span class=\"line\">        t_hr = times / 3600.0</span><br><span class=\"line\"></span><br><span class=\"line\">        plt.figure(figsize=(12, 4))</span><br><span class=\"line\">        plt.pcolormesh(t_hr, freqs, DOP, shading=&quot;auto&quot;)</span><br><span class=\"line\">        plt.colorbar(label=&quot;DOP&quot;)</span><br><span class=\"line\">        plt.yscale(&quot;log&quot;)</span><br><span class=\"line\">        plt.ylabel(&quot;Frequency (Hz)&quot;)</span><br><span class=\"line\">        plt.xlabel(&quot;Time (hours)&quot;)</span><br><span class=\"line\">        plt.title(&quot;DOP (S-transform)&quot;)</span><br><span class=\"line\">        plt.tight_layout()</span><br><span class=\"line\">        plt.savefig(out_prefix + &quot;_DOP.png&quot;, dpi=200)</span><br><span class=\"line\"></span><br><span class=\"line\">        plt.figure(figsize=(12, 4))</span><br><span class=\"line\">        baz_masked = np.where(Q &gt; 0, BAZ, np.nan)</span><br><span class=\"line\">        plt.pcolormesh(t_hr, freqs, baz_masked, shading=&quot;auto&quot;, cmap=&quot;hsv&quot;, vmin=0, vmax=360)</span><br><span class=\"line\">        plt.colorbar(label=&quot;Back Azimuth (°)&quot;)</span><br><span class=\"line\">        plt.yscale(&quot;log&quot;)</span><br><span class=\"line\">        plt.ylabel(&quot;Frequency (Hz)&quot;)</span><br><span class=\"line\">        plt.xlabel(&quot;Time (hours)&quot;)</span><br><span class=\"line\">        plt.title(f&quot;BAZ (DOP&gt;&#123;self.dop_thresh&#125;)&quot;)</span><br><span class=\"line\">        plt.tight_layout()</span><br><span class=\"line\">        plt.savefig(out_prefix + &quot;_BAZ_timefreq.png&quot;, dpi=200)</span><br><span class=\"line\"></span><br><span class=\"line\">        if target_freq is not None:</span><br><span class=\"line\">            idx = np.argmin(np.abs(freqs - target_freq))</span><br><span class=\"line\">            baz_vals = BAZ[idx, Q[idx, :] &gt; 0]</span><br><span class=\"line\">        else:</span><br><span class=\"line\">            baz_vals = BAZ[Q &gt; 0]</span><br><span class=\"line\"></span><br><span class=\"line\">        plt.figure(figsize=(6, 4))</span><br><span class=\"line\">        plt.hist(baz_vals[~np.isnan(baz_vals)], bins=np.arange(0, 361, 10))</span><br><span class=\"line\">        plt.xlabel(&quot;Back Azimuth (°)&quot;)</span><br><span class=\"line\">        plt.ylabel(&quot;Count&quot;)</span><br><span class=\"line\">        plt.title(&quot;BAZ Histogram&quot;)</span><br><span class=\"line\">        plt.tight_layout()</span><br><span class=\"line\">        plt.savefig(out_prefix + &quot;_BAZ_hist.png&quot;, dpi=200)</span><br><span class=\"line\">        plt.close(&quot;all&quot;)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"># ======================================================</span><br><span class=\"line\"># Utility: find 3-component sets</span><br><span class=\"line\"># ======================================================</span><br><span class=\"line\"></span><br><span class=\"line\">def find_triples_in_dir(sac_dir):</span><br><span class=\"line\">    files = glob.glob(os.path.join(sac_dir, &quot;*.SAC&quot;)) + glob.glob(os.path.join(sac_dir, &quot;*.sac&quot;))</span><br><span class=\"line\">    idx = defaultdict(dict)</span><br><span class=\"line\">    for f in files:</span><br><span class=\"line\">        b = os.path.basename(f)</span><br><span class=\"line\">        up = b.upper()</span><br><span class=\"line\">        if &quot;LHZ&quot; in up or &quot;HZ&quot; in up:</span><br><span class=\"line\">            base = up.replace(&quot;LHZ&quot;, &quot;&quot;).replace(&quot;HZ&quot;, &quot;&quot;).strip(&quot;_&quot;)</span><br><span class=\"line\">            idx[base][&quot;Z&quot;] = f</span><br><span class=\"line\">        elif &quot;LHN&quot; in up or &quot;HN&quot; in up:</span><br><span class=\"line\">            base = up.replace(&quot;LHN&quot;, &quot;&quot;).replace(&quot;HN&quot;, &quot;&quot;).strip(&quot;_&quot;)</span><br><span class=\"line\">            idx[base][&quot;N&quot;] = f</span><br><span class=\"line\">        elif &quot;LHE&quot; in up or &quot;HE&quot; in up:</span><br><span class=\"line\">            base = up.replace(&quot;LHE&quot;, &quot;&quot;).replace(&quot;HE&quot;, &quot;&quot;).strip(&quot;_&quot;)</span><br><span class=\"line\">            idx[base][&quot;E&quot;] = f</span><br><span class=\"line\">    triples = []</span><br><span class=\"line\">    for base, d in idx.items():</span><br><span class=\"line\">        if all(k in d for k in (&quot;Z&quot;, &quot;N&quot;, &quot;E&quot;)):</span><br><span class=\"line\">            triples.append((base, d[&quot;Z&quot;], d[&quot;N&quot;], d[&quot;E&quot;]))</span><br><span class=\"line\">    return triples</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"># ======================================================</span><br><span class=\"line\"># Main</span><br><span class=\"line\"># ======================================================</span><br><span class=\"line\"></span><br><span class=\"line\">if __name__ == &quot;__main__&quot;:</span><br><span class=\"line\">    p = argparse.ArgumentParser(description=&quot;DOP-E S-transform (paper consistent, optimized)&quot;)</span><br><span class=\"line\">    p.add_argument(&quot;sacdir&quot;, help=&quot;Directory with 3-component SAC files&quot;)</span><br><span class=\"line\">    p.add_argument(&quot;--target-freq&quot;, type=float, default=0.03, help=&quot;Center frequency (Hz)&quot;)</span><br><span class=\"line\">    p.add_argument(&quot;--fmin&quot;, type=float, default=None, help=&quot;Min frequency&quot;)</span><br><span class=\"line\">    p.add_argument(&quot;--fmax&quot;, type=float, default=None, help=&quot;Max frequency&quot;)</span><br><span class=\"line\">    p.add_argument(&quot;--outs&quot;, default=&quot;out&quot;, help=&quot;Output prefix&quot;)</span><br><span class=\"line\">    p.add_argument(&quot;--dop-thresh&quot;, type=float, default=0.8, help=&quot;DOP threshold&quot;)</span><br><span class=\"line\">    p.add_argument(&quot;--n-freqs&quot;, type=int, default=60, help=&quot;Number of frequency points&quot;)</span><br><span class=\"line\">    p.add_argument(&quot;--step&quot;, type=int, default=5, help=&quot;Downsample step for time (1 = full)&quot;)</span><br><span class=\"line\">    args = p.parse_args()</span><br><span class=\"line\"></span><br><span class=\"line\">    triples = find_triples_in_dir(args.sacdir)</span><br><span class=\"line\">    if not triples:</span><br><span class=\"line\">        print(&quot;No 3-component SAC sets found.&quot;)</span><br><span class=\"line\">        raise SystemExit</span><br><span class=\"line\"></span><br><span class=\"line\">    for base, fz, fn, fe in triples:</span><br><span class=\"line\">        print(&quot;Processing:&quot;, base)</span><br><span class=\"line\">        z, n, e, stats = DOPAnalyzer()._read_triple(fz, fn, fe)</span><br><span class=\"line\">        fs = stats.sampling_rate</span><br><span class=\"line\">        if args.fmin and args.fmax:</span><br><span class=\"line\">            freq_band = (args.fmin, args.fmax)</span><br><span class=\"line\">        else:</span><br><span class=\"line\">            freq_band = None</span><br><span class=\"line\">        analyzer = DOPAnalyzer(fs=fs,</span><br><span class=\"line\">                               target_freq=args.target_freq,</span><br><span class=\"line\">                               freq_band=freq_band,</span><br><span class=\"line\">                               dop_thresh=args.dop_thresh,</span><br><span class=\"line\">                               n_freqs=args.n_freqs,</span><br><span class=\"line\">                               step=args.step)</span><br><span class=\"line\">        res = analyzer.analyze_triple(z, n, e)</span><br><span class=\"line\">        outpref = f&quot;&#123;args.outs&#125;_&#123;base&#125;&quot;</span><br><span class=\"line\">        analyzer.plot_results(res, out_prefix=outpref, target_freq=args.target_freq)</span><br><span class=\"line\">        print(&quot;Saved:&quot;, outpref)</span><br></pre></td></tr></table></figure>"}],"PostAsset":[{"_id":"source/_posts/2020-05-31-reward-configuration/donate.png","post":"cmh498ip1003ewvouezu14ivt","slug":"donate.png","modified":1,"renderable":0},{"_id":"source/_posts/2020-06-18-stop-os-update/app.png","post":"cmh498ip50049wvoufw2tby5o","slug":"app.png","modified":1,"renderable":0},{"_id":"source/_posts/2020-06-20-how-to-add-frame-in-hexo-next/frame.png","post":"cmh498ip6004cwvou67j4f5om","slug":"frame.png","modified":1,"renderable":0},{"_id":"source/_posts/2020-07-10-IQ-decrease/iq.jpg","post":"cmh498ip8004vwvouebu6bl2g","slug":"iq.jpg","modified":1,"renderable":0},{"_id":"source/_posts/2020-07-04-gmt-time-axes/1.png","post":"cmh498ip7004kwvou3ef626ye","slug":"1.png","modified":1,"renderable":0},{"_id":"source/_posts/2020-07-04-gmt-time-axes/2.png","post":"cmh498ip7004kwvou3ef626ye","slug":"2.png","modified":1,"renderable":0},{"_id":"source/_posts/2020-07-04-gmt-time-axes/spec.png","post":"cmh498ip7004kwvou3ef626ye","slug":"spec.png","modified":1,"renderable":0},{"_id":"source/_posts/2020-07-21-mantle-transition-zone/Picture1.png","post":"cmh498ip9004zwvou9nag711j","slug":"Picture1.png","modified":1,"renderable":0},{"_id":"source/_posts/2020-07-21-mantle-transition-zone/Picture2.png","post":"cmh498ip9004zwvou9nag711j","slug":"Picture2.png","modified":1,"renderable":0},{"_id":"source/_posts/2020-07-29-US-upper-mantle-vs-model/figure5.png","post":"cmh498ip90051wvoudvmd7r8s","slug":"figure5.png","modified":1,"renderable":0},{"_id":"source/_posts/2020-07-31-how-to-configure-chinese-for-gmt/pstext.png","post":"cmh498ipa0053wvou1y3b1bbw","slug":"pstext.png","modified":1,"renderable":0},{"_id":"source/_posts/2020-09-14-how-to-calculate-synthetic-NCF/source_dis.png","post":"cmh498ipa0056wvou9zu7dkzz","slug":"source_dis.png","modified":1,"renderable":0},{"_id":"source/_posts/2021-02-12-happy-new-year/acce.png","post":"cmh498ipd005lwvou4zlmhzy4","slug":"acce.png","modified":1,"renderable":0}],"PostCategory":[{"post_id":"cmh498iod0009wvouhqnc1583","category_id":"cmh498iob0004wvou3t2m1wbh","_id":"cmh498ioh000gwvoubo54b036"},{"post_id":"cmh498io60001wvou0n657en9","category_id":"cmh498iob0004wvou3t2m1wbh","_id":"cmh498ioi000kwvoufupm9fr9"},{"post_id":"cmh498ioe000awvoualyhgorn","category_id":"cmh498iob0004wvou3t2m1wbh","_id":"cmh498ioj000nwvou0hjq76u4"},{"post_id":"cmh498io90003wvou3k2u7eug","category_id":"cmh498iob0004wvou3t2m1wbh","_id":"cmh498iok000rwvou47sbbuu8"},{"post_id":"cmh498ioh000fwvou4ll8gwt4","category_id":"cmh498iob0004wvou3t2m1wbh","_id":"cmh498iol000uwvou01whes4b"},{"post_id":"cmh498ioc0007wvouhzx3ccb4","category_id":"cmh498ioh000hwvou9jescuhj","_id":"cmh498iom000ywvou1iid86q5"},{"post_id":"cmh498ioi000mwvou4d412v2b","category_id":"cmh498iob0004wvou3t2m1wbh","_id":"cmh498iom0011wvou0z0naqwt"},{"post_id":"cmh498ioj000qwvou8tn18cpn","category_id":"cmh498iob0004wvou3t2m1wbh","_id":"cmh498ion0015wvou7ur8fm9f"},{"post_id":"cmh498iog000ewvoubleu9i6i","category_id":"cmh498ioh000hwvou9jescuhj","_id":"cmh498ion0018wvou34rkgvd3"},{"post_id":"cmh498iol000xwvou8kwr49dq","category_id":"cmh498iol000vwvou65jqgsu2","_id":"cmh498ioo001bwvoua84x9ka1"},{"post_id":"cmh498ioi000jwvou9hu6gacb","category_id":"cmh498iol000vwvou65jqgsu2","_id":"cmh498iop001dwvou5luh1dga"},{"post_id":"cmh498iom0010wvoud4hp2qil","category_id":"cmh498iol000vwvou65jqgsu2","_id":"cmh498iop001fwvouh3d6aukg"},{"post_id":"cmh498ion0014wvou4gju31fu","category_id":"cmh498iol000vwvou65jqgsu2","_id":"cmh498ioq001jwvou16zg4tj0"},{"post_id":"cmh498iok000twvouctii41yt","category_id":"cmh498iol000vwvou65jqgsu2","_id":"cmh498ioq001mwvouap279zwq"},{"post_id":"cmh498ion0017wvouhq2480i9","category_id":"cmh498iol000vwvou65jqgsu2","_id":"cmh498ior001qwvou5t7ah1vv"},{"post_id":"cmh498ioo001awvou4tzt5d35","category_id":"cmh498iol000vwvou65jqgsu2","_id":"cmh498ior001swvouejv48is8"},{"post_id":"cmh498ioo001cwvouea9pfzu8","category_id":"cmh498iol000vwvou65jqgsu2","_id":"cmh498ios001vwvou7gxgbrqs"},{"post_id":"cmh498iop001ewvouhks419p6","category_id":"cmh498iol000vwvou65jqgsu2","_id":"cmh498ios001ywvou1nyp93lk"},{"post_id":"cmh498iop001iwvoubyxeg7ne","category_id":"cmh498iob0004wvou3t2m1wbh","_id":"cmh498iot0021wvoufzyycwdq"},{"post_id":"cmh498ioq001lwvoua3jq3kua","category_id":"cmh498iol000vwvou65jqgsu2","_id":"cmh498iot0024wvou7typ0lij"},{"post_id":"cmh498ioq001pwvou2ksyf3ab","category_id":"cmh498ioh000hwvou9jescuhj","_id":"cmh498iou0028wvou18jwerig"},{"post_id":"cmh498ior001rwvoue9f3fk8b","category_id":"cmh498iol000vwvou65jqgsu2","_id":"cmh498iou002awvou389m9m8n"},{"post_id":"cmh498ior001uwvouhyjj0p2g","category_id":"cmh498iob0004wvou3t2m1wbh","_id":"cmh498iov002dwvou27mi3lnm"},{"post_id":"cmh498ios001xwvou589f7xmh","category_id":"cmh498ioh000hwvou9jescuhj","_id":"cmh498iov002gwvou82836s7j"},{"post_id":"cmh498iot0020wvou3ak11fag","category_id":"cmh498iob0004wvou3t2m1wbh","_id":"cmh498iow002kwvoufeefbq0g"},{"post_id":"cmh498iot0023wvou9rkcep4f","category_id":"cmh498ioh000hwvou9jescuhj","_id":"cmh498iow002owvou06ykam1b"},{"post_id":"cmh498iou0027wvoueas44p0s","category_id":"cmh498iol000vwvou65jqgsu2","_id":"cmh498iox002qwvou4mf12h4c"},{"post_id":"cmh498iou0029wvou96pp777i","category_id":"cmh498iol000vwvou65jqgsu2","_id":"cmh498iox002uwvou0yea9j4r"},{"post_id":"cmh498iov002fwvouba99g50k","category_id":"cmh498iol000vwvou65jqgsu2","_id":"cmh498ioy002xwvou2jnl5cn6"},{"post_id":"cmh498iov002jwvou1sv3beo8","category_id":"cmh498ioh000hwvou9jescuhj","_id":"cmh498ioy0031wvou5tq7h2wt"},{"post_id":"cmh498iou002cwvouax8i09uw","category_id":"cmh498iov002iwvoubenbh8q3","_id":"cmh498ioz0034wvoucqxg8v7q"},{"post_id":"cmh498iow002pwvouh9276n5y","category_id":"cmh498ioh000hwvou9jescuhj","_id":"cmh498ioz0037wvou126pctcl"},{"post_id":"cmh498iox002twvoueryycrim","category_id":"cmh498ioh000hwvou9jescuhj","_id":"cmh498ip0003awvoueuiic15d"},{"post_id":"cmh498ioy002wwvou4yvyavgn","category_id":"cmh498iob0004wvou3t2m1wbh","_id":"cmh498ip0003cwvoufkxi1wi3"},{"post_id":"cmh498iow002nwvoucc8h5nij","category_id":"cmh498iox002swvoub6h1bc8l","_id":"cmh498ip1003gwvou30ho4tg9"},{"post_id":"cmh498ioy0030wvou6ogid0sc","category_id":"cmh498ioh000hwvou9jescuhj","_id":"cmh498ip2003iwvou1lm49m2q"},{"post_id":"cmh498ioz0033wvoufssygo7p","category_id":"cmh498ip00038wvou3btofi23","_id":"cmh498ip2003lwvouakb38xm0"},{"post_id":"cmh498ip1003ewvouezu14ivt","category_id":"cmh498ip00038wvou3btofi23","_id":"cmh498ip3003owvou3zh14n8h"},{"post_id":"cmh498ip1003hwvouer8ncrf9","category_id":"cmh498ip00038wvou3btofi23","_id":"cmh498ip3003rwvou4skebkni"},{"post_id":"cmh498ioz0036wvouc1gceybh","category_id":"cmh498ip1003fwvou1ab8djs3","_id":"cmh498ip3003uwvoud34sbt7t"},{"post_id":"cmh498ip2003kwvouas2b8vph","category_id":"cmh498ip00038wvou3btofi23","_id":"cmh498ip4003ywvouat9vcdpj"},{"post_id":"cmh498ip2003nwvou0y6vdlwi","category_id":"cmh498iol000vwvou65jqgsu2","_id":"cmh498ip40041wvouhpzf22bg"},{"post_id":"cmh498ip00039wvou21594zk6","category_id":"cmh498ip00038wvou3btofi23","_id":"cmh498ip50044wvouh5m6dkir"},{"post_id":"cmh498ip3003qwvou53sfaf2c","category_id":"cmh498iol000vwvou65jqgsu2","_id":"cmh498ip50048wvou2ap63nek"},{"post_id":"cmh498ip3003twvoud0vl2eog","category_id":"cmh498iol000vwvou65jqgsu2","_id":"cmh498ip6004awvou7ptv4mpc"},{"post_id":"cmh498ip4003xwvou2p5pcvxo","category_id":"cmh498ioh000hwvou9jescuhj","_id":"cmh498ip6004dwvou3fvf3n9z"},{"post_id":"cmh498ip40040wvou06fj7cp5","category_id":"cmh498iov002iwvoubenbh8q3","_id":"cmh498ip6004fwvou19m4eoq5"},{"post_id":"cmh498ip40043wvouaas52xkg","category_id":"cmh498ip00038wvou3btofi23","_id":"cmh498ip7004iwvou0qyhca6e"},{"post_id":"cmh498ip50047wvouh46p3e36","category_id":"cmh498iox002swvoub6h1bc8l","_id":"cmh498ip7004lwvou2al50d08"},{"post_id":"cmh498ip50049wvoufw2tby5o","category_id":"cmh498iox002swvoub6h1bc8l","_id":"cmh498ip8004pwvoubqjz177z"},{"post_id":"cmh498ip6004cwvou67j4f5om","category_id":"cmh498ip00038wvou3btofi23","_id":"cmh498ip8004twvouhleq9sun"},{"post_id":"cmh498ip6004ewvouc2h623rn","category_id":"cmh498iox002swvoub6h1bc8l","_id":"cmh498ip9004wwvougymkauah"},{"post_id":"cmh498ip7004hwvouh3wudp4e","category_id":"cmh498ip00038wvou3btofi23","_id":"cmh498ip90050wvougpp91tsw"},{"post_id":"cmh498ip8004vwvouebu6bl2g","category_id":"cmh498iov002iwvoubenbh8q3","_id":"cmh498ipa0054wvouf4ba7pmd"},{"post_id":"cmh498ip7004kwvou3ef626ye","category_id":"cmh498ip8004rwvou85za9xd6","_id":"cmh498ipb0057wvou2a1b0py1"},{"post_id":"cmh498ip9004zwvou9nag711j","category_id":"cmh498ip1003fwvou1ab8djs3","_id":"cmh498ipb005bwvoufyl76v0e"},{"post_id":"cmh498ip90051wvoudvmd7r8s","category_id":"cmh498ip1003fwvou1ab8djs3","_id":"cmh498ipc005dwvoubw4y30sc"},{"post_id":"cmh498ipa0053wvou1y3b1bbw","category_id":"cmh498ip8004rwvou85za9xd6","_id":"cmh498ipc005gwvou9gcodb77"},{"post_id":"cmh498ipa0056wvou9zu7dkzz","category_id":"cmh498ip1003fwvou1ab8djs3","_id":"cmh498ipd005jwvou8d5fat6i"},{"post_id":"cmh498ipb005awvou33w65i5m","category_id":"cmh498ip00038wvou3btofi23","_id":"cmh498ipd005mwvoudt2w5cza"},{"post_id":"cmh498ipb005cwvoueg0y9kmy","category_id":"cmh498iol000vwvou65jqgsu2","_id":"cmh498ipe005qwvoud544cbku"},{"post_id":"cmh498ipc005fwvou5ihu2ewt","category_id":"cmh498iov002iwvoubenbh8q3","_id":"cmh498ipe005twvou7qxg8ga5"},{"post_id":"cmh498ipc005iwvoud7rv8twu","category_id":"cmh498iox002swvoub6h1bc8l","_id":"cmh498ipf005wwvou0c1l5fr1"},{"post_id":"cmh498ipd005lwvou4zlmhzy4","category_id":"cmh498iol000vwvou65jqgsu2","_id":"cmh498ipf005zwvou6t5rbhkm"},{"post_id":"cmh498ipd005pwvou44fjgpmo","category_id":"cmh498iox002swvoub6h1bc8l","_id":"cmh498ipg0063wvouc5fegie3"},{"post_id":"cmh498ipe005swvou9posese6","category_id":"cmh498iov002iwvoubenbh8q3","_id":"cmh498ipg0066wvouevgy8fgj"},{"post_id":"cmh498ipe005vwvou23ojbvbi","category_id":"cmh498iox002swvoub6h1bc8l","_id":"cmh498iph0069wvouh2400z3j"},{"post_id":"cmh498ipf005ywvoudxnjftlh","category_id":"cmh498ip1003fwvou1ab8djs3","_id":"cmh498iph006cwvou81ebaa8d"},{"post_id":"cmh498ipf0062wvouh3uo5rmk","category_id":"cmh498iox002swvoub6h1bc8l","_id":"cmh498iph006ewvou60sr58as"},{"post_id":"cmh498ipg0068wvou4uqtgba7","category_id":"cmh498ip00038wvou3btofi23","_id":"cmh498ipi006iwvou77cj74xi"},{"post_id":"cmh498iph006bwvoufvjs5mwb","category_id":"cmh498iox002swvoub6h1bc8l","_id":"cmh498ipi006lwvou0veic0zv"},{"post_id":"cmh498ipj006nwvou1qkt23l6","category_id":"cmh498ip00038wvou3btofi23","_id":"cmh498ipk006uwvou7ojy120x"},{"post_id":"cmh498iph006dwvou0qiz127b","category_id":"cmh498ipi006jwvouczyyhiqz","_id":"cmh498ipl006ywvou49k88arb"},{"post_id":"cmh498ipj006owvouagpj8aws","category_id":"cmh498ip00038wvou3btofi23","_id":"cmh498ipl0071wvou6te2g8n9"},{"post_id":"cmh498ipk006rwvouflovbzzx","category_id":"cmh498ipi006jwvouczyyhiqz","_id":"cmh498ipm0074wvoud1h8aiqf"},{"post_id":"cmh498ipi006kwvou29r26yjm","category_id":"cmh498ipi006jwvouczyyhiqz","_id":"cmh498ipm0077wvoua52vap0f"},{"post_id":"cmh498ipk006twvou3qbr62hf","category_id":"cmh498ip00038wvou3btofi23","_id":"cmh498ipn007awvoubbhq0acv"},{"post_id":"cmh498ipk006xwvou9spx2yug","category_id":"cmh498iox002swvoub6h1bc8l","_id":"cmh498ipn007dwvoubvnmcu19"},{"post_id":"cmh498ipl0070wvou6tf3c26x","category_id":"cmh498iox002swvoub6h1bc8l","_id":"cmh498ipn007fwvou9ujc0gsz"},{"post_id":"cmh498ipm0076wvouhehmdye5","category_id":"cmh498iox002swvoub6h1bc8l","_id":"cmh498ipo007jwvoud0bkhkk2"},{"post_id":"cmh498ipm0079wvougo3u3goc","category_id":"cmh498iox002swvoub6h1bc8l","_id":"cmh498ipp007mwvou8ubzay8c"},{"post_id":"cmh498ipn007cwvou4gjng4ag","category_id":"cmh498iox002swvoub6h1bc8l","_id":"cmh498ipp007pwvou1mt72d1w"},{"post_id":"cmh498ipl0073wvou8ilu4132","category_id":"cmh498ipm0078wvougjmpbftb","_id":"cmh498ipp007rwvouavx0aypi"},{"post_id":"cmh498ipn007ewvou9x1g7htb","category_id":"cmh498iob0004wvou3t2m1wbh","_id":"cmh498ipq007vwvou59tia5f0"},{"post_id":"cmh498ipo007lwvou9ex12wpm","category_id":"cmh498ipi006jwvouczyyhiqz","_id":"cmh498ipq007ywvou2cfydhe7"},{"post_id":"cmh498ipp007owvou4zja66fs","category_id":"cmh498ip1003fwvou1ab8djs3","_id":"cmh498ipr0082wvouaj7cc1dg"},{"post_id":"cmh498ipp007qwvou77mb03js","category_id":"cmh498ipi006jwvouczyyhiqz","_id":"cmh498ipr0085wvou82xm78hu"},{"post_id":"cmh498ipq007uwvouc4si70gu","category_id":"cmh498ip1003fwvou1ab8djs3","_id":"cmh498ips0089wvou59m6eqsu"},{"post_id":"cmh498ipq007xwvoucuvxgv8u","category_id":"cmh498ip1003fwvou1ab8djs3","_id":"cmh498ips008cwvouhh8sgynw"},{"post_id":"cmh498ipr0081wvou5le0dqas","category_id":"cmh498ip1003fwvou1ab8djs3","_id":"cmh498ipt008gwvouh9mk15lf"},{"post_id":"cmh498ipr0084wvou73wi1qzs","category_id":"cmh498ip1003fwvou1ab8djs3","_id":"cmh498ipt008jwvou5duz5m8j"},{"post_id":"cmh498ips0088wvou7caj7rhk","category_id":"cmh498ip1003fwvou1ab8djs3","_id":"cmh498ipu008nwvouhfuraaeu"},{"post_id":"cmh498ips008bwvouel0uhxer","category_id":"cmh498ip1003fwvou1ab8djs3","_id":"cmh498ipu008qwvou6vur6d4i"},{"post_id":"cmh498ipt008fwvou1bvg9k2b","category_id":"cmh498ip1003fwvou1ab8djs3","_id":"cmh498ipv008uwvoucxir8lfx"},{"post_id":"cmh498ipt008iwvoub8hh2vwz","category_id":"cmh498ip1003fwvou1ab8djs3","_id":"cmh498ipv008xwvou97nm6z1i"},{"post_id":"cmh498ipu008mwvoubh8w0a1l","category_id":"cmh498ip1003fwvou1ab8djs3","_id":"cmh498ipw0091wvou8ze825zf"},{"post_id":"cmh498ipu008pwvouhs8qbscr","category_id":"cmh498ip00038wvou3btofi23","_id":"cmh498ipw0094wvou6tz2eqnf"},{"post_id":"cmh498ipu008twvougtpyb6o6","category_id":"cmh498ip1003fwvou1ab8djs3","_id":"cmh498ipx0098wvou1ulr5ml6"},{"post_id":"cmh498ipv008wwvoubrk97maz","category_id":"cmh498ip1003fwvou1ab8djs3","_id":"cmh498ipx009bwvou2an76uv0"},{"post_id":"cmh498ipv0090wvou31ctgdik","category_id":"cmh498ip1003fwvou1ab8djs3","_id":"cmh498ipx009ewvoub9uv6eh1"},{"post_id":"cmh498ipw0093wvou11pb8bv0","category_id":"cmh498ip1003fwvou1ab8djs3","_id":"cmh498ipy009iwvou3wug2y5h"},{"post_id":"cmh498ipw0097wvou33mx8431","category_id":"cmh498ip1003fwvou1ab8djs3","_id":"cmh498ipy009lwvougpqca0np"},{"post_id":"cmh498ipx009awvougsvaadgt","category_id":"cmh498ip1003fwvou1ab8djs3","_id":"cmh498ipz009pwvoufrta3xq7"},{"post_id":"cmh498ipx009dwvou8dd16i3i","category_id":"cmh498ip1003fwvou1ab8djs3","_id":"cmh498ipz009swvou41tecs3f"},{"post_id":"cmh498ipy009hwvou4abq4acv","category_id":"cmh498ip1003fwvou1ab8djs3","_id":"cmh498iq0009wwvoudm2v7mcb"},{"post_id":"cmh498ipy009kwvoud8jffz90","category_id":"cmh498ip1003fwvou1ab8djs3","_id":"cmh498iq0009zwvou5g389xas"},{"post_id":"cmh498ipy009owvoua09v1k7i","category_id":"cmh498ip1003fwvou1ab8djs3","_id":"cmh498iq100a3wvoua3tg3q9b"},{"post_id":"cmh498ipz009rwvoud9at681t","category_id":"cmh498ip1003fwvou1ab8djs3","_id":"cmh498iq100a6wvoub7av2mxp"},{"post_id":"cmh498ipz009vwvou3zyhdw81","category_id":"cmh498ip1003fwvou1ab8djs3","_id":"cmh498iq200aawvou7apw1cxm"},{"post_id":"cmh498iq0009ywvou7w3xg94z","category_id":"cmh498ip1003fwvou1ab8djs3","_id":"cmh498iq200adwvougpl64sq2"},{"post_id":"cmh498iq000a2wvou9webh8do","category_id":"cmh498ip1003fwvou1ab8djs3","_id":"cmh498iq300ahwvoufllzfdkf"},{"post_id":"cmh498iq100a5wvoudgl9begy","category_id":"cmh498ip1003fwvou1ab8djs3","_id":"cmh498iq300akwvou2pl0a0te"},{"post_id":"cmh498iq100a9wvou8dzb0u0h","category_id":"cmh498ip1003fwvou1ab8djs3","_id":"cmh498iq300aowvou9n18cvah"},{"post_id":"cmh498iq200acwvou158u7417","category_id":"cmh498ip1003fwvou1ab8djs3","_id":"cmh498iq400arwvou3vbs1hh8"},{"post_id":"cmh498iq200agwvougr0d2fbj","category_id":"cmh498ip1003fwvou1ab8djs3","_id":"cmh498iq400avwvouca9v9c8l"},{"post_id":"cmh498iq300ajwvoub6x09ubt","category_id":"cmh498ip1003fwvou1ab8djs3","_id":"cmh498iq500aywvou5pm64ot6"},{"post_id":"cmh498iq300anwvoudugq7h9j","category_id":"cmh498ip1003fwvou1ab8djs3","_id":"cmh498iq500b2wvou4y25dv6h"},{"post_id":"cmh498iq400aqwvoughwb2un5","category_id":"cmh498ip1003fwvou1ab8djs3","_id":"cmh498iq600b5wvoubth3chux"},{"post_id":"cmh498iq500axwvoufua4hda1","category_id":"cmh498ip1003fwvou1ab8djs3","_id":"cmh498iq600b8wvou9r964bug"},{"post_id":"cmh498iq500b1wvou6tve0g4i","category_id":"cmh498ip1003fwvou1ab8djs3","_id":"cmh498iq700bcwvou7a9yc50k"},{"post_id":"cmh498iq600b4wvou9z4jdbjg","category_id":"cmh498ip1003fwvou1ab8djs3","_id":"cmh498iq700bfwvou5bzu5xpc"},{"post_id":"cmh498iq600b7wvouewcac68n","category_id":"cmh498iox002swvoub6h1bc8l","_id":"cmh498iq800bjwvou3zm9gcwn"},{"post_id":"cmh498iq700bbwvou4zygd0cd","category_id":"cmh498iox002swvoub6h1bc8l","_id":"cmh498iq800bmwvou7zxefu09"},{"post_id":"cmh498iq700bewvou9spi1ea3","category_id":"cmh498ip1003fwvou1ab8djs3","_id":"cmh498iq900bqwvou37n7h0lc"},{"post_id":"cmh498iq700biwvouhug50cg3","category_id":"cmh498ip1003fwvou1ab8djs3","_id":"cmh498iq900btwvou5yqm20m6"},{"post_id":"cmh498iq800blwvou2uct6eg9","category_id":"cmh498ip1003fwvou1ab8djs3","_id":"cmh498iqc00bxwvoug6mybcj9"},{"post_id":"cmh498iq800bpwvou0dce8zp9","category_id":"cmh498ip1003fwvou1ab8djs3","_id":"cmh498iqd00c0wvoudzoza1ga"},{"post_id":"cmh498iq900bswvougtvv2upr","category_id":"cmh498ip1003fwvou1ab8djs3","_id":"cmh498iqd00c4wvou112h9nuz"},{"post_id":"cmh498iqc00bwwvou9hpmdj0d","category_id":"cmh498ip1003fwvou1ab8djs3","_id":"cmh498iqe00c8wvouaw987d99"},{"post_id":"cmh498iqd00c7wvouhtlrfad4","category_id":"cmh498ip8004rwvou85za9xd6","_id":"cmh498iqf00ciwvou2uds17oh"},{"post_id":"cmh498iqe00cbwvou5tbghpij","category_id":"cmh498ip1003fwvou1ab8djs3","_id":"cmh498iqg00clwvou2g4f0bqs"},{"post_id":"cmh498iqc00bzwvou9lnd56t9","category_id":"cmh498iqd00c5wvou4mzzfude","_id":"cmh498iqg00cpwvoufroce8hn"},{"post_id":"cmh498iqe00cdwvou9wtxheij","category_id":"cmh498iqd00c5wvou4mzzfude","_id":"cmh498iqh00ctwvou16yx182d"},{"post_id":"cmh498iqf00chwvouglttbu7x","category_id":"cmh498iob0004wvou3t2m1wbh","_id":"cmh498iqh00cwwvoudpu7a3ly"},{"post_id":"cmh498iqd00c3wvou6v5480u5","category_id":"cmh498iqd00c5wvou4mzzfude","_id":"cmh498iqi00d0wvou4xlobkzr"},{"post_id":"cmh498iqg00cowvoufqha4uef","category_id":"cmh498ip1003fwvou1ab8djs3","_id":"cmh498iqi00d3wvoubbye4wde"},{"post_id":"cmh498iqh00cswvoudssp2rfy","category_id":"cmh498ip1003fwvou1ab8djs3","_id":"cmh498iqj00d7wvou5s4e8mam"},{"post_id":"cmh498iqh00cvwvou3hrt4mm4","category_id":"cmh498ip1003fwvou1ab8djs3","_id":"cmh498iqj00dawvou0vj4gv8e"},{"post_id":"cmh498iqg00ckwvou9ven8kv6","category_id":"cmh498iqg00cqwvou8510dynk","_id":"cmh498iqk00dewvou1gnt80g9"},{"post_id":"cmh498iqi00czwvou4jqfaify","category_id":"cmh498iox002swvoub6h1bc8l","_id":"cmh498iqk00dhwvou8cil435l"},{"post_id":"cmh498iqi00d2wvouct9ubg2x","category_id":"cmh498ip1003fwvou1ab8djs3","_id":"cmh498iql00dmwvoufttr2q6v"},{"post_id":"cmh498iqj00d6wvou535teuqd","category_id":"cmh498ip00038wvou3btofi23","_id":"cmh498iql00dpwvou5g7zcwnw"},{"post_id":"cmh498iqj00d9wvougkgu3pxh","category_id":"cmh498ip1003fwvou1ab8djs3","_id":"cmh498iqm00dswvou6y4yabsi"},{"post_id":"cmh498iqk00dgwvou1244bccq","category_id":"cmh498ip00038wvou3btofi23","_id":"cmh498iqm00dwwvoudd2l1b24"},{"post_id":"cmh498iqk00dlwvou9815gcyr","category_id":"cmh498iov002iwvoubenbh8q3","_id":"cmh498iqm00dzwvoug0lz2ucy"},{"post_id":"cmh498iql00dowvou3cfygoar","category_id":"cmh498ip1003fwvou1ab8djs3","_id":"cmh498iqn00e3wvouajy1er2q"},{"post_id":"cmh498iqk00ddwvou80ac70wq","category_id":"cmh498iqk00diwvou47358807","_id":"cmh498iqn00e6wvou1zqlh9br"},{"post_id":"cmh498iqm00dvwvoufw3ua8ri","category_id":"cmh498ip1003fwvou1ab8djs3","_id":"cmh498iqo00e9wvou5fr68xwk"},{"post_id":"cmh498iqm00dywvou4iw3dngc","category_id":"cmh498iqk00diwvou47358807","_id":"cmh498iqo00ecwvou6afqbm5y"},{"post_id":"cmh498iqn00e2wvou6i2v0pnc","category_id":"cmh498iqk00diwvou47358807","_id":"cmh498iqp00egwvou2rd8eteq"},{"post_id":"cmh498iqn00e5wvoueydygus8","category_id":"cmh498iox002swvoub6h1bc8l","_id":"cmh498iqp00eiwvoue10h6irf"},{"post_id":"cmh498iqo00e8wvou8fvg7htv","category_id":"cmh498iox002swvoub6h1bc8l","_id":"cmh498iqp00ekwvouf7a88kq4"},{"post_id":"cmh498iqo00ebwvou5rgmepmb","category_id":"cmh498ip1003fwvou1ab8djs3","_id":"cmh498iqp00enwvou9liu3yl9"},{"post_id":"cmh498iqp00efwvou1h6rcthc","category_id":"cmh498ip1003fwvou1ab8djs3","_id":"cmh498iqp00epwvou817r70ry"},{"post_id":"cmh498ir200i8wvouac8423u4","category_id":"cmh498ip1003fwvou1ab8djs3","_id":"cmh498ir300iawvoufg8b5y93"}],"PostTag":[{"post_id":"cmh498io60001wvou0n657en9","tag_id":"cmh498ioc0005wvou6fvw7pla","_id":"cmh498iog000dwvoucz3lfrdl"},{"post_id":"cmh498io90003wvou3k2u7eug","tag_id":"cmh498iof000cwvouekka9sc9","_id":"cmh498ioi000lwvou0rin5sxn"},{"post_id":"cmh498ioc0007wvouhzx3ccb4","tag_id":"cmh498ioh000iwvouaaka060z","_id":"cmh498iok000swvouar31hgyy"},{"post_id":"cmh498iod0009wvouhqnc1583","tag_id":"cmh498ioh000iwvouaaka060z","_id":"cmh498iom000zwvougovk9uzg"},{"post_id":"cmh498ioe000awvoualyhgorn","tag_id":"cmh498ioh000iwvouaaka060z","_id":"cmh498ion0016wvou58u04lk4"},{"post_id":"cmh498iog000ewvoubleu9i6i","tag_id":"cmh498iom0013wvou6bn648ta","_id":"cmh498iop001hwvou5cwk7l9o"},{"post_id":"cmh498iog000ewvoubleu9i6i","tag_id":"cmh498ioo0019wvou36zch6ax","_id":"cmh498ioq001kwvou3sn62rcx"},{"post_id":"cmh498ioh000fwvou4ll8gwt4","tag_id":"cmh498ioh000iwvouaaka060z","_id":"cmh498ioq001owvouhxx40b79"},{"post_id":"cmh498ioi000jwvou9hu6gacb","tag_id":"cmh498ioq001nwvou148e8f00","_id":"cmh498ios001wwvou0eo0a5c9"},{"post_id":"cmh498ioi000mwvou4d412v2b","tag_id":"cmh498ior001twvouhy2ledkg","_id":"cmh498iot0022wvou71m666ws"},{"post_id":"cmh498ioi000mwvou4d412v2b","tag_id":"cmh498ioh000iwvouaaka060z","_id":"cmh498iot0025wvougw30fndr"},{"post_id":"cmh498ioj000qwvou8tn18cpn","tag_id":"cmh498ioq001nwvou148e8f00","_id":"cmh498iov002ewvou54ra3tbs"},{"post_id":"cmh498ioj000qwvou8tn18cpn","tag_id":"cmh498iot0026wvou51vu50q1","_id":"cmh498iov002hwvouf94sgo6d"},{"post_id":"cmh498iop001iwvoubyxeg7ne","tag_id":"cmh498iou002bwvou0an9g2yt","_id":"cmh498iow002mwvouev1fepp3"},{"post_id":"cmh498ior001uwvouhyjj0p2g","tag_id":"cmh498iow002lwvou611b3znx","_id":"cmh498iox002vwvoubbx26rm8"},{"post_id":"cmh498iow002pwvouh9276n5y","tag_id":"cmh498ioh000iwvouaaka060z","_id":"cmh498ioy002ywvou4gvo18ac"},{"post_id":"cmh498ios001xwvou589f7xmh","tag_id":"cmh498iox002rwvoud5qdhv8h","_id":"cmh498ioz0032wvou33i84w8u"},{"post_id":"cmh498iot0020wvou3ak11fag","tag_id":"cmh498ioy002zwvougebihk2w","_id":"cmh498ip3003swvou27ideiiu"},{"post_id":"cmh498iot0020wvou3ak11fag","tag_id":"cmh498ioz0035wvou1wochdf7","_id":"cmh498ip4003vwvou8rna8v1k"},{"post_id":"cmh498iot0020wvou3ak11fag","tag_id":"cmh498ip0003dwvoudnpd88kx","_id":"cmh498ip4003zwvoufzrj863h"},{"post_id":"cmh498iot0020wvou3ak11fag","tag_id":"cmh498ip2003jwvouadky7rhm","_id":"cmh498ip40042wvou73bpd6io"},{"post_id":"cmh498ip40040wvou06fj7cp5","tag_id":"cmh498ioh000iwvouaaka060z","_id":"cmh498ip50046wvou86nlf15n"},{"post_id":"cmh498iot0023wvou9rkcep4f","tag_id":"cmh498ip3003pwvou9v6kc1s9","_id":"cmh498ip7004jwvou4dylbugx"},{"post_id":"cmh498iot0023wvou9rkcep4f","tag_id":"cmh498ip4003wwvoueykbd68k","_id":"cmh498ip7004mwvou9gwjel3b"},{"post_id":"cmh498iot0023wvou9rkcep4f","tag_id":"cmh498ip50045wvou03m0b1ad","_id":"cmh498ip8004qwvou37iu55td"},{"post_id":"cmh498iot0023wvou9rkcep4f","tag_id":"cmh498ip6004bwvou85fcadmh","_id":"cmh498ip8004uwvou8yxuaxcj"},{"post_id":"cmh498iou0027wvoueas44p0s","tag_id":"cmh498ip6004gwvou6wde14nu","_id":"cmh498ip9004ywvou5pzn73m4"},{"post_id":"cmh498iou0029wvou96pp777i","tag_id":"cmh498ip7004nwvouapx48jgs","_id":"cmh498ipa0055wvou2fw4hz23"},{"post_id":"cmh498iou0029wvou96pp777i","tag_id":"cmh498ip9004xwvoudou478k9","_id":"cmh498ipb0058wvou41sy4lqo"},{"post_id":"cmh498iou002cwvouax8i09uw","tag_id":"cmh498ioq001nwvou148e8f00","_id":"cmh498ipc005hwvou7r8ne7r7"},{"post_id":"cmh498iou002cwvouax8i09uw","tag_id":"cmh498ipa0052wvougwl48x4b","_id":"cmh498ipd005kwvou0jtnet41"},{"post_id":"cmh498iou002cwvouax8i09uw","tag_id":"cmh498ipb0059wvou08k3gxcz","_id":"cmh498ipd005owvou7hnib109"},{"post_id":"cmh498iov002fwvouba99g50k","tag_id":"cmh498ipc005ewvoubett1rs5","_id":"cmh498ipe005rwvou7k6t5nir"},{"post_id":"cmh498iov002jwvou1sv3beo8","tag_id":"cmh498ipd005nwvoubwrxdvmr","_id":"cmh498ipf005xwvou3b1qbn9w"},{"post_id":"cmh498ipe005swvou9posese6","tag_id":"cmh498ioh000iwvouaaka060z","_id":"cmh498ipf0060wvougabgd7ca"},{"post_id":"cmh498iow002nwvoucc8h5nij","tag_id":"cmh498ipe005uwvou5rztfal5","_id":"cmh498ipg0064wvouffqxe4jr"},{"post_id":"cmh498ioy002wwvou4yvyavgn","tag_id":"cmh498ipf0061wvou3s8w9zuw","_id":"cmh498iph006awvoudnsofch3"},{"post_id":"cmh498ioy0030wvou6ogid0sc","tag_id":"cmh498ipg0067wvou7wwtb3s0","_id":"cmh498ipi006gwvou0899auky"},{"post_id":"cmh498ioz0033wvoufssygo7p","tag_id":"cmh498iph006fwvouaf2b6so5","_id":"cmh498ipk006swvouhb2c4jh9"},{"post_id":"cmh498ioz0033wvoufssygo7p","tag_id":"cmh498ipi006mwvouhrwh5z5d","_id":"cmh498ipk006vwvouaozx697l"},{"post_id":"cmh498ioz0036wvouc1gceybh","tag_id":"cmh498ipj006qwvou4hx1451h","_id":"cmh498ipl006zwvouaiq18dp5"},{"post_id":"cmh498ip00039wvou21594zk6","tag_id":"cmh498iph006fwvouaf2b6so5","_id":"cmh498ipm0075wvou5m14agfb"},{"post_id":"cmh498ip0003bwvou60orgw44","tag_id":"cmh498ipl0072wvou35k4arlw","_id":"cmh498ipo007hwvouha242da2"},{"post_id":"cmh498ip0003bwvou60orgw44","tag_id":"cmh498iph006fwvouaf2b6so5","_id":"cmh498ipo007kwvouevk33fi4"},{"post_id":"cmh498ipp007owvou4zja66fs","tag_id":"cmh498ipj006qwvou4hx1451h","_id":"cmh498ipq007twvou70ot0whp"},{"post_id":"cmh498ip1003ewvouezu14ivt","tag_id":"cmh498iph006fwvouaf2b6so5","_id":"cmh498ipq007wwvoucqohfssx"},{"post_id":"cmh498ip1003ewvouezu14ivt","tag_id":"cmh498ipi006mwvouhrwh5z5d","_id":"cmh498ipr0080wvou0xdw7eom"},{"post_id":"cmh498ipq007xwvoucuvxgv8u","tag_id":"cmh498ipj006qwvou4hx1451h","_id":"cmh498ipr0083wvou7qqxfgfo"},{"post_id":"cmh498ipr0081wvou5le0dqas","tag_id":"cmh498ipj006qwvou4hx1451h","_id":"cmh498ips0087wvouelbw7vry"},{"post_id":"cmh498ip1003hwvouer8ncrf9","tag_id":"cmh498ipi006mwvouhrwh5z5d","_id":"cmh498ips008awvou53724ow3"},{"post_id":"cmh498ip1003hwvouer8ncrf9","tag_id":"cmh498iph006fwvouaf2b6so5","_id":"cmh498ipt008ewvou56pxe9r3"},{"post_id":"cmh498ipr0084wvou73wi1qzs","tag_id":"cmh498ipj006qwvou4hx1451h","_id":"cmh498ipt008hwvou9xyh0oy7"},{"post_id":"cmh498ips0088wvou7caj7rhk","tag_id":"cmh498ipj006qwvou4hx1451h","_id":"cmh498ipu008lwvou1w74786k"},{"post_id":"cmh498ips008bwvouel0uhxer","tag_id":"cmh498ipj006qwvou4hx1451h","_id":"cmh498ipu008owvou4xrkhfzo"},{"post_id":"cmh498ipt008fwvou1bvg9k2b","tag_id":"cmh498ipj006qwvou4hx1451h","_id":"cmh498ipu008swvou3g0a48hm"},{"post_id":"cmh498ip2003kwvouas2b8vph","tag_id":"cmh498ipi006mwvouhrwh5z5d","_id":"cmh498ipv008vwvou3jr1ecmu"},{"post_id":"cmh498ip2003kwvouas2b8vph","tag_id":"cmh498iph006fwvouaf2b6so5","_id":"cmh498ipv008zwvougnnwekne"},{"post_id":"cmh498ipu008mwvoubh8w0a1l","tag_id":"cmh498ipj006qwvou4hx1451h","_id":"cmh498ipw0092wvou9k0v3spr"},{"post_id":"cmh498ip2003nwvou0y6vdlwi","tag_id":"cmh498ipt008kwvoue6443fl9","_id":"cmh498ipw0095wvoucwvb63ch"},{"post_id":"cmh498ipu008pwvouhs8qbscr","tag_id":"cmh498ipl0072wvou35k4arlw","_id":"cmh498ipx0099wvou4wq93v4r"},{"post_id":"cmh498ipu008twvougtpyb6o6","tag_id":"cmh498ipj006qwvou4hx1451h","_id":"cmh498ipx009cwvoudutx6ap0"},{"post_id":"cmh498ipv008wwvoubrk97maz","tag_id":"cmh498ipj006qwvou4hx1451h","_id":"cmh498ipy009gwvou10fma24o"},{"post_id":"cmh498ipv0090wvou31ctgdik","tag_id":"cmh498ipj006qwvou4hx1451h","_id":"cmh498ipy009jwvou144ce6w0"},{"post_id":"cmh498ip3003qwvou53sfaf2c","tag_id":"cmh498ipu008rwvou6g40dke1","_id":"cmh498ipy009nwvou8nd2cxm2"},{"post_id":"cmh498ip3003qwvou53sfaf2c","tag_id":"cmh498ipv008ywvouhpj5gh6g","_id":"cmh498ipz009qwvouf44nbupz"},{"post_id":"cmh498ipw0093wvou11pb8bv0","tag_id":"cmh498ipj006qwvou4hx1451h","_id":"cmh498ipz009uwvou0mqi23zy"},{"post_id":"cmh498ipx009awvougsvaadgt","tag_id":"cmh498ipj006qwvou4hx1451h","_id":"cmh498iq0009xwvoubxwd3zft"},{"post_id":"cmh498ip3003twvoud0vl2eog","tag_id":"cmh498ipw0096wvouhjtd8hf3","_id":"cmh498iq000a1wvou1ifc2m29"},{"post_id":"cmh498ipx009dwvou8dd16i3i","tag_id":"cmh498ipj006qwvou4hx1451h","_id":"cmh498iq100a4wvoue5hna2if"},{"post_id":"cmh498ipy009hwvou4abq4acv","tag_id":"cmh498ipj006qwvou4hx1451h","_id":"cmh498iq100a8wvou1drc8lbo"},{"post_id":"cmh498ipy009owvoua09v1k7i","tag_id":"cmh498ipj006qwvou4hx1451h","_id":"cmh498iq200abwvou9bv7hpkp"},{"post_id":"cmh498ip4003xwvou2p5pcvxo","tag_id":"cmh498ipx009fwvoucj5i97gj","_id":"cmh498iq200aewvoueneu8tg6"},{"post_id":"cmh498ip4003xwvou2p5pcvxo","tag_id":"cmh498ipy009mwvou65h05ths","_id":"cmh498iq300aiwvou2jjlddwc"},{"post_id":"cmh498ipz009rwvoud9at681t","tag_id":"cmh498ipj006qwvou4hx1451h","_id":"cmh498iq300alwvou0lg19yai"},{"post_id":"cmh498ipz009vwvou3zyhdw81","tag_id":"cmh498ipj006qwvou4hx1451h","_id":"cmh498iq400apwvoubmvt6tg0"},{"post_id":"cmh498iq0009ywvou7w3xg94z","tag_id":"cmh498ipj006qwvou4hx1451h","_id":"cmh498iq400aswvou3s6dh98h"},{"post_id":"cmh498iq000a2wvou9webh8do","tag_id":"cmh498ipj006qwvou4hx1451h","_id":"cmh498iq500awwvou0b11h8mx"},{"post_id":"cmh498ip40043wvouaas52xkg","tag_id":"cmh498ipl0072wvou35k4arlw","_id":"cmh498iq500azwvou19cr5i96"},{"post_id":"cmh498ip40043wvouaas52xkg","tag_id":"cmh498ipi006mwvouhrwh5z5d","_id":"cmh498iq500b3wvoud1gl0m9l"},{"post_id":"cmh498iq200agwvougr0d2fbj","tag_id":"cmh498iph006fwvouaf2b6so5","_id":"cmh498iq600b6wvou5x5p27si"},{"post_id":"cmh498iq300ajwvoub6x09ubt","tag_id":"cmh498ipj006qwvou4hx1451h","_id":"cmh498iq600bawvou300xbjjt"},{"post_id":"cmh498iq300anwvoudugq7h9j","tag_id":"cmh498ipj006qwvou4hx1451h","_id":"cmh498iq700bdwvou2xbq6dtx"},{"post_id":"cmh498iq400aqwvoughwb2un5","tag_id":"cmh498ipj006qwvou4hx1451h","_id":"cmh498iq700bhwvou6pz9cqeq"},{"post_id":"cmh498ip50047wvouh46p3e36","tag_id":"cmh498iq100a7wvou9g0i2dfm","_id":"cmh498iq800bkwvou3jo8dqy9"},{"post_id":"cmh498ip50047wvouh46p3e36","tag_id":"cmh498ipl0072wvou35k4arlw","_id":"cmh498iq800bowvou3clgg7eu"},{"post_id":"cmh498ip50047wvouh46p3e36","tag_id":"cmh498ipi006mwvouhrwh5z5d","_id":"cmh498iq900brwvou3fri1ky9"},{"post_id":"cmh498ip50047wvouh46p3e36","tag_id":"cmh498iph006fwvouaf2b6so5","_id":"cmh498iqc00bvwvou7v9p1c1o"},{"post_id":"cmh498iq500axwvoufua4hda1","tag_id":"cmh498ipj006qwvou4hx1451h","_id":"cmh498iqc00bywvougbwwcqr8"},{"post_id":"cmh498iq500b1wvou6tve0g4i","tag_id":"cmh498ipj006qwvou4hx1451h","_id":"cmh498iqd00c2wvou71vw8lb1"},{"post_id":"cmh498iq600b4wvou9z4jdbjg","tag_id":"cmh498ipj006qwvou4hx1451h","_id":"cmh498iqd00c6wvouf35j4edp"},{"post_id":"cmh498ip50049wvoufw2tby5o","tag_id":"cmh498iq500b0wvou7bg90nuc","_id":"cmh498iqe00cawvou0bbkgf7m"},{"post_id":"cmh498iq600b7wvouewcac68n","tag_id":"cmh498iq500b0wvou7bg90nuc","_id":"cmh498iqe00ccwvoudc57bmbk"},{"post_id":"cmh498iq700bbwvou4zygd0cd","tag_id":"cmh498iq500b0wvou7bg90nuc","_id":"cmh498iqf00cgwvoubzdv9wzo"},{"post_id":"cmh498iq700bewvou9spi1ea3","tag_id":"cmh498ipj006qwvou4hx1451h","_id":"cmh498iqf00cjwvoufubw435x"},{"post_id":"cmh498iq700biwvouhug50cg3","tag_id":"cmh498ipj006qwvou4hx1451h","_id":"cmh498iqg00cmwvoud1qqd3aw"},{"post_id":"cmh498ip6004cwvou67j4f5om","tag_id":"cmh498ipl0072wvou35k4arlw","_id":"cmh498iqh00crwvouf005e3al"},{"post_id":"cmh498ip6004cwvou67j4f5om","tag_id":"cmh498iq700bgwvoua2uubgwn","_id":"cmh498iqh00cuwvougplkfci2"},{"post_id":"cmh498ip6004ewvouc2h623rn","tag_id":"cmh498iq800bnwvou5n0bcx7h","_id":"cmh498iqi00cywvou242890s9"},{"post_id":"cmh498iqc00bwwvou9hpmdj0d","tag_id":"cmh498ipj006qwvou4hx1451h","_id":"cmh498iqi00d1wvou1max0rp4"},{"post_id":"cmh498ip7004hwvouh3wudp4e","tag_id":"cmh498iph006fwvouaf2b6so5","_id":"cmh498iqj00d5wvou70v23baq"},{"post_id":"cmh498ip7004hwvouh3wudp4e","tag_id":"cmh498ipl0072wvou35k4arlw","_id":"cmh498iqj00d8wvou3ybk5677"},{"post_id":"cmh498ip7004hwvouh3wudp4e","tag_id":"cmh498ipi006mwvouhrwh5z5d","_id":"cmh498iqj00dcwvou16gl2xna"},{"post_id":"cmh498ip7004kwvou3ef626ye","tag_id":"cmh498iqf00cfwvou33gkbpb8","_id":"cmh498iqk00dfwvou6qh5cxh8"},{"post_id":"cmh498ip7004kwvou3ef626ye","tag_id":"cmh498iqg00cnwvou2ti2hhvm","_id":"cmh498iqk00djwvouhgy8ctj6"},{"post_id":"cmh498iqi00czwvou4jqfaify","tag_id":"cmh498iq500b0wvou7bg90nuc","_id":"cmh498iql00dnwvou23ds5lfz"},{"post_id":"cmh498ip8004vwvouebu6bl2g","tag_id":"cmh498iqh00cxwvouhnx59kur","_id":"cmh498iql00dqwvou2x1560u9"},{"post_id":"cmh498iqj00d6wvou535teuqd","tag_id":"cmh498iq500b0wvou7bg90nuc","_id":"cmh498iqm00duwvou6659ed50"},{"post_id":"cmh498ip9004zwvou9nag711j","tag_id":"cmh498iqi00d4wvou8wd22268","_id":"cmh498iqm00dxwvouc03lca7d"},{"post_id":"cmh498ip90051wvoudvmd7r8s","tag_id":"cmh498iqj00dbwvou87bqc26o","_id":"cmh498iqn00e1wvouea7w3st3"},{"post_id":"cmh498ipa0053wvou1y3b1bbw","tag_id":"cmh498iqk00dkwvouff4q20o1","_id":"cmh498iqn00e4wvoufigq89gw"},{"post_id":"cmh498ipa0056wvou9zu7dkzz","tag_id":"cmh498iqm00dtwvoudxi85qgt","_id":"cmh498iqo00eawvou8re73qpw"},{"post_id":"cmh498ipa0056wvou9zu7dkzz","tag_id":"cmh498iqm00e0wvoufm8x5uxx","_id":"cmh498iqo00edwvou25wvew63"},{"post_id":"cmh498iqn00e5wvoueydygus8","tag_id":"cmh498iq500b0wvou7bg90nuc","_id":"cmh498iqp00ehwvouhb8x0t2s"},{"post_id":"cmh498iqo00e8wvou8fvg7htv","tag_id":"cmh498iq500b0wvou7bg90nuc","_id":"cmh498iqp00ejwvoua7p66o5z"},{"post_id":"cmh498ipb005awvou33w65i5m","tag_id":"cmh498iqn00e7wvou8s3a6o2e","_id":"cmh498iqp00emwvoudxqibt8n"},{"post_id":"cmh498iqo00ebwvou5rgmepmb","tag_id":"cmh498ipj006qwvou4hx1451h","_id":"cmh498iqp00eowvouc5teedtq"},{"post_id":"cmh498iqp00efwvou1h6rcthc","tag_id":"cmh498ipj006qwvou4hx1451h","_id":"cmh498iqq00erwvou4kpla7n1"},{"post_id":"cmh498ipc005fwvou5ihu2ewt","tag_id":"cmh498iqo00eewvouakzj2br8","_id":"cmh498iqq00eswvouficpba32"},{"post_id":"cmh498ipc005iwvoud7rv8twu","tag_id":"cmh498iqp00elwvou1f1m8tlj","_id":"cmh498iqq00euwvoudmid27yp"},{"post_id":"cmh498ipd005lwvou4zlmhzy4","tag_id":"cmh498ipt008kwvoue6443fl9","_id":"cmh498iqq00evwvou64jsczlh"},{"post_id":"cmh498ipd005pwvou44fjgpmo","tag_id":"cmh498ipt008kwvoue6443fl9","_id":"cmh498iqq00exwvoua4e31uz3"},{"post_id":"cmh498ipe005vwvou23ojbvbi","tag_id":"cmh498iq500b0wvou7bg90nuc","_id":"cmh498iqq00ezwvou5iu0gee4"},{"post_id":"cmh498ipf005ywvoudxnjftlh","tag_id":"cmh498iqq00eywvoueafd565e","_id":"cmh498iqq00f1wvoucp419js8"},{"post_id":"cmh498ipf0062wvouh3uo5rmk","tag_id":"cmh498ipt008kwvoue6443fl9","_id":"cmh498iqr00f3wvou6az4aqr8"},{"post_id":"cmh498ipg0068wvou4uqtgba7","tag_id":"cmh498ipl0072wvou35k4arlw","_id":"cmh498iqr00f6wvou6as36tsl"},{"post_id":"cmh498ipg0068wvou4uqtgba7","tag_id":"cmh498iph006fwvouaf2b6so5","_id":"cmh498iqr00f7wvou76v0cg7f"},{"post_id":"cmh498iph006bwvoufvjs5mwb","tag_id":"cmh498iqr00f5wvouh50ibr20","_id":"cmh498iqr00f9wvou8exfhlmp"},{"post_id":"cmh498iph006dwvou0qiz127b","tag_id":"cmh498iqr00f8wvoug754c5hx","_id":"cmh498iqr00fbwvoucmt6410h"},{"post_id":"cmh498ipi006kwvou29r26yjm","tag_id":"cmh498iqr00f8wvoug754c5hx","_id":"cmh498iqr00fdwvou074884ny"},{"post_id":"cmh498ipj006nwvou1qkt23l6","tag_id":"cmh498ipl0072wvou35k4arlw","_id":"cmh498iqs00ffwvou2ahp9ue1"},{"post_id":"cmh498ipj006nwvou1qkt23l6","tag_id":"cmh498iph006fwvouaf2b6so5","_id":"cmh498iqs00fgwvou2kw41hus"},{"post_id":"cmh498ipj006owvouagpj8aws","tag_id":"cmh498iph006fwvouaf2b6so5","_id":"cmh498iqs00fiwvou5b3s7jfi"},{"post_id":"cmh498ipj006owvouagpj8aws","tag_id":"cmh498ipl0072wvou35k4arlw","_id":"cmh498iqs00fjwvou0jx92czo"},{"post_id":"cmh498ipk006rwvouflovbzzx","tag_id":"cmh498iqr00f8wvoug754c5hx","_id":"cmh498iqs00flwvou2ruzg1kr"},{"post_id":"cmh498ipk006twvou3qbr62hf","tag_id":"cmh498iph006fwvouaf2b6so5","_id":"cmh498iqs00fnwvouhj6j9666"},{"post_id":"cmh498ipk006twvou3qbr62hf","tag_id":"cmh498ipl0072wvou35k4arlw","_id":"cmh498iqs00fowvou8sthgtef"},{"post_id":"cmh498ipk006xwvou9spx2yug","tag_id":"cmh498iqf00cfwvou33gkbpb8","_id":"cmh498iqs00fqwvou30i846th"},{"post_id":"cmh498ipl0070wvou6tf3c26x","tag_id":"cmh498iqf00cfwvou33gkbpb8","_id":"cmh498iqs00fswvouhttabits"},{"post_id":"cmh498ipl0073wvou8ilu4132","tag_id":"cmh498iqs00frwvoudllgcybh","_id":"cmh498iqt00fuwvoueb367sbc"},{"post_id":"cmh498ipm0076wvouhehmdye5","tag_id":"cmh498iqf00cfwvou33gkbpb8","_id":"cmh498iqt00fwwvou9y2xcvz9"},{"post_id":"cmh498ipm0079wvougo3u3goc","tag_id":"cmh498iqf00cfwvou33gkbpb8","_id":"cmh498iqt00fywvou1x5zg2if"},{"post_id":"cmh498ipn007cwvou4gjng4ag","tag_id":"cmh498iqt00fxwvou80rs102d","_id":"cmh498iqt00g0wvoucq2n8ckl"},{"post_id":"cmh498ipn007ewvou9x1g7htb","tag_id":"cmh498iqt00fzwvou25i8cwzb","_id":"cmh498iqt00g2wvouf4incag6"},{"post_id":"cmh498ipo007iwvou1bf04qlm","tag_id":"cmh498iqr00f8wvoug754c5hx","_id":"cmh498iqt00g4wvou2d4rc2rh"},{"post_id":"cmh498ipo007lwvou9ex12wpm","tag_id":"cmh498iqt00g3wvou19wa3fg0","_id":"cmh498iqu00g6wvou4hbpd2ys"},{"post_id":"cmh498ipp007qwvou77mb03js","tag_id":"cmh498ipu008rwvou6g40dke1","_id":"cmh498iqu00g8wvou166netpn"},{"post_id":"cmh498ipq007uwvouc4si70gu","tag_id":"cmh498iqu00g7wvouekrsgaqj","_id":"cmh498iqu00gawvou9iibdmh5"},{"post_id":"cmh498ipt008iwvoub8hh2vwz","tag_id":"cmh498iqu00g9wvougxtq3nd7","_id":"cmh498iqu00gcwvoufdum6iyi"},{"post_id":"cmh498ipw0097wvou33mx8431","tag_id":"cmh498iqu00gbwvou44ur1z0r","_id":"cmh498iqu00gfwvou25x50uqw"},{"post_id":"cmh498ipw0097wvou33mx8431","tag_id":"cmh498iqu00gdwvou07g2fwom","_id":"cmh498iqu00ggwvou4e3977vb"},{"post_id":"cmh498ipy009kwvoud8jffz90","tag_id":"cmh498iqu00gewvou693pdz4p","_id":"cmh498iqu00gjwvou3ilj9lwt"},{"post_id":"cmh498ipy009kwvoud8jffz90","tag_id":"cmh498iqu00ghwvougn0uehrx","_id":"cmh498iqu00gkwvou6pepayda"},{"post_id":"cmh498iq100a5wvoudgl9begy","tag_id":"cmh498iqu00giwvou2ykzg68g","_id":"cmh498iqu00gmwvou1aer3pjn"},{"post_id":"cmh498iq100a9wvou8dzb0u0h","tag_id":"cmh498iqu00glwvoueg6o7zmm","_id":"cmh498iqv00gowvoubqaccaqm"},{"post_id":"cmh498iq200acwvou158u7417","tag_id":"cmh498iqu00gnwvoueqeffzp3","_id":"cmh498iqv00grwvou7yh8eqri"},{"post_id":"cmh498iq200acwvou158u7417","tag_id":"cmh498iqv00gpwvou8tcd8o50","_id":"cmh498iqv00gswvoudesqejar"},{"post_id":"cmh498iq400auwvouawxthi7t","tag_id":"cmh498iq500b0wvou7bg90nuc","_id":"cmh498iqv00guwvou8s6ffl71"},{"post_id":"cmh498iq800blwvou2uct6eg9","tag_id":"cmh498iqu00gbwvou44ur1z0r","_id":"cmh498iqv00gxwvouejda8wlw"},{"post_id":"cmh498iq800blwvou2uct6eg9","tag_id":"cmh498iqu00gdwvou07g2fwom","_id":"cmh498iqv00gywvou8l7ebyrz"},{"post_id":"cmh498iq800bpwvou0dce8zp9","tag_id":"cmh498iqv00gwwvou93ud901a","_id":"cmh498iqw00h1wvou73hmgs9i"},{"post_id":"cmh498iq800bpwvou0dce8zp9","tag_id":"cmh498iqu00gnwvoueqeffzp3","_id":"cmh498iqw00h2wvouhpitark1"},{"post_id":"cmh498iq900bswvougtvv2upr","tag_id":"cmh498iqu00gnwvoueqeffzp3","_id":"cmh498iqw00h4wvou2r23f5zs"},{"post_id":"cmh498iqc00bzwvou9lnd56t9","tag_id":"cmh498iqu00gnwvoueqeffzp3","_id":"cmh498iqw00h6wvou27qxeeui"},{"post_id":"cmh498iqd00c3wvou6v5480u5","tag_id":"cmh498iqu00gnwvoueqeffzp3","_id":"cmh498iqw00h8wvou8pqn2ds5"},{"post_id":"cmh498iqd00c7wvouhtlrfad4","tag_id":"cmh498iqw00h7wvou1f8mh9nh","_id":"cmh498iqw00hbwvou4lzp7a6d"},{"post_id":"cmh498iqd00c7wvouhtlrfad4","tag_id":"cmh498iqw00h9wvou376z37rk","_id":"cmh498iqw00hcwvougcxye7yj"},{"post_id":"cmh498iqe00cbwvou5tbghpij","tag_id":"cmh498iqu00gnwvoueqeffzp3","_id":"cmh498iqx00hewvoufzn59se3"},{"post_id":"cmh498iqe00cdwvou9wtxheij","tag_id":"cmh498iqu00gnwvoueqeffzp3","_id":"cmh498iqx00hgwvouaiyt9bbk"},{"post_id":"cmh498iqf00chwvouglttbu7x","tag_id":"cmh498iqx00hfwvoudletg7pb","_id":"cmh498iqx00hiwvouc44f004f"},{"post_id":"cmh498iqg00ckwvou9ven8kv6","tag_id":"cmh498iqu00gnwvoueqeffzp3","_id":"cmh498iqx00hkwvou897o26b1"},{"post_id":"cmh498iqg00cowvoufqha4uef","tag_id":"cmh498iqu00gnwvoueqeffzp3","_id":"cmh498iqx00hmwvouc9xadgnq"},{"post_id":"cmh498iqh00cswvoudssp2rfy","tag_id":"cmh498iqu00gnwvoueqeffzp3","_id":"cmh498iqx00howvoufu03heek"},{"post_id":"cmh498iqh00cvwvou3hrt4mm4","tag_id":"cmh498iqu00gnwvoueqeffzp3","_id":"cmh498iqy00hqwvou77ek77r7"},{"post_id":"cmh498iqi00d2wvouct9ubg2x","tag_id":"cmh498iqu00gnwvoueqeffzp3","_id":"cmh498iqy00hswvoub104bk6y"},{"post_id":"cmh498iqj00d9wvougkgu3pxh","tag_id":"cmh498iqu00gnwvoueqeffzp3","_id":"cmh498iqy00huwvou8d7s3s6g"},{"post_id":"cmh498iqk00ddwvou80ac70wq","tag_id":"cmh498iqu00gnwvoueqeffzp3","_id":"cmh498iqy00hwwvouelx5filr"},{"post_id":"cmh498iqk00dgwvou1244bccq","tag_id":"cmh498iqy00hvwvoubipsdjbd","_id":"cmh498iqy00hywvoudzraapde"},{"post_id":"cmh498iqk00dlwvou9815gcyr","tag_id":"cmh498iqy00hxwvouf9og0cic","_id":"cmh498iqy00i0wvougjru94ui"},{"post_id":"cmh498iql00dowvou3cfygoar","tag_id":"cmh498iqu00gnwvoueqeffzp3","_id":"cmh498iqz00i2wvou3z7pg6nl"},{"post_id":"cmh498iqm00dvwvoufw3ua8ri","tag_id":"cmh498iqu00gnwvoueqeffzp3","_id":"cmh498iqz00i4wvou6e8vh7kn"},{"post_id":"cmh498iqm00dywvou4iw3dngc","tag_id":"cmh498iqu00gnwvoueqeffzp3","_id":"cmh498iqz00i6wvoue38p8lr1"},{"post_id":"cmh498iqn00e2wvou6i2v0pnc","tag_id":"cmh498iqu00gnwvoueqeffzp3","_id":"cmh498iqz00i7wvou0gbmhdz9"},{"post_id":"cmh498ir200i8wvouac8423u4","tag_id":"cmh498iqq00eywvoueafd565e","_id":"cmh498ir300i9wvoufwmb34q9"}],"Tag":[{"name":"这是啥","_id":"cmh498ioc0005wvou6fvw7pla"},{"name":"阿甘","_id":"cmh498iof000cwvouekka9sc9"},{"name":"杂","_id":"cmh498ioh000iwvouaaka060z"},{"name":"外公","_id":"cmh498iom0013wvou6bn648ta"},{"name":"外婆","_id":"cmh498ioo0019wvou36zch6ax"},{"name":"电影","_id":"cmh498ioq001nwvou148e8f00"},{"name":"无题","_id":"cmh498ior001twvouhy2ledkg"},{"name":"迷雾","_id":"cmh498iot0026wvou51vu50q1"},{"name":"饭后感","_id":"cmh498iou002bwvou0an9g2yt"},{"name":"宁波","_id":"cmh498iow002lwvou611b3znx"},{"name":"憎恨","_id":"cmh498iox002rwvoud5qdhv8h"},{"name":"躯壳","_id":"cmh498ioy002zwvougebihk2w"},{"name":"逝者","_id":"cmh498ioz0035wvou1wochdf7"},{"name":"安息","_id":"cmh498ip0003dwvoudnpd88kx"},{"name":"好友","_id":"cmh498ip2003jwvouadky7rhm"},{"name":"成都","_id":"cmh498ip3003pwvou9v6kc1s9"},{"name":"打牌","_id":"cmh498ip4003wwvoueykbd68k"},{"name":"盆地","_id":"cmh498ip50045wvou03m0b1ad"},{"name":"茶铺","_id":"cmh498ip6004bwvou85fcadmh"},{"name":"读后感","_id":"cmh498ip6004gwvou6wde14nu"},{"name":"猫","_id":"cmh498ip7004nwvouapx48jgs"},{"name":"诡异","_id":"cmh498ip9004xwvoudou478k9"},{"name":"活着","_id":"cmh498ipa0052wvougwl48x4b"},{"name":"霸王别姬","_id":"cmh498ipb0059wvou08k3gxcz"},{"name":"命题作文","_id":"cmh498ipc005ewvoubett1rs5"},{"name":"雾霾","_id":"cmh498ipd005nwvoubwrxdvmr"},{"name":"grub","_id":"cmh498ipe005uwvou5rztfal5"},{"name":"电视剧","_id":"cmh498ipf0061wvou3s8w9zuw"},{"name":"妖怪","_id":"cmh498ipg0067wvou7wwtb3s0"},{"name":"web","_id":"cmh498iph006fwvouaf2b6so5"},{"name":"next","_id":"cmh498ipi006mwvouhrwh5z5d"},{"name":"paper","_id":"cmh498ipj006qwvou4hx1451h"},{"name":"hexo","_id":"cmh498ipl0072wvou35k4arlw"},{"name":"日记","_id":"cmh498ipt008kwvoue6443fl9"},{"name":"博客","_id":"cmh498ipu008rwvou6g40dke1"},{"name":"网易","_id":"cmh498ipv008ywvouhpj5gh6g"},{"name":"儿子","_id":"cmh498ipw0096wvouhjtd8hf3"},{"name":"反演","_id":"cmh498ipx009fwvoucj5i97gj"},{"name":"历史","_id":"cmh498ipy009mwvou65h05ths"},{"name":"sed","_id":"cmh498iq100a7wvou9g0i2dfm"},{"name":"Linux","_id":"cmh498iq500b0wvou7bg90nuc"},{"name":"blog","_id":"cmh498iq700bgwvoua2uubgwn"},{"name":"wiki","_id":"cmh498iq800bnwvou5n0bcx7h"},{"name":"linux","_id":"cmh498iqf00cfwvou33gkbpb8"},{"name":"axes","_id":"cmh498iqg00cnwvou2ti2hhvm"},{"name":"乱","_id":"cmh498iqh00cxwvouhnx59kur"},{"name":"过渡带","_id":"cmh498iqi00d4wvou8wd22268"},{"name":"model","_id":"cmh498iqj00dbwvou87bqc26o"},{"name":"中文","_id":"cmh498iqk00dkwvouff4q20o1"},{"name":"sem","_id":"cmh498iqm00dtwvoudxi85qgt"},{"name":"NCF","_id":"cmh498iqm00e0wvoufm8x5uxx"},{"name":"video","_id":"cmh498iqn00e7wvou8s3a6o2e"},{"name":"瘾","_id":"cmh498iqo00eewvouakzj2br8"},{"name":"filezilla","_id":"cmh498iqp00elwvou1f1m8tlj"},{"name":"work","_id":"cmh498iqq00eywvoueafd565e"},{"name":"git","_id":"cmh498iqr00f5wvouh50ibr20"},{"name":"学习","_id":"cmh498iqr00f8wvoug754c5hx"},{"name":"ai","_id":"cmh498iqs00frwvoudllgcybh"},{"name":"laTeX","_id":"cmh498iqt00fxwvou80rs102d"},{"name":"某日记","_id":"cmh498iqt00fzwvou25i8cwzb"},{"name":"大脑","_id":"cmh498iqt00g3wvou19wa3fg0"},{"name":"glacial seismology","_id":"cmh498iqu00g7wvouekrsgaqj"},{"name":"review","_id":"cmh498iqu00g9wvougxtq3nd7"},{"name":"code","_id":"cmh498iqu00gbwvou44ur1z0r"},{"name":"project","_id":"cmh498iqu00gdwvou07g2fwom"},{"name":"blogs","_id":"cmh498iqu00gewvou693pdz4p"},{"name":"science","_id":"cmh498iqu00ghwvougn0uehrx"},{"name":"seismic","_id":"cmh498iqu00giwvou2ykzg68g"},{"name":"Seismology","_id":"cmh498iqu00glwvoueg6o7zmm"},{"name":"python","_id":"cmh498iqu00gnwvoueqeffzp3"},{"name":"seismology","_id":"cmh498iqv00gpwvou8tcd8o50"},{"name":"obspy","_id":"cmh498iqv00gwwvou93ud901a"},{"name":"gmt","_id":"cmh498iqw00h7wvou1f8mh9nh"},{"name":"script","_id":"cmh498iqw00h9wvou376z37rk"},{"name":"乱笔","_id":"cmh498iqx00hfwvoudletg7pb"},{"name":"LaTeX","_id":"cmh498iqy00hvwvoubipsdjbd"},{"name":"Fun","_id":"cmh498iqy00hxwvouf9og0cic"}]}}